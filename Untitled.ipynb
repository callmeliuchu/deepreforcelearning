{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a3bc3ef-c357-4341-82fb-b5d1307d9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.bool8 = np.bool_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13dc9864-cfa8-4104-86bd-c8ed9814654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f40fd90-8ca9-477d-9e44-f5de89c2eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c8d5e8-1253-4a0b-b0fb-9555a477d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734b5d73-a8f3-45a2-9779-7c9e289e36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f92a06-efea-4d7b-a1dc-fc992ae2dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ca484aa-beeb-4ac0-b90e-c2e44387d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b61f32d-48b1-4b32-82bd-7a92b6b79d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_rate = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "271b6658-b7e4-4af5-88c5-3132031ea105",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f723c0-e7f0-4da3-b00c-d9c33d660603",
   "metadata": {},
   "outputs": [],
   "source": [
    "render = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eff16c6-4004-4a6c-8c0a-515b7c38c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 80 * 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f65705b-8292-4608-8bfd-95fd1b070dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume:\n",
    "    with open('save.p','rb') as f:\n",
    "        model = pickle.load(f)\n",
    "else:\n",
    "    model = {}\n",
    "    model['W1'] = np.random.randn(H,D) / np.sqrt(D)\n",
    "    model['W2'] = np.random.randn(H) / np.sqrt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd705389-2bff-477b-9e18-7d76e8507a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_buffer = {k:np.zeros_like(v) for k,v in model.items()}\n",
    "rmsprop_cache = {k:np.zeros_like(v) for k,v in model.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c9a2843-2d4b-46c7-83e0-6362104d0edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bf133b6-c6db-4bde-9cdf-38668a79088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(I):\n",
    "    I = I[35:195]\n",
    "    I = I[::2,::2,0]\n",
    "    I[I==144] = 0\n",
    "    I[I==109] = 0\n",
    "    I[I != 0] = 1\n",
    "    return I.astype(np.float32).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa48f43c-6f54-4c0d-a7df-9fa79bbfe168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro_1(I):\n",
    "    I = I[35:195]\n",
    "    I = I[::2,::2,0]\n",
    "    I[I==144] = 0\n",
    "    I[I==109] = 0\n",
    "    I[I != 0] = 1\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "061e018d-f825-4e2d-a8d4-38db09068689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(r):\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    for t in reversed(range(r.size)):\n",
    "        if r[t] != 0:\n",
    "            running_add = 0\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8d9a0e6-f133-4e4e-94bf-95eb1b9c7149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_forward(x):\n",
    "    h = np.dot(model['W1'],x)\n",
    "    h[h < 0] = 0\n",
    "    logp = np.dot(model['W2'],h)\n",
    "    p = sigmoid(logp)\n",
    "    return p, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3835cb90-ab61-44c5-a84e-57cace43841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_backward(eph,epdlogp):\n",
    "    dW2 = np.dot(eph.T,epdlogp).ravel()\n",
    "    dh = np.outer(epdlogp,model['W2'])\n",
    "    dh[eph <= 0] = 0\n",
    "    dW1 = np.dot(dh.T,eph)\n",
    "    return {'W1':dW1,'W2':dW2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d3d9321-42da-493c-8626-847d18509e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "# env = gym.make('Pong-v4',render_mode='human')\n",
    "env = gym.make('Pong-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb29a712-0275-479c-be2f-cdd96811162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07c7128f-131d-45ac-964d-5ccd9055d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = prepro(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cd44e34-dbd9-431c-8bf7-c16d782429d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d108fbb5-a1b1-4749-b8c7-18fd722e7fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c16df1e5-3b95-4585-8768-7b716866113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation,reward,terminated,truncated,info = env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b6b5b50-e6db-45de-bf82-466c306c7f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建一个随机的 (210, 160, 3) 矩阵\n",
    "image = observation\n",
    "# image = prepro_1(observation)\n",
    "\n",
    "# 使用 matplotlib 显示图像\n",
    "plt.imshow(image)\n",
    "# plt.axis('off')  # 隐藏坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "118ed5e2-dec1-4693-b65e-62728c95184b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建一个随机的 (210, 160, 3) 矩阵\n",
    "# image = observation\n",
    "image = prepro_1(observation)\n",
    "\n",
    "# 使用 matplotlib 显示图像\n",
    "plt.imshow(image)\n",
    "# plt.axis('off')  # 隐藏坐标轴\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4dc76670-39bc-47f8-8799-1523de08a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec75b4c0-2055-4d4e-8017-ba9316488ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/kds62tbj3x93zghv2_jz1xsr0000gn/T/ipykernel_88277/3593694649.py:39: RuntimeWarning: invalid value encountered in divide\n",
      "  discounted_epr /= np.std(discounted_epr)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (200,6400) and (1,200) not aligned: 6400 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m discounted_epr \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(discounted_epr)\n\u001b[1;32m     41\u001b[0m epdlog \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m discounted_epr\n\u001b[0;32m---> 42\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43meph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m model:\n\u001b[1;32m     45\u001b[0m     grad_buffer[k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grad[k]\n",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m, in \u001b[0;36mpolicy_forward\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpolicy_forward\u001b[39m(x):\n\u001b[0;32m----> 2\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mW1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     h[h \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m'\u001b[39m],h)\n\u001b[1;32m      4\u001b[0m     logp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m'\u001b[39m],h)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (200,6400) and (1,200) not aligned: 6400 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "prev_x = None\n",
    "xs,hs,dlogs,drs = [],[],[],[]\n",
    "running_reward = None\n",
    "reward_sum = 0\n",
    "episode_number = 0\n",
    "for i in range(10):\n",
    "    if render:\n",
    "        env.render()\n",
    "\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    aprob,h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3 # god don‘t  dice\n",
    "\n",
    "    xs.append(x)\n",
    "    hs.append(h)\n",
    "\n",
    "    y = 1 if action == 2 else 0\n",
    "    dlogs.append(y-aprob)\n",
    "\n",
    "    observation,reward,terminated,truncated,info = env.step(action)\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        episode_number += 1\n",
    "\n",
    "        epx = np.vstack(xs)\n",
    "        eph = np.vstack(hs)\n",
    "        epdlog = np.vstack(dlogs)\n",
    "        epr = np.vstack(drs)\n",
    "        xs,hs,dlogs,drs = [],[],[],[]\n",
    "\n",
    "        discounted_epr = discount_rewards(epr)\n",
    "        discounted_epr -= np.mean(discounted_epr)\n",
    "        discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "        epdlog *= discounted_epr\n",
    "        grad = policy_forward(eph)\n",
    "\n",
    "        for k in model:\n",
    "            grad_buffer[k] += grad[k]\n",
    "\n",
    "        if episode_number % batch_size == 0:\n",
    "            for k,v in model.items():\n",
    "                g = grad_buffer[k]\n",
    "                rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1-decay_rate) * g ** 2\n",
    "                model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k] + 1e-5))\n",
    "                grad_buffer[k] = np.zeros_like(v)\n",
    "\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        print(f'resetting env. episode reward total was {reward_sum}. running mean: {running_reward}')\n",
    "        if episode_number % 100 == 0:\n",
    "            with open('save.p','wb') as f:\n",
    "                pickle.dump(model,f)\n",
    "        reward_sum = 0\n",
    "        observation, _= env.reset()\n",
    "        prev_x = None\n",
    "\n",
    "    if reward != 0:\n",
    "        print(f'ep {episode_number}: game finished, reward: {reward}' + ('' if reward == -1 else ' !!!!!!!!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800cefc8-2b01-444b-a2c2-feaadd29fc73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a21563-c808-478a-b242-dbb83ee69ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c91951-c7e1-491a-b32a-119ea151bf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c336ff3-f8c7-4681-98b1-b34daf43aa05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3be59d8f-0137-4fc8-aed5-44d9d3ab2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_x = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6876e507-7cb5-4a9b-83b5-090db0d20232",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,hs,dlogs,drs = [],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "60dd7b04-e346-405a-9bec-5c2a92defbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_reward = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb01b55b-f0b8-43eb-874c-a1df2b8053c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1d00ea9c-b30c-47fe-bad6-07ac296970ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18432c65-c6d7-414d-b1a6-0bf81dbf1377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:13:33.649 python[61724:40888590] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-03 13:13:33.649 python[61724:40888590] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n",
      "2025-03-03 13:13:33.712 python[61724:40888590] TSM AdjustCapsLockLEDForKeyTransitionHandling - _ISSetPhysicalKeyboardCapsLockLED Inhibit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n",
      "ep 0: game finished, reward: -1.0\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    if render:\n",
    "        env.render()\n",
    "\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    aprob,h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3 # god don‘t  dice\n",
    "\n",
    "    xs.append(x)\n",
    "    hs.append(h)\n",
    "\n",
    "    y = 1 if action == 2 else 0\n",
    "    dlogs.append(y-aprob)\n",
    "\n",
    "    observation,reward,terminated,truncated,info = env.step(action)\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        episode_number += 1\n",
    "\n",
    "        epx = np.vstack(xs)\n",
    "        eph = np.vstack(hs)\n",
    "        epdlog = np.vstack(dlogs)\n",
    "        epr = np.vstack(drs)\n",
    "        xs,hs,dlogs,drs = [],[],[],[]\n",
    "\n",
    "        discounted_epr = discount_rewards(epr)\n",
    "        discounted_epr -= np.mean(discounted_epr)\n",
    "        discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "        epdlog *= discounted_epr\n",
    "        grad = policy_forward(eph,epdlog)\n",
    "\n",
    "        for k in model:\n",
    "            grad_buffer[k] += grad[k]\n",
    "\n",
    "        if episode_number % batch_size == 0:\n",
    "            for k,v in model.items():\n",
    "                g = grad_buffer[k]\n",
    "                rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1-decay_rate) * g ** 2\n",
    "                model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k] + 1e-5))\n",
    "                grad_buffer[k] = np.zeros_like(v)\n",
    "\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        print(f'resetting env. episode reward total was {reward_sum}. running mean: {running_reward}')\n",
    "        if episode_number % 100 == 0:\n",
    "            with open('save.p','wb') as f:\n",
    "                pickle.dump(model,f)\n",
    "        reward_sum = 0\n",
    "        observation, _= env.reset()\n",
    "        prev_x = None\n",
    "\n",
    "    if reward != 0:\n",
    "        print(f'ep {episode_number}: game finished, reward: {reward}' + ('' if reward == -1 else ' !!!!!!!!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c71fc-89a2-40c5-9676-8243493b99ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f01b3-9c37-49b6-85cc-bfb2552dd761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2adce179-168e-4288-b2ba-073100ea607c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: game finished, reward: -1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle  # 用 pickle 替代 cPickle\n",
    "import gym\n",
    "\n",
    "np.bool8 = np.bool_\n",
    "\n",
    "# 超参数\n",
    "H = 200  # 隐藏层神经元数量\n",
    "batch_size = 10  # 每多少集进行一次参数更新\n",
    "learning_rate = 1e-3\n",
    "gamma = 0.99  # 折扣因子\n",
    "decay_rate = 0.99  # RMSProp 衰减因子\n",
    "resume = False  # 是否从以前的检查点恢复\n",
    "render = False\n",
    "\n",
    "# 模型初始化\n",
    "D = 80 * 80  # 输入维度：80x80 网格\n",
    "if resume:\n",
    "    with open('save.p', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "else:\n",
    "    model = {}\n",
    "    model['W1'] = np.random.randn(H, D) / np.sqrt(D)  # \"Xavier\" 初始化\n",
    "    model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
    "\n",
    "# 更新缓存，用于 RMSProp 平滑梯度\n",
    "grad_buffer = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "rmsprop_cache = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))  # sigmoid 函数\n",
    "\n",
    "def prepro(I):\n",
    "    \"\"\"将 210x160x3 uint8 帧预处理为 6400 (80x80) 1D float 向量\"\"\"\n",
    "    I = I[35:195]  # 裁剪\n",
    "    I = I[::2, ::2, 0]  # 下采样因子为 2\n",
    "    I[I == 144] = 0  # 删除背景类型 1\n",
    "    I[I == 109] = 0  # 删除背景类型 2\n",
    "    I[I != 0] = 1  # 其他设置为 1\n",
    "    return I.astype(np.float32).ravel()\n",
    "\n",
    "def discount_rewards(r):\n",
    "    \"\"\"对奖励进行折扣\"\"\"\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    for t in reversed(range(r.size)):\n",
    "        if r[t] != 0: running_add = 0  # 如果是游戏边界（仅对 Pong 特有）\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "    return discounted_r\n",
    "\n",
    "def policy_forward(x):\n",
    "    h = np.dot(model['W1'], x)\n",
    "    h[h < 0] = 0  # ReLU\n",
    "    logp = np.dot(model['W2'], h)\n",
    "    p = sigmoid(logp)\n",
    "    return p, h  # 返回采取动作 2 的概率和隐藏状态\n",
    "\n",
    "def policy_backward(eph, epdlogp):\n",
    "    \"\"\"反向传播（eph 为隐藏状态数组）\"\"\"\n",
    "    dW2 = np.dot(eph.T, epdlogp).ravel()\n",
    "    dh = np.outer(epdlogp, model['W2'])\n",
    "    dh[eph <= 0] = 0  # Backprop ReLU\n",
    "    dW1 = np.dot(dh.T, epx)\n",
    "    return {'W1': dW1, 'W2': dW2}\n",
    "\n",
    "# 训练\n",
    "env = gym.make(\"Pong-v4\")\n",
    "observation, _ = env.reset()\n",
    "prev_x = None  # 用于计算差分帧\n",
    "xs, hs, dlogps, drs = [], [], [], []\n",
    "running_reward = None\n",
    "reward_sum = 0\n",
    "episode_number = 0\n",
    "\n",
    "for i in range(100):\n",
    "    if render: env.render()\n",
    "\n",
    "    # 预处理观测，设定网络输入为差分图像\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    # 前向传播并采样动作\n",
    "    aprob, h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3  # 投掷骰子！\n",
    "\n",
    "    # 记录中间变量（后续用于反向传播）\n",
    "    xs.append(x)  # 观测值\n",
    "    hs.append(h)  # 隐藏状态\n",
    "    # print(xs)\n",
    "    # print(hs)\n",
    "    y = 1 if action == 2 else 0  # “伪标签”\n",
    "    dlogps.append(y - aprob)  # 梯度鼓励采取的动作\n",
    "\n",
    "    # 环境步进，获取新状态\n",
    "    observation, reward, terminated, truncated, info = env.step(action)  # 更新为新的返回值\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward)  # 记录奖励\n",
    "\n",
    "    if terminated or truncated:  # 一个回合结束\n",
    "        episode_number += 1\n",
    "\n",
    "        # 堆叠输入、隐藏状态、动作梯度和奖励\n",
    "        epx = np.vstack(xs)\n",
    "        eph = np.vstack(hs)\n",
    "        epdlogp = np.vstack(dlogps)\n",
    "        epr = np.vstack(drs)\n",
    "        xs, hs, dlogps, drs = [], [], [], []  # 重置数组\n",
    "\n",
    "        # 计算折扣奖励\n",
    "        print('epr.shape',epr.shape)\n",
    "        discounted_epr = discount_rewards(epr)\n",
    "        print('discounted_epr.shape',discounted_epr.shape)\n",
    "        # 标准化奖励\n",
    "        discounted_epr -= np.mean(discounted_epr)\n",
    "        discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "        epdlogp *= discounted_epr  # 使用优势调制梯度\n",
    "        grad = policy_backward(eph, epdlogp)\n",
    "        for k in model: grad_buffer[k] += grad[k]  # 在 batch 中累积梯度\n",
    "\n",
    "        # 每 batch_size 集执行 RMSProp 参数更新\n",
    "        if episode_number % batch_size == 0:\n",
    "            for k, v in model.items():\n",
    "                g = grad_buffer[k]\n",
    "                rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g ** 2\n",
    "                model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "                print(model[k])\n",
    "                grad_buffer[k] = np.zeros_like(v)  # 重置 batch 梯度缓存\n",
    "\n",
    "        # 记录\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        print(f'resetting env. episode reward total was {reward_sum}. running mean: {running_reward}')\n",
    "        if episode_number % 100 == 0:\n",
    "            with open('save.p', 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "        reward_sum = 0\n",
    "        observation, _ = env.reset()\n",
    "        prev_x = None\n",
    "\n",
    "    if reward != 0:  # Pong 的奖励为 +1 或 -1（游戏结束时）\n",
    "        print(f'ep {episode_number}: game finished, reward: {reward}' + ('' if reward == -1 else ' !!!!!!!!'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "378f6595-2d61-4552-9f6b-58975a4627e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "ep 161: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.567037621842005\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "ep 162: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.571367245623584\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "ep 163: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.575653573167347\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "ep 164: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.579897037435675\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "ep 165: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.58409806706132\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "ep 166: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.58825708639071\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "ep 167: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.592374515526803\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "ep 168: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.596450770371536\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "ep 169: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.600486262667822\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "ep 170: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.604481400041145\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "ep 171: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.608436586040735\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "ep 172: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.612352220180327\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "ep 173: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.616228697978524\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "ep 174: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.62006641099874\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "ep 175: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.62386574688875\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "ep 176: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.627627089419864\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "ep 177: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.631350818525664\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "ep 178: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.635037310340408\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "ep 179: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.638686937237004\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "ep 180: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.642300067864635\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "ep 181: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.64587706718599\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "ep 182: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.64941829651413\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "ep 183: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.65292411354899\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "ep 184: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.6563948724135\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "ep 185: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.659830923689366\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "ep 186: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.663232614452472\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "ep 187: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.666600288307947\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "ep 188: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.66993428542487\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "ep 189: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.67323494257062\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "ep 190: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.676502593144914\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "ep 191: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.679737567213465\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "ep 192: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.68294019154133\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "ep 193: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.686110789625918\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "ep 194: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.68924968172966\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "ep 195: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.692357184912364\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "ep 196: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.69543361306324\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "ep 197: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.69847927693261\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "ep 198: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.701494484163284\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "ep 199: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.704479539321653\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "ep 200: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.707434743928438\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "ep 201: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.710360396489154\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "ep 202: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.713256792524263\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "ep 203: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71612422459902\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "ep 204: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71896298235303\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "ep 205: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.7217733525295\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "ep 206: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.724555619004207\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "ep 207: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.727310062814166\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "ep 208: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.730036962186023\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "ep 209: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.732736592564162\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "ep 210: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73540922663852\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "ep 211: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.738055134372136\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "ep 212: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.740674583028415\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "ep 213: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.743267837198132\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "ep 214: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.745835158826154\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "ep 215: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.748376807237893\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "ep 216: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.750893039165515\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "ep 217: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.75338410877386\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "ep 218: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.755850267686125\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "ep 219: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.758291765009265\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "ep 220: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.760708847359172\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "ep 221: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.763101758885583\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "ep 222: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.765470741296728\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "ep 223: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.76781603388376\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "ep 224: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.770137873544925\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "ep 225: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.772436494809476\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "ep 226: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.77471212986138\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "ep 227: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.77696500856277\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "ep 228: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.779195358477143\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "ep 229: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.781403404892373\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "ep 230: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.78358937084345\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "ep 231: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.785753477135017\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "ep 232: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.78789594236367\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "ep 233: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.79001698294003\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "ep 234: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.79211681311063\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "ep 235: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.794195644979524\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "ep 236: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.79625368852973\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "ep 237: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.798291151644435\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "ep 238: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.80030824012799\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "ep 239: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.80230515772671\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "ep 240: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.804282106149444\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "ep 241: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.80623928508795\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "ep 242: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.80817689223707\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "ep 243: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.810095123314703\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "ep 244: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.811994172081558\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "ep 245: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.813874230360742\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "ep 246: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.815735488057136\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "ep 247: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.817578133176564\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "ep 248: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.8194023518448\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "ep 249: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.821208328326353\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "ep 250: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.82299624504309\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "ep 251: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.82476628259266\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "ep 252: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.826518619766734\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "ep 253: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.828253433569067\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "ep 254: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.829970899233377\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "ep 255: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.831671190241043\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "ep 256: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.833354478338634\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "ep 257: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.83502093355525\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "ep 258: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.836670724219697\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "ep 259: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.8383040169775\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "ep 260: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.839920976807726\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "ep 261: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.841521767039648\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "ep 262: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.843106549369253\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "ep 263: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.844675483875562\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "ep 264: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.846228729036806\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "ep 265: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.84776644174644\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "ep 266: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.849288777328976\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "ep 267: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.850795889555688\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "ep 268: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.852287930660133\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "ep 269: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.85376505135353\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "ep 270: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.855227400839997\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "ep 271: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.856675126831597\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "ep 272: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.858108375563283\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "ep 273: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.85952729180765\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "ep 274: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.860932018889574\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "ep 275: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.86232269870068\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "ep 276: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.863699471713673\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "ep 277: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.86506247699654\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "ep 278: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.866411852226573\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "ep 279: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.86774773370431\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "ep 280: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.869070256367266\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "ep 281: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.870379553803595\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "ep 282: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.87167575826556\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "ep 283: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.872959000682904\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "ep 284: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.874229410676076\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "ep 285: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.875487116569317\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "ep 286: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.876732245403623\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "ep 287: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.877964922949587\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "ep 288: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.879185273720093\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "ep 289: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.880393420982895\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "ep 290: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.881589486773066\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "ep 291: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.882773591905337\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "ep 292: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.883945855986283\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "ep 293: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.885106397426423\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "ep 294: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.88625533345216\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "ep 295: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.887392780117636\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "ep 296: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.888518852316462\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "ep 297: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.889633663793298\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "ep 298: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.890737327155364\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "ep 299: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.89182995388381\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "ep 300: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.892911654344974\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "ep 301: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.893982537801524\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "ep 302: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.89504271242351\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "ep 303: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.896092285299275\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "ep 304: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.897131362446284\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "ep 305: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.898160048821822\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "ep 306: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.899178448333604\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "ep 307: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.900186663850267\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "ep 308: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.901184797211766\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "ep 309: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.90217294923965\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "ep 310: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.903151219747254\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "ep 311: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.904119707549782\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "ep 312: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.905078510474286\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "ep 313: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.906027725369544\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "ep 314: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.90696744811585\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "ep 315: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.90789777363469\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "ep 316: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.908818795898345\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "ep 317: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.909730607939363\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "ep 318: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.91063330185997\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "ep 319: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.911526968841372\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "ep 320: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.91241169915296\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "ep 321: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.91328758216143\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "ep 322: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.91415470633982\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "ep 323: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.91501315927642\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "ep 324: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.915863027683656\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "ep 325: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.91670439740682\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "ep 326: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.917537353432753\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "ep 327: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.918361979898425\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "ep 328: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.91917836009944\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "ep 329: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.919986576498445\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "ep 330: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.920786710733463\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "ep 331: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.92157884362613\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "ep 332: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.92236305518987\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "ep 333: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.92313942463797\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "ep 334: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.92390803039159\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "ep 335: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.924668950087675\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "ep 336: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.9254222605868\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "ep 337: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.926168037980933\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "ep 338: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.926906357601123\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "ep 339: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.92763729402511\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "ep 340: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.92836092108486\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "ep 341: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.92907731187401\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "ep 342: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.92978653875527\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "ep 343: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.93048867336772\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "ep 344: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.931183786634044\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "ep 345: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.931871948767704\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "ep 346: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.93255322928003\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "ep 347: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.933227696987228\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "ep 348: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.933895420017357\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "ep 349: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.934556465817185\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "ep 350: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.935210901159014\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "ep 351: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.935858792147425\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "ep 352: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.93650020422595\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "ep 353: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.937135202183693\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "ep 354: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.937763850161858\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "ep 355: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.93838621166024\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "ep 356: game finished, reward: -1.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.93900234954364\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n",
      "ep 357: game finished, reward: -1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(200000):\n",
    "    if render:\n",
    "        env.render()\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prex_x = cur_x\n",
    "\n",
    "    aprob,h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3\n",
    "\n",
    "    xs.append(x)\n",
    "    hs.append(h)\n",
    "    y = 1 if action == 2 else 0\n",
    "    dlogps.append(y-aprob)\n",
    "\n",
    "    observation,reward,terminated,truncated,info = env.step(action)\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        episode_number += 1\n",
    "        epx = np.vstack(xs)\n",
    "        eph = np.vstack(hs)\n",
    "        epdlogp = np.vstack(dlogps)\n",
    "        epr = np.vstack(drs)\n",
    "\n",
    "        xs,hs,dlogps,drs = [],[],[],[]\n",
    "\n",
    "        discounted_epr = discount_rewards(epr)\n",
    "\n",
    "        discounted_epr -= np.mean(discounted_epr)\n",
    "        discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "\n",
    "        epdlogp *= discounted_epr\n",
    "        grad = policy_backward(eph,epdlogp)\n",
    "\n",
    "        for k in model:\n",
    "            grad_buffer[k] += grad[k]\n",
    "\n",
    "\n",
    "        if episode_number % batch_size == 0:\n",
    "            for k,v in model.items():\n",
    "                g = grad_buffer[k]\n",
    "                rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1-decay_rate) * g ** 2\n",
    "                model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "                grad_buffer[k] = np.zeros_like(v)\n",
    "\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        print(f'resetting env. episode reward total was {reward_sum}. running mean: {running_reward}')\n",
    "\n",
    "        if episode_number % 100 == 0:\n",
    "            with open('save.p','wb') as f:\n",
    "                pickle.dump(model,f)\n",
    "        reward_sum = 0\n",
    "        observation, _ = env.reset()\n",
    "        prev_x = None\n",
    "\n",
    "    if reward != 0:  # Pong 的奖励为 +1 或 -1（游戏结束时）\n",
    "        print(f'ep {episode_number}: game finished, reward: {reward}' + ('' if reward == -1 else ' !!!!!!!!'))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e957c-8e60-4a4f-9744-246fddf77abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58796a65-f533-4b66-ac57-f52a06c1903f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "106c471a-b818-4110-a957-869f9c85d676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/kds62tbj3x93zghv2_jz1xsr0000gn/T/ipykernel_14744/298534476.py:39: RuntimeWarning: invalid value encountered in divide\n",
      "  discounted_epr /= np.std(discounted_epr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02277965  0.00900196 -0.00728398 ...  0.00266152  0.01104859\n",
      "   0.02041154]\n",
      " [ 0.0093176  -0.00426942  0.01031506 ...  0.00788837  0.01127802\n",
      "   0.0026124 ]\n",
      " [-0.00447577  0.00523385  0.00864176 ... -0.01528173 -0.00394352\n",
      "  -0.01766596]\n",
      " ...\n",
      " [        nan         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " [        nan         nan         nan ...         nan         nan\n",
      "          nan]\n",
      " [ 0.01184669 -0.00311401 -0.01040178 ...  0.00350182 -0.0149264\n",
      "  -0.00914175]]\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "resetting env. episode reward total was -20.0. running mean: -20.52126165464548\n",
      "resetting env. episode reward total was -21.0. running mean: -20.526049038099025\n",
      "resetting env. episode reward total was -21.0. running mean: -20.530788547718036\n",
      "resetting env. episode reward total was -21.0. running mean: -20.535480662240857\n",
      "resetting env. episode reward total was -21.0. running mean: -20.54012585561845\n",
      "resetting env. episode reward total was -21.0. running mean: -20.544724597062263\n",
      "resetting env. episode reward total was -21.0. running mean: -20.549277351091643\n",
      "resetting env. episode reward total was -21.0. running mean: -20.55378457758073\n",
      "resetting env. episode reward total was -21.0. running mean: -20.55824673180492\n",
      "resetting env. episode reward total was -21.0. running mean: -20.562664264486873\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    if render: env.render()\n",
    "\n",
    "    # 预处理观测，设定网络输入为差分图像\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    # 前向传播并采样动作\n",
    "    aprob, h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3  # 投掷骰子！\n",
    "\n",
    "    # 记录中间变量（后续用于反向传播）\n",
    "    xs.append(x)  # 观测值\n",
    "    hs.append(h)  # 隐藏状态\n",
    "    y = 1 if action == 2 else 0  # “伪标签”\n",
    "    dlogps.append(y - aprob)  # 梯度鼓励采取的动作\n",
    "\n",
    "    # 环境步进，获取新状态\n",
    "    observation, reward, terminated, truncated, info = env.step(action)  # 更新为新的返回值\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward)  # 记录奖励\n",
    "\n",
    "    if terminated or truncated:  # 一个回合结束\n",
    "        episode_number += 1\n",
    "\n",
    "        # 堆叠输入、隐藏状态、动作梯度和奖励\n",
    "        epx = np.vstack(xs)\n",
    "        eph = np.vstack(hs)\n",
    "        epdlogp = np.vstack(dlogps)\n",
    "        epr = np.vstack(drs)\n",
    "        xs, hs, dlogps, drs = [], [], [], []  # 重置数组\n",
    "\n",
    "        # 计算折扣奖励\n",
    "        discounted_epr = discount_rewards(epr)\n",
    "        # 标准化奖励\n",
    "        discounted_epr -= np.mean(discounted_epr)\n",
    "        discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "        epdlogp *= discounted_epr  # 使用优势调制梯度\n",
    "        grad = policy_backward(eph, epdlogp)\n",
    "        for k in model: grad_buffer[k] += grad[k]  # 在 batch 中累积梯度\n",
    "\n",
    "        # 每 batch_size 集执行 RMSProp 参数更新\n",
    "        if episode_number % batch_size == 0:\n",
    "            for k, v in model.items():\n",
    "                g = grad_buffer[k]\n",
    "                rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g ** 2\n",
    "                model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "                print(model[k])\n",
    "                grad_buffer[k] = np.zeros_like(v)  # 重置 batch 梯度缓存\n",
    "\n",
    "        # 记录\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        print(f'resetting env. episode reward total was {reward_sum}. running mean: {running_reward}')\n",
    "        if episode_number % 100 == 0:\n",
    "            with open('save.p', 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "        reward_sum = 0\n",
    "        observation, _ = env.reset()\n",
    "        prev_x = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50da0629-316f-4fc1-a795-d1bdddcd8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "\n",
    "    if render:\n",
    "        env.render()\n",
    "\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prev_x = cur_x\n",
    "\n",
    "\n",
    "    aprob, h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3\n",
    "\n",
    "    xs.append(x)\n",
    "    hs.append(h)\n",
    "\n",
    "    y = 1 if action == 2 else 0\n",
    "    dlogps.append(y - aprob)\n",
    "\n",
    "    observation,reward,terminated,truncated,info = env.step(action)\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        episode_number += 1\n",
    "\n",
    "        epx = np.vstack(xs)\n",
    "        eph = np.vstack(hs)\n",
    "        epdlogp = np.vstack(dlogps)\n",
    "        epr = np.vstack(drs)\n",
    "\n",
    "        xs,hs,dlogps,drs = [],[],[],[]\n",
    "\n",
    "        discounted_epr = discount_rewards(epr)\n",
    "\n",
    "        discounted_epr -= np.mean(discounted_epr)\n",
    "        discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "        epdlogp *= discounted_epr\n",
    "        grad = policy_backward(eph,epdlogp)\n",
    "\n",
    "        for k in model:\n",
    "            grad_buffer[k] += grad[k]\n",
    "\n",
    "        if episode_number % batch_size == 0:\n",
    "\n",
    "            for k,v in model.items():\n",
    "                g = grad_buffer[k]\n",
    "                rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1-decay_rate)*g**2\n",
    "                model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k])+1e-5)\n",
    "                grad_buffer[k] = np.zeros_like(v)\n",
    "\n",
    "\n",
    "        reward_sum = 0\n",
    "        observation,_ = env.reset()\n",
    "        prev_x = None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc37fd10-2d71-4be8-8cca-4ab395f1a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_forward(x):\n",
    "    h = np.dot(model['W1'], x)\n",
    "    h[h < 0] = 0  # ReLU\n",
    "    logp = np.dot(model['W2'], h)\n",
    "    p = sigmoid(logp)\n",
    "    return p, h  # 返回采取动作 2 的概率和隐藏状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ac05167-7930-431a-83f6-fe8b2b95ada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume:\n",
    "    with open('save.p','rb') as f:\n",
    "        model = pickle.load(f)\n",
    "else:\n",
    "    model = {}\n",
    "    model['W1'] = np.random.randn(H,D) / np.sqrt(D)\n",
    "    model['W2'] = np.random.randn(H) / np.sqrt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5abac216-5d96-451c-9c57-725394a4c157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "accc362c-68f6-4483-9442-99f093a41854",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = policy_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d64a34e-cb01-478b-b943-78fc1c722308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7df3dd1-8908-4355-943c-d7d29563a596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5006136318227263)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5cd34c85-0b9b-4162-a865-70775b2c519c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan]]),\n",
       " array([[nan],\n",
       "        [nan]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eph,epdlogp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ef6c4fd-8faf-40d9-8da2-53e31a19513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = policy_backward(eph,epdlogp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "399d3ab7-63b8-4ccc-acbe-9d298c5b6b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], shape=(200, 6400)),\n",
       " 'W2': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc7e5dd6-056a-46b9-9f0c-a1e7779b13a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-21.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f802bcf-18f7-4879-9ac8-64690b86e859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-21.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounted_epr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ba3ca1d-9554-494a-9798-452bab6b7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "discounted_epr = discount_rewards(epr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ce67cfb-9ccf-4e1e-851e-861697e360d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "discounted_epr -= np.mean(discounted_epr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d10a673f-8261-4c13-87c8-b005b0ca291e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounted_epr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a940903-3d6c-4d6c-a425-9478926bd627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(discounted_epr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d4b48e1-9dc6-4bb5-92b7-22ba8bce70d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.509334207259728\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.504473939557276\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.5064086312235883\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.5039604038129754\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.5011307427216143\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.5048138455075567\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.5059060769126392\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.49977011014645045\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.5034903124654426\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.4984333037161512\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.4881871011134745\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.49707727193804657\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.49325909494698705\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.5070668807879198\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.5048311838743476\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.49403156624147293\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.5095364168951741\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.4898218907250551\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.49170552314191907\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.5006136318227263\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "\n",
    "    if render:\n",
    "        env.render()\n",
    "\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros_like(D)\n",
    "    prev_x = cur_x\n",
    "    print(x)\n",
    "    aprob, h = policy_forward(x)\n",
    "    print(aprob)\n",
    "    action = 2 if np.random.uniform() < aprob else 3\n",
    "\n",
    "    xs.append(x)\n",
    "    hs.append(h)\n",
    "    y = 1 if action == 2 else 0\n",
    "    dlogps.append(y-aprob)\n",
    "\n",
    "    observation,reward,terminated,truncated,info = env.step(action)\n",
    "\n",
    "    reward_sum += reward\n",
    "    drs.append(reward_sum)\n",
    "\n",
    "    if terminated or truncated:\n",
    "\n",
    "        episode_number += 1\n",
    "        epx = np.vstack(xs)\n",
    "        eph = np.vstack(hs)\n",
    "        epdlogp = np.vstack(dlogps)\n",
    "        epr = np.vstack(drs)\n",
    "\n",
    "        xs,hs,dlogps,drs = [],[],[],[]\n",
    "\n",
    "        discounted_epr = discount_rewards(epr)\n",
    "\n",
    "        discounted_epr -= np.mean(discounted_epr)\n",
    "        discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "\n",
    "        epdlogp *= discounted_epr\n",
    "        grad = policy_backward(eph,epdlogp)\n",
    "        for k in model:\n",
    "            grad_buffer[k] += grad[k]\n",
    "\n",
    "        if episode_number % batch_size:\n",
    "            for k,v in model.items():\n",
    "                g = grad_buffer[k]\n",
    "                rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1-decay_rate) * g ** 2\n",
    "                model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "                grad_buffer[k] = np.zeros_like(v)\n",
    "\n",
    "        reward_sum = 0\n",
    "        observation,_ = env.reset()\n",
    "        prev_x = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab1394f6-db3f-427b-94c4-718abc43f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "])\n",
    "x = np.array([1,1,1])\n",
    "y = np.array([2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d3a5ba39-d685-44ae-bf45-244dcd52fb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 15])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12994363-9b14-4e42-8e89-f2d5f5b91bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [2, 2, 2]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3e448552-58a7-4a00-ba18-af2d6c501791",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,1,1])\n",
    "A = np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc64aa0-962a-4af1-9b5c-909dc352be74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1ab95d70-ffa8-4ab0-aa3b-d6e579ff5cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/kds62tbj3x93zghv2_jz1xsr0000gn/T/ipykernel_14744/531353037.py:38: RuntimeWarning: invalid value encountered in divide\n",
      "  discounted_epr /= np.std(discounted_epr)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (200,1) and (1784,1) not aligned: 1 (dim 1) != 1784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m discounted_epr \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(discounted_epr)\n\u001b[1;32m     40\u001b[0m epdlogp \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m discounted_epr\n\u001b[0;32m---> 41\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43meph\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepdlogp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m model:\n\u001b[1;32m     43\u001b[0m     grad_buffer[k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grad[k]\n",
      "Cell \u001b[0;32mIn[6], line 61\u001b[0m, in \u001b[0;36mpolicy_backward\u001b[0;34m(eph, epdlogp)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpolicy_backward\u001b[39m(eph, epdlogp):\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"反向传播（eph 为隐藏状态数组）\"\"\"\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     dW2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43meph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepdlogp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m     62\u001b[0m     dh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(epdlogp, model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     63\u001b[0m     dh[eph \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Backprop ReLU\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (200,1) and (1784,1) not aligned: 1 (dim 1) != 1784 (dim 0)"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "\n",
    "    if render:\n",
    "        env.render()\n",
    "\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    aprob,h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3\n",
    "\n",
    "    xs.append(x)\n",
    "    hs.append(h)\n",
    "\n",
    "    y = 1 if action == 2 else 0\n",
    "    dlogps.append(y-aprob)\n",
    "\n",
    "    observation,reward,terminated,truncated,info = env.step(action)\n",
    "\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward_sum)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        episode_number += 1\n",
    "\n",
    "        epx = np.vstack(xs)\n",
    "        eph = np.vstack(hs)\n",
    "        epdlogp = np.vstack(dlogps)\n",
    "        epr = np.vstack(drs)\n",
    "\n",
    "        xs,hs,dlogs,drs = [],[],[],[]\n",
    "        discounted_epr = discount_rewards(epr)\n",
    "\n",
    "\n",
    "        discounted_epr -= np.mean(discounted_epr)\n",
    "        discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "        epdlogp *= discounted_epr\n",
    "        grad = policy_backward(eph,epdlogp)\n",
    "        for k in model:\n",
    "            grad_buffer[k] += grad[k]\n",
    "\n",
    "        if episode_number % batch_size == 0:\n",
    "            for k,v in model.items():\n",
    "                g = grad_buffer[k]\n",
    "                rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1-decay_rate) * g ** 2\n",
    "                model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "                grad_buffer[k] = np.zeros_like(v)\n",
    "\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        print(f'resetting env. episode reward total was {reward_sum}. running mean: {running_reward}')\n",
    "        reward_sum = 0\n",
    "        observation, _= env.reset()\n",
    "        prev_x = None\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5685a27e-c2c6-4ff6-8353-23dc152bcc54",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (3,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m a1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m      2\u001b[0m b1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m],[\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],[\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m]])\n\u001b[0;32m----> 3\u001b[0m \u001b[43ma1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (3,2) "
     ]
    }
   ],
   "source": [
    "a1 = np.array([1,2,3])\n",
    "b1 = np.array([[2,1],[3,4],[4,5]])\n",
    "a1 * b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97e88f-0786-43d4-bd33-ef05df64ba7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
