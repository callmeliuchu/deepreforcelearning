{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7786b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c7a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CliffWalking-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4a11995",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bool8 = np.bool_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f2d4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.reset()\n",
    "# state,_ = env.reset()\n",
    "# done = False\n",
    "# while not done:\n",
    "#     env.render()\n",
    "#     action = int(np.random.choice([2,3]))\n",
    "#     next_state, reward, done, truncated, _ = env.sten\n",
    "# #     2 -1 36 False {'prob': 1.0}\n",
    "#     print(action,reward,next_state,done,_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b2e882a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e33908c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2c4c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueIteration:\n",
    "    \n",
    "    def __init__(self,env):\n",
    "        self.pi = [None for _ in range(env.observation_space.n)]\n",
    "        self.v = [0]*env.observation_space.n\n",
    "        self.gamma = 0.9\n",
    "        self.env = env\n",
    "    \n",
    "    def value_iterate(self):\n",
    "        cnt = 0\n",
    "        while 1:\n",
    "            diff = 0\n",
    "            cnt += 1\n",
    "            new_v = [0] * self.env.observation_space.n\n",
    "            for s in range(self.env.observation_space.n):\n",
    "                qsa_list = []\n",
    "                for a in range(self.env.action_space.n):\n",
    "                    next_state, reward, done, truncated, info = self.env.step(a)\n",
    "                    qsa = 0\n",
    "                    for prob, next_state, reward, done in self.env.P[s][a]:\n",
    "                        qsa += prob * (reward + self.gamma * self.v[next_state]*(1-done))\n",
    "                    qsa_list.append(qsa)\n",
    "                new_v[s] = max(qsa_list)\n",
    "                diff = max(diff,abs(new_v[s]-self.v[s]))\n",
    "            self.v = new_v\n",
    "            if diff < 0.001:\n",
    "                break\n",
    "        print('value iterations',cnt) \n",
    "        ### policy update\n",
    "        for s in range(self.env.observation_space.n):\n",
    "            qsa_list = []\n",
    "            for a in range(self.env.action_space.n):\n",
    "                next_state, reward, done, truncated, info = self.env.step(a)\n",
    "                qsa = 0\n",
    "                for prob, next_state, reward, done in self.env.P[s][a]:\n",
    "                    qsa += prob * (reward + self.gamma * self.v[next_state]*(1-done))\n",
    "                qsa_list.append(qsa)\n",
    "            print('xxx',qsa,qsa_list)\n",
    "            maxa = max(qsa_list)\n",
    "            cnt = qsa_list.count(maxa)\n",
    "            print('yyy',cnt)\n",
    "            self.pi[s] = [1/cnt if a == maxa else 0 for a in qsa_list]\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db34e970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "074d762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "agent = ValueIteration(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4541641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value iterations 15\n",
      "xxx -7.94108867905351 [-7.94108867905351, -7.7123207545039, -7.7123207545039, -7.94108867905351]\n",
      "yyy 2\n",
      "xxx -7.94108867905351 [-7.7123207545039, -7.458134171671, -7.458134171671, -7.94108867905351]\n",
      "yyy 2\n",
      "xxx -7.7123207545039 [-7.458134171671, -7.175704635190001, -7.175704635190001, -7.7123207545039]\n",
      "yyy 2\n",
      "xxx -7.458134171671 [-7.175704635190001, -6.861894039100001, -6.861894039100001, -7.458134171671]\n",
      "yyy 2\n",
      "xxx -7.175704635190001 [-6.861894039100001, -6.5132155990000005, -6.5132155990000005, -7.175704635190001]\n",
      "yyy 2\n",
      "xxx -6.861894039100001 [-6.5132155990000005, -6.12579511, -6.12579511, -6.861894039100001]\n",
      "yyy 2\n",
      "xxx -6.5132155990000005 [-6.12579511, -5.6953279000000006, -5.6953279000000006, -6.5132155990000005]\n",
      "yyy 2\n",
      "xxx -6.12579511 [-5.6953279000000006, -5.217031, -5.217031, -6.12579511]\n",
      "yyy 2\n",
      "xxx -5.6953279000000006 [-5.217031, -4.68559, -4.68559, -5.6953279000000006]\n",
      "yyy 2\n",
      "xxx -5.217031 [-4.68559, -4.0951, -4.0951, -5.217031]\n",
      "yyy 2\n",
      "xxx -4.68559 [-4.0951, -3.439, -3.439, -4.68559]\n",
      "yyy 2\n",
      "xxx -4.0951 [-3.439, -3.439, -2.71, -4.0951]\n",
      "yyy 1\n",
      "xxx -7.7123207545039 [-7.94108867905351, -7.458134171671, -7.458134171671, -7.7123207545039]\n",
      "yyy 2\n",
      "xxx -7.7123207545039 [-7.7123207545039, -7.175704635190001, -7.175704635190001, -7.7123207545039]\n",
      "yyy 2\n",
      "xxx -7.458134171671 [-7.458134171671, -6.861894039100001, -6.861894039100001, -7.458134171671]\n",
      "yyy 2\n",
      "xxx -7.175704635190001 [-7.175704635190001, -6.5132155990000005, -6.5132155990000005, -7.175704635190001]\n",
      "yyy 2\n",
      "xxx -6.861894039100001 [-6.861894039100001, -6.12579511, -6.12579511, -6.861894039100001]\n",
      "yyy 2\n",
      "xxx -6.5132155990000005 [-6.5132155990000005, -5.6953279000000006, -5.6953279000000006, -6.5132155990000005]\n",
      "yyy 2\n",
      "xxx -6.12579511 [-6.12579511, -5.217031, -5.217031, -6.12579511]\n",
      "yyy 2\n",
      "xxx -5.6953279000000006 [-5.6953279000000006, -4.68559, -4.68559, -5.6953279000000006]\n",
      "yyy 2\n",
      "xxx -5.217031 [-5.217031, -4.0951, -4.0951, -5.217031]\n",
      "yyy 2\n",
      "xxx -4.68559 [-4.68559, -3.439, -3.439, -4.68559]\n",
      "yyy 2\n",
      "xxx -4.0951 [-4.0951, -2.71, -2.71, -4.0951]\n",
      "yyy 2\n",
      "xxx -3.439 [-3.439, -2.71, -1.9, -3.439]\n",
      "yyy 1\n",
      "xxx -7.458134171671 [-7.7123207545039, -7.175704635190001, -7.7123207545039, -7.458134171671]\n",
      "yyy 1\n",
      "xxx -7.458134171671 [-7.458134171671, -6.861894039100001, -106.7123207545039, -7.458134171671]\n",
      "yyy 1\n",
      "xxx -7.175704635190001 [-7.175704635190001, -6.5132155990000005, -106.7123207545039, -7.175704635190001]\n",
      "yyy 1\n",
      "xxx -6.861894039100001 [-6.861894039100001, -6.12579511, -106.7123207545039, -6.861894039100001]\n",
      "yyy 1\n",
      "xxx -6.5132155990000005 [-6.5132155990000005, -5.6953279000000006, -106.7123207545039, -6.5132155990000005]\n",
      "yyy 1\n",
      "xxx -6.12579511 [-6.12579511, -5.217031, -106.7123207545039, -6.12579511]\n",
      "yyy 1\n",
      "xxx -5.6953279000000006 [-5.6953279000000006, -4.68559, -106.7123207545039, -5.6953279000000006]\n",
      "yyy 1\n",
      "xxx -5.217031 [-5.217031, -4.0951, -106.7123207545039, -5.217031]\n",
      "yyy 1\n",
      "xxx -4.68559 [-4.68559, -3.439, -106.7123207545039, -4.68559]\n",
      "yyy 1\n",
      "xxx -4.0951 [-4.0951, -2.71, -106.7123207545039, -4.0951]\n",
      "yyy 1\n",
      "xxx -3.439 [-3.439, -1.9, -106.7123207545039, -3.439]\n",
      "yyy 1\n",
      "xxx -2.71 [-2.71, -1.9, -1.0, -2.71]\n",
      "yyy 1\n",
      "xxx -7.7123207545039 [-7.458134171671, -106.7123207545039, -7.7123207545039, -7.7123207545039]\n",
      "yyy 1\n",
      "xxx -7.7123207545039 [-7.175704635190001, -106.7123207545039, -106.7123207545039, -7.7123207545039]\n",
      "yyy 1\n",
      "xxx -106.7123207545039 [-6.861894039100001, -106.7123207545039, -106.7123207545039, -106.7123207545039]\n",
      "yyy 1\n",
      "xxx -106.7123207545039 [-6.5132155990000005, -106.7123207545039, -106.7123207545039, -106.7123207545039]\n",
      "yyy 1\n",
      "xxx -106.7123207545039 [-6.12579511, -106.7123207545039, -106.7123207545039, -106.7123207545039]\n",
      "yyy 1\n",
      "xxx -106.7123207545039 [-5.6953279000000006, -106.7123207545039, -106.7123207545039, -106.7123207545039]\n",
      "yyy 1\n",
      "xxx -106.7123207545039 [-5.217031, -106.7123207545039, -106.7123207545039, -106.7123207545039]\n",
      "yyy 1\n",
      "xxx -106.7123207545039 [-4.68559, -106.7123207545039, -106.7123207545039, -106.7123207545039]\n",
      "yyy 1\n",
      "xxx -106.7123207545039 [-4.0951, -106.7123207545039, -106.7123207545039, -106.7123207545039]\n",
      "yyy 1\n",
      "xxx -106.7123207545039 [-3.439, -106.7123207545039, -106.7123207545039, -106.7123207545039]\n",
      "yyy 1\n",
      "xxx -106.7123207545039 [-2.71, -1.0, -106.7123207545039, -106.7123207545039]\n",
      "yyy 1\n",
      "xxx -106.7123207545039 [-1.9, -1.0, -1.0, -106.7123207545039]\n",
      "yyy 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent.value_iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e575b0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-7.7123207545039,\n",
       " -7.458134171671,\n",
       " -7.175704635190001,\n",
       " -6.861894039100001,\n",
       " -6.5132155990000005,\n",
       " -6.12579511,\n",
       " -5.6953279000000006,\n",
       " -5.217031,\n",
       " -4.68559,\n",
       " -4.0951,\n",
       " -3.439,\n",
       " -2.71,\n",
       " -7.458134171671,\n",
       " -7.175704635190001,\n",
       " -6.861894039100001,\n",
       " -6.5132155990000005,\n",
       " -6.12579511,\n",
       " -5.6953279000000006,\n",
       " -5.217031,\n",
       " -4.68559,\n",
       " -4.0951,\n",
       " -3.439,\n",
       " -2.71,\n",
       " -1.9,\n",
       " -7.175704635190001,\n",
       " -6.861894039100001,\n",
       " -6.5132155990000005,\n",
       " -6.12579511,\n",
       " -5.6953279000000006,\n",
       " -5.217031,\n",
       " -4.68559,\n",
       " -4.0951,\n",
       " -3.439,\n",
       " -2.71,\n",
       " -1.9,\n",
       " -1.0,\n",
       " -7.458134171671,\n",
       " -7.175704635190001,\n",
       " -6.861894039100001,\n",
       " -6.5132155990000005,\n",
       " -6.12579511,\n",
       " -5.6953279000000006,\n",
       " -5.217031,\n",
       " -4.68559,\n",
       " -4.0951,\n",
       " -3.439,\n",
       " -1.0,\n",
       " -1.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa1bc53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0, 1.0, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0.5, 0.5, 0],\n",
       " [0, 0, 1.0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 0, 1.0, 0],\n",
       " [1.0, 0, 0, 0],\n",
       " [1.0, 0, 0, 0],\n",
       " [1.0, 0, 0, 0],\n",
       " [1.0, 0, 0, 0],\n",
       " [1.0, 0, 0, 0],\n",
       " [1.0, 0, 0, 0],\n",
       " [1.0, 0, 0, 0],\n",
       " [1.0, 0, 0, 0],\n",
       " [1.0, 0, 0, 0],\n",
       " [1.0, 0, 0, 0],\n",
       " [0, 1.0, 0, 0],\n",
       " [0, 0.5, 0.5, 0]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60b699f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizing trained agent behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 09:47:08.140 python[43252:6450868] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-05-13 09:47:08.140 python[43252:6450868] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVisualizing trained agent behavior...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCliffWalking-v0\u001b[39m\u001b[38;5;124m'\u001b[39m,render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mvisualize_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 23\u001b[0m, in \u001b[0;36mvisualize_agent\u001b[0;34m(env, agent, num_episodes)\u001b[0m\n\u001b[1;32m     20\u001b[0m action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(agent\u001b[38;5;241m.\u001b[39mpi[state])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 执行动作\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m step_result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m next_state, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m step_result\n\u001b[1;32m     25\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/envs/toy_text/cliffwalking.py:153\u001b[0m, in \u001b[0;36mCliffWalkingEnv.step\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlastaction \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mint\u001b[39m(s), r, t, \u001b[38;5;28;01mFalse\u001b[39;00m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m\"\u001b[39m: p})\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/envs/toy_text/cliffwalking.py:175\u001b[0m, in \u001b[0;36mCliffWalkingEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_text()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_gui\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/envs/toy_text/cliffwalking.py:262\u001b[0m, in \u001b[0;36mCliffWalkingEnv._render_gui\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    260\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[1;32m    261\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# rgb_array\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[1;32m    265\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(pygame\u001b[38;5;241m.\u001b[39msurfarray\u001b[38;5;241m.\u001b[39mpixels3d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_surface)), axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    266\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "def visualize_agent(env, agent, num_episodes=5):\n",
    "    \"\"\"\n",
    "    渲染显示智能体的行动\n",
    "    \"\"\"\n",
    "    env = gym.make('CliffWalking-v0', render_mode='human')  # 创建可视化环境\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state_tuple = env.reset()\n",
    "        state = state_tuple[0] if isinstance(state_tuple, tuple) else state_tuple\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        done = False\n",
    "        \n",
    "        print(f\"\\nEpisode {episode + 1}\")\n",
    "        \n",
    "        while not done:\n",
    "            env.render()  # 渲染当前状态\n",
    "            \n",
    "            action = np.argmax(agent.pi[state])\n",
    "            \n",
    "            # 执行动作\n",
    "            step_result = env.step(action)\n",
    "            next_state, reward, terminated, truncated, _ = step_result\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "            state = next_state\n",
    "            \n",
    "            # 添加小延迟使动作更容易观察\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        print(f\"Episode finished after {steps} steps. Total reward: {total_reward}\")\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "# 在主程序最后添加：\n",
    "if __name__ == \"__main__\":    \n",
    "    # 训练完成后显示智能体行动\n",
    "    print(\"\\nVisualizing trained agent behavior...\")\n",
    "    env = gym.make('CliffWalking-v0',render_mode='human')\n",
    "    visualize_agent(env, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e39ec082",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61062c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e1b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
