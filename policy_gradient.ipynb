{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43a05fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -21.0. running mean: -21.0\n",
      "resetting env. episode reward total was -21.0. running mean: -21.0\n",
      "resetting env. episode reward total was -21.0. running mean: -21.0\n",
      "resetting env. episode reward total was -20.0. running mean: -20.99\n",
      "resetting env. episode reward total was -20.0. running mean: -20.980099999999997\n",
      "resetting env. episode reward total was -20.0. running mean: -20.970298999999997\n",
      "resetting env. episode reward total was -19.0. running mean: -20.950596009999998\n",
      "resetting env. episode reward total was -20.0. running mean: -20.941090049899998\n",
      "resetting env. episode reward total was -21.0. running mean: -20.941679149400997\n",
      "resetting env. episode reward total was -21.0. running mean: -20.942262357906987\n",
      "resetting env. episode reward total was -21.0. running mean: -20.94283973432792\n",
      "resetting env. episode reward total was -20.0. running mean: -20.933411336984637\n",
      "resetting env. episode reward total was -20.0. running mean: -20.92407722361479\n",
      "resetting env. episode reward total was -18.0. running mean: -20.894836451378644\n",
      "resetting env. episode reward total was -21.0. running mean: -20.895888086864858\n",
      "resetting env. episode reward total was -21.0. running mean: -20.89692920599621\n",
      "resetting env. episode reward total was -21.0. running mean: -20.897959913936248\n",
      "resetting env. episode reward total was -21.0. running mean: -20.898980314796887\n",
      "resetting env. episode reward total was -20.0. running mean: -20.889990511648918\n",
      "resetting env. episode reward total was -21.0. running mean: -20.89109060653243\n",
      "resetting env. episode reward total was -20.0. running mean: -20.882179700467105\n",
      "resetting env. episode reward total was -21.0. running mean: -20.883357903462436\n",
      "resetting env. episode reward total was -21.0. running mean: -20.88452432442781\n",
      "resetting env. episode reward total was -20.0. running mean: -20.87567908118353\n",
      "resetting env. episode reward total was -21.0. running mean: -20.876922290371695\n",
      "resetting env. episode reward total was -19.0. running mean: -20.858153067467978\n",
      "resetting env. episode reward total was -21.0. running mean: -20.859571536793297\n",
      "resetting env. episode reward total was -20.0. running mean: -20.85097582142536\n",
      "resetting env. episode reward total was -21.0. running mean: -20.852466063211107\n",
      "resetting env. episode reward total was -20.0. running mean: -20.843941402578995\n",
      "resetting env. episode reward total was -20.0. running mean: -20.835501988553204\n",
      "resetting env. episode reward total was -21.0. running mean: -20.837146968667675\n",
      "resetting env. episode reward total was -19.0. running mean: -20.818775498980997\n",
      "resetting env. episode reward total was -20.0. running mean: -20.810587743991185\n",
      "resetting env. episode reward total was -21.0. running mean: -20.812481866551273\n",
      "resetting env. episode reward total was -21.0. running mean: -20.81435704788576\n",
      "resetting env. episode reward total was -21.0. running mean: -20.816213477406905\n",
      "resetting env. episode reward total was -21.0. running mean: -20.818051342632835\n",
      "resetting env. episode reward total was -20.0. running mean: -20.809870829206506\n",
      "resetting env. episode reward total was -20.0. running mean: -20.80177212091444\n",
      "resetting env. episode reward total was -20.0. running mean: -20.793754399705293\n",
      "resetting env. episode reward total was -21.0. running mean: -20.79581685570824\n",
      "resetting env. episode reward total was -19.0. running mean: -20.77785868715116\n",
      "resetting env. episode reward total was -21.0. running mean: -20.780080100279648\n",
      "resetting env. episode reward total was -19.0. running mean: -20.76227929927685\n",
      "resetting env. episode reward total was -21.0. running mean: -20.764656506284084\n",
      "resetting env. episode reward total was -20.0. running mean: -20.75700994122124\n",
      "resetting env. episode reward total was -20.0. running mean: -20.74943984180903\n",
      "resetting env. episode reward total was -21.0. running mean: -20.751945443390937\n",
      "resetting env. episode reward total was -21.0. running mean: -20.754425988957028\n",
      "resetting env. episode reward total was -20.0. running mean: -20.746881729067457\n",
      "resetting env. episode reward total was -21.0. running mean: -20.749412911776783\n",
      "resetting env. episode reward total was -19.0. running mean: -20.731918782659015\n",
      "resetting env. episode reward total was -21.0. running mean: -20.734599594832424\n",
      "resetting env. episode reward total was -21.0. running mean: -20.737253598884102\n",
      "resetting env. episode reward total was -20.0. running mean: -20.72988106289526\n",
      "resetting env. episode reward total was -21.0. running mean: -20.732582252266308\n",
      "resetting env. episode reward total was -20.0. running mean: -20.725256429743645\n",
      "resetting env. episode reward total was -21.0. running mean: -20.728003865446208\n",
      "resetting env. episode reward total was -21.0. running mean: -20.730723826791746\n",
      "resetting env. episode reward total was -18.0. running mean: -20.703416588523826\n",
      "resetting env. episode reward total was -21.0. running mean: -20.706382422638587\n",
      "resetting env. episode reward total was -21.0. running mean: -20.709318598412203\n",
      "resetting env. episode reward total was -21.0. running mean: -20.712225412428083\n",
      "resetting env. episode reward total was -21.0. running mean: -20.7151031583038\n",
      "resetting env. episode reward total was -21.0. running mean: -20.717952126720764\n",
      "resetting env. episode reward total was -21.0. running mean: -20.720772605453558\n",
      "resetting env. episode reward total was -20.0. running mean: -20.713564879399023\n",
      "resetting env. episode reward total was -20.0. running mean: -20.706429230605032\n",
      "resetting env. episode reward total was -21.0. running mean: -20.709364938298982\n",
      "resetting env. episode reward total was -21.0. running mean: -20.712271288915993\n",
      "resetting env. episode reward total was -21.0. running mean: -20.715148576026834\n",
      "resetting env. episode reward total was -20.0. running mean: -20.707997090266566\n",
      "resetting env. episode reward total was -21.0. running mean: -20.710917119363902\n",
      "resetting env. episode reward total was -21.0. running mean: -20.713807948170263\n",
      "resetting env. episode reward total was -21.0. running mean: -20.716669868688562\n",
      "resetting env. episode reward total was -20.0. running mean: -20.709503170001675\n",
      "resetting env. episode reward total was -21.0. running mean: -20.712408138301658\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71528405691864\n",
      "resetting env. episode reward total was -21.0. running mean: -20.718131216349455\n",
      "resetting env. episode reward total was -21.0. running mean: -20.72094990418596\n",
      "resetting env. episode reward total was -21.0. running mean: -20.723740405144103\n",
      "resetting env. episode reward total was -20.0. running mean: -20.71650300109266\n",
      "resetting env. episode reward total was -21.0. running mean: -20.719337971081735\n",
      "resetting env. episode reward total was -21.0. running mean: -20.72214459137092\n",
      "resetting env. episode reward total was -21.0. running mean: -20.72492314545721\n",
      "resetting env. episode reward total was -21.0. running mean: -20.72767391400264\n",
      "resetting env. episode reward total was -21.0. running mean: -20.730397174862613\n",
      "resetting env. episode reward total was -21.0. running mean: -20.733093203113988\n",
      "resetting env. episode reward total was -20.0. running mean: -20.725762271082846\n",
      "resetting env. episode reward total was -21.0. running mean: -20.72850464837202\n",
      "resetting env. episode reward total was -21.0. running mean: -20.731219601888302\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73390740586942\n",
      "resetting env. episode reward total was -21.0. running mean: -20.736568331810727\n",
      "resetting env. episode reward total was -20.0. running mean: -20.729202648492617\n",
      "resetting env. episode reward total was -21.0. running mean: -20.731910622007693\n",
      "resetting env. episode reward total was -21.0. running mean: -20.734591515787617\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73724560062974\n",
      "resetting env. episode reward total was -21.0. running mean: -20.739873144623445\n",
      "resetting env. episode reward total was -21.0. running mean: -20.742474413177213\n",
      "resetting env. episode reward total was -21.0. running mean: -20.745049669045443\n",
      "resetting env. episode reward total was -21.0. running mean: -20.747599172354988\n",
      "resetting env. episode reward total was -21.0. running mean: -20.750123180631437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -21.0. running mean: -20.752621948825123\n",
      "resetting env. episode reward total was -19.0. running mean: -20.735095729336873\n",
      "resetting env. episode reward total was -21.0. running mean: -20.737744772043506\n",
      "resetting env. episode reward total was -21.0. running mean: -20.74036732432307\n",
      "resetting env. episode reward total was -21.0. running mean: -20.74296365107984\n",
      "resetting env. episode reward total was -21.0. running mean: -20.745534014569042\n",
      "resetting env. episode reward total was -21.0. running mean: -20.748078674423354\n",
      "resetting env. episode reward total was -19.0. running mean: -20.73059788767912\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73329190880233\n",
      "resetting env. episode reward total was -20.0. running mean: -20.725958989714304\n",
      "resetting env. episode reward total was -21.0. running mean: -20.72869939981716\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73141240581899\n",
      "resetting env. episode reward total was -19.0. running mean: -20.7140982817608\n",
      "resetting env. episode reward total was -21.0. running mean: -20.716957298943193\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71978772595376\n",
      "resetting env. episode reward total was -21.0. running mean: -20.722589848694223\n",
      "resetting env. episode reward total was -20.0. running mean: -20.71536395020728\n",
      "resetting env. episode reward total was -21.0. running mean: -20.718210310705206\n",
      "resetting env. episode reward total was -20.0. running mean: -20.711028207598154\n",
      "resetting env. episode reward total was -21.0. running mean: -20.713917925522175\n",
      "resetting env. episode reward total was -21.0. running mean: -20.716778746266954\n",
      "resetting env. episode reward total was -21.0. running mean: -20.719610958804285\n",
      "resetting env. episode reward total was -21.0. running mean: -20.722414849216243\n",
      "resetting env. episode reward total was -20.0. running mean: -20.71519070072408\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71803879371684\n",
      "resetting env. episode reward total was -21.0. running mean: -20.720858405779673\n",
      "resetting env. episode reward total was -21.0. running mean: -20.723649821721878\n",
      "resetting env. episode reward total was -21.0. running mean: -20.72641332350466\n",
      "resetting env. episode reward total was -21.0. running mean: -20.729149190269613\n",
      "resetting env. episode reward total was -21.0. running mean: -20.731857698366916\n",
      "resetting env. episode reward total was -20.0. running mean: -20.724539121383245\n",
      "resetting env. episode reward total was -21.0. running mean: -20.727293730169414\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73002079286772\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73272058493904\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73539337908965\n",
      "resetting env. episode reward total was -21.0. running mean: -20.738039445298753\n",
      "resetting env. episode reward total was -21.0. running mean: -20.740659050845768\n",
      "resetting env. episode reward total was -21.0. running mean: -20.74325246033731\n",
      "resetting env. episode reward total was -21.0. running mean: -20.745819935733937\n",
      "resetting env. episode reward total was -21.0. running mean: -20.748361736376598\n",
      "resetting env. episode reward total was -21.0. running mean: -20.75087811901283\n",
      "resetting env. episode reward total was -20.0. running mean: -20.743369337822703\n",
      "resetting env. episode reward total was -21.0. running mean: -20.745935644444476\n",
      "resetting env. episode reward total was -21.0. running mean: -20.74847628800003\n",
      "resetting env. episode reward total was -21.0. running mean: -20.750991525120032\n",
      "resetting env. episode reward total was -20.0. running mean: -20.74348160986883\n",
      "resetting env. episode reward total was -20.0. running mean: -20.73604679377014\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73868632583244\n",
      "resetting env. episode reward total was -21.0. running mean: -20.741299462574116\n",
      "resetting env. episode reward total was -20.0. running mean: -20.733886467948373\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73654760326889\n",
      "resetting env. episode reward total was -21.0. running mean: -20.7391821272362\n",
      "resetting env. episode reward total was -21.0. running mean: -20.74179030596384\n",
      "resetting env. episode reward total was -21.0. running mean: -20.7443724029042\n",
      "resetting env. episode reward total was -20.0. running mean: -20.73692867887516\n",
      "resetting env. episode reward total was -20.0. running mean: -20.729559392086408\n",
      "resetting env. episode reward total was -21.0. running mean: -20.732263798165544\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73494116018389\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73759174858205\n",
      "resetting env. episode reward total was -21.0. running mean: -20.740215831096233\n",
      "resetting env. episode reward total was -21.0. running mean: -20.74281367278527\n",
      "resetting env. episode reward total was -20.0. running mean: -20.735385536057418\n",
      "resetting env. episode reward total was -20.0. running mean: -20.728031680696844\n",
      "resetting env. episode reward total was -21.0. running mean: -20.730751363889876\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73344385025098\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73610941174847\n",
      "resetting env. episode reward total was -21.0. running mean: -20.738748317630986\n",
      "resetting env. episode reward total was -20.0. running mean: -20.731360834454676\n",
      "resetting env. episode reward total was -21.0. running mean: -20.734047226110132\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73670675384903\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73933968631054\n",
      "resetting env. episode reward total was -21.0. running mean: -20.741946289447437\n",
      "resetting env. episode reward total was -21.0. running mean: -20.744526826552963\n",
      "resetting env. episode reward total was -20.0. running mean: -20.737081558287432\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73971074270456\n",
      "resetting env. episode reward total was -20.0. running mean: -20.732313635277514\n",
      "resetting env. episode reward total was -20.0. running mean: -20.724990498924736\n",
      "resetting env. episode reward total was -21.0. running mean: -20.72774059393549\n",
      "resetting env. episode reward total was -21.0. running mean: -20.730463187996136\n",
      "resetting env. episode reward total was -21.0. running mean: -20.733158556116177\n",
      "resetting env. episode reward total was -21.0. running mean: -20.735826970555017\n",
      "resetting env. episode reward total was -20.0. running mean: -20.728468700849465\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73118401384097\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73387217370256\n",
      "resetting env. episode reward total was -21.0. running mean: -20.736533451965535\n",
      "resetting env. episode reward total was -21.0. running mean: -20.73916811744588\n",
      "resetting env. episode reward total was -20.0. running mean: -20.73177643627142\n",
      "resetting env. episode reward total was -20.0. running mean: -20.724458671908707\n",
      "resetting env. episode reward total was -19.0. running mean: -20.70721408518962\n",
      "resetting env. episode reward total was -21.0. running mean: -20.710141944337725\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71304052489435\n",
      "resetting env. episode reward total was -21.0. running mean: -20.715910119645407\n",
      "resetting env. episode reward total was -21.0. running mean: -20.718751018448955\n",
      "resetting env. episode reward total was -20.0. running mean: -20.711563508264465\n",
      "resetting env. episode reward total was -21.0. running mean: -20.714447873181822\n",
      "resetting env. episode reward total was -21.0. running mean: -20.717303394450003\n",
      "resetting env. episode reward total was -20.0. running mean: -20.710130360505502\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71302905690045\n",
      "resetting env. episode reward total was -21.0. running mean: -20.715898766331446\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71873977866813\n",
      "resetting env. episode reward total was -21.0. running mean: -20.721552380881448\n",
      "resetting env. episode reward total was -21.0. running mean: -20.724336857072636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -20.0. running mean: -20.71709348850191\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71992255361689\n",
      "resetting env. episode reward total was -21.0. running mean: -20.722723328080722\n",
      "resetting env. episode reward total was -21.0. running mean: -20.725496094799915\n",
      "resetting env. episode reward total was -21.0. running mean: -20.728241133851917\n",
      "resetting env. episode reward total was -21.0. running mean: -20.7309587225134\n",
      "resetting env. episode reward total was -21.0. running mean: -20.733649135288267\n",
      "resetting env. episode reward total was -20.0. running mean: -20.726312643935383\n",
      "resetting env. episode reward total was -21.0. running mean: -20.72904951749603\n",
      "resetting env. episode reward total was -20.0. running mean: -20.72175902232107\n",
      "resetting env. episode reward total was -20.0. running mean: -20.714541432097857\n",
      "resetting env. episode reward total was -20.0. running mean: -20.707396017776876\n",
      "resetting env. episode reward total was -21.0. running mean: -20.710322057599107\n",
      "resetting env. episode reward total was -21.0. running mean: -20.713218837023117\n",
      "resetting env. episode reward total was -21.0. running mean: -20.716086648652887\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71892578216636\n",
      "resetting env. episode reward total was -20.0. running mean: -20.711736524344694\n",
      "resetting env. episode reward total was -20.0. running mean: -20.704619159101245\n",
      "resetting env. episode reward total was -21.0. running mean: -20.707572967510234\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71049723783513\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71339226545678\n",
      "resetting env. episode reward total was -21.0. running mean: -20.716258342802213\n",
      "resetting env. episode reward total was -21.0. running mean: -20.71909575937419\n",
      "resetting env. episode reward total was -20.0. running mean: -20.71190480178045\n",
      "resetting env. episode reward total was -20.0. running mean: -20.704785753762643\n",
      "resetting env. episode reward total was -20.0. running mean: -20.697737896225014\n",
      "resetting env. episode reward total was -21.0. running mean: -20.700760517262765\n",
      "resetting env. episode reward total was -15.0. running mean: -20.643752912090136\n",
      "resetting env. episode reward total was -19.0. running mean: -20.627315382969236\n",
      "resetting env. episode reward total was -19.0. running mean: -20.611042229139546\n",
      "resetting env. episode reward total was -21.0. running mean: -20.61493180684815\n",
      "resetting env. episode reward total was -20.0. running mean: -20.608782488779667\n",
      "resetting env. episode reward total was -21.0. running mean: -20.612694663891872\n",
      "resetting env. episode reward total was -19.0. running mean: -20.596567717252956\n",
      "resetting env. episode reward total was -21.0. running mean: -20.600602040080428\n",
      "resetting env. episode reward total was -17.0. running mean: -20.564596019679627\n",
      "resetting env. episode reward total was -19.0. running mean: -20.54895005948283\n",
      "resetting env. episode reward total was -19.0. running mean: -20.533460558888002\n",
      "resetting env. episode reward total was -20.0. running mean: -20.52812595329912\n",
      "resetting env. episode reward total was -20.0. running mean: -20.522844693766128\n",
      "resetting env. episode reward total was -20.0. running mean: -20.517616246828467\n",
      "resetting env. episode reward total was -19.0. running mean: -20.502440084360185\n",
      "resetting env. episode reward total was -21.0. running mean: -20.507415683516584\n",
      "resetting env. episode reward total was -21.0. running mean: -20.512341526681418\n",
      "resetting env. episode reward total was -21.0. running mean: -20.517218111414603\n",
      "resetting env. episode reward total was -20.0. running mean: -20.512045930300456\n",
      "resetting env. episode reward total was -21.0. running mean: -20.516925470997453\n",
      "resetting env. episode reward total was -20.0. running mean: -20.511756216287477\n",
      "resetting env. episode reward total was -19.0. running mean: -20.496638654124602\n",
      "resetting env. episode reward total was -21.0. running mean: -20.501672267583356\n",
      "resetting env. episode reward total was -21.0. running mean: -20.506655544907524\n",
      "resetting env. episode reward total was -21.0. running mean: -20.51158898945845\n",
      "resetting env. episode reward total was -20.0. running mean: -20.506473099563863\n",
      "resetting env. episode reward total was -21.0. running mean: -20.511408368568226\n",
      "resetting env. episode reward total was -20.0. running mean: -20.506294284882543\n",
      "resetting env. episode reward total was -21.0. running mean: -20.511231342033717\n",
      "resetting env. episode reward total was -21.0. running mean: -20.51611902861338\n",
      "resetting env. episode reward total was -20.0. running mean: -20.510957838327247\n",
      "resetting env. episode reward total was -20.0. running mean: -20.505848259943974\n",
      "resetting env. episode reward total was -20.0. running mean: -20.500789777344533\n",
      "resetting env. episode reward total was -20.0. running mean: -20.495781879571087\n",
      "resetting env. episode reward total was -20.0. running mean: -20.490824060775374\n",
      "resetting env. episode reward total was -20.0. running mean: -20.48591582016762\n",
      "resetting env. episode reward total was -21.0. running mean: -20.491056661965946\n",
      "resetting env. episode reward total was -21.0. running mean: -20.496146095346287\n",
      "resetting env. episode reward total was -21.0. running mean: -20.501184634392825\n",
      "resetting env. episode reward total was -19.0. running mean: -20.486172788048897\n",
      "resetting env. episode reward total was -18.0. running mean: -20.46131106016841\n",
      "resetting env. episode reward total was -20.0. running mean: -20.456697949566724\n",
      "resetting env. episode reward total was -20.0. running mean: -20.452130970071057\n",
      "resetting env. episode reward total was -21.0. running mean: -20.45760966037035\n",
      "resetting env. episode reward total was -18.0. running mean: -20.433033563766646\n",
      "resetting env. episode reward total was -18.0. running mean: -20.408703228128978\n",
      "resetting env. episode reward total was -20.0. running mean: -20.404616195847687\n",
      "resetting env. episode reward total was -21.0. running mean: -20.41057003388921\n",
      "resetting env. episode reward total was -17.0. running mean: -20.37646433355032\n",
      "resetting env. episode reward total was -20.0. running mean: -20.372699690214816\n",
      "resetting env. episode reward total was -18.0. running mean: -20.348972693312668\n",
      "resetting env. episode reward total was -19.0. running mean: -20.33548296637954\n",
      "resetting env. episode reward total was -19.0. running mean: -20.322128136715747\n",
      "resetting env. episode reward total was -18.0. running mean: -20.29890685534859\n",
      "resetting env. episode reward total was -21.0. running mean: -20.305917786795106\n",
      "resetting env. episode reward total was -18.0. running mean: -20.282858608927153\n",
      "resetting env. episode reward total was -18.0. running mean: -20.26003002283788\n",
      "resetting env. episode reward total was -21.0. running mean: -20.267429722609503\n",
      "resetting env. episode reward total was -20.0. running mean: -20.264755425383406\n",
      "resetting env. episode reward total was -20.0. running mean: -20.262107871129572\n",
      "resetting env. episode reward total was -20.0. running mean: -20.259486792418276\n",
      "resetting env. episode reward total was -20.0. running mean: -20.25689192449409\n",
      "resetting env. episode reward total was -20.0. running mean: -20.254323005249148\n",
      "resetting env. episode reward total was -20.0. running mean: -20.251779775196656\n",
      "resetting env. episode reward total was -21.0. running mean: -20.25926197744469\n",
      "resetting env. episode reward total was -19.0. running mean: -20.246669357670246\n",
      "resetting env. episode reward total was -21.0. running mean: -20.254202664093544\n",
      "resetting env. episode reward total was -20.0. running mean: -20.25166063745261\n",
      "resetting env. episode reward total was -18.0. running mean: -20.229144031078082\n",
      "resetting env. episode reward total was -20.0. running mean: -20.2268525907673\n",
      "resetting env. episode reward total was -21.0. running mean: -20.23458406485963\n",
      "resetting env. episode reward total was -18.0. running mean: -20.21223822421103\n",
      "resetting env. episode reward total was -18.0. running mean: -20.19011584196892\n",
      "resetting env. episode reward total was -19.0. running mean: -20.178214683549232\n",
      "resetting env. episode reward total was -20.0. running mean: -20.17643253671374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -19.0. running mean: -20.164668211346605\n",
      "resetting env. episode reward total was -21.0. running mean: -20.17302152923314\n",
      "resetting env. episode reward total was -18.0. running mean: -20.151291313940806\n",
      "resetting env. episode reward total was -19.0. running mean: -20.1397784008014\n",
      "resetting env. episode reward total was -19.0. running mean: -20.128380616793386\n",
      "resetting env. episode reward total was -18.0. running mean: -20.107096810625453\n",
      "resetting env. episode reward total was -21.0. running mean: -20.1160258425192\n",
      "resetting env. episode reward total was -20.0. running mean: -20.114865584094005\n",
      "resetting env. episode reward total was -20.0. running mean: -20.113716928253066\n",
      "resetting env. episode reward total was -21.0. running mean: -20.122579758970534\n",
      "resetting env. episode reward total was -20.0. running mean: -20.121353961380827\n",
      "resetting env. episode reward total was -21.0. running mean: -20.13014042176702\n",
      "resetting env. episode reward total was -19.0. running mean: -20.11883901754935\n",
      "resetting env. episode reward total was -21.0. running mean: -20.12765062737386\n",
      "resetting env. episode reward total was -21.0. running mean: -20.136374121100122\n",
      "resetting env. episode reward total was -19.0. running mean: -20.125010379889122\n",
      "resetting env. episode reward total was -16.0. running mean: -20.08376027609023\n",
      "resetting env. episode reward total was -19.0. running mean: -20.07292267332933\n",
      "resetting env. episode reward total was -21.0. running mean: -20.082193446596037\n",
      "resetting env. episode reward total was -20.0. running mean: -20.081371512130076\n",
      "resetting env. episode reward total was -21.0. running mean: -20.090557797008778\n",
      "resetting env. episode reward total was -21.0. running mean: -20.099652219038692\n",
      "resetting env. episode reward total was -21.0. running mean: -20.108655696848306\n",
      "resetting env. episode reward total was -19.0. running mean: -20.097569139879823\n",
      "resetting env. episode reward total was -20.0. running mean: -20.096593448481023\n",
      "resetting env. episode reward total was -21.0. running mean: -20.105627513996215\n",
      "resetting env. episode reward total was -20.0. running mean: -20.104571238856252\n",
      "resetting env. episode reward total was -18.0. running mean: -20.08352552646769\n",
      "resetting env. episode reward total was -19.0. running mean: -20.07269027120301\n",
      "resetting env. episode reward total was -17.0. running mean: -20.041963368490983\n",
      "resetting env. episode reward total was -18.0. running mean: -20.021543734806073\n",
      "resetting env. episode reward total was -20.0. running mean: -20.021328297458012\n",
      "resetting env. episode reward total was -20.0. running mean: -20.02111501448343\n",
      "resetting env. episode reward total was -20.0. running mean: -20.020903864338596\n",
      "resetting env. episode reward total was -19.0. running mean: -20.01069482569521\n",
      "resetting env. episode reward total was -18.0. running mean: -19.99058787743826\n",
      "resetting env. episode reward total was -21.0. running mean: -20.000681998663875\n",
      "resetting env. episode reward total was -20.0. running mean: -20.000675178677234\n",
      "resetting env. episode reward total was -17.0. running mean: -19.970668426890462\n",
      "resetting env. episode reward total was -19.0. running mean: -19.96096174262156\n",
      "resetting env. episode reward total was -21.0. running mean: -19.971352125195345\n",
      "resetting env. episode reward total was -20.0. running mean: -19.97163860394339\n",
      "resetting env. episode reward total was -21.0. running mean: -19.981922217903957\n",
      "resetting env. episode reward total was -20.0. running mean: -19.982102995724915\n",
      "resetting env. episode reward total was -21.0. running mean: -19.992281965767667\n",
      "resetting env. episode reward total was -21.0. running mean: -20.002359146109992\n",
      "resetting env. episode reward total was -21.0. running mean: -20.012335554648892\n",
      "resetting env. episode reward total was -19.0. running mean: -20.002212199102406\n",
      "resetting env. episode reward total was -16.0. running mean: -19.96219007711138\n",
      "resetting env. episode reward total was -19.0. running mean: -19.952568176340268\n",
      "resetting env. episode reward total was -21.0. running mean: -19.963042494576865\n",
      "resetting env. episode reward total was -20.0. running mean: -19.963412069631094\n",
      "resetting env. episode reward total was -21.0. running mean: -19.973777948934785\n",
      "resetting env. episode reward total was -20.0. running mean: -19.974040169445438\n",
      "resetting env. episode reward total was -21.0. running mean: -19.984299767750983\n",
      "resetting env. episode reward total was -17.0. running mean: -19.954456770073474\n",
      "resetting env. episode reward total was -19.0. running mean: -19.94491220237274\n",
      "resetting env. episode reward total was -19.0. running mean: -19.935463080349013\n",
      "resetting env. episode reward total was -19.0. running mean: -19.926108449545524\n",
      "resetting env. episode reward total was -19.0. running mean: -19.91684736505007\n",
      "resetting env. episode reward total was -20.0. running mean: -19.917678891399568\n",
      "resetting env. episode reward total was -20.0. running mean: -19.918502102485572\n",
      "resetting env. episode reward total was -21.0. running mean: -19.929317081460717\n",
      "resetting env. episode reward total was -20.0. running mean: -19.93002391064611\n",
      "resetting env. episode reward total was -20.0. running mean: -19.93072367153965\n",
      "resetting env. episode reward total was -18.0. running mean: -19.911416434824254\n",
      "resetting env. episode reward total was -17.0. running mean: -19.882302270476014\n",
      "resetting env. episode reward total was -20.0. running mean: -19.883479247771252\n",
      "resetting env. episode reward total was -20.0. running mean: -19.88464445529354\n",
      "resetting env. episode reward total was -21.0. running mean: -19.895798010740606\n",
      "resetting env. episode reward total was -20.0. running mean: -19.8968400306332\n",
      "resetting env. episode reward total was -21.0. running mean: -19.90787163032687\n",
      "resetting env. episode reward total was -20.0. running mean: -19.9087929140236\n",
      "resetting env. episode reward total was -20.0. running mean: -19.909704984883362\n",
      "resetting env. episode reward total was -20.0. running mean: -19.910607935034527\n",
      "resetting env. episode reward total was -18.0. running mean: -19.89150185568418\n",
      "resetting env. episode reward total was -21.0. running mean: -19.902586837127338\n",
      "resetting env. episode reward total was -16.0. running mean: -19.863560968756065\n",
      "resetting env. episode reward total was -17.0. running mean: -19.834925359068507\n",
      "resetting env. episode reward total was -20.0. running mean: -19.83657610547782\n",
      "resetting env. episode reward total was -20.0. running mean: -19.838210344423043\n",
      "resetting env. episode reward total was -19.0. running mean: -19.829828240978813\n",
      "resetting env. episode reward total was -20.0. running mean: -19.831529958569025\n",
      "resetting env. episode reward total was -19.0. running mean: -19.823214658983336\n",
      "resetting env. episode reward total was -19.0. running mean: -19.814982512393502\n",
      "resetting env. episode reward total was -20.0. running mean: -19.816832687269567\n",
      "resetting env. episode reward total was -17.0. running mean: -19.788664360396872\n",
      "resetting env. episode reward total was -19.0. running mean: -19.780777716792905\n",
      "resetting env. episode reward total was -19.0. running mean: -19.772969939624975\n",
      "resetting env. episode reward total was -19.0. running mean: -19.765240240228728\n",
      "resetting env. episode reward total was -21.0. running mean: -19.77758783782644\n",
      "resetting env. episode reward total was -19.0. running mean: -19.769811959448177\n",
      "resetting env. episode reward total was -21.0. running mean: -19.782113839853697\n",
      "resetting env. episode reward total was -21.0. running mean: -19.79429270145516\n",
      "resetting env. episode reward total was -20.0. running mean: -19.796349774440607\n",
      "resetting env. episode reward total was -17.0. running mean: -19.7683862766962\n",
      "resetting env. episode reward total was -19.0. running mean: -19.76070241392924\n",
      "resetting env. episode reward total was -20.0. running mean: -19.76309538978995\n",
      "resetting env. episode reward total was -21.0. running mean: -19.77546443589205\n",
      "resetting env. episode reward total was -19.0. running mean: -19.767709791533132\n",
      "resetting env. episode reward total was -19.0. running mean: -19.760032693617802\n",
      "resetting env. episode reward total was -19.0. running mean: -19.752432366681624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -19.0. running mean: -19.74490804301481\n",
      "resetting env. episode reward total was -21.0. running mean: -19.757458962584664\n",
      "resetting env. episode reward total was -19.0. running mean: -19.749884372958817\n",
      "resetting env. episode reward total was -19.0. running mean: -19.74238552922923\n",
      "resetting env. episode reward total was -19.0. running mean: -19.73496167393694\n",
      "resetting env. episode reward total was -19.0. running mean: -19.72761205719757\n",
      "resetting env. episode reward total was -20.0. running mean: -19.730335936625597\n",
      "resetting env. episode reward total was -19.0. running mean: -19.723032577259342\n",
      "resetting env. episode reward total was -17.0. running mean: -19.69580225148675\n",
      "resetting env. episode reward total was -19.0. running mean: -19.688844228971885\n",
      "resetting env. episode reward total was -19.0. running mean: -19.681955786682167\n",
      "resetting env. episode reward total was -16.0. running mean: -19.645136228815346\n",
      "resetting env. episode reward total was -20.0. running mean: -19.64868486652719\n",
      "resetting env. episode reward total was -21.0. running mean: -19.66219801786192\n",
      "resetting env. episode reward total was -21.0. running mean: -19.6755760376833\n",
      "resetting env. episode reward total was -19.0. running mean: -19.668820277306466\n",
      "resetting env. episode reward total was -17.0. running mean: -19.642132074533404\n",
      "resetting env. episode reward total was -17.0. running mean: -19.615710753788072\n",
      "resetting env. episode reward total was -20.0. running mean: -19.61955364625019\n",
      "resetting env. episode reward total was -18.0. running mean: -19.60335810978769\n",
      "resetting env. episode reward total was -21.0. running mean: -19.617324528689814\n",
      "resetting env. episode reward total was -17.0. running mean: -19.591151283402915\n",
      "resetting env. episode reward total was -20.0. running mean: -19.595239770568885\n",
      "resetting env. episode reward total was -21.0. running mean: -19.609287372863196\n",
      "resetting env. episode reward total was -20.0. running mean: -19.613194499134565\n",
      "resetting env. episode reward total was -17.0. running mean: -19.58706255414322\n",
      "resetting env. episode reward total was -19.0. running mean: -19.58119192860179\n",
      "resetting env. episode reward total was -19.0. running mean: -19.575380009315772\n",
      "resetting env. episode reward total was -20.0. running mean: -19.579626209222614\n",
      "resetting env. episode reward total was -19.0. running mean: -19.57382994713039\n",
      "resetting env. episode reward total was -21.0. running mean: -19.588091647659084\n",
      "resetting env. episode reward total was -19.0. running mean: -19.582210731182496\n",
      "resetting env. episode reward total was -18.0. running mean: -19.56638862387067\n",
      "resetting env. episode reward total was -19.0. running mean: -19.560724737631965\n",
      "resetting env. episode reward total was -21.0. running mean: -19.575117490255646\n",
      "resetting env. episode reward total was -19.0. running mean: -19.56936631535309\n",
      "resetting env. episode reward total was -19.0. running mean: -19.56367265219956\n",
      "resetting env. episode reward total was -18.0. running mean: -19.548035925677564\n",
      "resetting env. episode reward total was -19.0. running mean: -19.542555566420788\n",
      "resetting env. episode reward total was -21.0. running mean: -19.55713001075658\n",
      "resetting env. episode reward total was -16.0. running mean: -19.521558710649014\n",
      "resetting env. episode reward total was -19.0. running mean: -19.516343123542526\n",
      "resetting env. episode reward total was -19.0. running mean: -19.511179692307103\n",
      "resetting env. episode reward total was -18.0. running mean: -19.49606789538403\n",
      "resetting env. episode reward total was -20.0. running mean: -19.50110721643019\n",
      "resetting env. episode reward total was -16.0. running mean: -19.466096144265887\n",
      "resetting env. episode reward total was -17.0. running mean: -19.44143518282323\n",
      "resetting env. episode reward total was -17.0. running mean: -19.417020830995\n",
      "resetting env. episode reward total was -18.0. running mean: -19.40285062268505\n",
      "resetting env. episode reward total was -17.0. running mean: -19.378822116458203\n",
      "resetting env. episode reward total was -19.0. running mean: -19.375033895293623\n",
      "resetting env. episode reward total was -20.0. running mean: -19.381283556340687\n",
      "resetting env. episode reward total was -19.0. running mean: -19.377470720777282\n",
      "resetting env. episode reward total was -20.0. running mean: -19.38369601356951\n",
      "resetting env. episode reward total was -18.0. running mean: -19.369859053433814\n",
      "resetting env. episode reward total was -18.0. running mean: -19.356160462899474\n",
      "resetting env. episode reward total was -20.0. running mean: -19.362598858270477\n",
      "resetting env. episode reward total was -21.0. running mean: -19.37897286968777\n",
      "resetting env. episode reward total was -20.0. running mean: -19.385183140990893\n",
      "resetting env. episode reward total was -20.0. running mean: -19.391331309580984\n",
      "resetting env. episode reward total was -20.0. running mean: -19.397417996485174\n",
      "resetting env. episode reward total was -19.0. running mean: -19.393443816520325\n",
      "resetting env. episode reward total was -20.0. running mean: -19.39950937835512\n",
      "resetting env. episode reward total was -19.0. running mean: -19.39551428457157\n",
      "resetting env. episode reward total was -17.0. running mean: -19.371559141725854\n",
      "resetting env. episode reward total was -18.0. running mean: -19.357843550308594\n",
      "resetting env. episode reward total was -17.0. running mean: -19.33426511480551\n",
      "resetting env. episode reward total was -17.0. running mean: -19.31092246365746\n",
      "resetting env. episode reward total was -17.0. running mean: -19.287813239020885\n",
      "resetting env. episode reward total was -18.0. running mean: -19.274935106630675\n",
      "resetting env. episode reward total was -14.0. running mean: -19.222185755564368\n",
      "resetting env. episode reward total was -21.0. running mean: -19.239963898008725\n",
      "resetting env. episode reward total was -21.0. running mean: -19.257564259028637\n",
      "resetting env. episode reward total was -19.0. running mean: -19.25498861643835\n",
      "resetting env. episode reward total was -16.0. running mean: -19.222438730273968\n",
      "resetting env. episode reward total was -18.0. running mean: -19.210214342971227\n",
      "resetting env. episode reward total was -20.0. running mean: -19.218112199541515\n",
      "resetting env. episode reward total was -20.0. running mean: -19.2259310775461\n",
      "resetting env. episode reward total was -20.0. running mean: -19.233671766770637\n",
      "resetting env. episode reward total was -20.0. running mean: -19.24133504910293\n",
      "resetting env. episode reward total was -20.0. running mean: -19.2489216986119\n",
      "resetting env. episode reward total was -20.0. running mean: -19.25643248162578\n",
      "resetting env. episode reward total was -21.0. running mean: -19.273868156809524\n",
      "resetting env. episode reward total was -15.0. running mean: -19.231129475241428\n",
      "resetting env. episode reward total was -18.0. running mean: -19.218818180489013\n",
      "resetting env. episode reward total was -16.0. running mean: -19.186629998684122\n",
      "resetting env. episode reward total was -21.0. running mean: -19.20476369869728\n",
      "resetting env. episode reward total was -17.0. running mean: -19.18271606171031\n",
      "resetting env. episode reward total was -18.0. running mean: -19.170888901093207\n",
      "resetting env. episode reward total was -15.0. running mean: -19.129180012082273\n",
      "resetting env. episode reward total was -20.0. running mean: -19.13788821196145\n",
      "resetting env. episode reward total was -19.0. running mean: -19.136509329841836\n",
      "resetting env. episode reward total was -21.0. running mean: -19.155144236543418\n",
      "resetting env. episode reward total was -20.0. running mean: -19.163592794177983\n",
      "resetting env. episode reward total was -19.0. running mean: -19.161956866236206\n",
      "resetting env. episode reward total was -20.0. running mean: -19.170337297573845\n",
      "resetting env. episode reward total was -21.0. running mean: -19.188633924598108\n",
      "resetting env. episode reward total was -18.0. running mean: -19.176747585352125\n",
      "resetting env. episode reward total was -17.0. running mean: -19.154980109498606\n",
      "resetting env. episode reward total was -19.0. running mean: -19.15343030840362\n",
      "resetting env. episode reward total was -19.0. running mean: -19.151896005319585\n",
      "resetting env. episode reward total was -18.0. running mean: -19.14037704526639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -18.0. running mean: -19.128973274813728\n",
      "resetting env. episode reward total was -21.0. running mean: -19.14768354206559\n",
      "resetting env. episode reward total was -20.0. running mean: -19.156206706644934\n",
      "resetting env. episode reward total was -18.0. running mean: -19.144644639578484\n",
      "resetting env. episode reward total was -20.0. running mean: -19.1531981931827\n",
      "resetting env. episode reward total was -18.0. running mean: -19.14166621125087\n",
      "resetting env. episode reward total was -15.0. running mean: -19.10024954913836\n",
      "resetting env. episode reward total was -19.0. running mean: -19.09924705364698\n",
      "resetting env. episode reward total was -21.0. running mean: -19.11825458311051\n",
      "resetting env. episode reward total was -18.0. running mean: -19.107072037279405\n",
      "resetting env. episode reward total was -18.0. running mean: -19.09600131690661\n",
      "resetting env. episode reward total was -18.0. running mean: -19.085041303737544\n",
      "resetting env. episode reward total was -17.0. running mean: -19.06419089070017\n",
      "resetting env. episode reward total was -18.0. running mean: -19.05354898179317\n",
      "resetting env. episode reward total was -20.0. running mean: -19.063013491975237\n",
      "resetting env. episode reward total was -20.0. running mean: -19.072383357055482\n",
      "resetting env. episode reward total was -17.0. running mean: -19.05165952348493\n",
      "resetting env. episode reward total was -18.0. running mean: -19.04114292825008\n",
      "resetting env. episode reward total was -20.0. running mean: -19.050731498967576\n",
      "resetting env. episode reward total was -19.0. running mean: -19.0502241839779\n",
      "resetting env. episode reward total was -20.0. running mean: -19.05972194213812\n",
      "resetting env. episode reward total was -21.0. running mean: -19.079124722716738\n",
      "resetting env. episode reward total was -15.0. running mean: -19.03833347548957\n",
      "resetting env. episode reward total was -20.0. running mean: -19.047950140734674\n",
      "resetting env. episode reward total was -19.0. running mean: -19.04747063932733\n",
      "resetting env. episode reward total was -19.0. running mean: -19.046995932934056\n",
      "resetting env. episode reward total was -20.0. running mean: -19.056525973604714\n",
      "resetting env. episode reward total was -18.0. running mean: -19.045960713868666\n",
      "resetting env. episode reward total was -18.0. running mean: -19.035501106729978\n",
      "resetting env. episode reward total was -20.0. running mean: -19.045146095662677\n",
      "resetting env. episode reward total was -16.0. running mean: -19.01469463470605\n",
      "resetting env. episode reward total was -17.0. running mean: -18.994547688358992\n",
      "resetting env. episode reward total was -21.0. running mean: -19.014602211475403\n",
      "resetting env. episode reward total was -16.0. running mean: -18.98445618936065\n",
      "resetting env. episode reward total was -18.0. running mean: -18.97461162746704\n",
      "resetting env. episode reward total was -21.0. running mean: -18.994865511192373\n",
      "resetting env. episode reward total was -20.0. running mean: -19.00491685608045\n",
      "resetting env. episode reward total was -19.0. running mean: -19.004867687519646\n",
      "resetting env. episode reward total was -19.0. running mean: -19.00481901064445\n",
      "resetting env. episode reward total was -18.0. running mean: -18.994770820538005\n",
      "resetting env. episode reward total was -17.0. running mean: -18.974823112332626\n",
      "resetting env. episode reward total was -20.0. running mean: -18.9850748812093\n",
      "resetting env. episode reward total was -15.0. running mean: -18.945224132397204\n",
      "resetting env. episode reward total was -19.0. running mean: -18.945771891073232\n",
      "resetting env. episode reward total was -19.0. running mean: -18.946314172162502\n",
      "resetting env. episode reward total was -20.0. running mean: -18.956851030440877\n",
      "resetting env. episode reward total was -19.0. running mean: -18.95728252013647\n",
      "resetting env. episode reward total was -18.0. running mean: -18.947709694935106\n",
      "resetting env. episode reward total was -20.0. running mean: -18.958232597985756\n",
      "resetting env. episode reward total was -19.0. running mean: -18.9586502720059\n",
      "resetting env. episode reward total was -18.0. running mean: -18.949063769285843\n",
      "resetting env. episode reward total was -19.0. running mean: -18.949573131592985\n",
      "resetting env. episode reward total was -21.0. running mean: -18.970077400277056\n",
      "resetting env. episode reward total was -18.0. running mean: -18.960376626274286\n",
      "resetting env. episode reward total was -21.0. running mean: -18.980772860011545\n",
      "resetting env. episode reward total was -21.0. running mean: -19.00096513141143\n",
      "resetting env. episode reward total was -19.0. running mean: -19.000955480097318\n",
      "resetting env. episode reward total was -15.0. running mean: -18.960945925296343\n",
      "resetting env. episode reward total was -17.0. running mean: -18.94133646604338\n",
      "resetting env. episode reward total was -20.0. running mean: -18.951923101382945\n",
      "resetting env. episode reward total was -19.0. running mean: -18.952403870369118\n",
      "resetting env. episode reward total was -17.0. running mean: -18.932879831665428\n",
      "resetting env. episode reward total was -20.0. running mean: -18.943551033348772\n",
      "resetting env. episode reward total was -20.0. running mean: -18.954115523015282\n",
      "resetting env. episode reward total was -20.0. running mean: -18.96457436778513\n",
      "resetting env. episode reward total was -17.0. running mean: -18.94492862410728\n",
      "resetting env. episode reward total was -19.0. running mean: -18.94547933786621\n",
      "resetting env. episode reward total was -18.0. running mean: -18.936024544487548\n",
      "resetting env. episode reward total was -19.0. running mean: -18.936664299042675\n",
      "resetting env. episode reward total was -19.0. running mean: -18.937297656052248\n",
      "resetting env. episode reward total was -19.0. running mean: -18.937924679491726\n",
      "resetting env. episode reward total was -20.0. running mean: -18.948545432696807\n",
      "resetting env. episode reward total was -20.0. running mean: -18.95905997836984\n",
      "resetting env. episode reward total was -16.0. running mean: -18.92946937858614\n",
      "resetting env. episode reward total was -18.0. running mean: -18.92017468480028\n",
      "resetting env. episode reward total was -19.0. running mean: -18.92097293795228\n",
      "resetting env. episode reward total was -17.0. running mean: -18.901763208572756\n",
      "resetting env. episode reward total was -19.0. running mean: -18.90274557648703\n",
      "resetting env. episode reward total was -19.0. running mean: -18.90371812072216\n",
      "resetting env. episode reward total was -17.0. running mean: -18.88468093951494\n",
      "resetting env. episode reward total was -13.0. running mean: -18.82583413011979\n",
      "resetting env. episode reward total was -17.0. running mean: -18.807575788818596\n",
      "resetting env. episode reward total was -18.0. running mean: -18.79950003093041\n",
      "resetting env. episode reward total was -15.0. running mean: -18.761505030621105\n",
      "resetting env. episode reward total was -17.0. running mean: -18.743889980314897\n",
      "resetting env. episode reward total was -19.0. running mean: -18.74645108051175\n",
      "resetting env. episode reward total was -20.0. running mean: -18.758986569706632\n",
      "resetting env. episode reward total was -16.0. running mean: -18.731396704009565\n",
      "resetting env. episode reward total was -21.0. running mean: -18.75408273696947\n",
      "resetting env. episode reward total was -17.0. running mean: -18.736541909599776\n",
      "resetting env. episode reward total was -18.0. running mean: -18.72917649050378\n",
      "resetting env. episode reward total was -19.0. running mean: -18.731884725598743\n",
      "resetting env. episode reward total was -20.0. running mean: -18.744565878342755\n",
      "resetting env. episode reward total was -15.0. running mean: -18.707120219559325\n",
      "resetting env. episode reward total was -20.0. running mean: -18.72004901736373\n",
      "resetting env. episode reward total was -19.0. running mean: -18.722848527190095\n",
      "resetting env. episode reward total was -19.0. running mean: -18.725620041918194\n",
      "resetting env. episode reward total was -21.0. running mean: -18.748363841499014\n",
      "resetting env. episode reward total was -16.0. running mean: -18.720880203084025\n",
      "resetting env. episode reward total was -16.0. running mean: -18.693671401053184\n",
      "resetting env. episode reward total was -18.0. running mean: -18.68673468704265\n",
      "resetting env. episode reward total was -16.0. running mean: -18.659867340172227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -10.0. running mean: -18.573268666770506\n",
      "resetting env. episode reward total was -17.0. running mean: -18.557535980102802\n",
      "resetting env. episode reward total was -17.0. running mean: -18.541960620301776\n",
      "resetting env. episode reward total was -21.0. running mean: -18.56654101409876\n",
      "resetting env. episode reward total was -16.0. running mean: -18.540875603957772\n",
      "resetting env. episode reward total was -16.0. running mean: -18.515466847918194\n",
      "resetting env. episode reward total was -19.0. running mean: -18.520312179439014\n",
      "resetting env. episode reward total was -19.0. running mean: -18.525109057644624\n",
      "resetting env. episode reward total was -18.0. running mean: -18.519857967068177\n",
      "resetting env. episode reward total was -18.0. running mean: -18.514659387397494\n",
      "resetting env. episode reward total was -16.0. running mean: -18.48951279352352\n",
      "resetting env. episode reward total was -17.0. running mean: -18.474617665588287\n",
      "resetting env. episode reward total was -19.0. running mean: -18.479871488932407\n",
      "resetting env. episode reward total was -19.0. running mean: -18.485072774043083\n",
      "resetting env. episode reward total was -16.0. running mean: -18.46022204630265\n",
      "resetting env. episode reward total was -19.0. running mean: -18.465619825839624\n",
      "resetting env. episode reward total was -18.0. running mean: -18.46096362758123\n",
      "resetting env. episode reward total was -21.0. running mean: -18.486353991305418\n",
      "resetting env. episode reward total was -17.0. running mean: -18.471490451392366\n",
      "resetting env. episode reward total was -17.0. running mean: -18.456775546878443\n",
      "resetting env. episode reward total was -18.0. running mean: -18.45220779140966\n",
      "resetting env. episode reward total was -19.0. running mean: -18.457685713495565\n",
      "resetting env. episode reward total was -20.0. running mean: -18.473108856360607\n",
      "resetting env. episode reward total was -17.0. running mean: -18.458377767797003\n",
      "resetting env. episode reward total was -17.0. running mean: -18.443793990119033\n",
      "resetting env. episode reward total was -19.0. running mean: -18.449356050217844\n",
      "resetting env. episode reward total was -20.0. running mean: -18.464862489715664\n",
      "resetting env. episode reward total was -19.0. running mean: -18.470213864818508\n",
      "resetting env. episode reward total was -16.0. running mean: -18.445511726170324\n",
      "resetting env. episode reward total was -18.0. running mean: -18.44105660890862\n",
      "resetting env. episode reward total was -20.0. running mean: -18.456646042819536\n",
      "resetting env. episode reward total was -18.0. running mean: -18.452079582391338\n",
      "resetting env. episode reward total was -16.0. running mean: -18.427558786567424\n",
      "resetting env. episode reward total was -19.0. running mean: -18.43328319870175\n",
      "resetting env. episode reward total was -15.0. running mean: -18.398950366714732\n",
      "resetting env. episode reward total was -19.0. running mean: -18.404960863047588\n",
      "resetting env. episode reward total was -21.0. running mean: -18.43091125441711\n",
      "resetting env. episode reward total was -16.0. running mean: -18.40660214187294\n",
      "resetting env. episode reward total was -20.0. running mean: -18.42253612045421\n",
      "resetting env. episode reward total was -21.0. running mean: -18.44831075924967\n",
      "resetting env. episode reward total was -17.0. running mean: -18.433827651657175\n",
      "resetting env. episode reward total was -18.0. running mean: -18.4294893751406\n",
      "resetting env. episode reward total was -14.0. running mean: -18.385194481389195\n",
      "resetting env. episode reward total was -19.0. running mean: -18.391342536575305\n",
      "resetting env. episode reward total was -16.0. running mean: -18.367429111209553\n",
      "resetting env. episode reward total was -17.0. running mean: -18.35375482009746\n",
      "resetting env. episode reward total was -19.0. running mean: -18.360217271896488\n",
      "resetting env. episode reward total was -18.0. running mean: -18.35661509917752\n",
      "resetting env. episode reward total was -20.0. running mean: -18.373048948185744\n",
      "resetting env. episode reward total was -17.0. running mean: -18.35931845870389\n",
      "resetting env. episode reward total was -17.0. running mean: -18.34572527411685\n",
      "resetting env. episode reward total was -19.0. running mean: -18.352268021375686\n",
      "resetting env. episode reward total was -19.0. running mean: -18.35874534116193\n",
      "resetting env. episode reward total was -17.0. running mean: -18.345157887750315\n",
      "resetting env. episode reward total was -21.0. running mean: -18.371706308872813\n",
      "resetting env. episode reward total was -20.0. running mean: -18.387989245784084\n",
      "resetting env. episode reward total was -20.0. running mean: -18.40410935332624\n",
      "resetting env. episode reward total was -19.0. running mean: -18.41006825979298\n",
      "resetting env. episode reward total was -14.0. running mean: -18.36596757719505\n",
      "resetting env. episode reward total was -19.0. running mean: -18.372307901423103\n",
      "resetting env. episode reward total was -16.0. running mean: -18.34858482240887\n",
      "resetting env. episode reward total was -16.0. running mean: -18.325098974184783\n",
      "resetting env. episode reward total was -17.0. running mean: -18.311847984442938\n",
      "resetting env. episode reward total was -18.0. running mean: -18.308729504598507\n",
      "resetting env. episode reward total was -18.0. running mean: -18.30564220955252\n",
      "resetting env. episode reward total was -18.0. running mean: -18.302585787456994\n",
      "resetting env. episode reward total was -19.0. running mean: -18.309559929582427\n",
      "resetting env. episode reward total was -18.0. running mean: -18.3064643302866\n",
      "resetting env. episode reward total was -17.0. running mean: -18.293399686983737\n",
      "resetting env. episode reward total was -17.0. running mean: -18.2804656901139\n",
      "resetting env. episode reward total was -18.0. running mean: -18.27766103321276\n",
      "resetting env. episode reward total was -15.0. running mean: -18.24488442288063\n",
      "resetting env. episode reward total was -13.0. running mean: -18.192435578651825\n",
      "resetting env. episode reward total was -16.0. running mean: -18.170511222865308\n",
      "resetting env. episode reward total was -17.0. running mean: -18.158806110636657\n",
      "resetting env. episode reward total was -20.0. running mean: -18.17721804953029\n",
      "resetting env. episode reward total was -18.0. running mean: -18.175445869034984\n",
      "resetting env. episode reward total was -17.0. running mean: -18.163691410344637\n",
      "resetting env. episode reward total was -18.0. running mean: -18.16205449624119\n",
      "resetting env. episode reward total was -18.0. running mean: -18.160433951278776\n",
      "resetting env. episode reward total was -15.0. running mean: -18.128829611765987\n",
      "resetting env. episode reward total was -18.0. running mean: -18.127541315648326\n",
      "resetting env. episode reward total was -19.0. running mean: -18.136265902491843\n",
      "resetting env. episode reward total was -15.0. running mean: -18.10490324346692\n",
      "resetting env. episode reward total was -19.0. running mean: -18.113854211032255\n",
      "resetting env. episode reward total was -13.0. running mean: -18.062715668921932\n",
      "resetting env. episode reward total was -18.0. running mean: -18.062088512232712\n",
      "resetting env. episode reward total was -18.0. running mean: -18.061467627110385\n",
      "resetting env. episode reward total was -20.0. running mean: -18.08085295083928\n",
      "resetting env. episode reward total was -20.0. running mean: -18.100044421330885\n",
      "resetting env. episode reward total was -13.0. running mean: -18.049043977117574\n",
      "resetting env. episode reward total was -16.0. running mean: -18.028553537346397\n",
      "resetting env. episode reward total was -18.0. running mean: -18.028268001972933\n",
      "resetting env. episode reward total was -18.0. running mean: -18.027985321953203\n",
      "resetting env. episode reward total was -15.0. running mean: -17.99770546873367\n",
      "resetting env. episode reward total was -15.0. running mean: -17.96772841404633\n",
      "resetting env. episode reward total was -18.0. running mean: -17.968051129905867\n",
      "resetting env. episode reward total was -15.0. running mean: -17.938370618606807\n",
      "resetting env. episode reward total was -21.0. running mean: -17.96898691242074\n",
      "resetting env. episode reward total was -17.0. running mean: -17.959297043296534\n",
      "resetting env. episode reward total was -20.0. running mean: -17.97970407286357\n",
      "resetting env. episode reward total was -20.0. running mean: -17.99990703213493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -21.0. running mean: -18.02990796181358\n",
      "resetting env. episode reward total was -21.0. running mean: -18.059608882195445\n",
      "resetting env. episode reward total was -20.0. running mean: -18.07901279337349\n",
      "resetting env. episode reward total was -19.0. running mean: -18.088222665439755\n",
      "resetting env. episode reward total was -19.0. running mean: -18.09734043878536\n",
      "resetting env. episode reward total was -19.0. running mean: -18.106367034397508\n",
      "resetting env. episode reward total was -19.0. running mean: -18.115303364053535\n",
      "resetting env. episode reward total was -15.0. running mean: -18.084150330413\n",
      "resetting env. episode reward total was -18.0. running mean: -18.08330882710887\n",
      "resetting env. episode reward total was -20.0. running mean: -18.10247573883778\n",
      "resetting env. episode reward total was -17.0. running mean: -18.091450981449402\n",
      "resetting env. episode reward total was -15.0. running mean: -18.060536471634908\n",
      "resetting env. episode reward total was -18.0. running mean: -18.059931106918558\n",
      "resetting env. episode reward total was -17.0. running mean: -18.049331795849373\n",
      "resetting env. episode reward total was -15.0. running mean: -18.018838477890878\n",
      "resetting env. episode reward total was -20.0. running mean: -18.03865009311197\n",
      "resetting env. episode reward total was -16.0. running mean: -18.018263592180848\n",
      "resetting env. episode reward total was -15.0. running mean: -17.988080956259036\n",
      "resetting env. episode reward total was -15.0. running mean: -17.958200146696445\n",
      "resetting env. episode reward total was -18.0. running mean: -17.95861814522948\n",
      "resetting env. episode reward total was -19.0. running mean: -17.969031963777187\n",
      "resetting env. episode reward total was -14.0. running mean: -17.929341644139416\n",
      "resetting env. episode reward total was -19.0. running mean: -17.940048227698025\n",
      "resetting env. episode reward total was -15.0. running mean: -17.91064774542104\n",
      "resetting env. episode reward total was -19.0. running mean: -17.92154126796683\n",
      "resetting env. episode reward total was -18.0. running mean: -17.922325855287163\n",
      "resetting env. episode reward total was -19.0. running mean: -17.933102596734294\n",
      "resetting env. episode reward total was -17.0. running mean: -17.923771570766952\n",
      "resetting env. episode reward total was -14.0. running mean: -17.88453385505928\n",
      "resetting env. episode reward total was -19.0. running mean: -17.895688516508688\n",
      "resetting env. episode reward total was -17.0. running mean: -17.886731631343604\n",
      "resetting env. episode reward total was -16.0. running mean: -17.867864315030168\n",
      "resetting env. episode reward total was -19.0. running mean: -17.879185671879867\n",
      "resetting env. episode reward total was -20.0. running mean: -17.900393815161067\n",
      "resetting env. episode reward total was -21.0. running mean: -17.931389877009458\n",
      "resetting env. episode reward total was -17.0. running mean: -17.922075978239366\n",
      "resetting env. episode reward total was -19.0. running mean: -17.932855218456975\n",
      "resetting env. episode reward total was -18.0. running mean: -17.933526666272407\n",
      "resetting env. episode reward total was -19.0. running mean: -17.944191399609682\n",
      "resetting env. episode reward total was -20.0. running mean: -17.964749485613584\n",
      "resetting env. episode reward total was -17.0. running mean: -17.95510199075745\n",
      "resetting env. episode reward total was -16.0. running mean: -17.935550970849874\n",
      "resetting env. episode reward total was -20.0. running mean: -17.956195461141373\n",
      "resetting env. episode reward total was -13.0. running mean: -17.906633506529957\n",
      "resetting env. episode reward total was -15.0. running mean: -17.877567171464655\n",
      "resetting env. episode reward total was -18.0. running mean: -17.878791499750008\n",
      "resetting env. episode reward total was -19.0. running mean: -17.89000358475251\n",
      "resetting env. episode reward total was -18.0. running mean: -17.891103548904983\n",
      "resetting env. episode reward total was -18.0. running mean: -17.89219251341593\n",
      "resetting env. episode reward total was -16.0. running mean: -17.873270588281773\n",
      "resetting env. episode reward total was -18.0. running mean: -17.874537882398954\n",
      "resetting env. episode reward total was -14.0. running mean: -17.835792503574964\n",
      "resetting env. episode reward total was -19.0. running mean: -17.847434578539215\n",
      "resetting env. episode reward total was -18.0. running mean: -17.84896023275382\n",
      "resetting env. episode reward total was -17.0. running mean: -17.840470630426285\n",
      "resetting env. episode reward total was -16.0. running mean: -17.822065924122022\n",
      "resetting env. episode reward total was -14.0. running mean: -17.783845264880803\n",
      "resetting env. episode reward total was -19.0. running mean: -17.796006812231997\n",
      "resetting env. episode reward total was -20.0. running mean: -17.818046744109676\n",
      "resetting env. episode reward total was -20.0. running mean: -17.839866276668577\n",
      "resetting env. episode reward total was -14.0. running mean: -17.80146761390189\n",
      "resetting env. episode reward total was -20.0. running mean: -17.823452937762873\n",
      "resetting env. episode reward total was -18.0. running mean: -17.825218408385243\n",
      "resetting env. episode reward total was -18.0. running mean: -17.82696622430139\n",
      "resetting env. episode reward total was -16.0. running mean: -17.808696562058376\n",
      "resetting env. episode reward total was -18.0. running mean: -17.810609596437793\n",
      "resetting env. episode reward total was -15.0. running mean: -17.782503500473414\n",
      "resetting env. episode reward total was -19.0. running mean: -17.79467846546868\n",
      "resetting env. episode reward total was -13.0. running mean: -17.746731680813994\n",
      "resetting env. episode reward total was -17.0. running mean: -17.739264364005855\n",
      "resetting env. episode reward total was -20.0. running mean: -17.761871720365797\n",
      "resetting env. episode reward total was -19.0. running mean: -17.77425300316214\n",
      "resetting env. episode reward total was -18.0. running mean: -17.776510473130518\n",
      "resetting env. episode reward total was -20.0. running mean: -17.798745368399214\n",
      "resetting env. episode reward total was -21.0. running mean: -17.83075791471522\n",
      "resetting env. episode reward total was -18.0. running mean: -17.83245033556807\n",
      "resetting env. episode reward total was -15.0. running mean: -17.804125832212385\n",
      "resetting env. episode reward total was -18.0. running mean: -17.80608457389026\n",
      "resetting env. episode reward total was -19.0. running mean: -17.81802372815136\n",
      "resetting env. episode reward total was -15.0. running mean: -17.789843490869846\n",
      "resetting env. episode reward total was -20.0. running mean: -17.811945055961147\n",
      "resetting env. episode reward total was -19.0. running mean: -17.823825605401534\n",
      "resetting env. episode reward total was -18.0. running mean: -17.82558734934752\n",
      "resetting env. episode reward total was -19.0. running mean: -17.837331475854043\n",
      "resetting env. episode reward total was -20.0. running mean: -17.8589581610955\n",
      "resetting env. episode reward total was -16.0. running mean: -17.840368579484547\n",
      "resetting env. episode reward total was -20.0. running mean: -17.861964893689702\n",
      "resetting env. episode reward total was -18.0. running mean: -17.863345244752804\n",
      "resetting env. episode reward total was -21.0. running mean: -17.894711792305277\n",
      "resetting env. episode reward total was -15.0. running mean: -17.865764674382223\n",
      "resetting env. episode reward total was -16.0. running mean: -17.8471070276384\n",
      "resetting env. episode reward total was -15.0. running mean: -17.818635957362016\n",
      "resetting env. episode reward total was -17.0. running mean: -17.8104495977884\n",
      "resetting env. episode reward total was -19.0. running mean: -17.822345101810516\n",
      "resetting env. episode reward total was -17.0. running mean: -17.814121650792412\n",
      "resetting env. episode reward total was -14.0. running mean: -17.775980434284488\n",
      "resetting env. episode reward total was -16.0. running mean: -17.758220629941643\n",
      "resetting env. episode reward total was -16.0. running mean: -17.740638423642228\n",
      "resetting env. episode reward total was -18.0. running mean: -17.743232039405804\n",
      "resetting env. episode reward total was -16.0. running mean: -17.725799719011746\n",
      "resetting env. episode reward total was -16.0. running mean: -17.70854172182163\n",
      "resetting env. episode reward total was -12.0. running mean: -17.651456304603414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -17.0. running mean: -17.644941741557382\n",
      "resetting env. episode reward total was -16.0. running mean: -17.628492324141806\n",
      "resetting env. episode reward total was -16.0. running mean: -17.612207400900388\n",
      "resetting env. episode reward total was -15.0. running mean: -17.586085326891382\n",
      "resetting env. episode reward total was -19.0. running mean: -17.60022447362247\n",
      "resetting env. episode reward total was -16.0. running mean: -17.584222228886244\n",
      "resetting env. episode reward total was -16.0. running mean: -17.56838000659738\n",
      "resetting env. episode reward total was -19.0. running mean: -17.582696206531406\n",
      "resetting env. episode reward total was -18.0. running mean: -17.58686924446609\n",
      "resetting env. episode reward total was -16.0. running mean: -17.57100055202143\n",
      "resetting env. episode reward total was -13.0. running mean: -17.525290546501214\n",
      "resetting env. episode reward total was -19.0. running mean: -17.540037641036204\n",
      "resetting env. episode reward total was -16.0. running mean: -17.52463726462584\n",
      "resetting env. episode reward total was -19.0. running mean: -17.539390891979583\n",
      "resetting env. episode reward total was -21.0. running mean: -17.57399698305979\n",
      "resetting env. episode reward total was -14.0. running mean: -17.53825701322919\n",
      "resetting env. episode reward total was -17.0. running mean: -17.5328744430969\n",
      "resetting env. episode reward total was -19.0. running mean: -17.54754569866593\n",
      "resetting env. episode reward total was -16.0. running mean: -17.53207024167927\n",
      "resetting env. episode reward total was -15.0. running mean: -17.506749539262476\n",
      "resetting env. episode reward total was -19.0. running mean: -17.521682043869852\n",
      "resetting env. episode reward total was -16.0. running mean: -17.506465223431153\n",
      "resetting env. episode reward total was -19.0. running mean: -17.521400571196843\n",
      "resetting env. episode reward total was -14.0. running mean: -17.486186565484875\n",
      "resetting env. episode reward total was -17.0. running mean: -17.48132469983003\n",
      "resetting env. episode reward total was -21.0. running mean: -17.51651145283173\n",
      "resetting env. episode reward total was -15.0. running mean: -17.49134633830341\n",
      "resetting env. episode reward total was -19.0. running mean: -17.506432874920375\n",
      "resetting env. episode reward total was -13.0. running mean: -17.46136854617117\n",
      "resetting env. episode reward total was -17.0. running mean: -17.45675486070946\n",
      "resetting env. episode reward total was -14.0. running mean: -17.422187312102366\n",
      "resetting env. episode reward total was -17.0. running mean: -17.417965438981344\n",
      "resetting env. episode reward total was -18.0. running mean: -17.42378578459153\n",
      "resetting env. episode reward total was -14.0. running mean: -17.389547926745614\n",
      "resetting env. episode reward total was -19.0. running mean: -17.405652447478158\n",
      "resetting env. episode reward total was -16.0. running mean: -17.391595923003376\n",
      "resetting env. episode reward total was -14.0. running mean: -17.357679963773343\n",
      "resetting env. episode reward total was -18.0. running mean: -17.36410316413561\n",
      "resetting env. episode reward total was -17.0. running mean: -17.360462132494256\n",
      "resetting env. episode reward total was -16.0. running mean: -17.34685751116931\n",
      "resetting env. episode reward total was -17.0. running mean: -17.343388936057618\n",
      "resetting env. episode reward total was -17.0. running mean: -17.339955046697042\n",
      "resetting env. episode reward total was -18.0. running mean: -17.34655549623007\n",
      "resetting env. episode reward total was -16.0. running mean: -17.33308994126777\n",
      "resetting env. episode reward total was -19.0. running mean: -17.34975904185509\n",
      "resetting env. episode reward total was -16.0. running mean: -17.33626145143654\n",
      "resetting env. episode reward total was -14.0. running mean: -17.302898836922175\n",
      "resetting env. episode reward total was -15.0. running mean: -17.279869848552952\n",
      "resetting env. episode reward total was -15.0. running mean: -17.25707115006742\n",
      "resetting env. episode reward total was -13.0. running mean: -17.214500438566745\n",
      "resetting env. episode reward total was -14.0. running mean: -17.182355434181076\n",
      "resetting env. episode reward total was -15.0. running mean: -17.160531879839265\n",
      "resetting env. episode reward total was -18.0. running mean: -17.168926561040873\n",
      "resetting env. episode reward total was -21.0. running mean: -17.207237295430467\n",
      "resetting env. episode reward total was -15.0. running mean: -17.18516492247616\n",
      "resetting env. episode reward total was -18.0. running mean: -17.1933132732514\n",
      "resetting env. episode reward total was -15.0. running mean: -17.17138014051888\n",
      "resetting env. episode reward total was -18.0. running mean: -17.17966633911369\n",
      "resetting env. episode reward total was -16.0. running mean: -17.167869675722553\n",
      "resetting env. episode reward total was -15.0. running mean: -17.146190978965326\n",
      "resetting env. episode reward total was -15.0. running mean: -17.12472906917567\n",
      "resetting env. episode reward total was -19.0. running mean: -17.143481778483917\n",
      "resetting env. episode reward total was -17.0. running mean: -17.14204696069908\n",
      "resetting env. episode reward total was -16.0. running mean: -17.13062649109209\n",
      "resetting env. episode reward total was -15.0. running mean: -17.10932022618117\n",
      "resetting env. episode reward total was -16.0. running mean: -17.098227023919357\n",
      "resetting env. episode reward total was -16.0. running mean: -17.087244753680164\n",
      "resetting env. episode reward total was -15.0. running mean: -17.06637230614336\n",
      "resetting env. episode reward total was -18.0. running mean: -17.075708583081926\n",
      "resetting env. episode reward total was -15.0. running mean: -17.054951497251107\n",
      "resetting env. episode reward total was -17.0. running mean: -17.0544019822786\n",
      "resetting env. episode reward total was -19.0. running mean: -17.073857962455815\n",
      "resetting env. episode reward total was -21.0. running mean: -17.113119382831258\n",
      "resetting env. episode reward total was -17.0. running mean: -17.111988189002947\n",
      "resetting env. episode reward total was -20.0. running mean: -17.140868307112918\n",
      "resetting env. episode reward total was -17.0. running mean: -17.13945962404179\n",
      "resetting env. episode reward total was -21.0. running mean: -17.178065027801374\n",
      "resetting env. episode reward total was -16.0. running mean: -17.16628437752336\n",
      "resetting env. episode reward total was -14.0. running mean: -17.134621533748128\n",
      "resetting env. episode reward total was -20.0. running mean: -17.163275318410644\n",
      "resetting env. episode reward total was -17.0. running mean: -17.16164256522654\n",
      "resetting env. episode reward total was -20.0. running mean: -17.190026139574275\n",
      "resetting env. episode reward total was -19.0. running mean: -17.208125878178535\n",
      "resetting env. episode reward total was -17.0. running mean: -17.206044619396753\n",
      "resetting env. episode reward total was -10.0. running mean: -17.133984173202787\n",
      "resetting env. episode reward total was -16.0. running mean: -17.12264433147076\n",
      "resetting env. episode reward total was -20.0. running mean: -17.15141788815605\n",
      "resetting env. episode reward total was -19.0. running mean: -17.16990370927449\n",
      "resetting env. episode reward total was -15.0. running mean: -17.148204672181745\n",
      "resetting env. episode reward total was -17.0. running mean: -17.14672262545993\n",
      "resetting env. episode reward total was -18.0. running mean: -17.15525539920533\n",
      "resetting env. episode reward total was -17.0. running mean: -17.153702845213278\n",
      "resetting env. episode reward total was -17.0. running mean: -17.152165816761148\n",
      "resetting env. episode reward total was -16.0. running mean: -17.140644158593535\n",
      "resetting env. episode reward total was -19.0. running mean: -17.1592377170076\n",
      "resetting env. episode reward total was -16.0. running mean: -17.147645339837524\n",
      "resetting env. episode reward total was -17.0. running mean: -17.14616888643915\n",
      "resetting env. episode reward total was -16.0. running mean: -17.13470719757476\n",
      "resetting env. episode reward total was -15.0. running mean: -17.11336012559901\n",
      "resetting env. episode reward total was -17.0. running mean: -17.11222652434302\n",
      "resetting env. episode reward total was -17.0. running mean: -17.11110425909959\n",
      "resetting env. episode reward total was -16.0. running mean: -17.099993216508594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -18.0. running mean: -17.10899328434351\n",
      "resetting env. episode reward total was -15.0. running mean: -17.08790335150007\n",
      "resetting env. episode reward total was -16.0. running mean: -17.07702431798507\n",
      "resetting env. episode reward total was -15.0. running mean: -17.056254074805217\n",
      "resetting env. episode reward total was -14.0. running mean: -17.025691534057167\n",
      "resetting env. episode reward total was -20.0. running mean: -17.055434618716593\n",
      "resetting env. episode reward total was -19.0. running mean: -17.074880272529427\n",
      "resetting env. episode reward total was -17.0. running mean: -17.074131469804133\n",
      "resetting env. episode reward total was -21.0. running mean: -17.113390155106092\n",
      "resetting env. episode reward total was -16.0. running mean: -17.10225625355503\n",
      "resetting env. episode reward total was -19.0. running mean: -17.12123369101948\n",
      "resetting env. episode reward total was -19.0. running mean: -17.140021354109287\n",
      "resetting env. episode reward total was -15.0. running mean: -17.11862114056819\n",
      "resetting env. episode reward total was -15.0. running mean: -17.097434929162507\n",
      "resetting env. episode reward total was -16.0. running mean: -17.08646057987088\n",
      "resetting env. episode reward total was -9.0. running mean: -17.005595974072172\n",
      "resetting env. episode reward total was -12.0. running mean: -16.95554001433145\n",
      "resetting env. episode reward total was -18.0. running mean: -16.965984614188137\n",
      "resetting env. episode reward total was -13.0. running mean: -16.926324768046253\n",
      "resetting env. episode reward total was -14.0. running mean: -16.897061520365792\n",
      "resetting env. episode reward total was -14.0. running mean: -16.868090905162134\n",
      "resetting env. episode reward total was -16.0. running mean: -16.859409996110514\n",
      "resetting env. episode reward total was -15.0. running mean: -16.840815896149408\n",
      "resetting env. episode reward total was -19.0. running mean: -16.862407737187915\n",
      "resetting env. episode reward total was -16.0. running mean: -16.853783659816035\n",
      "resetting env. episode reward total was -18.0. running mean: -16.865245823217872\n",
      "resetting env. episode reward total was -18.0. running mean: -16.876593364985695\n",
      "resetting env. episode reward total was -20.0. running mean: -16.907827431335836\n",
      "resetting env. episode reward total was -15.0. running mean: -16.888749157022477\n",
      "resetting env. episode reward total was -17.0. running mean: -16.889861665452255\n",
      "resetting env. episode reward total was -18.0. running mean: -16.90096304879773\n",
      "resetting env. episode reward total was -15.0. running mean: -16.881953418309752\n",
      "resetting env. episode reward total was -15.0. running mean: -16.863133884126654\n",
      "resetting env. episode reward total was -17.0. running mean: -16.86450254528539\n",
      "resetting env. episode reward total was -15.0. running mean: -16.845857519832535\n",
      "resetting env. episode reward total was -17.0. running mean: -16.84739894463421\n",
      "resetting env. episode reward total was -12.0. running mean: -16.79892495518787\n",
      "resetting env. episode reward total was -17.0. running mean: -16.800935705635993\n",
      "resetting env. episode reward total was -18.0. running mean: -16.812926348579634\n",
      "resetting env. episode reward total was -18.0. running mean: -16.824797085093838\n",
      "resetting env. episode reward total was -19.0. running mean: -16.8465491142429\n",
      "resetting env. episode reward total was -13.0. running mean: -16.808083623100472\n",
      "resetting env. episode reward total was -17.0. running mean: -16.810002786869468\n",
      "resetting env. episode reward total was -16.0. running mean: -16.80190275900077\n",
      "resetting env. episode reward total was -21.0. running mean: -16.843883731410763\n",
      "resetting env. episode reward total was -20.0. running mean: -16.875444894096656\n",
      "resetting env. episode reward total was -19.0. running mean: -16.89669044515569\n",
      "resetting env. episode reward total was -16.0. running mean: -16.887723540704133\n",
      "resetting env. episode reward total was -18.0. running mean: -16.89884630529709\n",
      "resetting env. episode reward total was -15.0. running mean: -16.879857842244117\n",
      "resetting env. episode reward total was -12.0. running mean: -16.831059263821675\n",
      "resetting env. episode reward total was -11.0. running mean: -16.772748671183457\n",
      "resetting env. episode reward total was -18.0. running mean: -16.78502118447162\n",
      "resetting env. episode reward total was -17.0. running mean: -16.787170972626907\n",
      "resetting env. episode reward total was -15.0. running mean: -16.769299262900635\n",
      "resetting env. episode reward total was -13.0. running mean: -16.731606270271627\n",
      "resetting env. episode reward total was -13.0. running mean: -16.69429020756891\n",
      "resetting env. episode reward total was -17.0. running mean: -16.69734730549322\n",
      "resetting env. episode reward total was -16.0. running mean: -16.69037383243829\n",
      "resetting env. episode reward total was -15.0. running mean: -16.673470094113906\n",
      "resetting env. episode reward total was -15.0. running mean: -16.656735393172767\n",
      "resetting env. episode reward total was -18.0. running mean: -16.670168039241037\n",
      "resetting env. episode reward total was -15.0. running mean: -16.653466358848625\n",
      "resetting env. episode reward total was -17.0. running mean: -16.65693169526014\n",
      "resetting env. episode reward total was -19.0. running mean: -16.680362378307542\n",
      "resetting env. episode reward total was -15.0. running mean: -16.663558754524466\n",
      "resetting env. episode reward total was -13.0. running mean: -16.62692316697922\n",
      "resetting env. episode reward total was -14.0. running mean: -16.60065393530943\n",
      "resetting env. episode reward total was -15.0. running mean: -16.584647395956335\n",
      "resetting env. episode reward total was -17.0. running mean: -16.58880092199677\n",
      "resetting env. episode reward total was -11.0. running mean: -16.5329129127768\n",
      "resetting env. episode reward total was -12.0. running mean: -16.487583783649033\n",
      "resetting env. episode reward total was -17.0. running mean: -16.492707945812544\n",
      "resetting env. episode reward total was -21.0. running mean: -16.53778086635442\n",
      "resetting env. episode reward total was -18.0. running mean: -16.552403057690878\n",
      "resetting env. episode reward total was -17.0. running mean: -16.556879027113972\n",
      "resetting env. episode reward total was -11.0. running mean: -16.50131023684283\n",
      "resetting env. episode reward total was -10.0. running mean: -16.436297134474405\n",
      "resetting env. episode reward total was -18.0. running mean: -16.45193416312966\n",
      "resetting env. episode reward total was -15.0. running mean: -16.43741482149836\n",
      "resetting env. episode reward total was -20.0. running mean: -16.47304067328338\n",
      "resetting env. episode reward total was -16.0. running mean: -16.468310266550546\n",
      "resetting env. episode reward total was -11.0. running mean: -16.41362716388504\n",
      "resetting env. episode reward total was -14.0. running mean: -16.38949089224619\n",
      "resetting env. episode reward total was -11.0. running mean: -16.335595983323728\n",
      "resetting env. episode reward total was -16.0. running mean: -16.332240023490492\n",
      "resetting env. episode reward total was -16.0. running mean: -16.328917623255588\n",
      "resetting env. episode reward total was -15.0. running mean: -16.31562844702303\n",
      "resetting env. episode reward total was -17.0. running mean: -16.322472162552803\n",
      "resetting env. episode reward total was -12.0. running mean: -16.279247440927275\n",
      "resetting env. episode reward total was -13.0. running mean: -16.246454966518\n",
      "resetting env. episode reward total was -18.0. running mean: -16.26399041685282\n",
      "resetting env. episode reward total was -16.0. running mean: -16.26135051268429\n",
      "resetting env. episode reward total was -13.0. running mean: -16.22873700755745\n",
      "resetting env. episode reward total was -18.0. running mean: -16.246449637481874\n",
      "resetting env. episode reward total was -9.0. running mean: -16.173985141107053\n",
      "resetting env. episode reward total was -16.0. running mean: -16.172245289695983\n",
      "resetting env. episode reward total was -15.0. running mean: -16.16052283679902\n",
      "resetting env. episode reward total was -12.0. running mean: -16.11891760843103\n",
      "resetting env. episode reward total was -16.0. running mean: -16.11772843234672\n",
      "resetting env. episode reward total was -14.0. running mean: -16.096551148023252\n",
      "resetting env. episode reward total was -17.0. running mean: -16.10558563654302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -19.0. running mean: -16.134529780177587\n",
      "resetting env. episode reward total was -16.0. running mean: -16.13318448237581\n",
      "resetting env. episode reward total was -19.0. running mean: -16.16185263755205\n",
      "resetting env. episode reward total was -19.0. running mean: -16.190234111176533\n",
      "resetting env. episode reward total was -15.0. running mean: -16.178331770064766\n",
      "resetting env. episode reward total was -16.0. running mean: -16.176548452364116\n",
      "resetting env. episode reward total was -6.0. running mean: -16.074782967840473\n",
      "resetting env. episode reward total was -13.0. running mean: -16.04403513816207\n",
      "resetting env. episode reward total was -14.0. running mean: -16.02359478678045\n",
      "resetting env. episode reward total was -16.0. running mean: -16.023358838912646\n",
      "resetting env. episode reward total was -9.0. running mean: -15.953125250523518\n",
      "resetting env. episode reward total was -15.0. running mean: -15.943593998018283\n",
      "resetting env. episode reward total was -15.0. running mean: -15.9341580580381\n",
      "resetting env. episode reward total was -17.0. running mean: -15.944816477457719\n",
      "resetting env. episode reward total was -19.0. running mean: -15.975368312683141\n",
      "resetting env. episode reward total was -17.0. running mean: -15.98561462955631\n",
      "resetting env. episode reward total was -19.0. running mean: -16.015758483260747\n",
      "resetting env. episode reward total was -19.0. running mean: -16.04560089842814\n",
      "resetting env. episode reward total was -15.0. running mean: -16.03514488944386\n",
      "resetting env. episode reward total was -15.0. running mean: -16.02479344054942\n",
      "resetting env. episode reward total was -11.0. running mean: -15.974545506143924\n",
      "resetting env. episode reward total was -17.0. running mean: -15.984800051082484\n",
      "resetting env. episode reward total was -15.0. running mean: -15.974952050571659\n",
      "resetting env. episode reward total was -18.0. running mean: -15.995202530065942\n",
      "resetting env. episode reward total was -16.0. running mean: -15.995250504765282\n",
      "resetting env. episode reward total was -16.0. running mean: -15.99529799971763\n",
      "resetting env. episode reward total was -9.0. running mean: -15.925345019720453\n",
      "resetting env. episode reward total was -10.0. running mean: -15.866091569523247\n",
      "resetting env. episode reward total was -18.0. running mean: -15.887430653828014\n",
      "resetting env. episode reward total was -17.0. running mean: -15.898556347289734\n",
      "resetting env. episode reward total was -15.0. running mean: -15.889570783816836\n",
      "resetting env. episode reward total was -13.0. running mean: -15.86067507597867\n",
      "resetting env. episode reward total was -14.0. running mean: -15.842068325218882\n",
      "resetting env. episode reward total was -12.0. running mean: -15.803647641966693\n",
      "resetting env. episode reward total was -15.0. running mean: -15.795611165547026\n",
      "resetting env. episode reward total was -14.0. running mean: -15.777655053891555\n",
      "resetting env. episode reward total was -16.0. running mean: -15.77987850335264\n",
      "resetting env. episode reward total was -14.0. running mean: -15.762079718319114\n",
      "resetting env. episode reward total was -15.0. running mean: -15.754458921135923\n",
      "resetting env. episode reward total was -7.0. running mean: -15.666914331924565\n",
      "resetting env. episode reward total was -20.0. running mean: -15.710245188605318\n",
      "resetting env. episode reward total was -11.0. running mean: -15.663142736719264\n",
      "resetting env. episode reward total was -16.0. running mean: -15.666511309352071\n",
      "resetting env. episode reward total was -10.0. running mean: -15.60984619625855\n",
      "resetting env. episode reward total was -20.0. running mean: -15.653747734295964\n",
      "resetting env. episode reward total was -17.0. running mean: -15.667210256953004\n",
      "resetting env. episode reward total was -10.0. running mean: -15.610538154383473\n",
      "resetting env. episode reward total was -9.0. running mean: -15.544432772839638\n",
      "resetting env. episode reward total was -15.0. running mean: -15.538988445111242\n",
      "resetting env. episode reward total was -11.0. running mean: -15.493598560660129\n",
      "resetting env. episode reward total was -15.0. running mean: -15.488662575053528\n",
      "resetting env. episode reward total was -15.0. running mean: -15.483775949302993\n",
      "resetting env. episode reward total was -8.0. running mean: -15.408938189809962\n",
      "resetting env. episode reward total was -13.0. running mean: -15.384848807911863\n",
      "resetting env. episode reward total was -18.0. running mean: -15.411000319832745\n",
      "resetting env. episode reward total was -15.0. running mean: -15.406890316634417\n",
      "resetting env. episode reward total was -17.0. running mean: -15.422821413468073\n",
      "resetting env. episode reward total was -14.0. running mean: -15.408593199333392\n",
      "resetting env. episode reward total was -15.0. running mean: -15.404507267340058\n",
      "resetting env. episode reward total was -16.0. running mean: -15.410462194666657\n",
      "resetting env. episode reward total was -18.0. running mean: -15.43635757271999\n",
      "resetting env. episode reward total was -18.0. running mean: -15.46199399699279\n",
      "resetting env. episode reward total was -11.0. running mean: -15.417374057022862\n",
      "resetting env. episode reward total was -14.0. running mean: -15.403200316452633\n",
      "resetting env. episode reward total was -12.0. running mean: -15.369168313288105\n",
      "resetting env. episode reward total was -21.0. running mean: -15.425476630155224\n",
      "resetting env. episode reward total was -15.0. running mean: -15.421221863853672\n",
      "resetting env. episode reward total was -17.0. running mean: -15.437009645215134\n",
      "resetting env. episode reward total was -17.0. running mean: -15.452639548762983\n",
      "resetting env. episode reward total was -12.0. running mean: -15.418113153275351\n",
      "resetting env. episode reward total was -17.0. running mean: -15.433932021742597\n",
      "resetting env. episode reward total was -16.0. running mean: -15.439592701525171\n",
      "resetting env. episode reward total was -20.0. running mean: -15.48519677450992\n",
      "resetting env. episode reward total was -16.0. running mean: -15.49034480676482\n",
      "resetting env. episode reward total was -15.0. running mean: -15.485441358697173\n",
      "resetting env. episode reward total was -15.0. running mean: -15.480586945110202\n",
      "resetting env. episode reward total was -7.0. running mean: -15.3957810756591\n",
      "resetting env. episode reward total was -17.0. running mean: -15.411823264902509\n",
      "resetting env. episode reward total was -18.0. running mean: -15.437705032253483\n",
      "resetting env. episode reward total was -15.0. running mean: -15.433327981930947\n",
      "resetting env. episode reward total was -21.0. running mean: -15.488994702111638\n",
      "resetting env. episode reward total was -17.0. running mean: -15.504104755090522\n",
      "resetting env. episode reward total was -11.0. running mean: -15.459063707539615\n",
      "resetting env. episode reward total was -15.0. running mean: -15.45447307046422\n",
      "resetting env. episode reward total was -13.0. running mean: -15.429928339759577\n",
      "resetting env. episode reward total was -12.0. running mean: -15.395629056361981\n",
      "resetting env. episode reward total was -18.0. running mean: -15.42167276579836\n",
      "resetting env. episode reward total was -19.0. running mean: -15.457456038140377\n",
      "resetting env. episode reward total was -17.0. running mean: -15.472881477758973\n",
      "resetting env. episode reward total was -17.0. running mean: -15.488152662981383\n",
      "resetting env. episode reward total was -13.0. running mean: -15.46327113635157\n",
      "resetting env. episode reward total was -17.0. running mean: -15.478638424988056\n",
      "resetting env. episode reward total was -12.0. running mean: -15.443852040738173\n",
      "resetting env. episode reward total was -14.0. running mean: -15.429413520330792\n",
      "resetting env. episode reward total was -11.0. running mean: -15.385119385127483\n",
      "resetting env. episode reward total was -10.0. running mean: -15.331268191276209\n",
      "resetting env. episode reward total was -17.0. running mean: -15.347955509363446\n",
      "resetting env. episode reward total was -15.0. running mean: -15.344475954269813\n",
      "resetting env. episode reward total was -17.0. running mean: -15.361031194727115\n",
      "resetting env. episode reward total was -17.0. running mean: -15.377420882779843\n",
      "resetting env. episode reward total was -11.0. running mean: -15.333646673952044\n",
      "resetting env. episode reward total was -13.0. running mean: -15.310310207212524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -11.0. running mean: -15.267207105140399\n",
      "resetting env. episode reward total was -10.0. running mean: -15.214535034088994\n",
      "resetting env. episode reward total was -14.0. running mean: -15.202389683748105\n",
      "resetting env. episode reward total was -9.0. running mean: -15.140365786910625\n",
      "resetting env. episode reward total was -16.0. running mean: -15.148962129041518\n",
      "resetting env. episode reward total was -15.0. running mean: -15.147472507751104\n",
      "resetting env. episode reward total was -19.0. running mean: -15.185997782673592\n",
      "resetting env. episode reward total was -15.0. running mean: -15.184137804846856\n",
      "resetting env. episode reward total was -19.0. running mean: -15.222296426798387\n",
      "resetting env. episode reward total was -15.0. running mean: -15.220073462530403\n",
      "resetting env. episode reward total was -18.0. running mean: -15.247872727905099\n",
      "resetting env. episode reward total was -15.0. running mean: -15.245394000626048\n",
      "resetting env. episode reward total was -15.0. running mean: -15.242940060619787\n",
      "resetting env. episode reward total was -13.0. running mean: -15.22051066001359\n",
      "resetting env. episode reward total was -12.0. running mean: -15.188305553413453\n",
      "resetting env. episode reward total was -10.0. running mean: -15.136422497879318\n",
      "resetting env. episode reward total was -14.0. running mean: -15.125058272900525\n",
      "resetting env. episode reward total was -18.0. running mean: -15.153807690171519\n",
      "resetting env. episode reward total was -17.0. running mean: -15.172269613269803\n",
      "resetting env. episode reward total was -15.0. running mean: -15.170546917137106\n",
      "resetting env. episode reward total was -17.0. running mean: -15.188841447965734\n",
      "resetting env. episode reward total was -12.0. running mean: -15.156953033486076\n",
      "resetting env. episode reward total was -16.0. running mean: -15.165383503151215\n",
      "resetting env. episode reward total was -14.0. running mean: -15.153729668119704\n",
      "resetting env. episode reward total was -13.0. running mean: -15.132192371438508\n",
      "resetting env. episode reward total was -12.0. running mean: -15.100870447724123\n",
      "resetting env. episode reward total was -17.0. running mean: -15.119861743246881\n",
      "resetting env. episode reward total was -9.0. running mean: -15.058663125814412\n",
      "resetting env. episode reward total was -11.0. running mean: -15.018076494556267\n",
      "resetting env. episode reward total was -17.0. running mean: -15.037895729610703\n",
      "resetting env. episode reward total was -13.0. running mean: -15.017516772314597\n",
      "resetting env. episode reward total was -17.0. running mean: -15.03734160459145\n",
      "resetting env. episode reward total was -17.0. running mean: -15.056968188545536\n",
      "resetting env. episode reward total was -14.0. running mean: -15.046398506660081\n",
      "resetting env. episode reward total was -15.0. running mean: -15.04593452159348\n",
      "resetting env. episode reward total was -13.0. running mean: -15.025475176377546\n",
      "resetting env. episode reward total was -11.0. running mean: -14.98522042461377\n",
      "resetting env. episode reward total was -15.0. running mean: -14.985368220367633\n",
      "resetting env. episode reward total was -19.0. running mean: -15.025514538163955\n",
      "resetting env. episode reward total was -14.0. running mean: -15.015259392782315\n",
      "resetting env. episode reward total was -13.0. running mean: -14.995106798854493\n",
      "resetting env. episode reward total was -17.0. running mean: -15.01515573086595\n",
      "resetting env. episode reward total was -9.0. running mean: -14.95500417355729\n",
      "resetting env. episode reward total was -17.0. running mean: -14.975454131821717\n",
      "resetting env. episode reward total was -13.0. running mean: -14.955699590503501\n",
      "resetting env. episode reward total was -13.0. running mean: -14.936142594598467\n",
      "resetting env. episode reward total was -15.0. running mean: -14.936781168652482\n",
      "resetting env. episode reward total was -17.0. running mean: -14.957413356965956\n",
      "resetting env. episode reward total was -16.0. running mean: -14.967839223396297\n",
      "resetting env. episode reward total was -13.0. running mean: -14.948160831162335\n",
      "resetting env. episode reward total was -15.0. running mean: -14.948679222850712\n",
      "resetting env. episode reward total was -9.0. running mean: -14.889192430622204\n",
      "resetting env. episode reward total was -13.0. running mean: -14.870300506315983\n",
      "resetting env. episode reward total was -13.0. running mean: -14.851597501252824\n",
      "resetting env. episode reward total was -10.0. running mean: -14.803081526240295\n",
      "resetting env. episode reward total was -13.0. running mean: -14.785050710977892\n",
      "resetting env. episode reward total was -13.0. running mean: -14.767200203868114\n",
      "resetting env. episode reward total was -15.0. running mean: -14.769528201829432\n",
      "resetting env. episode reward total was -16.0. running mean: -14.781832919811139\n",
      "resetting env. episode reward total was -9.0. running mean: -14.724014590613027\n",
      "resetting env. episode reward total was -17.0. running mean: -14.746774444706897\n",
      "resetting env. episode reward total was -10.0. running mean: -14.699306700259829\n",
      "resetting env. episode reward total was -5.0. running mean: -14.60231363325723\n",
      "resetting env. episode reward total was -11.0. running mean: -14.566290496924656\n",
      "resetting env. episode reward total was -18.0. running mean: -14.60062759195541\n",
      "resetting env. episode reward total was -10.0. running mean: -14.554621316035856\n",
      "resetting env. episode reward total was -13.0. running mean: -14.539075102875499\n",
      "resetting env. episode reward total was -17.0. running mean: -14.563684351846744\n",
      "resetting env. episode reward total was -13.0. running mean: -14.548047508328278\n",
      "resetting env. episode reward total was -10.0. running mean: -14.502567033244995\n",
      "resetting env. episode reward total was -13.0. running mean: -14.487541362912546\n",
      "resetting env. episode reward total was -17.0. running mean: -14.51266594928342\n",
      "resetting env. episode reward total was -12.0. running mean: -14.487539289790584\n",
      "resetting env. episode reward total was -3.0. running mean: -14.372663896892679\n",
      "resetting env. episode reward total was -9.0. running mean: -14.318937257923752\n",
      "resetting env. episode reward total was -3.0. running mean: -14.205747885344513\n",
      "resetting env. episode reward total was -17.0. running mean: -14.233690406491068\n",
      "resetting env. episode reward total was -10.0. running mean: -14.191353502426157\n",
      "resetting env. episode reward total was -7.0. running mean: -14.119439967401895\n",
      "resetting env. episode reward total was -14.0. running mean: -14.118245567727877\n",
      "resetting env. episode reward total was -12.0. running mean: -14.097063112050597\n",
      "resetting env. episode reward total was -15.0. running mean: -14.10609248093009\n",
      "resetting env. episode reward total was -10.0. running mean: -14.06503155612079\n",
      "resetting env. episode reward total was -11.0. running mean: -14.034381240559581\n",
      "resetting env. episode reward total was -14.0. running mean: -14.034037428153985\n",
      "resetting env. episode reward total was -18.0. running mean: -14.073697053872445\n",
      "resetting env. episode reward total was -15.0. running mean: -14.08296008333372\n",
      "resetting env. episode reward total was -13.0. running mean: -14.072130482500384\n",
      "resetting env. episode reward total was -12.0. running mean: -14.05140917767538\n",
      "resetting env. episode reward total was -14.0. running mean: -14.050895085898626\n",
      "resetting env. episode reward total was -11.0. running mean: -14.020386135039638\n",
      "resetting env. episode reward total was -14.0. running mean: -14.020182273689242\n",
      "resetting env. episode reward total was -9.0. running mean: -13.969980450952349\n",
      "resetting env. episode reward total was -17.0. running mean: -14.000280646442825\n",
      "resetting env. episode reward total was -14.0. running mean: -14.000277839978397\n",
      "resetting env. episode reward total was -19.0. running mean: -14.050275061578612\n",
      "resetting env. episode reward total was -16.0. running mean: -14.069772310962826\n",
      "resetting env. episode reward total was -12.0. running mean: -14.049074587853196\n",
      "resetting env. episode reward total was -8.0. running mean: -13.988583841974664\n",
      "resetting env. episode reward total was -18.0. running mean: -14.028698003554917\n",
      "resetting env. episode reward total was -17.0. running mean: -14.058411023519367\n",
      "resetting env. episode reward total was -14.0. running mean: -14.057826913284174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -17.0. running mean: -14.087248644151332\n",
      "resetting env. episode reward total was -17.0. running mean: -14.11637615770982\n",
      "resetting env. episode reward total was -12.0. running mean: -14.09521239613272\n",
      "resetting env. episode reward total was -19.0. running mean: -14.144260272171392\n",
      "resetting env. episode reward total was -21.0. running mean: -14.212817669449679\n",
      "resetting env. episode reward total was -7.0. running mean: -14.140689492755182\n",
      "resetting env. episode reward total was -10.0. running mean: -14.09928259782763\n",
      "resetting env. episode reward total was -8.0. running mean: -14.038289771849353\n",
      "resetting env. episode reward total was -16.0. running mean: -14.05790687413086\n",
      "resetting env. episode reward total was -9.0. running mean: -14.00732780538955\n",
      "resetting env. episode reward total was -13.0. running mean: -13.997254527335656\n",
      "resetting env. episode reward total was -10.0. running mean: -13.957281982062298\n",
      "resetting env. episode reward total was -10.0. running mean: -13.917709162241675\n",
      "resetting env. episode reward total was -13.0. running mean: -13.908532070619259\n",
      "resetting env. episode reward total was -13.0. running mean: -13.899446749913068\n",
      "resetting env. episode reward total was -16.0. running mean: -13.920452282413937\n",
      "resetting env. episode reward total was -11.0. running mean: -13.891247759589797\n",
      "resetting env. episode reward total was -7.0. running mean: -13.8223352819939\n",
      "resetting env. episode reward total was -10.0. running mean: -13.78411192917396\n",
      "resetting env. episode reward total was -13.0. running mean: -13.776270809882222\n",
      "resetting env. episode reward total was -17.0. running mean: -13.8085081017834\n",
      "resetting env. episode reward total was -10.0. running mean: -13.770423020765564\n",
      "resetting env. episode reward total was -20.0. running mean: -13.832718790557909\n",
      "resetting env. episode reward total was -11.0. running mean: -13.804391602652329\n",
      "resetting env. episode reward total was -13.0. running mean: -13.796347686625806\n",
      "resetting env. episode reward total was -13.0. running mean: -13.788384209759549\n",
      "resetting env. episode reward total was -11.0. running mean: -13.760500367661953\n",
      "resetting env. episode reward total was -11.0. running mean: -13.732895363985334\n",
      "resetting env. episode reward total was -10.0. running mean: -13.69556641034548\n",
      "resetting env. episode reward total was -16.0. running mean: -13.718610746242025\n",
      "resetting env. episode reward total was -16.0. running mean: -13.741424638779604\n",
      "resetting env. episode reward total was -15.0. running mean: -13.754010392391807\n",
      "resetting env. episode reward total was -12.0. running mean: -13.736470288467888\n",
      "resetting env. episode reward total was -16.0. running mean: -13.75910558558321\n",
      "resetting env. episode reward total was -13.0. running mean: -13.751514529727379\n",
      "resetting env. episode reward total was -8.0. running mean: -13.693999384430105\n",
      "resetting env. episode reward total was -10.0. running mean: -13.657059390585804\n",
      "resetting env. episode reward total was -17.0. running mean: -13.690488796679945\n",
      "resetting env. episode reward total was -11.0. running mean: -13.663583908713145\n",
      "resetting env. episode reward total was -16.0. running mean: -13.686948069626013\n",
      "resetting env. episode reward total was -17.0. running mean: -13.720078588929752\n",
      "resetting env. episode reward total was -11.0. running mean: -13.692877803040453\n",
      "resetting env. episode reward total was -9.0. running mean: -13.645949025010049\n",
      "resetting env. episode reward total was -8.0. running mean: -13.589489534759949\n",
      "resetting env. episode reward total was -17.0. running mean: -13.62359463941235\n",
      "resetting env. episode reward total was -13.0. running mean: -13.617358693018227\n",
      "resetting env. episode reward total was -19.0. running mean: -13.671185106088044\n",
      "resetting env. episode reward total was -11.0. running mean: -13.644473255027163\n",
      "resetting env. episode reward total was -17.0. running mean: -13.678028522476891\n",
      "resetting env. episode reward total was -11.0. running mean: -13.651248237252123\n",
      "resetting env. episode reward total was -14.0. running mean: -13.654735754879601\n",
      "resetting env. episode reward total was -14.0. running mean: -13.658188397330806\n",
      "resetting env. episode reward total was -14.0. running mean: -13.661606513357498\n",
      "resetting env. episode reward total was -13.0. running mean: -13.654990448223923\n",
      "resetting env. episode reward total was -10.0. running mean: -13.618440543741684\n",
      "resetting env. episode reward total was -11.0. running mean: -13.592256138304267\n",
      "resetting env. episode reward total was -13.0. running mean: -13.586333576921225\n",
      "resetting env. episode reward total was -13.0. running mean: -13.580470241152014\n",
      "resetting env. episode reward total was -13.0. running mean: -13.574665538740495\n",
      "resetting env. episode reward total was -15.0. running mean: -13.58891888335309\n",
      "resetting env. episode reward total was -12.0. running mean: -13.573029694519558\n",
      "resetting env. episode reward total was -9.0. running mean: -13.527299397574362\n",
      "resetting env. episode reward total was -15.0. running mean: -13.54202640359862\n",
      "resetting env. episode reward total was -6.0. running mean: -13.466606139562634\n",
      "resetting env. episode reward total was -11.0. running mean: -13.441940078167008\n",
      "resetting env. episode reward total was -12.0. running mean: -13.427520677385337\n",
      "resetting env. episode reward total was -12.0. running mean: -13.413245470611482\n",
      "resetting env. episode reward total was -12.0. running mean: -13.399113015905366\n",
      "resetting env. episode reward total was -14.0. running mean: -13.405121885746313\n",
      "resetting env. episode reward total was -14.0. running mean: -13.41107066688885\n",
      "resetting env. episode reward total was -15.0. running mean: -13.426959960219962\n",
      "resetting env. episode reward total was -4.0. running mean: -13.332690360617761\n",
      "resetting env. episode reward total was -8.0. running mean: -13.279363457011582\n",
      "resetting env. episode reward total was -12.0. running mean: -13.266569822441467\n",
      "resetting env. episode reward total was -5.0. running mean: -13.183904124217053\n",
      "resetting env. episode reward total was -9.0. running mean: -13.142065082974883\n",
      "resetting env. episode reward total was -9.0. running mean: -13.100644432145133\n",
      "resetting env. episode reward total was -16.0. running mean: -13.129637987823681\n",
      "resetting env. episode reward total was -11.0. running mean: -13.108341607945444\n",
      "resetting env. episode reward total was -15.0. running mean: -13.127258191865991\n",
      "resetting env. episode reward total was -8.0. running mean: -13.075985609947331\n",
      "resetting env. episode reward total was -12.0. running mean: -13.065225753847857\n",
      "resetting env. episode reward total was -12.0. running mean: -13.054573496309377\n",
      "resetting env. episode reward total was -18.0. running mean: -13.104027761346282\n",
      "resetting env. episode reward total was -9.0. running mean: -13.062987483732819\n",
      "resetting env. episode reward total was -9.0. running mean: -13.02235760889549\n",
      "resetting env. episode reward total was -15.0. running mean: -13.042134032806535\n",
      "resetting env. episode reward total was -11.0. running mean: -13.021712692478468\n",
      "resetting env. episode reward total was -12.0. running mean: -13.011495565553682\n",
      "resetting env. episode reward total was -13.0. running mean: -13.011380609898145\n",
      "resetting env. episode reward total was -10.0. running mean: -12.981266803799164\n",
      "resetting env. episode reward total was -14.0. running mean: -12.991454135761172\n",
      "resetting env. episode reward total was -9.0. running mean: -12.95153959440356\n",
      "resetting env. episode reward total was -16.0. running mean: -12.982024198459523\n",
      "resetting env. episode reward total was -10.0. running mean: -12.952203956474929\n",
      "resetting env. episode reward total was -16.0. running mean: -12.98268191691018\n",
      "resetting env. episode reward total was -8.0. running mean: -12.932855097741077\n",
      "resetting env. episode reward total was -13.0. running mean: -12.933526546763668\n",
      "resetting env. episode reward total was -13.0. running mean: -12.934191281296032\n",
      "resetting env. episode reward total was -12.0. running mean: -12.924849368483072\n",
      "resetting env. episode reward total was -11.0. running mean: -12.90560087479824\n",
      "resetting env. episode reward total was -15.0. running mean: -12.926544866050259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: -12.877279417389756\n",
      "resetting env. episode reward total was -10.0. running mean: -12.848506623215858\n",
      "resetting env. episode reward total was -13.0. running mean: -12.8500215569837\n",
      "resetting env. episode reward total was -9.0. running mean: -12.811521341413863\n",
      "resetting env. episode reward total was 2.0. running mean: -12.663406127999725\n",
      "resetting env. episode reward total was -11.0. running mean: -12.646772066719727\n",
      "resetting env. episode reward total was -11.0. running mean: -12.63030434605253\n",
      "resetting env. episode reward total was -9.0. running mean: -12.594001302592003\n",
      "resetting env. episode reward total was -15.0. running mean: -12.618061289566084\n",
      "resetting env. episode reward total was -8.0. running mean: -12.571880676670423\n",
      "resetting env. episode reward total was -10.0. running mean: -12.546161869903719\n",
      "resetting env. episode reward total was -8.0. running mean: -12.500700251204682\n",
      "resetting env. episode reward total was -16.0. running mean: -12.535693248692635\n",
      "resetting env. episode reward total was -13.0. running mean: -12.540336316205709\n",
      "resetting env. episode reward total was -9.0. running mean: -12.504932953043651\n",
      "resetting env. episode reward total was -14.0. running mean: -12.519883623513214\n",
      "resetting env. episode reward total was -10.0. running mean: -12.494684787278082\n",
      "resetting env. episode reward total was -13.0. running mean: -12.499737939405302\n",
      "resetting env. episode reward total was -7.0. running mean: -12.44474056001125\n",
      "resetting env. episode reward total was -13.0. running mean: -12.450293154411137\n",
      "resetting env. episode reward total was -13.0. running mean: -12.455790222867027\n",
      "resetting env. episode reward total was -16.0. running mean: -12.491232320638357\n",
      "resetting env. episode reward total was -15.0. running mean: -12.516319997431973\n",
      "resetting env. episode reward total was -15.0. running mean: -12.541156797457653\n",
      "resetting env. episode reward total was -7.0. running mean: -12.485745229483076\n",
      "resetting env. episode reward total was -9.0. running mean: -12.450887777188244\n",
      "resetting env. episode reward total was -1.0. running mean: -12.336378899416362\n",
      "resetting env. episode reward total was -17.0. running mean: -12.383015110422198\n",
      "resetting env. episode reward total was -6.0. running mean: -12.319184959317976\n",
      "resetting env. episode reward total was -13.0. running mean: -12.325993109724797\n",
      "resetting env. episode reward total was -12.0. running mean: -12.322733178627548\n",
      "resetting env. episode reward total was -14.0. running mean: -12.339505846841273\n",
      "resetting env. episode reward total was 2.0. running mean: -12.196110788372861\n",
      "resetting env. episode reward total was -8.0. running mean: -12.154149680489132\n",
      "resetting env. episode reward total was -8.0. running mean: -12.112608183684241\n",
      "resetting env. episode reward total was -13.0. running mean: -12.121482101847398\n",
      "resetting env. episode reward total was -18.0. running mean: -12.180267280828923\n",
      "resetting env. episode reward total was -12.0. running mean: -12.178464608020633\n",
      "resetting env. episode reward total was -17.0. running mean: -12.226679961940427\n",
      "resetting env. episode reward total was -5.0. running mean: -12.154413162321022\n",
      "resetting env. episode reward total was -9.0. running mean: -12.122869030697812\n",
      "resetting env. episode reward total was -14.0. running mean: -12.141640340390834\n",
      "resetting env. episode reward total was -14.0. running mean: -12.160223936986927\n",
      "resetting env. episode reward total was -16.0. running mean: -12.198621697617059\n",
      "resetting env. episode reward total was -12.0. running mean: -12.196635480640888\n",
      "resetting env. episode reward total was -3.0. running mean: -12.104669125834478\n",
      "resetting env. episode reward total was -9.0. running mean: -12.073622434576134\n",
      "resetting env. episode reward total was -13.0. running mean: -12.082886210230374\n",
      "resetting env. episode reward total was -12.0. running mean: -12.08205734812807\n",
      "resetting env. episode reward total was -6.0. running mean: -12.02123677464679\n",
      "resetting env. episode reward total was -14.0. running mean: -12.041024406900322\n",
      "resetting env. episode reward total was -13.0. running mean: -12.05061416283132\n",
      "resetting env. episode reward total was -13.0. running mean: -12.060108021203007\n",
      "resetting env. episode reward total was -15.0. running mean: -12.089506940990978\n",
      "resetting env. episode reward total was -11.0. running mean: -12.078611871581067\n",
      "resetting env. episode reward total was -7.0. running mean: -12.027825752865256\n",
      "resetting env. episode reward total was -6.0. running mean: -11.967547495336603\n",
      "resetting env. episode reward total was -11.0. running mean: -11.957872020383236\n",
      "resetting env. episode reward total was -13.0. running mean: -11.968293300179404\n",
      "resetting env. episode reward total was -19.0. running mean: -12.03861036717761\n",
      "resetting env. episode reward total was -10.0. running mean: -12.018224263505832\n",
      "resetting env. episode reward total was -16.0. running mean: -12.058042020870774\n",
      "resetting env. episode reward total was -7.0. running mean: -12.007461600662067\n",
      "resetting env. episode reward total was -9.0. running mean: -11.977386984655446\n",
      "resetting env. episode reward total was -12.0. running mean: -11.977613114808891\n",
      "resetting env. episode reward total was -10.0. running mean: -11.957836983660801\n",
      "resetting env. episode reward total was -15.0. running mean: -11.988258613824193\n",
      "resetting env. episode reward total was -3.0. running mean: -11.89837602768595\n",
      "resetting env. episode reward total was -11.0. running mean: -11.88939226740909\n",
      "resetting env. episode reward total was -8.0. running mean: -11.850498344734998\n",
      "resetting env. episode reward total was -11.0. running mean: -11.841993361287647\n",
      "resetting env. episode reward total was -12.0. running mean: -11.84357342767477\n",
      "resetting env. episode reward total was 2.0. running mean: -11.705137693398022\n",
      "resetting env. episode reward total was -15.0. running mean: -11.738086316464042\n",
      "resetting env. episode reward total was -16.0. running mean: -11.7807054532994\n",
      "resetting env. episode reward total was -5.0. running mean: -11.712898398766407\n",
      "resetting env. episode reward total was -15.0. running mean: -11.745769414778744\n",
      "resetting env. episode reward total was -4.0. running mean: -11.668311720630955\n",
      "resetting env. episode reward total was -15.0. running mean: -11.701628603424645\n",
      "resetting env. episode reward total was -13.0. running mean: -11.714612317390399\n",
      "resetting env. episode reward total was -8.0. running mean: -11.677466194216494\n",
      "resetting env. episode reward total was -13.0. running mean: -11.69069153227433\n",
      "resetting env. episode reward total was -10.0. running mean: -11.673784616951586\n",
      "resetting env. episode reward total was -17.0. running mean: -11.72704677078207\n",
      "resetting env. episode reward total was -12.0. running mean: -11.72977630307425\n",
      "resetting env. episode reward total was -17.0. running mean: -11.782478540043506\n",
      "resetting env. episode reward total was -11.0. running mean: -11.77465375464307\n",
      "resetting env. episode reward total was -10.0. running mean: -11.75690721709664\n",
      "resetting env. episode reward total was -6.0. running mean: -11.699338144925674\n",
      "resetting env. episode reward total was -10.0. running mean: -11.682344763476417\n",
      "resetting env. episode reward total was -15.0. running mean: -11.715521315841652\n",
      "resetting env. episode reward total was -12.0. running mean: -11.718366102683234\n",
      "resetting env. episode reward total was -11.0. running mean: -11.711182441656401\n",
      "resetting env. episode reward total was -13.0. running mean: -11.724070617239837\n",
      "resetting env. episode reward total was -12.0. running mean: -11.726829911067439\n",
      "resetting env. episode reward total was -11.0. running mean: -11.719561611956763\n",
      "resetting env. episode reward total was -14.0. running mean: -11.742365995837195\n",
      "resetting env. episode reward total was -9.0. running mean: -11.714942335878822\n",
      "resetting env. episode reward total was -11.0. running mean: -11.707792912520034\n",
      "resetting env. episode reward total was -11.0. running mean: -11.700714983394834\n",
      "resetting env. episode reward total was -12.0. running mean: -11.703707833560884\n",
      "resetting env. episode reward total was -9.0. running mean: -11.676670755225276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -9.0. running mean: -11.649904047673022\n",
      "resetting env. episode reward total was -15.0. running mean: -11.683405007196292\n",
      "resetting env. episode reward total was -11.0. running mean: -11.676570957124328\n",
      "resetting env. episode reward total was -18.0. running mean: -11.739805247553084\n",
      "resetting env. episode reward total was -10.0. running mean: -11.722407195077553\n",
      "resetting env. episode reward total was -11.0. running mean: -11.715183123126776\n",
      "resetting env. episode reward total was -12.0. running mean: -11.718031291895507\n",
      "resetting env. episode reward total was -3.0. running mean: -11.63085097897655\n",
      "resetting env. episode reward total was -14.0. running mean: -11.654542469186785\n",
      "resetting env. episode reward total was -9.0. running mean: -11.627997044494917\n",
      "resetting env. episode reward total was -18.0. running mean: -11.691717074049967\n",
      "resetting env. episode reward total was -8.0. running mean: -11.654799903309467\n",
      "resetting env. episode reward total was -3.0. running mean: -11.568251904276371\n",
      "resetting env. episode reward total was -9.0. running mean: -11.542569385233607\n",
      "resetting env. episode reward total was -15.0. running mean: -11.577143691381272\n",
      "resetting env. episode reward total was -7.0. running mean: -11.53137225446746\n",
      "resetting env. episode reward total was -11.0. running mean: -11.526058531922784\n",
      "resetting env. episode reward total was -16.0. running mean: -11.570797946603555\n",
      "resetting env. episode reward total was -12.0. running mean: -11.575089967137519\n",
      "resetting env. episode reward total was -10.0. running mean: -11.559339067466142\n",
      "resetting env. episode reward total was -11.0. running mean: -11.55374567679148\n",
      "resetting env. episode reward total was -16.0. running mean: -11.598208220023565\n",
      "resetting env. episode reward total was -9.0. running mean: -11.57222613782333\n",
      "resetting env. episode reward total was -12.0. running mean: -11.576503876445097\n",
      "resetting env. episode reward total was -19.0. running mean: -11.650738837680645\n",
      "resetting env. episode reward total was -15.0. running mean: -11.684231449303839\n",
      "resetting env. episode reward total was -6.0. running mean: -11.627389134810802\n",
      "resetting env. episode reward total was -10.0. running mean: -11.611115243462693\n",
      "resetting env. episode reward total was -17.0. running mean: -11.665004091028067\n",
      "resetting env. episode reward total was -15.0. running mean: -11.698354050117786\n",
      "resetting env. episode reward total was -15.0. running mean: -11.731370509616609\n",
      "resetting env. episode reward total was -15.0. running mean: -11.764056804520443\n",
      "resetting env. episode reward total was -6.0. running mean: -11.706416236475238\n",
      "resetting env. episode reward total was -12.0. running mean: -11.709352074110486\n",
      "resetting env. episode reward total was -14.0. running mean: -11.732258553369382\n",
      "resetting env. episode reward total was -6.0. running mean: -11.674935967835689\n",
      "resetting env. episode reward total was -7.0. running mean: -11.628186608157332\n",
      "resetting env. episode reward total was -11.0. running mean: -11.621904742075758\n",
      "resetting env. episode reward total was -5.0. running mean: -11.555685694655\n",
      "resetting env. episode reward total was -8.0. running mean: -11.52012883770845\n",
      "resetting env. episode reward total was -15.0. running mean: -11.554927549331365\n",
      "resetting env. episode reward total was -11.0. running mean: -11.549378273838052\n",
      "resetting env. episode reward total was -6.0. running mean: -11.493884491099672\n",
      "resetting env. episode reward total was -9.0. running mean: -11.468945646188676\n",
      "resetting env. episode reward total was -6.0. running mean: -11.414256189726789\n",
      "resetting env. episode reward total was 1.0. running mean: -11.290113627829522\n",
      "resetting env. episode reward total was -19.0. running mean: -11.367212491551225\n",
      "resetting env. episode reward total was -11.0. running mean: -11.363540366635712\n",
      "resetting env. episode reward total was -15.0. running mean: -11.399904962969355\n",
      "resetting env. episode reward total was -6.0. running mean: -11.345905913339662\n",
      "resetting env. episode reward total was -11.0. running mean: -11.342446854206264\n",
      "resetting env. episode reward total was -19.0. running mean: -11.419022385664201\n",
      "resetting env. episode reward total was -13.0. running mean: -11.43483216180756\n",
      "resetting env. episode reward total was -17.0. running mean: -11.490483840189484\n",
      "resetting env. episode reward total was -10.0. running mean: -11.475579001787588\n",
      "resetting env. episode reward total was -8.0. running mean: -11.440823211769713\n",
      "resetting env. episode reward total was -7.0. running mean: -11.396414979652016\n",
      "resetting env. episode reward total was -11.0. running mean: -11.392450829855495\n",
      "resetting env. episode reward total was -7.0. running mean: -11.34852632155694\n",
      "resetting env. episode reward total was -8.0. running mean: -11.315041058341372\n",
      "resetting env. episode reward total was -14.0. running mean: -11.341890647757959\n",
      "resetting env. episode reward total was -11.0. running mean: -11.338471741280378\n",
      "resetting env. episode reward total was -10.0. running mean: -11.325087023867573\n",
      "resetting env. episode reward total was -6.0. running mean: -11.271836153628897\n",
      "resetting env. episode reward total was -7.0. running mean: -11.229117792092607\n",
      "resetting env. episode reward total was -6.0. running mean: -11.17682661417168\n",
      "resetting env. episode reward total was -15.0. running mean: -11.215058348029965\n",
      "resetting env. episode reward total was -11.0. running mean: -11.212907764549664\n",
      "resetting env. episode reward total was -14.0. running mean: -11.240778686904168\n",
      "resetting env. episode reward total was -13.0. running mean: -11.258370900035127\n",
      "resetting env. episode reward total was -17.0. running mean: -11.315787191034776\n",
      "resetting env. episode reward total was -10.0. running mean: -11.302629319124428\n",
      "resetting env. episode reward total was -15.0. running mean: -11.339603025933183\n",
      "resetting env. episode reward total was -11.0. running mean: -11.33620699567385\n",
      "resetting env. episode reward total was -16.0. running mean: -11.38284492571711\n",
      "resetting env. episode reward total was -12.0. running mean: -11.389016476459938\n",
      "resetting env. episode reward total was -6.0. running mean: -11.335126311695339\n",
      "resetting env. episode reward total was -15.0. running mean: -11.371775048578385\n",
      "resetting env. episode reward total was -4.0. running mean: -11.298057298092601\n",
      "resetting env. episode reward total was -9.0. running mean: -11.275076725111676\n",
      "resetting env. episode reward total was -17.0. running mean: -11.33232595786056\n",
      "resetting env. episode reward total was -16.0. running mean: -11.379002698281955\n",
      "resetting env. episode reward total was 1.0. running mean: -11.255212671299136\n",
      "resetting env. episode reward total was -11.0. running mean: -11.252660544586144\n",
      "resetting env. episode reward total was -13.0. running mean: -11.270133939140283\n",
      "resetting env. episode reward total was -13.0. running mean: -11.28743259974888\n",
      "resetting env. episode reward total was -16.0. running mean: -11.334558273751393\n",
      "resetting env. episode reward total was -5.0. running mean: -11.27121269101388\n",
      "resetting env. episode reward total was -12.0. running mean: -11.278500564103739\n",
      "resetting env. episode reward total was -11.0. running mean: -11.275715558462702\n",
      "resetting env. episode reward total was -17.0. running mean: -11.332958402878075\n",
      "resetting env. episode reward total was -9.0. running mean: -11.309628818849294\n",
      "resetting env. episode reward total was -11.0. running mean: -11.306532530660801\n",
      "resetting env. episode reward total was -18.0. running mean: -11.373467205354192\n",
      "resetting env. episode reward total was -11.0. running mean: -11.369732533300649\n",
      "resetting env. episode reward total was -11.0. running mean: -11.366035207967641\n",
      "resetting env. episode reward total was -2.0. running mean: -11.272374855887964\n",
      "resetting env. episode reward total was -4.0. running mean: -11.199651107329084\n",
      "resetting env. episode reward total was -11.0. running mean: -11.197654596255791\n",
      "resetting env. episode reward total was -13.0. running mean: -11.215678050293235\n",
      "resetting env. episode reward total was -13.0. running mean: -11.233521269790304\n",
      "resetting env. episode reward total was -12.0. running mean: -11.2411860570924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: -11.178774196521475\n",
      "resetting env. episode reward total was -16.0. running mean: -11.226986454556261\n",
      "resetting env. episode reward total was -11.0. running mean: -11.224716590010697\n",
      "resetting env. episode reward total was -12.0. running mean: -11.232469424110588\n",
      "resetting env. episode reward total was -12.0. running mean: -11.240144729869481\n",
      "resetting env. episode reward total was -7.0. running mean: -11.197743282570787\n",
      "resetting env. episode reward total was -6.0. running mean: -11.14576584974508\n",
      "resetting env. episode reward total was -5.0. running mean: -11.084308191247631\n",
      "resetting env. episode reward total was -8.0. running mean: -11.053465109335155\n",
      "resetting env. episode reward total was -7.0. running mean: -11.012930458241804\n",
      "resetting env. episode reward total was -9.0. running mean: -10.992801153659386\n",
      "resetting env. episode reward total was -13.0. running mean: -11.012873142122793\n",
      "resetting env. episode reward total was -11.0. running mean: -11.012744410701565\n",
      "resetting env. episode reward total was -11.0. running mean: -11.012616966594548\n",
      "resetting env. episode reward total was 1.0. running mean: -10.892490796928602\n",
      "resetting env. episode reward total was -13.0. running mean: -10.913565888959317\n",
      "resetting env. episode reward total was -2.0. running mean: -10.824430230069723\n",
      "resetting env. episode reward total was -13.0. running mean: -10.846185927769026\n",
      "resetting env. episode reward total was -2.0. running mean: -10.757724068491335\n",
      "resetting env. episode reward total was -7.0. running mean: -10.720146827806422\n",
      "resetting env. episode reward total was -8.0. running mean: -10.692945359528357\n",
      "resetting env. episode reward total was -13.0. running mean: -10.716015905933075\n",
      "resetting env. episode reward total was -9.0. running mean: -10.698855746873743\n",
      "resetting env. episode reward total was -5.0. running mean: -10.641867189405007\n",
      "resetting env. episode reward total was -1.0. running mean: -10.545448517510957\n",
      "resetting env. episode reward total was -12.0. running mean: -10.559994032335847\n",
      "resetting env. episode reward total was -12.0. running mean: -10.574394092012488\n",
      "resetting env. episode reward total was -9.0. running mean: -10.558650151092364\n",
      "resetting env. episode reward total was -3.0. running mean: -10.483063649581439\n",
      "resetting env. episode reward total was -5.0. running mean: -10.428233013085626\n",
      "resetting env. episode reward total was -13.0. running mean: -10.45395068295477\n",
      "resetting env. episode reward total was -5.0. running mean: -10.399411176125223\n",
      "resetting env. episode reward total was -11.0. running mean: -10.40541706436397\n",
      "resetting env. episode reward total was 5.0. running mean: -10.25136289372033\n",
      "resetting env. episode reward total was -19.0. running mean: -10.338849264783127\n",
      "resetting env. episode reward total was -9.0. running mean: -10.325460772135296\n",
      "resetting env. episode reward total was 1.0. running mean: -10.212206164413942\n",
      "resetting env. episode reward total was -8.0. running mean: -10.190084102769802\n",
      "resetting env. episode reward total was -10.0. running mean: -10.188183261742104\n",
      "resetting env. episode reward total was -2.0. running mean: -10.106301429124683\n",
      "resetting env. episode reward total was -7.0. running mean: -10.075238414833436\n",
      "resetting env. episode reward total was -8.0. running mean: -10.054486030685101\n",
      "resetting env. episode reward total was -6.0. running mean: -10.013941170378251\n",
      "resetting env. episode reward total was -10.0. running mean: -10.013801758674468\n",
      "resetting env. episode reward total was -5.0. running mean: -9.963663741087725\n",
      "resetting env. episode reward total was -9.0. running mean: -9.954027103676847\n",
      "resetting env. episode reward total was -11.0. running mean: -9.964486832640077\n",
      "resetting env. episode reward total was -8.0. running mean: -9.944841964313676\n",
      "resetting env. episode reward total was -14.0. running mean: -9.98539354467054\n",
      "resetting env. episode reward total was -6.0. running mean: -9.945539609223834\n",
      "resetting env. episode reward total was -10.0. running mean: -9.946084213131595\n",
      "resetting env. episode reward total was -5.0. running mean: -9.89662337100028\n",
      "resetting env. episode reward total was -3.0. running mean: -9.827657137290275\n",
      "resetting env. episode reward total was -11.0. running mean: -9.839380565917372\n",
      "resetting env. episode reward total was -16.0. running mean: -9.900986760258197\n",
      "resetting env. episode reward total was -5.0. running mean: -9.851976892655616\n",
      "resetting env. episode reward total was -6.0. running mean: -9.81345712372906\n",
      "resetting env. episode reward total was -8.0. running mean: -9.79532255249177\n",
      "resetting env. episode reward total was -10.0. running mean: -9.797369326966852\n",
      "resetting env. episode reward total was -16.0. running mean: -9.859395633697183\n",
      "resetting env. episode reward total was -1.0. running mean: -9.770801677360211\n",
      "resetting env. episode reward total was -13.0. running mean: -9.80309366058661\n",
      "resetting env. episode reward total was -5.0. running mean: -9.755062723980744\n",
      "resetting env. episode reward total was -6.0. running mean: -9.717512096740938\n",
      "resetting env. episode reward total was -10.0. running mean: -9.720336975773527\n",
      "resetting env. episode reward total was -11.0. running mean: -9.733133606015791\n",
      "resetting env. episode reward total was -2.0. running mean: -9.655802269955633\n",
      "resetting env. episode reward total was -7.0. running mean: -9.629244247256077\n",
      "resetting env. episode reward total was -3.0. running mean: -9.562951804783516\n",
      "resetting env. episode reward total was -9.0. running mean: -9.557322286735682\n",
      "resetting env. episode reward total was -11.0. running mean: -9.571749063868324\n",
      "resetting env. episode reward total was -7.0. running mean: -9.54603157322964\n",
      "resetting env. episode reward total was -10.0. running mean: -9.550571257497344\n",
      "resetting env. episode reward total was -8.0. running mean: -9.53506554492237\n",
      "resetting env. episode reward total was -3.0. running mean: -9.469714889473146\n",
      "resetting env. episode reward total was -8.0. running mean: -9.455017740578414\n",
      "resetting env. episode reward total was -12.0. running mean: -9.48046756317263\n",
      "resetting env. episode reward total was -5.0. running mean: -9.435662887540904\n",
      "resetting env. episode reward total was -11.0. running mean: -9.451306258665493\n",
      "resetting env. episode reward total was -9.0. running mean: -9.446793196078838\n",
      "resetting env. episode reward total was -12.0. running mean: -9.472325264118048\n",
      "resetting env. episode reward total was -9.0. running mean: -9.467602011476867\n",
      "resetting env. episode reward total was -4.0. running mean: -9.412925991362098\n",
      "resetting env. episode reward total was -1.0. running mean: -9.328796731448476\n",
      "resetting env. episode reward total was -13.0. running mean: -9.365508764133992\n",
      "resetting env. episode reward total was -3.0. running mean: -9.301853676492652\n",
      "resetting env. episode reward total was -2.0. running mean: -9.228835139727725\n",
      "resetting env. episode reward total was -10.0. running mean: -9.236546788330447\n",
      "resetting env. episode reward total was -4.0. running mean: -9.184181320447141\n",
      "resetting env. episode reward total was -5.0. running mean: -9.14233950724267\n",
      "resetting env. episode reward total was -11.0. running mean: -9.160916112170243\n",
      "resetting env. episode reward total was -3.0. running mean: -9.09930695104854\n",
      "resetting env. episode reward total was -6.0. running mean: -9.068313881538055\n",
      "resetting env. episode reward total was 4.0. running mean: -8.937630742722675\n",
      "resetting env. episode reward total was -2.0. running mean: -8.868254435295448\n",
      "resetting env. episode reward total was -5.0. running mean: -8.829571890942495\n",
      "resetting env. episode reward total was -8.0. running mean: -8.82127617203307\n",
      "resetting env. episode reward total was 1.0. running mean: -8.723063410312738\n",
      "resetting env. episode reward total was -9.0. running mean: -8.72583277620961\n",
      "resetting env. episode reward total was -13.0. running mean: -8.768574448447515\n",
      "resetting env. episode reward total was -13.0. running mean: -8.810888703963041\n",
      "resetting env. episode reward total was 4.0. running mean: -8.68277981692341\n",
      "resetting env. episode reward total was -11.0. running mean: -8.705952018754177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -8.688892498566636\n",
      "resetting env. episode reward total was -9.0. running mean: -8.692003573580969\n",
      "resetting env. episode reward total was -6.0. running mean: -8.66508353784516\n",
      "resetting env. episode reward total was -11.0. running mean: -8.688432702466708\n",
      "resetting env. episode reward total was -5.0. running mean: -8.651548375442042\n",
      "resetting env. episode reward total was -10.0. running mean: -8.665032891687622\n",
      "resetting env. episode reward total was 7.0. running mean: -8.508382562770745\n",
      "resetting env. episode reward total was -7.0. running mean: -8.493298737143038\n",
      "resetting env. episode reward total was -5.0. running mean: -8.458365749771607\n",
      "resetting env. episode reward total was -10.0. running mean: -8.47378209227389\n",
      "resetting env. episode reward total was -12.0. running mean: -8.50904427135115\n",
      "resetting env. episode reward total was -8.0. running mean: -8.50395382863764\n",
      "resetting env. episode reward total was -7.0. running mean: -8.488914290351262\n",
      "resetting env. episode reward total was -1.0. running mean: -8.414025147447749\n",
      "resetting env. episode reward total was -10.0. running mean: -8.42988489597327\n",
      "resetting env. episode reward total was -9.0. running mean: -8.435586047013537\n",
      "resetting env. episode reward total was -15.0. running mean: -8.501230186543403\n",
      "resetting env. episode reward total was -11.0. running mean: -8.526217884677967\n",
      "resetting env. episode reward total was -6.0. running mean: -8.500955705831188\n",
      "resetting env. episode reward total was -4.0. running mean: -8.455946148772876\n",
      "resetting env. episode reward total was -14.0. running mean: -8.511386687285148\n",
      "resetting env. episode reward total was -5.0. running mean: -8.476272820412296\n",
      "resetting env. episode reward total was -3.0. running mean: -8.421510092208173\n",
      "resetting env. episode reward total was -1.0. running mean: -8.347294991286091\n",
      "resetting env. episode reward total was -9.0. running mean: -8.35382204137323\n",
      "resetting env. episode reward total was -14.0. running mean: -8.410283820959497\n",
      "resetting env. episode reward total was -5.0. running mean: -8.376180982749903\n",
      "resetting env. episode reward total was -9.0. running mean: -8.382419172922404\n",
      "resetting env. episode reward total was -7.0. running mean: -8.36859498119318\n",
      "resetting env. episode reward total was -5.0. running mean: -8.33490903138125\n",
      "resetting env. episode reward total was -9.0. running mean: -8.341559941067436\n",
      "resetting env. episode reward total was -5.0. running mean: -8.308144341656762\n",
      "resetting env. episode reward total was -11.0. running mean: -8.335062898240194\n",
      "resetting env. episode reward total was -7.0. running mean: -8.321712269257793\n",
      "resetting env. episode reward total was -3.0. running mean: -8.268495146565215\n",
      "resetting env. episode reward total was -9.0. running mean: -8.275810195099563\n",
      "resetting env. episode reward total was -7.0. running mean: -8.263052093148568\n",
      "resetting env. episode reward total was -13.0. running mean: -8.310421572217082\n",
      "resetting env. episode reward total was -11.0. running mean: -8.33731735649491\n",
      "resetting env. episode reward total was -4.0. running mean: -8.29394418292996\n",
      "resetting env. episode reward total was -13.0. running mean: -8.341004741100662\n",
      "resetting env. episode reward total was -5.0. running mean: -8.307594693689655\n",
      "resetting env. episode reward total was -9.0. running mean: -8.314518746752759\n",
      "resetting env. episode reward total was -11.0. running mean: -8.34137355928523\n",
      "resetting env. episode reward total was -2.0. running mean: -8.277959823692377\n",
      "resetting env. episode reward total was -10.0. running mean: -8.295180225455454\n",
      "resetting env. episode reward total was -9.0. running mean: -8.3022284232009\n",
      "resetting env. episode reward total was -8.0. running mean: -8.299206138968891\n",
      "resetting env. episode reward total was -4.0. running mean: -8.256214077579202\n",
      "resetting env. episode reward total was -4.0. running mean: -8.213651936803409\n",
      "resetting env. episode reward total was -5.0. running mean: -8.181515417435374\n",
      "resetting env. episode reward total was -8.0. running mean: -8.17970026326102\n",
      "resetting env. episode reward total was -12.0. running mean: -8.21790326062841\n",
      "resetting env. episode reward total was -6.0. running mean: -8.195724228022126\n",
      "resetting env. episode reward total was -7.0. running mean: -8.183766985741904\n",
      "resetting env. episode reward total was -10.0. running mean: -8.201929315884485\n",
      "resetting env. episode reward total was -5.0. running mean: -8.16991002272564\n",
      "resetting env. episode reward total was -5.0. running mean: -8.138210922498384\n",
      "resetting env. episode reward total was -5.0. running mean: -8.1068288132734\n",
      "resetting env. episode reward total was -7.0. running mean: -8.095760525140667\n",
      "resetting env. episode reward total was -8.0. running mean: -8.094802919889261\n",
      "resetting env. episode reward total was 1.0. running mean: -8.003854890690368\n",
      "resetting env. episode reward total was -14.0. running mean: -8.063816341783465\n",
      "resetting env. episode reward total was -11.0. running mean: -8.09317817836563\n",
      "resetting env. episode reward total was -7.0. running mean: -8.082246396581974\n",
      "resetting env. episode reward total was -8.0. running mean: -8.081423932616154\n",
      "resetting env. episode reward total was -12.0. running mean: -8.120609693289992\n",
      "resetting env. episode reward total was 5.0. running mean: -7.989403596357092\n",
      "resetting env. episode reward total was -1.0. running mean: -7.919509560393521\n",
      "resetting env. episode reward total was -9.0. running mean: -7.930314464789586\n",
      "resetting env. episode reward total was -13.0. running mean: -7.98101132014169\n",
      "resetting env. episode reward total was -13.0. running mean: -8.031201206940272\n",
      "resetting env. episode reward total was -11.0. running mean: -8.06088919487087\n",
      "resetting env. episode reward total was -7.0. running mean: -8.050280302922161\n",
      "resetting env. episode reward total was -9.0. running mean: -8.05977749989294\n",
      "resetting env. episode reward total was -7.0. running mean: -8.04917972489401\n",
      "resetting env. episode reward total was -7.0. running mean: -8.03868792764507\n",
      "resetting env. episode reward total was 1.0. running mean: -7.948301048368619\n",
      "resetting env. episode reward total was -1.0. running mean: -7.878818037884932\n",
      "resetting env. episode reward total was -7.0. running mean: -7.870029857506084\n",
      "resetting env. episode reward total was -1.0. running mean: -7.801329558931022\n",
      "resetting env. episode reward total was -12.0. running mean: -7.843316263341712\n",
      "resetting env. episode reward total was -4.0. running mean: -7.804883100708294\n",
      "resetting env. episode reward total was 3.0. running mean: -7.6968342697012115\n",
      "resetting env. episode reward total was -7.0. running mean: -7.6898659270042\n",
      "resetting env. episode reward total was -11.0. running mean: -7.722967267734158\n",
      "resetting env. episode reward total was -3.0. running mean: -7.675737595056817\n",
      "resetting env. episode reward total was 5.0. running mean: -7.548980219106249\n",
      "resetting env. episode reward total was -7.0. running mean: -7.543490416915187\n",
      "resetting env. episode reward total was 5.0. running mean: -7.418055512746036\n",
      "resetting env. episode reward total was -9.0. running mean: -7.433874957618575\n",
      "resetting env. episode reward total was -11.0. running mean: -7.469536208042389\n",
      "resetting env. episode reward total was -4.0. running mean: -7.434840845961966\n",
      "resetting env. episode reward total was -17.0. running mean: -7.530492437502346\n",
      "resetting env. episode reward total was -6.0. running mean: -7.515187513127322\n",
      "resetting env. episode reward total was -3.0. running mean: -7.470035637996049\n",
      "resetting env. episode reward total was -5.0. running mean: -7.445335281616089\n",
      "resetting env. episode reward total was -4.0. running mean: -7.4108819287999275\n",
      "resetting env. episode reward total was -15.0. running mean: -7.486773109511929\n",
      "resetting env. episode reward total was -13.0. running mean: -7.541905378416809\n",
      "resetting env. episode reward total was -3.0. running mean: -7.496486324632641\n",
      "resetting env. episode reward total was 8.0. running mean: -7.341521461386314\n",
      "resetting env. episode reward total was -11.0. running mean: -7.378106246772451\n",
      "resetting env. episode reward total was -1.0. running mean: -7.314325184304726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -10.0. running mean: -7.341181932461678\n",
      "resetting env. episode reward total was -5.0. running mean: -7.317770113137061\n",
      "resetting env. episode reward total was -5.0. running mean: -7.29459241200569\n",
      "resetting env. episode reward total was 10.0. running mean: -7.121646487885633\n",
      "resetting env. episode reward total was -2.0. running mean: -7.070430023006777\n",
      "resetting env. episode reward total was -4.0. running mean: -7.039725722776709\n",
      "resetting env. episode reward total was -6.0. running mean: -7.029328465548942\n",
      "resetting env. episode reward total was -9.0. running mean: -7.049035180893452\n",
      "resetting env. episode reward total was -8.0. running mean: -7.058544829084518\n",
      "resetting env. episode reward total was -8.0. running mean: -7.067959380793672\n",
      "resetting env. episode reward total was 8.0. running mean: -6.917279786985735\n",
      "resetting env. episode reward total was 1.0. running mean: -6.838106989115878\n",
      "resetting env. episode reward total was 3.0. running mean: -6.7397259192247185\n",
      "resetting env. episode reward total was -11.0. running mean: -6.782328660032472\n",
      "resetting env. episode reward total was -3.0. running mean: -6.744505373432148\n",
      "resetting env. episode reward total was -13.0. running mean: -6.807060319697826\n",
      "resetting env. episode reward total was -1.0. running mean: -6.748989716500848\n",
      "resetting env. episode reward total was -7.0. running mean: -6.75149981933584\n",
      "resetting env. episode reward total was -9.0. running mean: -6.773984821142482\n",
      "resetting env. episode reward total was -2.0. running mean: -6.726244972931056\n",
      "resetting env. episode reward total was -2.0. running mean: -6.678982523201745\n",
      "resetting env. episode reward total was -7.0. running mean: -6.682192697969727\n",
      "resetting env. episode reward total was -3.0. running mean: -6.64537077099003\n",
      "resetting env. episode reward total was -17.0. running mean: -6.748917063280129\n",
      "resetting env. episode reward total was -4.0. running mean: -6.721427892647328\n",
      "resetting env. episode reward total was -1.0. running mean: -6.664213613720855\n",
      "resetting env. episode reward total was -3.0. running mean: -6.627571477583646\n",
      "resetting env. episode reward total was -17.0. running mean: -6.731295762807809\n",
      "resetting env. episode reward total was -3.0. running mean: -6.693982805179731\n",
      "resetting env. episode reward total was -10.0. running mean: -6.727042977127933\n",
      "resetting env. episode reward total was 3.0. running mean: -6.629772547356653\n",
      "resetting env. episode reward total was -11.0. running mean: -6.6734748218830875\n",
      "resetting env. episode reward total was -9.0. running mean: -6.696740073664256\n",
      "resetting env. episode reward total was -9.0. running mean: -6.719772672927613\n",
      "resetting env. episode reward total was -7.0. running mean: -6.722574946198337\n",
      "resetting env. episode reward total was -8.0. running mean: -6.735349196736354\n",
      "resetting env. episode reward total was -1.0. running mean: -6.67799570476899\n",
      "resetting env. episode reward total was -6.0. running mean: -6.671215747721299\n",
      "resetting env. episode reward total was -10.0. running mean: -6.7045035902440855\n",
      "resetting env. episode reward total was 4.0. running mean: -6.597458554341644\n",
      "resetting env. episode reward total was -13.0. running mean: -6.661483968798228\n",
      "resetting env. episode reward total was -4.0. running mean: -6.634869129110245\n",
      "resetting env. episode reward total was -3.0. running mean: -6.598520437819143\n",
      "resetting env. episode reward total was -4.0. running mean: -6.572535233440952\n",
      "resetting env. episode reward total was 3.0. running mean: -6.476809881106543\n",
      "resetting env. episode reward total was -17.0. running mean: -6.5820417822954775\n",
      "resetting env. episode reward total was -15.0. running mean: -6.6662213644725234\n",
      "resetting env. episode reward total was -8.0. running mean: -6.6795591508277985\n",
      "resetting env. episode reward total was -17.0. running mean: -6.782763559319521\n",
      "resetting env. episode reward total was -5.0. running mean: -6.764935923726325\n",
      "resetting env. episode reward total was -1.0. running mean: -6.707286564489062\n",
      "resetting env. episode reward total was -11.0. running mean: -6.750213698844171\n",
      "resetting env. episode reward total was -4.0. running mean: -6.722711561855729\n",
      "resetting env. episode reward total was -9.0. running mean: -6.745484446237172\n",
      "resetting env. episode reward total was -6.0. running mean: -6.7380296017748\n",
      "resetting env. episode reward total was -9.0. running mean: -6.760649305757052\n",
      "resetting env. episode reward total was -3.0. running mean: -6.7230428126994815\n",
      "resetting env. episode reward total was 8.0. running mean: -6.575812384572487\n",
      "resetting env. episode reward total was -8.0. running mean: -6.590054260726762\n",
      "resetting env. episode reward total was -4.0. running mean: -6.564153718119495\n",
      "resetting env. episode reward total was -3.0. running mean: -6.5285121809383\n",
      "resetting env. episode reward total was -6.0. running mean: -6.523227059128916\n",
      "resetting env. episode reward total was 3.0. running mean: -6.427994788537627\n",
      "resetting env. episode reward total was -7.0. running mean: -6.433714840652251\n",
      "resetting env. episode reward total was -6.0. running mean: -6.429377692245728\n",
      "resetting env. episode reward total was -7.0. running mean: -6.435083915323271\n",
      "resetting env. episode reward total was -13.0. running mean: -6.500733076170039\n",
      "resetting env. episode reward total was -13.0. running mean: -6.565725745408338\n",
      "resetting env. episode reward total was 1.0. running mean: -6.490068487954255\n",
      "resetting env. episode reward total was -5.0. running mean: -6.4751678030747115\n",
      "resetting env. episode reward total was -15.0. running mean: -6.5604161250439645\n",
      "resetting env. episode reward total was -10.0. running mean: -6.594811963793524\n",
      "resetting env. episode reward total was -6.0. running mean: -6.588863844155588\n",
      "resetting env. episode reward total was -3.0. running mean: -6.5529752057140325\n",
      "resetting env. episode reward total was -6.0. running mean: -6.547445453656891\n",
      "resetting env. episode reward total was -11.0. running mean: -6.591970999120322\n",
      "resetting env. episode reward total was 4.0. running mean: -6.486051289129119\n",
      "resetting env. episode reward total was -13.0. running mean: -6.551190776237827\n",
      "resetting env. episode reward total was -1.0. running mean: -6.495678868475449\n",
      "resetting env. episode reward total was -7.0. running mean: -6.500722079790695\n",
      "resetting env. episode reward total was -1.0. running mean: -6.445714858992788\n",
      "resetting env. episode reward total was -1.0. running mean: -6.39125771040286\n",
      "resetting env. episode reward total was -11.0. running mean: -6.437345133298831\n",
      "resetting env. episode reward total was -10.0. running mean: -6.472971681965842\n",
      "resetting env. episode reward total was 2.0. running mean: -6.388241965146184\n",
      "resetting env. episode reward total was -7.0. running mean: -6.394359545494723\n",
      "resetting env. episode reward total was -3.0. running mean: -6.3604159500397754\n",
      "resetting env. episode reward total was -12.0. running mean: -6.416811790539378\n",
      "resetting env. episode reward total was -9.0. running mean: -6.442643672633984\n",
      "resetting env. episode reward total was -8.0. running mean: -6.458217235907645\n",
      "resetting env. episode reward total was 1.0. running mean: -6.383635063548568\n",
      "resetting env. episode reward total was -1.0. running mean: -6.329798712913083\n",
      "resetting env. episode reward total was -8.0. running mean: -6.346500725783952\n",
      "resetting env. episode reward total was -5.0. running mean: -6.333035718526112\n",
      "resetting env. episode reward total was -9.0. running mean: -6.3597053613408505\n",
      "resetting env. episode reward total was -11.0. running mean: -6.406108307727442\n",
      "resetting env. episode reward total was -13.0. running mean: -6.472047224650168\n",
      "resetting env. episode reward total was -13.0. running mean: -6.537326752403666\n",
      "resetting env. episode reward total was -1.0. running mean: -6.481953484879629\n",
      "resetting env. episode reward total was -13.0. running mean: -6.547133950030832\n",
      "resetting env. episode reward total was -13.0. running mean: -6.611662610530524\n",
      "resetting env. episode reward total was -10.0. running mean: -6.645545984425218\n",
      "resetting env. episode reward total was -1.0. running mean: -6.589090524580966\n",
      "resetting env. episode reward total was -7.0. running mean: -6.593199619335157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -6.597267623141805\n",
      "resetting env. episode reward total was -10.0. running mean: -6.631294946910387\n",
      "resetting env. episode reward total was -3.0. running mean: -6.594981997441283\n",
      "resetting env. episode reward total was -6.0. running mean: -6.58903217746687\n",
      "resetting env. episode reward total was -2.0. running mean: -6.543141855692201\n",
      "resetting env. episode reward total was -9.0. running mean: -6.567710437135279\n",
      "resetting env. episode reward total was -4.0. running mean: -6.542033332763927\n",
      "resetting env. episode reward total was -5.0. running mean: -6.526612999436287\n",
      "resetting env. episode reward total was -5.0. running mean: -6.511346869441923\n",
      "resetting env. episode reward total was -8.0. running mean: -6.526233400747504\n",
      "resetting env. episode reward total was -12.0. running mean: -6.580971066740029\n",
      "resetting env. episode reward total was -7.0. running mean: -6.585161356072629\n",
      "resetting env. episode reward total was -9.0. running mean: -6.609309742511903\n",
      "resetting env. episode reward total was -8.0. running mean: -6.623216645086784\n",
      "resetting env. episode reward total was -11.0. running mean: -6.666984478635917\n",
      "resetting env. episode reward total was -3.0. running mean: -6.630314633849558\n",
      "resetting env. episode reward total was 6.0. running mean: -6.504011487511063\n",
      "resetting env. episode reward total was -11.0. running mean: -6.548971372635952\n",
      "resetting env. episode reward total was -12.0. running mean: -6.603481658909593\n",
      "resetting env. episode reward total was -7.0. running mean: -6.607446842320497\n",
      "resetting env. episode reward total was -3.0. running mean: -6.571372373897293\n",
      "resetting env. episode reward total was 3.0. running mean: -6.475658650158319\n",
      "resetting env. episode reward total was -12.0. running mean: -6.530902063656736\n",
      "resetting env. episode reward total was -8.0. running mean: -6.545593043020169\n",
      "resetting env. episode reward total was -5.0. running mean: -6.530137112589967\n",
      "resetting env. episode reward total was 1.0. running mean: -6.454835741464068\n",
      "resetting env. episode reward total was -15.0. running mean: -6.540287384049428\n",
      "resetting env. episode reward total was -4.0. running mean: -6.514884510208934\n",
      "resetting env. episode reward total was -4.0. running mean: -6.489735665106845\n",
      "resetting env. episode reward total was -6.0. running mean: -6.4848383084557755\n",
      "resetting env. episode reward total was -6.0. running mean: -6.479989925371218\n",
      "resetting env. episode reward total was -4.0. running mean: -6.4551900261175055\n",
      "resetting env. episode reward total was -13.0. running mean: -6.520638125856331\n",
      "resetting env. episode reward total was -8.0. running mean: -6.535431744597767\n",
      "resetting env. episode reward total was -7.0. running mean: -6.54007742715179\n",
      "resetting env. episode reward total was -7.0. running mean: -6.544676652880272\n",
      "resetting env. episode reward total was -3.0. running mean: -6.509229886351469\n",
      "resetting env. episode reward total was 2.0. running mean: -6.424137587487955\n",
      "resetting env. episode reward total was -7.0. running mean: -6.429896211613076\n",
      "resetting env. episode reward total was -3.0. running mean: -6.395597249496945\n",
      "resetting env. episode reward total was -11.0. running mean: -6.441641277001976\n",
      "resetting env. episode reward total was -5.0. running mean: -6.427224864231956\n",
      "resetting env. episode reward total was -11.0. running mean: -6.472952615589636\n",
      "resetting env. episode reward total was -11.0. running mean: -6.51822308943374\n",
      "resetting env. episode reward total was 3.0. running mean: -6.4230408585394025\n",
      "resetting env. episode reward total was -11.0. running mean: -6.468810449954009\n",
      "resetting env. episode reward total was -18.0. running mean: -6.584122345454468\n",
      "resetting env. episode reward total was -11.0. running mean: -6.628281121999924\n",
      "resetting env. episode reward total was -6.0. running mean: -6.621998310779925\n",
      "resetting env. episode reward total was -10.0. running mean: -6.655778327672126\n",
      "resetting env. episode reward total was -9.0. running mean: -6.679220544395404\n",
      "resetting env. episode reward total was -12.0. running mean: -6.7324283389514505\n",
      "resetting env. episode reward total was -9.0. running mean: -6.755104055561936\n",
      "resetting env. episode reward total was 2.0. running mean: -6.667553015006317\n",
      "resetting env. episode reward total was -7.0. running mean: -6.670877484856254\n",
      "resetting env. episode reward total was -12.0. running mean: -6.7241687100076915\n",
      "resetting env. episode reward total was -3.0. running mean: -6.686927022907614\n",
      "resetting env. episode reward total was -11.0. running mean: -6.730057752678539\n",
      "resetting env. episode reward total was -11.0. running mean: -6.772757175151753\n",
      "resetting env. episode reward total was -13.0. running mean: -6.835029603400235\n",
      "resetting env. episode reward total was -7.0. running mean: -6.836679307366233\n",
      "resetting env. episode reward total was -3.0. running mean: -6.798312514292571\n",
      "resetting env. episode reward total was -11.0. running mean: -6.8403293891496455\n",
      "resetting env. episode reward total was -7.0. running mean: -6.841926095258149\n",
      "resetting env. episode reward total was -9.0. running mean: -6.863506834305567\n",
      "resetting env. episode reward total was -3.0. running mean: -6.824871765962511\n",
      "resetting env. episode reward total was -12.0. running mean: -6.876623048302886\n",
      "resetting env. episode reward total was -9.0. running mean: -6.897856817819856\n",
      "resetting env. episode reward total was 4.0. running mean: -6.788878249641658\n",
      "resetting env. episode reward total was -7.0. running mean: -6.790989467145241\n",
      "resetting env. episode reward total was -9.0. running mean: -6.8130795724737885\n",
      "resetting env. episode reward total was 5.0. running mean: -6.694948776749051\n",
      "resetting env. episode reward total was -6.0. running mean: -6.68799928898156\n",
      "resetting env. episode reward total was 2.0. running mean: -6.601119296091745\n",
      "resetting env. episode reward total was -14.0. running mean: -6.675108103130827\n",
      "resetting env. episode reward total was -5.0. running mean: -6.658357022099519\n",
      "resetting env. episode reward total was -4.0. running mean: -6.631773451878524\n",
      "resetting env. episode reward total was -4.0. running mean: -6.605455717359739\n",
      "resetting env. episode reward total was -5.0. running mean: -6.589401160186141\n",
      "resetting env. episode reward total was -5.0. running mean: -6.573507148584279\n",
      "resetting env. episode reward total was -5.0. running mean: -6.557772077098436\n",
      "resetting env. episode reward total was -2.0. running mean: -6.512194356327451\n",
      "resetting env. episode reward total was -5.0. running mean: -6.497072412764177\n",
      "resetting env. episode reward total was -6.0. running mean: -6.492101688636534\n",
      "resetting env. episode reward total was -7.0. running mean: -6.4971806717501694\n",
      "resetting env. episode reward total was -1.0. running mean: -6.442208865032668\n",
      "resetting env. episode reward total was -9.0. running mean: -6.467786776382341\n",
      "resetting env. episode reward total was 3.0. running mean: -6.3731089086185175\n",
      "resetting env. episode reward total was -6.0. running mean: -6.369377819532332\n",
      "resetting env. episode reward total was -11.0. running mean: -6.415684041337009\n",
      "resetting env. episode reward total was -11.0. running mean: -6.461527200923639\n",
      "resetting env. episode reward total was -3.0. running mean: -6.426911928914403\n",
      "resetting env. episode reward total was -4.0. running mean: -6.402642809625259\n",
      "resetting env. episode reward total was -14.0. running mean: -6.478616381529005\n",
      "resetting env. episode reward total was -4.0. running mean: -6.4538302177137155\n",
      "resetting env. episode reward total was -9.0. running mean: -6.479291915536578\n",
      "resetting env. episode reward total was 3.0. running mean: -6.384498996381212\n",
      "resetting env. episode reward total was -13.0. running mean: -6.4506540064174\n",
      "resetting env. episode reward total was -6.0. running mean: -6.446147466353225\n",
      "resetting env. episode reward total was -4.0. running mean: -6.421685991689693\n",
      "resetting env. episode reward total was -2.0. running mean: -6.377469131772796\n",
      "resetting env. episode reward total was -10.0. running mean: -6.4136944404550675\n",
      "resetting env. episode reward total was -5.0. running mean: -6.399557496050517\n",
      "resetting env. episode reward total was -8.0. running mean: -6.415561921090012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -12.0. running mean: -6.471406301879112\n",
      "resetting env. episode reward total was -7.0. running mean: -6.476692238860321\n",
      "resetting env. episode reward total was -6.0. running mean: -6.471925316471717\n",
      "resetting env. episode reward total was -4.0. running mean: -6.447206063307\n",
      "resetting env. episode reward total was 2.0. running mean: -6.36273400267393\n",
      "resetting env. episode reward total was 1.0. running mean: -6.289106662647191\n",
      "resetting env. episode reward total was -9.0. running mean: -6.316215596020719\n",
      "resetting env. episode reward total was -2.0. running mean: -6.273053440060511\n",
      "resetting env. episode reward total was -4.0. running mean: -6.250322905659906\n",
      "resetting env. episode reward total was -16.0. running mean: -6.347819676603307\n",
      "resetting env. episode reward total was -3.0. running mean: -6.314341479837275\n",
      "resetting env. episode reward total was -9.0. running mean: -6.341198065038902\n",
      "resetting env. episode reward total was -3.0. running mean: -6.307786084388513\n",
      "resetting env. episode reward total was -9.0. running mean: -6.334708223544628\n",
      "resetting env. episode reward total was -8.0. running mean: -6.351361141309182\n",
      "resetting env. episode reward total was -6.0. running mean: -6.3478475298960895\n",
      "resetting env. episode reward total was -2.0. running mean: -6.304369054597128\n",
      "resetting env. episode reward total was -4.0. running mean: -6.281325364051157\n",
      "resetting env. episode reward total was -12.0. running mean: -6.338512110410646\n",
      "resetting env. episode reward total was -9.0. running mean: -6.365126989306539\n",
      "resetting env. episode reward total was -4.0. running mean: -6.341475719413474\n",
      "resetting env. episode reward total was -5.0. running mean: -6.328060962219339\n",
      "resetting env. episode reward total was -1.0. running mean: -6.274780352597145\n",
      "resetting env. episode reward total was -8.0. running mean: -6.292032549071173\n",
      "resetting env. episode reward total was -15.0. running mean: -6.379112223580462\n",
      "resetting env. episode reward total was -8.0. running mean: -6.395321101344657\n",
      "resetting env. episode reward total was -17.0. running mean: -6.501367890331211\n",
      "resetting env. episode reward total was -3.0. running mean: -6.466354211427899\n",
      "resetting env. episode reward total was -10.0. running mean: -6.50169066931362\n",
      "resetting env. episode reward total was -15.0. running mean: -6.586673762620483\n",
      "resetting env. episode reward total was 4.0. running mean: -6.480807024994278\n",
      "resetting env. episode reward total was -3.0. running mean: -6.4459989547443355\n",
      "resetting env. episode reward total was -7.0. running mean: -6.451538965196892\n",
      "resetting env. episode reward total was 5.0. running mean: -6.337023575544924\n",
      "resetting env. episode reward total was -11.0. running mean: -6.3836533397894755\n",
      "resetting env. episode reward total was -7.0. running mean: -6.389816806391581\n",
      "resetting env. episode reward total was -2.0. running mean: -6.345918638327665\n",
      "resetting env. episode reward total was 8.0. running mean: -6.202459451944388\n",
      "resetting env. episode reward total was -9.0. running mean: -6.230434857424944\n",
      "resetting env. episode reward total was -5.0. running mean: -6.218130508850694\n",
      "resetting env. episode reward total was -13.0. running mean: -6.285949203762187\n",
      "resetting env. episode reward total was 4.0. running mean: -6.183089711724565\n",
      "resetting env. episode reward total was 7.0. running mean: -6.051258814607319\n",
      "resetting env. episode reward total was -10.0. running mean: -6.0907462264612455\n",
      "resetting env. episode reward total was 1.0. running mean: -6.019838764196633\n",
      "resetting env. episode reward total was -3.0. running mean: -5.989640376554667\n",
      "resetting env. episode reward total was -7.0. running mean: -5.999743972789121\n",
      "resetting env. episode reward total was -1.0. running mean: -5.949746533061229\n",
      "resetting env. episode reward total was -4.0. running mean: -5.9302490677306166\n",
      "resetting env. episode reward total was -9.0. running mean: -5.96094657705331\n",
      "resetting env. episode reward total was -5.0. running mean: -5.951337111282776\n",
      "resetting env. episode reward total was -3.0. running mean: -5.921823740169949\n",
      "resetting env. episode reward total was -4.0. running mean: -5.90260550276825\n",
      "resetting env. episode reward total was -6.0. running mean: -5.903579447740567\n",
      "resetting env. episode reward total was -7.0. running mean: -5.914543653263162\n",
      "resetting env. episode reward total was -10.0. running mean: -5.95539821673053\n",
      "resetting env. episode reward total was -13.0. running mean: -6.025844234563225\n",
      "resetting env. episode reward total was -7.0. running mean: -6.035585792217593\n",
      "resetting env. episode reward total was -12.0. running mean: -6.095229934295417\n",
      "resetting env. episode reward total was -11.0. running mean: -6.144277634952463\n",
      "resetting env. episode reward total was -7.0. running mean: -6.152834858602938\n",
      "resetting env. episode reward total was -5.0. running mean: -6.141306510016909\n",
      "resetting env. episode reward total was -2.0. running mean: -6.09989344491674\n",
      "resetting env. episode reward total was -8.0. running mean: -6.118894510467572\n",
      "resetting env. episode reward total was -5.0. running mean: -6.107705565362896\n",
      "resetting env. episode reward total was -4.0. running mean: -6.086628509709267\n",
      "resetting env. episode reward total was -4.0. running mean: -6.0657622246121745\n",
      "resetting env. episode reward total was -6.0. running mean: -6.065104602366052\n",
      "resetting env. episode reward total was -9.0. running mean: -6.094453556342391\n",
      "resetting env. episode reward total was -13.0. running mean: -6.163509020778967\n",
      "resetting env. episode reward total was -11.0. running mean: -6.211873930571178\n",
      "resetting env. episode reward total was 5.0. running mean: -6.099755191265467\n",
      "resetting env. episode reward total was 6.0. running mean: -5.978757639352812\n",
      "resetting env. episode reward total was -9.0. running mean: -6.008970062959284\n",
      "resetting env. episode reward total was 7.0. running mean: -5.87888036232969\n",
      "resetting env. episode reward total was -5.0. running mean: -5.8700915587063935\n",
      "resetting env. episode reward total was -9.0. running mean: -5.9013906431193295\n",
      "resetting env. episode reward total was -4.0. running mean: -5.882376736688136\n",
      "resetting env. episode reward total was -1.0. running mean: -5.8335529693212544\n",
      "resetting env. episode reward total was -3.0. running mean: -5.805217439628042\n",
      "resetting env. episode reward total was -11.0. running mean: -5.857165265231762\n",
      "resetting env. episode reward total was -11.0. running mean: -5.908593612579445\n",
      "resetting env. episode reward total was -2.0. running mean: -5.86950767645365\n",
      "resetting env. episode reward total was 5.0. running mean: -5.760812599689114\n",
      "resetting env. episode reward total was -13.0. running mean: -5.833204473692223\n",
      "resetting env. episode reward total was -13.0. running mean: -5.9048724289553\n",
      "resetting env. episode reward total was -7.0. running mean: -5.915823704665747\n",
      "resetting env. episode reward total was -5.0. running mean: -5.906665467619089\n",
      "resetting env. episode reward total was -1.0. running mean: -5.857598812942897\n",
      "resetting env. episode reward total was 3.0. running mean: -5.769022824813468\n",
      "resetting env. episode reward total was -5.0. running mean: -5.761332596565333\n",
      "resetting env. episode reward total was -9.0. running mean: -5.793719270599679\n",
      "resetting env. episode reward total was -11.0. running mean: -5.845782077893682\n",
      "resetting env. episode reward total was -6.0. running mean: -5.847324257114745\n",
      "resetting env. episode reward total was -1.0. running mean: -5.798851014543597\n",
      "resetting env. episode reward total was -5.0. running mean: -5.790862504398161\n",
      "resetting env. episode reward total was -2.0. running mean: -5.7529538793541795\n",
      "resetting env. episode reward total was -11.0. running mean: -5.805424340560638\n",
      "resetting env. episode reward total was 4.0. running mean: -5.707370097155032\n",
      "resetting env. episode reward total was -5.0. running mean: -5.700296396183481\n",
      "resetting env. episode reward total was -6.0. running mean: -5.703293432221646\n",
      "resetting env. episode reward total was -2.0. running mean: -5.6662604978994295\n",
      "resetting env. episode reward total was -1.0. running mean: -5.619597892920435\n",
      "resetting env. episode reward total was -8.0. running mean: -5.643401913991231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: -5.546967894851319\n",
      "resetting env. episode reward total was 2.0. running mean: -5.471498215902806\n",
      "resetting env. episode reward total was -11.0. running mean: -5.526783233743778\n",
      "resetting env. episode reward total was -7.0. running mean: -5.541515401406341\n",
      "resetting env. episode reward total was -8.0. running mean: -5.566100247392277\n",
      "resetting env. episode reward total was -11.0. running mean: -5.620439244918354\n",
      "resetting env. episode reward total was -3.0. running mean: -5.594234852469171\n",
      "resetting env. episode reward total was 2.0. running mean: -5.51829250394448\n",
      "resetting env. episode reward total was -7.0. running mean: -5.5331095789050355\n",
      "resetting env. episode reward total was -8.0. running mean: -5.557778483115985\n",
      "resetting env. episode reward total was -7.0. running mean: -5.572200698284826\n",
      "resetting env. episode reward total was -10.0. running mean: -5.616478691301977\n",
      "resetting env. episode reward total was -3.0. running mean: -5.590313904388958\n",
      "resetting env. episode reward total was -6.0. running mean: -5.594410765345067\n",
      "resetting env. episode reward total was -7.0. running mean: -5.608466657691617\n",
      "resetting env. episode reward total was -9.0. running mean: -5.6423819911147\n",
      "resetting env. episode reward total was -9.0. running mean: -5.675958171203553\n",
      "resetting env. episode reward total was -15.0. running mean: -5.769198589491518\n",
      "resetting env. episode reward total was 2.0. running mean: -5.691506603596603\n",
      "resetting env. episode reward total was -12.0. running mean: -5.754591537560637\n",
      "resetting env. episode reward total was -8.0. running mean: -5.777045622185031\n",
      "resetting env. episode reward total was -7.0. running mean: -5.789275165963181\n",
      "resetting env. episode reward total was -11.0. running mean: -5.841382414303549\n",
      "resetting env. episode reward total was -3.0. running mean: -5.812968590160514\n",
      "resetting env. episode reward total was -9.0. running mean: -5.844838904258909\n",
      "resetting env. episode reward total was -5.0. running mean: -5.836390515216319\n",
      "resetting env. episode reward total was -15.0. running mean: -5.9280266100641565\n",
      "resetting env. episode reward total was -6.0. running mean: -5.928746343963515\n",
      "resetting env. episode reward total was 6.0. running mean: -5.80945888052388\n",
      "resetting env. episode reward total was 2.0. running mean: -5.731364291718641\n",
      "resetting env. episode reward total was -5.0. running mean: -5.724050648801454\n",
      "resetting env. episode reward total was -3.0. running mean: -5.69681014231344\n",
      "resetting env. episode reward total was -3.0. running mean: -5.669842040890306\n",
      "resetting env. episode reward total was -16.0. running mean: -5.773143620481403\n",
      "resetting env. episode reward total was -13.0. running mean: -5.845412184276589\n",
      "resetting env. episode reward total was -9.0. running mean: -5.876958062433823\n",
      "resetting env. episode reward total was -15.0. running mean: -5.968188481809484\n",
      "resetting env. episode reward total was 3.0. running mean: -5.878506596991389\n",
      "resetting env. episode reward total was -3.0. running mean: -5.849721531021475\n",
      "resetting env. episode reward total was -12.0. running mean: -5.9112243157112605\n",
      "resetting env. episode reward total was -6.0. running mean: -5.912112072554147\n",
      "resetting env. episode reward total was -2.0. running mean: -5.872990951828605\n",
      "resetting env. episode reward total was -9.0. running mean: -5.904261042310319\n",
      "resetting env. episode reward total was 2.0. running mean: -5.825218431887216\n",
      "resetting env. episode reward total was -3.0. running mean: -5.796966247568344\n",
      "resetting env. episode reward total was -6.0. running mean: -5.79899658509266\n",
      "resetting env. episode reward total was 14.0. running mean: -5.601006619241734\n",
      "resetting env. episode reward total was -13.0. running mean: -5.674996553049317\n",
      "resetting env. episode reward total was 1.0. running mean: -5.608246587518824\n",
      "resetting env. episode reward total was -1.0. running mean: -5.562164121643636\n",
      "resetting env. episode reward total was -17.0. running mean: -5.676542480427199\n",
      "resetting env. episode reward total was -3.0. running mean: -5.649777055622927\n",
      "resetting env. episode reward total was 7.0. running mean: -5.523279285066697\n",
      "resetting env. episode reward total was -5.0. running mean: -5.51804649221603\n",
      "resetting env. episode reward total was -6.0. running mean: -5.522866027293869\n",
      "resetting env. episode reward total was -8.0. running mean: -5.54763736702093\n",
      "resetting env. episode reward total was 9.0. running mean: -5.402160993350721\n",
      "resetting env. episode reward total was -13.0. running mean: -5.478139383417214\n",
      "resetting env. episode reward total was -7.0. running mean: -5.493357989583042\n",
      "resetting env. episode reward total was 5.0. running mean: -5.388424409687212\n",
      "resetting env. episode reward total was -7.0. running mean: -5.40454016559034\n",
      "resetting env. episode reward total was 3.0. running mean: -5.320494763934436\n",
      "resetting env. episode reward total was -2.0. running mean: -5.2872898162950905\n",
      "resetting env. episode reward total was -2.0. running mean: -5.254416918132139\n",
      "resetting env. episode reward total was -12.0. running mean: -5.321872748950818\n",
      "resetting env. episode reward total was -8.0. running mean: -5.34865402146131\n",
      "resetting env. episode reward total was -9.0. running mean: -5.385167481246697\n",
      "resetting env. episode reward total was -17.0. running mean: -5.50131580643423\n",
      "resetting env. episode reward total was -14.0. running mean: -5.5863026483698865\n",
      "resetting env. episode reward total was -4.0. running mean: -5.570439621886187\n",
      "resetting env. episode reward total was 4.0. running mean: -5.474735225667326\n",
      "resetting env. episode reward total was -11.0. running mean: -5.5299878734106525\n",
      "resetting env. episode reward total was -9.0. running mean: -5.564687994676546\n",
      "resetting env. episode reward total was -4.0. running mean: -5.54904111472978\n",
      "resetting env. episode reward total was -6.0. running mean: -5.553550703582482\n",
      "resetting env. episode reward total was 7.0. running mean: -5.4280151965466565\n",
      "resetting env. episode reward total was -9.0. running mean: -5.46373504458119\n",
      "resetting env. episode reward total was -11.0. running mean: -5.519097694135379\n",
      "resetting env. episode reward total was -7.0. running mean: -5.533906717194025\n",
      "resetting env. episode reward total was -13.0. running mean: -5.608567650022085\n",
      "resetting env. episode reward total was -9.0. running mean: -5.642481973521864\n",
      "resetting env. episode reward total was -7.0. running mean: -5.656057153786645\n",
      "resetting env. episode reward total was 1.0. running mean: -5.589496582248779\n",
      "resetting env. episode reward total was -4.0. running mean: -5.573601616426291\n",
      "resetting env. episode reward total was -16.0. running mean: -5.677865600262028\n",
      "resetting env. episode reward total was 1.0. running mean: -5.611086944259408\n",
      "resetting env. episode reward total was 6.0. running mean: -5.494976074816814\n",
      "resetting env. episode reward total was -1.0. running mean: -5.450026314068646\n",
      "resetting env. episode reward total was -3.0. running mean: -5.42552605092796\n",
      "resetting env. episode reward total was -7.0. running mean: -5.441270790418681\n",
      "resetting env. episode reward total was -8.0. running mean: -5.466858082514494\n",
      "resetting env. episode reward total was -4.0. running mean: -5.452189501689349\n",
      "resetting env. episode reward total was -7.0. running mean: -5.467667606672456\n",
      "resetting env. episode reward total was -1.0. running mean: -5.422990930605731\n",
      "resetting env. episode reward total was -3.0. running mean: -5.3987610212996735\n",
      "resetting env. episode reward total was -6.0. running mean: -5.404773411086676\n",
      "resetting env. episode reward total was 1.0. running mean: -5.34072567697581\n",
      "resetting env. episode reward total was 3.0. running mean: -5.257318420206051\n",
      "resetting env. episode reward total was -1.0. running mean: -5.21474523600399\n",
      "resetting env. episode reward total was -2.0. running mean: -5.18259778364395\n",
      "resetting env. episode reward total was -11.0. running mean: -5.240771805807511\n",
      "resetting env. episode reward total was -4.0. running mean: -5.228364087749436\n",
      "resetting env. episode reward total was -12.0. running mean: -5.296080446871942\n",
      "resetting env. episode reward total was -11.0. running mean: -5.353119642403223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: -5.3395884459791905\n",
      "resetting env. episode reward total was 7.0. running mean: -5.2161925615193985\n",
      "resetting env. episode reward total was 6.0. running mean: -5.104030635904205\n",
      "resetting env. episode reward total was -9.0. running mean: -5.142990329545163\n",
      "resetting env. episode reward total was 3.0. running mean: -5.061560426249711\n",
      "resetting env. episode reward total was -10.0. running mean: -5.110944821987213\n",
      "resetting env. episode reward total was -5.0. running mean: -5.109835373767341\n",
      "resetting env. episode reward total was -5.0. running mean: -5.108737020029667\n",
      "resetting env. episode reward total was 5.0. running mean: -5.0076496498293706\n",
      "resetting env. episode reward total was 10.0. running mean: -4.857573153331077\n",
      "resetting env. episode reward total was -7.0. running mean: -4.8789974217977665\n",
      "resetting env. episode reward total was -7.0. running mean: -4.900207447579789\n",
      "resetting env. episode reward total was -4.0. running mean: -4.8912053731039915\n",
      "resetting env. episode reward total was -13.0. running mean: -4.972293319372952\n",
      "resetting env. episode reward total was -3.0. running mean: -4.9525703861792225\n",
      "resetting env. episode reward total was -7.0. running mean: -4.973044682317431\n",
      "resetting env. episode reward total was -9.0. running mean: -5.013314235494256\n",
      "resetting env. episode reward total was -13.0. running mean: -5.0931810931393136\n",
      "resetting env. episode reward total was -10.0. running mean: -5.14224928220792\n",
      "resetting env. episode reward total was -7.0. running mean: -5.16082678938584\n",
      "resetting env. episode reward total was -5.0. running mean: -5.159218521491982\n",
      "resetting env. episode reward total was -6.0. running mean: -5.167626336277062\n",
      "resetting env. episode reward total was 3.0. running mean: -5.085950072914291\n",
      "resetting env. episode reward total was -3.0. running mean: -5.065090572185149\n",
      "resetting env. episode reward total was -11.0. running mean: -5.124439666463298\n",
      "resetting env. episode reward total was 2.0. running mean: -5.053195269798665\n",
      "resetting env. episode reward total was -10.0. running mean: -5.102663317100678\n",
      "resetting env. episode reward total was -11.0. running mean: -5.161636683929672\n",
      "resetting env. episode reward total was -1.0. running mean: -5.120020317090375\n",
      "resetting env. episode reward total was 4.0. running mean: -5.028820113919471\n",
      "resetting env. episode reward total was -6.0. running mean: -5.038531912780275\n",
      "resetting env. episode reward total was -13.0. running mean: -5.118146593652472\n",
      "resetting env. episode reward total was -7.0. running mean: -5.136965127715948\n",
      "resetting env. episode reward total was 6.0. running mean: -5.025595476438789\n",
      "resetting env. episode reward total was -6.0. running mean: -5.0353395216744\n",
      "resetting env. episode reward total was -8.0. running mean: -5.064986126457656\n",
      "resetting env. episode reward total was -7.0. running mean: -5.0843362651930795\n",
      "resetting env. episode reward total was -4.0. running mean: -5.073492902541148\n",
      "resetting env. episode reward total was -10.0. running mean: -5.1227579735157365\n",
      "resetting env. episode reward total was 7.0. running mean: -5.001530393780579\n",
      "resetting env. episode reward total was -11.0. running mean: -5.061515089842773\n",
      "resetting env. episode reward total was -9.0. running mean: -5.1008999389443455\n",
      "resetting env. episode reward total was -3.0. running mean: -5.079890939554902\n",
      "resetting env. episode reward total was -8.0. running mean: -5.109092030159353\n",
      "resetting env. episode reward total was 6.0. running mean: -4.99800110985776\n",
      "resetting env. episode reward total was -11.0. running mean: -5.058021098759182\n",
      "resetting env. episode reward total was -3.0. running mean: -5.037440887771591\n",
      "resetting env. episode reward total was -3.0. running mean: -5.017066478893875\n",
      "resetting env. episode reward total was -3.0. running mean: -4.996895814104936\n",
      "resetting env. episode reward total was -15.0. running mean: -5.096926855963887\n",
      "resetting env. episode reward total was -7.0. running mean: -5.115957587404249\n",
      "resetting env. episode reward total was 3.0. running mean: -5.034798011530206\n",
      "resetting env. episode reward total was -9.0. running mean: -5.074450031414903\n",
      "resetting env. episode reward total was 1.0. running mean: -5.013705531100754\n",
      "resetting env. episode reward total was -8.0. running mean: -5.043568475789747\n",
      "resetting env. episode reward total was -12.0. running mean: -5.113132791031849\n",
      "resetting env. episode reward total was 13.0. running mean: -4.932001463121531\n",
      "resetting env. episode reward total was 2.0. running mean: -4.862681448490316\n",
      "resetting env. episode reward total was 2.0. running mean: -4.7940546340054135\n",
      "resetting env. episode reward total was -10.0. running mean: -4.8461140876653594\n",
      "resetting env. episode reward total was -19.0. running mean: -4.987652946788706\n",
      "resetting env. episode reward total was -7.0. running mean: -5.0077764173208195\n",
      "resetting env. episode reward total was -4.0. running mean: -4.997698653147611\n",
      "resetting env. episode reward total was -3.0. running mean: -4.9777216666161355\n",
      "resetting env. episode reward total was 5.0. running mean: -4.8779444499499744\n",
      "resetting env. episode reward total was -9.0. running mean: -4.919165005450474\n",
      "resetting env. episode reward total was -3.0. running mean: -4.89997335539597\n",
      "resetting env. episode reward total was 6.0. running mean: -4.79097362184201\n",
      "resetting env. episode reward total was -16.0. running mean: -4.90306388562359\n",
      "resetting env. episode reward total was 5.0. running mean: -4.8040332467673545\n",
      "resetting env. episode reward total was -4.0. running mean: -4.795992914299681\n",
      "resetting env. episode reward total was -8.0. running mean: -4.8280329851566846\n",
      "resetting env. episode reward total was -11.0. running mean: -4.889752655305118\n",
      "resetting env. episode reward total was -17.0. running mean: -5.010855128752067\n",
      "resetting env. episode reward total was -3.0. running mean: -4.990746577464547\n",
      "resetting env. episode reward total was -13.0. running mean: -5.070839111689901\n",
      "resetting env. episode reward total was -4.0. running mean: -5.060130720573002\n",
      "resetting env. episode reward total was -10.0. running mean: -5.109529413367272\n",
      "resetting env. episode reward total was -4.0. running mean: -5.098434119233599\n",
      "resetting env. episode reward total was -4.0. running mean: -5.087449778041263\n",
      "resetting env. episode reward total was 3.0. running mean: -5.00657528026085\n",
      "resetting env. episode reward total was -4.0. running mean: -4.996509527458241\n",
      "resetting env. episode reward total was 2.0. running mean: -4.926544432183659\n",
      "resetting env. episode reward total was -9.0. running mean: -4.967278987861823\n",
      "resetting env. episode reward total was -4.0. running mean: -4.957606197983204\n",
      "resetting env. episode reward total was -13.0. running mean: -5.038030136003372\n",
      "resetting env. episode reward total was -6.0. running mean: -5.047649834643338\n",
      "resetting env. episode reward total was -2.0. running mean: -5.017173336296905\n",
      "resetting env. episode reward total was -12.0. running mean: -5.0870016029339356\n",
      "resetting env. episode reward total was 5.0. running mean: -4.986131586904596\n",
      "resetting env. episode reward total was -5.0. running mean: -4.98627027103555\n",
      "resetting env. episode reward total was -12.0. running mean: -5.056407568325194\n",
      "resetting env. episode reward total was -9.0. running mean: -5.095843492641942\n",
      "resetting env. episode reward total was -5.0. running mean: -5.094885057715522\n",
      "resetting env. episode reward total was -1.0. running mean: -5.053936207138366\n",
      "resetting env. episode reward total was -7.0. running mean: -5.073396845066982\n",
      "resetting env. episode reward total was -9.0. running mean: -5.112662876616312\n",
      "resetting env. episode reward total was 6.0. running mean: -5.001536247850149\n",
      "resetting env. episode reward total was 3.0. running mean: -4.921520885371647\n",
      "resetting env. episode reward total was -8.0. running mean: -4.9523056765179305\n",
      "resetting env. episode reward total was -5.0. running mean: -4.952782619752751\n",
      "resetting env. episode reward total was -1.0. running mean: -4.9132547935552235\n",
      "resetting env. episode reward total was -5.0. running mean: -4.914122245619671\n",
      "resetting env. episode reward total was 10.0. running mean: -4.764981023163474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: -4.76733121293184\n",
      "resetting env. episode reward total was 6.0. running mean: -4.659657900802522\n",
      "resetting env. episode reward total was -2.0. running mean: -4.633061321794496\n",
      "resetting env. episode reward total was -3.0. running mean: -4.616730708576551\n",
      "resetting env. episode reward total was -2.0. running mean: -4.590563401490785\n",
      "resetting env. episode reward total was -5.0. running mean: -4.594657767475877\n",
      "resetting env. episode reward total was -4.0. running mean: -4.588711189801119\n",
      "resetting env. episode reward total was -8.0. running mean: -4.622824077903108\n",
      "resetting env. episode reward total was -4.0. running mean: -4.616595837124076\n",
      "resetting env. episode reward total was -2.0. running mean: -4.590429878752835\n",
      "resetting env. episode reward total was -12.0. running mean: -4.664525579965307\n",
      "resetting env. episode reward total was -4.0. running mean: -4.657880324165654\n",
      "resetting env. episode reward total was -6.0. running mean: -4.671301520923997\n",
      "resetting env. episode reward total was -17.0. running mean: -4.794588505714757\n",
      "resetting env. episode reward total was 14.0. running mean: -4.60664262065761\n",
      "resetting env. episode reward total was -5.0. running mean: -4.610576194451033\n",
      "resetting env. episode reward total was -3.0. running mean: -4.594470432506523\n",
      "resetting env. episode reward total was -4.0. running mean: -4.588525728181458\n",
      "resetting env. episode reward total was -6.0. running mean: -4.602640470899643\n",
      "resetting env. episode reward total was -1.0. running mean: -4.566614066190646\n",
      "resetting env. episode reward total was -9.0. running mean: -4.610947925528739\n",
      "resetting env. episode reward total was 7.0. running mean: -4.494838446273452\n",
      "resetting env. episode reward total was -1.0. running mean: -4.459890061810717\n",
      "resetting env. episode reward total was -3.0. running mean: -4.4452911611926105\n",
      "resetting env. episode reward total was 9.0. running mean: -4.3108382495806845\n",
      "resetting env. episode reward total was -6.0. running mean: -4.327729867084877\n",
      "resetting env. episode reward total was -3.0. running mean: -4.314452568414029\n",
      "resetting env. episode reward total was 1.0. running mean: -4.261308042729889\n",
      "resetting env. episode reward total was -6.0. running mean: -4.278694962302589\n",
      "resetting env. episode reward total was -12.0. running mean: -4.3559080126795635\n",
      "resetting env. episode reward total was -1.0. running mean: -4.322348932552767\n",
      "resetting env. episode reward total was -2.0. running mean: -4.299125443227239\n",
      "resetting env. episode reward total was -6.0. running mean: -4.316134188794966\n",
      "resetting env. episode reward total was -16.0. running mean: -4.432972846907017\n",
      "resetting env. episode reward total was -8.0. running mean: -4.468643118437947\n",
      "resetting env. episode reward total was -11.0. running mean: -4.533956687253568\n",
      "resetting env. episode reward total was -11.0. running mean: -4.598617120381032\n",
      "resetting env. episode reward total was 4.0. running mean: -4.512630949177222\n",
      "resetting env. episode reward total was -11.0. running mean: -4.57750463968545\n",
      "resetting env. episode reward total was 9.0. running mean: -4.441729593288596\n",
      "resetting env. episode reward total was -1.0. running mean: -4.407312297355709\n",
      "resetting env. episode reward total was 3.0. running mean: -4.333239174382152\n",
      "resetting env. episode reward total was 2.0. running mean: -4.269906782638331\n",
      "resetting env. episode reward total was -7.0. running mean: -4.297207714811948\n",
      "resetting env. episode reward total was 3.0. running mean: -4.224235637663828\n",
      "resetting env. episode reward total was 4.0. running mean: -4.141993281287189\n",
      "resetting env. episode reward total was -11.0. running mean: -4.210573348474318\n",
      "resetting env. episode reward total was -2.0. running mean: -4.188467614989574\n",
      "resetting env. episode reward total was 4.0. running mean: -4.106582938839678\n",
      "resetting env. episode reward total was -4.0. running mean: -4.105517109451282\n",
      "resetting env. episode reward total was -14.0. running mean: -4.2044619383567685\n",
      "resetting env. episode reward total was -9.0. running mean: -4.252417318973201\n",
      "resetting env. episode reward total was 6.0. running mean: -4.149893145783469\n",
      "resetting env. episode reward total was -9.0. running mean: -4.198394214325634\n",
      "resetting env. episode reward total was 11.0. running mean: -4.046410272182378\n",
      "resetting env. episode reward total was -7.0. running mean: -4.075946169460554\n",
      "resetting env. episode reward total was -3.0. running mean: -4.065186707765949\n",
      "resetting env. episode reward total was -8.0. running mean: -4.104534840688289\n",
      "resetting env. episode reward total was -9.0. running mean: -4.153489492281405\n",
      "resetting env. episode reward total was -9.0. running mean: -4.201954597358591\n",
      "resetting env. episode reward total was -1.0. running mean: -4.169935051385004\n",
      "resetting env. episode reward total was -5.0. running mean: -4.178235700871154\n",
      "resetting env. episode reward total was -6.0. running mean: -4.196453343862442\n",
      "resetting env. episode reward total was -4.0. running mean: -4.194488810423818\n",
      "resetting env. episode reward total was -4.0. running mean: -4.1925439223195795\n",
      "resetting env. episode reward total was 6.0. running mean: -4.090618483096384\n",
      "resetting env. episode reward total was -9.0. running mean: -4.139712298265421\n",
      "resetting env. episode reward total was -8.0. running mean: -4.1783151752827665\n",
      "resetting env. episode reward total was -1.0. running mean: -4.1465320235299385\n",
      "resetting env. episode reward total was -5.0. running mean: -4.155066703294639\n",
      "resetting env. episode reward total was 2.0. running mean: -4.093516036261693\n",
      "resetting env. episode reward total was -8.0. running mean: -4.132580875899077\n",
      "resetting env. episode reward total was -12.0. running mean: -4.211255067140086\n",
      "resetting env. episode reward total was 9.0. running mean: -4.079142516468685\n",
      "resetting env. episode reward total was -11.0. running mean: -4.148351091303998\n",
      "resetting env. episode reward total was -8.0. running mean: -4.186867580390958\n",
      "resetting env. episode reward total was 10.0. running mean: -4.0449989045870485\n",
      "resetting env. episode reward total was -8.0. running mean: -4.084548915541178\n",
      "resetting env. episode reward total was -3.0. running mean: -4.073703426385766\n",
      "resetting env. episode reward total was -3.0. running mean: -4.062966392121909\n",
      "resetting env. episode reward total was -16.0. running mean: -4.182336728200689\n",
      "resetting env. episode reward total was -3.0. running mean: -4.170513360918683\n",
      "resetting env. episode reward total was 1.0. running mean: -4.118808227309496\n",
      "resetting env. episode reward total was -10.0. running mean: -4.177620145036401\n",
      "resetting env. episode reward total was 1.0. running mean: -4.125843943586037\n",
      "resetting env. episode reward total was -5.0. running mean: -4.134585504150176\n",
      "resetting env. episode reward total was -8.0. running mean: -4.173239649108674\n",
      "resetting env. episode reward total was -3.0. running mean: -4.161507252617588\n",
      "resetting env. episode reward total was 4.0. running mean: -4.079892180091411\n",
      "resetting env. episode reward total was -9.0. running mean: -4.129093258290497\n",
      "resetting env. episode reward total was -7.0. running mean: -4.157802325707592\n",
      "resetting env. episode reward total was -4.0. running mean: -4.156224302450516\n",
      "resetting env. episode reward total was 2.0. running mean: -4.094662059426011\n",
      "resetting env. episode reward total was -5.0. running mean: -4.103715438831751\n",
      "resetting env. episode reward total was 1.0. running mean: -4.0526782844434335\n",
      "resetting env. episode reward total was -7.0. running mean: -4.082151501598999\n",
      "resetting env. episode reward total was -13.0. running mean: -4.171329986583009\n",
      "resetting env. episode reward total was -4.0. running mean: -4.169616686717179\n",
      "resetting env. episode reward total was -3.0. running mean: -4.157920519850007\n",
      "resetting env. episode reward total was -4.0. running mean: -4.156341314651507\n",
      "resetting env. episode reward total was 4.0. running mean: -4.074777901504992\n",
      "resetting env. episode reward total was -9.0. running mean: -4.124030122489941\n",
      "resetting env. episode reward total was -15.0. running mean: -4.232789821265042\n",
      "resetting env. episode reward total was -7.0. running mean: -4.260461923052392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -10.0. running mean: -4.317857303821868\n",
      "resetting env. episode reward total was -12.0. running mean: -4.3946787307836495\n",
      "resetting env. episode reward total was 1.0. running mean: -4.340731943475813\n",
      "resetting env. episode reward total was 3.0. running mean: -4.267324624041055\n",
      "resetting env. episode reward total was -1.0. running mean: -4.234651377800644\n",
      "resetting env. episode reward total was 2.0. running mean: -4.172304864022638\n",
      "resetting env. episode reward total was -6.0. running mean: -4.190581815382411\n",
      "resetting env. episode reward total was -5.0. running mean: -4.1986759972285865\n",
      "resetting env. episode reward total was -10.0. running mean: -4.2566892372563006\n",
      "resetting env. episode reward total was 6.0. running mean: -4.154122344883738\n",
      "resetting env. episode reward total was -4.0. running mean: -4.1525811214349\n",
      "resetting env. episode reward total was 8.0. running mean: -4.031055310220551\n",
      "resetting env. episode reward total was 5.0. running mean: -3.9407447571183454\n",
      "resetting env. episode reward total was -5.0. running mean: -3.951337309547162\n",
      "resetting env. episode reward total was -9.0. running mean: -4.00182393645169\n",
      "resetting env. episode reward total was -2.0. running mean: -3.9818056970871734\n",
      "resetting env. episode reward total was -3.0. running mean: -3.9719876401163012\n",
      "resetting env. episode reward total was -4.0. running mean: -3.9722677637151382\n",
      "resetting env. episode reward total was 1.0. running mean: -3.922545086077987\n",
      "resetting env. episode reward total was -3.0. running mean: -3.913319635217207\n",
      "resetting env. episode reward total was -11.0. running mean: -3.9841864388650348\n",
      "resetting env. episode reward total was 3.0. running mean: -3.9143445744763845\n",
      "resetting env. episode reward total was -3.0. running mean: -3.9052011287316204\n",
      "resetting env. episode reward total was -3.0. running mean: -3.896149117444304\n",
      "resetting env. episode reward total was 3.0. running mean: -3.827187626269861\n",
      "resetting env. episode reward total was -5.0. running mean: -3.8389157500071622\n",
      "resetting env. episode reward total was -15.0. running mean: -3.9505265925070905\n",
      "resetting env. episode reward total was 5.0. running mean: -3.8610213265820197\n",
      "resetting env. episode reward total was 6.0. running mean: -3.7624111133161993\n",
      "resetting env. episode reward total was 13.0. running mean: -3.5947870021830375\n",
      "resetting env. episode reward total was 5.0. running mean: -3.5088391321612074\n",
      "resetting env. episode reward total was 2.0. running mean: -3.4537507408395953\n",
      "resetting env. episode reward total was 6.0. running mean: -3.3592132334311993\n",
      "resetting env. episode reward total was -7.0. running mean: -3.395621101096887\n",
      "resetting env. episode reward total was 7.0. running mean: -3.2916648900859182\n",
      "resetting env. episode reward total was -6.0. running mean: -3.3187482411850593\n",
      "resetting env. episode reward total was -3.0. running mean: -3.3155607587732083\n",
      "resetting env. episode reward total was 10.0. running mean: -3.1824051511854763\n",
      "resetting env. episode reward total was 5.0. running mean: -3.100581099673622\n",
      "resetting env. episode reward total was -2.0. running mean: -3.0895752886768855\n",
      "resetting env. episode reward total was -7.0. running mean: -3.1286795357901163\n",
      "resetting env. episode reward total was -14.0. running mean: -3.2373927404322154\n",
      "resetting env. episode reward total was -13.0. running mean: -3.3350188130278933\n",
      "resetting env. episode reward total was -1.0. running mean: -3.311668624897614\n",
      "resetting env. episode reward total was -1.0. running mean: -3.288551938648638\n",
      "resetting env. episode reward total was 5.0. running mean: -3.2056664192621516\n",
      "resetting env. episode reward total was -1.0. running mean: -3.1836097550695297\n",
      "resetting env. episode reward total was -6.0. running mean: -3.2117736575188345\n",
      "resetting env. episode reward total was 10.0. running mean: -3.079655920943646\n",
      "resetting env. episode reward total was 1.0. running mean: -3.0388593617342097\n",
      "resetting env. episode reward total was -9.0. running mean: -3.0984707681168673\n",
      "resetting env. episode reward total was 4.0. running mean: -3.0274860604356983\n",
      "resetting env. episode reward total was -7.0. running mean: -3.067211199831341\n",
      "resetting env. episode reward total was 3.0. running mean: -3.006539087833028\n",
      "resetting env. episode reward total was -8.0. running mean: -3.056473696954698\n",
      "resetting env. episode reward total was -1.0. running mean: -3.0359089599851505\n",
      "resetting env. episode reward total was 7.0. running mean: -2.9355498703852994\n",
      "resetting env. episode reward total was -6.0. running mean: -2.9661943716814463\n",
      "resetting env. episode reward total was -6.0. running mean: -2.996532427964632\n",
      "resetting env. episode reward total was -9.0. running mean: -3.0565671036849853\n",
      "resetting env. episode reward total was 8.0. running mean: -2.9460014326481354\n",
      "resetting env. episode reward total was 9.0. running mean: -2.826541418321654\n",
      "resetting env. episode reward total was -10.0. running mean: -2.8982760041384377\n",
      "resetting env. episode reward total was 1.0. running mean: -2.8592932440970533\n",
      "resetting env. episode reward total was -10.0. running mean: -2.930700311656083\n",
      "resetting env. episode reward total was -11.0. running mean: -3.011393308539522\n",
      "resetting env. episode reward total was -19.0. running mean: -3.1712793754541266\n",
      "resetting env. episode reward total was -6.0. running mean: -3.1995665816995853\n",
      "resetting env. episode reward total was -6.0. running mean: -3.2275709158825894\n",
      "resetting env. episode reward total was -9.0. running mean: -3.2852952067237635\n",
      "resetting env. episode reward total was 4.0. running mean: -3.212442254656526\n",
      "resetting env. episode reward total was 7.0. running mean: -3.1103178321099607\n",
      "resetting env. episode reward total was -11.0. running mean: -3.189214653788861\n",
      "resetting env. episode reward total was 6.0. running mean: -3.0973225072509725\n",
      "resetting env. episode reward total was -13.0. running mean: -3.1963492821784625\n",
      "resetting env. episode reward total was -7.0. running mean: -3.234385789356678\n",
      "resetting env. episode reward total was -3.0. running mean: -3.232041931463111\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2697215121484797\n",
      "resetting env. episode reward total was -11.0. running mean: -3.3470242970269948\n",
      "resetting env. episode reward total was 10.0. running mean: -3.2135540540567247\n",
      "resetting env. episode reward total was -6.0. running mean: -3.2414185135161575\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2790043283809958\n",
      "resetting env. episode reward total was -6.0. running mean: -3.3062142850971856\n",
      "resetting env. episode reward total was 3.0. running mean: -3.2431521422462137\n",
      "resetting env. episode reward total was -9.0. running mean: -3.3007206208237516\n",
      "resetting env. episode reward total was -7.0. running mean: -3.337713414615514\n",
      "resetting env. episode reward total was 6.0. running mean: -3.2443362804693585\n",
      "resetting env. episode reward total was 8.0. running mean: -3.131892917664665\n",
      "resetting env. episode reward total was -1.0. running mean: -3.110573988488018\n",
      "resetting env. episode reward total was 1.0. running mean: -3.069468248603138\n",
      "resetting env. episode reward total was -6.0. running mean: -3.098773566117107\n",
      "resetting env. episode reward total was 7.0. running mean: -2.997785830455936\n",
      "resetting env. episode reward total was 15.0. running mean: -2.8178079721513765\n",
      "resetting env. episode reward total was -4.0. running mean: -2.8296298924298626\n",
      "resetting env. episode reward total was 5.0. running mean: -2.751333593505564\n",
      "resetting env. episode reward total was 1.0. running mean: -2.7138202575705086\n",
      "resetting env. episode reward total was -6.0. running mean: -2.7466820549948037\n",
      "resetting env. episode reward total was -4.0. running mean: -2.7592152344448557\n",
      "resetting env. episode reward total was 7.0. running mean: -2.6616230821004074\n",
      "resetting env. episode reward total was -1.0. running mean: -2.645006851279403\n",
      "resetting env. episode reward total was -13.0. running mean: -2.7485567827666086\n",
      "resetting env. episode reward total was 8.0. running mean: -2.6410712149389424\n",
      "resetting env. episode reward total was -4.0. running mean: -2.654660502789553\n",
      "resetting env. episode reward total was -2.0. running mean: -2.6481138977616574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: -2.581632758784041\n",
      "resetting env. episode reward total was -7.0. running mean: -2.6258164311962005\n",
      "resetting env. episode reward total was -9.0. running mean: -2.689558266884238\n",
      "resetting env. episode reward total was -3.0. running mean: -2.6926626842153953\n",
      "resetting env. episode reward total was -10.0. running mean: -2.7657360573732412\n",
      "resetting env. episode reward total was -5.0. running mean: -2.788078696799509\n",
      "resetting env. episode reward total was -12.0. running mean: -2.880197909831514\n",
      "resetting env. episode reward total was 6.0. running mean: -2.791395930733199\n",
      "resetting env. episode reward total was 3.0. running mean: -2.733481971425867\n",
      "resetting env. episode reward total was -3.0. running mean: -2.736147151711608\n",
      "resetting env. episode reward total was -9.0. running mean: -2.798785680194492\n",
      "resetting env. episode reward total was -11.0. running mean: -2.880797823392547\n",
      "resetting env. episode reward total was -3.0. running mean: -2.881989845158621\n",
      "resetting env. episode reward total was -13.0. running mean: -2.9831699467070347\n",
      "resetting env. episode reward total was 3.0. running mean: -2.9233382472399647\n",
      "resetting env. episode reward total was -13.0. running mean: -3.024104864767565\n",
      "resetting env. episode reward total was 1.0. running mean: -2.9838638161198894\n",
      "resetting env. episode reward total was -9.0. running mean: -3.0440251779586904\n",
      "resetting env. episode reward total was -1.0. running mean: -3.0235849261791032\n",
      "resetting env. episode reward total was -1.0. running mean: -3.003349076917312\n",
      "resetting env. episode reward total was -4.0. running mean: -3.013315586148139\n",
      "resetting env. episode reward total was -10.0. running mean: -3.0831824302866577\n",
      "resetting env. episode reward total was 5.0. running mean: -3.0023506059837914\n",
      "resetting env. episode reward total was 3.0. running mean: -2.9423270999239537\n",
      "resetting env. episode reward total was -2.0. running mean: -2.9329038289247142\n",
      "resetting env. episode reward total was -15.0. running mean: -3.053574790635467\n",
      "resetting env. episode reward total was -10.0. running mean: -3.1230390427291126\n",
      "resetting env. episode reward total was -11.0. running mean: -3.201808652301821\n",
      "resetting env. episode reward total was -4.0. running mean: -3.209790565778803\n",
      "resetting env. episode reward total was -5.0. running mean: -3.2276926601210145\n",
      "resetting env. episode reward total was -3.0. running mean: -3.2254157335198044\n",
      "resetting env. episode reward total was 1.0. running mean: -3.1831615761846064\n",
      "resetting env. episode reward total was -14.0. running mean: -3.2913299604227606\n",
      "resetting env. episode reward total was -4.0. running mean: -3.298416660818533\n",
      "resetting env. episode reward total was -4.0. running mean: -3.3054324942103475\n",
      "resetting env. episode reward total was 2.0. running mean: -3.252378169268244\n",
      "resetting env. episode reward total was -3.0. running mean: -3.2498543875755614\n",
      "resetting env. episode reward total was -3.0. running mean: -3.247355843699806\n",
      "resetting env. episode reward total was -2.0. running mean: -3.234882285262808\n",
      "resetting env. episode reward total was 5.0. running mean: -3.15253346241018\n",
      "resetting env. episode reward total was -14.0. running mean: -3.261008127786078\n",
      "resetting env. episode reward total was 9.0. running mean: -3.1383980465082173\n",
      "resetting env. episode reward total was -7.0. running mean: -3.1770140660431347\n",
      "resetting env. episode reward total was -11.0. running mean: -3.2552439253827035\n",
      "resetting env. episode reward total was -2.0. running mean: -3.2426914861288765\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2802645712675873\n",
      "resetting env. episode reward total was 6.0. running mean: -3.1874619255549113\n",
      "resetting env. episode reward total was -9.0. running mean: -3.245587306299362\n",
      "resetting env. episode reward total was -11.0. running mean: -3.323131433236368\n",
      "resetting env. episode reward total was -1.0. running mean: -3.299900118904004\n",
      "resetting env. episode reward total was 11.0. running mean: -3.156901117714964\n",
      "resetting env. episode reward total was 4.0. running mean: -3.0853321065378143\n",
      "resetting env. episode reward total was -5.0. running mean: -3.104478785472436\n",
      "resetting env. episode reward total was -5.0. running mean: -3.1234339976177115\n",
      "resetting env. episode reward total was 5.0. running mean: -3.0421996576415347\n",
      "resetting env. episode reward total was -6.0. running mean: -3.0717776610651195\n",
      "resetting env. episode reward total was -10.0. running mean: -3.1410598844544686\n",
      "resetting env. episode reward total was -9.0. running mean: -3.1996492856099237\n",
      "resetting env. episode reward total was -11.0. running mean: -3.277652792753824\n",
      "resetting env. episode reward total was -4.0. running mean: -3.284876264826286\n",
      "resetting env. episode reward total was 3.0. running mean: -3.2220275021780234\n",
      "resetting env. episode reward total was -11.0. running mean: -3.299807227156243\n",
      "resetting env. episode reward total was 4.0. running mean: -3.2268091548846805\n",
      "resetting env. episode reward total was -9.0. running mean: -3.2845410633358334\n",
      "resetting env. episode reward total was -5.0. running mean: -3.301695652702475\n",
      "resetting env. episode reward total was -7.0. running mean: -3.33867869617545\n",
      "resetting env. episode reward total was -4.0. running mean: -3.3452919092136955\n",
      "resetting env. episode reward total was 6.0. running mean: -3.2518389901215583\n",
      "resetting env. episode reward total was -3.0. running mean: -3.2493206002203423\n",
      "resetting env. episode reward total was 12.0. running mean: -3.096827394218139\n",
      "resetting env. episode reward total was 2.0. running mean: -3.0458591202759573\n",
      "resetting env. episode reward total was -2.0. running mean: -3.035400529073198\n",
      "resetting env. episode reward total was 5.0. running mean: -2.955046523782466\n",
      "resetting env. episode reward total was -9.0. running mean: -3.0154960585446413\n",
      "resetting env. episode reward total was 1.0. running mean: -2.975341097959195\n",
      "resetting env. episode reward total was 5.0. running mean: -2.8955876869796033\n",
      "resetting env. episode reward total was 3.0. running mean: -2.8366318101098074\n",
      "resetting env. episode reward total was 1.0. running mean: -2.7982654920087096\n",
      "resetting env. episode reward total was -5.0. running mean: -2.820282837088622\n",
      "resetting env. episode reward total was 3.0. running mean: -2.762080008717736\n",
      "resetting env. episode reward total was -9.0. running mean: -2.824459208630558\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8062146165442523\n",
      "resetting env. episode reward total was 8.0. running mean: -2.6981524703788096\n",
      "resetting env. episode reward total was 4.0. running mean: -2.6311709456750214\n",
      "resetting env. episode reward total was 4.0. running mean: -2.564859236218271\n",
      "resetting env. episode reward total was -2.0. running mean: -2.559210643856088\n",
      "resetting env. episode reward total was -2.0. running mean: -2.5536185374175275\n",
      "resetting env. episode reward total was 9.0. running mean: -2.4380823520433523\n",
      "resetting env. episode reward total was 5.0. running mean: -2.363701528522919\n",
      "resetting env. episode reward total was 1.0. running mean: -2.3300645132376903\n",
      "resetting env. episode reward total was -15.0. running mean: -2.4567638681053134\n",
      "resetting env. episode reward total was -13.0. running mean: -2.56219622942426\n",
      "resetting env. episode reward total was 4.0. running mean: -2.4965742671300175\n",
      "resetting env. episode reward total was 1.0. running mean: -2.4616085244587174\n",
      "resetting env. episode reward total was -3.0. running mean: -2.46699243921413\n",
      "resetting env. episode reward total was -1.0. running mean: -2.4523225148219883\n",
      "resetting env. episode reward total was -5.0. running mean: -2.477799289673768\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5030212967770304\n",
      "resetting env. episode reward total was -13.0. running mean: -2.60799108380926\n",
      "resetting env. episode reward total was -5.0. running mean: -2.6319111729711673\n",
      "resetting env. episode reward total was 7.0. running mean: -2.5355920612414558\n",
      "resetting env. episode reward total was 2.0. running mean: -2.490236140629041\n",
      "resetting env. episode reward total was -11.0. running mean: -2.5753337792227504\n",
      "resetting env. episode reward total was -11.0. running mean: -2.659580441430523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: -2.6029846370162177\n",
      "resetting env. episode reward total was -3.0. running mean: -2.6069547906460553\n",
      "resetting env. episode reward total was 8.0. running mean: -2.5008852427395944\n",
      "resetting env. episode reward total was -8.0. running mean: -2.5558763903121986\n",
      "resetting env. episode reward total was -7.0. running mean: -2.6003176264090766\n",
      "resetting env. episode reward total was 4.0. running mean: -2.534314450144986\n",
      "resetting env. episode reward total was -7.0. running mean: -2.578971305643536\n",
      "resetting env. episode reward total was 5.0. running mean: -2.503181592587101\n",
      "resetting env. episode reward total was -2.0. running mean: -2.4981497766612297\n",
      "resetting env. episode reward total was 7.0. running mean: -2.4031682788946176\n",
      "resetting env. episode reward total was 5.0. running mean: -2.3291365961056716\n",
      "resetting env. episode reward total was -4.0. running mean: -2.345845230144615\n",
      "resetting env. episode reward total was -3.0. running mean: -2.3523867778431686\n",
      "resetting env. episode reward total was -9.0. running mean: -2.4188629100647367\n",
      "resetting env. episode reward total was 2.0. running mean: -2.3746742809640895\n",
      "resetting env. episode reward total was -5.0. running mean: -2.4009275381544484\n",
      "resetting env. episode reward total was 5.0. running mean: -2.326918262772904\n",
      "resetting env. episode reward total was -11.0. running mean: -2.413649080145175\n",
      "resetting env. episode reward total was -1.0. running mean: -2.399512589343723\n",
      "resetting env. episode reward total was 3.0. running mean: -2.3455174634502858\n",
      "resetting env. episode reward total was 2.0. running mean: -2.3020622888157827\n",
      "resetting env. episode reward total was -5.0. running mean: -2.3290416659276247\n",
      "resetting env. episode reward total was -1.0. running mean: -2.3157512492683483\n",
      "resetting env. episode reward total was -6.0. running mean: -2.3525937367756646\n",
      "resetting env. episode reward total was 11.0. running mean: -2.219067799407908\n",
      "resetting env. episode reward total was -8.0. running mean: -2.276877121413829\n",
      "resetting env. episode reward total was 14.0. running mean: -2.1141083501996905\n",
      "resetting env. episode reward total was 6.0. running mean: -2.0329672666976935\n",
      "resetting env. episode reward total was 5.0. running mean: -1.9626375940307164\n",
      "resetting env. episode reward total was -8.0. running mean: -2.023011218090409\n",
      "resetting env. episode reward total was 8.0. running mean: -1.9227811059095048\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9335532948504097\n",
      "resetting env. episode reward total was -13.0. running mean: -2.0442177619019057\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9937755842828866\n",
      "resetting env. episode reward total was -10.0. running mean: -2.0738378284400576\n",
      "resetting env. episode reward total was -5.0. running mean: -2.103099450155657\n",
      "resetting env. episode reward total was -4.0. running mean: -2.1220684556541003\n",
      "resetting env. episode reward total was 3.0. running mean: -2.0708477710975597\n",
      "resetting env. episode reward total was -7.0. running mean: -2.120139293386584\n",
      "resetting env. episode reward total was -11.0. running mean: -2.208937900452718\n",
      "resetting env. episode reward total was -3.0. running mean: -2.2168485214481906\n",
      "resetting env. episode reward total was 6.0. running mean: -2.1346800362337084\n",
      "resetting env. episode reward total was -4.0. running mean: -2.1533332358713713\n",
      "resetting env. episode reward total was -5.0. running mean: -2.1817999035126574\n",
      "resetting env. episode reward total was -1.0. running mean: -2.1699819044775306\n",
      "resetting env. episode reward total was 7.0. running mean: -2.0782820854327553\n",
      "resetting env. episode reward total was 3.0. running mean: -2.0274992645784278\n",
      "resetting env. episode reward total was 1.0. running mean: -1.9972242719326434\n",
      "resetting env. episode reward total was -12.0. running mean: -2.0972520292133168\n",
      "resetting env. episode reward total was -7.0. running mean: -2.1462795089211832\n",
      "resetting env. episode reward total was -7.0. running mean: -2.194816713831971\n",
      "resetting env. episode reward total was -2.0. running mean: -2.1928685466936515\n",
      "resetting env. episode reward total was 1.0. running mean: -2.160939861226715\n",
      "resetting env. episode reward total was 5.0. running mean: -2.0893304626144484\n",
      "resetting env. episode reward total was -12.0. running mean: -2.188437157988304\n",
      "resetting env. episode reward total was 7.0. running mean: -2.0965527864084215\n",
      "resetting env. episode reward total was 9.0. running mean: -1.985587258544337\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9957313859588937\n",
      "resetting env. episode reward total was -7.0. running mean: -2.0457740720993045\n",
      "resetting env. episode reward total was -2.0. running mean: -2.0453163313783116\n",
      "resetting env. episode reward total was 4.0. running mean: -1.9848631680645283\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9750145363838831\n",
      "resetting env. episode reward total was 5.0. running mean: -1.9052643910200442\n",
      "resetting env. episode reward total was -1.0. running mean: -1.8962117471098436\n",
      "resetting env. episode reward total was -7.0. running mean: -1.9472496296387451\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9577771333423577\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9481993620089342\n",
      "resetting env. episode reward total was 11.0. running mean: -1.8187173683888447\n",
      "resetting env. episode reward total was 3.0. running mean: -1.770530194704956\n",
      "resetting env. episode reward total was -11.0. running mean: -1.8628248927579065\n",
      "resetting env. episode reward total was -14.0. running mean: -1.9841966438303276\n",
      "resetting env. episode reward total was -9.0. running mean: -2.0543546773920243\n",
      "resetting env. episode reward total was 12.0. running mean: -1.9138111306181038\n",
      "resetting env. episode reward total was -2.0. running mean: -1.9146730193119228\n",
      "resetting env. episode reward total was -4.0. running mean: -1.9355262891188036\n",
      "resetting env. episode reward total was -5.0. running mean: -1.9661710262276155\n",
      "resetting env. episode reward total was -5.0. running mean: -1.9965093159653393\n",
      "resetting env. episode reward total was -7.0. running mean: -2.046544222805686\n",
      "resetting env. episode reward total was -6.0. running mean: -2.086078780577629\n",
      "resetting env. episode reward total was 10.0. running mean: -1.9652179927718523\n",
      "resetting env. episode reward total was -8.0. running mean: -2.0255658128441336\n",
      "resetting env. episode reward total was 10.0. running mean: -1.9053101547156923\n",
      "resetting env. episode reward total was -2.0. running mean: -1.9062570531685354\n",
      "resetting env. episode reward total was -4.0. running mean: -1.9271944826368501\n",
      "resetting env. episode reward total was 1.0. running mean: -1.8979225378104816\n",
      "resetting env. episode reward total was -5.0. running mean: -1.9289433124323767\n",
      "resetting env. episode reward total was -7.0. running mean: -1.979653879308053\n",
      "resetting env. episode reward total was 9.0. running mean: -1.8698573405149723\n",
      "resetting env. episode reward total was -9.0. running mean: -1.9411587671098227\n",
      "resetting env. episode reward total was 1.0. running mean: -1.9117471794387244\n",
      "resetting env. episode reward total was 4.0. running mean: -1.8526297076443372\n",
      "resetting env. episode reward total was -1.0. running mean: -1.8441034105678937\n",
      "resetting env. episode reward total was -11.0. running mean: -1.935662376462215\n",
      "resetting env. episode reward total was 1.0. running mean: -1.9063057526975928\n",
      "resetting env. episode reward total was 13.0. running mean: -1.7572426951706168\n",
      "resetting env. episode reward total was -10.0. running mean: -1.8396702682189108\n",
      "resetting env. episode reward total was 9.0. running mean: -1.7312735655367215\n",
      "resetting env. episode reward total was 11.0. running mean: -1.6039608298813541\n",
      "resetting env. episode reward total was -2.0. running mean: -1.6079212215825407\n",
      "resetting env. episode reward total was -15.0. running mean: -1.7418420093667153\n",
      "resetting env. episode reward total was 6.0. running mean: -1.6644235892730481\n",
      "resetting env. episode reward total was -7.0. running mean: -1.7177793533803176\n",
      "resetting env. episode reward total was -15.0. running mean: -1.8506015598465144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: -1.8020955442480493\n",
      "resetting env. episode reward total was 1.0. running mean: -1.7740745888055687\n",
      "resetting env. episode reward total was -5.0. running mean: -1.806333842917513\n",
      "resetting env. episode reward total was 3.0. running mean: -1.758270504488338\n",
      "resetting env. episode reward total was -15.0. running mean: -1.8906877994434546\n",
      "resetting env. episode reward total was 2.0. running mean: -1.85178092144902\n",
      "resetting env. episode reward total was 7.0. running mean: -1.7632631122345297\n",
      "resetting env. episode reward total was -15.0. running mean: -1.8956304811121842\n",
      "resetting env. episode reward total was -4.0. running mean: -1.9166741763010624\n",
      "resetting env. episode reward total was -9.0. running mean: -1.987507434538052\n",
      "resetting env. episode reward total was 1.0. running mean: -1.9576323601926713\n",
      "resetting env. episode reward total was -5.0. running mean: -1.9880560365907447\n",
      "resetting env. episode reward total was -13.0. running mean: -2.0981754762248372\n",
      "resetting env. episode reward total was -5.0. running mean: -2.127193721462589\n",
      "resetting env. episode reward total was -15.0. running mean: -2.255921784247963\n",
      "resetting env. episode reward total was 1.0. running mean: -2.2233625664054832\n",
      "resetting env. episode reward total was 6.0. running mean: -2.1411289407414285\n",
      "resetting env. episode reward total was -4.0. running mean: -2.1597176513340144\n",
      "resetting env. episode reward total was -3.0. running mean: -2.168120474820674\n",
      "resetting env. episode reward total was -5.0. running mean: -2.196439270072467\n",
      "resetting env. episode reward total was -4.0. running mean: -2.2144748773717424\n",
      "resetting env. episode reward total was 11.0. running mean: -2.082330128598025\n",
      "resetting env. episode reward total was -3.0. running mean: -2.0915068273120445\n",
      "resetting env. episode reward total was -4.0. running mean: -2.110591759038924\n",
      "resetting env. episode reward total was -4.0. running mean: -2.1294858414485347\n",
      "resetting env. episode reward total was -8.0. running mean: -2.1881909830340494\n",
      "resetting env. episode reward total was -4.0. running mean: -2.206309073203709\n",
      "resetting env. episode reward total was -1.0. running mean: -2.1942459824716716\n",
      "resetting env. episode reward total was 1.0. running mean: -2.162303522646955\n",
      "resetting env. episode reward total was -7.0. running mean: -2.2106804874204853\n",
      "resetting env. episode reward total was -3.0. running mean: -2.21857368254628\n",
      "resetting env. episode reward total was -6.0. running mean: -2.2563879457208174\n",
      "resetting env. episode reward total was -7.0. running mean: -2.303824066263609\n",
      "resetting env. episode reward total was -1.0. running mean: -2.2907858256009725\n",
      "resetting env. episode reward total was -1.0. running mean: -2.2778779673449625\n",
      "resetting env. episode reward total was -9.0. running mean: -2.345099187671513\n",
      "resetting env. episode reward total was 2.0. running mean: -2.301648195794798\n",
      "resetting env. episode reward total was 4.0. running mean: -2.23863171383685\n",
      "resetting env. episode reward total was -7.0. running mean: -2.2862453966984813\n",
      "resetting env. episode reward total was -3.0. running mean: -2.2933829427314962\n",
      "resetting env. episode reward total was 3.0. running mean: -2.2404491133041815\n",
      "resetting env. episode reward total was -4.0. running mean: -2.25804462217114\n",
      "resetting env. episode reward total was -6.0. running mean: -2.2954641759494283\n",
      "resetting env. episode reward total was -1.0. running mean: -2.2825095341899337\n",
      "resetting env. episode reward total was -11.0. running mean: -2.3696844388480343\n",
      "resetting env. episode reward total was -7.0. running mean: -2.415987594459554\n",
      "resetting env. episode reward total was 7.0. running mean: -2.3218277185149585\n",
      "resetting env. episode reward total was -6.0. running mean: -2.358609441329809\n",
      "resetting env. episode reward total was -13.0. running mean: -2.465023346916511\n",
      "resetting env. episode reward total was -9.0. running mean: -2.5303731134473457\n",
      "resetting env. episode reward total was -11.0. running mean: -2.615069382312872\n",
      "resetting env. episode reward total was -1.0. running mean: -2.5989186884897433\n",
      "resetting env. episode reward total was -7.0. running mean: -2.6429295016048457\n",
      "resetting env. episode reward total was -17.0. running mean: -2.7865002065887974\n",
      "resetting env. episode reward total was -7.0. running mean: -2.828635204522909\n",
      "resetting env. episode reward total was -4.0. running mean: -2.84034885247768\n",
      "resetting env. episode reward total was -5.0. running mean: -2.861945363952903\n",
      "resetting env. episode reward total was -8.0. running mean: -2.913325910313374\n",
      "resetting env. episode reward total was -2.0. running mean: -2.90419265121024\n",
      "resetting env. episode reward total was -2.0. running mean: -2.8951507246981376\n",
      "resetting env. episode reward total was -9.0. running mean: -2.956199217451156\n",
      "resetting env. episode reward total was -1.0. running mean: -2.936637225276644\n",
      "resetting env. episode reward total was 4.0. running mean: -2.8672708530238777\n",
      "resetting env. episode reward total was -6.0. running mean: -2.898598144493639\n",
      "resetting env. episode reward total was -9.0. running mean: -2.9596121630487024\n",
      "resetting env. episode reward total was 2.0. running mean: -2.9100160414182152\n",
      "resetting env. episode reward total was 5.0. running mean: -2.8309158810040334\n",
      "resetting env. episode reward total was -9.0. running mean: -2.892606722193993\n",
      "resetting env. episode reward total was 2.0. running mean: -2.843680654972053\n",
      "resetting env. episode reward total was -7.0. running mean: -2.8852438484223324\n",
      "resetting env. episode reward total was -13.0. running mean: -2.986391409938109\n",
      "resetting env. episode reward total was -3.0. running mean: -2.9865274958387276\n",
      "resetting env. episode reward total was -9.0. running mean: -3.04666222088034\n",
      "resetting env. episode reward total was 1.0. running mean: -3.006195598671537\n",
      "resetting env. episode reward total was 7.0. running mean: -2.906133642684822\n",
      "resetting env. episode reward total was -8.0. running mean: -2.957072306257974\n",
      "resetting env. episode reward total was 5.0. running mean: -2.8775015831953943\n",
      "resetting env. episode reward total was 1.0. running mean: -2.8387265673634405\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8203393016898057\n",
      "resetting env. episode reward total was -5.0. running mean: -2.8421359086729074\n",
      "resetting env. episode reward total was 6.0. running mean: -2.7537145495861783\n",
      "resetting env. episode reward total was -2.0. running mean: -2.7461774040903166\n",
      "resetting env. episode reward total was -12.0. running mean: -2.8387156300494136\n",
      "resetting env. episode reward total was -7.0. running mean: -2.880328473748919\n",
      "resetting env. episode reward total was 1.0. running mean: -2.8415251890114304\n",
      "resetting env. episode reward total was -2.0. running mean: -2.833109937121316\n",
      "resetting env. episode reward total was 9.0. running mean: -2.714778837750103\n",
      "resetting env. episode reward total was 6.0. running mean: -2.627631049372602\n",
      "resetting env. episode reward total was -7.0. running mean: -2.671354738878876\n",
      "resetting env. episode reward total was 5.0. running mean: -2.594641191490087\n",
      "resetting env. episode reward total was -2.0. running mean: -2.588694779575186\n",
      "resetting env. episode reward total was 3.0. running mean: -2.5328078317794342\n",
      "resetting env. episode reward total was -19.0. running mean: -2.6974797534616397\n",
      "resetting env. episode reward total was -7.0. running mean: -2.740504955927023\n",
      "resetting env. episode reward total was -3.0. running mean: -2.7430999063677524\n",
      "resetting env. episode reward total was 7.0. running mean: -2.645668907304075\n",
      "resetting env. episode reward total was -8.0. running mean: -2.6992122182310343\n",
      "resetting env. episode reward total was -13.0. running mean: -2.802220096048724\n",
      "resetting env. episode reward total was -10.0. running mean: -2.8741978950882365\n",
      "resetting env. episode reward total was 5.0. running mean: -2.7954559161373544\n",
      "resetting env. episode reward total was -3.0. running mean: -2.797501356975981\n",
      "resetting env. episode reward total was 6.0. running mean: -2.709526343406221\n",
      "resetting env. episode reward total was -6.0. running mean: -2.742431079972159\n",
      "resetting env. episode reward total was -3.0. running mean: -2.7450067691724374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: -2.697556701480713\n",
      "resetting env. episode reward total was 1.0. running mean: -2.660581134465906\n",
      "resetting env. episode reward total was -5.0. running mean: -2.683975323121247\n",
      "resetting env. episode reward total was -7.0. running mean: -2.7271355698900344\n",
      "resetting env. episode reward total was -10.0. running mean: -2.799864214191134\n",
      "resetting env. episode reward total was -10.0. running mean: -2.8718655720492228\n",
      "resetting env. episode reward total was -6.0. running mean: -2.9031469163287307\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8841154471654433\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8652742926937886\n",
      "resetting env. episode reward total was -5.0. running mean: -2.8866215497668506\n",
      "resetting env. episode reward total was -7.0. running mean: -2.927755334269182\n",
      "resetting env. episode reward total was -2.0. running mean: -2.9184777809264904\n",
      "resetting env. episode reward total was -4.0. running mean: -2.9292930031172255\n",
      "resetting env. episode reward total was -3.0. running mean: -2.930000073086053\n",
      "resetting env. episode reward total was 5.0. running mean: -2.8507000723551927\n",
      "resetting env. episode reward total was -8.0. running mean: -2.9021930716316406\n",
      "resetting env. episode reward total was -1.0. running mean: -2.883171140915324\n",
      "resetting env. episode reward total was -7.0. running mean: -2.9243394295061704\n",
      "resetting env. episode reward total was 4.0. running mean: -2.8550960352111088\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8365450748589973\n",
      "resetting env. episode reward total was -3.0. running mean: -2.838179624110407\n",
      "resetting env. episode reward total was -7.0. running mean: -2.879797827869303\n",
      "resetting env. episode reward total was -5.0. running mean: -2.9009998495906095\n",
      "resetting env. episode reward total was -4.0. running mean: -2.9119898510947033\n",
      "resetting env. episode reward total was 9.0. running mean: -2.7928699525837564\n",
      "resetting env. episode reward total was 6.0. running mean: -2.704941253057919\n",
      "resetting env. episode reward total was -4.0. running mean: -2.7178918405273396\n",
      "resetting env. episode reward total was -4.0. running mean: -2.7307129221220663\n",
      "resetting env. episode reward total was 3.0. running mean: -2.6734057929008457\n",
      "resetting env. episode reward total was -3.0. running mean: -2.676671734971837\n",
      "resetting env. episode reward total was 7.0. running mean: -2.5799050176221185\n",
      "resetting env. episode reward total was -7.0. running mean: -2.6241059674458973\n",
      "resetting env. episode reward total was -6.0. running mean: -2.6578649077714385\n",
      "resetting env. episode reward total was 1.0. running mean: -2.6212862586937242\n",
      "resetting env. episode reward total was -11.0. running mean: -2.705073396106787\n",
      "resetting env. episode reward total was -2.0. running mean: -2.698022662145719\n",
      "resetting env. episode reward total was 6.0. running mean: -2.611042435524262\n",
      "resetting env. episode reward total was -9.0. running mean: -2.674932011169019\n",
      "resetting env. episode reward total was -5.0. running mean: -2.6981826910573288\n",
      "resetting env. episode reward total was 14.0. running mean: -2.531200864146755\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5558888555052874\n",
      "resetting env. episode reward total was 8.0. running mean: -2.4503299669502345\n",
      "resetting env. episode reward total was -6.0. running mean: -2.4858266672807323\n",
      "resetting env. episode reward total was -1.0. running mean: -2.4709684006079247\n",
      "resetting env. episode reward total was 6.0. running mean: -2.386258716601845\n",
      "resetting env. episode reward total was -5.0. running mean: -2.4123961294358267\n",
      "resetting env. episode reward total was -11.0. running mean: -2.4982721681414684\n",
      "resetting env. episode reward total was 2.0. running mean: -2.4532894464600536\n",
      "resetting env. episode reward total was -1.0. running mean: -2.438756551995453\n",
      "resetting env. episode reward total was -1.0. running mean: -2.4243689864754985\n",
      "resetting env. episode reward total was 7.0. running mean: -2.3301252966107437\n",
      "resetting env. episode reward total was -13.0. running mean: -2.436824043644636\n",
      "resetting env. episode reward total was -5.0. running mean: -2.4624558032081896\n",
      "resetting env. episode reward total was -8.0. running mean: -2.5178312451761076\n",
      "resetting env. episode reward total was 6.0. running mean: -2.4326529327243462\n",
      "resetting env. episode reward total was -13.0. running mean: -2.5383264033971025\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5629431393631315\n",
      "resetting env. episode reward total was 2.0. running mean: -2.5173137079695\n",
      "resetting env. episode reward total was 4.0. running mean: -2.452140570889805\n",
      "resetting env. episode reward total was -11.0. running mean: -2.537619165180907\n",
      "resetting env. episode reward total was 2.0. running mean: -2.492242973529098\n",
      "resetting env. episode reward total was -1.0. running mean: -2.4773205437938066\n",
      "resetting env. episode reward total was -9.0. running mean: -2.5425473383558685\n",
      "resetting env. episode reward total was -18.0. running mean: -2.69712186497231\n",
      "resetting env. episode reward total was -10.0. running mean: -2.7701506463225867\n",
      "resetting env. episode reward total was -16.0. running mean: -2.902449139859361\n",
      "resetting env. episode reward total was -3.0. running mean: -2.903424648460767\n",
      "resetting env. episode reward total was -9.0. running mean: -2.9643904019761593\n",
      "resetting env. episode reward total was 4.0. running mean: -2.8947464979563975\n",
      "resetting env. episode reward total was -9.0. running mean: -2.9557990329768336\n",
      "resetting env. episode reward total was 2.0. running mean: -2.906241042647065\n",
      "resetting env. episode reward total was 8.0. running mean: -2.7971786322205943\n",
      "resetting env. episode reward total was -3.0. running mean: -2.799206845898388\n",
      "resetting env. episode reward total was 7.0. running mean: -2.701214777439404\n",
      "resetting env. episode reward total was 5.0. running mean: -2.6242026296650103\n",
      "resetting env. episode reward total was -7.0. running mean: -2.66796060336836\n",
      "resetting env. episode reward total was -9.0. running mean: -2.731280997334676\n",
      "resetting env. episode reward total was 1.0. running mean: -2.6939681873613295\n",
      "resetting env. episode reward total was 2.0. running mean: -2.6470285054877163\n",
      "resetting env. episode reward total was 1.0. running mean: -2.6105582204328392\n",
      "resetting env. episode reward total was -3.0. running mean: -2.6144526382285105\n",
      "resetting env. episode reward total was 9.0. running mean: -2.4983081118462254\n",
      "resetting env. episode reward total was 2.0. running mean: -2.453325030727763\n",
      "resetting env. episode reward total was -15.0. running mean: -2.5787917804204854\n",
      "resetting env. episode reward total was -8.0. running mean: -2.6330038626162806\n",
      "resetting env. episode reward total was -9.0. running mean: -2.6966738239901176\n",
      "resetting env. episode reward total was -9.0. running mean: -2.7597070857502164\n",
      "resetting env. episode reward total was 4.0. running mean: -2.692110014892714\n",
      "resetting env. episode reward total was -5.0. running mean: -2.715188914743787\n",
      "resetting env. episode reward total was 1.0. running mean: -2.6780370255963493\n",
      "resetting env. episode reward total was 10.0. running mean: -2.5512566553403855\n",
      "resetting env. episode reward total was 4.0. running mean: -2.4857440887869817\n",
      "resetting env. episode reward total was 8.0. running mean: -2.380886647899112\n",
      "resetting env. episode reward total was -9.0. running mean: -2.447077781420121\n",
      "resetting env. episode reward total was -6.0. running mean: -2.48260700360592\n",
      "resetting env. episode reward total was 3.0. running mean: -2.427780933569861\n",
      "resetting env. episode reward total was -5.0. running mean: -2.453503124234162\n",
      "resetting env. episode reward total was 8.0. running mean: -2.34896809299182\n",
      "resetting env. episode reward total was 7.0. running mean: -2.255478412061902\n",
      "resetting env. episode reward total was 1.0. running mean: -2.222923627941283\n",
      "resetting env. episode reward total was 7.0. running mean: -2.1306943916618706\n",
      "resetting env. episode reward total was -8.0. running mean: -2.189387447745252\n",
      "resetting env. episode reward total was -5.0. running mean: -2.217493573267799\n",
      "resetting env. episode reward total was -5.0. running mean: -2.245318637535121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -11.0. running mean: -2.3328654511597695\n",
      "resetting env. episode reward total was 9.0. running mean: -2.219536796648172\n",
      "resetting env. episode reward total was -9.0. running mean: -2.28734142868169\n",
      "resetting env. episode reward total was -4.0. running mean: -2.3044680143948733\n",
      "resetting env. episode reward total was 3.0. running mean: -2.2514233342509247\n",
      "resetting env. episode reward total was -8.0. running mean: -2.3089091009084153\n",
      "resetting env. episode reward total was -9.0. running mean: -2.375820009899331\n",
      "resetting env. episode reward total was -2.0. running mean: -2.372061809800338\n",
      "resetting env. episode reward total was 6.0. running mean: -2.2883411917023344\n",
      "resetting env. episode reward total was 4.0. running mean: -2.225457779785311\n",
      "resetting env. episode reward total was 2.0. running mean: -2.1832032019874577\n",
      "resetting env. episode reward total was 7.0. running mean: -2.091371169967583\n",
      "resetting env. episode reward total was 4.0. running mean: -2.0304574582679074\n",
      "resetting env. episode reward total was -5.0. running mean: -2.060152883685228\n",
      "resetting env. episode reward total was 8.0. running mean: -1.9595513548483758\n",
      "resetting env. episode reward total was -1.0. running mean: -1.949955841299892\n",
      "resetting env. episode reward total was 7.0. running mean: -1.8604562828868931\n",
      "resetting env. episode reward total was -15.0. running mean: -1.9918517200580241\n",
      "resetting env. episode reward total was 9.0. running mean: -1.8819332028574438\n",
      "resetting env. episode reward total was 4.0. running mean: -1.8231138708288692\n",
      "resetting env. episode reward total was 4.0. running mean: -1.7648827321205804\n",
      "resetting env. episode reward total was 6.0. running mean: -1.6872339047993745\n",
      "resetting env. episode reward total was -6.0. running mean: -1.730361565751381\n",
      "resetting env. episode reward total was -13.0. running mean: -1.843057950093867\n",
      "resetting env. episode reward total was -1.0. running mean: -1.8346273705929284\n",
      "resetting env. episode reward total was -3.0. running mean: -1.8462810968869992\n",
      "resetting env. episode reward total was -6.0. running mean: -1.8878182859181292\n",
      "resetting env. episode reward total was -7.0. running mean: -1.938940103058948\n",
      "resetting env. episode reward total was -9.0. running mean: -2.0095507020283585\n",
      "resetting env. episode reward total was 6.0. running mean: -1.929455195008075\n",
      "resetting env. episode reward total was 8.0. running mean: -1.8301606430579942\n",
      "resetting env. episode reward total was 4.0. running mean: -1.7718590366274143\n",
      "resetting env. episode reward total was 4.0. running mean: -1.71414044626114\n",
      "resetting env. episode reward total was 6.0. running mean: -1.6369990417985285\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6706290513805433\n",
      "resetting env. episode reward total was 5.0. running mean: -1.603922760866738\n",
      "resetting env. episode reward total was -7.0. running mean: -1.6578835332580706\n",
      "resetting env. episode reward total was 3.0. running mean: -1.61130469792549\n",
      "resetting env. episode reward total was 10.0. running mean: -1.4951916509462349\n",
      "resetting env. episode reward total was 1.0. running mean: -1.4702397344367726\n",
      "resetting env. episode reward total was -1.0. running mean: -1.4655373370924047\n",
      "resetting env. episode reward total was 3.0. running mean: -1.4208819637214807\n",
      "resetting env. episode reward total was 7.0. running mean: -1.3366731440842659\n",
      "resetting env. episode reward total was -6.0. running mean: -1.3833064126434231\n",
      "resetting env. episode reward total was 6.0. running mean: -1.309473348516989\n",
      "resetting env. episode reward total was 5.0. running mean: -1.246378615031819\n",
      "resetting env. episode reward total was 4.0. running mean: -1.1939148288815007\n",
      "resetting env. episode reward total was 1.0. running mean: -1.1719756805926858\n",
      "resetting env. episode reward total was -1.0. running mean: -1.170255923786759\n",
      "resetting env. episode reward total was -1.0. running mean: -1.1685533645488912\n",
      "resetting env. episode reward total was -4.0. running mean: -1.1968678309034024\n",
      "resetting env. episode reward total was -4.0. running mean: -1.2248991525943684\n",
      "resetting env. episode reward total was -5.0. running mean: -1.2626501610684249\n",
      "resetting env. episode reward total was 1.0. running mean: -1.2400236594577405\n",
      "resetting env. episode reward total was 5.0. running mean: -1.177623422863163\n",
      "resetting env. episode reward total was -5.0. running mean: -1.2158471886345315\n",
      "resetting env. episode reward total was -8.0. running mean: -1.2836887167481863\n",
      "resetting env. episode reward total was 5.0. running mean: -1.2208518295807045\n",
      "resetting env. episode reward total was 6.0. running mean: -1.1486433112848973\n",
      "resetting env. episode reward total was 9.0. running mean: -1.0471568781720482\n",
      "resetting env. episode reward total was -2.0. running mean: -1.0566853093903277\n",
      "resetting env. episode reward total was -3.0. running mean: -1.0761184562964243\n",
      "resetting env. episode reward total was -3.0. running mean: -1.09535727173346\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1144036990161255\n",
      "resetting env. episode reward total was -7.0. running mean: -1.1732596620259643\n",
      "resetting env. episode reward total was -9.0. running mean: -1.2515270654057047\n",
      "resetting env. episode reward total was -5.0. running mean: -1.2890117947516477\n",
      "resetting env. episode reward total was -2.0. running mean: -1.2961216768041313\n",
      "resetting env. episode reward total was 9.0. running mean: -1.1931604600360899\n",
      "resetting env. episode reward total was 4.0. running mean: -1.141228855435729\n",
      "resetting env. episode reward total was -14.0. running mean: -1.2698165668813717\n",
      "resetting env. episode reward total was -5.0. running mean: -1.307118401212558\n",
      "resetting env. episode reward total was 10.0. running mean: -1.1940472172004324\n",
      "resetting env. episode reward total was -1.0. running mean: -1.1921067450284282\n",
      "resetting env. episode reward total was 9.0. running mean: -1.0901856775781438\n",
      "resetting env. episode reward total was -11.0. running mean: -1.1892838208023624\n",
      "resetting env. episode reward total was -4.0. running mean: -1.2173909825943388\n",
      "resetting env. episode reward total was -5.0. running mean: -1.2552170727683953\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2526649020407115\n",
      "resetting env. episode reward total was -4.0. running mean: -1.2801382530203043\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2773368704901011\n",
      "resetting env. episode reward total was 3.0. running mean: -1.2345635017852001\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2322178667673482\n",
      "resetting env. episode reward total was 11.0. running mean: -1.1098956880996746\n",
      "resetting env. episode reward total was 4.0. running mean: -1.058796731218678\n",
      "resetting env. episode reward total was -4.0. running mean: -1.0882087639064912\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1073266762674263\n",
      "resetting env. episode reward total was 1.0. running mean: -1.086253409504752\n",
      "resetting env. episode reward total was -4.0. running mean: -1.1153908754097046\n",
      "resetting env. episode reward total was 1.0. running mean: -1.0942369666556075\n",
      "resetting env. episode reward total was 1.0. running mean: -1.0732945969890515\n",
      "resetting env. episode reward total was -5.0. running mean: -1.112561651019161\n",
      "resetting env. episode reward total was 2.0. running mean: -1.0814360345089693\n",
      "resetting env. episode reward total was 7.0. running mean: -1.0006216741638796\n",
      "resetting env. episode reward total was -2.0. running mean: -1.0106154574222408\n",
      "resetting env. episode reward total was -3.0. running mean: -1.0305093028480183\n",
      "resetting env. episode reward total was -4.0. running mean: -1.0602042098195381\n",
      "resetting env. episode reward total was 2.0. running mean: -1.0296021677213427\n",
      "resetting env. episode reward total was 2.0. running mean: -0.9993061460441293\n",
      "resetting env. episode reward total was 7.0. running mean: -0.9193130845836879\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9801199537378511\n",
      "resetting env. episode reward total was 1.0. running mean: -0.9603187542004725\n",
      "resetting env. episode reward total was 12.0. running mean: -0.8307155666584678\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8024084109918831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: -0.7643843268819642\n",
      "resetting env. episode reward total was 2.0. running mean: -0.7367404836131446\n",
      "resetting env. episode reward total was -15.0. running mean: -0.8793730787770132\n",
      "resetting env. episode reward total was -2.0. running mean: -0.8905793479892431\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8416735545093507\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8632568189642572\n",
      "resetting env. episode reward total was -2.0. running mean: -0.8746242507746147\n",
      "resetting env. episode reward total was 3.0. running mean: -0.8358780082668685\n",
      "resetting env. episode reward total was 6.0. running mean: -0.7675192281841998\n",
      "resetting env. episode reward total was 6.0. running mean: -0.6998440359023579\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7628455955433342\n",
      "resetting env. episode reward total was 12.0. running mean: -0.6352171395879008\n",
      "resetting env. episode reward total was 2.0. running mean: -0.6088649681920217\n",
      "resetting env. episode reward total was -12.0. running mean: -0.7227763185101015\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7855485553250006\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8376930697717506\n",
      "resetting env. episode reward total was -8.0. running mean: -0.9093161390740331\n",
      "resetting env. episode reward total was -3.0. running mean: -0.9302229776832928\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9909207479064599\n",
      "resetting env. episode reward total was 12.0. running mean: -0.8610115404273952\n",
      "resetting env. episode reward total was 3.0. running mean: -0.8224014250231213\n",
      "resetting env. episode reward total was 8.0. running mean: -0.7341774107728901\n",
      "resetting env. episode reward total was -9.0. running mean: -0.8168356366651611\n",
      "resetting env. episode reward total was 14.0. running mean: -0.6686672802985095\n",
      "resetting env. episode reward total was -9.0. running mean: -0.7519806074955244\n",
      "resetting env. episode reward total was -9.0. running mean: -0.8344608014205691\n",
      "resetting env. episode reward total was -2.0. running mean: -0.8461161934063635\n",
      "resetting env. episode reward total was 3.0. running mean: -0.8076550314722998\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8595784811575768\n",
      "resetting env. episode reward total was -6.0. running mean: -0.910982696346001\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8818728693825411\n",
      "resetting env. episode reward total was -6.0. running mean: -0.9330541406887156\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9937235992818285\n",
      "resetting env. episode reward total was 11.0. running mean: -0.8737863632890103\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8750484996561202\n",
      "resetting env. episode reward total was 2.0. running mean: -0.846298014659559\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8878350345129634\n",
      "resetting env. episode reward total was -13.0. running mean: -1.008956684167834\n",
      "resetting env. episode reward total was -7.0. running mean: -1.0688671173261555\n",
      "resetting env. episode reward total was -1.0. running mean: -1.0681784461528938\n",
      "resetting env. episode reward total was 7.0. running mean: -0.9874966616913647\n",
      "resetting env. episode reward total was -7.0. running mean: -1.047621695074451\n",
      "resetting env. episode reward total was 1.0. running mean: -1.0271454781237066\n",
      "resetting env. episode reward total was 3.0. running mean: -0.9868740233424695\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9870052831090449\n",
      "resetting env. episode reward total was -9.0. running mean: -1.0671352302779544\n",
      "resetting env. episode reward total was -11.0. running mean: -1.166463877975175\n",
      "resetting env. episode reward total was -11.0. running mean: -1.2647992391954235\n",
      "resetting env. episode reward total was 2.0. running mean: -1.2321512468034692\n",
      "resetting env. episode reward total was 5.0. running mean: -1.1698297343354345\n",
      "resetting env. episode reward total was 7.0. running mean: -1.08813143699208\n",
      "resetting env. episode reward total was 7.0. running mean: -1.007250122622159\n",
      "resetting env. episode reward total was -6.0. running mean: -1.0571776213959374\n",
      "resetting env. episode reward total was 1.0. running mean: -1.036605845181978\n",
      "resetting env. episode reward total was 1.0. running mean: -1.0162397867301582\n",
      "resetting env. episode reward total was 2.0. running mean: -0.9860773888628567\n",
      "resetting env. episode reward total was 7.0. running mean: -0.9062166149742281\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8571544488244858\n",
      "resetting env. episode reward total was -8.0. running mean: -0.9285829043362409\n",
      "resetting env. episode reward total was 1.0. running mean: -0.9092970752928785\n",
      "resetting env. episode reward total was -3.0. running mean: -0.9302041045399497\n",
      "resetting env. episode reward total was 1.0. running mean: -0.9109020634945502\n",
      "resetting env. episode reward total was -3.0. running mean: -0.9317930428596046\n",
      "resetting env. episode reward total was 3.0. running mean: -0.8924751124310085\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8635503613066984\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8149148576936314\n",
      "resetting env. episode reward total was 3.0. running mean: -0.7767657091166951\n",
      "resetting env. episode reward total was 1.0. running mean: -0.7589980520255281\n",
      "resetting env. episode reward total was -8.0. running mean: -0.8314080715052727\n",
      "resetting env. episode reward total was 5.0. running mean: -0.77309399079022\n",
      "resetting env. episode reward total was 12.0. running mean: -0.6453630508823178\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6489094203734946\n",
      "resetting env. episode reward total was 7.0. running mean: -0.5724203261697596\n",
      "resetting env. episode reward total was 4.0. running mean: -0.5266961229080619\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5514291616789813\n",
      "resetting env. episode reward total was -2.0. running mean: -0.5659148700621914\n",
      "resetting env. episode reward total was -4.0. running mean: -0.6002557213615696\n",
      "resetting env. episode reward total was -2.0. running mean: -0.6142531641479538\n",
      "resetting env. episode reward total was -2.0. running mean: -0.6281106325064743\n",
      "resetting env. episode reward total was 2.0. running mean: -0.6018295261814095\n",
      "resetting env. episode reward total was 6.0. running mean: -0.5358112309195955\n",
      "resetting env. episode reward total was -5.0. running mean: -0.5804531186103996\n",
      "resetting env. episode reward total was -7.0. running mean: -0.6446485874242955\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6482021015500525\n",
      "resetting env. episode reward total was -5.0. running mean: -0.691720080534552\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7548028797292066\n",
      "resetting env. episode reward total was 5.0. running mean: -0.6972548509319144\n",
      "resetting env. episode reward total was 15.0. running mean: -0.5402823024225952\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5248794793983692\n",
      "resetting env. episode reward total was -2.0. running mean: -0.5396306846043856\n",
      "resetting env. episode reward total was 9.0. running mean: -0.44423437775834174\n",
      "resetting env. episode reward total was -6.0. running mean: -0.49979203398075833\n",
      "resetting env. episode reward total was 4.0. running mean: -0.4547941136409508\n",
      "resetting env. episode reward total was -6.0. running mean: -0.5102461725045413\n",
      "resetting env. episode reward total was 6.0. running mean: -0.4451437107794958\n",
      "resetting env. episode reward total was 2.0. running mean: -0.42069227367170087\n",
      "resetting env. episode reward total was 9.0. running mean: -0.3264853509349839\n",
      "resetting env. episode reward total was 2.0. running mean: -0.303220497425634\n",
      "resetting env. episode reward total was -3.0. running mean: -0.3301882924513777\n",
      "resetting env. episode reward total was -2.0. running mean: -0.34688640952686395\n",
      "resetting env. episode reward total was 2.0. running mean: -0.3234175454315953\n",
      "resetting env. episode reward total was -8.0. running mean: -0.4001833699772793\n",
      "resetting env. episode reward total was -8.0. running mean: -0.47618153627750653\n",
      "resetting env. episode reward total was -8.0. running mean: -0.5514197209147315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: -0.4959055237055841\n",
      "resetting env. episode reward total was 9.0. running mean: -0.4009464684685282\n",
      "resetting env. episode reward total was -5.0. running mean: -0.44693700378384293\n",
      "resetting env. episode reward total was 11.0. running mean: -0.3324676337460045\n",
      "resetting env. episode reward total was -12.0. running mean: -0.4491429574085445\n",
      "resetting env. episode reward total was 3.0. running mean: -0.414651527834459\n",
      "resetting env. episode reward total was 2.0. running mean: -0.3905050125561144\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4165999624305533\n",
      "resetting env. episode reward total was -9.0. running mean: -0.5024339628062477\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5074096231781853\n",
      "resetting env. episode reward total was 13.0. running mean: -0.3723355269464034\n",
      "resetting env. episode reward total was -6.0. running mean: -0.4286121716769393\n",
      "resetting env. episode reward total was -1.0. running mean: -0.43432604996016994\n",
      "resetting env. episode reward total was -7.0. running mean: -0.49998278946056823\n",
      "resetting env. episode reward total was -11.0. running mean: -0.6049829615659625\n",
      "resetting env. episode reward total was -5.0. running mean: -0.648933131950303\n",
      "resetting env. episode reward total was 12.0. running mean: -0.5224438006308\n",
      "resetting env. episode reward total was 13.0. running mean: -0.38721936262449197\n",
      "resetting env. episode reward total was -9.0. running mean: -0.473347168998247\n",
      "resetting env. episode reward total was -4.0. running mean: -0.5086136973082646\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5335275603351819\n",
      "resetting env. episode reward total was 2.0. running mean: -0.5081922847318301\n",
      "resetting env. episode reward total was -8.0. running mean: -0.5831103618845117\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5872792582656666\n",
      "resetting env. episode reward total was -7.0. running mean: -0.6514064656830099\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6948924010261798\n",
      "resetting env. episode reward total was 2.0. running mean: -0.6679434770159179\n",
      "resetting env. episode reward total was 8.0. running mean: -0.5812640422457588\n",
      "resetting env. episode reward total was 4.0. running mean: -0.5354514018233012\n",
      "resetting env. episode reward total was -9.0. running mean: -0.6200968878050681\n",
      "resetting env. episode reward total was -3.0. running mean: -0.6438959189270175\n",
      "resetting env. episode reward total was -9.0. running mean: -0.7274569597377473\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7901823901403697\n",
      "resetting env. episode reward total was 1.0. running mean: -0.772280566238966\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8245577605765764\n",
      "resetting env. episode reward total was 1.0. running mean: -0.8063121829708106\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8282490611411025\n",
      "resetting env. episode reward total was -10.0. running mean: -0.9199665705296914\n",
      "resetting env. episode reward total was 5.0. running mean: -0.8607669048243944\n",
      "resetting env. episode reward total was -2.0. running mean: -0.8721592357761505\n",
      "resetting env. episode reward total was 2.0. running mean: -0.843437643418389\n",
      "resetting env. episode reward total was 9.0. running mean: -0.7450032669842052\n",
      "resetting env. episode reward total was -1.0. running mean: -0.7475532343143632\n",
      "resetting env. episode reward total was 7.0. running mean: -0.6700777019712194\n",
      "resetting env. episode reward total was 6.0. running mean: -0.6033769249515073\n",
      "resetting env. episode reward total was -9.0. running mean: -0.6873431557019922\n",
      "resetting env. episode reward total was 4.0. running mean: -0.6404697241449723\n",
      "resetting env. episode reward total was 8.0. running mean: -0.5540650269035226\n",
      "resetting env. episode reward total was -4.0. running mean: -0.5885243766344873\n",
      "resetting env. episode reward total was 5.0. running mean: -0.5326391328681424\n",
      "resetting env. episode reward total was -7.0. running mean: -0.597312741539461\n",
      "resetting env. episode reward total was -7.0. running mean: -0.6613396141240664\n",
      "resetting env. episode reward total was 7.0. running mean: -0.5847262179828256\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6288789558029975\n",
      "resetting env. episode reward total was 5.0. running mean: -0.5725901662449674\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6168642645825178\n",
      "resetting env. episode reward total was -4.0. running mean: -0.6506956219366926\n",
      "resetting env. episode reward total was -4.0. running mean: -0.6841886657173257\n",
      "resetting env. episode reward total was -9.0. running mean: -0.7673467790601525\n",
      "resetting env. episode reward total was 4.0. running mean: -0.7196733112695509\n",
      "resetting env. episode reward total was 2.0. running mean: -0.6924765781568554\n",
      "resetting env. episode reward total was -4.0. running mean: -0.7255518123752869\n",
      "resetting env. episode reward total was 8.0. running mean: -0.638296294251534\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6819133313090187\n",
      "resetting env. episode reward total was 6.0. running mean: -0.6150941979959286\n",
      "resetting env. episode reward total was 9.0. running mean: -0.5189432560159694\n",
      "resetting env. episode reward total was -7.0. running mean: -0.5837538234558097\n",
      "resetting env. episode reward total was -3.0. running mean: -0.6079162852212516\n",
      "resetting env. episode reward total was -10.0. running mean: -0.7018371223690391\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7648187511453486\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8171705636338951\n",
      "resetting env. episode reward total was 1.0. running mean: -0.7989988579975561\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8210088694175806\n",
      "resetting env. episode reward total was -7.0. running mean: -0.8827987807234048\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9439707929161707\n",
      "resetting env. episode reward total was -9.0. running mean: -1.024531084987009\n",
      "resetting env. episode reward total was 2.0. running mean: -0.9942857741371389\n",
      "resetting env. episode reward total was -10.0. running mean: -1.0843429163957676\n",
      "resetting env. episode reward total was -5.0. running mean: -1.12349948723181\n",
      "resetting env. episode reward total was -5.0. running mean: -1.162264492359492\n",
      "resetting env. episode reward total was 5.0. running mean: -1.100641847435897\n",
      "resetting env. episode reward total was -3.0. running mean: -1.119635428961538\n",
      "resetting env. episode reward total was -7.0. running mean: -1.1784390746719227\n",
      "resetting env. episode reward total was -1.0. running mean: -1.1766546839252034\n",
      "resetting env. episode reward total was 10.0. running mean: -1.0648881370859513\n",
      "resetting env. episode reward total was 3.0. running mean: -1.0242392557150917\n",
      "resetting env. episode reward total was -3.0. running mean: -1.0439968631579408\n",
      "resetting env. episode reward total was 2.0. running mean: -1.0135568945263613\n",
      "resetting env. episode reward total was 7.0. running mean: -0.9334213255810977\n",
      "resetting env. episode reward total was -13.0. running mean: -1.0540871123252868\n",
      "resetting env. episode reward total was -5.0. running mean: -1.093546241202034\n",
      "resetting env. episode reward total was -8.0. running mean: -1.1626107787900137\n",
      "resetting env. episode reward total was -4.0. running mean: -1.1909846710021137\n",
      "resetting env. episode reward total was -1.0. running mean: -1.1890748242920925\n",
      "resetting env. episode reward total was -5.0. running mean: -1.2271840760491717\n",
      "resetting env. episode reward total was 3.0. running mean: -1.1849122352886798\n",
      "resetting env. episode reward total was 1.0. running mean: -1.1630631129357931\n",
      "resetting env. episode reward total was -11.0. running mean: -1.2614324818064353\n",
      "resetting env. episode reward total was 7.0. running mean: -1.178818156988371\n",
      "resetting env. episode reward total was 2.0. running mean: -1.1470299754184872\n",
      "resetting env. episode reward total was 6.0. running mean: -1.0755596756643022\n",
      "resetting env. episode reward total was -4.0. running mean: -1.1048040789076592\n",
      "resetting env. episode reward total was 6.0. running mean: -1.0337560381185826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -6.0. running mean: -1.0834184777373967\n",
      "resetting env. episode reward total was -1.0. running mean: -1.0825842929600227\n",
      "resetting env. episode reward total was -12.0. running mean: -1.1917584500304224\n",
      "resetting env. episode reward total was -2.0. running mean: -1.199840865530118\n",
      "resetting env. episode reward total was -12.0. running mean: -1.307842456874817\n",
      "resetting env. episode reward total was 3.0. running mean: -1.264764032306069\n",
      "resetting env. episode reward total was -3.0. running mean: -1.2821163919830083\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2792952280631782\n",
      "resetting env. episode reward total was 11.0. running mean: -1.1565022757825463\n",
      "resetting env. episode reward total was -10.0. running mean: -1.244937253024721\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2424878804944737\n",
      "resetting env. episode reward total was 5.0. running mean: -1.1800630016895288\n",
      "resetting env. episode reward total was -5.0. running mean: -1.2182623716726335\n",
      "resetting env. episode reward total was 4.0. running mean: -1.166079747955907\n",
      "resetting env. episode reward total was -5.0. running mean: -1.204418950476348\n",
      "resetting env. episode reward total was 2.0. running mean: -1.1723747609715847\n",
      "resetting env. episode reward total was -6.0. running mean: -1.2206510133618689\n",
      "resetting env. episode reward total was 2.0. running mean: -1.1884445032282502\n",
      "resetting env. episode reward total was -4.0. running mean: -1.2165600581959677\n",
      "resetting env. episode reward total was -9.0. running mean: -1.294394457614008\n",
      "resetting env. episode reward total was 2.0. running mean: -1.261450513037868\n",
      "resetting env. episode reward total was 2.0. running mean: -1.2288360079074891\n",
      "resetting env. episode reward total was -7.0. running mean: -1.2865476478284144\n",
      "resetting env. episode reward total was -5.0. running mean: -1.3236821713501303\n",
      "resetting env. episode reward total was -11.0. running mean: -1.4204453496366292\n",
      "resetting env. episode reward total was -9.0. running mean: -1.496240896140263\n",
      "resetting env. episode reward total was 2.0. running mean: -1.4612784871788602\n",
      "resetting env. episode reward total was 6.0. running mean: -1.3866657023070716\n",
      "resetting env. episode reward total was -7.0. running mean: -1.442799045284001\n",
      "resetting env. episode reward total was -5.0. running mean: -1.478371054831161\n",
      "resetting env. episode reward total was 9.0. running mean: -1.3735873442828495\n",
      "resetting env. episode reward total was -12.0. running mean: -1.4798514708400208\n",
      "resetting env. episode reward total was 3.0. running mean: -1.4350529561316205\n",
      "resetting env. episode reward total was 6.0. running mean: -1.3607024265703043\n",
      "resetting env. episode reward total was 2.0. running mean: -1.327095402304601\n",
      "resetting env. episode reward total was 3.0. running mean: -1.283824448281555\n",
      "resetting env. episode reward total was 8.0. running mean: -1.1909862037987395\n",
      "resetting env. episode reward total was -4.0. running mean: -1.2190763417607522\n",
      "resetting env. episode reward total was -2.0. running mean: -1.2268855783431447\n",
      "resetting env. episode reward total was 2.0. running mean: -1.1946167225597133\n",
      "resetting env. episode reward total was 5.0. running mean: -1.132670555334116\n",
      "resetting env. episode reward total was 7.0. running mean: -1.0513438497807748\n",
      "resetting env. episode reward total was 6.0. running mean: -0.9808304112829669\n",
      "resetting env. episode reward total was 6.0. running mean: -0.9110221071701372\n",
      "resetting env. episode reward total was -6.0. running mean: -0.9619118860984359\n",
      "resetting env. episode reward total was 3.0. running mean: -0.9222927672374516\n",
      "resetting env. episode reward total was -1.0. running mean: -0.923069839565077\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8738391411694262\n",
      "resetting env. episode reward total was 5.0. running mean: -0.8151007497577318\n",
      "resetting env. episode reward total was 1.0. running mean: -0.7969497422601545\n",
      "resetting env. episode reward total was -7.0. running mean: -0.858980244837553\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8603904423891775\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8317865379652857\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8834686725856329\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8846339858597766\n",
      "resetting env. episode reward total was 15.0. running mean: -0.7257876460011788\n",
      "resetting env. episode reward total was 8.0. running mean: -0.6385297695411671\n",
      "resetting env. episode reward total was -2.0. running mean: -0.6521444718457555\n",
      "resetting env. episode reward total was 9.0. running mean: -0.5556230271272979\n",
      "resetting env. episode reward total was -9.0. running mean: -0.640066796856025\n",
      "resetting env. episode reward total was 4.0. running mean: -0.5936661288874647\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5777294675985901\n",
      "resetting env. episode reward total was 6.0. running mean: -0.5119521729226042\n",
      "resetting env. episode reward total was 6.0. running mean: -0.44683265119337817\n",
      "resetting env. episode reward total was -1.0. running mean: -0.4523643246814444\n",
      "resetting env. episode reward total was 9.0. running mean: -0.35784068143463\n",
      "resetting env. episode reward total was -5.0. running mean: -0.4042622746202837\n",
      "resetting env. episode reward total was 8.0. running mean: -0.32021965187408086\n",
      "resetting env. episode reward total was -1.0. running mean: -0.32701745535534005\n",
      "resetting env. episode reward total was 4.0. running mean: -0.2837472808017867\n",
      "resetting env. episode reward total was -5.0. running mean: -0.3309098079937688\n",
      "resetting env. episode reward total was 5.0. running mean: -0.2776007099138311\n",
      "resetting env. episode reward total was 2.0. running mean: -0.25482470281469277\n",
      "resetting env. episode reward total was 8.0. running mean: -0.17227645578654582\n",
      "resetting env. episode reward total was -11.0. running mean: -0.28055369122868035\n",
      "resetting env. episode reward total was -11.0. running mean: -0.38774815431639353\n",
      "resetting env. episode reward total was 10.0. running mean: -0.28387067277322964\n",
      "resetting env. episode reward total was -3.0. running mean: -0.3110319660454973\n",
      "resetting env. episode reward total was 5.0. running mean: -0.25792164638504234\n",
      "resetting env. episode reward total was 3.0. running mean: -0.22534242992119188\n",
      "resetting env. episode reward total was -2.0. running mean: -0.24308900562197996\n",
      "resetting env. episode reward total was -5.0. running mean: -0.29065811556576016\n",
      "resetting env. episode reward total was 1.0. running mean: -0.27775153441010253\n",
      "resetting env. episode reward total was -1.0. running mean: -0.2849740190660015\n",
      "resetting env. episode reward total was 4.0. running mean: -0.24212427887534146\n",
      "resetting env. episode reward total was 6.0. running mean: -0.17970303608658805\n",
      "resetting env. episode reward total was 4.0. running mean: -0.13790600572572217\n",
      "resetting env. episode reward total was 8.0. running mean: -0.05652694566846496\n",
      "resetting env. episode reward total was 5.0. running mean: -0.005961676211780308\n",
      "resetting env. episode reward total was 6.0. running mean: 0.054097940550337495\n",
      "resetting env. episode reward total was -5.0. running mean: 0.0035569611448341143\n",
      "resetting env. episode reward total was 7.0. running mean: 0.07352139153338579\n",
      "resetting env. episode reward total was -11.0. running mean: -0.03721382238194808\n",
      "resetting env. episode reward total was 11.0. running mean: 0.07315831584187141\n",
      "resetting env. episode reward total was -13.0. running mean: -0.057573267316547314\n",
      "resetting env. episode reward total was 11.0. running mean: 0.05300246535661816\n",
      "resetting env. episode reward total was -11.0. running mean: -0.05752755929694803\n",
      "resetting env. episode reward total was -6.0. running mean: -0.11695228370397855\n",
      "resetting env. episode reward total was -10.0. running mean: -0.21578276086693876\n",
      "resetting env. episode reward total was 1.0. running mean: -0.20362493325826936\n",
      "resetting env. episode reward total was 4.0. running mean: -0.16158868392568665\n",
      "resetting env. episode reward total was 8.0. running mean: -0.07997279708642978\n",
      "resetting env. episode reward total was 9.0. running mean: 0.01082693088443451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 0.10071866157559016\n",
      "resetting env. episode reward total was 8.0. running mean: 0.17971147495983425\n",
      "resetting env. episode reward total was -2.0. running mean: 0.15791436021023592\n",
      "resetting env. episode reward total was -3.0. running mean: 0.12633521660813354\n",
      "resetting env. episode reward total was -5.0. running mean: 0.0750718644420522\n",
      "resetting env. episode reward total was -6.0. running mean: 0.014321145797631676\n",
      "resetting env. episode reward total was -5.0. running mean: -0.03582206566034464\n",
      "resetting env. episode reward total was 14.0. running mean: 0.10453615499625882\n",
      "resetting env. episode reward total was -4.0. running mean: 0.06349079344629624\n",
      "resetting env. episode reward total was 9.0. running mean: 0.15285588551183327\n",
      "resetting env. episode reward total was -9.0. running mean: 0.06132732665671495\n",
      "resetting env. episode reward total was -6.0. running mean: 0.0007140533901478022\n",
      "resetting env. episode reward total was -10.0. running mean: -0.09929308714375368\n",
      "resetting env. episode reward total was 4.0. running mean: -0.05830015627231614\n",
      "resetting env. episode reward total was -7.0. running mean: -0.127717154709593\n",
      "resetting env. episode reward total was 7.0. running mean: -0.05643998316249707\n",
      "resetting env. episode reward total was -4.0. running mean: -0.0958755833308721\n",
      "resetting env. episode reward total was 4.0. running mean: -0.054916827497563374\n",
      "resetting env. episode reward total was -12.0. running mean: -0.17436765922258773\n",
      "resetting env. episode reward total was -3.0. running mean: -0.20262398263036185\n",
      "resetting env. episode reward total was 8.0. running mean: -0.12059774280405823\n",
      "resetting env. episode reward total was 3.0. running mean: -0.08939176537601765\n",
      "resetting env. episode reward total was 2.0. running mean: -0.06849784772225746\n",
      "resetting env. episode reward total was -9.0. running mean: -0.1578128692450349\n",
      "resetting env. episode reward total was 6.0. running mean: -0.09623474055258455\n",
      "resetting env. episode reward total was 3.0. running mean: -0.0652723931470587\n",
      "resetting env. episode reward total was -2.0. running mean: -0.08461966921558811\n",
      "resetting env. episode reward total was 4.0. running mean: -0.04377347252343223\n",
      "resetting env. episode reward total was -2.0. running mean: -0.0633357377981979\n",
      "resetting env. episode reward total was -3.0. running mean: -0.09270238042021592\n",
      "resetting env. episode reward total was 12.0. running mean: 0.02822464338398624\n",
      "resetting env. episode reward total was 2.0. running mean: 0.047942396950146376\n",
      "resetting env. episode reward total was 10.0. running mean: 0.14746297298064492\n",
      "resetting env. episode reward total was -5.0. running mean: 0.09598834325083848\n",
      "resetting env. episode reward total was -1.0. running mean: 0.0850284598183301\n",
      "resetting env. episode reward total was -15.0. running mean: -0.0658218247798532\n",
      "resetting env. episode reward total was 7.0. running mean: 0.0048363934679453435\n",
      "resetting env. episode reward total was 7.0. running mean: 0.0747880295332659\n",
      "resetting env. episode reward total was 6.0. running mean: 0.13404014923793323\n",
      "resetting env. episode reward total was -13.0. running mean: 0.0026997477455538987\n",
      "resetting env. episode reward total was 4.0. running mean: 0.04267275026809836\n",
      "resetting env. episode reward total was -6.0. running mean: -0.01775397723458262\n",
      "resetting env. episode reward total was -11.0. running mean: -0.1275764374622368\n",
      "resetting env. episode reward total was 3.0. running mean: -0.09630067308761442\n",
      "resetting env. episode reward total was -11.0. running mean: -0.20533766635673828\n",
      "resetting env. episode reward total was -1.0. running mean: -0.2132842896931709\n",
      "resetting env. episode reward total was 2.0. running mean: -0.1911514467962392\n",
      "resetting env. episode reward total was -4.0. running mean: -0.2292399323282768\n",
      "resetting env. episode reward total was -4.0. running mean: -0.266947533004994\n",
      "resetting env. episode reward total was -7.0. running mean: -0.33427805767494406\n",
      "resetting env. episode reward total was 3.0. running mean: -0.30093527709819456\n",
      "resetting env. episode reward total was -9.0. running mean: -0.3879259243272126\n",
      "resetting env. episode reward total was -9.0. running mean: -0.47404666508394044\n",
      "resetting env. episode reward total was -9.0. running mean: -0.559306198433101\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5437131364487701\n",
      "resetting env. episode reward total was -7.0. running mean: -0.6082760050842824\n",
      "resetting env. episode reward total was 8.0. running mean: -0.5221932450334396\n",
      "resetting env. episode reward total was 5.0. running mean: -0.46697131258310515\n",
      "resetting env. episode reward total was 10.0. running mean: -0.36230159945727414\n",
      "resetting env. episode reward total was -1.0. running mean: -0.3686785834627014\n",
      "resetting env. episode reward total was -8.0. running mean: -0.4449917976280744\n",
      "resetting env. episode reward total was -17.0. running mean: -0.6105418796517936\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6144364608552757\n",
      "resetting env. episode reward total was 3.0. running mean: -0.578292096246723\n",
      "resetting env. episode reward total was 3.0. running mean: -0.5425091752842557\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5270840835314131\n",
      "resetting env. episode reward total was -4.0. running mean: -0.561813242696099\n",
      "resetting env. episode reward total was 3.0. running mean: -0.526195110269138\n",
      "resetting env. episode reward total was 4.0. running mean: -0.4809331591664467\n",
      "resetting env. episode reward total was 2.0. running mean: -0.4561238275747822\n",
      "resetting env. episode reward total was -7.0. running mean: -0.5215625892990343\n",
      "resetting env. episode reward total was 8.0. running mean: -0.436346963406044\n",
      "resetting env. episode reward total was 3.0. running mean: -0.4019834937719836\n",
      "resetting env. episode reward total was 6.0. running mean: -0.33796365883426377\n",
      "resetting env. episode reward total was 1.0. running mean: -0.32458402224592114\n",
      "resetting env. episode reward total was -6.0. running mean: -0.3813381820234619\n",
      "resetting env. episode reward total was 9.0. running mean: -0.28752480020322735\n",
      "resetting env. episode reward total was 1.0. running mean: -0.2746495522011951\n",
      "resetting env. episode reward total was 2.0. running mean: -0.2519030566791831\n",
      "resetting env. episode reward total was -6.0. running mean: -0.30938402611239124\n",
      "resetting env. episode reward total was 3.0. running mean: -0.2762901858512673\n",
      "resetting env. episode reward total was -8.0. running mean: -0.3535272839927546\n",
      "resetting env. episode reward total was 4.0. running mean: -0.3099920111528271\n",
      "resetting env. episode reward total was -9.0. running mean: -0.39689209104129886\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4229231701308859\n",
      "resetting env. episode reward total was -3.0. running mean: -0.44869393842957705\n",
      "resetting env. episode reward total was -11.0. running mean: -0.5542069990452813\n",
      "resetting env. episode reward total was -11.0. running mean: -0.6586649290548284\n",
      "resetting env. episode reward total was -3.0. running mean: -0.6820782797642801\n",
      "resetting env. episode reward total was -3.0. running mean: -0.7052574969666374\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7682049219969711\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8105228727770014\n",
      "resetting env. episode reward total was 10.0. running mean: -0.7024176440492315\n",
      "resetting env. episode reward total was 4.0. running mean: -0.6553934676087391\n",
      "resetting env. episode reward total was -8.0. running mean: -0.7288395329326516\n",
      "resetting env. episode reward total was -1.0. running mean: -0.731551137603325\n",
      "resetting env. episode reward total was 11.0. running mean: -0.6142356262272918\n",
      "resetting env. episode reward total was -7.0. running mean: -0.6780932699650188\n",
      "resetting env. episode reward total was -6.0. running mean: -0.7313123372653687\n",
      "resetting env. episode reward total was -1.0. running mean: -0.733999213892715\n",
      "resetting env. episode reward total was -7.0. running mean: -0.796659221753788\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8386926295362501\n",
      "resetting env. episode reward total was 5.0. running mean: -0.7803057032408875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: -0.7825026462084786\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8346776197463939\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8063308435489299\n",
      "resetting env. episode reward total was 3.0. running mean: -0.7682675351134406\n",
      "resetting env. episode reward total was 6.0. running mean: -0.7005848597623061\n",
      "resetting env. episode reward total was 9.0. running mean: -0.603579011164683\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5875432210530362\n",
      "resetting env. episode reward total was -3.0. running mean: -0.6116677888425059\n",
      "resetting env. episode reward total was 2.0. running mean: -0.5855511109540809\n",
      "resetting env. episode reward total was 5.0. running mean: -0.52969559984454\n",
      "resetting env. episode reward total was -13.0. running mean: -0.6543986438460946\n",
      "resetting env. episode reward total was -6.0. running mean: -0.7078546574076336\n",
      "resetting env. episode reward total was -6.0. running mean: -0.7607761108335573\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8131683497252218\n",
      "resetting env. episode reward total was 5.0. running mean: -0.7550366662279695\n",
      "resetting env. episode reward total was 5.0. running mean: -0.6974862995656897\n",
      "resetting env. episode reward total was 4.0. running mean: -0.6505114365700329\n",
      "resetting env. episode reward total was 5.0. running mean: -0.5940063222043325\n",
      "resetting env. episode reward total was 7.0. running mean: -0.5180662589822891\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5428855963924663\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5674567404285417\n",
      "resetting env. episode reward total was 6.0. running mean: -0.5017821730242562\n",
      "resetting env. episode reward total was -9.0. running mean: -0.5867643512940136\n",
      "resetting env. episode reward total was 5.0. running mean: -0.5308967077810735\n",
      "resetting env. episode reward total was 4.0. running mean: -0.48558774070326277\n",
      "resetting env. episode reward total was -8.0. running mean: -0.5607318632962301\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6051245446632679\n",
      "resetting env. episode reward total was -9.0. running mean: -0.6890732992166352\n",
      "resetting env. episode reward total was -4.0. running mean: -0.7221825662244689\n",
      "resetting env. episode reward total was 9.0. running mean: -0.6249607405622242\n",
      "resetting env. episode reward total was 4.0. running mean: -0.5787111331566019\n",
      "resetting env. episode reward total was -8.0. running mean: -0.6529240218250358\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6963947816067855\n",
      "resetting env. episode reward total was 8.0. running mean: -0.6094308337907176\n",
      "resetting env. episode reward total was 3.0. running mean: -0.5733365254528104\n",
      "resetting env. episode reward total was -2.0. running mean: -0.5876031601982824\n",
      "resetting env. episode reward total was 4.0. running mean: -0.5417271285962996\n",
      "resetting env. episode reward total was -9.0. running mean: -0.6263098573103365\n",
      "resetting env. episode reward total was 3.0. running mean: -0.5900467587372331\n",
      "resetting env. episode reward total was 3.0. running mean: -0.5541462911498608\n",
      "resetting env. episode reward total was -2.0. running mean: -0.5686048282383622\n",
      "resetting env. episode reward total was 12.0. running mean: -0.4429187799559786\n",
      "resetting env. episode reward total was 15.0. running mean: -0.2884895921564188\n",
      "resetting env. episode reward total was 3.0. running mean: -0.2556046962348546\n",
      "resetting env. episode reward total was 5.0. running mean: -0.20304864927250604\n",
      "resetting env. episode reward total was 5.0. running mean: -0.15101816277978097\n",
      "resetting env. episode reward total was 11.0. running mean: -0.03950798115198316\n",
      "resetting env. episode reward total was -3.0. running mean: -0.06911290134046333\n",
      "resetting env. episode reward total was 7.0. running mean: 0.0015782276729413153\n",
      "resetting env. episode reward total was 12.0. running mean: 0.1215624453962119\n",
      "resetting env. episode reward total was -3.0. running mean: 0.09034682094224979\n",
      "resetting env. episode reward total was 4.0. running mean: 0.12944335273282728\n",
      "resetting env. episode reward total was -3.0. running mean: 0.09814891920549901\n",
      "resetting env. episode reward total was -3.0. running mean: 0.06716743001344402\n",
      "resetting env. episode reward total was 5.0. running mean: 0.11649575571330958\n",
      "resetting env. episode reward total was 1.0. running mean: 0.12533079815617648\n",
      "resetting env. episode reward total was 8.0. running mean: 0.2040774901746147\n",
      "resetting env. episode reward total was 10.0. running mean: 0.30203671527286857\n",
      "resetting env. episode reward total was 11.0. running mean: 0.40901634812013987\n",
      "resetting env. episode reward total was 1.0. running mean: 0.4149261846389385\n",
      "resetting env. episode reward total was 2.0. running mean: 0.43077692279254914\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4464691535646237\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5020044620289774\n",
      "resetting env. episode reward total was 10.0. running mean: 0.5969844174086877\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6410145732346009\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6646044275022549\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6979583832272324\n",
      "resetting env. episode reward total was -5.0. running mean: 0.6409787993949599\n",
      "resetting env. episode reward total was 10.0. running mean: 0.7345690114010103\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6972233212870002\n",
      "resetting env. episode reward total was -5.0. running mean: 0.6402510880741301\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6238485771933888\n",
      "resetting env. episode reward total was 2.0. running mean: 0.637610091421455\n",
      "resetting env. episode reward total was -9.0. running mean: 0.5412339905072404\n",
      "resetting env. episode reward total was -7.0. running mean: 0.465821650602168\n",
      "resetting env. episode reward total was -13.0. running mean: 0.33116343409614635\n",
      "resetting env. episode reward total was 4.0. running mean: 0.36785179975518484\n",
      "resetting env. episode reward total was -13.0. running mean: 0.23417328175763297\n",
      "resetting env. episode reward total was -8.0. running mean: 0.15183154894005663\n",
      "resetting env. episode reward total was 12.0. running mean: 0.27031323345065605\n",
      "resetting env. episode reward total was -11.0. running mean: 0.15761010111614948\n",
      "resetting env. episode reward total was 11.0. running mean: 0.266034000104988\n",
      "resetting env. episode reward total was -5.0. running mean: 0.21337366010393816\n",
      "resetting env. episode reward total was 1.0. running mean: 0.22123992350289878\n",
      "resetting env. episode reward total was 10.0. running mean: 0.3190275242678698\n",
      "resetting env. episode reward total was -11.0. running mean: 0.20583724902519113\n",
      "resetting env. episode reward total was 5.0. running mean: 0.2537788765349392\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3012410877695898\n",
      "resetting env. episode reward total was 7.0. running mean: 0.3682286768918939\n",
      "resetting env. episode reward total was 2.0. running mean: 0.384546390122975\n",
      "resetting env. episode reward total was -2.0. running mean: 0.3607009262217452\n",
      "resetting env. episode reward total was 7.0. running mean: 0.42709391695952775\n",
      "resetting env. episode reward total was -12.0. running mean: 0.3028229777899325\n",
      "resetting env. episode reward total was 10.0. running mean: 0.3997947480120332\n",
      "resetting env. episode reward total was 6.0. running mean: 0.45579680053191285\n",
      "resetting env. episode reward total was -5.0. running mean: 0.4012388325265937\n",
      "resetting env. episode reward total was 1.0. running mean: 0.40722644420132775\n",
      "resetting env. episode reward total was 6.0. running mean: 0.46315417975931444\n",
      "resetting env. episode reward total was -1.0. running mean: 0.44852263796172126\n",
      "resetting env. episode reward total was -11.0. running mean: 0.33403741158210404\n",
      "resetting env. episode reward total was 6.0. running mean: 0.390697037466283\n",
      "resetting env. episode reward total was -2.0. running mean: 0.36679006709162015\n",
      "resetting env. episode reward total was 1.0. running mean: 0.37312216642070395\n",
      "resetting env. episode reward total was 3.0. running mean: 0.39939094475649695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: 0.425397035308932\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4411430649558427\n",
      "resetting env. episode reward total was -11.0. running mean: 0.32673163430628427\n",
      "resetting env. episode reward total was 3.0. running mean: 0.3534643179632214\n",
      "resetting env. episode reward total was -4.0. running mean: 0.30992967478358924\n",
      "resetting env. episode reward total was -1.0. running mean: 0.29683037803575335\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3438620742553958\n",
      "resetting env. episode reward total was 1.0. running mean: 0.3504234535128418\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3369192189777134\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3035500267879362\n",
      "resetting env. episode reward total was -7.0. running mean: 0.23051452652005683\n",
      "resetting env. episode reward total was 6.0. running mean: 0.2882093812548563\n",
      "resetting env. episode reward total was 3.0. running mean: 0.31532728744230776\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2821740145678847\n",
      "resetting env. episode reward total was -10.0. running mean: 0.17935227442220583\n",
      "resetting env. episode reward total was 3.0. running mean: 0.20755875167798377\n",
      "resetting env. episode reward total was -3.0. running mean: 0.17548316416120394\n",
      "resetting env. episode reward total was 13.0. running mean: 0.30372833251959186\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3506910491943959\n",
      "resetting env. episode reward total was -5.0. running mean: 0.29718413870245197\n",
      "resetting env. episode reward total was -9.0. running mean: 0.20421229731542748\n",
      "resetting env. episode reward total was 3.0. running mean: 0.2321701743422732\n",
      "resetting env. episode reward total was 6.0. running mean: 0.2898484725988505\n",
      "resetting env. episode reward total was 5.0. running mean: 0.33694998787286196\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3035804879941333\n",
      "resetting env. episode reward total was -13.0. running mean: 0.17054468311419196\n",
      "resetting env. episode reward total was -11.0. running mean: 0.05883923628305003\n",
      "resetting env. episode reward total was 4.0. running mean: 0.09825084392021953\n",
      "resetting env. episode reward total was 4.0. running mean: 0.13726833548101733\n",
      "resetting env. episode reward total was -2.0. running mean: 0.11589565212620716\n",
      "resetting env. episode reward total was 5.0. running mean: 0.16473669560494508\n",
      "resetting env. episode reward total was -5.0. running mean: 0.11308932864889563\n",
      "resetting env. episode reward total was 8.0. running mean: 0.1919584353624067\n",
      "resetting env. episode reward total was -8.0. running mean: 0.11003885100878262\n",
      "resetting env. episode reward total was 1.0. running mean: 0.11893846249869479\n",
      "resetting env. episode reward total was 3.0. running mean: 0.14774907787370783\n",
      "resetting env. episode reward total was 9.0. running mean: 0.23627158709497076\n",
      "resetting env. episode reward total was -5.0. running mean: 0.18390887122402105\n",
      "resetting env. episode reward total was 2.0. running mean: 0.20206978251178084\n",
      "resetting env. episode reward total was 5.0. running mean: 0.25004908468666304\n",
      "resetting env. episode reward total was 4.0. running mean: 0.2875485938397964\n",
      "resetting env. episode reward total was -9.0. running mean: 0.19467310790139844\n",
      "resetting env. episode reward total was 13.0. running mean: 0.3227263768223845\n",
      "resetting env. episode reward total was -5.0. running mean: 0.26949911305416063\n",
      "resetting env. episode reward total was -1.0. running mean: 0.256804121923619\n",
      "resetting env. episode reward total was -6.0. running mean: 0.1942360807043828\n",
      "resetting env. episode reward total was 4.0. running mean: 0.232293719897339\n",
      "resetting env. episode reward total was -8.0. running mean: 0.1499707826983656\n",
      "resetting env. episode reward total was 7.0. running mean: 0.21847107487138195\n",
      "resetting env. episode reward total was -6.0. running mean: 0.15628636412266814\n",
      "resetting env. episode reward total was -6.0. running mean: 0.09472350048144146\n",
      "resetting env. episode reward total was 4.0. running mean: 0.13377626547662705\n",
      "resetting env. episode reward total was 4.0. running mean: 0.1724385028218608\n",
      "resetting env. episode reward total was -8.0. running mean: 0.09071411779364218\n",
      "resetting env. episode reward total was 6.0. running mean: 0.14980697661570574\n",
      "resetting env. episode reward total was -11.0. running mean: 0.0383089068495487\n",
      "resetting env. episode reward total was -9.0. running mean: -0.05207418221894679\n",
      "resetting env. episode reward total was 3.0. running mean: -0.02155344039675732\n",
      "resetting env. episode reward total was 3.0. running mean: 0.008662094007210252\n",
      "resetting env. episode reward total was -1.0. running mean: -0.0014245269328618509\n",
      "resetting env. episode reward total was 7.0. running mean: 0.06858971833646678\n",
      "resetting env. episode reward total was -15.0. running mean: -0.08209617884689788\n",
      "resetting env. episode reward total was 2.0. running mean: -0.061275217058428894\n",
      "resetting env. episode reward total was 12.0. running mean: 0.05933753511215539\n",
      "resetting env. episode reward total was 10.0. running mean: 0.15874415976103384\n",
      "resetting env. episode reward total was 7.0. running mean: 0.2271567181634235\n",
      "resetting env. episode reward total was 9.0. running mean: 0.31488515098178926\n",
      "resetting env. episode reward total was 3.0. running mean: 0.34173629947197137\n",
      "resetting env. episode reward total was -13.0. running mean: 0.20831893647725164\n",
      "resetting env. episode reward total was -7.0. running mean: 0.1362357471124791\n",
      "resetting env. episode reward total was -4.0. running mean: 0.0948733896413543\n",
      "resetting env. episode reward total was -1.0. running mean: 0.08392465574494076\n",
      "resetting env. episode reward total was -3.0. running mean: 0.053085409187491356\n",
      "resetting env. episode reward total was -5.0. running mean: 0.0025545550956164384\n",
      "resetting env. episode reward total was -3.0. running mean: -0.027470990455339725\n",
      "resetting env. episode reward total was 17.0. running mean: 0.1428037194492137\n",
      "resetting env. episode reward total was -3.0. running mean: 0.11137568225472155\n",
      "resetting env. episode reward total was 4.0. running mean: 0.15026192543217434\n",
      "resetting env. episode reward total was -1.0. running mean: 0.1387593061778526\n",
      "resetting env. episode reward total was -5.0. running mean: 0.08737171311607407\n",
      "resetting env. episode reward total was -5.0. running mean: 0.03649799598491332\n",
      "resetting env. episode reward total was 8.0. running mean: 0.11613301602506419\n",
      "resetting env. episode reward total was 2.0. running mean: 0.13497168586481353\n",
      "resetting env. episode reward total was -7.0. running mean: 0.0636219690061654\n",
      "resetting env. episode reward total was -13.0. running mean: -0.06701425068389626\n",
      "resetting env. episode reward total was 9.0. running mean: 0.0236558918229427\n",
      "resetting env. episode reward total was 13.0. running mean: 0.15341933290471327\n",
      "resetting env. episode reward total was 6.0. running mean: 0.21188513957566613\n",
      "resetting env. episode reward total was 6.0. running mean: 0.26976628817990944\n",
      "resetting env. episode reward total was 6.0. running mean: 0.3270686252981103\n",
      "resetting env. episode reward total was 7.0. running mean: 0.3937979390451292\n",
      "resetting env. episode reward total was 6.0. running mean: 0.4498599596546779\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3953613600581311\n",
      "resetting env. episode reward total was -9.0. running mean: 0.30140774645754975\n",
      "resetting env. episode reward total was -5.0. running mean: 0.24839366899297427\n",
      "resetting env. episode reward total was 16.0. running mean: 0.4059097323030445\n",
      "resetting env. episode reward total was -7.0. running mean: 0.33185063498001405\n",
      "resetting env. episode reward total was -7.0. running mean: 0.2585321286302139\n",
      "resetting env. episode reward total was -8.0. running mean: 0.17594680734391177\n",
      "resetting env. episode reward total was 3.0. running mean: 0.20418733927047264\n",
      "resetting env. episode reward total was -7.0. running mean: 0.1321454658777679\n",
      "resetting env. episode reward total was -2.0. running mean: 0.11082401121899023\n",
      "resetting env. episode reward total was 8.0. running mean: 0.18971577110680032\n",
      "resetting env. episode reward total was 5.0. running mean: 0.23781861339573235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: 0.265440427261775\n",
      "resetting env. episode reward total was -2.0. running mean: 0.24278602298915727\n",
      "resetting env. episode reward total was 11.0. running mean: 0.3503581627592657\n",
      "resetting env. episode reward total was -5.0. running mean: 0.296854581131673\n",
      "resetting env. episode reward total was -14.0. running mean: 0.15388603532035627\n",
      "resetting env. episode reward total was -2.0. running mean: 0.13234717496715273\n",
      "resetting env. episode reward total was -5.0. running mean: 0.08102370321748119\n",
      "resetting env. episode reward total was -4.0. running mean: 0.04021346618530638\n",
      "resetting env. episode reward total was 11.0. running mean: 0.14981133152345333\n",
      "resetting env. episode reward total was 5.0. running mean: 0.1983132182082188\n",
      "resetting env. episode reward total was -12.0. running mean: 0.07633008602613661\n",
      "resetting env. episode reward total was -9.0. running mean: -0.014433214834124755\n",
      "resetting env. episode reward total was 15.0. running mean: 0.13571111731421648\n",
      "resetting env. episode reward total was -11.0. running mean: 0.024354006141074316\n",
      "resetting env. episode reward total was -11.0. running mean: -0.08588953392033644\n",
      "resetting env. episode reward total was 6.0. running mean: -0.02503063858113308\n",
      "resetting env. episode reward total was -1.0. running mean: -0.03478033219532175\n",
      "resetting env. episode reward total was 9.0. running mean: 0.05556747112663146\n",
      "resetting env. episode reward total was 1.0. running mean: 0.06501179641536514\n",
      "resetting env. episode reward total was 2.0. running mean: 0.0843616784512115\n",
      "resetting env. episode reward total was 6.0. running mean: 0.1435180616666994\n",
      "resetting env. episode reward total was -13.0. running mean: 0.012082881050032385\n",
      "resetting env. episode reward total was -3.0. running mean: -0.018037947760467937\n",
      "resetting env. episode reward total was 6.0. running mean: 0.04214243171713674\n",
      "resetting env. episode reward total was -12.0. running mean: -0.07827899260003462\n",
      "resetting env. episode reward total was 6.0. running mean: -0.017496202674034275\n",
      "resetting env. episode reward total was -1.0. running mean: -0.02732124064729393\n",
      "resetting env. episode reward total was -9.0. running mean: -0.11704802824082099\n",
      "resetting env. episode reward total was -7.0. running mean: -0.18587754795841277\n",
      "resetting env. episode reward total was -5.0. running mean: -0.23401877247882863\n",
      "resetting env. episode reward total was 7.0. running mean: -0.16167858475404034\n",
      "resetting env. episode reward total was 2.0. running mean: -0.14006179890649995\n",
      "resetting env. episode reward total was 6.0. running mean: -0.07866118091743496\n",
      "resetting env. episode reward total was -3.0. running mean: -0.10787456910826061\n",
      "resetting env. episode reward total was -11.0. running mean: -0.216795823417178\n",
      "resetting env. episode reward total was -7.0. running mean: -0.2846278651830062\n",
      "resetting env. episode reward total was -9.0. running mean: -0.3717815865311761\n",
      "resetting env. episode reward total was -2.0. running mean: -0.38806377066586434\n",
      "resetting env. episode reward total was 2.0. running mean: -0.3641831329592057\n",
      "resetting env. episode reward total was -2.0. running mean: -0.38054130162961364\n",
      "resetting env. episode reward total was -3.0. running mean: -0.40673588861331744\n",
      "resetting env. episode reward total was -8.0. running mean: -0.48266852972718427\n",
      "resetting env. episode reward total was -7.0. running mean: -0.5478418444299125\n",
      "resetting env. episode reward total was 3.0. running mean: -0.5123634259856134\n",
      "resetting env. episode reward total was 1.0. running mean: -0.49723979172575716\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5222673938084996\n",
      "resetting env. episode reward total was 4.0. running mean: -0.4770447198704147\n",
      "resetting env. episode reward total was -2.0. running mean: -0.49227427267171053\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5173515299449934\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5421780146455435\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5467562344990881\n",
      "resetting env. episode reward total was 2.0. running mean: -0.5212886721540971\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5460757854325562\n",
      "resetting env. episode reward total was 8.0. running mean: -0.46061502757823064\n",
      "resetting env. episode reward total was 7.0. running mean: -0.3860088773024483\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3521487885294239\n",
      "resetting env. episode reward total was 6.0. running mean: -0.28862730064412967\n",
      "resetting env. episode reward total was -3.0. running mean: -0.3157410276376884\n",
      "resetting env. episode reward total was 8.0. running mean: -0.2325836173613115\n",
      "resetting env. episode reward total was 1.0. running mean: -0.22025778118769837\n",
      "resetting env. episode reward total was 8.0. running mean: -0.1380552033758214\n",
      "resetting env. episode reward total was 7.0. running mean: -0.06667465134206316\n",
      "resetting env. episode reward total was -11.0. running mean: -0.17600790482864254\n",
      "resetting env. episode reward total was 3.0. running mean: -0.1442478257803561\n",
      "resetting env. episode reward total was -2.0. running mean: -0.16280534752255255\n",
      "resetting env. episode reward total was 7.0. running mean: -0.09117729404732702\n",
      "resetting env. episode reward total was -5.0. running mean: -0.14026552110685375\n",
      "resetting env. episode reward total was 4.0. running mean: -0.09886286589578522\n",
      "resetting env. episode reward total was -7.0. running mean: -0.16787423723682737\n",
      "resetting env. episode reward total was 3.0. running mean: -0.1361954948644591\n",
      "resetting env. episode reward total was -7.0. running mean: -0.2048335399158145\n",
      "resetting env. episode reward total was 7.0. running mean: -0.13278520451665635\n",
      "resetting env. episode reward total was -9.0. running mean: -0.2214573524714898\n",
      "resetting env. episode reward total was 7.0. running mean: -0.14924277894677487\n",
      "resetting env. episode reward total was 7.0. running mean: -0.07775035115730711\n",
      "resetting env. episode reward total was -1.0. running mean: -0.08697284764573403\n",
      "resetting env. episode reward total was -7.0. running mean: -0.1561031191692767\n",
      "resetting env. episode reward total was 3.0. running mean: -0.12454208797758393\n",
      "resetting env. episode reward total was 1.0. running mean: -0.11329666709780808\n",
      "resetting env. episode reward total was 3.0. running mean: -0.08216370042683001\n",
      "resetting env. episode reward total was -11.0. running mean: -0.19134206342256171\n",
      "resetting env. episode reward total was -1.0. running mean: -0.1994286427883361\n",
      "resetting env. episode reward total was -9.0. running mean: -0.2874343563604528\n",
      "resetting env. episode reward total was 13.0. running mean: -0.15456001279684822\n",
      "resetting env. episode reward total was -1.0. running mean: -0.16301441266887975\n",
      "resetting env. episode reward total was -11.0. running mean: -0.27138426854219094\n",
      "resetting env. episode reward total was -2.0. running mean: -0.28867042585676905\n",
      "resetting env. episode reward total was -6.0. running mean: -0.34578372159820137\n",
      "resetting env. episode reward total was -4.0. running mean: -0.3823258843822193\n",
      "resetting env. episode reward total was 9.0. running mean: -0.2885026255383971\n",
      "resetting env. episode reward total was -3.0. running mean: -0.31561759928301314\n",
      "resetting env. episode reward total was -5.0. running mean: -0.362461423290183\n",
      "resetting env. episode reward total was -18.0. running mean: -0.5388368090572812\n",
      "resetting env. episode reward total was 7.0. running mean: -0.4634484409667083\n",
      "resetting env. episode reward total was -14.0. running mean: -0.5988139565570412\n",
      "resetting env. episode reward total was -7.0. running mean: -0.6628258169914707\n",
      "resetting env. episode reward total was 6.0. running mean: -0.596197558821556\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5802355832333405\n",
      "resetting env. episode reward total was 2.0. running mean: -0.554433227401007\n",
      "resetting env. episode reward total was -4.0. running mean: -0.5888888951269969\n",
      "resetting env. episode reward total was 4.0. running mean: -0.543000006175727\n",
      "resetting env. episode reward total was 7.0. running mean: -0.46757000611396965\n",
      "resetting env. episode reward total was 9.0. running mean: -0.3728943060528299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: -0.31916536299230164\n",
      "resetting env. episode reward total was 4.0. running mean: -0.27597370936237864\n",
      "resetting env. episode reward total was -1.0. running mean: -0.28321397226875483\n",
      "resetting env. episode reward total was -13.0. running mean: -0.4103818325460673\n",
      "resetting env. episode reward total was -7.0. running mean: -0.4762780142206066\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5015152340784006\n",
      "resetting env. episode reward total was 4.0. running mean: -0.4565000817376166\n",
      "resetting env. episode reward total was -11.0. running mean: -0.5619350809202405\n",
      "resetting env. episode reward total was -4.0. running mean: -0.5963157301110381\n",
      "resetting env. episode reward total was 5.0. running mean: -0.5403525728099277\n",
      "resetting env. episode reward total was 8.0. running mean: -0.4549490470818283\n",
      "resetting env. episode reward total was -5.0. running mean: -0.5003995566110101\n",
      "resetting env. episode reward total was -8.0. running mean: -0.5753955610449\n",
      "resetting env. episode reward total was -1.0. running mean: -0.579641605434451\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6238451893801065\n",
      "resetting env. episode reward total was -9.0. running mean: -0.7076067374863053\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7705306701114423\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8128253634103279\n",
      "resetting env. episode reward total was 7.0. running mean: -0.7346971097762245\n",
      "resetting env. episode reward total was 9.0. running mean: -0.6373501386784622\n",
      "resetting env. episode reward total was -3.0. running mean: -0.6609766372916777\n",
      "resetting env. episode reward total was 1.0. running mean: -0.6443668709187609\n",
      "resetting env. episode reward total was 12.0. running mean: -0.5179232022095732\n",
      "resetting env. episode reward total was -7.0. running mean: -0.5827439701874775\n",
      "resetting env. episode reward total was 8.0. running mean: -0.49691653048560264\n",
      "resetting env. episode reward total was -9.0. running mean: -0.5819473651807466\n",
      "resetting env. episode reward total was 4.0. running mean: -0.5361278915289391\n",
      "resetting env. episode reward total was -9.0. running mean: -0.6207666126136497\n",
      "resetting env. episode reward total was -11.0. running mean: -0.7245589464875132\n",
      "resetting env. episode reward total was -3.0. running mean: -0.747313357022638\n",
      "resetting env. episode reward total was -3.0. running mean: -0.7698402234524117\n",
      "resetting env. episode reward total was -12.0. running mean: -0.8821418212178875\n",
      "resetting env. episode reward total was 6.0. running mean: -0.8133204030057086\n",
      "resetting env. episode reward total was 5.0. running mean: -0.7551871989756515\n",
      "resetting env. episode reward total was 3.0. running mean: -0.7176353269858949\n",
      "resetting env. episode reward total was -4.0. running mean: -0.750458973716036\n",
      "resetting env. episode reward total was 5.0. running mean: -0.6929543839788755\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7560248401390868\n",
      "resetting env. episode reward total was 7.0. running mean: -0.6784645917376959\n",
      "resetting env. episode reward total was 1.0. running mean: -0.661679945820319\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6650631463621158\n",
      "resetting env. episode reward total was 8.0. running mean: -0.5784125148984947\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6226283897495097\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6664021058520146\n",
      "resetting env. episode reward total was -3.0. running mean: -0.6897380847934945\n",
      "resetting env. episode reward total was 11.0. running mean: -0.5728407039455596\n",
      "resetting env. episode reward total was -9.0. running mean: -0.657112296906104\n",
      "resetting env. episode reward total was 8.0. running mean: -0.570541173937043\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5748357621976725\n",
      "resetting env. episode reward total was 4.0. running mean: -0.5290874045756957\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5137965305299387\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5186585652246393\n",
      "resetting env. episode reward total was 3.0. running mean: -0.48347197957239285\n",
      "resetting env. episode reward total was 15.0. running mean: -0.3286372597766689\n",
      "resetting env. episode reward total was 4.0. running mean: -0.2853508871789022\n",
      "resetting env. episode reward total was 6.0. running mean: -0.2224973783071132\n",
      "resetting env. episode reward total was 6.0. running mean: -0.16027240452404207\n",
      "resetting env. episode reward total was -4.0. running mean: -0.19866968047880165\n",
      "resetting env. episode reward total was -6.0. running mean: -0.25668298367401365\n",
      "resetting env. episode reward total was -3.0. running mean: -0.2841161538372735\n",
      "resetting env. episode reward total was 7.0. running mean: -0.2112749922989008\n",
      "resetting env. episode reward total was -7.0. running mean: -0.2791622423759118\n",
      "resetting env. episode reward total was -11.0. running mean: -0.38637061995215266\n",
      "resetting env. episode reward total was 15.0. running mean: -0.23250691375263113\n",
      "resetting env. episode reward total was -10.0. running mean: -0.3301818446151048\n",
      "resetting env. episode reward total was 6.0. running mean: -0.26688002616895373\n",
      "resetting env. episode reward total was 10.0. running mean: -0.1642112259072642\n",
      "resetting env. episode reward total was -15.0. running mean: -0.3125691136481915\n",
      "resetting env. episode reward total was 3.0. running mean: -0.2794434225117096\n",
      "resetting env. episode reward total was 4.0. running mean: -0.2366489882865925\n",
      "resetting env. episode reward total was 2.0. running mean: -0.2142824984037266\n",
      "resetting env. episode reward total was 7.0. running mean: -0.14213967341968933\n",
      "resetting env. episode reward total was 3.0. running mean: -0.11071827668549244\n",
      "resetting env. episode reward total was -2.0. running mean: -0.1296110939186375\n",
      "resetting env. episode reward total was -3.0. running mean: -0.15831498297945112\n",
      "resetting env. episode reward total was 3.0. running mean: -0.1267318331496566\n",
      "resetting env. episode reward total was 4.0. running mean: -0.08546451481816003\n",
      "resetting env. episode reward total was -4.0. running mean: -0.12460986966997842\n",
      "resetting env. episode reward total was 6.0. running mean: -0.06336377097327864\n",
      "resetting env. episode reward total was 1.0. running mean: -0.05273013326354584\n",
      "resetting env. episode reward total was -4.0. running mean: -0.09220283193091039\n",
      "resetting env. episode reward total was 11.0. running mean: 0.01871919638839871\n",
      "resetting env. episode reward total was 4.0. running mean: 0.05853200442451473\n",
      "resetting env. episode reward total was 11.0. running mean: 0.16794668438026958\n",
      "resetting env. episode reward total was -5.0. running mean: 0.11626721753646689\n",
      "resetting env. episode reward total was 6.0. running mean: 0.1751045453611022\n",
      "resetting env. episode reward total was -10.0. running mean: 0.07335349990749118\n",
      "resetting env. episode reward total was -4.0. running mean: 0.03261996490841627\n",
      "resetting env. episode reward total was 4.0. running mean: 0.07229376525933211\n",
      "resetting env. episode reward total was -2.0. running mean: 0.051570827606738784\n",
      "resetting env. episode reward total was 12.0. running mean: 0.17105511933067138\n",
      "resetting env. episode reward total was -7.0. running mean: 0.09934456813736467\n",
      "resetting env. episode reward total was 3.0. running mean: 0.128351122455991\n",
      "resetting env. episode reward total was 6.0. running mean: 0.1870676112314311\n",
      "resetting env. episode reward total was 9.0. running mean: 0.2751969351191168\n",
      "resetting env. episode reward total was -1.0. running mean: 0.26244496576792564\n",
      "resetting env. episode reward total was -2.0. running mean: 0.23982051611024638\n",
      "resetting env. episode reward total was -10.0. running mean: 0.1374223109491439\n",
      "resetting env. episode reward total was -11.0. running mean: 0.026048087839652442\n",
      "resetting env. episode reward total was 6.0. running mean: 0.08578760696125591\n",
      "resetting env. episode reward total was 6.0. running mean: 0.14492973089164335\n",
      "resetting env. episode reward total was 5.0. running mean: 0.19348043358272693\n",
      "resetting env. episode reward total was -6.0. running mean: 0.13154562924689966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 0.22023017295443068\n",
      "resetting env. episode reward total was 6.0. running mean: 0.27802787122488637\n",
      "resetting env. episode reward total was -7.0. running mean: 0.20524759251263752\n",
      "resetting env. episode reward total was -13.0. running mean: 0.07319511658751113\n",
      "resetting env. episode reward total was 13.0. running mean: 0.202463165421636\n",
      "resetting env. episode reward total was 6.0. running mean: 0.26043853376741966\n",
      "resetting env. episode reward total was -4.0. running mean: 0.21783414842974544\n",
      "resetting env. episode reward total was 4.0. running mean: 0.255655806945448\n",
      "resetting env. episode reward total was 3.0. running mean: 0.28309924887599347\n",
      "resetting env. episode reward total was 1.0. running mean: 0.2902682563872335\n",
      "resetting env. episode reward total was 4.0. running mean: 0.3273655738233612\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2940919180851276\n",
      "resetting env. episode reward total was -6.0. running mean: 0.23115099890427632\n",
      "resetting env. episode reward total was -5.0. running mean: 0.17883948891523355\n",
      "resetting env. episode reward total was 5.0. running mean: 0.2270510940260812\n",
      "resetting env. episode reward total was 8.0. running mean: 0.3047805830858204\n",
      "resetting env. episode reward total was 4.0. running mean: 0.34173277725496215\n",
      "resetting env. episode reward total was -2.0. running mean: 0.3183154494824125\n",
      "resetting env. episode reward total was 1.0. running mean: 0.3251322949875884\n",
      "resetting env. episode reward total was 7.0. running mean: 0.3918809720377125\n",
      "resetting env. episode reward total was 3.0. running mean: 0.4179621623173354\n",
      "resetting env. episode reward total was 2.0. running mean: 0.43378254069416206\n",
      "resetting env. episode reward total was 14.0. running mean: 0.5694447152872204\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5337502681343481\n",
      "resetting env. episode reward total was 10.0. running mean: 0.6284127654530046\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6421286377984746\n",
      "resetting env. episode reward total was 1.0. running mean: 0.6457073514204899\n",
      "resetting env. episode reward total was -11.0. running mean: 0.529250277906285\n",
      "resetting env. episode reward total was -10.0. running mean: 0.4239577751272221\n",
      "resetting env. episode reward total was -2.0. running mean: 0.3997181973759499\n",
      "resetting env. episode reward total was 10.0. running mean: 0.4957210154021904\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5507638052481685\n",
      "resetting env. episode reward total was 10.0. running mean: 0.6452561671956868\n",
      "resetting env. episode reward total was 10.0. running mean: 0.7388036055237299\n",
      "resetting env. episode reward total was -11.0. running mean: 0.6214155694684926\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5652014137738076\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5895493996360696\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6236539056397089\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5674173665833118\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5317431929174786\n",
      "resetting env. episode reward total was 7.0. running mean: 0.5964257609883039\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5204615033784208\n",
      "resetting env. episode reward total was -6.0. running mean: 0.45525688834463657\n",
      "resetting env. episode reward total was -5.0. running mean: 0.40070431946119023\n",
      "resetting env. episode reward total was 12.0. running mean: 0.5166972762665782\n",
      "resetting env. episode reward total was -10.0. running mean: 0.4115303035039125\n",
      "resetting env. episode reward total was 5.0. running mean: 0.45741500046887335\n",
      "resetting env. episode reward total was 3.0. running mean: 0.48284085046418457\n",
      "resetting env. episode reward total was -3.0. running mean: 0.4480124419595427\n",
      "resetting env. episode reward total was -1.0. running mean: 0.43353231753994725\n",
      "resetting env. episode reward total was 7.0. running mean: 0.4991969943645478\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5242050244209023\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5789629741766933\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6231733444349264\n",
      "resetting env. episode reward total was -9.0. running mean: 0.5269416109905772\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5016721948806715\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5066554729318647\n",
      "resetting env. episode reward total was -7.0. running mean: 0.43158891820254613\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5172730290205206\n",
      "resetting env. episode reward total was -3.0. running mean: 0.48210029873031535\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5672792957430122\n",
      "resetting env. episode reward total was -6.0. running mean: 0.501606502785582\n",
      "resetting env. episode reward total was -13.0. running mean: 0.3665904377577262\n",
      "resetting env. episode reward total was -3.0. running mean: 0.33292453338014893\n",
      "resetting env. episode reward total was 9.0. running mean: 0.4195952880463475\n",
      "resetting env. episode reward total was 4.0. running mean: 0.455399335165884\n",
      "resetting env. episode reward total was -4.0. running mean: 0.41084534181422516\n",
      "resetting env. episode reward total was 3.0. running mean: 0.43673688839608293\n",
      "resetting env. episode reward total was 4.0. running mean: 0.4723695195121221\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5476458243170008\n",
      "resetting env. episode reward total was -5.0. running mean: 0.4921693660738308\n",
      "resetting env. episode reward total was -5.0. running mean: 0.43724767241309254\n",
      "resetting env. episode reward total was 7.0. running mean: 0.5028751956889617\n",
      "resetting env. episode reward total was -2.0. running mean: 0.477846443732072\n",
      "resetting env. episode reward total was -3.0. running mean: 0.4430679792947513\n",
      "resetting env. episode reward total was 5.0. running mean: 0.48863729950180373\n",
      "resetting env. episode reward total was 2.0. running mean: 0.5037509265067857\n",
      "resetting env. episode reward total was 2.0. running mean: 0.5187134172417178\n",
      "resetting env. episode reward total was -11.0. running mean: 0.4035262830693006\n",
      "resetting env. episode reward total was 3.0. running mean: 0.42949102023860763\n",
      "resetting env. episode reward total was 1.0. running mean: 0.43519611003622155\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5208441489358593\n",
      "resetting env. episode reward total was -10.0. running mean: 0.4156357074465007\n",
      "resetting env. episode reward total was -11.0. running mean: 0.3014793503720357\n",
      "resetting env. episode reward total was -5.0. running mean: 0.24846455686831537\n",
      "resetting env. episode reward total was 2.0. running mean: 0.2659799112996322\n",
      "resetting env. episode reward total was 9.0. running mean: 0.35332011218663595\n",
      "resetting env. episode reward total was 2.0. running mean: 0.36978691106476963\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3360890419541219\n",
      "resetting env. episode reward total was 12.0. running mean: 0.4527281515345807\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3982008700192349\n",
      "resetting env. episode reward total was 10.0. running mean: 0.4942188613190426\n",
      "resetting env. episode reward total was 5.0. running mean: 0.5392766727058521\n",
      "resetting env. episode reward total was -7.0. running mean: 0.46388390597879353\n",
      "resetting env. episode reward total was -2.0. running mean: 0.43924506691900556\n",
      "resetting env. episode reward total was 4.0. running mean: 0.47485261624981545\n",
      "resetting env. episode reward total was -7.0. running mean: 0.4001040900873173\n",
      "resetting env. episode reward total was -7.0. running mean: 0.3261030491864441\n",
      "resetting env. episode reward total was -1.0. running mean: 0.31284201869457967\n",
      "resetting env. episode reward total was 5.0. running mean: 0.35971359850763385\n",
      "resetting env. episode reward total was 11.0. running mean: 0.4661164625225575\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5414552978973319\n",
      "resetting env. episode reward total was -10.0. running mean: 0.43604074491835865\n",
      "resetting env. episode reward total was 5.0. running mean: 0.48168033746917505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: 0.4868635340944833\n",
      "resetting env. episode reward total was -11.0. running mean: 0.37199489875353847\n",
      "resetting env. episode reward total was 1.0. running mean: 0.37827494976600307\n",
      "resetting env. episode reward total was -5.0. running mean: 0.324492200268343\n",
      "resetting env. episode reward total was 4.0. running mean: 0.36124727826565955\n",
      "resetting env. episode reward total was 7.0. running mean: 0.427634805483003\n",
      "resetting env. episode reward total was 7.0. running mean: 0.49335845742817297\n",
      "resetting env. episode reward total was -9.0. running mean: 0.3984248728538913\n",
      "resetting env. episode reward total was -5.0. running mean: 0.34444062412535237\n",
      "resetting env. episode reward total was 1.0. running mean: 0.35099621788409885\n",
      "resetting env. episode reward total was 8.0. running mean: 0.4274862557052579\n",
      "resetting env. episode reward total was 10.0. running mean: 0.5232113931482053\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5079792792167233\n",
      "resetting env. episode reward total was -3.0. running mean: 0.47289948642455604\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5081704915603105\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5430887866447074\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5976578987782604\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6116813197904778\n",
      "resetting env. episode reward total was 5.0. running mean: 0.655564506592573\n",
      "resetting env. episode reward total was -2.0. running mean: 0.6290088615266473\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5927187729113808\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5367915851822669\n",
      "resetting env. episode reward total was -6.0. running mean: 0.47142366933044416\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5567094326371397\n",
      "resetting env. episode reward total was 2.0. running mean: 0.5711423383107683\n",
      "resetting env. episode reward total was -7.0. running mean: 0.4954309149276606\n",
      "resetting env. episode reward total was 9.0. running mean: 0.580476605778384\n",
      "resetting env. episode reward total was 10.0. running mean: 0.6746718397206002\n",
      "resetting env. episode reward total was 1.0. running mean: 0.6779251213233942\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6011458701101602\n",
      "resetting env. episode reward total was 1.0. running mean: 0.6051344114090585\n",
      "resetting env. episode reward total was 2.0. running mean: 0.619083067294968\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5428922366220184\n",
      "resetting env. episode reward total was -9.0. running mean: 0.4474633142557982\n",
      "resetting env. episode reward total was 4.0. running mean: 0.4829886811132402\n",
      "resetting env. episode reward total was 1.0. running mean: 0.48815879430210785\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5932772063590868\n",
      "resetting env. episode reward total was -8.0. running mean: 0.5073444342954959\n",
      "resetting env. episode reward total was -6.0. running mean: 0.44227098995254094\n",
      "resetting env. episode reward total was 5.0. running mean: 0.4878482800530155\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5229697972524854\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5077400992799606\n",
      "resetting env. episode reward total was -7.0. running mean: 0.4326626982871609\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5183360713042893\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5431527105912464\n",
      "resetting env. episode reward total was -11.0. running mean: 0.42772118348533394\n",
      "resetting env. episode reward total was 6.0. running mean: 0.4834439716504806\n",
      "resetting env. episode reward total was -4.0. running mean: 0.4386095319339758\n",
      "resetting env. episode reward total was 1.0. running mean: 0.44422343661463604\n",
      "resetting env. episode reward total was -9.0. running mean: 0.34978120224848963\n",
      "resetting env. episode reward total was 4.0. running mean: 0.3862833902260047\n",
      "resetting env. episode reward total was -1.0. running mean: 0.37242055632374466\n",
      "resetting env. episode reward total was 4.0. running mean: 0.4086963507605072\n",
      "resetting env. episode reward total was -11.0. running mean: 0.29460938725290214\n",
      "resetting env. episode reward total was 2.0. running mean: 0.31166329338037313\n",
      "resetting env. episode reward total was -5.0. running mean: 0.25854666044656943\n",
      "resetting env. episode reward total was 2.0. running mean: 0.27596119384210377\n",
      "resetting env. episode reward total was 9.0. running mean: 0.3632015819036827\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3295695660846458\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2962738704237994\n",
      "resetting env. episode reward total was -10.0. running mean: 0.19331113171956135\n",
      "resetting env. episode reward total was 7.0. running mean: 0.26137802040236574\n",
      "resetting env. episode reward total was 10.0. running mean: 0.3587642401983421\n",
      "resetting env. episode reward total was 6.0. running mean: 0.4151765977963586\n",
      "resetting env. episode reward total was -5.0. running mean: 0.36102483181839506\n",
      "resetting env. episode reward total was -4.0. running mean: 0.3174145835002111\n",
      "resetting env. episode reward total was -1.0. running mean: 0.304240437665209\n",
      "resetting env. episode reward total was 1.0. running mean: 0.3111980332885569\n",
      "resetting env. episode reward total was 4.0. running mean: 0.3480860529556713\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3346051924261146\n",
      "resetting env. episode reward total was -3.0. running mean: 0.30125914050185343\n",
      "resetting env. episode reward total was 1.0. running mean: 0.3082465490968349\n",
      "resetting env. episode reward total was -7.0. running mean: 0.23516408360586655\n",
      "resetting env. episode reward total was -8.0. running mean: 0.15281244276980788\n",
      "resetting env. episode reward total was 11.0. running mean: 0.2612843183421098\n",
      "resetting env. episode reward total was -13.0. running mean: 0.1286714751586887\n",
      "resetting env. episode reward total was 1.0. running mean: 0.13738476040710182\n",
      "resetting env. episode reward total was -5.0. running mean: 0.08601091280303079\n",
      "resetting env. episode reward total was -7.0. running mean: 0.015150803675000477\n",
      "resetting env. episode reward total was -7.0. running mean: -0.05500070436174954\n",
      "resetting env. episode reward total was 7.0. running mean: 0.015549302681867966\n",
      "resetting env. episode reward total was 3.0. running mean: 0.045393809655049286\n",
      "resetting env. episode reward total was -1.0. running mean: 0.03493987155849879\n",
      "resetting env. episode reward total was 3.0. running mean: 0.0645904728429138\n",
      "resetting env. episode reward total was -1.0. running mean: 0.05394456811448466\n",
      "resetting env. episode reward total was -1.0. running mean: 0.04340512243333981\n",
      "resetting env. episode reward total was 1.0. running mean: 0.05297107120900642\n",
      "resetting env. episode reward total was 16.0. running mean: 0.21244136049691636\n",
      "resetting env. episode reward total was -3.0. running mean: 0.1803169468919472\n",
      "resetting env. episode reward total was -10.0. running mean: 0.0785137774230277\n",
      "resetting env. episode reward total was -3.0. running mean: 0.04772863964879742\n",
      "resetting env. episode reward total was -2.0. running mean: 0.027251353252309447\n",
      "resetting env. episode reward total was -5.0. running mean: -0.02302116028021365\n",
      "resetting env. episode reward total was -11.0. running mean: -0.1327909486774115\n",
      "resetting env. episode reward total was 2.0. running mean: -0.1114630391906374\n",
      "resetting env. episode reward total was -3.0. running mean: -0.140348408798731\n",
      "resetting env. episode reward total was 10.0. running mean: -0.03894492471074368\n",
      "resetting env. episode reward total was -3.0. running mean: -0.06855547546363625\n",
      "resetting env. episode reward total was -7.0. running mean: -0.1378699207089999\n",
      "resetting env. episode reward total was 11.0. running mean: -0.026491221501909898\n",
      "resetting env. episode reward total was 4.0. running mean: 0.013773690713109202\n",
      "resetting env. episode reward total was 8.0. running mean: 0.09363595380597811\n",
      "resetting env. episode reward total was 4.0. running mean: 0.13269959426791833\n",
      "resetting env. episode reward total was 11.0. running mean: 0.24137259832523916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: 0.19895887234198675\n",
      "resetting env. episode reward total was -2.0. running mean: 0.1769692836185669\n",
      "resetting env. episode reward total was 8.0. running mean: 0.25519959078238125\n",
      "resetting env. episode reward total was 3.0. running mean: 0.2826475948745575\n",
      "resetting env. episode reward total was -1.0. running mean: 0.2698211189258119\n",
      "resetting env. episode reward total was 2.0. running mean: 0.2871229077365538\n",
      "resetting env. episode reward total was -4.0. running mean: 0.24425167865918826\n",
      "resetting env. episode reward total was -9.0. running mean: 0.15180916187259638\n",
      "resetting env. episode reward total was -3.0. running mean: 0.12029107025387042\n",
      "resetting env. episode reward total was 4.0. running mean: 0.1590881595513317\n",
      "resetting env. episode reward total was 2.0. running mean: 0.17749727795581838\n",
      "resetting env. episode reward total was 11.0. running mean: 0.2857223051762602\n",
      "resetting env. episode reward total was -1.0. running mean: 0.27286508212449756\n",
      "resetting env. episode reward total was -9.0. running mean: 0.1801364313032526\n",
      "resetting env. episode reward total was 5.0. running mean: 0.2283350669902201\n",
      "resetting env. episode reward total was 4.0. running mean: 0.2660517163203179\n",
      "resetting env. episode reward total was 5.0. running mean: 0.31339119915711466\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3602572871655435\n",
      "resetting env. episode reward total was -6.0. running mean: 0.29665471429388807\n",
      "resetting env. episode reward total was -4.0. running mean: 0.2536881671509492\n",
      "resetting env. episode reward total was -7.0. running mean: 0.1811512854794397\n",
      "resetting env. episode reward total was 9.0. running mean: 0.2693397726246453\n",
      "resetting env. episode reward total was -10.0. running mean: 0.16664637489839887\n",
      "resetting env. episode reward total was 7.0. running mean: 0.23497991114941488\n",
      "resetting env. episode reward total was 13.0. running mean: 0.3626301120379207\n",
      "resetting env. episode reward total was -19.0. running mean: 0.16900381091754152\n",
      "resetting env. episode reward total was -1.0. running mean: 0.1573137728083661\n",
      "resetting env. episode reward total was -4.0. running mean: 0.11574063508028243\n",
      "resetting env. episode reward total was 3.0. running mean: 0.1445832287294796\n",
      "resetting env. episode reward total was 4.0. running mean: 0.1831373964421848\n",
      "resetting env. episode reward total was -2.0. running mean: 0.16130602247776296\n",
      "resetting env. episode reward total was -3.0. running mean: 0.12969296225298532\n",
      "resetting env. episode reward total was -2.0. running mean: 0.10839603263045546\n",
      "resetting env. episode reward total was -3.0. running mean: 0.0773120723041509\n",
      "resetting env. episode reward total was 2.0. running mean: 0.0965389515811094\n",
      "resetting env. episode reward total was 1.0. running mean: 0.10557356206529829\n",
      "resetting env. episode reward total was -4.0. running mean: 0.0645178264446453\n",
      "resetting env. episode reward total was 7.0. running mean: 0.13387264818019884\n",
      "resetting env. episode reward total was 5.0. running mean: 0.18253392169839683\n",
      "resetting env. episode reward total was 15.0. running mean: 0.3307085824814129\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3174014966565987\n",
      "resetting env. episode reward total was -7.0. running mean: 0.24422748169003272\n",
      "resetting env. episode reward total was -8.0. running mean: 0.16178520687313241\n",
      "resetting env. episode reward total was 9.0. running mean: 0.2501673548044011\n",
      "resetting env. episode reward total was 11.0. running mean: 0.3576656812563571\n",
      "resetting env. episode reward total was 6.0. running mean: 0.41408902444379353\n",
      "resetting env. episode reward total was -2.0. running mean: 0.3899481341993556\n",
      "resetting env. episode reward total was -1.0. running mean: 0.376048652857362\n",
      "resetting env. episode reward total was 10.0. running mean: 0.47228816632878834\n",
      "resetting env. episode reward total was -4.0. running mean: 0.4275652846655005\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4132896318188455\n",
      "resetting env. episode reward total was 13.0. running mean: 0.539156735500657\n",
      "resetting env. episode reward total was 10.0. running mean: 0.6337651681456504\n",
      "resetting env. episode reward total was -11.0. running mean: 0.5174275164641939\n",
      "resetting env. episode reward total was 10.0. running mean: 0.6122532412995519\n",
      "resetting env. episode reward total was -8.0. running mean: 0.5261307088865564\n",
      "resetting env. episode reward total was -3.0. running mean: 0.4908694017976909\n",
      "resetting env. episode reward total was 4.0. running mean: 0.525960707779714\n",
      "resetting env. episode reward total was -5.0. running mean: 0.4707011007019169\n",
      "resetting env. episode reward total was -1.0. running mean: 0.45599408969489774\n",
      "resetting env. episode reward total was 4.0. running mean: 0.4914341487979487\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5165198073099693\n",
      "resetting env. episode reward total was 10.0. running mean: 0.6113546092368696\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6252410631445009\n",
      "resetting env. episode reward total was -11.0. running mean: 0.5089886525130559\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5338987659879254\n",
      "resetting env. episode reward total was 9.0. running mean: 0.6185597783280461\n",
      "resetting env. episode reward total was 10.0. running mean: 0.7123741805447656\n",
      "resetting env. episode reward total was -6.0. running mean: 0.6452504387393181\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6087979343519249\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5527099550084056\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5871828554583216\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5913110269037384\n",
      "resetting env. episode reward total was 12.0. running mean: 0.705397916634701\n",
      "resetting env. episode reward total was 11.0. running mean: 0.808343937468354\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9002604980936704\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9012578931127336\n",
      "resetting env. episode reward total was -13.0. running mean: 0.7622453141816062\n",
      "resetting env. episode reward total was 4.0. running mean: 0.7946228610397902\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8466766324293922\n",
      "resetting env. episode reward total was -8.0. running mean: 0.7582098661050983\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7406277674440473\n",
      "resetting env. episode reward total was 11.0. running mean: 0.8432214897696069\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8847892748719108\n",
      "resetting env. episode reward total was -7.0. running mean: 0.8059413821231918\n",
      "resetting env. episode reward total was -7.0. running mean: 0.72788196830196\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7706031486189404\n",
      "resetting env. episode reward total was 14.0. running mean: 0.902897117132751\n",
      "resetting env. episode reward total was 12.0. running mean: 1.0138681459614234\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0337294645018091\n",
      "resetting env. episode reward total was 8.0. running mean: 1.103392169856791\n",
      "resetting env. episode reward total was 7.0. running mean: 1.162358248158223\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1407346656766408\n",
      "resetting env. episode reward total was -5.0. running mean: 1.0793273190198744\n",
      "resetting env. episode reward total was -2.0. running mean: 1.0485340458296757\n",
      "resetting env. episode reward total was -2.0. running mean: 1.018048705371379\n",
      "resetting env. episode reward total was 2.0. running mean: 1.027868218317665\n",
      "resetting env. episode reward total was -8.0. running mean: 0.9375895361344885\n",
      "resetting env. episode reward total was 10.0. running mean: 1.0282136407731437\n",
      "resetting env. episode reward total was -6.0. running mean: 0.9579315043654122\n",
      "resetting env. episode reward total was -2.0. running mean: 0.928352189321758\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8990686674285404\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9200779807542551\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9408772009467126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: 0.9214684289372455\n",
      "resetting env. episode reward total was -3.0. running mean: 0.882253744647873\n",
      "resetting env. episode reward total was -9.0. running mean: 0.7834312072013943\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7255968951293803\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7783409261780865\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8305575169163055\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8622519417471425\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8436294223296711\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7851931281063743\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7573411968253105\n",
      "resetting env. episode reward total was 9.0. running mean: 0.8397677848570574\n",
      "resetting env. episode reward total was -13.0. running mean: 0.7013701070084868\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7543564059384018\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7268128418790177\n",
      "resetting env. episode reward total was 8.0. running mean: 0.7995447134602275\n",
      "resetting env. episode reward total was -9.0. running mean: 0.7015492663256252\n",
      "resetting env. episode reward total was -9.0. running mean: 0.6045337736623689\n",
      "resetting env. episode reward total was -9.0. running mean: 0.5084884359257452\n",
      "resetting env. episode reward total was 2.0. running mean: 0.5234035515664878\n",
      "resetting env. episode reward total was 12.0. running mean: 0.6381695160508228\n",
      "resetting env. episode reward total was 10.0. running mean: 0.7317878208903146\n",
      "resetting env. episode reward total was -4.0. running mean: 0.6844699426814114\n",
      "resetting env. episode reward total was 4.0. running mean: 0.7176252432545973\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6404489908220514\n",
      "resetting env. episode reward total was 8.0. running mean: 0.7140445009138309\n",
      "resetting env. episode reward total was -11.0. running mean: 0.5969040559046925\n",
      "resetting env. episode reward total was -9.0. running mean: 0.5009350153456457\n",
      "resetting env. episode reward total was 7.0. running mean: 0.5659256651921892\n",
      "resetting env. episode reward total was 15.0. running mean: 0.7102664085402673\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7531637444548647\n",
      "resetting env. episode reward total was 2.0. running mean: 0.765632107010316\n",
      "resetting env. episode reward total was 7.0. running mean: 0.8279757859402128\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9096960280808106\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9205990678000026\n",
      "resetting env. episode reward total was -7.0. running mean: 0.8413930771220026\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7829791463507826\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8551493548872747\n",
      "resetting env. episode reward total was 4.0. running mean: 0.886597861338402\n",
      "resetting env. episode reward total was 2.0. running mean: 0.897731882725018\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9387545638977679\n",
      "resetting env. episode reward total was 10.0. running mean: 1.0293670182587902\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9790733480762022\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8792826145954402\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8204897884494857\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8722848905649909\n",
      "resetting env. episode reward total was 3.0. running mean: 0.893562041659341\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9846264212427476\n",
      "resetting env. episode reward total was 4.0. running mean: 1.01478015703032\n",
      "resetting env. episode reward total was 5.0. running mean: 1.054632355460017\n",
      "resetting env. episode reward total was 8.0. running mean: 1.124086031905417\n",
      "resetting env. episode reward total was 12.0. running mean: 1.2328451715863626\n",
      "resetting env. episode reward total was -8.0. running mean: 1.1405167198704989\n",
      "resetting env. episode reward total was -7.0. running mean: 1.0591115526717938\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9985204371450758\n",
      "resetting env. episode reward total was 1.0. running mean: 0.998535232773625\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0585498804458888\n",
      "resetting env. episode reward total was -1.0. running mean: 1.03796438164143\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0375847378250156\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9872088904467653\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0373368015422977\n",
      "resetting env. episode reward total was -8.0. running mean: 0.9469634335268747\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9874937991916061\n",
      "resetting env. episode reward total was 6.0. running mean: 1.03761886119969\n",
      "resetting env. episode reward total was 1.0. running mean: 1.037242672587693\n",
      "resetting env. episode reward total was -3.0. running mean: 0.9968702458618162\n",
      "resetting env. episode reward total was 3.0. running mean: 1.016901543403198\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9367325279691661\n",
      "resetting env. episode reward total was -11.0. running mean: 0.8173652026894744\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8591915506625797\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9205996351559538\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9713936388043942\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9816797024163503\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9918629053921868\n",
      "resetting env. episode reward total was -11.0. running mean: 0.871944276338265\n",
      "resetting env. episode reward total was -9.0. running mean: 0.7732248335748824\n",
      "resetting env. episode reward total was -11.0. running mean: 0.6554925852391336\n",
      "resetting env. episode reward total was 13.0. running mean: 0.7789376593867422\n",
      "resetting env. episode reward total was 9.0. running mean: 0.8611482827928747\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8625367999649459\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9139114319652966\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9847723176456435\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0149245944691871\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9147753485244953\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9356275950392503\n",
      "resetting env. episode reward total was 4.0. running mean: 0.9662713190888579\n",
      "resetting env. episode reward total was 4.0. running mean: 0.9966086058979693\n",
      "resetting env. episode reward total was -3.0. running mean: 0.9566425198389895\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9770760946405996\n",
      "resetting env. episode reward total was 8.0. running mean: 1.0473053336941935\n",
      "resetting env. episode reward total was 9.0. running mean: 1.1268322803572517\n",
      "resetting env. episode reward total was -3.0. running mean: 1.085563957553679\n",
      "resetting env. episode reward total was -11.0. running mean: 0.9647083179781423\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9050612347983608\n",
      "resetting env. episode reward total was 11.0. running mean: 1.006010622450377\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0559505162258733\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0753910110636147\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1046371009529785\n",
      "resetting env. episode reward total was -9.0. running mean: 1.0035907299434486\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0535548226440141\n",
      "resetting env. episode reward total was 4.0. running mean: 1.083019274417574\n",
      "resetting env. episode reward total was 8.0. running mean: 1.1521890816733982\n",
      "resetting env. episode reward total was -9.0. running mean: 1.050667190856664\n",
      "resetting env. episode reward total was 12.0. running mean: 1.1601605189480972\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2085589137586163\n",
      "resetting env. episode reward total was 11.0. running mean: 1.3064733246210303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 1.37340859137482\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3396745054610717\n",
      "resetting env. episode reward total was -7.0. running mean: 1.256277760406461\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3137149828023964\n",
      "resetting env. episode reward total was -4.0. running mean: 1.2605778329743724\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2879720546446287\n",
      "resetting env. episode reward total was -2.0. running mean: 1.2550923340981823\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2725414107572006\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2898159966496285\n",
      "resetting env. episode reward total was 1.0. running mean: 1.2869178366831322\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2240486583163008\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1818081717331377\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1599900900158062\n",
      "resetting env. episode reward total was 8.0. running mean: 1.2283901891156481\n",
      "resetting env. episode reward total was 9.0. running mean: 1.3061062872244917\n",
      "resetting env. episode reward total was -3.0. running mean: 1.2630452243522468\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3304147721087243\n",
      "resetting env. episode reward total was -3.0. running mean: 1.287110624387637\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3442395181437605\n",
      "resetting env. episode reward total was 1.0. running mean: 1.340797122962323\n",
      "resetting env. episode reward total was -3.0. running mean: 1.2973891517326996\n",
      "resetting env. episode reward total was 3.0. running mean: 1.3144152602153727\n",
      "resetting env. episode reward total was -1.0. running mean: 1.2912711076132188\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2983583965370866\n",
      "resetting env. episode reward total was 1.0. running mean: 1.2953748125717157\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3824210644459987\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3885968538015387\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4147108852635233\n",
      "resetting env. episode reward total was 6.0. running mean: 1.460563776410888\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3759581386467792\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3321985572603114\n",
      "resetting env. episode reward total was 11.0. running mean: 1.4288765716877083\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4845878059708313\n",
      "resetting env. episode reward total was -3.0. running mean: 1.439741927911123\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3753445086320117\n",
      "resetting env. episode reward total was -4.0. running mean: 1.3215910635456916\n",
      "resetting env. episode reward total was -4.0. running mean: 1.2683751529102345\n",
      "resetting env. episode reward total was -2.0. running mean: 1.2356914013811322\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1933344873673208\n",
      "resetting env. episode reward total was -11.0. running mean: 1.0714011424936476\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0906871310687112\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0997802597580242\n",
      "resetting env. episode reward total was -11.0. running mean: 0.9787824571604439\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0089946325888395\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9089046862629511\n",
      "resetting env. episode reward total was 4.0. running mean: 0.9398156394003215\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8404174830063184\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8220133081762552\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8537931750944927\n",
      "resetting env. episode reward total was -10.0. running mean: 0.7452552433435478\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8178026909101123\n",
      "resetting env. episode reward total was 12.0. running mean: 0.9296246640010112\n",
      "resetting env. episode reward total was 7.0. running mean: 0.990328417361001\n",
      "resetting env. episode reward total was -3.0. running mean: 0.950425133187391\n",
      "resetting env. episode reward total was -4.0. running mean: 0.900920881855517\n",
      "resetting env. episode reward total was 13.0. running mean: 1.021911673036962\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0216925563065924\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0614756307435265\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1208608744360913\n",
      "resetting env. episode reward total was 8.0. running mean: 1.1896522656917303\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2277557430348132\n",
      "resetting env. episode reward total was -15.0. running mean: 1.065478185604465\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0848234037484203\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1139751697109361\n",
      "resetting env. episode reward total was 10.0. running mean: 1.2028354180138268\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2208070638336885\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2985989931953517\n",
      "resetting env. episode reward total was -6.0. running mean: 1.225613003263398\n",
      "resetting env. episode reward total was 3.0. running mean: 1.243356873230764\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2609233044984565\n",
      "resetting env. episode reward total was -3.0. running mean: 1.218314071453472\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2961309307389373\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3031696214315478\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3601379252172323\n",
      "resetting env. episode reward total was 5.0. running mean: 1.39653654596506\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4125711805054095\n",
      "resetting env. episode reward total was 11.0. running mean: 1.5084454687003555\n",
      "resetting env. episode reward total was 4.0. running mean: 1.533361014013352\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5580274038732185\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5524471298344862\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5169226585361413\n",
      "resetting env. episode reward total was 11.0. running mean: 1.61175343195078\n",
      "resetting env. episode reward total was -5.0. running mean: 1.545635897631272\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5001795386549592\n",
      "resetting env. episode reward total was -8.0. running mean: 1.4051777432684096\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4611259658357256\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4365147061773684\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4321495591155948\n",
      "resetting env. episode reward total was 6.0. running mean: 1.477828063524439\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4930497828891947\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5781192850603027\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6323380922096997\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6360147112876027\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6296545641747266\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6933580185329795\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6564244383476496\n",
      "resetting env. episode reward total was 5.0. running mean: 1.689860193964173\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7129615920245314\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6358319761042859\n",
      "resetting env. episode reward total was 5.0. running mean: 1.669473656343243\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6727789197798106\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7260511305820125\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6987906192761923\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6918027130834303\n",
      "resetting env. episode reward total was 1.0. running mean: 1.684884685952596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -11.0. running mean: 1.55803583909307\n",
      "resetting env. episode reward total was 12.0. running mean: 1.6624554807021394\n",
      "resetting env. episode reward total was 11.0. running mean: 1.7558309258951181\n",
      "resetting env. episode reward total was 8.0. running mean: 1.818272616636167\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8700898904698053\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8013889915651071\n",
      "resetting env. episode reward total was -3.0. running mean: 1.753375101649456\n",
      "resetting env. episode reward total was -1.0. running mean: 1.7258413506329615\n",
      "resetting env. episode reward total was 7.0. running mean: 1.778582937126632\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8007971077553657\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8427891366778122\n",
      "resetting env. episode reward total was 4.0. running mean: 1.864361245311034\n",
      "resetting env. episode reward total was 11.0. running mean: 1.9557176328579238\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8861604565293444\n",
      "resetting env. episode reward total was 3.0. running mean: 1.897298851964051\n",
      "resetting env. episode reward total was 14.0. running mean: 2.0183258634444106\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9581426048099664\n",
      "resetting env. episode reward total was -7.0. running mean: 1.8685611787618666\n",
      "resetting env. episode reward total was -3.0. running mean: 1.819875566974248\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8316768113045054\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8433600431914603\n",
      "resetting env. episode reward total was 13.0. running mean: 1.9549264427595459\n",
      "resetting env. episode reward total was -4.0. running mean: 1.8953771783319504\n",
      "resetting env. episode reward total was -5.0. running mean: 1.826423406548631\n",
      "resetting env. episode reward total was 14.0. running mean: 1.9481591724831446\n",
      "resetting env. episode reward total was -10.0. running mean: 1.828677580758313\n",
      "resetting env. episode reward total was 7.0. running mean: 1.88039080495073\n",
      "resetting env. episode reward total was -8.0. running mean: 1.7815868969012227\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7837710279322105\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8259333176528885\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8676739844763597\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9189972446315962\n",
      "resetting env. episode reward total was -5.0. running mean: 1.84980727218528\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8813091994634272\n",
      "resetting env. episode reward total was 8.0. running mean: 1.942496107468793\n",
      "resetting env. episode reward total was 4.0. running mean: 1.963071146394105\n",
      "resetting env. episode reward total was 2.0. running mean: 1.963440434930164\n",
      "resetting env. episode reward total was -11.0. running mean: 1.8338060305808621\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7854679702750536\n",
      "resetting env. episode reward total was 2.0. running mean: 1.787613290572303\n",
      "resetting env. episode reward total was 6.0. running mean: 1.82973715766658\n",
      "resetting env. episode reward total was 4.0. running mean: 1.851439786089914\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8729253882290149\n",
      "resetting env. episode reward total was 11.0. running mean: 1.964196134346725\n",
      "resetting env. episode reward total was -2.0. running mean: 1.9245541730032576\n",
      "resetting env. episode reward total was 1.0. running mean: 1.915308631273225\n",
      "resetting env. episode reward total was -11.0. running mean: 1.7861555449604927\n",
      "resetting env. episode reward total was -6.0. running mean: 1.7082939895108877\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6012110496157788\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6651989391196211\n",
      "resetting env. episode reward total was 5.0. running mean: 1.698546949728425\n",
      "resetting env. episode reward total was 10.0. running mean: 1.7815614802311408\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7337458654288294\n",
      "resetting env. episode reward total was -3.0. running mean: 1.686408406774541\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7395443227067957\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6921488794797277\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6452273906849304\n",
      "resetting env. episode reward total was -2.0. running mean: 1.608775116778081\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6326873656103003\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6563604919541972\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6797968870346554\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6529989181643088\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6064689289826657\n",
      "resetting env. episode reward total was 11.0. running mean: 1.7004042396928392\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7334001972959108\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7760661953229517\n",
      "resetting env. episode reward total was 8.0. running mean: 1.8383055333697222\n",
      "resetting env. episode reward total was 3.0. running mean: 1.849922478036025\n",
      "resetting env. episode reward total was -9.0. running mean: 1.7414232532556646\n",
      "resetting env. episode reward total was 10.0. running mean: 1.824009020723108\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8757689305158771\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8070112412107182\n",
      "resetting env. episode reward total was -7.0. running mean: 1.718941128798611\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6817517175106247\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7449342003355186\n",
      "resetting env. episode reward total was -1.0. running mean: 1.7174848583321634\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7303100097488417\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7630069096513534\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7653768405548398\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7677230721492914\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7700458414277984\n",
      "resetting env. episode reward total was 8.0. running mean: 1.8323453830135206\n",
      "resetting env. episode reward total was -9.0. running mean: 1.7240219291833854\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7467817098915515\n",
      "resetting env. episode reward total was -4.0. running mean: 1.6893138927926359\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7224207538647096\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7351965463260626\n",
      "resetting env. episode reward total was -4.0. running mean: 1.677844580862802\n",
      "resetting env. episode reward total was -7.0. running mean: 1.591066135054174\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6451554737036322\n",
      "resetting env. episode reward total was 6.0. running mean: 1.688703918966596\n",
      "resetting env. episode reward total was 2.0. running mean: 1.69181687977693\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7448987109791607\n",
      "resetting env. episode reward total was -3.0. running mean: 1.697449723869369\n",
      "resetting env. episode reward total was -7.0. running mean: 1.6104752266306754\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6343704743643688\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6580267696207251\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5914465019245179\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5055320369052727\n",
      "resetting env. episode reward total was 4.0. running mean: 1.53047671653622\n",
      "resetting env. episode reward total was 4.0. running mean: 1.555171949370858\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6096202298771494\n",
      "resetting env. episode reward total was 12.0. running mean: 1.7135240275783779\n",
      "resetting env. episode reward total was -9.0. running mean: 1.606388787302594\n",
      "resetting env. episode reward total was -3.0. running mean: 1.560324899429568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: 1.5047216504352723\n",
      "resetting env. episode reward total was -8.0. running mean: 1.4096744339309195\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4255776895916104\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4613219126956942\n",
      "resetting env. episode reward total was 12.0. running mean: 1.5667086935687373\n",
      "resetting env. episode reward total was 8.0. running mean: 1.63104160663305\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5847311905667194\n",
      "resetting env. episode reward total was 11.0. running mean: 1.6788838786610523\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7120950398744417\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7449740894756973\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7475243485809404\n",
      "resetting env. episode reward total was -2.0. running mean: 1.710049105095131\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7229486140441796\n",
      "resetting env. episode reward total was -7.0. running mean: 1.6357191279037377\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6993619366247004\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7023683172584534\n",
      "resetting env. episode reward total was 8.0. running mean: 1.765344634085869\n",
      "resetting env. episode reward total was 9.0. running mean: 1.8376911877450104\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8393142758675602\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8609211331088846\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9423119217777958\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9928888025600178\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9329599145344176\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9036303153890735\n",
      "resetting env. episode reward total was -4.0. running mean: 1.8445940122351827\n",
      "resetting env. episode reward total was 10.0. running mean: 1.926148072112831\n",
      "resetting env. episode reward total was -7.0. running mean: 1.8368865913917025\n",
      "resetting env. episode reward total was 9.0. running mean: 1.9085177254777856\n",
      "resetting env. episode reward total was -7.0. running mean: 1.8194325482230078\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9212382227407776\n",
      "resetting env. episode reward total was -14.0. running mean: 1.76202584051337\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8144055821082363\n",
      "resetting env. episode reward total was 5.0. running mean: 1.846261526287154\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8377989110242825\n",
      "resetting env. episode reward total was 9.0. running mean: 1.9094209219140397\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9503267126948993\n",
      "resetting env. episode reward total was 11.0. running mean: 2.04082344556795\n",
      "resetting env. episode reward total was -9.0. running mean: 1.9304152111122705\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8911110590011477\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8521999484111362\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8536779489270248\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8851411694377544\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9162897577433768\n",
      "resetting env. episode reward total was -3.0. running mean: 1.867126860165943\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7984555915642835\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7604710356486406\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7728663252921542\n",
      "resetting env. episode reward total was 9.0. running mean: 1.8451376620392326\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8766862854188402\n",
      "resetting env. episode reward total was 9.0. running mean: 1.947919422564652\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9484402283390054\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9789558260556155\n",
      "resetting env. episode reward total was -7.0. running mean: 1.8891662677950594\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8902746051171089\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8513718590659378\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8028581404752784\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8448295590705257\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8063812634798204\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8583174508450222\n",
      "resetting env. episode reward total was -11.0. running mean: 1.729734276336572\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6924369335732061\n",
      "resetting env. episode reward total was 3.0. running mean: 1.705512564237474\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7084574385950992\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6713728642091483\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6846591355670568\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6078125442113862\n",
      "resetting env. episode reward total was -6.0. running mean: 1.5317344187692723\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5864170745815795\n",
      "resetting env. episode reward total was -8.0. running mean: 1.4905529038357637\n",
      "resetting env. episode reward total was -7.0. running mean: 1.4056473747974059\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4015909010494318\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4475749920389376\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4230992421185482\n",
      "resetting env. episode reward total was 14.0. running mean: 1.548868249697363\n",
      "resetting env. episode reward total was -10.0. running mean: 1.4333795672003893\n",
      "resetting env. episode reward total was -11.0. running mean: 1.3090457715283852\n",
      "resetting env. episode reward total was -9.0. running mean: 1.2059553138131012\n",
      "resetting env. episode reward total was 11.0. running mean: 1.3038957606749702\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3708568030682204\n",
      "resetting env. episode reward total was 14.0. running mean: 1.497148235037538\n",
      "resetting env. episode reward total was 12.0. running mean: 1.6021767526871624\n",
      "resetting env. episode reward total was -6.0. running mean: 1.5261549851602907\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5408934353086878\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5654845009556009\n",
      "resetting env. episode reward total was -9.0. running mean: 1.4598296559460449\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5152313593865845\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5700790457927187\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6143782553347916\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5882344727814437\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6023521280536293\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5663286067730928\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5606653207053618\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6050586674983083\n",
      "resetting env. episode reward total was -5.0. running mean: 1.539008080823325\n",
      "resetting env. episode reward total was -11.0. running mean: 1.4136180000150917\n",
      "resetting env. episode reward total was 11.0. running mean: 1.509481820014941\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5643870018147916\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6387431317966439\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6123557004786775\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5862321434738906\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5403698220391517\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6149661238187603\n",
      "resetting env. episode reward total was -6.0. running mean: 1.5388164625805727\n",
      "resetting env. episode reward total was 11.0. running mean: 1.633428297954767\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5670940149752193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: 1.5214230748254671\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6062088440772124\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6301467556364404\n",
      "resetting env. episode reward total was 11.0. running mean: 1.723845288080076\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6166068351992753\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6104407668472824\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5643363591788095\n",
      "resetting env. episode reward total was -6.0. running mean: 1.4886929955870214\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4638060656311511\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4391680049748397\n",
      "resetting env. episode reward total was 13.0. running mean: 1.5547763249250912\n",
      "resetting env. episode reward total was -11.0. running mean: 1.4292285616758402\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4749362760590818\n",
      "resetting env. episode reward total was 3.0. running mean: 1.490186913298491\n",
      "resetting env. episode reward total was 14.0. running mean: 1.615285044165506\n",
      "resetting env. episode reward total was -11.0. running mean: 1.4891321937238509\n",
      "resetting env. episode reward total was 5.0. running mean: 1.5242408717866125\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5289984630687463\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6137084784380589\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6775713936536782\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7107956797171415\n",
      "resetting env. episode reward total was 10.0. running mean: 1.7936877229199701\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7957508456907705\n",
      "resetting env. episode reward total was 10.0. running mean: 1.8777933372338629\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9190154038615244\n",
      "resetting env. episode reward total was 12.0. running mean: 2.019825249822909\n",
      "resetting env. episode reward total was 3.0. running mean: 2.0296269973246797\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9993307273514327\n",
      "resetting env. episode reward total was 11.0. running mean: 2.0893374200779182\n",
      "resetting env. episode reward total was 10.0. running mean: 2.168444045877139\n",
      "resetting env. episode reward total was 9.0. running mean: 2.2367596054183676\n",
      "resetting env. episode reward total was -8.0. running mean: 2.1343920093641837\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1730480892705417\n",
      "resetting env. episode reward total was -3.0. running mean: 2.1213176083778365\n",
      "resetting env. episode reward total was -13.0. running mean: 1.970104432294058\n",
      "resetting env. episode reward total was -3.0. running mean: 1.9204033879711173\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9811993540914061\n",
      "resetting env. episode reward total was -2.0. running mean: 1.941387360550492\n",
      "resetting env. episode reward total was 10.0. running mean: 2.021973486944987\n",
      "resetting env. episode reward total was -14.0. running mean: 1.8617537520755372\n",
      "resetting env. episode reward total was 12.0. running mean: 1.963136214554782\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9535048524092342\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9839698038851419\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9841301058462906\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9942888047878278\n",
      "resetting env. episode reward total was 11.0. running mean: 2.0843459167399496\n",
      "resetting env. episode reward total was 1.0. running mean: 2.07350245757255\n",
      "resetting env. episode reward total was -7.0. running mean: 1.9827674329968243\n",
      "resetting env. episode reward total was -3.0. running mean: 1.932939758666856\n",
      "resetting env. episode reward total was 11.0. running mean: 2.023610361080187\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0233742574693854\n",
      "resetting env. episode reward total was -9.0. running mean: 1.9131405148946914\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8440091097457445\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8555690186482872\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8270133284618042\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8687431951771862\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8700557632254144\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9113552055931604\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9222416535372289\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8930192370018566\n",
      "resetting env. episode reward total was -3.0. running mean: 1.844089044631838\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8956481541855197\n",
      "resetting env. episode reward total was -4.0. running mean: 1.8366916726436644\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7683247559172277\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7206415083580553\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7434350932744747\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7760007423417299\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7082407349183126\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6611583275691295\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6645467442934383\n",
      "resetting env. episode reward total was 2.0. running mean: 1.667901276850504\n",
      "resetting env. episode reward total was 12.0. running mean: 1.7712222640819988\n",
      "resetting env. episode reward total was -10.0. running mean: 1.6535100414411787\n",
      "resetting env. episode reward total was 9.0. running mean: 1.726974941026767\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7897051916164994\n",
      "resetting env. episode reward total was 17.0. running mean: 1.9418081397003344\n",
      "resetting env. episode reward total was -3.0. running mean: 1.892390058303331\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8834661577202978\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8546314961430947\n",
      "resetting env. episode reward total was 4.0. running mean: 1.876085181181664\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9573243293698472\n",
      "resetting env. episode reward total was -9.0. running mean: 1.8477510860761486\n",
      "resetting env. episode reward total was 6.0. running mean: 1.889273575215387\n",
      "resetting env. episode reward total was -7.0. running mean: 1.8003808394632332\n",
      "resetting env. episode reward total was 9.0. running mean: 1.872377031068601\n",
      "resetting env. episode reward total was 6.0. running mean: 1.913653260757915\n",
      "resetting env. episode reward total was 1.0. running mean: 1.904516728150336\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9254715608688326\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9762168452601443\n",
      "resetting env. episode reward total was -6.0. running mean: 1.8964546768075428\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9474901300394674\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9480152287390726\n",
      "resetting env. episode reward total was 2.0. running mean: 1.948535076451682\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9390497256871653\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9596592284302936\n",
      "resetting env. episode reward total was -7.0. running mean: 1.8700626361459907\n",
      "resetting env. episode reward total was 11.0. running mean: 1.9613620097845308\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9017483896866854\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9327309057898185\n",
      "resetting env. episode reward total was -13.0. running mean: 1.7834035967319202\n",
      "resetting env. episode reward total was 5.0. running mean: 1.815569560764601\n",
      "resetting env. episode reward total was 5.0. running mean: 1.847413865156955\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8589397265053853\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8803503292403314\n",
      "resetting env. episode reward total was 11.0. running mean: 1.971546825947928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -9.0. running mean: 1.8618313576884487\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9132130441115642\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9940809136704487\n",
      "resetting env. episode reward total was 9.0. running mean: 2.064140104533744\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0234987034884067\n",
      "resetting env. episode reward total was 9.0. running mean: 2.0932637164535226\n",
      "resetting env. episode reward total was -13.0. running mean: 1.9423310792889876\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8729077684960977\n",
      "resetting env. episode reward total was -11.0. running mean: 1.7441786908111367\n",
      "resetting env. episode reward total was -4.0. running mean: 1.6867369039030253\n",
      "resetting env. episode reward total was -15.0. running mean: 1.5198695348639952\n",
      "resetting env. episode reward total was -4.0. running mean: 1.4646708395153551\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4800241311202016\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4552238898089995\n",
      "resetting env. episode reward total was -6.0. running mean: 1.3806716509109094\n",
      "resetting env. episode reward total was 9.0. running mean: 1.4568649344018003\n",
      "resetting env. episode reward total was -9.0. running mean: 1.3522962850577822\n",
      "resetting env. episode reward total was 9.0. running mean: 1.4287733222072045\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3844855889851324\n",
      "resetting env. episode reward total was -11.0. running mean: 1.260640733095281\n",
      "resetting env. episode reward total was 5.0. running mean: 1.298034325764328\n",
      "resetting env. episode reward total was 13.0. running mean: 1.4150539825066848\n",
      "resetting env. episode reward total was -14.0. running mean: 1.260903442681618\n",
      "resetting env. episode reward total was -3.0. running mean: 1.2182944082548017\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2361114641722537\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2737503495305311\n",
      "resetting env. episode reward total was 4.0. running mean: 1.301012846035226\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3680027175748737\n",
      "resetting env. episode reward total was 6.0. running mean: 1.414322690399125\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3301794634951338\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3668776688601825\n",
      "resetting env. episode reward total was 10.0. running mean: 1.4532088921715807\n",
      "resetting env. episode reward total was -9.0. running mean: 1.3486768032498648\n",
      "resetting env. episode reward total was 12.0. running mean: 1.4551900352173663\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3706381348651926\n",
      "resetting env. episode reward total was -9.0. running mean: 1.2669317535165405\n",
      "resetting env. episode reward total was -12.0. running mean: 1.134262435981375\n",
      "resetting env. episode reward total was 6.0. running mean: 1.1829198116215613\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2310906135053459\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1887797073702924\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2168919102965894\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1947229911936235\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1527757612816871\n",
      "resetting env. episode reward total was 5.0. running mean: 1.1912480036688702\n",
      "resetting env. episode reward total was 12.0. running mean: 1.2993355236321813\n",
      "resetting env. episode reward total was -7.0. running mean: 1.2163421683958595\n",
      "resetting env. episode reward total was 8.0. running mean: 1.284178746711901\n",
      "resetting env. episode reward total was -2.0. running mean: 1.251336959244782\n",
      "resetting env. episode reward total was 13.0. running mean: 1.3688235896523344\n",
      "resetting env. episode reward total was 2.0. running mean: 1.375135353755811\n",
      "resetting env. episode reward total was 8.0. running mean: 1.441384000218253\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4569701602160705\n",
      "resetting env. episode reward total was 7.0. running mean: 1.51240045861391\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4672764540277707\n",
      "resetting env. episode reward total was 1.0. running mean: 1.462603689487493\n",
      "resetting env. episode reward total was 6.0. running mean: 1.507977652592618\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5328978760666918\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4675688973060248\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5128932083329647\n",
      "resetting env. episode reward total was 9.0. running mean: 1.5877642762496351\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5218866334871388\n",
      "resetting env. episode reward total was 11.0. running mean: 1.6166677671522676\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6105010894807448\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6843960785859373\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5975521178000778\n",
      "resetting env. episode reward total was 1.0. running mean: 1.591576596622077\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5456608306558561\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5202042223492975\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5450021801258045\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5995521583245464\n",
      "resetting env. episode reward total was -1.0. running mean: 1.573556636741301\n",
      "resetting env. episode reward total was 1.0. running mean: 1.567821070373888\n",
      "resetting env. episode reward total was 11.0. running mean: 1.662142859670149\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6655214310734476\n",
      "resetting env. episode reward total was -3.0. running mean: 1.618866216762713\n",
      "resetting env. episode reward total was -1.0. running mean: 1.592677554595086\n",
      "resetting env. episode reward total was 1.0. running mean: 1.586750779049135\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6008832712586438\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6248744385460574\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5586256941605967\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5330394372189906\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5977090428468008\n",
      "resetting env. episode reward total was 5.0. running mean: 1.631731952418333\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6554146328941497\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7188604865652082\n",
      "resetting env. episode reward total was 11.0. running mean: 1.8116718816995563\n",
      "resetting env. episode reward total was -1.0. running mean: 1.7835551628825608\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7957196112537352\n",
      "resetting env. episode reward total was -13.0. running mean: 1.647762415141198\n",
      "resetting env. episode reward total was -5.0. running mean: 1.581284790989786\n",
      "resetting env. episode reward total was -6.0. running mean: 1.5054719430798882\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5904172236490894\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6445130514125985\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6680679208984726\n",
      "resetting env. episode reward total was -11.0. running mean: 1.5413872416894878\n",
      "resetting env. episode reward total was 10.0. running mean: 1.625973369272593\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6597136355798672\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6131164992240685\n",
      "resetting env. episode reward total was 6.0. running mean: 1.656985334231828\n",
      "resetting env. episode reward total was -8.0. running mean: 1.5604154808895097\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6348113260806145\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5984632128198084\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5724785806916104\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6167537948846944\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6205862569358473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 1.654380394366489\n",
      "resetting env. episode reward total was 9.0. running mean: 1.7278365904228241\n",
      "resetting env. episode reward total was 11.0. running mean: 1.820558224518596\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8623526422734102\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9137291158506762\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9445918246921694\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8951459064452476\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8561944473807952\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8476325029069873\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8191561778779175\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7709646160991384\n",
      "resetting env. episode reward total was -12.0. running mean: 1.6332549699381471\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6869224202387656\n",
      "resetting env. episode reward total was -7.0. running mean: 1.600053196036378\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6340526640760142\n",
      "resetting env. episode reward total was -5.0. running mean: 1.567712137435254\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5720350160609016\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5463146659002924\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5708515192412895\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6551430040488766\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6685915740083879\n",
      "resetting env. episode reward total was 3.0. running mean: 1.681905658268304\n",
      "resetting env. episode reward total was 6.0. running mean: 1.725086601685621\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7678357356687648\n",
      "resetting env. episode reward total was -11.0. running mean: 1.640157378312077\n",
      "resetting env. episode reward total was 10.0. running mean: 1.7237558045289565\n",
      "resetting env. episode reward total was -12.0. running mean: 1.5865182464836671\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5206530640188305\n",
      "resetting env. episode reward total was 11.0. running mean: 1.6154465333786423\n",
      "resetting env. episode reward total was 3.0. running mean: 1.629292068044856\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6829991473644075\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6561691558907634\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6996074643318557\n",
      "resetting env. episode reward total was 4.0. running mean: 1.722611389688537\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6753852757916516\n",
      "resetting env. episode reward total was -7.0. running mean: 1.588631423033735\n",
      "resetting env. episode reward total was 14.0. running mean: 1.7127451088033978\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6356176577153638\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6892614811382103\n",
      "resetting env. episode reward total was -6.0. running mean: 1.612368866326828\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6362451776635598\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6098827258869242\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5737838986280548\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5080460596417742\n",
      "resetting env. episode reward total was -7.0. running mean: 1.4229655990453565\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3587359430549029\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3951485836243538\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4011970977881103\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4671851268102292\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4225132755421268\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4582881427867056\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4537052613588386\n",
      "resetting env. episode reward total was 12.0. running mean: 1.55916820874525\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5635765266577977\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6279407613912198\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6416613537773077\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6552447402395347\n",
      "resetting env. episode reward total was -11.0. running mean: 1.5286922928371394\n",
      "resetting env. episode reward total was 7.0. running mean: 1.583405369908768\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6075713162096803\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6614956030475836\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6148806470171078\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6187318405469366\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6625445221414674\n",
      "resetting env. episode reward total was -6.0. running mean: 1.5859190769200526\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6200598861508522\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6838592872893436\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6570206944164503\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5704504874722858\n",
      "resetting env. episode reward total was 4.0. running mean: 1.594745982597563\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5287985227715872\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4635105375438713\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4388754321684325\n",
      "resetting env. episode reward total was -9.0. running mean: 1.3344866778467481\n",
      "resetting env. episode reward total was -8.0. running mean: 1.2411418110682806\n",
      "resetting env. episode reward total was -6.0. running mean: 1.1687303929575976\n",
      "resetting env. episode reward total was 1.0. running mean: 1.1670430890280217\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1453726581377415\n",
      "resetting env. episode reward total was 9.0. running mean: 1.223918931556364\n",
      "resetting env. episode reward total was 11.0. running mean: 1.3216797422408006\n",
      "resetting env. episode reward total was 13.0. running mean: 1.4384629448183928\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5040783153702089\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5190375322165068\n",
      "resetting env. episode reward total was -8.0. running mean: 1.4238471568943416\n",
      "resetting env. episode reward total was -10.0. running mean: 1.309608685325398\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3365125984721442\n",
      "resetting env. episode reward total was 17.0. running mean: 1.4931474724874227\n",
      "resetting env. episode reward total was 9.0. running mean: 1.5682159977625485\n",
      "resetting env. episode reward total was 13.0. running mean: 1.682533837784923\n",
      "resetting env. episode reward total was 7.0. running mean: 1.735708499407074\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7283514144130032\n",
      "resetting env. episode reward total was -4.0. running mean: 1.671067900268873\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5843572212661843\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6085136490535226\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6224285125629874\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5662042274373575\n",
      "resetting env. episode reward total was -6.0. running mean: 1.4905421851629839\n",
      "resetting env. episode reward total was -9.0. running mean: 1.385636763311354\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3817803956782404\n",
      "resetting env. episode reward total was 3.0. running mean: 1.397962591721458\n",
      "resetting env. episode reward total was -4.0. running mean: 1.3439829658042433\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2805431361462007\n",
      "resetting env. episode reward total was 13.0. running mean: 1.3977377047847388\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4637603277368916\n",
      "resetting env. episode reward total was 11.0. running mean: 1.5591227244595227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: 1.5135314972149274\n",
      "resetting env. episode reward total was 13.0. running mean: 1.6283961822427782\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6021122204203504\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5460910982161469\n",
      "resetting env. episode reward total was -6.0. running mean: 1.4706301872339853\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5359238853616455\n",
      "resetting env. episode reward total was -1.0. running mean: 1.510564646508029\n",
      "resetting env. episode reward total was 11.0. running mean: 1.6054590000429487\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6094044100425193\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6933103659420943\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6563772622826733\n",
      "resetting env. episode reward total was 12.0. running mean: 1.7598134896598467\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7222153547632482\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6749932012156157\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6282432692034594\n",
      "resetting env. episode reward total was -6.0. running mean: 1.5519608365114248\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5964412281463105\n",
      "resetting env. episode reward total was 17.0. running mean: 1.7504768158648474\n",
      "resetting env. episode reward total was -1.0. running mean: 1.722972047706199\n",
      "resetting env. episode reward total was -12.0. running mean: 1.5857423272291369\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5598849039568454\n",
      "resetting env. episode reward total was 8.0. running mean: 1.624286054917277\n",
      "resetting env. episode reward total was -9.0. running mean: 1.5180431943681043\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6028627624244234\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6068341348001791\n",
      "resetting env. episode reward total was -9.0. running mean: 1.5007657934521772\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5457581355176555\n",
      "resetting env. episode reward total was 6.0. running mean: 1.590300554162479\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6243975486208544\n",
      "resetting env. episode reward total was -2.0. running mean: 1.588153573134646\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6022720374032995\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5562493170292664\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5506868238589737\n",
      "resetting env. episode reward total was 1.0. running mean: 1.545179955620384\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5197281560641802\n",
      "resetting env. episode reward total was -8.0. running mean: 1.4245308745035383\n",
      "resetting env. episode reward total was 4.0. running mean: 1.450285565758503\n",
      "resetting env. episode reward total was -4.0. running mean: 1.395782710100918\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4118248829999087\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3277066341699095\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3944295678282106\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3104852721499285\n",
      "resetting env. episode reward total was -9.0. running mean: 1.2073804194284292\n",
      "resetting env. episode reward total was 2.0. running mean: 1.215306615234145\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1531535490818035\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1316220135909854\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2103057934550756\n",
      "resetting env. episode reward total was 3.0. running mean: 1.228202735520525\n",
      "resetting env. episode reward total was -7.0. running mean: 1.1459207081653195\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1744615010836663\n",
      "resetting env. episode reward total was -11.0. running mean: 1.0527168860728295\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0721897172121013\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0914678200399803\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1205531418395807\n",
      "resetting env. episode reward total was 3.0. running mean: 1.1393476104211848\n",
      "resetting env. episode reward total was -2.0. running mean: 1.107954134316973\n",
      "resetting env. episode reward total was 2.0. running mean: 1.1168745929738033\n",
      "resetting env. episode reward total was 1.0. running mean: 1.1157058470440653\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0745487885736247\n",
      "resetting env. episode reward total was 11.0. running mean: 1.1738033006878885\n",
      "resetting env. episode reward total was 1.0. running mean: 1.1720652676810097\n",
      "resetting env. episode reward total was -7.0. running mean: 1.0903446150041995\n",
      "resetting env. episode reward total was -5.0. running mean: 1.0294411688541576\n",
      "resetting env. episode reward total was -6.0. running mean: 0.959146757165616\n",
      "resetting env. episode reward total was -7.0. running mean: 0.8795552895939598\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8807597366980202\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9319521393310399\n",
      "resetting env. episode reward total was -14.0. running mean: 0.7826326179377295\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7548062917583522\n",
      "resetting env. episode reward total was 4.0. running mean: 0.7872582288407688\n",
      "resetting env. episode reward total was 8.0. running mean: 0.859385646552361\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8907917900868375\n",
      "resetting env. episode reward total was 9.0. running mean: 0.971883872185969\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8721650334641093\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8734433831294682\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9347089492981735\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9753618598051917\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9256082412071398\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8663521587950683\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8676886372071176\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8390117508350464\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7806216333266959\n",
      "resetting env. episode reward total was -6.0. running mean: 0.7128154169934289\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7656872628234945\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6880303901952596\n",
      "resetting env. episode reward total was 3.0. running mean: 0.711150086293307\n",
      "resetting env. episode reward total was 2.0. running mean: 0.7240385854303739\n",
      "resetting env. episode reward total was -6.0. running mean: 0.6567981995760701\n",
      "resetting env. episode reward total was 8.0. running mean: 0.7302302175803094\n",
      "resetting env. episode reward total was 1.0. running mean: 0.7329279154045063\n",
      "resetting env. episode reward total was 9.0. running mean: 0.8155986362504613\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7574426498879566\n",
      "resetting env. episode reward total was 5.0. running mean: 0.799868223389077\n",
      "resetting env. episode reward total was 13.0. running mean: 0.9218695411551863\n",
      "resetting env. episode reward total was 9.0. running mean: 1.0026508457436345\n",
      "resetting env. episode reward total was 6.0. running mean: 1.052624337286198\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0920980939133362\n",
      "resetting env. episode reward total was 8.0. running mean: 1.161177112974203\n",
      "resetting env. episode reward total was -7.0. running mean: 1.0795653418444608\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0587696884260163\n",
      "resetting env. episode reward total was -2.0. running mean: 1.028181991541756\n",
      "resetting env. episode reward total was 14.0. running mean: 1.1579001716263386\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2363211699100753\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3239579582109746\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3707183786288648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 1.4470111948425761\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5025410828941503\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4575156720652087\n",
      "resetting env. episode reward total was -9.0. running mean: 1.3529405153445566\n",
      "resetting env. episode reward total was 2.0. running mean: 1.359411110191111\n",
      "resetting env. episode reward total was 3.0. running mean: 1.3758169990892\n",
      "resetting env. episode reward total was 3.0. running mean: 1.392058829098308\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3281382408073248\n",
      "resetting env. episode reward total was -17.0. running mean: 1.1448568583992516\n",
      "resetting env. episode reward total was 12.0. running mean: 1.2534082898152592\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2908742069171066\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2279654648479355\n",
      "resetting env. episode reward total was 12.0. running mean: 1.3356858101994562\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3823289520974618\n",
      "resetting env. episode reward total was -3.0. running mean: 1.338505662576487\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4051206059507222\n",
      "resetting env. episode reward total was 11.0. running mean: 1.501069399891215\n",
      "resetting env. episode reward total was 3.0. running mean: 1.516058705892303\n",
      "resetting env. episode reward total was 4.0. running mean: 1.54089811883338\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5154891376450461\n",
      "resetting env. episode reward total was -7.0. running mean: 1.4303342462685955\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5160309038059097\n",
      "resetting env. episode reward total was -14.0. running mean: 1.3608705947678503\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3972618888201718\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4132892699319701\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4691563772326506\n",
      "resetting env. episode reward total was 6.0. running mean: 1.514464813460324\n",
      "resetting env. episode reward total was 5.0. running mean: 1.549320165325721\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5038269636724637\n",
      "resetting env. episode reward total was 1.0. running mean: 1.498788694035739\n",
      "resetting env. episode reward total was 9.0. running mean: 1.5738008070953817\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6380627990244279\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6916821710341836\n",
      "resetting env. episode reward total was -7.0. running mean: 1.6047653493238416\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6887176958306034\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7418305188722973\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7444122136835745\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7969680915467388\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7889984106312713\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7411084265249586\n",
      "resetting env. episode reward total was 4.0. running mean: 1.763697342259709\n",
      "resetting env. episode reward total was 5.0. running mean: 1.796060368837112\n",
      "resetting env. episode reward total was 14.0. running mean: 1.918099765148741\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9589187674972537\n",
      "resetting env. episode reward total was -3.0. running mean: 1.9093295798222811\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9302362840240583\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9209339211838177\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9117245819719795\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8626073361522597\n",
      "resetting env. episode reward total was 3.0. running mean: 1.873981262790737\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8252414501628296\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8269890356612013\n",
      "resetting env. episode reward total was -8.0. running mean: 1.7287191453045891\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7614319538515433\n",
      "resetting env. episode reward total was -7.0. running mean: 1.6738176343130278\n",
      "resetting env. episode reward total was -4.0. running mean: 1.6170794579698975\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6709086633901986\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7141995767562968\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6470575809887338\n",
      "resetting env. episode reward total was 14.0. running mean: 1.7705870051788466\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7928811351270582\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7449523237757876\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6375028005380297\n",
      "resetting env. episode reward total was 11.0. running mean: 1.7311277725326495\n",
      "resetting env. episode reward total was 7.0. running mean: 1.783816494807323\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7959783298592498\n",
      "resetting env. episode reward total was 10.0. running mean: 1.8780185465606574\n",
      "resetting env. episode reward total was 9.0. running mean: 1.9492383610950508\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9997459774841002\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0197485177092593\n",
      "resetting env. episode reward total was 1.0. running mean: 2.009551032532167\n",
      "resetting env. episode reward total was 7.0. running mean: 2.059455522206845\n",
      "resetting env. episode reward total was 4.0. running mean: 2.078860966984777\n",
      "resetting env. episode reward total was 5.0. running mean: 2.1080723573149287\n",
      "resetting env. episode reward total was 7.0. running mean: 2.156991633741779\n",
      "resetting env. episode reward total was 13.0. running mean: 2.265421717404361\n",
      "resetting env. episode reward total was 8.0. running mean: 2.3227675002303174\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2895398252280144\n",
      "resetting env. episode reward total was 7.0. running mean: 2.336644426975734\n",
      "resetting env. episode reward total was 12.0. running mean: 2.433277982705977\n",
      "resetting env. episode reward total was 12.0. running mean: 2.5289452028789174\n",
      "resetting env. episode reward total was 3.0. running mean: 2.533655750850128\n",
      "resetting env. episode reward total was 11.0. running mean: 2.6183191933416263\n",
      "resetting env. episode reward total was 10.0. running mean: 2.69213600140821\n",
      "resetting env. episode reward total was 10.0. running mean: 2.765214641394128\n",
      "resetting env. episode reward total was -4.0. running mean: 2.6975624949801866\n",
      "resetting env. episode reward total was 5.0. running mean: 2.7205868700303846\n",
      "resetting env. episode reward total was 4.0. running mean: 2.7333810013300806\n",
      "resetting env. episode reward total was 6.0. running mean: 2.7660471913167797\n",
      "resetting env. episode reward total was 1.0. running mean: 2.748386719403612\n",
      "resetting env. episode reward total was -1.0. running mean: 2.7109028522095757\n",
      "resetting env. episode reward total was 9.0. running mean: 2.77379382368748\n",
      "resetting env. episode reward total was 12.0. running mean: 2.866055885450605\n",
      "resetting env. episode reward total was 8.0. running mean: 2.917395326596099\n",
      "resetting env. episode reward total was 10.0. running mean: 2.988221373330138\n",
      "resetting env. episode reward total was 7.0. running mean: 3.0283391595968365\n",
      "resetting env. episode reward total was 10.0. running mean: 3.0980557680008682\n",
      "resetting env. episode reward total was 2.0. running mean: 3.0870752103208594\n",
      "resetting env. episode reward total was 4.0. running mean: 3.0962044582176507\n",
      "resetting env. episode reward total was 10.0. running mean: 3.1652424136354744\n",
      "resetting env. episode reward total was 8.0. running mean: 3.21358998949912\n",
      "resetting env. episode reward total was 8.0. running mean: 3.2614540896041286\n",
      "resetting env. episode reward total was 9.0. running mean: 3.318839548708087\n",
      "resetting env. episode reward total was 3.0. running mean: 3.315651153221006\n",
      "resetting env. episode reward total was 11.0. running mean: 3.392494641688796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 3.4985696952719083\n",
      "resetting env. episode reward total was 7.0. running mean: 3.5335839983191892\n",
      "resetting env. episode reward total was -1.0. running mean: 3.4882481583359977\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4733656767526377\n",
      "resetting env. episode reward total was 6.0. running mean: 3.4986320199851115\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4836456997852605\n",
      "resetting env. episode reward total was 6.0. running mean: 3.508809242787408\n",
      "resetting env. episode reward total was -2.0. running mean: 3.4537211503595335\n",
      "resetting env. episode reward total was -7.0. running mean: 3.3491839388559383\n",
      "resetting env. episode reward total was -6.0. running mean: 3.255692099467379\n",
      "resetting env. episode reward total was 5.0. running mean: 3.273135178472705\n",
      "resetting env. episode reward total was -5.0. running mean: 3.190403826687978\n",
      "resetting env. episode reward total was 2.0. running mean: 3.178499788421098\n",
      "resetting env. episode reward total was 2.0. running mean: 3.1667147905368873\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1750476426315184\n",
      "resetting env. episode reward total was -7.0. running mean: 3.0732971662052035\n",
      "resetting env. episode reward total was 4.0. running mean: 3.0825641945431514\n",
      "resetting env. episode reward total was 9.0. running mean: 3.1417385525977197\n",
      "resetting env. episode reward total was 12.0. running mean: 3.2303211670717427\n",
      "resetting env. episode reward total was 11.0. running mean: 3.308017955401025\n",
      "resetting env. episode reward total was -3.0. running mean: 3.244937775847015\n",
      "resetting env. episode reward total was 2.0. running mean: 3.232488398088545\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2701635141076593\n",
      "resetting env. episode reward total was 12.0. running mean: 3.357461878966583\n",
      "resetting env. episode reward total was 2.0. running mean: 3.343887260176917\n",
      "resetting env. episode reward total was 4.0. running mean: 3.3504483875751476\n",
      "resetting env. episode reward total was 4.0. running mean: 3.356943903699396\n",
      "resetting env. episode reward total was 12.0. running mean: 3.4433744646624023\n",
      "resetting env. episode reward total was 9.0. running mean: 3.4989407200157783\n",
      "resetting env. episode reward total was -1.0. running mean: 3.4539513128156205\n",
      "resetting env. episode reward total was -2.0. running mean: 3.3994117996874644\n",
      "resetting env. episode reward total was 6.0. running mean: 3.4254176816905897\n",
      "resetting env. episode reward total was 4.0. running mean: 3.431163504873684\n",
      "resetting env. episode reward total was 13.0. running mean: 3.526851869824947\n",
      "resetting env. episode reward total was 7.0. running mean: 3.561583351126697\n",
      "resetting env. episode reward total was 4.0. running mean: 3.56596751761543\n",
      "resetting env. episode reward total was -8.0. running mean: 3.4503078424392757\n",
      "resetting env. episode reward total was 7.0. running mean: 3.485804764014883\n",
      "resetting env. episode reward total was -2.0. running mean: 3.430946716374734\n",
      "resetting env. episode reward total was 3.0. running mean: 3.4266372492109864\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4323708767188768\n",
      "resetting env. episode reward total was -5.0. running mean: 3.3480471679516883\n",
      "resetting env. episode reward total was 4.0. running mean: 3.3545666962721716\n",
      "resetting env. episode reward total was 5.0. running mean: 3.37102102930945\n",
      "resetting env. episode reward total was 7.0. running mean: 3.407310819016355\n",
      "resetting env. episode reward total was -3.0. running mean: 3.3432377108261915\n",
      "resetting env. episode reward total was 7.0. running mean: 3.3798053337179295\n",
      "resetting env. episode reward total was -7.0. running mean: 3.2760072803807505\n",
      "resetting env. episode reward total was -1.0. running mean: 3.233247207576943\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2709147355011736\n",
      "resetting env. episode reward total was 14.0. running mean: 3.378205588146162\n",
      "resetting env. episode reward total was 2.0. running mean: 3.3644235322647003\n",
      "resetting env. episode reward total was 10.0. running mean: 3.4307792969420534\n",
      "resetting env. episode reward total was 9.0. running mean: 3.486471503972633\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4916067889329065\n",
      "resetting env. episode reward total was 12.0. running mean: 3.5766907210435774\n",
      "resetting env. episode reward total was -2.0. running mean: 3.5209238138331416\n",
      "resetting env. episode reward total was -4.0. running mean: 3.44571457569481\n",
      "resetting env. episode reward total was 3.0. running mean: 3.441257429937862\n",
      "resetting env. episode reward total was -1.0. running mean: 3.3968448556384834\n",
      "resetting env. episode reward total was 11.0. running mean: 3.4728764070820985\n",
      "resetting env. episode reward total was 10.0. running mean: 3.5381476430112775\n",
      "resetting env. episode reward total was -7.0. running mean: 3.432766166581165\n",
      "resetting env. episode reward total was 1.0. running mean: 3.408438504915353\n",
      "resetting env. episode reward total was 5.0. running mean: 3.4243541198661993\n",
      "resetting env. episode reward total was -1.0. running mean: 3.3801105786675376\n",
      "resetting env. episode reward total was -1.0. running mean: 3.3363094728808624\n",
      "resetting env. episode reward total was -7.0. running mean: 3.2329463781520538\n",
      "resetting env. episode reward total was 15.0. running mean: 3.350616914370533\n",
      "resetting env. episode reward total was 12.0. running mean: 3.437110745226828\n",
      "resetting env. episode reward total was 11.0. running mean: 3.5127396377745597\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5176122413968143\n",
      "resetting env. episode reward total was 3.0. running mean: 3.512436118982846\n",
      "resetting env. episode reward total was 3.0. running mean: 3.5073117577930173\n",
      "resetting env. episode reward total was -13.0. running mean: 3.342238640215087\n",
      "resetting env. episode reward total was 2.0. running mean: 3.328816253812936\n",
      "resetting env. episode reward total was 15.0. running mean: 3.4455280912748067\n",
      "resetting env. episode reward total was 8.0. running mean: 3.4910728103620587\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5361620822584383\n",
      "resetting env. episode reward total was 8.0. running mean: 3.580800461435854\n",
      "resetting env. episode reward total was 15.0. running mean: 3.6949924568214954\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7480425322532804\n",
      "resetting env. episode reward total was 11.0. running mean: 3.8205621069307476\n",
      "resetting env. episode reward total was 7.0. running mean: 3.85235648586144\n",
      "resetting env. episode reward total was 4.0. running mean: 3.8538329210028253\n",
      "resetting env. episode reward total was 9.0. running mean: 3.905294591792797\n",
      "resetting env. episode reward total was 3.0. running mean: 3.896241645874869\n",
      "resetting env. episode reward total was 10.0. running mean: 3.9572792294161205\n",
      "resetting env. episode reward total was 12.0. running mean: 4.037706437121959\n",
      "resetting env. episode reward total was 6.0. running mean: 4.057329372750739\n",
      "resetting env. episode reward total was -2.0. running mean: 3.9967560790232315\n",
      "resetting env. episode reward total was 4.0. running mean: 3.996788518232999\n",
      "resetting env. episode reward total was -9.0. running mean: 3.8668206330506694\n",
      "resetting env. episode reward total was 6.0. running mean: 3.8881524267201626\n",
      "resetting env. episode reward total was 5.0. running mean: 3.899270902452961\n",
      "resetting env. episode reward total was 2.0. running mean: 3.880278193428431\n",
      "resetting env. episode reward total was -3.0. running mean: 3.811475411494147\n",
      "resetting env. episode reward total was 2.0. running mean: 3.7933606573792056\n",
      "resetting env. episode reward total was 7.0. running mean: 3.825427050805413\n",
      "resetting env. episode reward total was -3.0. running mean: 3.7571727802973593\n",
      "resetting env. episode reward total was -1.0. running mean: 3.709601052494386\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7625050419694417\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7648799915497473\n",
      "resetting env. episode reward total was 2.0. running mean: 3.74723119163425\n",
      "resetting env. episode reward total was -2.0. running mean: 3.6897588797179073\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6428612909207283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 3.716432678011521\n",
      "resetting env. episode reward total was -4.0. running mean: 3.6392683512314057\n",
      "resetting env. episode reward total was 15.0. running mean: 3.7528756677190915\n",
      "resetting env. episode reward total was 2.0. running mean: 3.7353469110419004\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7479934419314813\n",
      "resetting env. episode reward total was -6.0. running mean: 3.6505135075121666\n",
      "resetting env. episode reward total was 6.0. running mean: 3.674008372437045\n",
      "resetting env. episode reward total was 5.0. running mean: 3.687268288712674\n",
      "resetting env. episode reward total was 14.0. running mean: 3.7903956058255477\n",
      "resetting env. episode reward total was -11.0. running mean: 3.642491649767292\n",
      "resetting env. episode reward total was 10.0. running mean: 3.706066733269619\n",
      "resetting env. episode reward total was 10.0. running mean: 3.769006065936923\n",
      "resetting env. episode reward total was 2.0. running mean: 3.751316005277554\n",
      "resetting env. episode reward total was -1.0. running mean: 3.7038028452247787\n",
      "resetting env. episode reward total was 7.0. running mean: 3.7367648167725305\n",
      "resetting env. episode reward total was 4.0. running mean: 3.739397168604805\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7920031969187566\n",
      "resetting env. episode reward total was 9.0. running mean: 3.844083164949569\n",
      "resetting env. episode reward total was 7.0. running mean: 3.8756423333000733\n",
      "resetting env. episode reward total was 1.0. running mean: 3.8468859099670722\n",
      "resetting env. episode reward total was 2.0. running mean: 3.8284170508674014\n",
      "resetting env. episode reward total was 9.0. running mean: 3.8801328803587274\n",
      "resetting env. episode reward total was 3.0. running mean: 3.87133155155514\n",
      "resetting env. episode reward total was -3.0. running mean: 3.8026182360395886\n",
      "resetting env. episode reward total was 7.0. running mean: 3.8345920536791924\n",
      "resetting env. episode reward total was 9.0. running mean: 3.8862461331424005\n",
      "resetting env. episode reward total was 1.0. running mean: 3.857383671810976\n",
      "resetting env. episode reward total was 9.0. running mean: 3.908809835092866\n",
      "resetting env. episode reward total was 13.0. running mean: 3.9997217367419373\n",
      "resetting env. episode reward total was 1.0. running mean: 3.969724519374518\n",
      "resetting env. episode reward total was 9.0. running mean: 4.020027274180773\n",
      "resetting env. episode reward total was 7.0. running mean: 4.049827001438965\n",
      "resetting env. episode reward total was 12.0. running mean: 4.129328731424575\n",
      "resetting env. episode reward total was 2.0. running mean: 4.108035444110329\n",
      "resetting env. episode reward total was 4.0. running mean: 4.106955089669226\n",
      "resetting env. episode reward total was 6.0. running mean: 4.1258855387725335\n",
      "resetting env. episode reward total was -5.0. running mean: 4.034626683384809\n",
      "resetting env. episode reward total was 1.0. running mean: 4.0042804165509605\n",
      "resetting env. episode reward total was 13.0. running mean: 4.094237612385451\n",
      "resetting env. episode reward total was -8.0. running mean: 3.9732952362615963\n",
      "resetting env. episode reward total was 5.0. running mean: 3.98356228389898\n",
      "resetting env. episode reward total was 14.0. running mean: 4.08372666105999\n",
      "resetting env. episode reward total was -5.0. running mean: 3.9928893944493904\n",
      "resetting env. episode reward total was 8.0. running mean: 4.032960500504896\n",
      "resetting env. episode reward total was -9.0. running mean: 3.9026308954998474\n",
      "resetting env. episode reward total was 7.0. running mean: 3.9336045865448486\n",
      "resetting env. episode reward total was 11.0. running mean: 4.0042685406794005\n",
      "resetting env. episode reward total was 3.0. running mean: 3.994225855272606\n",
      "resetting env. episode reward total was 14.0. running mean: 4.09428359671988\n",
      "resetting env. episode reward total was -11.0. running mean: 3.943340760752681\n",
      "resetting env. episode reward total was 4.0. running mean: 3.9439073531451543\n",
      "resetting env. episode reward total was 2.0. running mean: 3.924468279613703\n",
      "resetting env. episode reward total was 4.0. running mean: 3.925223596817566\n",
      "resetting env. episode reward total was 1.0. running mean: 3.89597136084939\n",
      "resetting env. episode reward total was 16.0. running mean: 4.0170116472408965\n",
      "resetting env. episode reward total was -5.0. running mean: 3.926841530768488\n",
      "resetting env. episode reward total was 4.0. running mean: 3.927573115460803\n",
      "resetting env. episode reward total was 11.0. running mean: 3.998297384306195\n",
      "resetting env. episode reward total was 6.0. running mean: 4.018314410463133\n",
      "resetting env. episode reward total was 3.0. running mean: 4.008131266358502\n",
      "resetting env. episode reward total was -7.0. running mean: 3.898049953694917\n",
      "resetting env. episode reward total was -11.0. running mean: 3.749069454157968\n",
      "resetting env. episode reward total was -3.0. running mean: 3.6815787596163885\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7347629720202242\n",
      "resetting env. episode reward total was -8.0. running mean: 3.617415342300022\n",
      "resetting env. episode reward total was -1.0. running mean: 3.5712411888770217\n",
      "resetting env. episode reward total was 11.0. running mean: 3.645528776988251\n",
      "resetting env. episode reward total was 12.0. running mean: 3.7290734892183686\n",
      "resetting env. episode reward total was 11.0. running mean: 3.801782754326185\n",
      "resetting env. episode reward total was 12.0. running mean: 3.883764926782923\n",
      "resetting env. episode reward total was -5.0. running mean: 3.794927277515094\n",
      "resetting env. episode reward total was 8.0. running mean: 3.836978004739943\n",
      "resetting env. episode reward total was 16.0. running mean: 3.9586082246925436\n",
      "resetting env. episode reward total was 11.0. running mean: 4.029022142445618\n",
      "resetting env. episode reward total was 3.0. running mean: 4.018731921021162\n",
      "resetting env. episode reward total was 7.0. running mean: 4.048544601810951\n",
      "resetting env. episode reward total was -3.0. running mean: 3.9780591557928413\n",
      "resetting env. episode reward total was 8.0. running mean: 4.018278564234913\n",
      "resetting env. episode reward total was 3.0. running mean: 4.008095778592564\n",
      "resetting env. episode reward total was -3.0. running mean: 3.938014820806638\n",
      "resetting env. episode reward total was 7.0. running mean: 3.9686346725985717\n",
      "resetting env. episode reward total was 7.0. running mean: 3.9989483258725858\n",
      "resetting env. episode reward total was 5.0. running mean: 4.00895884261386\n",
      "resetting env. episode reward total was 7.0. running mean: 4.038869254187722\n",
      "resetting env. episode reward total was 4.0. running mean: 4.038480561645844\n",
      "resetting env. episode reward total was 10.0. running mean: 4.098095756029386\n",
      "resetting env. episode reward total was 4.0. running mean: 4.097114798469092\n",
      "resetting env. episode reward total was 8.0. running mean: 4.136143650484401\n",
      "resetting env. episode reward total was 14.0. running mean: 4.234782213979557\n",
      "resetting env. episode reward total was 10.0. running mean: 4.292434391839761\n",
      "resetting env. episode reward total was -6.0. running mean: 4.189510047921363\n",
      "resetting env. episode reward total was 7.0. running mean: 4.21761494744215\n",
      "resetting env. episode reward total was 14.0. running mean: 4.315438797967728\n",
      "resetting env. episode reward total was 5.0. running mean: 4.32228440998805\n",
      "resetting env. episode reward total was 5.0. running mean: 4.3290615658881695\n",
      "resetting env. episode reward total was 6.0. running mean: 4.345770950229287\n",
      "resetting env. episode reward total was -4.0. running mean: 4.262313240726995\n",
      "resetting env. episode reward total was 9.0. running mean: 4.3096901083197245\n",
      "resetting env. episode reward total was 6.0. running mean: 4.3265932072365265\n",
      "resetting env. episode reward total was -1.0. running mean: 4.273327275164162\n",
      "resetting env. episode reward total was 3.0. running mean: 4.26059400241252\n",
      "resetting env. episode reward total was -3.0. running mean: 4.187988062388395\n",
      "resetting env. episode reward total was 8.0. running mean: 4.226108181764511\n",
      "resetting env. episode reward total was -2.0. running mean: 4.163847099946866\n",
      "resetting env. episode reward total was 2.0. running mean: 4.142208628947397\n",
      "resetting env. episode reward total was -3.0. running mean: 4.070786542657923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 4.0700786772313435\n",
      "resetting env. episode reward total was 6.0. running mean: 4.08937789045903\n",
      "resetting env. episode reward total was 11.0. running mean: 4.15848411155444\n",
      "resetting env. episode reward total was 4.0. running mean: 4.156899270438895\n",
      "resetting env. episode reward total was 7.0. running mean: 4.185330277734507\n",
      "resetting env. episode reward total was 7.0. running mean: 4.213476974957162\n",
      "resetting env. episode reward total was 5.0. running mean: 4.22134220520759\n",
      "resetting env. episode reward total was 9.0. running mean: 4.269128783155514\n",
      "resetting env. episode reward total was 12.0. running mean: 4.346437495323959\n",
      "resetting env. episode reward total was -5.0. running mean: 4.2529731203707195\n",
      "resetting env. episode reward total was -4.0. running mean: 4.170443389167012\n",
      "resetting env. episode reward total was 7.0. running mean: 4.198738955275342\n",
      "resetting env. episode reward total was 10.0. running mean: 4.256751565722588\n",
      "resetting env. episode reward total was -15.0. running mean: 4.064184050065362\n",
      "resetting env. episode reward total was -3.0. running mean: 3.993542209564708\n",
      "resetting env. episode reward total was 4.0. running mean: 3.993606787469061\n",
      "resetting env. episode reward total was 13.0. running mean: 4.0836707195943704\n",
      "resetting env. episode reward total was 5.0. running mean: 4.092834012398426\n",
      "resetting env. episode reward total was -3.0. running mean: 4.021905672274442\n",
      "resetting env. episode reward total was 13.0. running mean: 4.111686615551697\n",
      "resetting env. episode reward total was 13.0. running mean: 4.20056974939618\n",
      "resetting env. episode reward total was -1.0. running mean: 4.148564051902219\n",
      "resetting env. episode reward total was 3.0. running mean: 4.137078411383197\n",
      "resetting env. episode reward total was -5.0. running mean: 4.045707627269365\n",
      "resetting env. episode reward total was 5.0. running mean: 4.0552505509966705\n",
      "resetting env. episode reward total was 11.0. running mean: 4.124698045486704\n",
      "resetting env. episode reward total was -5.0. running mean: 4.033451065031837\n",
      "resetting env. episode reward total was -6.0. running mean: 3.9331165543815185\n",
      "resetting env. episode reward total was 7.0. running mean: 3.963785388837703\n",
      "resetting env. episode reward total was -1.0. running mean: 3.914147534949326\n",
      "resetting env. episode reward total was 11.0. running mean: 3.9850060595998325\n",
      "resetting env. episode reward total was 3.0. running mean: 3.975155999003834\n",
      "resetting env. episode reward total was -5.0. running mean: 3.885404439013796\n",
      "resetting env. episode reward total was 8.0. running mean: 3.926550394623658\n",
      "resetting env. episode reward total was 2.0. running mean: 3.9072848906774214\n",
      "resetting env. episode reward total was 8.0. running mean: 3.948212041770647\n",
      "resetting env. episode reward total was 11.0. running mean: 4.018729921352941\n",
      "resetting env. episode reward total was -12.0. running mean: 3.8585426221394115\n",
      "resetting env. episode reward total was -5.0. running mean: 3.7699571959180176\n",
      "resetting env. episode reward total was 2.0. running mean: 3.752257623958837\n",
      "resetting env. episode reward total was -6.0. running mean: 3.6547350477192486\n",
      "resetting env. episode reward total was -6.0. running mean: 3.558187697242056\n",
      "resetting env. episode reward total was 15.0. running mean: 3.6726058202696352\n",
      "resetting env. episode reward total was 2.0. running mean: 3.655879762066939\n",
      "resetting env. episode reward total was 10.0. running mean: 3.7193209644462697\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6921277548018065\n",
      "resetting env. episode reward total was 7.0. running mean: 3.7252064772537885\n",
      "resetting env. episode reward total was 18.0. running mean: 3.8679544124812506\n",
      "resetting env. episode reward total was 3.0. running mean: 3.859274868356438\n",
      "resetting env. episode reward total was 1.0. running mean: 3.8306821196728733\n",
      "resetting env. episode reward total was 7.0. running mean: 3.8623752984761444\n",
      "resetting env. episode reward total was 14.0. running mean: 3.963751545491383\n",
      "resetting env. episode reward total was 7.0. running mean: 3.994114030036469\n",
      "resetting env. episode reward total was 3.0. running mean: 3.984172889736104\n",
      "resetting env. episode reward total was -4.0. running mean: 3.9043311608387428\n",
      "resetting env. episode reward total was 1.0. running mean: 3.875287849230355\n",
      "resetting env. episode reward total was 4.0. running mean: 3.8765349707380516\n",
      "resetting env. episode reward total was 2.0. running mean: 3.857769621030671\n",
      "resetting env. episode reward total was 1.0. running mean: 3.829191924820364\n",
      "resetting env. episode reward total was -11.0. running mean: 3.6809000055721603\n",
      "resetting env. episode reward total was -7.0. running mean: 3.574091005516439\n",
      "resetting env. episode reward total was 2.0. running mean: 3.558350095461275\n",
      "resetting env. episode reward total was 1.0. running mean: 3.5327665945066618\n",
      "resetting env. episode reward total was -1.0. running mean: 3.487438928561595\n",
      "resetting env. episode reward total was -6.0. running mean: 3.392564539275979\n",
      "resetting env. episode reward total was 7.0. running mean: 3.4286388938832193\n",
      "resetting env. episode reward total was -6.0. running mean: 3.334352504944387\n",
      "resetting env. episode reward total was 3.0. running mean: 3.331008979894943\n",
      "resetting env. episode reward total was -9.0. running mean: 3.207698890095994\n",
      "resetting env. episode reward total was 12.0. running mean: 3.2956219011950343\n",
      "resetting env. episode reward total was 8.0. running mean: 3.342665682183084\n",
      "resetting env. episode reward total was 1.0. running mean: 3.319239025361253\n",
      "resetting env. episode reward total was 14.0. running mean: 3.4260466351076406\n",
      "resetting env. episode reward total was -7.0. running mean: 3.321786168756564\n",
      "resetting env. episode reward total was -1.0. running mean: 3.2785683070689986\n",
      "resetting env. episode reward total was 1.0. running mean: 3.2557826239983085\n",
      "resetting env. episode reward total was -3.0. running mean: 3.1932247977583255\n",
      "resetting env. episode reward total was 5.0. running mean: 3.211292549780742\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2291796242829345\n",
      "resetting env. episode reward total was -9.0. running mean: 3.1068878280401053\n",
      "resetting env. episode reward total was 7.0. running mean: 3.145818949759704\n",
      "resetting env. episode reward total was 11.0. running mean: 3.224360760262107\n",
      "resetting env. episode reward total was 11.0. running mean: 3.302117152659486\n",
      "resetting env. episode reward total was 15.0. running mean: 3.419095981132891\n",
      "resetting env. episode reward total was 4.0. running mean: 3.424905021321562\n",
      "resetting env. episode reward total was 10.0. running mean: 3.4906559711083465\n",
      "resetting env. episode reward total was 14.0. running mean: 3.595749411397263\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5997919172832904\n",
      "resetting env. episode reward total was 13.0. running mean: 3.6937939981104573\n",
      "resetting env. episode reward total was 12.0. running mean: 3.776856058129353\n",
      "resetting env. episode reward total was -7.0. running mean: 3.6690874975480594\n",
      "resetting env. episode reward total was 3.0. running mean: 3.6623966225725786\n",
      "resetting env. episode reward total was -9.0. running mean: 3.535772656346853\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6004149297833847\n",
      "resetting env. episode reward total was -5.0. running mean: 3.514410780485551\n",
      "resetting env. episode reward total was -9.0. running mean: 3.3892666726806957\n",
      "resetting env. episode reward total was 13.0. running mean: 3.4853740059538887\n",
      "resetting env. episode reward total was 9.0. running mean: 3.5405202658943495\n",
      "resetting env. episode reward total was 3.0. running mean: 3.535115063235406\n",
      "resetting env. episode reward total was 12.0. running mean: 3.619763912603052\n",
      "resetting env. episode reward total was 3.0. running mean: 3.6135662734770215\n",
      "resetting env. episode reward total was 6.0. running mean: 3.637430610742251\n",
      "resetting env. episode reward total was 4.0. running mean: 3.6410563046348288\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6646457415884806\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6879992841725957\n",
      "resetting env. episode reward total was 16.0. running mean: 3.81111929133087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 3.863008098417561\n",
      "resetting env. episode reward total was 15.0. running mean: 3.974378017433385\n",
      "resetting env. episode reward total was 4.0. running mean: 3.9746342372590515\n",
      "resetting env. episode reward total was 7.0. running mean: 4.004887894886461\n",
      "resetting env. episode reward total was 4.0. running mean: 4.004839015937597\n",
      "resetting env. episode reward total was -2.0. running mean: 3.9447906257782206\n",
      "resetting env. episode reward total was 8.0. running mean: 3.9853427195204385\n",
      "resetting env. episode reward total was -3.0. running mean: 3.9154892923252342\n",
      "resetting env. episode reward total was 10.0. running mean: 3.9763343994019817\n",
      "resetting env. episode reward total was 3.0. running mean: 3.966571055407962\n",
      "resetting env. episode reward total was 10.0. running mean: 4.026905344853882\n",
      "resetting env. episode reward total was 7.0. running mean: 4.056636291405343\n",
      "resetting env. episode reward total was -2.0. running mean: 3.996069928491289\n",
      "resetting env. episode reward total was -3.0. running mean: 3.9261092292063764\n",
      "resetting env. episode reward total was 4.0. running mean: 3.9268481369143124\n",
      "resetting env. episode reward total was 5.0. running mean: 3.937579655545169\n",
      "resetting env. episode reward total was -12.0. running mean: 3.7782038589897176\n",
      "resetting env. episode reward total was 8.0. running mean: 3.8204218203998206\n",
      "resetting env. episode reward total was 6.0. running mean: 3.8422176021958223\n",
      "resetting env. episode reward total was 1.0. running mean: 3.813795426173864\n",
      "resetting env. episode reward total was -1.0. running mean: 3.7656574719121254\n",
      "resetting env. episode reward total was 4.0. running mean: 3.768000897193004\n",
      "resetting env. episode reward total was -1.0. running mean: 3.720320888221074\n",
      "resetting env. episode reward total was 7.0. running mean: 3.753117679338863\n",
      "resetting env. episode reward total was 9.0. running mean: 3.805586502545474\n",
      "resetting env. episode reward total was 6.0. running mean: 3.8275306375200193\n",
      "resetting env. episode reward total was 11.0. running mean: 3.899255331144819\n",
      "resetting env. episode reward total was -8.0. running mean: 3.7802627778333706\n",
      "resetting env. episode reward total was 3.0. running mean: 3.7724601500550365\n",
      "resetting env. episode reward total was -6.0. running mean: 3.674735548554486\n",
      "resetting env. episode reward total was 12.0. running mean: 3.757988193068941\n",
      "resetting env. episode reward total was -2.0. running mean: 3.7004083111382515\n",
      "resetting env. episode reward total was 11.0. running mean: 3.7734042280268687\n",
      "resetting env. episode reward total was 7.0. running mean: 3.8056701857466\n",
      "resetting env. episode reward total was 6.0. running mean: 3.827613483889134\n",
      "resetting env. episode reward total was -6.0. running mean: 3.7293373490502426\n",
      "resetting env. episode reward total was 11.0. running mean: 3.80204397555974\n",
      "resetting env. episode reward total was 11.0. running mean: 3.8740235358041426\n",
      "resetting env. episode reward total was -5.0. running mean: 3.7852833004461015\n",
      "resetting env. episode reward total was 1.0. running mean: 3.7574304674416403\n",
      "resetting env. episode reward total was 10.0. running mean: 3.819856162767224\n",
      "resetting env. episode reward total was 17.0. running mean: 3.9516576011395514\n",
      "resetting env. episode reward total was 6.0. running mean: 3.972141025128156\n",
      "resetting env. episode reward total was 7.0. running mean: 4.0024196148768745\n",
      "resetting env. episode reward total was 9.0. running mean: 4.052395418728106\n",
      "resetting env. episode reward total was 3.0. running mean: 4.041871464540825\n",
      "resetting env. episode reward total was -2.0. running mean: 3.9814527498954164\n",
      "resetting env. episode reward total was 8.0. running mean: 4.021638222396462\n",
      "resetting env. episode reward total was 1.0. running mean: 3.9914218401724977\n",
      "resetting env. episode reward total was 12.0. running mean: 4.071507621770772\n",
      "resetting env. episode reward total was 10.0. running mean: 4.130792545553064\n",
      "resetting env. episode reward total was -3.0. running mean: 4.059484620097533\n",
      "resetting env. episode reward total was 7.0. running mean: 4.0888897738965575\n",
      "resetting env. episode reward total was 1.0. running mean: 4.058000876157592\n",
      "resetting env. episode reward total was -5.0. running mean: 3.967420867396016\n",
      "resetting env. episode reward total was 7.0. running mean: 3.997746658722056\n",
      "resetting env. episode reward total was 6.0. running mean: 4.017769192134835\n",
      "resetting env. episode reward total was 14.0. running mean: 4.117591500213486\n",
      "resetting env. episode reward total was 3.0. running mean: 4.1064155852113515\n",
      "resetting env. episode reward total was 9.0. running mean: 4.1553514293592375\n",
      "resetting env. episode reward total was 4.0. running mean: 4.153797915065645\n",
      "resetting env. episode reward total was 14.0. running mean: 4.252259935914989\n",
      "resetting env. episode reward total was 12.0. running mean: 4.329737336555839\n",
      "resetting env. episode reward total was 12.0. running mean: 4.40643996319028\n",
      "resetting env. episode reward total was 5.0. running mean: 4.412375563558377\n",
      "resetting env. episode reward total was 14.0. running mean: 4.508251807922792\n",
      "resetting env. episode reward total was 7.0. running mean: 4.533169289843564\n",
      "resetting env. episode reward total was 4.0. running mean: 4.527837596945129\n",
      "resetting env. episode reward total was 15.0. running mean: 4.632559220975677\n",
      "resetting env. episode reward total was 3.0. running mean: 4.6162336287659205\n",
      "resetting env. episode reward total was 6.0. running mean: 4.630071292478261\n",
      "resetting env. episode reward total was 8.0. running mean: 4.6637705795534785\n",
      "resetting env. episode reward total was 6.0. running mean: 4.677132873757944\n",
      "resetting env. episode reward total was 9.0. running mean: 4.720361545020364\n",
      "resetting env. episode reward total was 10.0. running mean: 4.773157929570161\n",
      "resetting env. episode reward total was 6.0. running mean: 4.7854263502744585\n",
      "resetting env. episode reward total was 7.0. running mean: 4.807572086771714\n",
      "resetting env. episode reward total was -2.0. running mean: 4.739496365903997\n",
      "resetting env. episode reward total was 6.0. running mean: 4.752101402244956\n",
      "resetting env. episode reward total was 7.0. running mean: 4.774580388222507\n",
      "resetting env. episode reward total was 11.0. running mean: 4.8368345843402825\n",
      "resetting env. episode reward total was -6.0. running mean: 4.72846623849688\n",
      "resetting env. episode reward total was -9.0. running mean: 4.591181576111912\n",
      "resetting env. episode reward total was 8.0. running mean: 4.625269760350792\n",
      "resetting env. episode reward total was -1.0. running mean: 4.569017062747284\n",
      "resetting env. episode reward total was 3.0. running mean: 4.553326892119812\n",
      "resetting env. episode reward total was 6.0. running mean: 4.567793623198614\n",
      "resetting env. episode reward total was 7.0. running mean: 4.592115686966627\n",
      "resetting env. episode reward total was -9.0. running mean: 4.456194530096961\n",
      "resetting env. episode reward total was 5.0. running mean: 4.461632584795991\n",
      "resetting env. episode reward total was 12.0. running mean: 4.537016258948031\n",
      "resetting env. episode reward total was 4.0. running mean: 4.531646096358551\n",
      "resetting env. episode reward total was -1.0. running mean: 4.476329635394966\n",
      "resetting env. episode reward total was 7.0. running mean: 4.501566339041016\n",
      "resetting env. episode reward total was -4.0. running mean: 4.416550675650606\n",
      "resetting env. episode reward total was 8.0. running mean: 4.4523851688941\n",
      "resetting env. episode reward total was 12.0. running mean: 4.527861317205159\n",
      "resetting env. episode reward total was 4.0. running mean: 4.522582704033107\n",
      "resetting env. episode reward total was 15.0. running mean: 4.627356876992777\n",
      "resetting env. episode reward total was 7.0. running mean: 4.65108330822285\n",
      "resetting env. episode reward total was 4.0. running mean: 4.644572475140621\n",
      "resetting env. episode reward total was 2.0. running mean: 4.618126750389215\n",
      "resetting env. episode reward total was -1.0. running mean: 4.5619454828853225\n",
      "resetting env. episode reward total was 4.0. running mean: 4.5563260280564695\n",
      "resetting env. episode reward total was 8.0. running mean: 4.590762767775905\n",
      "resetting env. episode reward total was 11.0. running mean: 4.654855140098146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: 4.578306588697164\n",
      "resetting env. episode reward total was 12.0. running mean: 4.652523522810193\n",
      "resetting env. episode reward total was 4.0. running mean: 4.645998287582091\n",
      "resetting env. episode reward total was 6.0. running mean: 4.6595383047062695\n",
      "resetting env. episode reward total was 9.0. running mean: 4.702942921659207\n",
      "resetting env. episode reward total was 6.0. running mean: 4.715913492442614\n",
      "resetting env. episode reward total was 12.0. running mean: 4.788754357518188\n",
      "resetting env. episode reward total was 1.0. running mean: 4.750866813943007\n",
      "resetting env. episode reward total was 13.0. running mean: 4.833358145803577\n",
      "resetting env. episode reward total was -4.0. running mean: 4.745024564345541\n",
      "resetting env. episode reward total was 5.0. running mean: 4.747574318702085\n",
      "resetting env. episode reward total was -11.0. running mean: 4.590098575515064\n",
      "resetting env. episode reward total was 5.0. running mean: 4.594197589759913\n",
      "resetting env. episode reward total was 2.0. running mean: 4.568255613862314\n",
      "resetting env. episode reward total was 6.0. running mean: 4.58257305772369\n",
      "resetting env. episode reward total was 5.0. running mean: 4.586747327146453\n",
      "resetting env. episode reward total was 7.0. running mean: 4.610879853874988\n",
      "resetting env. episode reward total was -2.0. running mean: 4.544771055336239\n",
      "resetting env. episode reward total was 10.0. running mean: 4.599323344782876\n",
      "resetting env. episode reward total was -5.0. running mean: 4.503330111335047\n",
      "resetting env. episode reward total was -2.0. running mean: 4.438296810221697\n",
      "resetting env. episode reward total was 1.0. running mean: 4.40391384211948\n",
      "resetting env. episode reward total was 14.0. running mean: 4.499874703698285\n",
      "resetting env. episode reward total was 13.0. running mean: 4.5848759566613015\n",
      "resetting env. episode reward total was 11.0. running mean: 4.649027197094688\n",
      "resetting env. episode reward total was 16.0. running mean: 4.762536925123742\n",
      "resetting env. episode reward total was 9.0. running mean: 4.804911555872504\n",
      "resetting env. episode reward total was 3.0. running mean: 4.786862440313779\n",
      "resetting env. episode reward total was 1.0. running mean: 4.748993815910642\n",
      "resetting env. episode reward total was 4.0. running mean: 4.741503877751535\n",
      "resetting env. episode reward total was 7.0. running mean: 4.76408883897402\n",
      "resetting env. episode reward total was 1.0. running mean: 4.72644795058428\n",
      "resetting env. episode reward total was -2.0. running mean: 4.659183471078437\n",
      "resetting env. episode reward total was 12.0. running mean: 4.732591636367653\n",
      "resetting env. episode reward total was 9.0. running mean: 4.7752657200039765\n",
      "resetting env. episode reward total was 6.0. running mean: 4.787513062803936\n",
      "resetting env. episode reward total was -5.0. running mean: 4.689637932175897\n",
      "resetting env. episode reward total was 7.0. running mean: 4.712741552854138\n",
      "resetting env. episode reward total was 2.0. running mean: 4.685614137325596\n",
      "resetting env. episode reward total was 4.0. running mean: 4.67875799595234\n",
      "resetting env. episode reward total was 7.0. running mean: 4.701970415992817\n",
      "resetting env. episode reward total was 1.0. running mean: 4.664950711832889\n",
      "resetting env. episode reward total was 11.0. running mean: 4.72830120471456\n",
      "resetting env. episode reward total was 3.0. running mean: 4.711018192667415\n",
      "resetting env. episode reward total was -1.0. running mean: 4.65390801074074\n",
      "resetting env. episode reward total was 5.0. running mean: 4.657368930633333\n",
      "resetting env. episode reward total was 3.0. running mean: 4.640795241327\n",
      "resetting env. episode reward total was -4.0. running mean: 4.55438728891373\n",
      "resetting env. episode reward total was 15.0. running mean: 4.658843416024593\n",
      "resetting env. episode reward total was 11.0. running mean: 4.722254981864347\n",
      "resetting env. episode reward total was -5.0. running mean: 4.625032432045703\n",
      "resetting env. episode reward total was 3.0. running mean: 4.608782107725246\n",
      "resetting env. episode reward total was 14.0. running mean: 4.7026942866479935\n",
      "resetting env. episode reward total was 11.0. running mean: 4.765667343781514\n",
      "resetting env. episode reward total was 3.0. running mean: 4.7480106703436995\n",
      "resetting env. episode reward total was -1.0. running mean: 4.690530563640262\n",
      "resetting env. episode reward total was 12.0. running mean: 4.763625258003859\n",
      "resetting env. episode reward total was 11.0. running mean: 4.825989005423821\n",
      "resetting env. episode reward total was 1.0. running mean: 4.787729115369583\n",
      "resetting env. episode reward total was 4.0. running mean: 4.779851824215887\n",
      "resetting env. episode reward total was -5.0. running mean: 4.682053305973729\n",
      "resetting env. episode reward total was 7.0. running mean: 4.705232772913992\n",
      "resetting env. episode reward total was -4.0. running mean: 4.618180445184852\n",
      "resetting env. episode reward total was 12.0. running mean: 4.691998640733003\n",
      "resetting env. episode reward total was 13.0. running mean: 4.775078654325673\n",
      "resetting env. episode reward total was -3.0. running mean: 4.697327867782416\n",
      "resetting env. episode reward total was -3.0. running mean: 4.620354589104592\n",
      "resetting env. episode reward total was 10.0. running mean: 4.674151043213545\n",
      "resetting env. episode reward total was 3.0. running mean: 4.65740953278141\n",
      "resetting env. episode reward total was 6.0. running mean: 4.670835437453595\n",
      "resetting env. episode reward total was -5.0. running mean: 4.57412708307906\n",
      "resetting env. episode reward total was 5.0. running mean: 4.5783858122482695\n",
      "resetting env. episode reward total was 2.0. running mean: 4.5526019541257865\n",
      "resetting env. episode reward total was 10.0. running mean: 4.607075934584528\n",
      "resetting env. episode reward total was -3.0. running mean: 4.531005175238683\n",
      "resetting env. episode reward total was 11.0. running mean: 4.595695123486296\n",
      "resetting env. episode reward total was 1.0. running mean: 4.559738172251433\n",
      "resetting env. episode reward total was 3.0. running mean: 4.544140790528919\n",
      "resetting env. episode reward total was 11.0. running mean: 4.60869938262363\n",
      "resetting env. episode reward total was 15.0. running mean: 4.712612388797394\n",
      "resetting env. episode reward total was 8.0. running mean: 4.74548626490942\n",
      "resetting env. episode reward total was 4.0. running mean: 4.738031402260326\n",
      "resetting env. episode reward total was 5.0. running mean: 4.740651088237723\n",
      "resetting env. episode reward total was -5.0. running mean: 4.643244577355346\n",
      "resetting env. episode reward total was 6.0. running mean: 4.656812131581792\n",
      "resetting env. episode reward total was 2.0. running mean: 4.630244010265974\n",
      "resetting env. episode reward total was 8.0. running mean: 4.663941570163314\n",
      "resetting env. episode reward total was 3.0. running mean: 4.6473021544616815\n",
      "resetting env. episode reward total was -1.0. running mean: 4.590829132917065\n",
      "resetting env. episode reward total was 15.0. running mean: 4.694920841587895\n",
      "resetting env. episode reward total was 5.0. running mean: 4.697971633172016\n",
      "resetting env. episode reward total was 4.0. running mean: 4.690991916840296\n",
      "resetting env. episode reward total was 13.0. running mean: 4.7740819976718925\n",
      "resetting env. episode reward total was 8.0. running mean: 4.806341177695174\n",
      "resetting env. episode reward total was 1.0. running mean: 4.768277765918222\n",
      "resetting env. episode reward total was 5.0. running mean: 4.770594988259039\n",
      "resetting env. episode reward total was -1.0. running mean: 4.712889038376449\n",
      "resetting env. episode reward total was 4.0. running mean: 4.7057601479926845\n",
      "resetting env. episode reward total was 6.0. running mean: 4.718702546512757\n",
      "resetting env. episode reward total was -8.0. running mean: 4.591515521047629\n",
      "resetting env. episode reward total was -3.0. running mean: 4.515600365837153\n",
      "resetting env. episode reward total was 5.0. running mean: 4.520444362178781\n",
      "resetting env. episode reward total was 8.0. running mean: 4.5552399185569925\n",
      "resetting env. episode reward total was 10.0. running mean: 4.609687519371422\n",
      "resetting env. episode reward total was 4.0. running mean: 4.603590644177708\n",
      "resetting env. episode reward total was -3.0. running mean: 4.52755473773593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 4.5822791903585705\n",
      "resetting env. episode reward total was 2.0. running mean: 4.556456398454984\n",
      "resetting env. episode reward total was 6.0. running mean: 4.570891834470435\n",
      "resetting env. episode reward total was 5.0. running mean: 4.57518291612573\n",
      "resetting env. episode reward total was 9.0. running mean: 4.619431086964473\n",
      "resetting env. episode reward total was 5.0. running mean: 4.623236776094828\n",
      "resetting env. episode reward total was 5.0. running mean: 4.627004408333879\n",
      "resetting env. episode reward total was 1.0. running mean: 4.59073436425054\n",
      "resetting env. episode reward total was 8.0. running mean: 4.624827020608035\n",
      "resetting env. episode reward total was 11.0. running mean: 4.688578750401955\n",
      "resetting env. episode reward total was 3.0. running mean: 4.671692962897936\n",
      "resetting env. episode reward total was -5.0. running mean: 4.574976033268957\n",
      "resetting env. episode reward total was 8.0. running mean: 4.609226272936267\n",
      "resetting env. episode reward total was 8.0. running mean: 4.6431340102069045\n",
      "resetting env. episode reward total was 5.0. running mean: 4.646702670104835\n",
      "resetting env. episode reward total was -3.0. running mean: 4.5702356434037865\n",
      "resetting env. episode reward total was 8.0. running mean: 4.604533286969748\n",
      "resetting env. episode reward total was 8.0. running mean: 4.638487954100051\n",
      "resetting env. episode reward total was -7.0. running mean: 4.52210307455905\n",
      "resetting env. episode reward total was -5.0. running mean: 4.4268820438134595\n",
      "resetting env. episode reward total was -4.0. running mean: 4.3426132233753245\n",
      "resetting env. episode reward total was 3.0. running mean: 4.329187091141572\n",
      "resetting env. episode reward total was 7.0. running mean: 4.355895220230156\n",
      "resetting env. episode reward total was 14.0. running mean: 4.452336268027854\n",
      "resetting env. episode reward total was -4.0. running mean: 4.367812905347575\n",
      "resetting env. episode reward total was 2.0. running mean: 4.344134776294099\n",
      "resetting env. episode reward total was 3.0. running mean: 4.330693428531158\n",
      "resetting env. episode reward total was 3.0. running mean: 4.317386494245847\n",
      "resetting env. episode reward total was -3.0. running mean: 4.244212629303388\n",
      "resetting env. episode reward total was -1.0. running mean: 4.191770503010354\n",
      "resetting env. episode reward total was -2.0. running mean: 4.129852797980251\n",
      "resetting env. episode reward total was 1.0. running mean: 4.098554270000449\n",
      "resetting env. episode reward total was -14.0. running mean: 3.9175687273004445\n",
      "resetting env. episode reward total was 3.0. running mean: 3.90839304002744\n",
      "resetting env. episode reward total was 5.0. running mean: 3.9193091096271653\n",
      "resetting env. episode reward total was -3.0. running mean: 3.8501160185308936\n",
      "resetting env. episode reward total was -9.0. running mean: 3.7216148583455846\n",
      "resetting env. episode reward total was -6.0. running mean: 3.624398709762129\n",
      "resetting env. episode reward total was -2.0. running mean: 3.5681547226645076\n",
      "resetting env. episode reward total was -1.0. running mean: 3.5224731754378626\n",
      "resetting env. episode reward total was 14.0. running mean: 3.627248443683484\n",
      "resetting env. episode reward total was -1.0. running mean: 3.5809759592466492\n",
      "resetting env. episode reward total was 11.0. running mean: 3.6551661996541824\n",
      "resetting env. episode reward total was 14.0. running mean: 3.7586145376576408\n",
      "resetting env. episode reward total was 9.0. running mean: 3.8110283922810644\n",
      "resetting env. episode reward total was 11.0. running mean: 3.8829181083582536\n",
      "resetting env. episode reward total was 7.0. running mean: 3.914088927274671\n",
      "resetting env. episode reward total was -8.0. running mean: 3.794948038001924\n",
      "resetting env. episode reward total was 7.0. running mean: 3.8269985576219048\n",
      "resetting env. episode reward total was 13.0. running mean: 3.9187285720456857\n",
      "resetting env. episode reward total was -3.0. running mean: 3.849541286325229\n",
      "resetting env. episode reward total was 8.0. running mean: 3.891045873461977\n",
      "resetting env. episode reward total was 2.0. running mean: 3.8721354147273574\n",
      "resetting env. episode reward total was 8.0. running mean: 3.913414060580084\n",
      "resetting env. episode reward total was 2.0. running mean: 3.894279919974283\n",
      "resetting env. episode reward total was -9.0. running mean: 3.7653371207745403\n",
      "resetting env. episode reward total was -1.0. running mean: 3.717683749566795\n",
      "resetting env. episode reward total was 4.0. running mean: 3.720506912071127\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7733018429504157\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7755688245209114\n",
      "resetting env. episode reward total was 5.0. running mean: 3.787813136275702\n",
      "resetting env. episode reward total was 10.0. running mean: 3.849935004912945\n",
      "resetting env. episode reward total was 2.0. running mean: 3.8314356548638155\n",
      "resetting env. episode reward total was 7.0. running mean: 3.863121298315177\n",
      "resetting env. episode reward total was 2.0. running mean: 3.8444900853320254\n",
      "resetting env. episode reward total was 14.0. running mean: 3.9460451844787054\n",
      "resetting env. episode reward total was 2.0. running mean: 3.9265847326339185\n",
      "resetting env. episode reward total was -4.0. running mean: 3.8473188853075793\n",
      "resetting env. episode reward total was 4.0. running mean: 3.8488456964545033\n",
      "resetting env. episode reward total was -1.0. running mean: 3.8003572394899585\n",
      "resetting env. episode reward total was 2.0. running mean: 3.782353667095059\n",
      "resetting env. episode reward total was 1.0. running mean: 3.754530130424108\n",
      "resetting env. episode reward total was -4.0. running mean: 3.6769848291198666\n",
      "resetting env. episode reward total was 8.0. running mean: 3.720214980828668\n",
      "resetting env. episode reward total was -14.0. running mean: 3.543012831020381\n",
      "resetting env. episode reward total was -7.0. running mean: 3.4375827027101775\n",
      "resetting env. episode reward total was 4.0. running mean: 3.443206875683076\n",
      "resetting env. episode reward total was 3.0. running mean: 3.438774806926245\n",
      "resetting env. episode reward total was -13.0. running mean: 3.274387058856983\n",
      "resetting env. episode reward total was -5.0. running mean: 3.1916431882684133\n",
      "resetting env. episode reward total was 2.0. running mean: 3.179726756385729\n",
      "resetting env. episode reward total was 8.0. running mean: 3.227929488821872\n",
      "resetting env. episode reward total was -3.0. running mean: 3.1656501939336534\n",
      "resetting env. episode reward total was 6.0. running mean: 3.193993691994317\n",
      "resetting env. episode reward total was -3.0. running mean: 3.1320537550743737\n",
      "resetting env. episode reward total was 2.0. running mean: 3.1207332175236298\n",
      "resetting env. episode reward total was -7.0. running mean: 3.0195258853483935\n",
      "resetting env. episode reward total was 2.0. running mean: 3.0093306264949096\n",
      "resetting env. episode reward total was 1.0. running mean: 2.98923732022996\n",
      "resetting env. episode reward total was 8.0. running mean: 3.0393449470276606\n",
      "resetting env. episode reward total was -3.0. running mean: 2.978951497557384\n",
      "resetting env. episode reward total was 6.0. running mean: 3.0091619825818103\n",
      "resetting env. episode reward total was -8.0. running mean: 2.899070362755992\n",
      "resetting env. episode reward total was 6.0. running mean: 2.930079659128432\n",
      "resetting env. episode reward total was 2.0. running mean: 2.920778862537148\n",
      "resetting env. episode reward total was 8.0. running mean: 2.971571073911776\n",
      "resetting env. episode reward total was 4.0. running mean: 2.9818553631726585\n",
      "resetting env. episode reward total was 7.0. running mean: 3.0220368095409316\n",
      "resetting env. episode reward total was -6.0. running mean: 2.9318164414455223\n",
      "resetting env. episode reward total was -3.0. running mean: 2.872498277031067\n",
      "resetting env. episode reward total was 3.0. running mean: 2.873773294260756\n",
      "resetting env. episode reward total was 2.0. running mean: 2.8650355613181486\n",
      "resetting env. episode reward total was 14.0. running mean: 2.9763852057049673\n",
      "resetting env. episode reward total was -2.0. running mean: 2.9266213536479175\n",
      "resetting env. episode reward total was 10.0. running mean: 2.997355140111438\n",
      "resetting env. episode reward total was 1.0. running mean: 2.9773815887103234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 3.0476077728232203\n",
      "resetting env. episode reward total was 2.0. running mean: 3.0371316950949883\n",
      "resetting env. episode reward total was 12.0. running mean: 3.1267603781440383\n",
      "resetting env. episode reward total was 10.0. running mean: 3.195492774362598\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2135378466189715\n",
      "resetting env. episode reward total was 2.0. running mean: 3.2014024681527817\n",
      "resetting env. episode reward total was 6.0. running mean: 3.229388443471254\n",
      "resetting env. episode reward total was -6.0. running mean: 3.1370945590365413\n",
      "resetting env. episode reward total was 10.0. running mean: 3.205723613446176\n",
      "resetting env. episode reward total was -7.0. running mean: 3.1036663773117144\n",
      "resetting env. episode reward total was 1.0. running mean: 3.082629713538597\n",
      "resetting env. episode reward total was 13.0. running mean: 3.181803416403211\n",
      "resetting env. episode reward total was 12.0. running mean: 3.269985382239179\n",
      "resetting env. episode reward total was 1.0. running mean: 3.247285528416787\n",
      "resetting env. episode reward total was 3.0. running mean: 3.244812673132619\n",
      "resetting env. episode reward total was 6.0. running mean: 3.2723645464012927\n",
      "resetting env. episode reward total was 10.0. running mean: 3.33964090093728\n",
      "resetting env. episode reward total was 2.0. running mean: 3.3262444919279073\n",
      "resetting env. episode reward total was -4.0. running mean: 3.252982047008628\n",
      "resetting env. episode reward total was -7.0. running mean: 3.1504522265385417\n",
      "resetting env. episode reward total was 12.0. running mean: 3.2389477042731563\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2765582272304243\n",
      "resetting env. episode reward total was 6.0. running mean: 3.3037926449581203\n",
      "resetting env. episode reward total was -1.0. running mean: 3.2607547185085393\n",
      "resetting env. episode reward total was 11.0. running mean: 3.338147171323454\n",
      "resetting env. episode reward total was 3.0. running mean: 3.334765699610219\n",
      "resetting env. episode reward total was 4.0. running mean: 3.3414180426141167\n",
      "resetting env. episode reward total was 7.0. running mean: 3.3780038621879753\n",
      "resetting env. episode reward total was 6.0. running mean: 3.4042238235660958\n",
      "resetting env. episode reward total was 12.0. running mean: 3.490181585330435\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5352797694771305\n",
      "resetting env. episode reward total was 13.0. running mean: 3.6299269717823592\n",
      "resetting env. episode reward total was 3.0. running mean: 3.6236277020645353\n",
      "resetting env. episode reward total was 2.0. running mean: 3.60739142504389\n",
      "resetting env. episode reward total was 12.0. running mean: 3.6913175107934513\n",
      "resetting env. episode reward total was -7.0. running mean: 3.584404335685517\n",
      "resetting env. episode reward total was 9.0. running mean: 3.6385602923286617\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6621746894053753\n",
      "resetting env. episode reward total was 7.0. running mean: 3.695552942511321\n",
      "resetting env. episode reward total was 13.0. running mean: 3.7885974130862077\n",
      "resetting env. episode reward total was -2.0. running mean: 3.7307114389553457\n",
      "resetting env. episode reward total was 8.0. running mean: 3.7734043245657922\n",
      "resetting env. episode reward total was 8.0. running mean: 3.815670281320134\n",
      "resetting env. episode reward total was -1.0. running mean: 3.767513578506933\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7698384427218636\n",
      "resetting env. episode reward total was 8.0. running mean: 3.812140058294645\n",
      "resetting env. episode reward total was -1.0. running mean: 3.7640186577116985\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7663784711345816\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7787146864232355\n",
      "resetting env. episode reward total was 14.0. running mean: 3.880927539559003\n",
      "resetting env. episode reward total was 11.0. running mean: 3.952118264163413\n",
      "resetting env. episode reward total was 14.0. running mean: 4.052597081521779\n",
      "resetting env. episode reward total was 2.0. running mean: 4.0320711107065605\n",
      "resetting env. episode reward total was 6.0. running mean: 4.051750399599495\n",
      "resetting env. episode reward total was 10.0. running mean: 4.1112328956035\n",
      "resetting env. episode reward total was 4.0. running mean: 4.110120566647465\n",
      "resetting env. episode reward total was 12.0. running mean: 4.189019360980991\n",
      "resetting env. episode reward total was 1.0. running mean: 4.15712916737118\n",
      "resetting env. episode reward total was 6.0. running mean: 4.175557875697468\n",
      "resetting env. episode reward total was 4.0. running mean: 4.173802296940493\n",
      "resetting env. episode reward total was -3.0. running mean: 4.102064273971088\n",
      "resetting env. episode reward total was 6.0. running mean: 4.121043631231377\n",
      "resetting env. episode reward total was 12.0. running mean: 4.199833194919063\n",
      "resetting env. episode reward total was -3.0. running mean: 4.1278348629698725\n",
      "resetting env. episode reward total was 11.0. running mean: 4.196556514340174\n",
      "resetting env. episode reward total was -1.0. running mean: 4.144590949196773\n",
      "resetting env. episode reward total was 8.0. running mean: 4.183145039704805\n",
      "resetting env. episode reward total was 9.0. running mean: 4.231313589307757\n",
      "resetting env. episode reward total was 13.0. running mean: 4.31900045341468\n",
      "resetting env. episode reward total was 13.0. running mean: 4.405810448880533\n",
      "resetting env. episode reward total was 10.0. running mean: 4.461752344391727\n",
      "resetting env. episode reward total was 5.0. running mean: 4.46713482094781\n",
      "resetting env. episode reward total was -4.0. running mean: 4.382463472738332\n",
      "resetting env. episode reward total was -6.0. running mean: 4.278638838010949\n",
      "resetting env. episode reward total was 10.0. running mean: 4.335852449630838\n",
      "resetting env. episode reward total was 9.0. running mean: 4.38249392513453\n",
      "resetting env. episode reward total was 12.0. running mean: 4.458668985883185\n",
      "resetting env. episode reward total was -3.0. running mean: 4.384082296024353\n",
      "resetting env. episode reward total was 5.0. running mean: 4.390241473064109\n",
      "resetting env. episode reward total was 15.0. running mean: 4.496339058333469\n",
      "resetting env. episode reward total was 11.0. running mean: 4.561375667750134\n",
      "resetting env. episode reward total was 3.0. running mean: 4.545761911072633\n",
      "resetting env. episode reward total was -2.0. running mean: 4.480304291961907\n",
      "resetting env. episode reward total was 8.0. running mean: 4.515501249042289\n",
      "resetting env. episode reward total was 3.0. running mean: 4.500346236551866\n",
      "resetting env. episode reward total was -1.0. running mean: 4.445342774186347\n",
      "resetting env. episode reward total was 9.0. running mean: 4.490889346444484\n",
      "resetting env. episode reward total was 4.0. running mean: 4.485980452980039\n",
      "resetting env. episode reward total was 10.0. running mean: 4.541120648450238\n",
      "resetting env. episode reward total was 10.0. running mean: 4.595709441965735\n",
      "resetting env. episode reward total was 16.0. running mean: 4.709752347546078\n",
      "resetting env. episode reward total was 1.0. running mean: 4.672654824070617\n",
      "resetting env. episode reward total was 10.0. running mean: 4.725928275829911\n",
      "resetting env. episode reward total was 11.0. running mean: 4.788668993071612\n",
      "resetting env. episode reward total was -5.0. running mean: 4.690782303140896\n",
      "resetting env. episode reward total was 6.0. running mean: 4.703874480109486\n",
      "resetting env. episode reward total was 14.0. running mean: 4.796835735308391\n",
      "resetting env. episode reward total was 1.0. running mean: 4.758867377955307\n",
      "resetting env. episode reward total was -3.0. running mean: 4.681278704175753\n",
      "resetting env. episode reward total was 1.0. running mean: 4.644465917133996\n",
      "resetting env. episode reward total was -3.0. running mean: 4.568021257962656\n",
      "resetting env. episode reward total was 9.0. running mean: 4.612341045383029\n",
      "resetting env. episode reward total was -7.0. running mean: 4.496217634929198\n",
      "resetting env. episode reward total was 14.0. running mean: 4.591255458579905\n",
      "resetting env. episode reward total was 13.0. running mean: 4.675342903994106\n",
      "resetting env. episode reward total was 10.0. running mean: 4.728589474954164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 4.721303580204623\n",
      "resetting env. episode reward total was 14.0. running mean: 4.8140905444025766\n",
      "resetting env. episode reward total was 11.0. running mean: 4.875949638958551\n",
      "resetting env. episode reward total was 2.0. running mean: 4.847190142568965\n",
      "resetting env. episode reward total was 14.0. running mean: 4.938718241143275\n",
      "resetting env. episode reward total was 8.0. running mean: 4.969331058731842\n",
      "resetting env. episode reward total was 12.0. running mean: 5.039637748144524\n",
      "resetting env. episode reward total was 2.0. running mean: 5.009241370663078\n",
      "resetting env. episode reward total was 10.0. running mean: 5.059148956956447\n",
      "resetting env. episode reward total was 2.0. running mean: 5.028557467386882\n",
      "resetting env. episode reward total was 5.0. running mean: 5.028271892713013\n",
      "resetting env. episode reward total was 10.0. running mean: 5.077989173785882\n",
      "resetting env. episode reward total was 10.0. running mean: 5.127209282048023\n",
      "resetting env. episode reward total was 8.0. running mean: 5.155937189227543\n",
      "resetting env. episode reward total was 2.0. running mean: 5.124377817335267\n",
      "resetting env. episode reward total was -1.0. running mean: 5.063134039161914\n",
      "resetting env. episode reward total was 4.0. running mean: 5.0525026987702955\n",
      "resetting env. episode reward total was 2.0. running mean: 5.021977671782592\n",
      "resetting env. episode reward total was 4.0. running mean: 5.011757895064766\n",
      "resetting env. episode reward total was 6.0. running mean: 5.021640316114118\n",
      "resetting env. episode reward total was 4.0. running mean: 5.011423912952976\n",
      "resetting env. episode reward total was 9.0. running mean: 5.051309673823446\n",
      "resetting env. episode reward total was 11.0. running mean: 5.110796577085211\n",
      "resetting env. episode reward total was 7.0. running mean: 5.12968861131436\n",
      "resetting env. episode reward total was -7.0. running mean: 5.008391725201216\n",
      "resetting env. episode reward total was 8.0. running mean: 5.038307807949204\n",
      "resetting env. episode reward total was 12.0. running mean: 5.107924729869712\n",
      "resetting env. episode reward total was -4.0. running mean: 5.016845482571015\n",
      "resetting env. episode reward total was 2.0. running mean: 4.986677027745304\n",
      "resetting env. episode reward total was 11.0. running mean: 5.046810257467851\n",
      "resetting env. episode reward total was 8.0. running mean: 5.076342154893172\n",
      "resetting env. episode reward total was 5.0. running mean: 5.075578733344241\n",
      "resetting env. episode reward total was 15.0. running mean: 5.174822946010798\n",
      "resetting env. episode reward total was 16.0. running mean: 5.283074716550691\n",
      "resetting env. episode reward total was 5.0. running mean: 5.280243969385183\n",
      "resetting env. episode reward total was -6.0. running mean: 5.167441529691332\n",
      "resetting env. episode reward total was 14.0. running mean: 5.255767114394418\n",
      "resetting env. episode reward total was -2.0. running mean: 5.183209443250474\n",
      "resetting env. episode reward total was 3.0. running mean: 5.16137734881797\n",
      "resetting env. episode reward total was 14.0. running mean: 5.24976357532979\n",
      "resetting env. episode reward total was 3.0. running mean: 5.227265939576492\n",
      "resetting env. episode reward total was -6.0. running mean: 5.114993280180728\n",
      "resetting env. episode reward total was 11.0. running mean: 5.173843347378921\n",
      "resetting env. episode reward total was 11.0. running mean: 5.232104913905132\n",
      "resetting env. episode reward total was 8.0. running mean: 5.259783864766081\n",
      "resetting env. episode reward total was 4.0. running mean: 5.2471860261184196\n",
      "resetting env. episode reward total was 8.0. running mean: 5.274714165857235\n",
      "resetting env. episode reward total was -2.0. running mean: 5.201967024198663\n",
      "resetting env. episode reward total was -9.0. running mean: 5.059947353956677\n",
      "resetting env. episode reward total was 10.0. running mean: 5.1093478804171095\n",
      "resetting env. episode reward total was 5.0. running mean: 5.108254401612938\n",
      "resetting env. episode reward total was 12.0. running mean: 5.177171857596809\n",
      "resetting env. episode reward total was 10.0. running mean: 5.225400139020841\n",
      "resetting env. episode reward total was 10.0. running mean: 5.273146137630632\n",
      "resetting env. episode reward total was 3.0. running mean: 5.250414676254326\n",
      "resetting env. episode reward total was 3.0. running mean: 5.2279105294917825\n",
      "resetting env. episode reward total was -3.0. running mean: 5.145631424196864\n",
      "resetting env. episode reward total was 2.0. running mean: 5.114175109954895\n",
      "resetting env. episode reward total was 2.0. running mean: 5.083033358855346\n",
      "resetting env. episode reward total was 5.0. running mean: 5.082203025266792\n",
      "resetting env. episode reward total was 6.0. running mean: 5.091380995014124\n",
      "resetting env. episode reward total was 11.0. running mean: 5.150467185063983\n",
      "resetting env. episode reward total was 16.0. running mean: 5.258962513213343\n",
      "resetting env. episode reward total was 5.0. running mean: 5.256372888081209\n",
      "resetting env. episode reward total was 15.0. running mean: 5.353809159200398\n",
      "resetting env. episode reward total was 3.0. running mean: 5.330271067608394\n",
      "resetting env. episode reward total was 1.0. running mean: 5.28696835693231\n",
      "resetting env. episode reward total was 12.0. running mean: 5.354098673362987\n",
      "resetting env. episode reward total was 5.0. running mean: 5.350557686629357\n",
      "resetting env. episode reward total was -9.0. running mean: 5.2070521097630635\n",
      "resetting env. episode reward total was -1.0. running mean: 5.144981588665433\n",
      "resetting env. episode reward total was -2.0. running mean: 5.07353177277878\n",
      "resetting env. episode reward total was -1.0. running mean: 5.012796455050992\n",
      "resetting env. episode reward total was 7.0. running mean: 5.032668490500482\n",
      "resetting env. episode reward total was -2.0. running mean: 4.962341805595478\n",
      "resetting env. episode reward total was -1.0. running mean: 4.902718387539523\n",
      "resetting env. episode reward total was 6.0. running mean: 4.913691203664127\n",
      "resetting env. episode reward total was 14.0. running mean: 5.004554291627485\n",
      "resetting env. episode reward total was 3.0. running mean: 4.984508748711211\n",
      "resetting env. episode reward total was -3.0. running mean: 4.904663661224099\n",
      "resetting env. episode reward total was 9.0. running mean: 4.945617024611858\n",
      "resetting env. episode reward total was -4.0. running mean: 4.856160854365739\n",
      "resetting env. episode reward total was -9.0. running mean: 4.717599245822082\n",
      "resetting env. episode reward total was 15.0. running mean: 4.820423253363861\n",
      "resetting env. episode reward total was 13.0. running mean: 4.9022190208302225\n",
      "resetting env. episode reward total was -5.0. running mean: 4.80319683062192\n",
      "resetting env. episode reward total was -2.0. running mean: 4.735164862315702\n",
      "resetting env. episode reward total was 6.0. running mean: 4.747813213692544\n",
      "resetting env. episode reward total was 6.0. running mean: 4.760335081555619\n",
      "resetting env. episode reward total was -4.0. running mean: 4.672731730740062\n",
      "resetting env. episode reward total was 6.0. running mean: 4.686004413432661\n",
      "resetting env. episode reward total was 7.0. running mean: 4.709144369298334\n",
      "resetting env. episode reward total was 6.0. running mean: 4.72205292560535\n",
      "resetting env. episode reward total was 6.0. running mean: 4.734832396349296\n",
      "resetting env. episode reward total was -1.0. running mean: 4.677484072385804\n",
      "resetting env. episode reward total was -3.0. running mean: 4.600709231661946\n",
      "resetting env. episode reward total was 7.0. running mean: 4.6247021393453265\n",
      "resetting env. episode reward total was 3.0. running mean: 4.608455117951873\n",
      "resetting env. episode reward total was 8.0. running mean: 4.642370566772355\n",
      "resetting env. episode reward total was 7.0. running mean: 4.665946861104632\n",
      "resetting env. episode reward total was 8.0. running mean: 4.699287392493586\n",
      "resetting env. episode reward total was -1.0. running mean: 4.64229451856865\n",
      "resetting env. episode reward total was 3.0. running mean: 4.625871573382963\n",
      "resetting env. episode reward total was 1.0. running mean: 4.589612857649134\n",
      "resetting env. episode reward total was 4.0. running mean: 4.583716729072642\n",
      "resetting env. episode reward total was -8.0. running mean: 4.457879561781915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: 4.423300766164096\n",
      "resetting env. episode reward total was 2.0. running mean: 4.399067758502454\n",
      "resetting env. episode reward total was -1.0. running mean: 4.34507708091743\n",
      "resetting env. episode reward total was -5.0. running mean: 4.251626310108255\n",
      "resetting env. episode reward total was 14.0. running mean: 4.349110047007173\n",
      "resetting env. episode reward total was 6.0. running mean: 4.365618946537101\n",
      "resetting env. episode reward total was 6.0. running mean: 4.381962757071729\n",
      "resetting env. episode reward total was 4.0. running mean: 4.378143129501012\n",
      "resetting env. episode reward total was 5.0. running mean: 4.384361698206002\n",
      "resetting env. episode reward total was 2.0. running mean: 4.360518081223941\n",
      "resetting env. episode reward total was 8.0. running mean: 4.396912900411702\n",
      "resetting env. episode reward total was 9.0. running mean: 4.442943771407585\n",
      "resetting env. episode reward total was 5.0. running mean: 4.448514333693509\n",
      "resetting env. episode reward total was 9.0. running mean: 4.4940291903565734\n",
      "resetting env. episode reward total was 1.0. running mean: 4.4590888984530075\n",
      "resetting env. episode reward total was 4.0. running mean: 4.454498009468478\n",
      "resetting env. episode reward total was 8.0. running mean: 4.489953029373793\n",
      "resetting env. episode reward total was 9.0. running mean: 4.535053499080055\n",
      "resetting env. episode reward total was 5.0. running mean: 4.539702964089254\n",
      "resetting env. episode reward total was 5.0. running mean: 4.544305934448361\n",
      "resetting env. episode reward total was 13.0. running mean: 4.628862875103877\n",
      "resetting env. episode reward total was 8.0. running mean: 4.662574246352839\n",
      "resetting env. episode reward total was -9.0. running mean: 4.52594850388931\n",
      "resetting env. episode reward total was -6.0. running mean: 4.4206890188504175\n",
      "resetting env. episode reward total was -1.0. running mean: 4.3664821286619135\n",
      "resetting env. episode reward total was 1.0. running mean: 4.3328173073752945\n",
      "resetting env. episode reward total was 3.0. running mean: 4.319489134301541\n",
      "resetting env. episode reward total was 9.0. running mean: 4.366294242958526\n",
      "resetting env. episode reward total was 6.0. running mean: 4.38263130052894\n",
      "resetting env. episode reward total was 11.0. running mean: 4.448804987523651\n",
      "resetting env. episode reward total was -7.0. running mean: 4.334316937648414\n",
      "resetting env. episode reward total was 11.0. running mean: 4.40097376827193\n",
      "resetting env. episode reward total was -2.0. running mean: 4.336964030589211\n",
      "resetting env. episode reward total was 6.0. running mean: 4.353594390283319\n",
      "resetting env. episode reward total was 7.0. running mean: 4.3800584463804855\n",
      "resetting env. episode reward total was 7.0. running mean: 4.406257861916681\n",
      "resetting env. episode reward total was 5.0. running mean: 4.412195283297514\n",
      "resetting env. episode reward total was 5.0. running mean: 4.418073330464539\n",
      "resetting env. episode reward total was 7.0. running mean: 4.443892597159894\n",
      "resetting env. episode reward total was 9.0. running mean: 4.489453671188294\n",
      "resetting env. episode reward total was 10.0. running mean: 4.544559134476411\n",
      "resetting env. episode reward total was 5.0. running mean: 4.5491135431316465\n",
      "resetting env. episode reward total was 11.0. running mean: 4.613622407700331\n",
      "resetting env. episode reward total was 4.0. running mean: 4.607486183623328\n",
      "resetting env. episode reward total was 6.0. running mean: 4.621411321787094\n",
      "resetting env. episode reward total was 4.0. running mean: 4.615197208569223\n",
      "resetting env. episode reward total was 16.0. running mean: 4.729045236483532\n",
      "resetting env. episode reward total was -3.0. running mean: 4.651754784118696\n",
      "resetting env. episode reward total was 3.0. running mean: 4.635237236277509\n",
      "resetting env. episode reward total was 2.0. running mean: 4.608884863914733\n",
      "resetting env. episode reward total was 5.0. running mean: 4.612796015275586\n",
      "resetting env. episode reward total was 9.0. running mean: 4.65666805512283\n",
      "resetting env. episode reward total was 6.0. running mean: 4.670101374571601\n",
      "resetting env. episode reward total was 8.0. running mean: 4.703400360825885\n",
      "resetting env. episode reward total was 3.0. running mean: 4.686366357217627\n",
      "resetting env. episode reward total was 13.0. running mean: 4.7695026936454505\n",
      "resetting env. episode reward total was -2.0. running mean: 4.701807666708996\n",
      "resetting env. episode reward total was 5.0. running mean: 4.704789590041906\n",
      "resetting env. episode reward total was -6.0. running mean: 4.5977416941414875\n",
      "resetting env. episode reward total was -2.0. running mean: 4.531764277200073\n",
      "resetting env. episode reward total was 9.0. running mean: 4.576446634428072\n",
      "resetting env. episode reward total was 5.0. running mean: 4.580682168083791\n",
      "resetting env. episode reward total was 1.0. running mean: 4.544875346402953\n",
      "resetting env. episode reward total was 7.0. running mean: 4.569426592938924\n",
      "resetting env. episode reward total was -1.0. running mean: 4.513732327009535\n",
      "resetting env. episode reward total was 12.0. running mean: 4.58859500373944\n",
      "resetting env. episode reward total was 15.0. running mean: 4.692709053702045\n",
      "resetting env. episode reward total was 5.0. running mean: 4.695781963165024\n",
      "resetting env. episode reward total was 6.0. running mean: 4.7088241435333735\n",
      "resetting env. episode reward total was 7.0. running mean: 4.73173590209804\n",
      "resetting env. episode reward total was 6.0. running mean: 4.744418543077059\n",
      "resetting env. episode reward total was 5.0. running mean: 4.746974357646288\n",
      "resetting env. episode reward total was 9.0. running mean: 4.789504614069825\n",
      "resetting env. episode reward total was -8.0. running mean: 4.661609567929127\n",
      "resetting env. episode reward total was -5.0. running mean: 4.564993472249836\n",
      "resetting env. episode reward total was 4.0. running mean: 4.5593435375273375\n",
      "resetting env. episode reward total was 1.0. running mean: 4.523750102152063\n",
      "resetting env. episode reward total was -1.0. running mean: 4.468512601130543\n",
      "resetting env. episode reward total was -6.0. running mean: 4.363827475119238\n",
      "resetting env. episode reward total was 9.0. running mean: 4.410189200368046\n",
      "resetting env. episode reward total was 7.0. running mean: 4.436087308364366\n",
      "resetting env. episode reward total was -5.0. running mean: 4.341726435280722\n",
      "resetting env. episode reward total was 3.0. running mean: 4.328309170927915\n",
      "resetting env. episode reward total was 9.0. running mean: 4.375026079218636\n",
      "resetting env. episode reward total was -6.0. running mean: 4.27127581842645\n",
      "resetting env. episode reward total was 10.0. running mean: 4.328563060242185\n",
      "resetting env. episode reward total was 9.0. running mean: 4.375277429639763\n",
      "resetting env. episode reward total was 5.0. running mean: 4.381524655343366\n",
      "resetting env. episode reward total was 7.0. running mean: 4.407709408789932\n",
      "resetting env. episode reward total was -1.0. running mean: 4.3536323147020335\n",
      "resetting env. episode reward total was -3.0. running mean: 4.2800959915550125\n",
      "resetting env. episode reward total was 2.0. running mean: 4.257295031639462\n",
      "resetting env. episode reward total was 12.0. running mean: 4.334722081323068\n",
      "resetting env. episode reward total was 4.0. running mean: 4.331374860509837\n",
      "resetting env. episode reward total was 8.0. running mean: 4.368061111904739\n",
      "resetting env. episode reward total was 17.0. running mean: 4.494380500785692\n",
      "resetting env. episode reward total was 8.0. running mean: 4.529436695777835\n",
      "resetting env. episode reward total was 8.0. running mean: 4.564142328820057\n",
      "resetting env. episode reward total was 15.0. running mean: 4.6685009055318565\n",
      "resetting env. episode reward total was 7.0. running mean: 4.691815896476538\n",
      "resetting env. episode reward total was -2.0. running mean: 4.624897737511773\n",
      "resetting env. episode reward total was -2.0. running mean: 4.558648760136656\n",
      "resetting env. episode reward total was 6.0. running mean: 4.573062272535289\n",
      "resetting env. episode reward total was 9.0. running mean: 4.617331649809936\n",
      "resetting env. episode reward total was 7.0. running mean: 4.641158333311837\n",
      "resetting env. episode reward total was 8.0. running mean: 4.674746749978718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 4.737999282478931\n",
      "resetting env. episode reward total was 7.0. running mean: 4.760619289654142\n",
      "resetting env. episode reward total was -1.0. running mean: 4.7030130967576005\n",
      "resetting env. episode reward total was 9.0. running mean: 4.7459829657900245\n",
      "resetting env. episode reward total was -8.0. running mean: 4.618523136132124\n",
      "resetting env. episode reward total was 3.0. running mean: 4.602337904770803\n",
      "resetting env. episode reward total was -1.0. running mean: 4.546314525723095\n",
      "resetting env. episode reward total was 1.0. running mean: 4.510851380465864\n",
      "resetting env. episode reward total was 9.0. running mean: 4.555742866661205\n",
      "resetting env. episode reward total was 4.0. running mean: 4.550185437994593\n",
      "resetting env. episode reward total was -1.0. running mean: 4.4946835836146475\n",
      "resetting env. episode reward total was 4.0. running mean: 4.489736747778501\n",
      "resetting env. episode reward total was 4.0. running mean: 4.484839380300716\n",
      "resetting env. episode reward total was 6.0. running mean: 4.499990986497709\n",
      "resetting env. episode reward total was 11.0. running mean: 4.564991076632732\n",
      "resetting env. episode reward total was -3.0. running mean: 4.489341165866405\n",
      "resetting env. episode reward total was -1.0. running mean: 4.434447754207741\n",
      "resetting env. episode reward total was 3.0. running mean: 4.420103276665664\n",
      "resetting env. episode reward total was 7.0. running mean: 4.445902243899007\n",
      "resetting env. episode reward total was 7.0. running mean: 4.471443221460017\n",
      "resetting env. episode reward total was 7.0. running mean: 4.4967287892454175\n",
      "resetting env. episode reward total was 7.0. running mean: 4.521761501352963\n",
      "resetting env. episode reward total was -1.0. running mean: 4.4665438863394336\n",
      "resetting env. episode reward total was 4.0. running mean: 4.461878447476039\n",
      "resetting env. episode reward total was 2.0. running mean: 4.437259663001278\n",
      "resetting env. episode reward total was 11.0. running mean: 4.502887066371265\n",
      "resetting env. episode reward total was 10.0. running mean: 4.557858195707552\n",
      "resetting env. episode reward total was -2.0. running mean: 4.492279613750477\n",
      "resetting env. episode reward total was -5.0. running mean: 4.397356817612972\n",
      "resetting env. episode reward total was 7.0. running mean: 4.423383249436843\n",
      "resetting env. episode reward total was 8.0. running mean: 4.459149416942474\n",
      "resetting env. episode reward total was -2.0. running mean: 4.39455792277305\n",
      "resetting env. episode reward total was 8.0. running mean: 4.430612343545319\n",
      "resetting env. episode reward total was 2.0. running mean: 4.406306220109865\n",
      "resetting env. episode reward total was 13.0. running mean: 4.492243157908766\n",
      "resetting env. episode reward total was 3.0. running mean: 4.477320726329679\n",
      "resetting env. episode reward total was 5.0. running mean: 4.482547519066382\n",
      "resetting env. episode reward total was 11.0. running mean: 4.547722043875718\n",
      "resetting env. episode reward total was 11.0. running mean: 4.612244823436962\n",
      "resetting env. episode reward total was -5.0. running mean: 4.516122375202592\n",
      "resetting env. episode reward total was -3.0. running mean: 4.440961151450566\n",
      "resetting env. episode reward total was 9.0. running mean: 4.48655153993606\n",
      "resetting env. episode reward total was 5.0. running mean: 4.491686024536699\n",
      "resetting env. episode reward total was 9.0. running mean: 4.536769164291332\n",
      "resetting env. episode reward total was 7.0. running mean: 4.561401472648419\n",
      "resetting env. episode reward total was 9.0. running mean: 4.6057874579219344\n",
      "resetting env. episode reward total was 3.0. running mean: 4.589729583342716\n",
      "resetting env. episode reward total was 3.0. running mean: 4.573832287509289\n",
      "resetting env. episode reward total was -1.0. running mean: 4.518093964634196\n",
      "resetting env. episode reward total was -3.0. running mean: 4.4429130249878535\n",
      "resetting env. episode reward total was -2.0. running mean: 4.378483894737975\n",
      "resetting env. episode reward total was 4.0. running mean: 4.374699055790596\n",
      "resetting env. episode reward total was -1.0. running mean: 4.32095206523269\n",
      "resetting env. episode reward total was -2.0. running mean: 4.257742544580363\n",
      "resetting env. episode reward total was 6.0. running mean: 4.275165119134559\n",
      "resetting env. episode reward total was 6.0. running mean: 4.292413467943214\n",
      "resetting env. episode reward total was 5.0. running mean: 4.299489333263781\n",
      "resetting env. episode reward total was 14.0. running mean: 4.396494439931143\n",
      "resetting env. episode reward total was -1.0. running mean: 4.342529495531831\n",
      "resetting env. episode reward total was 9.0. running mean: 4.389104200576513\n",
      "resetting env. episode reward total was -3.0. running mean: 4.315213158570748\n",
      "resetting env. episode reward total was 7.0. running mean: 4.34206102698504\n",
      "resetting env. episode reward total was 3.0. running mean: 4.32864041671519\n",
      "resetting env. episode reward total was -7.0. running mean: 4.215354012548038\n",
      "resetting env. episode reward total was 8.0. running mean: 4.253200472422558\n",
      "resetting env. episode reward total was 10.0. running mean: 4.310668467698331\n",
      "resetting env. episode reward total was 7.0. running mean: 4.337561783021348\n",
      "resetting env. episode reward total was 6.0. running mean: 4.354186165191134\n",
      "resetting env. episode reward total was 9.0. running mean: 4.400644303539223\n",
      "resetting env. episode reward total was 2.0. running mean: 4.3766378605038305\n",
      "resetting env. episode reward total was 10.0. running mean: 4.4328714818987915\n",
      "resetting env. episode reward total was 5.0. running mean: 4.438542767079803\n",
      "resetting env. episode reward total was 13.0. running mean: 4.524157339409005\n",
      "resetting env. episode reward total was 5.0. running mean: 4.528915766014914\n",
      "resetting env. episode reward total was 11.0. running mean: 4.593626608354765\n",
      "resetting env. episode reward total was -1.0. running mean: 4.537690342271218\n",
      "resetting env. episode reward total was 14.0. running mean: 4.632313438848506\n",
      "resetting env. episode reward total was 14.0. running mean: 4.72599030446002\n",
      "resetting env. episode reward total was 4.0. running mean: 4.71873040141542\n",
      "resetting env. episode reward total was 5.0. running mean: 4.721543097401265\n",
      "resetting env. episode reward total was 6.0. running mean: 4.7343276664272524\n",
      "resetting env. episode reward total was 1.0. running mean: 4.69698438976298\n",
      "resetting env. episode reward total was 15.0. running mean: 4.80001454586535\n",
      "resetting env. episode reward total was 11.0. running mean: 4.862014400406697\n",
      "resetting env. episode reward total was 3.0. running mean: 4.843394256402631\n",
      "resetting env. episode reward total was 1.0. running mean: 4.804960313838604\n",
      "resetting env. episode reward total was 14.0. running mean: 4.896910710700218\n",
      "resetting env. episode reward total was -3.0. running mean: 4.817941603593216\n",
      "resetting env. episode reward total was 2.0. running mean: 4.789762187557283\n",
      "resetting env. episode reward total was -9.0. running mean: 4.65186456568171\n",
      "resetting env. episode reward total was -3.0. running mean: 4.575345920024893\n",
      "resetting env. episode reward total was 2.0. running mean: 4.549592460824644\n",
      "resetting env. episode reward total was 14.0. running mean: 4.644096536216397\n",
      "resetting env. episode reward total was -5.0. running mean: 4.547655570854233\n",
      "resetting env. episode reward total was 8.0. running mean: 4.582179015145691\n",
      "resetting env. episode reward total was 5.0. running mean: 4.5863572249942335\n",
      "resetting env. episode reward total was 4.0. running mean: 4.580493652744291\n",
      "resetting env. episode reward total was -7.0. running mean: 4.464688716216848\n",
      "resetting env. episode reward total was 11.0. running mean: 4.53004182905468\n",
      "resetting env. episode reward total was 12.0. running mean: 4.604741410764133\n",
      "resetting env. episode reward total was 2.0. running mean: 4.578693996656491\n",
      "resetting env. episode reward total was 6.0. running mean: 4.592907056689926\n",
      "resetting env. episode reward total was 7.0. running mean: 4.616977986123027\n",
      "resetting env. episode reward total was -1.0. running mean: 4.560808206261797\n",
      "resetting env. episode reward total was 11.0. running mean: 4.625200124199179\n",
      "resetting env. episode reward total was 3.0. running mean: 4.608948122957187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 4.582858641727615\n",
      "resetting env. episode reward total was 6.0. running mean: 4.597030055310339\n",
      "resetting env. episode reward total was 2.0. running mean: 4.5710597547572345\n",
      "resetting env. episode reward total was -5.0. running mean: 4.475349157209663\n",
      "resetting env. episode reward total was 7.0. running mean: 4.500595665637566\n",
      "resetting env. episode reward total was 4.0. running mean: 4.49558970898119\n",
      "resetting env. episode reward total was 12.0. running mean: 4.570633811891378\n",
      "resetting env. episode reward total was 1.0. running mean: 4.534927473772464\n",
      "resetting env. episode reward total was 9.0. running mean: 4.579578199034739\n",
      "resetting env. episode reward total was -7.0. running mean: 4.463782417044391\n",
      "resetting env. episode reward total was 9.0. running mean: 4.509144592873947\n",
      "resetting env. episode reward total was 16.0. running mean: 4.624053146945208\n",
      "resetting env. episode reward total was 17.0. running mean: 4.747812615475755\n",
      "resetting env. episode reward total was 17.0. running mean: 4.870334489320998\n",
      "resetting env. episode reward total was 5.0. running mean: 4.871631144427788\n",
      "resetting env. episode reward total was 10.0. running mean: 4.922914832983509\n",
      "resetting env. episode reward total was 14.0. running mean: 5.013685684653674\n",
      "resetting env. episode reward total was 3.0. running mean: 4.993548827807137\n",
      "resetting env. episode reward total was 8.0. running mean: 5.023613339529065\n",
      "resetting env. episode reward total was 9.0. running mean: 5.063377206133775\n",
      "resetting env. episode reward total was 4.0. running mean: 5.052743434072437\n",
      "resetting env. episode reward total was 10.0. running mean: 5.102215999731713\n",
      "resetting env. episode reward total was 9.0. running mean: 5.141193839734395\n",
      "resetting env. episode reward total was 10.0. running mean: 5.189781901337051\n",
      "resetting env. episode reward total was -13.0. running mean: 5.007884082323681\n",
      "resetting env. episode reward total was 6.0. running mean: 5.017805241500444\n",
      "resetting env. episode reward total was 5.0. running mean: 5.017627189085439\n",
      "resetting env. episode reward total was 2.0. running mean: 4.987450917194584\n",
      "resetting env. episode reward total was 7.0. running mean: 5.007576408022639\n",
      "resetting env. episode reward total was 7.0. running mean: 5.027500643942413\n",
      "resetting env. episode reward total was 5.0. running mean: 5.027225637502989\n",
      "resetting env. episode reward total was 8.0. running mean: 5.056953381127959\n",
      "resetting env. episode reward total was -3.0. running mean: 4.976383847316678\n",
      "resetting env. episode reward total was 11.0. running mean: 5.036620008843512\n",
      "resetting env. episode reward total was 14.0. running mean: 5.126253808755076\n",
      "resetting env. episode reward total was 7.0. running mean: 5.144991270667526\n",
      "resetting env. episode reward total was 9.0. running mean: 5.18354135796085\n",
      "resetting env. episode reward total was 11.0. running mean: 5.241705944381242\n",
      "resetting env. episode reward total was 8.0. running mean: 5.2692888849374295\n",
      "resetting env. episode reward total was 9.0. running mean: 5.306595996088055\n",
      "resetting env. episode reward total was 11.0. running mean: 5.363530036127175\n",
      "resetting env. episode reward total was 6.0. running mean: 5.369894735765903\n",
      "resetting env. episode reward total was 12.0. running mean: 5.436195788408244\n",
      "resetting env. episode reward total was -8.0. running mean: 5.301833830524162\n",
      "resetting env. episode reward total was 16.0. running mean: 5.40881549221892\n",
      "resetting env. episode reward total was 5.0. running mean: 5.404727337296731\n",
      "resetting env. episode reward total was 12.0. running mean: 5.470680063923764\n",
      "resetting env. episode reward total was 12.0. running mean: 5.535973263284526\n",
      "resetting env. episode reward total was -1.0. running mean: 5.470613530651681\n",
      "resetting env. episode reward total was 7.0. running mean: 5.485907395345165\n",
      "resetting env. episode reward total was 11.0. running mean: 5.541048321391713\n",
      "resetting env. episode reward total was 10.0. running mean: 5.585637838177796\n",
      "resetting env. episode reward total was 3.0. running mean: 5.559781459796018\n",
      "resetting env. episode reward total was 3.0. running mean: 5.534183645198058\n",
      "resetting env. episode reward total was 6.0. running mean: 5.538841808746077\n",
      "resetting env. episode reward total was 9.0. running mean: 5.573453390658616\n",
      "resetting env. episode reward total was 10.0. running mean: 5.61771885675203\n",
      "resetting env. episode reward total was 7.0. running mean: 5.63154166818451\n",
      "resetting env. episode reward total was -8.0. running mean: 5.495226251502665\n",
      "resetting env. episode reward total was 4.0. running mean: 5.480273988987638\n",
      "resetting env. episode reward total was 6.0. running mean: 5.4854712490977615\n",
      "resetting env. episode reward total was -5.0. running mean: 5.380616536606784\n",
      "resetting env. episode reward total was 11.0. running mean: 5.436810371240716\n",
      "resetting env. episode reward total was 9.0. running mean: 5.472442267528309\n",
      "resetting env. episode reward total was -3.0. running mean: 5.387717844853025\n",
      "resetting env. episode reward total was 10.0. running mean: 5.433840666404494\n",
      "resetting env. episode reward total was 7.0. running mean: 5.449502259740449\n",
      "resetting env. episode reward total was 12.0. running mean: 5.515007237143045\n",
      "resetting env. episode reward total was -7.0. running mean: 5.389857164771614\n",
      "resetting env. episode reward total was 8.0. running mean: 5.415958593123898\n",
      "resetting env. episode reward total was 10.0. running mean: 5.461799007192659\n",
      "resetting env. episode reward total was 15.0. running mean: 5.557181017120732\n",
      "resetting env. episode reward total was 7.0. running mean: 5.5716092069495256\n",
      "resetting env. episode reward total was 9.0. running mean: 5.60589311488003\n",
      "resetting env. episode reward total was 5.0. running mean: 5.59983418373123\n",
      "resetting env. episode reward total was 12.0. running mean: 5.663835841893918\n",
      "resetting env. episode reward total was 6.0. running mean: 5.667197483474978\n",
      "resetting env. episode reward total was 8.0. running mean: 5.690525508640229\n",
      "resetting env. episode reward total was 2.0. running mean: 5.653620253553826\n",
      "resetting env. episode reward total was -5.0. running mean: 5.547084051018288\n",
      "resetting env. episode reward total was 3.0. running mean: 5.5216132105081055\n",
      "resetting env. episode reward total was -1.0. running mean: 5.4563970784030245\n",
      "resetting env. episode reward total was 12.0. running mean: 5.521833107618995\n",
      "resetting env. episode reward total was 9.0. running mean: 5.556614776542805\n",
      "resetting env. episode reward total was 10.0. running mean: 5.601048628777376\n",
      "resetting env. episode reward total was -1.0. running mean: 5.5350381424896025\n",
      "resetting env. episode reward total was 14.0. running mean: 5.619687761064706\n",
      "resetting env. episode reward total was 6.0. running mean: 5.623490883454059\n",
      "resetting env. episode reward total was -2.0. running mean: 5.547255974619518\n",
      "resetting env. episode reward total was 10.0. running mean: 5.591783414873323\n",
      "resetting env. episode reward total was 2.0. running mean: 5.555865580724589\n",
      "resetting env. episode reward total was 11.0. running mean: 5.610306924917343\n",
      "resetting env. episode reward total was 8.0. running mean: 5.6342038556681695\n",
      "resetting env. episode reward total was -6.0. running mean: 5.517861817111488\n",
      "resetting env. episode reward total was 3.0. running mean: 5.492683198940373\n",
      "resetting env. episode reward total was 9.0. running mean: 5.527756366950969\n",
      "resetting env. episode reward total was 4.0. running mean: 5.51247880328146\n",
      "resetting env. episode reward total was 9.0. running mean: 5.547354015248645\n",
      "resetting env. episode reward total was -3.0. running mean: 5.461880475096159\n",
      "resetting env. episode reward total was 16.0. running mean: 5.567261670345197\n",
      "resetting env. episode reward total was 7.0. running mean: 5.581589053641745\n",
      "resetting env. episode reward total was 6.0. running mean: 5.585773163105327\n",
      "resetting env. episode reward total was 9.0. running mean: 5.619915431474274\n",
      "resetting env. episode reward total was 15.0. running mean: 5.713716277159532\n",
      "resetting env. episode reward total was 4.0. running mean: 5.696579114387936\n",
      "resetting env. episode reward total was 2.0. running mean: 5.659613323244057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 5.643017190011616\n",
      "resetting env. episode reward total was 2.0. running mean: 5.606587018111499\n",
      "resetting env. episode reward total was 1.0. running mean: 5.560521147930384\n",
      "resetting env. episode reward total was 8.0. running mean: 5.58491593645108\n",
      "resetting env. episode reward total was 1.0. running mean: 5.5390667770865685\n",
      "resetting env. episode reward total was 7.0. running mean: 5.553676109315703\n",
      "resetting env. episode reward total was 3.0. running mean: 5.528139348222546\n",
      "resetting env. episode reward total was 2.0. running mean: 5.4928579547403205\n",
      "resetting env. episode reward total was 4.0. running mean: 5.477929375192917\n",
      "resetting env. episode reward total was 1.0. running mean: 5.433150081440988\n",
      "resetting env. episode reward total was 3.0. running mean: 5.408818580626578\n",
      "resetting env. episode reward total was 1.0. running mean: 5.364730394820312\n",
      "resetting env. episode reward total was 18.0. running mean: 5.491083090872109\n",
      "resetting env. episode reward total was 8.0. running mean: 5.516172259963388\n",
      "resetting env. episode reward total was 7.0. running mean: 5.531010537363754\n",
      "resetting env. episode reward total was 5.0. running mean: 5.525700431990116\n",
      "resetting env. episode reward total was 7.0. running mean: 5.5404434276702155\n",
      "resetting env. episode reward total was 14.0. running mean: 5.625038993393513\n",
      "resetting env. episode reward total was 7.0. running mean: 5.638788603459578\n",
      "resetting env. episode reward total was -1.0. running mean: 5.5724007174249826\n",
      "resetting env. episode reward total was 4.0. running mean: 5.556676710250732\n",
      "resetting env. episode reward total was 13.0. running mean: 5.631109943148225\n",
      "resetting env. episode reward total was 11.0. running mean: 5.6847988437167425\n",
      "resetting env. episode reward total was 9.0. running mean: 5.717950855279575\n",
      "resetting env. episode reward total was 11.0. running mean: 5.77077134672678\n",
      "resetting env. episode reward total was 15.0. running mean: 5.863063633259512\n",
      "resetting env. episode reward total was 3.0. running mean: 5.834432996926917\n",
      "resetting env. episode reward total was 7.0. running mean: 5.846088666957647\n",
      "resetting env. episode reward total was 4.0. running mean: 5.827627780288071\n",
      "resetting env. episode reward total was 10.0. running mean: 5.86935150248519\n",
      "resetting env. episode reward total was 1.0. running mean: 5.820657987460338\n",
      "resetting env. episode reward total was -7.0. running mean: 5.692451407585734\n",
      "resetting env. episode reward total was 10.0. running mean: 5.735526893509877\n",
      "resetting env. episode reward total was 5.0. running mean: 5.728171624574778\n",
      "resetting env. episode reward total was 4.0. running mean: 5.7108899083290305\n",
      "resetting env. episode reward total was 10.0. running mean: 5.75378100924574\n",
      "resetting env. episode reward total was 3.0. running mean: 5.726243199153283\n",
      "resetting env. episode reward total was 8.0. running mean: 5.7489807671617505\n",
      "resetting env. episode reward total was -2.0. running mean: 5.671490959490133\n",
      "resetting env. episode reward total was 6.0. running mean: 5.6747760498952315\n",
      "resetting env. episode reward total was -1.0. running mean: 5.608028289396279\n",
      "resetting env. episode reward total was -8.0. running mean: 5.471948006502316\n",
      "resetting env. episode reward total was 9.0. running mean: 5.507228526437293\n",
      "resetting env. episode reward total was 9.0. running mean: 5.54215624117292\n",
      "resetting env. episode reward total was 7.0. running mean: 5.556734678761191\n",
      "resetting env. episode reward total was 11.0. running mean: 5.611167331973579\n",
      "resetting env. episode reward total was 4.0. running mean: 5.595055658653844\n",
      "resetting env. episode reward total was -6.0. running mean: 5.479105102067305\n",
      "resetting env. episode reward total was 12.0. running mean: 5.544314051046633\n",
      "resetting env. episode reward total was 13.0. running mean: 5.618870910536166\n",
      "resetting env. episode reward total was 13.0. running mean: 5.692682201430804\n",
      "resetting env. episode reward total was 6.0. running mean: 5.695755379416496\n",
      "resetting env. episode reward total was 8.0. running mean: 5.718797825622331\n",
      "resetting env. episode reward total was 2.0. running mean: 5.681609847366107\n",
      "resetting env. episode reward total was 9.0. running mean: 5.714793748892446\n",
      "resetting env. episode reward total was -3.0. running mean: 5.6276458114035215\n",
      "resetting env. episode reward total was 4.0. running mean: 5.611369353289486\n",
      "resetting env. episode reward total was 5.0. running mean: 5.605255659756591\n",
      "resetting env. episode reward total was 5.0. running mean: 5.5992031031590255\n",
      "resetting env. episode reward total was -1.0. running mean: 5.533211072127435\n",
      "resetting env. episode reward total was 9.0. running mean: 5.56787896140616\n",
      "resetting env. episode reward total was -3.0. running mean: 5.4822001717920985\n",
      "resetting env. episode reward total was 6.0. running mean: 5.4873781700741775\n",
      "resetting env. episode reward total was 4.0. running mean: 5.4725043883734354\n",
      "resetting env. episode reward total was 6.0. running mean: 5.477779344489701\n",
      "resetting env. episode reward total was 4.0. running mean: 5.463001551044804\n",
      "resetting env. episode reward total was 2.0. running mean: 5.428371535534355\n",
      "resetting env. episode reward total was 7.0. running mean: 5.4440878201790115\n",
      "resetting env. episode reward total was 13.0. running mean: 5.519646941977221\n",
      "resetting env. episode reward total was 6.0. running mean: 5.524450472557449\n",
      "resetting env. episode reward total was 13.0. running mean: 5.599205967831875\n",
      "resetting env. episode reward total was 5.0. running mean: 5.5932139081535555\n",
      "resetting env. episode reward total was 1.0. running mean: 5.547281769072019\n",
      "resetting env. episode reward total was 3.0. running mean: 5.521808951381299\n",
      "resetting env. episode reward total was 9.0. running mean: 5.556590861867486\n",
      "resetting env. episode reward total was 4.0. running mean: 5.541024953248811\n",
      "resetting env. episode reward total was 14.0. running mean: 5.625614703716322\n",
      "resetting env. episode reward total was 9.0. running mean: 5.659358556679159\n",
      "resetting env. episode reward total was 12.0. running mean: 5.722764971112367\n",
      "resetting env. episode reward total was 12.0. running mean: 5.785537321401243\n",
      "resetting env. episode reward total was 6.0. running mean: 5.78768194818723\n",
      "resetting env. episode reward total was -3.0. running mean: 5.699805128705358\n",
      "resetting env. episode reward total was 3.0. running mean: 5.672807077418304\n",
      "resetting env. episode reward total was 15.0. running mean: 5.766079006644121\n",
      "resetting env. episode reward total was 14.0. running mean: 5.84841821657768\n",
      "resetting env. episode reward total was -3.0. running mean: 5.759934034411903\n",
      "resetting env. episode reward total was 9.0. running mean: 5.792334694067784\n",
      "resetting env. episode reward total was -4.0. running mean: 5.694411347127106\n",
      "resetting env. episode reward total was 8.0. running mean: 5.717467233655835\n",
      "resetting env. episode reward total was 9.0. running mean: 5.750292561319276\n",
      "resetting env. episode reward total was 6.0. running mean: 5.752789635706083\n",
      "resetting env. episode reward total was 7.0. running mean: 5.765261739349023\n",
      "resetting env. episode reward total was 1.0. running mean: 5.717609121955532\n",
      "resetting env. episode reward total was -1.0. running mean: 5.650433030735977\n",
      "resetting env. episode reward total was 11.0. running mean: 5.703928700428618\n",
      "resetting env. episode reward total was 8.0. running mean: 5.726889413424331\n",
      "resetting env. episode reward total was 3.0. running mean: 5.699620519290088\n",
      "resetting env. episode reward total was -9.0. running mean: 5.552624314097187\n",
      "resetting env. episode reward total was 13.0. running mean: 5.627098070956215\n",
      "resetting env. episode reward total was -5.0. running mean: 5.520827090246653\n",
      "resetting env. episode reward total was 5.0. running mean: 5.515618819344187\n",
      "resetting env. episode reward total was 9.0. running mean: 5.5504626311507455\n",
      "resetting env. episode reward total was -4.0. running mean: 5.454958004839238\n",
      "resetting env. episode reward total was 6.0. running mean: 5.460408424790845\n",
      "resetting env. episode reward total was 11.0. running mean: 5.515804340542937\n",
      "resetting env. episode reward total was -7.0. running mean: 5.390646297137508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 5.386739834166132\n",
      "resetting env. episode reward total was 6.0. running mean: 5.39287243582447\n",
      "resetting env. episode reward total was 7.0. running mean: 5.408943711466226\n",
      "resetting env. episode reward total was -8.0. running mean: 5.274854274351564\n",
      "resetting env. episode reward total was 11.0. running mean: 5.332105731608049\n",
      "resetting env. episode reward total was 12.0. running mean: 5.398784674291969\n",
      "resetting env. episode reward total was 2.0. running mean: 5.364796827549049\n",
      "resetting env. episode reward total was 8.0. running mean: 5.391148859273558\n",
      "resetting env. episode reward total was 6.0. running mean: 5.3972373706808225\n",
      "resetting env. episode reward total was 7.0. running mean: 5.413264996974014\n",
      "resetting env. episode reward total was -1.0. running mean: 5.349132347004274\n",
      "resetting env. episode reward total was 6.0. running mean: 5.355641023534231\n",
      "resetting env. episode reward total was 11.0. running mean: 5.412084613298889\n",
      "resetting env. episode reward total was 2.0. running mean: 5.3779637671659\n",
      "resetting env. episode reward total was -1.0. running mean: 5.314184129494241\n",
      "resetting env. episode reward total was 8.0. running mean: 5.341042288199299\n",
      "resetting env. episode reward total was 9.0. running mean: 5.377631865317306\n",
      "resetting env. episode reward total was 7.0. running mean: 5.393855546664133\n",
      "resetting env. episode reward total was 9.0. running mean: 5.429916991197492\n",
      "resetting env. episode reward total was 1.0. running mean: 5.385617821285517\n",
      "resetting env. episode reward total was -4.0. running mean: 5.291761643072662\n",
      "resetting env. episode reward total was 1.0. running mean: 5.248844026641935\n",
      "resetting env. episode reward total was 7.0. running mean: 5.266355586375516\n",
      "resetting env. episode reward total was 11.0. running mean: 5.323692030511761\n",
      "resetting env. episode reward total was 1.0. running mean: 5.280455110206644\n",
      "resetting env. episode reward total was 12.0. running mean: 5.3476505591045775\n",
      "resetting env. episode reward total was 14.0. running mean: 5.434174053513531\n",
      "resetting env. episode reward total was 10.0. running mean: 5.479832312978395\n",
      "resetting env. episode reward total was 7.0. running mean: 5.495033989848611\n",
      "resetting env. episode reward total was 16.0. running mean: 5.600083649950125\n",
      "resetting env. episode reward total was -1.0. running mean: 5.534082813450624\n",
      "resetting env. episode reward total was 4.0. running mean: 5.518741985316118\n",
      "resetting env. episode reward total was 14.0. running mean: 5.603554565462956\n",
      "resetting env. episode reward total was 11.0. running mean: 5.657519019808327\n",
      "resetting env. episode reward total was 15.0. running mean: 5.750943829610244\n",
      "resetting env. episode reward total was 3.0. running mean: 5.723434391314142\n",
      "resetting env. episode reward total was 9.0. running mean: 5.756200047401\n",
      "resetting env. episode reward total was -3.0. running mean: 5.66863804692699\n",
      "resetting env. episode reward total was 9.0. running mean: 5.7019516664577194\n",
      "resetting env. episode reward total was 2.0. running mean: 5.664932149793142\n",
      "resetting env. episode reward total was 1.0. running mean: 5.61828282829521\n",
      "resetting env. episode reward total was 16.0. running mean: 5.722100000012258\n",
      "resetting env. episode reward total was 8.0. running mean: 5.744879000012135\n",
      "resetting env. episode reward total was 12.0. running mean: 5.807430210012014\n",
      "resetting env. episode reward total was 8.0. running mean: 5.829355907911894\n",
      "resetting env. episode reward total was 9.0. running mean: 5.861062348832775\n",
      "resetting env. episode reward total was -1.0. running mean: 5.792451725344447\n",
      "resetting env. episode reward total was 4.0. running mean: 5.774527208091003\n",
      "resetting env. episode reward total was 5.0. running mean: 5.7667819360100925\n",
      "resetting env. episode reward total was 14.0. running mean: 5.849114116649991\n",
      "resetting env. episode reward total was -10.0. running mean: 5.690622975483492\n",
      "resetting env. episode reward total was 5.0. running mean: 5.683716745728656\n",
      "resetting env. episode reward total was 6.0. running mean: 5.686879578271369\n",
      "resetting env. episode reward total was -11.0. running mean: 5.520010782488654\n",
      "resetting env. episode reward total was 1.0. running mean: 5.474810674663767\n",
      "resetting env. episode reward total was 5.0. running mean: 5.47006256791713\n",
      "resetting env. episode reward total was 15.0. running mean: 5.565361942237959\n",
      "resetting env. episode reward total was 11.0. running mean: 5.61970832281558\n",
      "resetting env. episode reward total was 10.0. running mean: 5.663511239587423\n",
      "resetting env. episode reward total was -5.0. running mean: 5.55687612719155\n",
      "resetting env. episode reward total was 10.0. running mean: 5.6013073659196335\n",
      "resetting env. episode reward total was -8.0. running mean: 5.465294292260437\n",
      "resetting env. episode reward total was -5.0. running mean: 5.360641349337833\n",
      "resetting env. episode reward total was 9.0. running mean: 5.397034935844454\n",
      "resetting env. episode reward total was 11.0. running mean: 5.4530645864860094\n",
      "resetting env. episode reward total was -11.0. running mean: 5.288533940621149\n",
      "resetting env. episode reward total was 4.0. running mean: 5.275648601214938\n",
      "resetting env. episode reward total was 15.0. running mean: 5.372892115202789\n",
      "resetting env. episode reward total was 3.0. running mean: 5.349163194050761\n",
      "resetting env. episode reward total was 4.0. running mean: 5.335671562110253\n",
      "resetting env. episode reward total was 7.0. running mean: 5.352314846489151\n",
      "resetting env. episode reward total was 7.0. running mean: 5.36879169802426\n",
      "resetting env. episode reward total was 10.0. running mean: 5.415103781044016\n",
      "resetting env. episode reward total was -4.0. running mean: 5.320952743233576\n",
      "resetting env. episode reward total was -8.0. running mean: 5.18774321580124\n",
      "resetting env. episode reward total was 6.0. running mean: 5.195865783643227\n",
      "resetting env. episode reward total was 6.0. running mean: 5.203907125806794\n",
      "resetting env. episode reward total was 1.0. running mean: 5.1618680545487265\n",
      "resetting env. episode reward total was 11.0. running mean: 5.22024937400324\n",
      "resetting env. episode reward total was -6.0. running mean: 5.108046880263208\n",
      "resetting env. episode reward total was -8.0. running mean: 4.976966411460576\n",
      "resetting env. episode reward total was 7.0. running mean: 4.997196747345971\n",
      "resetting env. episode reward total was 6.0. running mean: 5.0072247798725105\n",
      "resetting env. episode reward total was 5.0. running mean: 5.0071525320737855\n",
      "resetting env. episode reward total was 5.0. running mean: 5.007081006753047\n",
      "resetting env. episode reward total was 14.0. running mean: 5.097010196685517\n",
      "resetting env. episode reward total was 10.0. running mean: 5.1460400947186615\n",
      "resetting env. episode reward total was 2.0. running mean: 5.114579693771474\n",
      "resetting env. episode reward total was 7.0. running mean: 5.133433896833759\n",
      "resetting env. episode reward total was -11.0. running mean: 4.9720995578654215\n",
      "resetting env. episode reward total was 12.0. running mean: 5.042378562286768\n",
      "resetting env. episode reward total was 15.0. running mean: 5.1419547766639\n",
      "resetting env. episode reward total was 5.0. running mean: 5.140535228897261\n",
      "resetting env. episode reward total was -2.0. running mean: 5.069129876608288\n",
      "resetting env. episode reward total was -1.0. running mean: 5.008438577842206\n",
      "resetting env. episode reward total was 3.0. running mean: 4.988354192063785\n",
      "resetting env. episode reward total was 3.0. running mean: 4.968470650143147\n",
      "resetting env. episode reward total was -5.0. running mean: 4.868785943641716\n",
      "resetting env. episode reward total was 8.0. running mean: 4.900098084205299\n",
      "resetting env. episode reward total was 5.0. running mean: 4.901097103363245\n",
      "resetting env. episode reward total was 3.0. running mean: 4.882086132329613\n",
      "resetting env. episode reward total was 7.0. running mean: 4.903265271006317\n",
      "resetting env. episode reward total was 10.0. running mean: 4.9542326182962535\n",
      "resetting env. episode reward total was 7.0. running mean: 4.974690292113292\n",
      "resetting env. episode reward total was 7.0. running mean: 4.994943389192159\n",
      "resetting env. episode reward total was 8.0. running mean: 5.024993955300237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 5.044744015747235\n",
      "resetting env. episode reward total was 2.0. running mean: 5.014296575589762\n",
      "resetting env. episode reward total was 15.0. running mean: 5.114153609833865\n",
      "resetting env. episode reward total was 2.0. running mean: 5.083012073735526\n",
      "resetting env. episode reward total was -3.0. running mean: 5.00218195299817\n",
      "resetting env. episode reward total was 13.0. running mean: 5.0821601334681885\n",
      "resetting env. episode reward total was 1.0. running mean: 5.041338532133507\n",
      "resetting env. episode reward total was 13.0. running mean: 5.120925146812171\n",
      "resetting env. episode reward total was 13.0. running mean: 5.199715895344049\n",
      "resetting env. episode reward total was 9.0. running mean: 5.237718736390608\n",
      "resetting env. episode reward total was 9.0. running mean: 5.2753415490267015\n",
      "resetting env. episode reward total was 10.0. running mean: 5.322588133536434\n",
      "resetting env. episode reward total was -7.0. running mean: 5.19936225220107\n",
      "resetting env. episode reward total was 5.0. running mean: 5.197368629679059\n",
      "resetting env. episode reward total was -1.0. running mean: 5.135394943382269\n",
      "resetting env. episode reward total was 11.0. running mean: 5.194040993948446\n",
      "resetting env. episode reward total was 2.0. running mean: 5.162100584008962\n",
      "resetting env. episode reward total was 12.0. running mean: 5.230479578168872\n",
      "resetting env. episode reward total was 11.0. running mean: 5.288174782387183\n",
      "resetting env. episode reward total was 13.0. running mean: 5.365293034563312\n",
      "resetting env. episode reward total was 13.0. running mean: 5.4416401042176785\n",
      "resetting env. episode reward total was 1.0. running mean: 5.397223703175501\n",
      "resetting env. episode reward total was -1.0. running mean: 5.3332514661437465\n",
      "resetting env. episode reward total was 8.0. running mean: 5.359918951482309\n",
      "resetting env. episode reward total was 7.0. running mean: 5.376319761967486\n",
      "resetting env. episode reward total was 10.0. running mean: 5.42255656434781\n",
      "resetting env. episode reward total was -1.0. running mean: 5.358330998704332\n",
      "resetting env. episode reward total was -5.0. running mean: 5.254747688717289\n",
      "resetting env. episode reward total was 5.0. running mean: 5.252200211830115\n",
      "resetting env. episode reward total was 2.0. running mean: 5.219678209711814\n",
      "resetting env. episode reward total was 6.0. running mean: 5.227481427614696\n",
      "resetting env. episode reward total was 1.0. running mean: 5.185206613338549\n",
      "resetting env. episode reward total was -2.0. running mean: 5.113354547205164\n",
      "resetting env. episode reward total was -1.0. running mean: 5.052221001733113\n",
      "resetting env. episode reward total was 6.0. running mean: 5.061698791715781\n",
      "resetting env. episode reward total was 13.0. running mean: 5.141081803798623\n",
      "resetting env. episode reward total was -7.0. running mean: 5.019670985760636\n",
      "resetting env. episode reward total was 8.0. running mean: 5.04947427590303\n",
      "resetting env. episode reward total was 7.0. running mean: 5.068979533144\n",
      "resetting env. episode reward total was -13.0. running mean: 4.88828973781256\n",
      "resetting env. episode reward total was 6.0. running mean: 4.899406840434434\n",
      "resetting env. episode reward total was 15.0. running mean: 5.00041277203009\n",
      "resetting env. episode reward total was -5.0. running mean: 4.900408644309789\n",
      "resetting env. episode reward total was -2.0. running mean: 4.8314045578666915\n",
      "resetting env. episode reward total was 5.0. running mean: 4.833090512288025\n",
      "resetting env. episode reward total was 9.0. running mean: 4.874759607165144\n",
      "resetting env. episode reward total was 6.0. running mean: 4.886012011093492\n",
      "resetting env. episode reward total was 2.0. running mean: 4.857151890982557\n",
      "resetting env. episode reward total was 10.0. running mean: 4.9085803720727315\n",
      "resetting env. episode reward total was 3.0. running mean: 4.889494568352005\n",
      "resetting env. episode reward total was 5.0. running mean: 4.890599622668485\n",
      "resetting env. episode reward total was -1.0. running mean: 4.8316936264418\n",
      "resetting env. episode reward total was 1.0. running mean: 4.793376690177382\n",
      "resetting env. episode reward total was -1.0. running mean: 4.735442923275609\n",
      "resetting env. episode reward total was 8.0. running mean: 4.7680884940428525\n",
      "resetting env. episode reward total was 13.0. running mean: 4.850407609102424\n",
      "resetting env. episode reward total was 4.0. running mean: 4.8419035330114\n",
      "resetting env. episode reward total was 7.0. running mean: 4.863484497681286\n",
      "resetting env. episode reward total was 7.0. running mean: 4.884849652704474\n",
      "resetting env. episode reward total was 13.0. running mean: 4.966001156177429\n",
      "resetting env. episode reward total was 14.0. running mean: 5.056341144615654\n",
      "resetting env. episode reward total was 11.0. running mean: 5.115777733169498\n",
      "resetting env. episode reward total was 3.0. running mean: 5.094619955837803\n",
      "resetting env. episode reward total was -8.0. running mean: 4.963673756279425\n",
      "resetting env. episode reward total was 10.0. running mean: 5.01403701871663\n",
      "resetting env. episode reward total was 7.0. running mean: 5.033896648529464\n",
      "resetting env. episode reward total was 4.0. running mean: 5.02355768204417\n",
      "resetting env. episode reward total was 5.0. running mean: 5.023322105223728\n",
      "resetting env. episode reward total was 7.0. running mean: 5.043088884171491\n",
      "resetting env. episode reward total was -1.0. running mean: 4.982657995329776\n",
      "resetting env. episode reward total was 4.0. running mean: 4.972831415376477\n",
      "resetting env. episode reward total was 6.0. running mean: 4.983103101222712\n",
      "resetting env. episode reward total was 4.0. running mean: 4.973272070210485\n",
      "resetting env. episode reward total was 1.0. running mean: 4.93353934950838\n",
      "resetting env. episode reward total was 14.0. running mean: 5.024203956013296\n",
      "resetting env. episode reward total was 9.0. running mean: 5.063961916453163\n",
      "resetting env. episode reward total was 10.0. running mean: 5.113322297288631\n",
      "resetting env. episode reward total was 7.0. running mean: 5.132189074315745\n",
      "resetting env. episode reward total was 8.0. running mean: 5.160867183572588\n",
      "resetting env. episode reward total was 14.0. running mean: 5.249258511736862\n",
      "resetting env. episode reward total was 8.0. running mean: 5.276765926619493\n",
      "resetting env. episode reward total was -9.0. running mean: 5.133998267353299\n",
      "resetting env. episode reward total was 6.0. running mean: 5.142658284679765\n",
      "resetting env. episode reward total was -3.0. running mean: 5.061231701832967\n",
      "resetting env. episode reward total was 8.0. running mean: 5.090619384814637\n",
      "resetting env. episode reward total was 10.0. running mean: 5.13971319096649\n",
      "resetting env. episode reward total was 5.0. running mean: 5.138316059056825\n",
      "resetting env. episode reward total was 12.0. running mean: 5.206932898466257\n",
      "resetting env. episode reward total was 11.0. running mean: 5.264863569481594\n",
      "resetting env. episode reward total was 11.0. running mean: 5.322214933786778\n",
      "resetting env. episode reward total was -2.0. running mean: 5.248992784448911\n",
      "resetting env. episode reward total was 3.0. running mean: 5.226502856604422\n",
      "resetting env. episode reward total was 5.0. running mean: 5.224237828038378\n",
      "resetting env. episode reward total was 14.0. running mean: 5.311995449757994\n",
      "resetting env. episode reward total was 5.0. running mean: 5.308875495260414\n",
      "resetting env. episode reward total was 14.0. running mean: 5.395786740307809\n",
      "resetting env. episode reward total was 14.0. running mean: 5.481828872904731\n",
      "resetting env. episode reward total was 8.0. running mean: 5.507010584175684\n",
      "resetting env. episode reward total was 6.0. running mean: 5.511940478333926\n",
      "resetting env. episode reward total was 2.0. running mean: 5.476821073550586\n",
      "resetting env. episode reward total was 11.0. running mean: 5.532052862815081\n",
      "resetting env. episode reward total was -3.0. running mean: 5.44673233418693\n",
      "resetting env. episode reward total was 6.0. running mean: 5.45226501084506\n",
      "resetting env. episode reward total was 11.0. running mean: 5.507742360736609\n",
      "resetting env. episode reward total was 1.0. running mean: 5.462664937129243\n",
      "resetting env. episode reward total was 13.0. running mean: 5.53803828775795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 5.52265790488037\n",
      "resetting env. episode reward total was 2.0. running mean: 5.487431325831566\n",
      "resetting env. episode reward total was 4.0. running mean: 5.47255701257325\n",
      "resetting env. episode reward total was 16.0. running mean: 5.5778314424475175\n",
      "resetting env. episode reward total was 10.0. running mean: 5.622053128023042\n",
      "resetting env. episode reward total was 5.0. running mean: 5.615832596742812\n",
      "resetting env. episode reward total was 3.0. running mean: 5.589674270775384\n",
      "resetting env. episode reward total was 6.0. running mean: 5.59377752806763\n",
      "resetting env. episode reward total was 13.0. running mean: 5.6678397527869535\n",
      "resetting env. episode reward total was 3.0. running mean: 5.641161355259084\n",
      "resetting env. episode reward total was 6.0. running mean: 5.644749741706493\n",
      "resetting env. episode reward total was 7.0. running mean: 5.658302244289428\n",
      "resetting env. episode reward total was -2.0. running mean: 5.581719221846534\n",
      "resetting env. episode reward total was -3.0. running mean: 5.495902029628068\n",
      "resetting env. episode reward total was 10.0. running mean: 5.540943009331787\n",
      "resetting env. episode reward total was -1.0. running mean: 5.475533579238469\n",
      "resetting env. episode reward total was 9.0. running mean: 5.510778243446084\n",
      "resetting env. episode reward total was -4.0. running mean: 5.415670461011623\n",
      "resetting env. episode reward total was 6.0. running mean: 5.421513756401507\n",
      "resetting env. episode reward total was 8.0. running mean: 5.4472986188374914\n",
      "resetting env. episode reward total was -6.0. running mean: 5.332825632649117\n",
      "resetting env. episode reward total was 9.0. running mean: 5.3694973763226255\n",
      "resetting env. episode reward total was 6.0. running mean: 5.3758024025593985\n",
      "resetting env. episode reward total was 2.0. running mean: 5.342044378533804\n",
      "resetting env. episode reward total was 9.0. running mean: 5.3786239347484655\n",
      "resetting env. episode reward total was 3.0. running mean: 5.354837695400981\n",
      "resetting env. episode reward total was 11.0. running mean: 5.411289318446972\n",
      "resetting env. episode reward total was 2.0. running mean: 5.377176425262502\n",
      "resetting env. episode reward total was 16.0. running mean: 5.483404661009877\n",
      "resetting env. episode reward total was 9.0. running mean: 5.518570614399779\n",
      "resetting env. episode reward total was 1.0. running mean: 5.47338490825578\n",
      "resetting env. episode reward total was 9.0. running mean: 5.508651059173222\n",
      "resetting env. episode reward total was 10.0. running mean: 5.553564548581489\n",
      "resetting env. episode reward total was 9.0. running mean: 5.588028903095674\n",
      "resetting env. episode reward total was 1.0. running mean: 5.542148614064717\n",
      "resetting env. episode reward total was 1.0. running mean: 5.49672712792407\n",
      "resetting env. episode reward total was 6.0. running mean: 5.50175985664483\n",
      "resetting env. episode reward total was 12.0. running mean: 5.566742258078381\n",
      "resetting env. episode reward total was 11.0. running mean: 5.6210748354975975\n",
      "resetting env. episode reward total was 7.0. running mean: 5.634864087142621\n",
      "resetting env. episode reward total was -1.0. running mean: 5.568515446271196\n",
      "resetting env. episode reward total was 6.0. running mean: 5.572830291808483\n",
      "resetting env. episode reward total was 2.0. running mean: 5.537101988890398\n",
      "resetting env. episode reward total was -4.0. running mean: 5.441730969001494\n",
      "resetting env. episode reward total was 10.0. running mean: 5.487313659311479\n",
      "resetting env. episode reward total was 2.0. running mean: 5.452440522718363\n",
      "resetting env. episode reward total was 10.0. running mean: 5.497916117491179\n",
      "resetting env. episode reward total was 9.0. running mean: 5.5329369563162665\n",
      "resetting env. episode reward total was 6.0. running mean: 5.537607586753103\n",
      "resetting env. episode reward total was 6.0. running mean: 5.542231510885572\n",
      "resetting env. episode reward total was 14.0. running mean: 5.626809195776716\n",
      "resetting env. episode reward total was 8.0. running mean: 5.6505411038189495\n",
      "resetting env. episode reward total was 6.0. running mean: 5.654035692780759\n",
      "resetting env. episode reward total was 11.0. running mean: 5.707495335852952\n",
      "resetting env. episode reward total was 5.0. running mean: 5.700420382494422\n",
      "resetting env. episode reward total was 12.0. running mean: 5.763416178669478\n",
      "resetting env. episode reward total was -1.0. running mean: 5.6957820168827835\n",
      "resetting env. episode reward total was -3.0. running mean: 5.608824196713956\n",
      "resetting env. episode reward total was -2.0. running mean: 5.5327359547468165\n",
      "resetting env. episode reward total was -3.0. running mean: 5.447408595199348\n",
      "resetting env. episode reward total was -4.0. running mean: 5.352934509247354\n",
      "resetting env. episode reward total was 9.0. running mean: 5.38940516415488\n",
      "resetting env. episode reward total was 2.0. running mean: 5.355511112513331\n",
      "resetting env. episode reward total was 7.0. running mean: 5.371956001388198\n",
      "resetting env. episode reward total was 10.0. running mean: 5.418236441374315\n",
      "resetting env. episode reward total was 9.0. running mean: 5.454054076960571\n",
      "resetting env. episode reward total was 9.0. running mean: 5.489513536190966\n",
      "resetting env. episode reward total was 8.0. running mean: 5.514618400829057\n",
      "resetting env. episode reward total was 7.0. running mean: 5.529472216820766\n",
      "resetting env. episode reward total was 5.0. running mean: 5.524177494652558\n",
      "resetting env. episode reward total was 5.0. running mean: 5.5189357197060325\n",
      "resetting env. episode reward total was -11.0. running mean: 5.353746362508971\n",
      "resetting env. episode reward total was 14.0. running mean: 5.440208898883881\n",
      "resetting env. episode reward total was 6.0. running mean: 5.445806809895042\n",
      "resetting env. episode reward total was 12.0. running mean: 5.511348741796091\n",
      "resetting env. episode reward total was 13.0. running mean: 5.58623525437813\n",
      "resetting env. episode reward total was 4.0. running mean: 5.570372901834349\n",
      "resetting env. episode reward total was -3.0. running mean: 5.484669172816005\n",
      "resetting env. episode reward total was -3.0. running mean: 5.399822481087845\n",
      "resetting env. episode reward total was 5.0. running mean: 5.395824256276966\n",
      "resetting env. episode reward total was -8.0. running mean: 5.261866013714196\n",
      "resetting env. episode reward total was 16.0. running mean: 5.369247353577054\n",
      "resetting env. episode reward total was 9.0. running mean: 5.405554880041284\n",
      "resetting env. episode reward total was 8.0. running mean: 5.431499331240871\n",
      "resetting env. episode reward total was 12.0. running mean: 5.497184337928462\n",
      "resetting env. episode reward total was -1.0. running mean: 5.432212494549177\n",
      "resetting env. episode reward total was 4.0. running mean: 5.417890369603685\n",
      "resetting env. episode reward total was 13.0. running mean: 5.493711465907649\n",
      "resetting env. episode reward total was 6.0. running mean: 5.498774351248572\n",
      "resetting env. episode reward total was 11.0. running mean: 5.553786607736086\n",
      "resetting env. episode reward total was 8.0. running mean: 5.578248741658725\n",
      "resetting env. episode reward total was 4.0. running mean: 5.562466254242138\n",
      "resetting env. episode reward total was 10.0. running mean: 5.606841591699716\n",
      "resetting env. episode reward total was -3.0. running mean: 5.520773175782718\n",
      "resetting env. episode reward total was 6.0. running mean: 5.525565444024891\n",
      "resetting env. episode reward total was 11.0. running mean: 5.580309789584642\n",
      "resetting env. episode reward total was 1.0. running mean: 5.5345066916887955\n",
      "resetting env. episode reward total was 8.0. running mean: 5.559161624771908\n",
      "resetting env. episode reward total was 3.0. running mean: 5.533570008524189\n",
      "resetting env. episode reward total was 2.0. running mean: 5.4982343084389464\n",
      "resetting env. episode reward total was 8.0. running mean: 5.523251965354557\n",
      "resetting env. episode reward total was 9.0. running mean: 5.558019445701012\n",
      "resetting env. episode reward total was 7.0. running mean: 5.572439251244002\n",
      "resetting env. episode reward total was 6.0. running mean: 5.576714858731561\n",
      "resetting env. episode reward total was -13.0. running mean: 5.390947710144246\n",
      "resetting env. episode reward total was 2.0. running mean: 5.357038233042803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 5.363467850712374\n",
      "resetting env. episode reward total was 6.0. running mean: 5.36983317220525\n",
      "resetting env. episode reward total was 8.0. running mean: 5.396134840483198\n",
      "resetting env. episode reward total was 2.0. running mean: 5.362173492078365\n",
      "resetting env. episode reward total was 3.0. running mean: 5.338551757157582\n",
      "resetting env. episode reward total was 2.0. running mean: 5.305166239586005\n",
      "resetting env. episode reward total was 8.0. running mean: 5.332114577190145\n",
      "resetting env. episode reward total was -1.0. running mean: 5.268793431418244\n",
      "resetting env. episode reward total was 2.0. running mean: 5.236105497104061\n",
      "resetting env. episode reward total was 16.0. running mean: 5.343744442133021\n",
      "resetting env. episode reward total was 7.0. running mean: 5.360306997711691\n",
      "resetting env. episode reward total was 12.0. running mean: 5.426703927734573\n",
      "resetting env. episode reward total was 3.0. running mean: 5.402436888457228\n",
      "resetting env. episode reward total was 1.0. running mean: 5.358412519572655\n",
      "resetting env. episode reward total was 12.0. running mean: 5.424828394376928\n",
      "resetting env. episode reward total was 2.0. running mean: 5.3905801104331585\n",
      "resetting env. episode reward total was 11.0. running mean: 5.446674309328827\n",
      "resetting env. episode reward total was 10.0. running mean: 5.492207566235539\n",
      "resetting env. episode reward total was 8.0. running mean: 5.517285490573183\n",
      "resetting env. episode reward total was -2.0. running mean: 5.442112635667452\n",
      "resetting env. episode reward total was 16.0. running mean: 5.547691509310777\n",
      "resetting env. episode reward total was 8.0. running mean: 5.5722145942176695\n",
      "resetting env. episode reward total was -1.0. running mean: 5.506492448275493\n",
      "resetting env. episode reward total was -5.0. running mean: 5.401427523792738\n",
      "resetting env. episode reward total was -4.0. running mean: 5.307413248554811\n",
      "resetting env. episode reward total was 10.0. running mean: 5.354339116069262\n",
      "resetting env. episode reward total was 2.0. running mean: 5.320795724908569\n",
      "resetting env. episode reward total was 7.0. running mean: 5.337587767659484\n",
      "resetting env. episode reward total was 2.0. running mean: 5.304211889982889\n",
      "resetting env. episode reward total was 6.0. running mean: 5.311169771083059\n",
      "resetting env. episode reward total was 11.0. running mean: 5.368058073372229\n",
      "resetting env. episode reward total was 4.0. running mean: 5.354377492638506\n",
      "resetting env. episode reward total was 9.0. running mean: 5.3908337177121215\n",
      "resetting env. episode reward total was 7.0. running mean: 5.406925380535\n",
      "resetting env. episode reward total was 3.0. running mean: 5.38285612672965\n",
      "resetting env. episode reward total was 9.0. running mean: 5.419027565462353\n",
      "resetting env. episode reward total was 3.0. running mean: 5.39483728980773\n",
      "resetting env. episode reward total was 5.0. running mean: 5.3908889169096526\n",
      "resetting env. episode reward total was 10.0. running mean: 5.436980027740556\n",
      "resetting env. episode reward total was 3.0. running mean: 5.4126102274631505\n",
      "resetting env. episode reward total was 8.0. running mean: 5.438484125188519\n",
      "resetting env. episode reward total was 7.0. running mean: 5.4540992839366345\n",
      "resetting env. episode reward total was 5.0. running mean: 5.449558291097268\n",
      "resetting env. episode reward total was 10.0. running mean: 5.495062708186294\n",
      "resetting env. episode reward total was 2.0. running mean: 5.460112081104431\n",
      "resetting env. episode reward total was 5.0. running mean: 5.4555109602933864\n",
      "resetting env. episode reward total was 6.0. running mean: 5.4609558506904525\n",
      "resetting env. episode reward total was 16.0. running mean: 5.566346292183548\n",
      "resetting env. episode reward total was -3.0. running mean: 5.4806828292617125\n",
      "resetting env. episode reward total was 10.0. running mean: 5.525876000969095\n",
      "resetting env. episode reward total was 4.0. running mean: 5.510617240959404\n",
      "resetting env. episode reward total was 7.0. running mean: 5.52551106854981\n",
      "resetting env. episode reward total was -3.0. running mean: 5.440255957864312\n",
      "resetting env. episode reward total was -3.0. running mean: 5.355853398285668\n",
      "resetting env. episode reward total was -3.0. running mean: 5.272294864302811\n",
      "resetting env. episode reward total was 8.0. running mean: 5.299571915659783\n",
      "resetting env. episode reward total was 11.0. running mean: 5.356576196503186\n",
      "resetting env. episode reward total was 13.0. running mean: 5.433010434538153\n",
      "resetting env. episode reward total was 4.0. running mean: 5.418680330192772\n",
      "resetting env. episode reward total was 14.0. running mean: 5.504493526890844\n",
      "resetting env. episode reward total was 9.0. running mean: 5.539448591621936\n",
      "resetting env. episode reward total was 3.0. running mean: 5.514054105705717\n",
      "resetting env. episode reward total was 11.0. running mean: 5.56891356464866\n",
      "resetting env. episode reward total was 10.0. running mean: 5.613224429002172\n",
      "resetting env. episode reward total was -4.0. running mean: 5.51709218471215\n",
      "resetting env. episode reward total was 8.0. running mean: 5.541921262865029\n",
      "resetting env. episode reward total was 2.0. running mean: 5.506502050236378\n",
      "resetting env. episode reward total was 6.0. running mean: 5.511437029734013\n",
      "resetting env. episode reward total was 15.0. running mean: 5.606322659436674\n",
      "resetting env. episode reward total was 12.0. running mean: 5.6702594328423075\n",
      "resetting env. episode reward total was -3.0. running mean: 5.583556838513884\n",
      "resetting env. episode reward total was -8.0. running mean: 5.447721270128745\n",
      "resetting env. episode reward total was 10.0. running mean: 5.493244057427457\n",
      "resetting env. episode reward total was 11.0. running mean: 5.548311616853183\n",
      "resetting env. episode reward total was 3.0. running mean: 5.522828500684651\n",
      "resetting env. episode reward total was 1.0. running mean: 5.477600215677804\n",
      "resetting env. episode reward total was 2.0. running mean: 5.442824213521026\n",
      "resetting env. episode reward total was -3.0. running mean: 5.358395971385815\n",
      "resetting env. episode reward total was 1.0. running mean: 5.314812011671957\n",
      "resetting env. episode reward total was 3.0. running mean: 5.291663891555237\n",
      "resetting env. episode reward total was 5.0. running mean: 5.288747252639685\n",
      "resetting env. episode reward total was 3.0. running mean: 5.2658597801132885\n",
      "resetting env. episode reward total was 12.0. running mean: 5.3332011823121555\n",
      "resetting env. episode reward total was 3.0. running mean: 5.309869170489034\n",
      "resetting env. episode reward total was -13.0. running mean: 5.126770478784144\n",
      "resetting env. episode reward total was 8.0. running mean: 5.155502773996303\n",
      "resetting env. episode reward total was 9.0. running mean: 5.19394774625634\n",
      "resetting env. episode reward total was 6.0. running mean: 5.202008268793776\n",
      "resetting env. episode reward total was 9.0. running mean: 5.239988186105838\n",
      "resetting env. episode reward total was -1.0. running mean: 5.17758830424478\n",
      "resetting env. episode reward total was -1.0. running mean: 5.115812421202332\n",
      "resetting env. episode reward total was 7.0. running mean: 5.134654296990309\n",
      "resetting env. episode reward total was 9.0. running mean: 5.1733077540204055\n",
      "resetting env. episode reward total was 9.0. running mean: 5.211574676480201\n",
      "resetting env. episode reward total was 11.0. running mean: 5.2694589297154\n",
      "resetting env. episode reward total was 7.0. running mean: 5.286764340418246\n",
      "resetting env. episode reward total was 1.0. running mean: 5.243896697014064\n",
      "resetting env. episode reward total was 14.0. running mean: 5.3314577300439225\n",
      "resetting env. episode reward total was 10.0. running mean: 5.378143152743483\n",
      "resetting env. episode reward total was 8.0. running mean: 5.404361721216048\n",
      "resetting env. episode reward total was 9.0. running mean: 5.440318104003888\n",
      "resetting env. episode reward total was -3.0. running mean: 5.355914922963849\n",
      "resetting env. episode reward total was 5.0. running mean: 5.35235577373421\n",
      "resetting env. episode reward total was 12.0. running mean: 5.4188322159968685\n",
      "resetting env. episode reward total was -8.0. running mean: 5.2846438938369\n",
      "resetting env. episode reward total was 5.0. running mean: 5.2817974548985305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 5.308979480349545\n",
      "resetting env. episode reward total was 5.0. running mean: 5.305889685546049\n",
      "resetting env. episode reward total was 11.0. running mean: 5.362830788690589\n",
      "resetting env. episode reward total was 2.0. running mean: 5.329202480803683\n",
      "resetting env. episode reward total was 4.0. running mean: 5.315910455995645\n",
      "resetting env. episode reward total was 10.0. running mean: 5.362751351435689\n",
      "resetting env. episode reward total was 4.0. running mean: 5.349123837921332\n",
      "resetting env. episode reward total was -2.0. running mean: 5.275632599542119\n",
      "resetting env. episode reward total was 13.0. running mean: 5.3528762735466975\n",
      "resetting env. episode reward total was 2.0. running mean: 5.31934751081123\n",
      "resetting env. episode reward total was 2.0. running mean: 5.286154035703118\n",
      "resetting env. episode reward total was 4.0. running mean: 5.2732924953460865\n",
      "resetting env. episode reward total was 4.0. running mean: 5.260559570392625\n",
      "resetting env. episode reward total was 12.0. running mean: 5.3279539746886995\n",
      "resetting env. episode reward total was 6.0. running mean: 5.334674434941812\n",
      "resetting env. episode reward total was 7.0. running mean: 5.351327690592394\n",
      "resetting env. episode reward total was 3.0. running mean: 5.327814413686471\n",
      "resetting env. episode reward total was 3.0. running mean: 5.304536269549606\n",
      "resetting env. episode reward total was -5.0. running mean: 5.201490906854111\n",
      "resetting env. episode reward total was -7.0. running mean: 5.079475997785569\n",
      "resetting env. episode reward total was -1.0. running mean: 5.018681237807714\n",
      "resetting env. episode reward total was 5.0. running mean: 5.018494425429637\n",
      "resetting env. episode reward total was 1.0. running mean: 4.97830948117534\n",
      "resetting env. episode reward total was 10.0. running mean: 5.028526386363586\n",
      "resetting env. episode reward total was 7.0. running mean: 5.048241122499951\n",
      "resetting env. episode reward total was 3.0. running mean: 5.027758711274951\n",
      "resetting env. episode reward total was 12.0. running mean: 5.097481124162202\n",
      "resetting env. episode reward total was 14.0. running mean: 5.186506312920579\n",
      "resetting env. episode reward total was 5.0. running mean: 5.1846412497913725\n",
      "resetting env. episode reward total was -1.0. running mean: 5.122794837293459\n",
      "resetting env. episode reward total was 2.0. running mean: 5.091566888920524\n",
      "resetting env. episode reward total was -3.0. running mean: 5.010651220031319\n",
      "resetting env. episode reward total was 10.0. running mean: 5.0605447078310055\n",
      "resetting env. episode reward total was -5.0. running mean: 4.959939260752695\n",
      "resetting env. episode reward total was 11.0. running mean: 5.020339868145169\n",
      "resetting env. episode reward total was 7.0. running mean: 5.040136469463717\n",
      "resetting env. episode reward total was 2.0. running mean: 5.00973510476908\n",
      "resetting env. episode reward total was 3.0. running mean: 4.989637753721389\n",
      "resetting env. episode reward total was 3.0. running mean: 4.969741376184175\n",
      "resetting env. episode reward total was 3.0. running mean: 4.950043962422334\n",
      "resetting env. episode reward total was 8.0. running mean: 4.9805435227981105\n",
      "resetting env. episode reward total was 9.0. running mean: 5.0207380875701295\n",
      "resetting env. episode reward total was 13.0. running mean: 5.100530706694428\n",
      "resetting env. episode reward total was 8.0. running mean: 5.129525399627484\n",
      "resetting env. episode reward total was 11.0. running mean: 5.188230145631209\n",
      "resetting env. episode reward total was 18.0. running mean: 5.316347844174897\n",
      "resetting env. episode reward total was -2.0. running mean: 5.243184365733148\n",
      "resetting env. episode reward total was 2.0. running mean: 5.210752522075816\n",
      "resetting env. episode reward total was 2.0. running mean: 5.178644996855057\n",
      "resetting env. episode reward total was 5.0. running mean: 5.176858546886507\n",
      "resetting env. episode reward total was 5.0. running mean: 5.175089961417641\n",
      "resetting env. episode reward total was 5.0. running mean: 5.173339061803465\n",
      "resetting env. episode reward total was -11.0. running mean: 5.01160567118543\n",
      "resetting env. episode reward total was -7.0. running mean: 4.891489614473576\n",
      "resetting env. episode reward total was 5.0. running mean: 4.89257471832884\n",
      "resetting env. episode reward total was 1.0. running mean: 4.853648971145551\n",
      "resetting env. episode reward total was -2.0. running mean: 4.785112481434096\n",
      "resetting env. episode reward total was 2.0. running mean: 4.757261356619755\n",
      "resetting env. episode reward total was 8.0. running mean: 4.789688743053557\n",
      "resetting env. episode reward total was 5.0. running mean: 4.791791855623021\n",
      "resetting env. episode reward total was -3.0. running mean: 4.713873937066791\n",
      "resetting env. episode reward total was -7.0. running mean: 4.596735197696122\n",
      "resetting env. episode reward total was 1.0. running mean: 4.560767845719161\n",
      "resetting env. episode reward total was 9.0. running mean: 4.605160167261969\n",
      "resetting env. episode reward total was 8.0. running mean: 4.63910856558935\n",
      "resetting env. episode reward total was 5.0. running mean: 4.642717479933456\n",
      "resetting env. episode reward total was 5.0. running mean: 4.646290305134121\n",
      "resetting env. episode reward total was 8.0. running mean: 4.67982740208278\n",
      "resetting env. episode reward total was 6.0. running mean: 4.693029128061951\n",
      "resetting env. episode reward total was 6.0. running mean: 4.706098836781331\n",
      "resetting env. episode reward total was -1.0. running mean: 4.649037848413518\n",
      "resetting env. episode reward total was 8.0. running mean: 4.682547469929383\n",
      "resetting env. episode reward total was 12.0. running mean: 4.755721995230089\n",
      "resetting env. episode reward total was -7.0. running mean: 4.6381647752777875\n",
      "resetting env. episode reward total was 7.0. running mean: 4.66178312752501\n",
      "resetting env. episode reward total was 15.0. running mean: 4.76516529624976\n",
      "resetting env. episode reward total was 5.0. running mean: 4.767513643287263\n",
      "resetting env. episode reward total was 8.0. running mean: 4.79983850685439\n",
      "resetting env. episode reward total was 15.0. running mean: 4.901840121785846\n",
      "resetting env. episode reward total was 7.0. running mean: 4.922821720567988\n",
      "resetting env. episode reward total was 12.0. running mean: 4.993593503362309\n",
      "resetting env. episode reward total was -8.0. running mean: 4.863657568328685\n",
      "resetting env. episode reward total was -3.0. running mean: 4.785020992645398\n",
      "resetting env. episode reward total was -2.0. running mean: 4.717170782718944\n",
      "resetting env. episode reward total was 1.0. running mean: 4.679999074891755\n",
      "resetting env. episode reward total was -9.0. running mean: 4.543199084142837\n",
      "resetting env. episode reward total was -3.0. running mean: 4.467767093301409\n",
      "resetting env. episode reward total was -3.0. running mean: 4.393089422368394\n",
      "resetting env. episode reward total was 8.0. running mean: 4.42915852814471\n",
      "resetting env. episode reward total was 9.0. running mean: 4.4748669428632635\n",
      "resetting env. episode reward total was 5.0. running mean: 4.4801182734346305\n",
      "resetting env. episode reward total was 9.0. running mean: 4.525317090700284\n",
      "resetting env. episode reward total was 7.0. running mean: 4.550063919793281\n",
      "resetting env. episode reward total was 2.0. running mean: 4.524563280595348\n",
      "resetting env. episode reward total was 5.0. running mean: 4.529317647789394\n",
      "resetting env. episode reward total was 10.0. running mean: 4.5840244713115\n",
      "resetting env. episode reward total was 5.0. running mean: 4.588184226598385\n",
      "resetting env. episode reward total was -5.0. running mean: 4.492302384332402\n",
      "resetting env. episode reward total was 2.0. running mean: 4.467379360489077\n",
      "resetting env. episode reward total was -1.0. running mean: 4.412705566884187\n",
      "resetting env. episode reward total was -3.0. running mean: 4.338578511215345\n",
      "resetting env. episode reward total was -3.0. running mean: 4.265192726103191\n",
      "resetting env. episode reward total was -1.0. running mean: 4.212540798842159\n",
      "resetting env. episode reward total was 12.0. running mean: 4.290415390853738\n",
      "resetting env. episode reward total was 11.0. running mean: 4.357511236945201\n",
      "resetting env. episode reward total was 4.0. running mean: 4.353936124575749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 4.370396763329991\n",
      "resetting env. episode reward total was 5.0. running mean: 4.376692795696691\n",
      "resetting env. episode reward total was 5.0. running mean: 4.382925867739724\n",
      "resetting env. episode reward total was 1.0. running mean: 4.349096609062326\n",
      "resetting env. episode reward total was 14.0. running mean: 4.445605642971703\n",
      "resetting env. episode reward total was 4.0. running mean: 4.441149586541986\n",
      "resetting env. episode reward total was 9.0. running mean: 4.486738090676566\n",
      "resetting env. episode reward total was 9.0. running mean: 4.5318707097698\n",
      "resetting env. episode reward total was 5.0. running mean: 4.536552002672102\n",
      "resetting env. episode reward total was 1.0. running mean: 4.501186482645381\n",
      "resetting env. episode reward total was 3.0. running mean: 4.486174617818928\n",
      "resetting env. episode reward total was 15.0. running mean: 4.5913128716407385\n",
      "resetting env. episode reward total was 1.0. running mean: 4.5553997429243305\n",
      "resetting env. episode reward total was -5.0. running mean: 4.4598457454950875\n",
      "resetting env. episode reward total was -1.0. running mean: 4.405247288040137\n",
      "resetting env. episode reward total was 6.0. running mean: 4.421194815159735\n",
      "resetting env. episode reward total was 6.0. running mean: 4.436982867008138\n",
      "resetting env. episode reward total was 12.0. running mean: 4.512613038338056\n",
      "resetting env. episode reward total was 1.0. running mean: 4.477486907954676\n",
      "resetting env. episode reward total was 4.0. running mean: 4.472712038875129\n",
      "resetting env. episode reward total was 7.0. running mean: 4.497984918486378\n",
      "resetting env. episode reward total was 9.0. running mean: 4.543005069301515\n",
      "resetting env. episode reward total was 8.0. running mean: 4.5775750186085\n",
      "resetting env. episode reward total was 3.0. running mean: 4.561799268422416\n",
      "resetting env. episode reward total was 5.0. running mean: 4.566181275738191\n",
      "resetting env. episode reward total was -14.0. running mean: 4.380519462980809\n",
      "resetting env. episode reward total was -1.0. running mean: 4.326714268351001\n",
      "resetting env. episode reward total was 9.0. running mean: 4.373447125667491\n",
      "resetting env. episode reward total was 5.0. running mean: 4.379712654410816\n",
      "resetting env. episode reward total was -3.0. running mean: 4.305915527866707\n",
      "resetting env. episode reward total was 11.0. running mean: 4.372856372588041\n",
      "resetting env. episode reward total was 9.0. running mean: 4.41912780886216\n",
      "resetting env. episode reward total was 12.0. running mean: 4.494936530773538\n",
      "resetting env. episode reward total was -1.0. running mean: 4.439987165465803\n",
      "resetting env. episode reward total was 1.0. running mean: 4.405587293811145\n",
      "resetting env. episode reward total was -11.0. running mean: 4.251531420873033\n",
      "resetting env. episode reward total was 4.0. running mean: 4.249016106664303\n",
      "resetting env. episode reward total was 3.0. running mean: 4.23652594559766\n",
      "resetting env. episode reward total was 4.0. running mean: 4.234160686141683\n",
      "resetting env. episode reward total was 8.0. running mean: 4.271819079280267\n",
      "resetting env. episode reward total was -1.0. running mean: 4.219100888487464\n",
      "resetting env. episode reward total was 2.0. running mean: 4.196909879602589\n",
      "resetting env. episode reward total was 5.0. running mean: 4.204940780806563\n",
      "resetting env. episode reward total was 11.0. running mean: 4.272891372998497\n",
      "resetting env. episode reward total was 7.0. running mean: 4.300162459268512\n",
      "resetting env. episode reward total was 11.0. running mean: 4.367160834675827\n",
      "resetting env. episode reward total was 8.0. running mean: 4.403489226329069\n",
      "resetting env. episode reward total was 9.0. running mean: 4.449454334065778\n",
      "resetting env. episode reward total was 1.0. running mean: 4.41495979072512\n",
      "resetting env. episode reward total was 10.0. running mean: 4.4708101928178685\n",
      "resetting env. episode reward total was 15.0. running mean: 4.57610209088969\n",
      "resetting env. episode reward total was 7.0. running mean: 4.600341069980794\n",
      "resetting env. episode reward total was -1.0. running mean: 4.544337659280986\n",
      "resetting env. episode reward total was 2.0. running mean: 4.5188942826881755\n",
      "resetting env. episode reward total was 11.0. running mean: 4.583705339861294\n",
      "resetting env. episode reward total was 6.0. running mean: 4.59786828646268\n",
      "resetting env. episode reward total was 3.0. running mean: 4.581889603598054\n",
      "resetting env. episode reward total was 11.0. running mean: 4.646070707562074\n",
      "resetting env. episode reward total was 15.0. running mean: 4.749610000486453\n",
      "resetting env. episode reward total was 10.0. running mean: 4.802113900481588\n",
      "resetting env. episode reward total was 4.0. running mean: 4.794092761476772\n",
      "resetting env. episode reward total was -5.0. running mean: 4.696151833862005\n",
      "resetting env. episode reward total was 7.0. running mean: 4.7191903155233845\n",
      "resetting env. episode reward total was 11.0. running mean: 4.781998412368151\n",
      "resetting env. episode reward total was -6.0. running mean: 4.67417842824447\n",
      "resetting env. episode reward total was 7.0. running mean: 4.697436643962025\n",
      "resetting env. episode reward total was -7.0. running mean: 4.580462277522404\n",
      "resetting env. episode reward total was -3.0. running mean: 4.50465765474718\n",
      "resetting env. episode reward total was 8.0. running mean: 4.539611078199708\n",
      "resetting env. episode reward total was 6.0. running mean: 4.55421496741771\n",
      "resetting env. episode reward total was 11.0. running mean: 4.618672817743533\n",
      "resetting env. episode reward total was 6.0. running mean: 4.632486089566098\n",
      "resetting env. episode reward total was 3.0. running mean: 4.616161228670437\n",
      "resetting env. episode reward total was -3.0. running mean: 4.539999616383732\n",
      "resetting env. episode reward total was -1.0. running mean: 4.484599620219895\n",
      "resetting env. episode reward total was -7.0. running mean: 4.3697536240176955\n",
      "resetting env. episode reward total was 11.0. running mean: 4.436056087777519\n",
      "resetting env. episode reward total was 10.0. running mean: 4.491695526899743\n",
      "resetting env. episode reward total was 3.0. running mean: 4.476778571630746\n",
      "resetting env. episode reward total was 8.0. running mean: 4.5120107859144385\n",
      "resetting env. episode reward total was 13.0. running mean: 4.596890678055294\n",
      "resetting env. episode reward total was 2.0. running mean: 4.57092177127474\n",
      "resetting env. episode reward total was 5.0. running mean: 4.575212553561992\n",
      "resetting env. episode reward total was 9.0. running mean: 4.619460428026372\n",
      "resetting env. episode reward total was 8.0. running mean: 4.653265823746108\n",
      "resetting env. episode reward total was 12.0. running mean: 4.726733165508647\n",
      "resetting env. episode reward total was 8.0. running mean: 4.759465833853561\n",
      "resetting env. episode reward total was 4.0. running mean: 4.751871175515025\n",
      "resetting env. episode reward total was 15.0. running mean: 4.854352463759875\n",
      "resetting env. episode reward total was 12.0. running mean: 4.925808939122277\n",
      "resetting env. episode reward total was 11.0. running mean: 4.986550849731055\n",
      "resetting env. episode reward total was 3.0. running mean: 4.966685341233744\n",
      "resetting env. episode reward total was 6.0. running mean: 4.9770184878214065\n",
      "resetting env. episode reward total was 5.0. running mean: 4.977248302943193\n",
      "resetting env. episode reward total was 2.0. running mean: 4.94747581991376\n",
      "resetting env. episode reward total was 6.0. running mean: 4.958001061714622\n",
      "resetting env. episode reward total was -3.0. running mean: 4.878421051097476\n",
      "resetting env. episode reward total was 7.0. running mean: 4.899636840586502\n",
      "resetting env. episode reward total was 5.0. running mean: 4.900640472180637\n",
      "resetting env. episode reward total was 14.0. running mean: 4.99163406745883\n",
      "resetting env. episode reward total was -1.0. running mean: 4.931717726784242\n",
      "resetting env. episode reward total was 3.0. running mean: 4.912400549516399\n",
      "resetting env. episode reward total was -3.0. running mean: 4.833276544021235\n",
      "resetting env. episode reward total was 13.0. running mean: 4.914943778581022\n",
      "resetting env. episode reward total was 7.0. running mean: 4.935794340795212\n",
      "resetting env. episode reward total was 7.0. running mean: 4.95643639738726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 5.016872033413388\n",
      "resetting env. episode reward total was -2.0. running mean: 4.946703313079254\n",
      "resetting env. episode reward total was 7.0. running mean: 4.967236279948462\n",
      "resetting env. episode reward total was 9.0. running mean: 5.007563917148977\n",
      "resetting env. episode reward total was 10.0. running mean: 5.0574882779774875\n",
      "resetting env. episode reward total was 1.0. running mean: 5.0169133951977125\n",
      "resetting env. episode reward total was 8.0. running mean: 5.046744261245736\n",
      "resetting env. episode reward total was 14.0. running mean: 5.136276818633278\n",
      "resetting env. episode reward total was 15.0. running mean: 5.234914050446946\n",
      "resetting env. episode reward total was 5.0. running mean: 5.232564909942476\n",
      "resetting env. episode reward total was -9.0. running mean: 5.090239260843052\n",
      "resetting env. episode reward total was 10.0. running mean: 5.13933686823462\n",
      "resetting env. episode reward total was 11.0. running mean: 5.197943499552275\n",
      "resetting env. episode reward total was 13.0. running mean: 5.275964064556752\n",
      "resetting env. episode reward total was 7.0. running mean: 5.293204423911185\n",
      "resetting env. episode reward total was 4.0. running mean: 5.2802723796720725\n",
      "resetting env. episode reward total was -2.0. running mean: 5.207469655875352\n",
      "resetting env. episode reward total was -1.0. running mean: 5.145394959316598\n",
      "resetting env. episode reward total was 7.0. running mean: 5.163941009723432\n",
      "resetting env. episode reward total was 10.0. running mean: 5.212301599626198\n",
      "resetting env. episode reward total was 11.0. running mean: 5.270178583629936\n",
      "resetting env. episode reward total was 5.0. running mean: 5.267476797793637\n",
      "resetting env. episode reward total was 9.0. running mean: 5.304802029815701\n",
      "resetting env. episode reward total was -1.0. running mean: 5.2417540095175434\n",
      "resetting env. episode reward total was 16.0. running mean: 5.349336469422368\n",
      "resetting env. episode reward total was -7.0. running mean: 5.225843104728144\n",
      "resetting env. episode reward total was 15.0. running mean: 5.3235846736808625\n",
      "resetting env. episode reward total was -2.0. running mean: 5.250348826944054\n",
      "resetting env. episode reward total was -12.0. running mean: 5.077845338674614\n",
      "resetting env. episode reward total was 7.0. running mean: 5.097066885287868\n",
      "resetting env. episode reward total was 10.0. running mean: 5.146096216434989\n",
      "resetting env. episode reward total was 11.0. running mean: 5.20463525427064\n",
      "resetting env. episode reward total was 3.0. running mean: 5.182588901727933\n",
      "resetting env. episode reward total was 7.0. running mean: 5.200763012710654\n",
      "resetting env. episode reward total was 1.0. running mean: 5.158755382583547\n",
      "resetting env. episode reward total was 7.0. running mean: 5.177167828757712\n",
      "resetting env. episode reward total was 4.0. running mean: 5.165396150470135\n",
      "resetting env. episode reward total was 8.0. running mean: 5.193742188965434\n",
      "resetting env. episode reward total was 11.0. running mean: 5.25180476707578\n",
      "resetting env. episode reward total was 9.0. running mean: 5.2892867194050215\n",
      "resetting env. episode reward total was 3.0. running mean: 5.266393852210972\n",
      "resetting env. episode reward total was 8.0. running mean: 5.293729913688862\n",
      "resetting env. episode reward total was 8.0. running mean: 5.320792614551974\n",
      "resetting env. episode reward total was -9.0. running mean: 5.177584688406454\n",
      "resetting env. episode reward total was 9.0. running mean: 5.2158088415223895\n",
      "resetting env. episode reward total was 9.0. running mean: 5.2536507531071654\n",
      "resetting env. episode reward total was 2.0. running mean: 5.221114245576094\n",
      "resetting env. episode reward total was -3.0. running mean: 5.138903103120333\n",
      "resetting env. episode reward total was 10.0. running mean: 5.187514072089129\n",
      "resetting env. episode reward total was 5.0. running mean: 5.185638931368237\n",
      "resetting env. episode reward total was -2.0. running mean: 5.113782542054555\n",
      "resetting env. episode reward total was 6.0. running mean: 5.122644716634008\n",
      "resetting env. episode reward total was 10.0. running mean: 5.171418269467668\n",
      "resetting env. episode reward total was 3.0. running mean: 5.149704086772991\n",
      "resetting env. episode reward total was 9.0. running mean: 5.188207045905261\n",
      "resetting env. episode reward total was -8.0. running mean: 5.056324975446208\n",
      "resetting env. episode reward total was 2.0. running mean: 5.025761725691746\n",
      "resetting env. episode reward total was 13.0. running mean: 5.105504108434828\n",
      "resetting env. episode reward total was 12.0. running mean: 5.17444906735048\n",
      "resetting env. episode reward total was 14.0. running mean: 5.262704576676975\n",
      "resetting env. episode reward total was 8.0. running mean: 5.290077530910205\n",
      "resetting env. episode reward total was -5.0. running mean: 5.187176755601103\n",
      "resetting env. episode reward total was 12.0. running mean: 5.255304988045092\n",
      "resetting env. episode reward total was 10.0. running mean: 5.30275193816464\n",
      "resetting env. episode reward total was 9.0. running mean: 5.3397244187829935\n",
      "resetting env. episode reward total was 5.0. running mean: 5.336327174595163\n",
      "resetting env. episode reward total was -1.0. running mean: 5.272963902849211\n",
      "resetting env. episode reward total was -3.0. running mean: 5.190234263820718\n",
      "resetting env. episode reward total was 2.0. running mean: 5.158331921182511\n",
      "resetting env. episode reward total was 4.0. running mean: 5.146748601970686\n",
      "resetting env. episode reward total was 8.0. running mean: 5.1752811159509795\n",
      "resetting env. episode reward total was 5.0. running mean: 5.1735283047914695\n",
      "resetting env. episode reward total was 12.0. running mean: 5.241793021743555\n",
      "resetting env. episode reward total was 5.0. running mean: 5.239375091526119\n",
      "resetting env. episode reward total was 4.0. running mean: 5.226981340610858\n",
      "resetting env. episode reward total was 9.0. running mean: 5.264711527204749\n",
      "resetting env. episode reward total was 5.0. running mean: 5.262064411932702\n",
      "resetting env. episode reward total was 6.0. running mean: 5.2694437678133745\n",
      "resetting env. episode reward total was 2.0. running mean: 5.236749330135241\n",
      "resetting env. episode reward total was 8.0. running mean: 5.264381836833889\n",
      "resetting env. episode reward total was 13.0. running mean: 5.341738018465549\n",
      "resetting env. episode reward total was 11.0. running mean: 5.398320638280894\n",
      "resetting env. episode reward total was 9.0. running mean: 5.434337431898085\n",
      "resetting env. episode reward total was 5.0. running mean: 5.429994057579104\n",
      "resetting env. episode reward total was 4.0. running mean: 5.415694117003313\n",
      "resetting env. episode reward total was -1.0. running mean: 5.35153717583328\n",
      "resetting env. episode reward total was 9.0. running mean: 5.388021804074947\n",
      "resetting env. episode reward total was 11.0. running mean: 5.444141586034198\n",
      "resetting env. episode reward total was 12.0. running mean: 5.509700170173856\n",
      "resetting env. episode reward total was 7.0. running mean: 5.524603168472118\n",
      "resetting env. episode reward total was 6.0. running mean: 5.529357136787397\n",
      "resetting env. episode reward total was 9.0. running mean: 5.564063565419523\n",
      "resetting env. episode reward total was -5.0. running mean: 5.4584229297653275\n",
      "resetting env. episode reward total was -2.0. running mean: 5.383838700467675\n",
      "resetting env. episode reward total was 3.0. running mean: 5.360000313462998\n",
      "resetting env. episode reward total was -2.0. running mean: 5.286400310328369\n",
      "resetting env. episode reward total was 13.0. running mean: 5.363536307225085\n",
      "resetting env. episode reward total was -5.0. running mean: 5.259900944152834\n",
      "resetting env. episode reward total was 3.0. running mean: 5.237301934711306\n",
      "resetting env. episode reward total was 6.0. running mean: 5.244928915364192\n",
      "resetting env. episode reward total was 3.0. running mean: 5.222479626210551\n",
      "resetting env. episode reward total was 1.0. running mean: 5.180254829948445\n",
      "resetting env. episode reward total was 4.0. running mean: 5.16845228164896\n",
      "resetting env. episode reward total was 4.0. running mean: 5.156767758832471\n",
      "resetting env. episode reward total was -7.0. running mean: 5.035200081244146\n",
      "resetting env. episode reward total was 8.0. running mean: 5.064848080431704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 5.084199599627388\n",
      "resetting env. episode reward total was 8.0. running mean: 5.113357603631114\n",
      "resetting env. episode reward total was 3.0. running mean: 5.092224027594803\n",
      "resetting env. episode reward total was -1.0. running mean: 5.031301787318855\n",
      "resetting env. episode reward total was 7.0. running mean: 5.0509887694456665\n",
      "resetting env. episode reward total was 2.0. running mean: 5.02047888175121\n",
      "resetting env. episode reward total was 10.0. running mean: 5.070274092933697\n",
      "resetting env. episode reward total was -9.0. running mean: 4.92957135200436\n",
      "resetting env. episode reward total was 6.0. running mean: 4.940275638484316\n",
      "resetting env. episode reward total was -7.0. running mean: 4.820872882099472\n",
      "resetting env. episode reward total was -3.0. running mean: 4.7426641532784775\n",
      "resetting env. episode reward total was 12.0. running mean: 4.815237511745693\n",
      "resetting env. episode reward total was 4.0. running mean: 4.807085136628236\n",
      "resetting env. episode reward total was 8.0. running mean: 4.839014285261953\n",
      "resetting env. episode reward total was 12.0. running mean: 4.9106241424093335\n",
      "resetting env. episode reward total was 6.0. running mean: 4.92151790098524\n",
      "resetting env. episode reward total was 4.0. running mean: 4.912302721975387\n",
      "resetting env. episode reward total was 8.0. running mean: 4.943179694755633\n",
      "resetting env. episode reward total was 3.0. running mean: 4.923747897808077\n",
      "resetting env. episode reward total was 15.0. running mean: 5.024510418829997\n",
      "resetting env. episode reward total was 11.0. running mean: 5.084265314641697\n",
      "resetting env. episode reward total was 9.0. running mean: 5.12342266149528\n",
      "resetting env. episode reward total was 9.0. running mean: 5.162188434880327\n",
      "resetting env. episode reward total was -8.0. running mean: 5.030566550531524\n",
      "resetting env. episode reward total was -8.0. running mean: 4.900260885026208\n",
      "resetting env. episode reward total was 9.0. running mean: 4.941258276175946\n",
      "resetting env. episode reward total was 7.0. running mean: 4.961845693414187\n",
      "resetting env. episode reward total was 7.0. running mean: 4.982227236480045\n",
      "resetting env. episode reward total was 15.0. running mean: 5.082404964115245\n",
      "resetting env. episode reward total was 2.0. running mean: 5.051580914474092\n",
      "resetting env. episode reward total was 9.0. running mean: 5.091065105329351\n",
      "resetting env. episode reward total was -1.0. running mean: 5.030154454276057\n",
      "resetting env. episode reward total was 6.0. running mean: 5.0398529097332965\n",
      "resetting env. episode reward total was 6.0. running mean: 5.049454380635963\n",
      "resetting env. episode reward total was -2.0. running mean: 4.9789598368296035\n",
      "resetting env. episode reward total was 7.0. running mean: 4.999170238461308\n",
      "resetting env. episode reward total was 5.0. running mean: 4.999178536076695\n",
      "resetting env. episode reward total was 2.0. running mean: 4.969186750715927\n",
      "resetting env. episode reward total was 8.0. running mean: 4.999494883208768\n",
      "resetting env. episode reward total was 9.0. running mean: 5.03949993437668\n",
      "resetting env. episode reward total was 4.0. running mean: 5.029104935032914\n",
      "resetting env. episode reward total was 10.0. running mean: 5.078813885682584\n",
      "resetting env. episode reward total was 6.0. running mean: 5.088025746825758\n",
      "resetting env. episode reward total was 11.0. running mean: 5.1471454893575\n",
      "resetting env. episode reward total was 4.0. running mean: 5.135674034463926\n",
      "resetting env. episode reward total was 7.0. running mean: 5.154317294119287\n",
      "resetting env. episode reward total was 2.0. running mean: 5.122774121178094\n",
      "resetting env. episode reward total was 13.0. running mean: 5.201546379966313\n",
      "resetting env. episode reward total was 2.0. running mean: 5.169530916166649\n",
      "resetting env. episode reward total was 2.0. running mean: 5.137835607004982\n",
      "resetting env. episode reward total was 3.0. running mean: 5.116457250934933\n",
      "resetting env. episode reward total was 2.0. running mean: 5.085292678425583\n",
      "resetting env. episode reward total was 6.0. running mean: 5.094439751641327\n",
      "resetting env. episode reward total was 3.0. running mean: 5.073495354124915\n",
      "resetting env. episode reward total was 1.0. running mean: 5.0327604005836655\n",
      "resetting env. episode reward total was 10.0. running mean: 5.082432796577828\n",
      "resetting env. episode reward total was 5.0. running mean: 5.08160846861205\n",
      "resetting env. episode reward total was 11.0. running mean: 5.1407923839259295\n",
      "resetting env. episode reward total was 7.0. running mean: 5.15938446008667\n",
      "resetting env. episode reward total was 5.0. running mean: 5.157790615485803\n",
      "resetting env. episode reward total was -3.0. running mean: 5.076212709330945\n",
      "resetting env. episode reward total was 7.0. running mean: 5.0954505822376355\n",
      "resetting env. episode reward total was 5.0. running mean: 5.0944960764152585\n",
      "resetting env. episode reward total was 11.0. running mean: 5.153551115651106\n",
      "resetting env. episode reward total was 4.0. running mean: 5.142015604494595\n",
      "resetting env. episode reward total was 1.0. running mean: 5.100595448449648\n",
      "resetting env. episode reward total was 3.0. running mean: 5.079589493965152\n",
      "resetting env. episode reward total was 7.0. running mean: 5.098793599025501\n",
      "resetting env. episode reward total was 13.0. running mean: 5.177805663035246\n",
      "resetting env. episode reward total was 4.0. running mean: 5.166027606404893\n",
      "resetting env. episode reward total was 12.0. running mean: 5.234367330340844\n",
      "resetting env. episode reward total was 8.0. running mean: 5.262023657037436\n",
      "resetting env. episode reward total was 7.0. running mean: 5.279403420467062\n",
      "resetting env. episode reward total was -5.0. running mean: 5.176609386262392\n",
      "resetting env. episode reward total was 5.0. running mean: 5.174843292399768\n",
      "resetting env. episode reward total was 11.0. running mean: 5.23309485947577\n",
      "resetting env. episode reward total was 4.0. running mean: 5.220763910881012\n",
      "resetting env. episode reward total was -1.0. running mean: 5.158556271772202\n",
      "resetting env. episode reward total was -9.0. running mean: 5.01697070905448\n",
      "resetting env. episode reward total was -9.0. running mean: 4.876801001963935\n",
      "resetting env. episode reward total was 11.0. running mean: 4.938032991944296\n",
      "resetting env. episode reward total was 7.0. running mean: 4.958652662024853\n",
      "resetting env. episode reward total was 9.0. running mean: 4.999066135404605\n",
      "resetting env. episode reward total was 7.0. running mean: 5.019075474050559\n",
      "resetting env. episode reward total was 11.0. running mean: 5.078884719310054\n",
      "resetting env. episode reward total was 8.0. running mean: 5.108095872116953\n",
      "resetting env. episode reward total was 2.0. running mean: 5.077014913395783\n",
      "resetting env. episode reward total was 11.0. running mean: 5.136244764261826\n",
      "resetting env. episode reward total was 3.0. running mean: 5.114882316619208\n",
      "resetting env. episode reward total was 3.0. running mean: 5.093733493453016\n",
      "resetting env. episode reward total was 8.0. running mean: 5.122796158518486\n",
      "resetting env. episode reward total was 11.0. running mean: 5.181568196933301\n",
      "resetting env. episode reward total was 5.0. running mean: 5.179752514963968\n",
      "resetting env. episode reward total was 4.0. running mean: 5.167954989814328\n",
      "resetting env. episode reward total was 9.0. running mean: 5.206275439916185\n",
      "resetting env. episode reward total was -3.0. running mean: 5.124212685517023\n",
      "resetting env. episode reward total was 2.0. running mean: 5.092970558661852\n",
      "resetting env. episode reward total was -9.0. running mean: 4.952040853075234\n",
      "resetting env. episode reward total was 14.0. running mean: 5.042520444544481\n",
      "resetting env. episode reward total was 7.0. running mean: 5.062095240099036\n",
      "resetting env. episode reward total was 17.0. running mean: 5.1814742876980455\n",
      "resetting env. episode reward total was -4.0. running mean: 5.089659544821065\n",
      "resetting env. episode reward total was 9.0. running mean: 5.128762949372854\n",
      "resetting env. episode reward total was 6.0. running mean: 5.137475319879125\n",
      "resetting env. episode reward total was -1.0. running mean: 5.076100566680334\n",
      "resetting env. episode reward total was 3.0. running mean: 5.055339561013531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 5.044786165403395\n",
      "resetting env. episode reward total was 1.0. running mean: 5.004338303749361\n",
      "resetting env. episode reward total was -5.0. running mean: 4.904294920711868\n",
      "resetting env. episode reward total was 3.0. running mean: 4.885251971504749\n",
      "resetting env. episode reward total was 7.0. running mean: 4.906399451789702\n",
      "resetting env. episode reward total was 6.0. running mean: 4.917335457271805\n",
      "resetting env. episode reward total was -1.0. running mean: 4.858162102699087\n",
      "resetting env. episode reward total was 8.0. running mean: 4.889580481672096\n",
      "resetting env. episode reward total was 5.0. running mean: 4.890684676855375\n",
      "resetting env. episode reward total was 8.0. running mean: 4.921777830086821\n",
      "resetting env. episode reward total was 2.0. running mean: 4.892560051785953\n",
      "resetting env. episode reward total was 17.0. running mean: 5.013634451268093\n",
      "resetting env. episode reward total was 7.0. running mean: 5.033498106755412\n",
      "resetting env. episode reward total was 2.0. running mean: 5.003163125687858\n",
      "resetting env. episode reward total was -2.0. running mean: 4.93313149443098\n",
      "resetting env. episode reward total was 8.0. running mean: 4.96380017948667\n",
      "resetting env. episode reward total was 2.0. running mean: 4.934162177691803\n",
      "resetting env. episode reward total was 7.0. running mean: 4.9548205559148855\n",
      "resetting env. episode reward total was -1.0. running mean: 4.895272350355737\n",
      "resetting env. episode reward total was 11.0. running mean: 4.95631962685218\n",
      "resetting env. episode reward total was -2.0. running mean: 4.886756430583659\n",
      "resetting env. episode reward total was 16.0. running mean: 4.9978888662778225\n",
      "resetting env. episode reward total was 3.0. running mean: 4.977909977615044\n",
      "resetting env. episode reward total was 10.0. running mean: 5.028130877838893\n",
      "resetting env. episode reward total was 2.0. running mean: 4.997849569060504\n",
      "resetting env. episode reward total was 7.0. running mean: 5.017871073369899\n",
      "resetting env. episode reward total was 6.0. running mean: 5.027692362636199\n",
      "resetting env. episode reward total was 5.0. running mean: 5.027415439009837\n",
      "resetting env. episode reward total was -3.0. running mean: 4.947141284619738\n",
      "resetting env. episode reward total was 5.0. running mean: 4.94766987177354\n",
      "resetting env. episode reward total was 8.0. running mean: 4.978193173055804\n",
      "resetting env. episode reward total was 9.0. running mean: 5.018411241325246\n",
      "resetting env. episode reward total was 11.0. running mean: 5.078227128911994\n",
      "resetting env. episode reward total was 12.0. running mean: 5.147444857622874\n",
      "resetting env. episode reward total was 7.0. running mean: 5.165970409046646\n",
      "resetting env. episode reward total was 14.0. running mean: 5.254310704956179\n",
      "resetting env. episode reward total was 1.0. running mean: 5.211767597906617\n",
      "resetting env. episode reward total was 5.0. running mean: 5.20964992192755\n",
      "resetting env. episode reward total was 6.0. running mean: 5.217553422708274\n",
      "resetting env. episode reward total was 1.0. running mean: 5.175377888481191\n",
      "resetting env. episode reward total was 12.0. running mean: 5.243624109596379\n",
      "resetting env. episode reward total was 11.0. running mean: 5.301187868500415\n",
      "resetting env. episode reward total was 5.0. running mean: 5.298175989815411\n",
      "resetting env. episode reward total was 3.0. running mean: 5.275194229917257\n",
      "resetting env. episode reward total was 2.0. running mean: 5.242442287618084\n",
      "resetting env. episode reward total was -2.0. running mean: 5.1700178647419035\n",
      "resetting env. episode reward total was 8.0. running mean: 5.198317686094485\n",
      "resetting env. episode reward total was -4.0. running mean: 5.106334509233539\n",
      "resetting env. episode reward total was 5.0. running mean: 5.105271164141204\n",
      "resetting env. episode reward total was -11.0. running mean: 4.944218452499792\n",
      "resetting env. episode reward total was 9.0. running mean: 4.984776267974794\n",
      "resetting env. episode reward total was 8.0. running mean: 5.014928505295046\n",
      "resetting env. episode reward total was 4.0. running mean: 5.004779220242096\n",
      "resetting env. episode reward total was 12.0. running mean: 5.074731428039675\n",
      "resetting env. episode reward total was 14.0. running mean: 5.163984113759278\n",
      "resetting env. episode reward total was 1.0. running mean: 5.122344272621684\n",
      "resetting env. episode reward total was 3.0. running mean: 5.101120829895468\n",
      "resetting env. episode reward total was 11.0. running mean: 5.160109621596513\n",
      "resetting env. episode reward total was -1.0. running mean: 5.098508525380549\n",
      "resetting env. episode reward total was 10.0. running mean: 5.147523440126743\n",
      "resetting env. episode reward total was 10.0. running mean: 5.196048205725475\n",
      "resetting env. episode reward total was 4.0. running mean: 5.18408772366822\n",
      "resetting env. episode reward total was 2.0. running mean: 5.152246846431538\n",
      "resetting env. episode reward total was 12.0. running mean: 5.2207243779672226\n",
      "resetting env. episode reward total was 9.0. running mean: 5.25851713418755\n",
      "resetting env. episode reward total was 15.0. running mean: 5.355931962845675\n",
      "resetting env. episode reward total was 3.0. running mean: 5.3323726432172185\n",
      "resetting env. episode reward total was 11.0. running mean: 5.389048916785047\n",
      "resetting env. episode reward total was 2.0. running mean: 5.355158427617196\n",
      "resetting env. episode reward total was 7.0. running mean: 5.3716068433410245\n",
      "resetting env. episode reward total was 16.0. running mean: 5.477890774907614\n",
      "resetting env. episode reward total was 6.0. running mean: 5.483111867158537\n",
      "resetting env. episode reward total was 5.0. running mean: 5.478280748486951\n",
      "resetting env. episode reward total was 7.0. running mean: 5.493497941002082\n",
      "resetting env. episode reward total was 6.0. running mean: 5.498562961592061\n",
      "resetting env. episode reward total was 6.0. running mean: 5.50357733197614\n",
      "resetting env. episode reward total was 8.0. running mean: 5.528541558656379\n",
      "resetting env. episode reward total was 11.0. running mean: 5.583256143069815\n",
      "resetting env. episode reward total was -6.0. running mean: 5.4674235816391175\n",
      "resetting env. episode reward total was 16.0. running mean: 5.572749345822726\n",
      "resetting env. episode reward total was 11.0. running mean: 5.627021852364499\n",
      "resetting env. episode reward total was 10.0. running mean: 5.670751633840854\n",
      "resetting env. episode reward total was 16.0. running mean: 5.774044117502445\n",
      "resetting env. episode reward total was 2.0. running mean: 5.73630367632742\n",
      "resetting env. episode reward total was 3.0. running mean: 5.708940639564147\n",
      "resetting env. episode reward total was 17.0. running mean: 5.8218512331685055\n",
      "resetting env. episode reward total was 8.0. running mean: 5.843632720836821\n",
      "resetting env. episode reward total was 9.0. running mean: 5.875196393628452\n",
      "resetting env. episode reward total was 9.0. running mean: 5.906444429692168\n",
      "resetting env. episode reward total was 12.0. running mean: 5.967379985395246\n",
      "resetting env. episode reward total was 12.0. running mean: 6.027706185541293\n",
      "resetting env. episode reward total was -2.0. running mean: 5.94742912368588\n",
      "resetting env. episode reward total was 11.0. running mean: 5.997954832449022\n",
      "resetting env. episode reward total was 2.0. running mean: 5.957975284124531\n",
      "resetting env. episode reward total was 1.0. running mean: 5.908395531283285\n",
      "resetting env. episode reward total was 5.0. running mean: 5.899311575970453\n",
      "resetting env. episode reward total was -1.0. running mean: 5.830318460210748\n",
      "resetting env. episode reward total was 4.0. running mean: 5.8120152756086405\n",
      "resetting env. episode reward total was 8.0. running mean: 5.833895122852554\n",
      "resetting env. episode reward total was 7.0. running mean: 5.845556171624029\n",
      "resetting env. episode reward total was 5.0. running mean: 5.837100609907789\n",
      "resetting env. episode reward total was 2.0. running mean: 5.79872960380871\n",
      "resetting env. episode reward total was -3.0. running mean: 5.710742307770623\n",
      "resetting env. episode reward total was -5.0. running mean: 5.603634884692917\n",
      "resetting env. episode reward total was 10.0. running mean: 5.6475985358459875\n",
      "resetting env. episode reward total was 3.0. running mean: 5.621122550487528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 5.6149113249826526\n",
      "resetting env. episode reward total was 5.0. running mean: 5.6087622117328255\n",
      "resetting env. episode reward total was -9.0. running mean: 5.462674589615498\n",
      "resetting env. episode reward total was -6.0. running mean: 5.348047843719343\n",
      "resetting env. episode reward total was 7.0. running mean: 5.3645673652821495\n",
      "resetting env. episode reward total was 2.0. running mean: 5.330921691629327\n",
      "resetting env. episode reward total was 9.0. running mean: 5.367612474713034\n",
      "resetting env. episode reward total was 1.0. running mean: 5.323936349965903\n",
      "resetting env. episode reward total was 11.0. running mean: 5.380696986466244\n",
      "resetting env. episode reward total was 6.0. running mean: 5.386890016601582\n",
      "resetting env. episode reward total was 6.0. running mean: 5.393021116435565\n",
      "resetting env. episode reward total was 6.0. running mean: 5.399090905271209\n",
      "resetting env. episode reward total was 13.0. running mean: 5.475099996218497\n",
      "resetting env. episode reward total was 6.0. running mean: 5.4803489962563114\n",
      "resetting env. episode reward total was 12.0. running mean: 5.545545506293748\n",
      "resetting env. episode reward total was 1.0. running mean: 5.50009005123081\n",
      "resetting env. episode reward total was 17.0. running mean: 5.615089150718502\n",
      "resetting env. episode reward total was 5.0. running mean: 5.608938259211317\n",
      "resetting env. episode reward total was -7.0. running mean: 5.482848876619203\n",
      "resetting env. episode reward total was 2.0. running mean: 5.44802038785301\n",
      "resetting env. episode reward total was 12.0. running mean: 5.51354018397448\n",
      "resetting env. episode reward total was 8.0. running mean: 5.5384047821347355\n",
      "resetting env. episode reward total was 6.0. running mean: 5.543020734313388\n",
      "resetting env. episode reward total was -2.0. running mean: 5.4675905269702545\n",
      "resetting env. episode reward total was 7.0. running mean: 5.482914621700552\n",
      "resetting env. episode reward total was 7.0. running mean: 5.498085475483547\n",
      "resetting env. episode reward total was 6.0. running mean: 5.5031046207287115\n",
      "resetting env. episode reward total was 11.0. running mean: 5.5580735745214245\n",
      "resetting env. episode reward total was 3.0. running mean: 5.532492838776211\n",
      "resetting env. episode reward total was 4.0. running mean: 5.517167910388449\n",
      "resetting env. episode reward total was 1.0. running mean: 5.471996231284564\n",
      "resetting env. episode reward total was 11.0. running mean: 5.527276268971718\n",
      "resetting env. episode reward total was 4.0. running mean: 5.512003506282001\n",
      "resetting env. episode reward total was 7.0. running mean: 5.526883471219182\n",
      "resetting env. episode reward total was 4.0. running mean: 5.51161463650699\n",
      "resetting env. episode reward total was -1.0. running mean: 5.44649849014192\n",
      "resetting env. episode reward total was 6.0. running mean: 5.4520335052405\n",
      "resetting env. episode reward total was -6.0. running mean: 5.337513170188096\n",
      "resetting env. episode reward total was 1.0. running mean: 5.2941380384862144\n",
      "resetting env. episode reward total was 13.0. running mean: 5.371196658101352\n",
      "resetting env. episode reward total was 10.0. running mean: 5.417484691520339\n",
      "resetting env. episode reward total was 6.0. running mean: 5.423309844605135\n",
      "resetting env. episode reward total was 6.0. running mean: 5.429076746159083\n",
      "resetting env. episode reward total was -3.0. running mean: 5.344785978697492\n",
      "resetting env. episode reward total was 6.0. running mean: 5.351338118910516\n",
      "resetting env. episode reward total was -1.0. running mean: 5.287824737721412\n",
      "resetting env. episode reward total was 11.0. running mean: 5.344946490344197\n",
      "resetting env. episode reward total was 14.0. running mean: 5.4314970254407555\n",
      "resetting env. episode reward total was -5.0. running mean: 5.3271820551863485\n",
      "resetting env. episode reward total was 5.0. running mean: 5.323910234634485\n",
      "resetting env. episode reward total was 5.0. running mean: 5.3206711322881395\n",
      "resetting env. episode reward total was 9.0. running mean: 5.3574644209652575\n",
      "resetting env. episode reward total was -4.0. running mean: 5.2638897767556045\n",
      "resetting env. episode reward total was -3.0. running mean: 5.181250878988048\n",
      "resetting env. episode reward total was 4.0. running mean: 5.169438370198168\n",
      "resetting env. episode reward total was -5.0. running mean: 5.067743986496186\n",
      "resetting env. episode reward total was 10.0. running mean: 5.117066546631224\n",
      "resetting env. episode reward total was 7.0. running mean: 5.135895881164912\n",
      "resetting env. episode reward total was 7.0. running mean: 5.154536922353263\n",
      "resetting env. episode reward total was 13.0. running mean: 5.232991553129731\n",
      "resetting env. episode reward total was 12.0. running mean: 5.3006616375984335\n",
      "resetting env. episode reward total was 7.0. running mean: 5.317655021222449\n",
      "resetting env. episode reward total was 11.0. running mean: 5.3744784710102245\n",
      "resetting env. episode reward total was 3.0. running mean: 5.3507336863001225\n",
      "resetting env. episode reward total was 7.0. running mean: 5.3672263494371215\n",
      "resetting env. episode reward total was 8.0. running mean: 5.393554085942751\n",
      "resetting env. episode reward total was 8.0. running mean: 5.419618545083323\n",
      "resetting env. episode reward total was -3.0. running mean: 5.3354223596324895\n",
      "resetting env. episode reward total was 7.0. running mean: 5.352068136036165\n",
      "resetting env. episode reward total was 7.0. running mean: 5.368547454675803\n",
      "resetting env. episode reward total was 7.0. running mean: 5.384861980129045\n",
      "resetting env. episode reward total was 3.0. running mean: 5.361013360327755\n",
      "resetting env. episode reward total was 2.0. running mean: 5.327403226724477\n",
      "resetting env. episode reward total was 9.0. running mean: 5.364129194457232\n",
      "resetting env. episode reward total was 14.0. running mean: 5.450487902512659\n",
      "resetting env. episode reward total was 10.0. running mean: 5.495983023487532\n",
      "resetting env. episode reward total was 1.0. running mean: 5.451023193252656\n",
      "resetting env. episode reward total was 15.0. running mean: 5.546512961320129\n",
      "resetting env. episode reward total was -9.0. running mean: 5.401047831706928\n",
      "resetting env. episode reward total was 6.0. running mean: 5.407037353389859\n",
      "resetting env. episode reward total was 10.0. running mean: 5.45296697985596\n",
      "resetting env. episode reward total was 6.0. running mean: 5.4584373100574\n",
      "resetting env. episode reward total was 6.0. running mean: 5.463852936956826\n",
      "resetting env. episode reward total was 6.0. running mean: 5.469214407587257\n",
      "resetting env. episode reward total was 9.0. running mean: 5.504522263511385\n",
      "resetting env. episode reward total was 13.0. running mean: 5.579477040876271\n",
      "resetting env. episode reward total was 12.0. running mean: 5.643682270467508\n",
      "resetting env. episode reward total was 14.0. running mean: 5.727245447762833\n",
      "resetting env. episode reward total was 9.0. running mean: 5.759972993285205\n",
      "resetting env. episode reward total was -2.0. running mean: 5.682373263352353\n",
      "resetting env. episode reward total was 3.0. running mean: 5.65554953071883\n",
      "resetting env. episode reward total was 10.0. running mean: 5.6989940354116415\n",
      "resetting env. episode reward total was 2.0. running mean: 5.662004095057525\n",
      "resetting env. episode reward total was 2.0. running mean: 5.6253840541069495\n",
      "resetting env. episode reward total was 3.0. running mean: 5.59913021356588\n",
      "resetting env. episode reward total was 6.0. running mean: 5.603138911430221\n",
      "resetting env. episode reward total was 3.0. running mean: 5.577107522315918\n",
      "resetting env. episode reward total was 7.0. running mean: 5.591336447092759\n",
      "resetting env. episode reward total was 2.0. running mean: 5.555423082621831\n",
      "resetting env. episode reward total was -1.0. running mean: 5.489868851795613\n",
      "resetting env. episode reward total was 7.0. running mean: 5.504970163277657\n",
      "resetting env. episode reward total was 7.0. running mean: 5.519920461644881\n",
      "resetting env. episode reward total was 4.0. running mean: 5.504721257028432\n",
      "resetting env. episode reward total was 6.0. running mean: 5.509674044458148\n",
      "resetting env. episode reward total was 2.0. running mean: 5.4745773040135655\n",
      "resetting env. episode reward total was 4.0. running mean: 5.45983153097343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 5.445233215663696\n",
      "resetting env. episode reward total was -9.0. running mean: 5.300780883507059\n",
      "resetting env. episode reward total was 8.0. running mean: 5.327773074671988\n",
      "resetting env. episode reward total was 4.0. running mean: 5.314495343925269\n",
      "resetting env. episode reward total was 1.0. running mean: 5.271350390486016\n",
      "resetting env. episode reward total was 9.0. running mean: 5.308636886581156\n",
      "resetting env. episode reward total was -6.0. running mean: 5.195550517715345\n",
      "resetting env. episode reward total was 8.0. running mean: 5.223595012538191\n",
      "resetting env. episode reward total was -5.0. running mean: 5.121359062412809\n",
      "resetting env. episode reward total was -3.0. running mean: 5.040145471788681\n",
      "resetting env. episode reward total was 9.0. running mean: 5.0797440170707935\n",
      "resetting env. episode reward total was 8.0. running mean: 5.1089465769000855\n",
      "resetting env. episode reward total was -1.0. running mean: 5.047857111131084\n",
      "resetting env. episode reward total was 4.0. running mean: 5.037378540019773\n",
      "resetting env. episode reward total was 9.0. running mean: 5.077004754619575\n",
      "resetting env. episode reward total was 8.0. running mean: 5.10623470707338\n",
      "resetting env. episode reward total was 9.0. running mean: 5.145172360002646\n",
      "resetting env. episode reward total was 7.0. running mean: 5.16372063640262\n",
      "resetting env. episode reward total was 6.0. running mean: 5.172083430038593\n",
      "resetting env. episode reward total was 9.0. running mean: 5.210362595738207\n",
      "resetting env. episode reward total was 4.0. running mean: 5.1982589697808255\n",
      "resetting env. episode reward total was 3.0. running mean: 5.176276380083017\n",
      "resetting env. episode reward total was 7.0. running mean: 5.194513616282188\n",
      "resetting env. episode reward total was 7.0. running mean: 5.212568480119366\n",
      "resetting env. episode reward total was 5.0. running mean: 5.210442795318172\n",
      "resetting env. episode reward total was 5.0. running mean: 5.2083383673649895\n",
      "resetting env. episode reward total was 9.0. running mean: 5.2462549836913395\n",
      "resetting env. episode reward total was 9.0. running mean: 5.283792433854426\n",
      "resetting env. episode reward total was 8.0. running mean: 5.310954509515882\n",
      "resetting env. episode reward total was 7.0. running mean: 5.327844964420723\n",
      "resetting env. episode reward total was 1.0. running mean: 5.2845665147765155\n",
      "resetting env. episode reward total was 12.0. running mean: 5.351720849628751\n",
      "resetting env. episode reward total was 9.0. running mean: 5.388203641132463\n",
      "resetting env. episode reward total was -3.0. running mean: 5.304321604721139\n",
      "resetting env. episode reward total was 14.0. running mean: 5.391278388673927\n",
      "resetting env. episode reward total was -1.0. running mean: 5.327365604787188\n",
      "resetting env. episode reward total was 7.0. running mean: 5.344091948739316\n",
      "resetting env. episode reward total was -8.0. running mean: 5.210651029251923\n",
      "resetting env. episode reward total was -7.0. running mean: 5.088544518959403\n",
      "resetting env. episode reward total was 8.0. running mean: 5.1176590737698096\n",
      "resetting env. episode reward total was 2.0. running mean: 5.086482483032111\n",
      "resetting env. episode reward total was 11.0. running mean: 5.1456176582017905\n",
      "resetting env. episode reward total was 7.0. running mean: 5.1641614816197725\n",
      "resetting env. episode reward total was 7.0. running mean: 5.182519866803575\n",
      "resetting env. episode reward total was 15.0. running mean: 5.280694668135539\n",
      "resetting env. episode reward total was 5.0. running mean: 5.277887721454183\n",
      "resetting env. episode reward total was 6.0. running mean: 5.285108844239641\n",
      "resetting env. episode reward total was 11.0. running mean: 5.342257755797245\n",
      "resetting env. episode reward total was -6.0. running mean: 5.228835178239273\n",
      "resetting env. episode reward total was 8.0. running mean: 5.256546826456881\n",
      "resetting env. episode reward total was 7.0. running mean: 5.273981358192312\n",
      "resetting env. episode reward total was 16.0. running mean: 5.381241544610389\n",
      "resetting env. episode reward total was -5.0. running mean: 5.277429129164285\n",
      "resetting env. episode reward total was 12.0. running mean: 5.344654837872643\n",
      "resetting env. episode reward total was 10.0. running mean: 5.391208289493916\n",
      "resetting env. episode reward total was 6.0. running mean: 5.397296206598976\n",
      "resetting env. episode reward total was 6.0. running mean: 5.403323244532986\n",
      "resetting env. episode reward total was -3.0. running mean: 5.319290012087656\n",
      "resetting env. episode reward total was 5.0. running mean: 5.316097111966779\n",
      "resetting env. episode reward total was 12.0. running mean: 5.382936140847112\n",
      "resetting env. episode reward total was 9.0. running mean: 5.41910677943864\n",
      "resetting env. episode reward total was -11.0. running mean: 5.254915711644253\n",
      "resetting env. episode reward total was -3.0. running mean: 5.172366554527811\n",
      "resetting env. episode reward total was 10.0. running mean: 5.220642888982532\n",
      "resetting env. episode reward total was 10.0. running mean: 5.2684364600927065\n",
      "resetting env. episode reward total was 1.0. running mean: 5.225752095491779\n",
      "resetting env. episode reward total was 20.0. running mean: 5.373494574536862\n",
      "resetting env. episode reward total was 13.0. running mean: 5.449759628791493\n",
      "resetting env. episode reward total was 7.0. running mean: 5.465262032503579\n",
      "resetting env. episode reward total was 2.0. running mean: 5.430609412178542\n",
      "resetting env. episode reward total was 9.0. running mean: 5.466303318056757\n",
      "resetting env. episode reward total was 3.0. running mean: 5.44164028487619\n",
      "resetting env. episode reward total was 3.0. running mean: 5.417223882027428\n",
      "resetting env. episode reward total was 6.0. running mean: 5.423051643207153\n",
      "resetting env. episode reward total was 5.0. running mean: 5.418821126775081\n",
      "resetting env. episode reward total was 9.0. running mean: 5.4546329155073305\n",
      "resetting env. episode reward total was -4.0. running mean: 5.360086586352257\n",
      "resetting env. episode reward total was -1.0. running mean: 5.296485720488735\n",
      "resetting env. episode reward total was 3.0. running mean: 5.2735208632838475\n",
      "resetting env. episode reward total was 3.0. running mean: 5.250785654651009\n",
      "resetting env. episode reward total was -1.0. running mean: 5.188277798104499\n",
      "resetting env. episode reward total was 11.0. running mean: 5.246395020123455\n",
      "resetting env. episode reward total was 2.0. running mean: 5.21393106992222\n",
      "resetting env. episode reward total was 4.0. running mean: 5.201791759222997\n",
      "resetting env. episode reward total was 12.0. running mean: 5.269773841630768\n",
      "resetting env. episode reward total was 2.0. running mean: 5.237076103214459\n",
      "resetting env. episode reward total was -2.0. running mean: 5.164705342182315\n",
      "resetting env. episode reward total was 11.0. running mean: 5.223058288760492\n",
      "resetting env. episode reward total was -3.0. running mean: 5.140827705872887\n",
      "resetting env. episode reward total was 3.0. running mean: 5.119419428814158\n",
      "resetting env. episode reward total was 9.0. running mean: 5.158225234526016\n",
      "resetting env. episode reward total was 8.0. running mean: 5.186642982180756\n",
      "resetting env. episode reward total was 12.0. running mean: 5.2547765523589485\n",
      "resetting env. episode reward total was 16.0. running mean: 5.362228786835359\n",
      "resetting env. episode reward total was 7.0. running mean: 5.378606498967005\n",
      "resetting env. episode reward total was 12.0. running mean: 5.444820433977335\n",
      "resetting env. episode reward total was 3.0. running mean: 5.420372229637562\n",
      "resetting env. episode reward total was 9.0. running mean: 5.456168507341186\n",
      "resetting env. episode reward total was 11.0. running mean: 5.511606822267774\n",
      "resetting env. episode reward total was 10.0. running mean: 5.556490754045096\n",
      "resetting env. episode reward total was 6.0. running mean: 5.560925846504644\n",
      "resetting env. episode reward total was 1.0. running mean: 5.515316588039598\n",
      "resetting env. episode reward total was 8.0. running mean: 5.5401634221592015\n",
      "resetting env. episode reward total was 16.0. running mean: 5.644761787937609\n",
      "resetting env. episode reward total was 6.0. running mean: 5.648314170058232\n",
      "resetting env. episode reward total was -3.0. running mean: 5.56183102835765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 5.5962127180740735\n",
      "resetting env. episode reward total was 4.0. running mean: 5.580250590893333\n",
      "resetting env. episode reward total was 2.0. running mean: 5.544448084984399\n",
      "resetting env. episode reward total was 15.0. running mean: 5.6390036041345555\n",
      "resetting env. episode reward total was 10.0. running mean: 5.68261356809321\n",
      "resetting env. episode reward total was 8.0. running mean: 5.7057874324122775\n",
      "resetting env. episode reward total was -2.0. running mean: 5.628729558088155\n",
      "resetting env. episode reward total was 5.0. running mean: 5.622442262507273\n",
      "resetting env. episode reward total was 11.0. running mean: 5.6762178398822005\n",
      "resetting env. episode reward total was 9.0. running mean: 5.7094556614833785\n",
      "resetting env. episode reward total was 12.0. running mean: 5.772361104868545\n",
      "resetting env. episode reward total was 2.0. running mean: 5.734637493819859\n",
      "resetting env. episode reward total was 4.0. running mean: 5.71729111888166\n",
      "resetting env. episode reward total was 11.0. running mean: 5.770118207692844\n",
      "resetting env. episode reward total was 1.0. running mean: 5.722417025615916\n",
      "resetting env. episode reward total was 8.0. running mean: 5.745192855359757\n",
      "resetting env. episode reward total was 5.0. running mean: 5.7377409268061585\n",
      "resetting env. episode reward total was 2.0. running mean: 5.700363517538096\n",
      "resetting env. episode reward total was 5.0. running mean: 5.693359882362715\n",
      "resetting env. episode reward total was -4.0. running mean: 5.596426283539088\n",
      "resetting env. episode reward total was 9.0. running mean: 5.630462020703697\n",
      "resetting env. episode reward total was -3.0. running mean: 5.54415740049666\n",
      "resetting env. episode reward total was 6.0. running mean: 5.548715826491693\n",
      "resetting env. episode reward total was 9.0. running mean: 5.583228668226776\n",
      "resetting env. episode reward total was 11.0. running mean: 5.637396381544509\n",
      "resetting env. episode reward total was 7.0. running mean: 5.651022417729064\n",
      "resetting env. episode reward total was 2.0. running mean: 5.614512193551773\n",
      "resetting env. episode reward total was 4.0. running mean: 5.598367071616256\n",
      "resetting env. episode reward total was 6.0. running mean: 5.602383400900092\n",
      "resetting env. episode reward total was 14.0. running mean: 5.686359566891091\n",
      "resetting env. episode reward total was 5.0. running mean: 5.67949597122218\n",
      "resetting env. episode reward total was 10.0. running mean: 5.722701011509958\n",
      "resetting env. episode reward total was 7.0. running mean: 5.735474001394858\n",
      "resetting env. episode reward total was 1.0. running mean: 5.688119261380909\n",
      "resetting env. episode reward total was 7.0. running mean: 5.7012380687671005\n",
      "resetting env. episode reward total was 2.0. running mean: 5.664225688079429\n",
      "resetting env. episode reward total was 6.0. running mean: 5.667583431198635\n",
      "resetting env. episode reward total was 7.0. running mean: 5.680907596886649\n",
      "resetting env. episode reward total was -13.0. running mean: 5.494098520917783\n",
      "resetting env. episode reward total was 3.0. running mean: 5.4691575357086055\n",
      "resetting env. episode reward total was -4.0. running mean: 5.374465960351519\n",
      "resetting env. episode reward total was 8.0. running mean: 5.400721300748004\n",
      "resetting env. episode reward total was 12.0. running mean: 5.466714087740524\n",
      "resetting env. episode reward total was 10.0. running mean: 5.512046946863118\n",
      "resetting env. episode reward total was 14.0. running mean: 5.5969264773944865\n",
      "resetting env. episode reward total was 4.0. running mean: 5.580957212620541\n",
      "resetting env. episode reward total was 5.0. running mean: 5.575147640494336\n",
      "resetting env. episode reward total was -8.0. running mean: 5.439396164089392\n",
      "resetting env. episode reward total was -1.0. running mean: 5.375002202448498\n",
      "resetting env. episode reward total was 12.0. running mean: 5.441252180424013\n",
      "resetting env. episode reward total was 9.0. running mean: 5.476839658619773\n",
      "resetting env. episode reward total was 11.0. running mean: 5.5320712620335755\n",
      "resetting env. episode reward total was 10.0. running mean: 5.576750549413239\n",
      "resetting env. episode reward total was 7.0. running mean: 5.590983043919107\n",
      "resetting env. episode reward total was 11.0. running mean: 5.645073213479916\n",
      "resetting env. episode reward total was 8.0. running mean: 5.668622481345118\n",
      "resetting env. episode reward total was 14.0. running mean: 5.751936256531666\n",
      "resetting env. episode reward total was 3.0. running mean: 5.72441689396635\n",
      "resetting env. episode reward total was 10.0. running mean: 5.767172725026685\n",
      "resetting env. episode reward total was 6.0. running mean: 5.769500997776418\n",
      "resetting env. episode reward total was 12.0. running mean: 5.831805987798654\n",
      "resetting env. episode reward total was 4.0. running mean: 5.813487927920667\n",
      "resetting env. episode reward total was 4.0. running mean: 5.79535304864146\n",
      "resetting env. episode reward total was 6.0. running mean: 5.7973995181550455\n",
      "resetting env. episode reward total was 10.0. running mean: 5.839425522973495\n",
      "resetting env. episode reward total was 10.0. running mean: 5.88103126774376\n",
      "resetting env. episode reward total was 2.0. running mean: 5.842220955066321\n",
      "resetting env. episode reward total was 8.0. running mean: 5.863798745515658\n",
      "resetting env. episode reward total was 7.0. running mean: 5.875160758060502\n",
      "resetting env. episode reward total was 9.0. running mean: 5.906409150479896\n",
      "resetting env. episode reward total was 9.0. running mean: 5.937345058975097\n",
      "resetting env. episode reward total was 10.0. running mean: 5.977971608385346\n",
      "resetting env. episode reward total was 12.0. running mean: 6.038191892301493\n",
      "resetting env. episode reward total was 1.0. running mean: 5.987809973378478\n",
      "resetting env. episode reward total was 9.0. running mean: 6.0179318736446925\n",
      "resetting env. episode reward total was 2.0. running mean: 5.977752554908245\n",
      "resetting env. episode reward total was 12.0. running mean: 6.0379750293591625\n",
      "resetting env. episode reward total was 11.0. running mean: 6.087595279065571\n",
      "resetting env. episode reward total was 5.0. running mean: 6.076719326274915\n",
      "resetting env. episode reward total was 8.0. running mean: 6.095952133012166\n",
      "resetting env. episode reward total was 4.0. running mean: 6.0749926116820445\n",
      "resetting env. episode reward total was 11.0. running mean: 6.124242685565225\n",
      "resetting env. episode reward total was 5.0. running mean: 6.113000258709572\n",
      "resetting env. episode reward total was -1.0. running mean: 6.041870256122476\n",
      "resetting env. episode reward total was -6.0. running mean: 5.921451553561252\n",
      "resetting env. episode reward total was 4.0. running mean: 5.90223703802564\n",
      "resetting env. episode reward total was 1.0. running mean: 5.853214667645383\n",
      "resetting env. episode reward total was 11.0. running mean: 5.9046825209689295\n",
      "resetting env. episode reward total was 8.0. running mean: 5.92563569575924\n",
      "resetting env. episode reward total was 10.0. running mean: 5.966379338801647\n",
      "resetting env. episode reward total was 10.0. running mean: 6.0067155454136305\n",
      "resetting env. episode reward total was 8.0. running mean: 6.026648389959494\n",
      "resetting env. episode reward total was 10.0. running mean: 6.066381906059898\n",
      "resetting env. episode reward total was 7.0. running mean: 6.0757180869992995\n",
      "resetting env. episode reward total was 12.0. running mean: 6.134960906129306\n",
      "resetting env. episode reward total was 11.0. running mean: 6.183611297068014\n",
      "resetting env. episode reward total was 12.0. running mean: 6.2417751840973335\n",
      "resetting env. episode reward total was 1.0. running mean: 6.18935743225636\n",
      "resetting env. episode reward total was 1.0. running mean: 6.137463857933796\n",
      "resetting env. episode reward total was 2.0. running mean: 6.096089219354458\n",
      "resetting env. episode reward total was -3.0. running mean: 6.0051283271609135\n",
      "resetting env. episode reward total was 3.0. running mean: 5.975077043889304\n",
      "resetting env. episode reward total was 2.0. running mean: 5.935326273450411\n",
      "resetting env. episode reward total was 12.0. running mean: 5.995973010715907\n",
      "resetting env. episode reward total was -8.0. running mean: 5.856013280608748\n",
      "resetting env. episode reward total was -1.0. running mean: 5.78745314780266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 17.0. running mean: 5.899578616324633\n",
      "resetting env. episode reward total was 11.0. running mean: 5.9505828301613874\n",
      "resetting env. episode reward total was -2.0. running mean: 5.871077001859774\n",
      "resetting env. episode reward total was 5.0. running mean: 5.862366231841176\n",
      "resetting env. episode reward total was 1.0. running mean: 5.8137425695227645\n",
      "resetting env. episode reward total was 1.0. running mean: 5.765605143827536\n",
      "resetting env. episode reward total was 2.0. running mean: 5.72794909238926\n",
      "resetting env. episode reward total was 3.0. running mean: 5.700669601465368\n",
      "resetting env. episode reward total was 11.0. running mean: 5.753662905450715\n",
      "resetting env. episode reward total was -1.0. running mean: 5.686126276396208\n",
      "resetting env. episode reward total was 2.0. running mean: 5.649265013632245\n",
      "resetting env. episode reward total was 6.0. running mean: 5.652772363495923\n",
      "resetting env. episode reward total was 9.0. running mean: 5.686244639860964\n",
      "resetting env. episode reward total was 4.0. running mean: 5.669382193462354\n",
      "resetting env. episode reward total was 4.0. running mean: 5.669382193462354\n",
      "resetting env. episode reward total was 11.0. running mean: 5.722688371527731\n",
      "resetting env. episode reward total was 11.0. running mean: 5.775461487812454\n",
      "resetting env. episode reward total was -5.0. running mean: 5.66770687293433\n",
      "resetting env. episode reward total was 8.0. running mean: 5.6910298042049865\n",
      "resetting env. episode reward total was -4.0. running mean: 5.5941195061629365\n",
      "resetting env. episode reward total was 9.0. running mean: 5.628178311101307\n",
      "resetting env. episode reward total was 10.0. running mean: 5.6718965279902935\n",
      "resetting env. episode reward total was 16.0. running mean: 5.7751775627103905\n",
      "resetting env. episode reward total was 12.0. running mean: 5.837425787083287\n",
      "resetting env. episode reward total was 12.0. running mean: 5.899051529212454\n",
      "resetting env. episode reward total was 13.0. running mean: 5.97006101392033\n",
      "resetting env. episode reward total was 6.0. running mean: 5.970360403781126\n",
      "resetting env. episode reward total was 11.0. running mean: 6.020656799743315\n",
      "resetting env. episode reward total was 3.0. running mean: 5.990450231745882\n",
      "resetting env. episode reward total was 11.0. running mean: 6.040545729428423\n",
      "resetting env. episode reward total was 8.0. running mean: 6.060140272134139\n",
      "resetting env. episode reward total was -6.0. running mean: 5.9395388694127975\n",
      "resetting env. episode reward total was 4.0. running mean: 5.92014348071867\n",
      "resetting env. episode reward total was -3.0. running mean: 5.830942045911483\n",
      "resetting env. episode reward total was -6.0. running mean: 5.712632625452368\n",
      "resetting env. episode reward total was 7.0. running mean: 5.7255062991978445\n",
      "resetting env. episode reward total was 4.0. running mean: 5.708251236205866\n",
      "resetting env. episode reward total was 13.0. running mean: 5.781168723843807\n",
      "resetting env. episode reward total was 7.0. running mean: 5.79335703660537\n",
      "resetting env. episode reward total was -5.0. running mean: 5.685423466239316\n",
      "resetting env. episode reward total was 13.0. running mean: 5.758569231576923\n",
      "resetting env. episode reward total was 7.0. running mean: 5.770983539261153\n",
      "resetting env. episode reward total was 16.0. running mean: 5.873273703868541\n",
      "resetting env. episode reward total was 3.0. running mean: 5.8445409668298565\n",
      "resetting env. episode reward total was 8.0. running mean: 5.866095557161558\n",
      "resetting env. episode reward total was 12.0. running mean: 5.927434601589943\n",
      "resetting env. episode reward total was 6.0. running mean: 5.928160255574043\n",
      "resetting env. episode reward total was 10.0. running mean: 5.968878653018302\n",
      "resetting env. episode reward total was 18.0. running mean: 6.089189866488119\n",
      "resetting env. episode reward total was 14.0. running mean: 6.1682979678232375\n",
      "resetting env. episode reward total was 9.0. running mean: 6.196614988145005\n",
      "resetting env. episode reward total was 4.0. running mean: 6.174648838263555\n",
      "resetting env. episode reward total was 15.0. running mean: 6.262902349880919\n",
      "resetting env. episode reward total was 1.0. running mean: 6.21027332638211\n",
      "resetting env. episode reward total was 13.0. running mean: 6.278170593118288\n",
      "resetting env. episode reward total was 10.0. running mean: 6.315388887187105\n",
      "resetting env. episode reward total was 4.0. running mean: 6.292234998315234\n",
      "resetting env. episode reward total was -1.0. running mean: 6.219312648332082\n",
      "resetting env. episode reward total was 15.0. running mean: 6.307119521848761\n",
      "resetting env. episode reward total was 6.0. running mean: 6.304048326630273\n",
      "resetting env. episode reward total was 5.0. running mean: 6.29100784336397\n",
      "resetting env. episode reward total was 9.0. running mean: 6.3180977649303305\n",
      "resetting env. episode reward total was 13.0. running mean: 6.384916787281027\n",
      "resetting env. episode reward total was 7.0. running mean: 6.391067619408217\n",
      "resetting env. episode reward total was 9.0. running mean: 6.417156943214135\n",
      "resetting env. episode reward total was 15.0. running mean: 6.502985373781994\n",
      "resetting env. episode reward total was -1.0. running mean: 6.427955520044174\n",
      "resetting env. episode reward total was 5.0. running mean: 6.413675964843732\n",
      "resetting env. episode reward total was 4.0. running mean: 6.389539205195295\n",
      "resetting env. episode reward total was 3.0. running mean: 6.355643813143342\n",
      "resetting env. episode reward total was 11.0. running mean: 6.4020873750119085\n",
      "resetting env. episode reward total was -4.0. running mean: 6.298066501261789\n",
      "resetting env. episode reward total was 11.0. running mean: 6.345085836249171\n",
      "resetting env. episode reward total was 12.0. running mean: 6.40163497788668\n",
      "resetting env. episode reward total was 8.0. running mean: 6.417618628107813\n",
      "resetting env. episode reward total was 8.0. running mean: 6.433442441826735\n",
      "resetting env. episode reward total was 3.0. running mean: 6.399108017408468\n",
      "resetting env. episode reward total was 4.0. running mean: 6.375116937234383\n",
      "resetting env. episode reward total was 10.0. running mean: 6.411365767862039\n",
      "resetting env. episode reward total was 11.0. running mean: 6.457252110183418\n",
      "resetting env. episode reward total was 13.0. running mean: 6.522679589081584\n",
      "resetting env. episode reward total was 2.0. running mean: 6.477452793190768\n",
      "resetting env. episode reward total was 7.0. running mean: 6.48267826525886\n",
      "resetting env. episode reward total was -1.0. running mean: 6.407851482606271\n",
      "resetting env. episode reward total was 4.0. running mean: 6.383772967780208\n",
      "resetting env. episode reward total was 10.0. running mean: 6.419935238102406\n",
      "resetting env. episode reward total was 5.0. running mean: 6.4057358857213815\n",
      "resetting env. episode reward total was 10.0. running mean: 6.441678526864167\n",
      "resetting env. episode reward total was 5.0. running mean: 6.427261741595525\n",
      "resetting env. episode reward total was 6.0. running mean: 6.422989124179569\n",
      "resetting env. episode reward total was 5.0. running mean: 6.408759232937773\n",
      "resetting env. episode reward total was -4.0. running mean: 6.304671640608395\n",
      "resetting env. episode reward total was 12.0. running mean: 6.361624924202311\n",
      "resetting env. episode reward total was 7.0. running mean: 6.368008674960288\n",
      "resetting env. episode reward total was 10.0. running mean: 6.404328588210685\n",
      "resetting env. episode reward total was 16.0. running mean: 6.500285302328578\n",
      "resetting env. episode reward total was 6.0. running mean: 6.495282449305292\n",
      "resetting env. episode reward total was 16.0. running mean: 6.590329624812239\n",
      "resetting env. episode reward total was 4.0. running mean: 6.5644263285641165\n",
      "resetting env. episode reward total was 1.0. running mean: 6.508782065278475\n",
      "resetting env. episode reward total was 12.0. running mean: 6.56369424462569\n",
      "resetting env. episode reward total was 3.0. running mean: 6.528057302179434\n",
      "resetting env. episode reward total was 9.0. running mean: 6.55277672915764\n",
      "resetting env. episode reward total was 10.0. running mean: 6.587248961866063\n",
      "resetting env. episode reward total was 15.0. running mean: 6.6713764722474025\n",
      "resetting env. episode reward total was 6.0. running mean: 6.664662707524928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 6.678016080449679\n",
      "resetting env. episode reward total was 16.0. running mean: 6.771235919645183\n",
      "resetting env. episode reward total was -1.0. running mean: 6.693523560448732\n",
      "resetting env. episode reward total was 8.0. running mean: 6.706588324844245\n",
      "resetting env. episode reward total was 12.0. running mean: 6.759522441595802\n",
      "resetting env. episode reward total was 4.0. running mean: 6.7319272171798445\n",
      "resetting env. episode reward total was 8.0. running mean: 6.744607945008046\n",
      "resetting env. episode reward total was -4.0. running mean: 6.637161865557966\n",
      "resetting env. episode reward total was 5.0. running mean: 6.620790246902386\n",
      "resetting env. episode reward total was 8.0. running mean: 6.634582344433362\n",
      "resetting env. episode reward total was 11.0. running mean: 6.678236520989029\n",
      "resetting env. episode reward total was 9.0. running mean: 6.701454155779138\n",
      "resetting env. episode reward total was 5.0. running mean: 6.684439614221346\n",
      "resetting env. episode reward total was -1.0. running mean: 6.607595218079132\n",
      "resetting env. episode reward total was 6.0. running mean: 6.60151926589834\n",
      "resetting env. episode reward total was 7.0. running mean: 6.6055040732393575\n",
      "resetting env. episode reward total was 8.0. running mean: 6.619449032506964\n",
      "resetting env. episode reward total was 11.0. running mean: 6.663254542181894\n",
      "resetting env. episode reward total was -5.0. running mean: 6.546621996760075\n",
      "resetting env. episode reward total was 7.0. running mean: 6.551155776792475\n",
      "resetting env. episode reward total was 4.0. running mean: 6.52564421902455\n",
      "resetting env. episode reward total was -11.0. running mean: 6.350387776834304\n",
      "resetting env. episode reward total was 10.0. running mean: 6.38688389906596\n",
      "resetting env. episode reward total was 4.0. running mean: 6.363015060075301\n",
      "resetting env. episode reward total was 12.0. running mean: 6.419384909474548\n",
      "resetting env. episode reward total was 11.0. running mean: 6.465191060379803\n",
      "resetting env. episode reward total was 6.0. running mean: 6.460539149776005\n",
      "resetting env. episode reward total was 7.0. running mean: 6.465933758278245\n",
      "resetting env. episode reward total was 7.0. running mean: 6.471274420695463\n",
      "resetting env. episode reward total was -1.0. running mean: 6.396561676488508\n",
      "resetting env. episode reward total was 7.0. running mean: 6.402596059723623\n",
      "resetting env. episode reward total was 8.0. running mean: 6.418570099126387\n",
      "resetting env. episode reward total was 6.0. running mean: 6.414384398135122\n",
      "resetting env. episode reward total was 7.0. running mean: 6.4202405541537715\n",
      "resetting env. episode reward total was 15.0. running mean: 6.506038148612234\n",
      "resetting env. episode reward total was -3.0. running mean: 6.410977767126111\n",
      "resetting env. episode reward total was -9.0. running mean: 6.25686798945485\n",
      "resetting env. episode reward total was 7.0. running mean: 6.264299309560302\n",
      "resetting env. episode reward total was 5.0. running mean: 6.2516563164646985\n",
      "resetting env. episode reward total was 4.0. running mean: 6.229139753300052\n",
      "resetting env. episode reward total was 2.0. running mean: 6.186848355767051\n",
      "resetting env. episode reward total was 6.0. running mean: 6.18497987220938\n",
      "resetting env. episode reward total was 5.0. running mean: 6.173130073487285\n",
      "resetting env. episode reward total was 5.0. running mean: 6.161398772752412\n",
      "resetting env. episode reward total was 14.0. running mean: 6.239784785024888\n",
      "resetting env. episode reward total was 11.0. running mean: 6.287386937174639\n",
      "resetting env. episode reward total was 4.0. running mean: 6.264513067802892\n",
      "resetting env. episode reward total was 14.0. running mean: 6.341867937124863\n",
      "resetting env. episode reward total was 13.0. running mean: 6.408449257753614\n",
      "resetting env. episode reward total was 14.0. running mean: 6.484364765176077\n",
      "resetting env. episode reward total was 10.0. running mean: 6.519521117524317\n",
      "resetting env. episode reward total was -1.0. running mean: 6.444325906349073\n",
      "resetting env. episode reward total was 5.0. running mean: 6.429882647285583\n",
      "resetting env. episode reward total was 5.0. running mean: 6.415583820812727\n",
      "resetting env. episode reward total was -1.0. running mean: 6.3414279826046\n",
      "resetting env. episode reward total was 15.0. running mean: 6.428013702778554\n",
      "resetting env. episode reward total was 4.0. running mean: 6.403733565750769\n",
      "resetting env. episode reward total was -1.0. running mean: 6.329696230093261\n",
      "resetting env. episode reward total was 6.0. running mean: 6.326399267792328\n",
      "resetting env. episode reward total was 4.0. running mean: 6.303135275114405\n",
      "resetting env. episode reward total was -5.0. running mean: 6.190103922363261\n",
      "resetting env. episode reward total was 14.0. running mean: 6.268202883139628\n",
      "resetting env. episode reward total was -7.0. running mean: 6.135520854308231\n",
      "resetting env. episode reward total was 3.0. running mean: 6.104165645765149\n",
      "resetting env. episode reward total was 10.0. running mean: 6.143123989307497\n",
      "resetting env. episode reward total was 2.0. running mean: 6.101692749414422\n",
      "resetting env. episode reward total was 2.0. running mean: 6.060675821920277\n",
      "resetting env. episode reward total was 9.0. running mean: 6.090069063701074\n",
      "resetting env. episode reward total was 12.0. running mean: 6.149168373064064\n",
      "resetting env. episode reward total was 7.0. running mean: 6.157676689333424\n",
      "resetting env. episode reward total was 1.0. running mean: 6.106099922440089\n",
      "resetting env. episode reward total was 5.0. running mean: 6.095038923215688\n",
      "resetting env. episode reward total was 1.0. running mean: 6.044088533983531\n",
      "resetting env. episode reward total was 6.0. running mean: 6.043647648643695\n",
      "resetting env. episode reward total was 13.0. running mean: 6.113211172157258\n",
      "resetting env. episode reward total was 13.0. running mean: 6.182079060435685\n",
      "resetting env. episode reward total was 11.0. running mean: 6.230258269831328\n",
      "resetting env. episode reward total was 11.0. running mean: 6.277955687133015\n",
      "resetting env. episode reward total was 2.0. running mean: 6.235176130261684\n",
      "resetting env. episode reward total was 5.0. running mean: 6.222824368959067\n",
      "resetting env. episode reward total was 6.0. running mean: 6.220596125269476\n",
      "resetting env. episode reward total was 9.0. running mean: 6.248390164016781\n",
      "resetting env. episode reward total was 5.0. running mean: 6.235906262376613\n",
      "resetting env. episode reward total was -2.0. running mean: 6.153547199752847\n",
      "resetting env. episode reward total was 14.0. running mean: 6.232011727755318\n",
      "resetting env. episode reward total was 1.0. running mean: 6.179691610477764\n",
      "resetting env. episode reward total was 11.0. running mean: 6.227894694372987\n",
      "resetting env. episode reward total was 5.0. running mean: 6.215615747429257\n",
      "resetting env. episode reward total was -1.0. running mean: 6.143459589954964\n",
      "resetting env. episode reward total was 7.0. running mean: 6.152024994055415\n",
      "resetting env. episode reward total was 5.0. running mean: 6.14050474411486\n",
      "resetting env. episode reward total was 12.0. running mean: 6.199099696673712\n",
      "resetting env. episode reward total was 3.0. running mean: 6.167108699706975\n",
      "resetting env. episode reward total was 7.0. running mean: 6.1754376127099055\n",
      "resetting env. episode reward total was 3.0. running mean: 6.143683236582807\n",
      "resetting env. episode reward total was 7.0. running mean: 6.152246404216979\n",
      "resetting env. episode reward total was 6.0. running mean: 6.150723940174808\n",
      "resetting env. episode reward total was 7.0. running mean: 6.159216700773061\n",
      "resetting env. episode reward total was 16.0. running mean: 6.2576245337653305\n",
      "resetting env. episode reward total was 6.0. running mean: 6.255048288427677\n",
      "resetting env. episode reward total was 8.0. running mean: 6.2724978055434\n",
      "resetting env. episode reward total was 14.0. running mean: 6.349772827487966\n",
      "resetting env. episode reward total was -5.0. running mean: 6.236275099213087\n",
      "resetting env. episode reward total was 8.0. running mean: 6.253912348220956\n",
      "resetting env. episode reward total was 11.0. running mean: 6.301373224738747\n",
      "resetting env. episode reward total was -9.0. running mean: 6.148359492491359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 6.176875897566445\n",
      "resetting env. episode reward total was -4.0. running mean: 6.075107138590781\n",
      "resetting env. episode reward total was 13.0. running mean: 6.144356067204873\n",
      "resetting env. episode reward total was 12.0. running mean: 6.202912506532824\n",
      "resetting env. episode reward total was -6.0. running mean: 6.080883381467496\n",
      "resetting env. episode reward total was 8.0. running mean: 6.100074547652821\n",
      "resetting env. episode reward total was 7.0. running mean: 6.109073802176293\n",
      "resetting env. episode reward total was 11.0. running mean: 6.15798306415453\n",
      "resetting env. episode reward total was 3.0. running mean: 6.126403233512986\n",
      "resetting env. episode reward total was 5.0. running mean: 6.115139201177856\n",
      "resetting env. episode reward total was 5.0. running mean: 6.103987809166077\n",
      "resetting env. episode reward total was 13.0. running mean: 6.172947931074416\n",
      "resetting env. episode reward total was 10.0. running mean: 6.2112184517636715\n",
      "resetting env. episode reward total was 10.0. running mean: 6.2491062672460345\n",
      "resetting env. episode reward total was 3.0. running mean: 6.216615204573574\n",
      "resetting env. episode reward total was 16.0. running mean: 6.314449052527839\n",
      "resetting env. episode reward total was 1.0. running mean: 6.26130456200256\n",
      "resetting env. episode reward total was 7.0. running mean: 6.2686915163825345\n",
      "resetting env. episode reward total was 8.0. running mean: 6.28600460121871\n",
      "resetting env. episode reward total was 5.0. running mean: 6.273144555206522\n",
      "resetting env. episode reward total was 5.0. running mean: 6.260413109654457\n",
      "resetting env. episode reward total was 8.0. running mean: 6.277808978557912\n",
      "resetting env. episode reward total was 7.0. running mean: 6.285030888772334\n",
      "resetting env. episode reward total was 5.0. running mean: 6.27218057988461\n",
      "resetting env. episode reward total was 8.0. running mean: 6.289458774085764\n",
      "resetting env. episode reward total was -11.0. running mean: 6.116564186344906\n",
      "resetting env. episode reward total was -1.0. running mean: 6.045398544481457\n",
      "resetting env. episode reward total was 7.0. running mean: 6.054944559036643\n",
      "resetting env. episode reward total was 4.0. running mean: 6.034395113446276\n",
      "resetting env. episode reward total was 3.0. running mean: 6.004051162311813\n",
      "resetting env. episode reward total was -1.0. running mean: 5.934010650688696\n",
      "resetting env. episode reward total was 1.0. running mean: 5.884670544181809\n",
      "resetting env. episode reward total was 10.0. running mean: 5.925823838739991\n",
      "resetting env. episode reward total was 12.0. running mean: 5.98656560035259\n",
      "resetting env. episode reward total was 3.0. running mean: 5.956699944349065\n",
      "resetting env. episode reward total was 9.0. running mean: 5.987132944905574\n",
      "resetting env. episode reward total was 6.0. running mean: 5.987261615456518\n",
      "resetting env. episode reward total was 5.0. running mean: 5.977388999301953\n",
      "resetting env. episode reward total was 4.0. running mean: 5.957615109308933\n",
      "resetting env. episode reward total was 13.0. running mean: 6.028038958215844\n",
      "resetting env. episode reward total was 3.0. running mean: 5.997758568633686\n",
      "resetting env. episode reward total was 9.0. running mean: 6.027780982947349\n",
      "resetting env. episode reward total was 17.0. running mean: 6.137503173117875\n",
      "resetting env. episode reward total was 8.0. running mean: 6.156128141386697\n",
      "resetting env. episode reward total was 4.0. running mean: 6.13456685997283\n",
      "resetting env. episode reward total was -1.0. running mean: 6.063221191373102\n",
      "resetting env. episode reward total was 3.0. running mean: 6.032588979459371\n",
      "resetting env. episode reward total was 9.0. running mean: 6.062263089664777\n",
      "resetting env. episode reward total was -5.0. running mean: 5.951640458768129\n",
      "resetting env. episode reward total was 9.0. running mean: 5.9821240541804475\n",
      "resetting env. episode reward total was 6.0. running mean: 5.9823028136386425\n",
      "resetting env. episode reward total was 7.0. running mean: 5.9924797855022565\n",
      "resetting env. episode reward total was 13.0. running mean: 6.062554987647234\n",
      "resetting env. episode reward total was 7.0. running mean: 6.071929437770762\n",
      "resetting env. episode reward total was 6.0. running mean: 6.071210143393054\n",
      "resetting env. episode reward total was -1.0. running mean: 6.000498041959124\n",
      "resetting env. episode reward total was 3.0. running mean: 5.970493061539533\n",
      "resetting env. episode reward total was 3.0. running mean: 5.940788130924138\n",
      "resetting env. episode reward total was 4.0. running mean: 5.921380249614896\n",
      "resetting env. episode reward total was 8.0. running mean: 5.942166447118747\n",
      "resetting env. episode reward total was 8.0. running mean: 5.962744782647559\n",
      "resetting env. episode reward total was 7.0. running mean: 5.973117334821084\n",
      "resetting env. episode reward total was 9.0. running mean: 6.003386161472873\n",
      "resetting env. episode reward total was 10.0. running mean: 6.043352299858144\n",
      "resetting env. episode reward total was 10.0. running mean: 6.082918776859563\n",
      "resetting env. episode reward total was 13.0. running mean: 6.152089589090967\n",
      "resetting env. episode reward total was 3.0. running mean: 6.120568693200058\n",
      "resetting env. episode reward total was 13.0. running mean: 6.189363006268057\n",
      "resetting env. episode reward total was 5.0. running mean: 6.1774693762053765\n",
      "resetting env. episode reward total was 10.0. running mean: 6.215694682443322\n",
      "resetting env. episode reward total was 1.0. running mean: 6.163537735618889\n",
      "resetting env. episode reward total was 2.0. running mean: 6.1219023582627\n",
      "resetting env. episode reward total was 5.0. running mean: 6.110683334680073\n",
      "resetting env. episode reward total was 18.0. running mean: 6.229576501333272\n",
      "resetting env. episode reward total was 5.0. running mean: 6.217280736319939\n",
      "resetting env. episode reward total was -2.0. running mean: 6.13510792895674\n",
      "resetting env. episode reward total was 13.0. running mean: 6.2037568496671724\n",
      "resetting env. episode reward total was -3.0. running mean: 6.1117192811705\n",
      "resetting env. episode reward total was 1.0. running mean: 6.060602088358795\n",
      "resetting env. episode reward total was 12.0. running mean: 6.119996067475207\n",
      "resetting env. episode reward total was 7.0. running mean: 6.128796106800455\n",
      "resetting env. episode reward total was 10.0. running mean: 6.16750814573245\n",
      "resetting env. episode reward total was 11.0. running mean: 6.215833064275126\n",
      "resetting env. episode reward total was 14.0. running mean: 6.293674733632374\n",
      "resetting env. episode reward total was 10.0. running mean: 6.330737986296049\n",
      "resetting env. episode reward total was -5.0. running mean: 6.217430606433089\n",
      "resetting env. episode reward total was -11.0. running mean: 6.045256300368758\n",
      "resetting env. episode reward total was -7.0. running mean: 5.9148037373650695\n",
      "resetting env. episode reward total was 15.0. running mean: 6.0056556999914195\n",
      "resetting env. episode reward total was 17.0. running mean: 6.115599142991505\n",
      "resetting env. episode reward total was 9.0. running mean: 6.14444315156159\n",
      "resetting env. episode reward total was 12.0. running mean: 6.202998720045974\n",
      "resetting env. episode reward total was 12.0. running mean: 6.260968732845514\n",
      "resetting env. episode reward total was 13.0. running mean: 6.328359045517058\n",
      "resetting env. episode reward total was -5.0. running mean: 6.215075455061888\n",
      "resetting env. episode reward total was -7.0. running mean: 6.082924700511269\n",
      "resetting env. episode reward total was 12.0. running mean: 6.1420954535061565\n",
      "resetting env. episode reward total was -3.0. running mean: 6.0506744989710946\n",
      "resetting env. episode reward total was 13.0. running mean: 6.1201677539813835\n",
      "resetting env. episode reward total was 8.0. running mean: 6.138966076441569\n",
      "resetting env. episode reward total was -6.0. running mean: 6.017576415677154\n",
      "resetting env. episode reward total was 14.0. running mean: 6.097400651520382\n",
      "resetting env. episode reward total was 6.0. running mean: 6.096426645005177\n",
      "resetting env. episode reward total was 8.0. running mean: 6.115462378555126\n",
      "resetting env. episode reward total was 8.0. running mean: 6.134307754769575\n",
      "resetting env. episode reward total was 2.0. running mean: 6.092964677221878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 6.082035030449659\n",
      "resetting env. episode reward total was 2.0. running mean: 6.041214680145162\n",
      "resetting env. episode reward total was -9.0. running mean: 5.89080253334371\n",
      "resetting env. episode reward total was 8.0. running mean: 5.911894508010273\n",
      "resetting env. episode reward total was 5.0. running mean: 5.90277556293017\n",
      "resetting env. episode reward total was 1.0. running mean: 5.853747807300868\n",
      "resetting env. episode reward total was 8.0. running mean: 5.875210329227859\n",
      "resetting env. episode reward total was 11.0. running mean: 5.926458225935581\n",
      "resetting env. episode reward total was 4.0. running mean: 5.907193643676225\n",
      "resetting env. episode reward total was 2.0. running mean: 5.868121707239462\n",
      "resetting env. episode reward total was 14.0. running mean: 5.949440490167067\n",
      "resetting env. episode reward total was 13.0. running mean: 6.0199460852653965\n",
      "resetting env. episode reward total was 11.0. running mean: 6.069746624412743\n",
      "resetting env. episode reward total was 14.0. running mean: 6.149049158168616\n",
      "resetting env. episode reward total was 1.0. running mean: 6.097558666586929\n",
      "resetting env. episode reward total was 6.0. running mean: 6.096583079921059\n",
      "resetting env. episode reward total was 11.0. running mean: 6.145617249121849\n",
      "resetting env. episode reward total was 10.0. running mean: 6.18416107663063\n",
      "resetting env. episode reward total was -1.0. running mean: 6.112319465864324\n",
      "resetting env. episode reward total was 13.0. running mean: 6.181196271205681\n",
      "resetting env. episode reward total was 15.0. running mean: 6.269384308493624\n",
      "resetting env. episode reward total was 7.0. running mean: 6.276690465408688\n",
      "resetting env. episode reward total was 2.0. running mean: 6.233923560754601\n",
      "resetting env. episode reward total was 11.0. running mean: 6.281584325147055\n",
      "resetting env. episode reward total was 10.0. running mean: 6.318768481895583\n",
      "resetting env. episode reward total was 10.0. running mean: 6.355580797076627\n",
      "resetting env. episode reward total was -5.0. running mean: 6.24202498910586\n",
      "resetting env. episode reward total was 8.0. running mean: 6.259604739214802\n",
      "resetting env. episode reward total was 6.0. running mean: 6.257008691822653\n",
      "resetting env. episode reward total was -2.0. running mean: 6.174438604904427\n",
      "resetting env. episode reward total was 8.0. running mean: 6.192694218855383\n",
      "resetting env. episode reward total was 14.0. running mean: 6.270767276666829\n",
      "resetting env. episode reward total was 14.0. running mean: 6.34805960390016\n",
      "resetting env. episode reward total was 1.0. running mean: 6.2945790078611585\n",
      "resetting env. episode reward total was -1.0. running mean: 6.221633217782547\n",
      "resetting env. episode reward total was 12.0. running mean: 6.279416885604721\n",
      "resetting env. episode reward total was 8.0. running mean: 6.296622716748674\n",
      "resetting env. episode reward total was 10.0. running mean: 6.333656489581187\n",
      "resetting env. episode reward total was 10.0. running mean: 6.370319924685375\n",
      "resetting env. episode reward total was 9.0. running mean: 6.396616725438521\n",
      "resetting env. episode reward total was -3.0. running mean: 6.302650558184135\n",
      "resetting env. episode reward total was 8.0. running mean: 6.319624052602294\n",
      "resetting env. episode reward total was 3.0. running mean: 6.286427812076272\n",
      "resetting env. episode reward total was 12.0. running mean: 6.343563533955509\n",
      "resetting env. episode reward total was 9.0. running mean: 6.370127898615953\n",
      "resetting env. episode reward total was 14.0. running mean: 6.4464266196297935\n",
      "resetting env. episode reward total was 10.0. running mean: 6.481962353433495\n",
      "resetting env. episode reward total was 8.0. running mean: 6.49714272989916\n",
      "resetting env. episode reward total was -3.0. running mean: 6.402171302600168\n",
      "resetting env. episode reward total was 6.0. running mean: 6.398149589574166\n",
      "resetting env. episode reward total was 9.0. running mean: 6.424168093678424\n",
      "resetting env. episode reward total was 7.0. running mean: 6.42992641274164\n",
      "resetting env. episode reward total was 6.0. running mean: 6.425627148614224\n",
      "resetting env. episode reward total was 1.0. running mean: 6.371370877128081\n",
      "resetting env. episode reward total was 10.0. running mean: 6.4076571683568\n",
      "resetting env. episode reward total was 1.0. running mean: 6.353580596673232\n",
      "resetting env. episode reward total was 5.0. running mean: 6.340044790706499\n",
      "resetting env. episode reward total was 16.0. running mean: 6.436644342799434\n",
      "resetting env. episode reward total was 15.0. running mean: 6.52227789937144\n",
      "resetting env. episode reward total was 1.0. running mean: 6.467055120377726\n",
      "resetting env. episode reward total was 14.0. running mean: 6.542384569173948\n",
      "resetting env. episode reward total was 8.0. running mean: 6.5569607234822085\n",
      "resetting env. episode reward total was 7.0. running mean: 6.561391116247386\n",
      "resetting env. episode reward total was 13.0. running mean: 6.625777205084912\n",
      "resetting env. episode reward total was 5.0. running mean: 6.6095194330340625\n",
      "resetting env. episode reward total was -3.0. running mean: 6.513424238703721\n",
      "resetting env. episode reward total was 4.0. running mean: 6.488289996316684\n",
      "resetting env. episode reward total was 11.0. running mean: 6.533407096353518\n",
      "resetting env. episode reward total was 1.0. running mean: 6.478073025389982\n",
      "resetting env. episode reward total was 5.0. running mean: 6.463292295136082\n",
      "resetting env. episode reward total was 2.0. running mean: 6.41865937218472\n",
      "resetting env. episode reward total was 9.0. running mean: 6.444472778462873\n",
      "resetting env. episode reward total was 8.0. running mean: 6.460028050678244\n",
      "resetting env. episode reward total was 3.0. running mean: 6.425427770171462\n",
      "resetting env. episode reward total was 12.0. running mean: 6.481173492469747\n",
      "resetting env. episode reward total was 16.0. running mean: 6.576361757545049\n",
      "resetting env. episode reward total was 5.0. running mean: 6.560598139969598\n",
      "resetting env. episode reward total was 5.0. running mean: 6.544992158569902\n",
      "resetting env. episode reward total was 7.0. running mean: 6.549542236984203\n",
      "resetting env. episode reward total was 1.0. running mean: 6.49404681461436\n",
      "resetting env. episode reward total was 6.0. running mean: 6.4891063464682155\n",
      "resetting env. episode reward total was 10.0. running mean: 6.5242152830035325\n",
      "resetting env. episode reward total was 3.0. running mean: 6.488973130173497\n",
      "resetting env. episode reward total was 6.0. running mean: 6.484083398871762\n",
      "resetting env. episode reward total was 6.0. running mean: 6.4792425648830445\n",
      "resetting env. episode reward total was -5.0. running mean: 6.364450139234214\n",
      "resetting env. episode reward total was 12.0. running mean: 6.420805637841872\n",
      "resetting env. episode reward total was 7.0. running mean: 6.4265975814634535\n",
      "resetting env. episode reward total was 11.0. running mean: 6.47233160564882\n",
      "resetting env. episode reward total was 5.0. running mean: 6.457608289592331\n",
      "resetting env. episode reward total was 12.0. running mean: 6.5130322066964075\n",
      "resetting env. episode reward total was 8.0. running mean: 6.527901884629443\n",
      "resetting env. episode reward total was -2.0. running mean: 6.442622865783149\n",
      "resetting env. episode reward total was 1.0. running mean: 6.388196637125318\n",
      "resetting env. episode reward total was -1.0. running mean: 6.314314670754064\n",
      "resetting env. episode reward total was 11.0. running mean: 6.361171524046524\n",
      "resetting env. episode reward total was 4.0. running mean: 6.337559808806059\n",
      "resetting env. episode reward total was 6.0. running mean: 6.334184210717998\n",
      "resetting env. episode reward total was 5.0. running mean: 6.320842368610818\n",
      "resetting env. episode reward total was 3.0. running mean: 6.2876339449247105\n",
      "resetting env. episode reward total was 8.0. running mean: 6.304757605475463\n",
      "resetting env. episode reward total was 9.0. running mean: 6.331710029420708\n",
      "resetting env. episode reward total was 13.0. running mean: 6.3983929291265005\n",
      "resetting env. episode reward total was 9.0. running mean: 6.424408999835236\n",
      "resetting env. episode reward total was 10.0. running mean: 6.460164909836883\n",
      "resetting env. episode reward total was 6.0. running mean: 6.455563260738514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 6.441007628131128\n",
      "resetting env. episode reward total was 8.0. running mean: 6.456597551849817\n",
      "resetting env. episode reward total was 1.0. running mean: 6.402031576331319\n",
      "resetting env. episode reward total was 5.0. running mean: 6.388011260568005\n",
      "resetting env. episode reward total was -2.0. running mean: 6.304131147962325\n",
      "resetting env. episode reward total was 8.0. running mean: 6.3210898364827015\n",
      "resetting env. episode reward total was 5.0. running mean: 6.307878938117875\n",
      "resetting env. episode reward total was 15.0. running mean: 6.394800148736696\n",
      "resetting env. episode reward total was 10.0. running mean: 6.430852147249328\n",
      "resetting env. episode reward total was 6.0. running mean: 6.4265436257768345\n",
      "resetting env. episode reward total was 5.0. running mean: 6.412278189519066\n",
      "resetting env. episode reward total was -5.0. running mean: 6.2981554076238755\n",
      "resetting env. episode reward total was 1.0. running mean: 6.245173853547636\n",
      "resetting env. episode reward total was 11.0. running mean: 6.29272211501216\n",
      "resetting env. episode reward total was 6.0. running mean: 6.289794893862038\n",
      "resetting env. episode reward total was -3.0. running mean: 6.1968969449234175\n",
      "resetting env. episode reward total was 17.0. running mean: 6.304927975474183\n",
      "resetting env. episode reward total was 18.0. running mean: 6.421878695719442\n",
      "resetting env. episode reward total was 13.0. running mean: 6.487659908762247\n",
      "resetting env. episode reward total was 12.0. running mean: 6.542783309674625\n",
      "resetting env. episode reward total was 16.0. running mean: 6.637355476577879\n",
      "resetting env. episode reward total was 9.0. running mean: 6.6609819218121\n",
      "resetting env. episode reward total was 5.0. running mean: 6.644372102593978\n",
      "resetting env. episode reward total was -11.0. running mean: 6.467928381568038\n",
      "resetting env. episode reward total was 2.0. running mean: 6.4232490977523575\n",
      "resetting env. episode reward total was 3.0. running mean: 6.389016606774834\n",
      "resetting env. episode reward total was 12.0. running mean: 6.445126440707085\n",
      "resetting env. episode reward total was 2.0. running mean: 6.400675176300014\n",
      "resetting env. episode reward total was 13.0. running mean: 6.466668424537014\n",
      "resetting env. episode reward total was 6.0. running mean: 6.462001740291643\n",
      "resetting env. episode reward total was 6.0. running mean: 6.4573817228887265\n",
      "resetting env. episode reward total was 9.0. running mean: 6.482807905659839\n",
      "resetting env. episode reward total was 12.0. running mean: 6.537979826603241\n",
      "resetting env. episode reward total was 9.0. running mean: 6.562600028337208\n",
      "resetting env. episode reward total was 5.0. running mean: 6.546974028053835\n",
      "resetting env. episode reward total was -1.0. running mean: 6.471504287773297\n",
      "resetting env. episode reward total was 5.0. running mean: 6.456789244895564\n",
      "resetting env. episode reward total was -5.0. running mean: 6.342221352446608\n",
      "resetting env. episode reward total was 4.0. running mean: 6.3187991389221425\n",
      "resetting env. episode reward total was -11.0. running mean: 6.145611147532921\n",
      "resetting env. episode reward total was 7.0. running mean: 6.154155036057592\n",
      "resetting env. episode reward total was 10.0. running mean: 6.192613485697016\n",
      "resetting env. episode reward total was 5.0. running mean: 6.180687350840045\n",
      "resetting env. episode reward total was 7.0. running mean: 6.188880477331645\n",
      "resetting env. episode reward total was 3.0. running mean: 6.156991672558329\n",
      "resetting env. episode reward total was 10.0. running mean: 6.195421755832745\n",
      "resetting env. episode reward total was 12.0. running mean: 6.253467538274418\n",
      "resetting env. episode reward total was 9.0. running mean: 6.280932862891674\n",
      "resetting env. episode reward total was 7.0. running mean: 6.288123534262757\n",
      "resetting env. episode reward total was 5.0. running mean: 6.275242298920129\n",
      "resetting env. episode reward total was 6.0. running mean: 6.272489875930927\n",
      "resetting env. episode reward total was 13.0. running mean: 6.339764977171618\n",
      "resetting env. episode reward total was 7.0. running mean: 6.346367327399902\n",
      "resetting env. episode reward total was 9.0. running mean: 6.372903654125903\n",
      "resetting env. episode reward total was 10.0. running mean: 6.409174617584643\n",
      "resetting env. episode reward total was 5.0. running mean: 6.395082871408796\n",
      "resetting env. episode reward total was 8.0. running mean: 6.4111320426947085\n",
      "resetting env. episode reward total was 10.0. running mean: 6.447020722267761\n",
      "resetting env. episode reward total was 12.0. running mean: 6.502550515045084\n",
      "resetting env. episode reward total was -1.0. running mean: 6.427525009894634\n",
      "resetting env. episode reward total was 16.0. running mean: 6.5232497597956876\n",
      "resetting env. episode reward total was 5.0. running mean: 6.508017262197731\n",
      "resetting env. episode reward total was 2.0. running mean: 6.462937089575753\n",
      "resetting env. episode reward total was 7.0. running mean: 6.468307718679996\n",
      "resetting env. episode reward total was 6.0. running mean: 6.463624641493196\n",
      "resetting env. episode reward total was 4.0. running mean: 6.438988395078264\n",
      "resetting env. episode reward total was 6.0. running mean: 6.43459851112748\n",
      "resetting env. episode reward total was 12.0. running mean: 6.490252526016206\n",
      "resetting env. episode reward total was 8.0. running mean: 6.505350000756043\n",
      "resetting env. episode reward total was 5.0. running mean: 6.4902965007484825\n",
      "resetting env. episode reward total was 7.0. running mean: 6.495393535740998\n",
      "resetting env. episode reward total was 13.0. running mean: 6.560439600383588\n",
      "resetting env. episode reward total was 1.0. running mean: 6.504835204379752\n",
      "resetting env. episode reward total was 14.0. running mean: 6.579786852335954\n",
      "resetting env. episode reward total was 4.0. running mean: 6.553988983812594\n",
      "resetting env. episode reward total was 7.0. running mean: 6.558449093974469\n",
      "resetting env. episode reward total was 7.0. running mean: 6.562864603034724\n",
      "resetting env. episode reward total was 11.0. running mean: 6.607235957004376\n",
      "resetting env. episode reward total was 9.0. running mean: 6.631163597434332\n",
      "resetting env. episode reward total was 9.0. running mean: 6.654851961459989\n",
      "resetting env. episode reward total was 14.0. running mean: 6.728303441845388\n",
      "resetting env. episode reward total was 11.0. running mean: 6.771020407426935\n",
      "resetting env. episode reward total was 7.0. running mean: 6.773310203352666\n",
      "resetting env. episode reward total was -8.0. running mean: 6.625577101319139\n",
      "resetting env. episode reward total was 10.0. running mean: 6.659321330305947\n",
      "resetting env. episode reward total was -3.0. running mean: 6.562728117002887\n",
      "resetting env. episode reward total was 8.0. running mean: 6.577100835832859\n",
      "resetting env. episode reward total was 10.0. running mean: 6.611329827474529\n",
      "resetting env. episode reward total was 12.0. running mean: 6.6652165291997845\n",
      "resetting env. episode reward total was 6.0. running mean: 6.658564363907786\n",
      "resetting env. episode reward total was 8.0. running mean: 6.671978720268708\n",
      "resetting env. episode reward total was 12.0. running mean: 6.725258933066021\n",
      "resetting env. episode reward total was 6.0. running mean: 6.71800634373536\n",
      "resetting env. episode reward total was 2.0. running mean: 6.670826280298006\n",
      "resetting env. episode reward total was 10.0. running mean: 6.704118017495025\n",
      "resetting env. episode reward total was 8.0. running mean: 6.717076837320075\n",
      "resetting env. episode reward total was 9.0. running mean: 6.739906068946874\n",
      "resetting env. episode reward total was 3.0. running mean: 6.702507008257406\n",
      "resetting env. episode reward total was 7.0. running mean: 6.705481938174832\n",
      "resetting env. episode reward total was -7.0. running mean: 6.568427118793084\n",
      "resetting env. episode reward total was -3.0. running mean: 6.4727428476051525\n",
      "resetting env. episode reward total was 9.0. running mean: 6.498015419129101\n",
      "resetting env. episode reward total was 9.0. running mean: 6.52303526493781\n",
      "resetting env. episode reward total was 11.0. running mean: 6.567804912288432\n",
      "resetting env. episode reward total was 13.0. running mean: 6.6321268631655474\n",
      "resetting env. episode reward total was 8.0. running mean: 6.645805594533892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 6.649347538588553\n",
      "resetting env. episode reward total was 16.0. running mean: 6.7428540632026674\n",
      "resetting env. episode reward total was -4.0. running mean: 6.635425522570641\n",
      "resetting env. episode reward total was 8.0. running mean: 6.649071267344934\n",
      "resetting env. episode reward total was 8.0. running mean: 6.662580554671485\n",
      "resetting env. episode reward total was 9.0. running mean: 6.68595474912477\n",
      "resetting env. episode reward total was -9.0. running mean: 6.529095201633522\n",
      "resetting env. episode reward total was 4.0. running mean: 6.503804249617187\n",
      "resetting env. episode reward total was -5.0. running mean: 6.388766207121015\n",
      "resetting env. episode reward total was 11.0. running mean: 6.434878545049805\n",
      "resetting env. episode reward total was -1.0. running mean: 6.360529759599307\n",
      "resetting env. episode reward total was 5.0. running mean: 6.346924462003313\n",
      "resetting env. episode reward total was 2.0. running mean: 6.30345521738328\n",
      "resetting env. episode reward total was 4.0. running mean: 6.280420665209447\n",
      "resetting env. episode reward total was -1.0. running mean: 6.207616458557353\n",
      "resetting env. episode reward total was 10.0. running mean: 6.245540293971779\n",
      "resetting env. episode reward total was 11.0. running mean: 6.293084891032061\n",
      "resetting env. episode reward total was 14.0. running mean: 6.37015404212174\n",
      "resetting env. episode reward total was 17.0. running mean: 6.476452501700523\n",
      "resetting env. episode reward total was 9.0. running mean: 6.501687976683518\n",
      "resetting env. episode reward total was 16.0. running mean: 6.596671096916682\n",
      "resetting env. episode reward total was -6.0. running mean: 6.470704385947516\n",
      "resetting env. episode reward total was 6.0. running mean: 6.46599734208804\n",
      "resetting env. episode reward total was -1.0. running mean: 6.39133736866716\n",
      "resetting env. episode reward total was 9.0. running mean: 6.4174239949804885\n",
      "resetting env. episode reward total was 12.0. running mean: 6.473249755030683\n",
      "resetting env. episode reward total was 10.0. running mean: 6.508517257480376\n",
      "resetting env. episode reward total was 12.0. running mean: 6.563432084905572\n",
      "resetting env. episode reward total was 7.0. running mean: 6.567797764056516\n",
      "resetting env. episode reward total was 5.0. running mean: 6.552119786415951\n",
      "resetting env. episode reward total was 9.0. running mean: 6.576598588551792\n",
      "resetting env. episode reward total was -10.0. running mean: 6.410832602666274\n",
      "resetting env. episode reward total was 5.0. running mean: 6.3967242766396115\n",
      "resetting env. episode reward total was 5.0. running mean: 6.382757033873215\n",
      "resetting env. episode reward total was 6.0. running mean: 6.378929463534482\n",
      "resetting env. episode reward total was 13.0. running mean: 6.445140168899138\n",
      "resetting env. episode reward total was 13.0. running mean: 6.510688767210146\n",
      "resetting env. episode reward total was 4.0. running mean: 6.485581879538045\n",
      "resetting env. episode reward total was 3.0. running mean: 6.450726060742665\n",
      "resetting env. episode reward total was 14.0. running mean: 6.526218800135237\n",
      "resetting env. episode reward total was 9.0. running mean: 6.550956612133884\n",
      "resetting env. episode reward total was 10.0. running mean: 6.585447046012545\n",
      "resetting env. episode reward total was -4.0. running mean: 6.479592575552419\n",
      "resetting env. episode reward total was 8.0. running mean: 6.494796649796895\n",
      "resetting env. episode reward total was 8.0. running mean: 6.509848683298927\n",
      "resetting env. episode reward total was 8.0. running mean: 6.524750196465938\n",
      "resetting env. episode reward total was 12.0. running mean: 6.5795026945012784\n",
      "resetting env. episode reward total was 9.0. running mean: 6.603707667556265\n",
      "resetting env. episode reward total was 14.0. running mean: 6.677670590880703\n",
      "resetting env. episode reward total was 8.0. running mean: 6.690893884971896\n",
      "resetting env. episode reward total was 13.0. running mean: 6.753984946122177\n",
      "resetting env. episode reward total was 10.0. running mean: 6.786445096660954\n",
      "resetting env. episode reward total was 8.0. running mean: 6.7985806456943445\n",
      "resetting env. episode reward total was 5.0. running mean: 6.780594839237401\n",
      "resetting env. episode reward total was 11.0. running mean: 6.822788890845027\n",
      "resetting env. episode reward total was -1.0. running mean: 6.744561001936577\n",
      "resetting env. episode reward total was 11.0. running mean: 6.787115391917212\n",
      "resetting env. episode reward total was 12.0. running mean: 6.83924423799804\n",
      "resetting env. episode reward total was 6.0. running mean: 6.8308517956180586\n",
      "resetting env. episode reward total was 7.0. running mean: 6.832543277661879\n",
      "resetting env. episode reward total was 3.0. running mean: 6.79421784488526\n",
      "resetting env. episode reward total was 9.0. running mean: 6.8162756664364075\n",
      "resetting env. episode reward total was 5.0. running mean: 6.798112909772043\n",
      "resetting env. episode reward total was -2.0. running mean: 6.710131780674323\n",
      "resetting env. episode reward total was 5.0. running mean: 6.693030462867579\n",
      "resetting env. episode reward total was 7.0. running mean: 6.696100158238903\n",
      "resetting env. episode reward total was 1.0. running mean: 6.639139156656514\n",
      "resetting env. episode reward total was -12.0. running mean: 6.452747765089948\n",
      "resetting env. episode reward total was 12.0. running mean: 6.508220287439049\n",
      "resetting env. episode reward total was 2.0. running mean: 6.463138084564658\n",
      "resetting env. episode reward total was 5.0. running mean: 6.448506703719011\n",
      "resetting env. episode reward total was 1.0. running mean: 6.3940216366818206\n",
      "resetting env. episode reward total was 5.0. running mean: 6.380081420315002\n",
      "resetting env. episode reward total was 7.0. running mean: 6.386280606111852\n",
      "resetting env. episode reward total was 1.0. running mean: 6.332417800050734\n",
      "resetting env. episode reward total was 3.0. running mean: 6.2990936220502265\n",
      "resetting env. episode reward total was 13.0. running mean: 6.366102685829724\n",
      "resetting env. episode reward total was 12.0. running mean: 6.422441658971427\n",
      "resetting env. episode reward total was 4.0. running mean: 6.398217242381713\n",
      "resetting env. episode reward total was 4.0. running mean: 6.374235069957896\n",
      "resetting env. episode reward total was -1.0. running mean: 6.300492719258317\n",
      "resetting env. episode reward total was 13.0. running mean: 6.367487792065734\n",
      "resetting env. episode reward total was 2.0. running mean: 6.323812914145075\n",
      "resetting env. episode reward total was 12.0. running mean: 6.380574785003625\n",
      "resetting env. episode reward total was 9.0. running mean: 6.406769037153588\n",
      "resetting env. episode reward total was 1.0. running mean: 6.352701346782053\n",
      "resetting env. episode reward total was 7.0. running mean: 6.3591743333142325\n",
      "resetting env. episode reward total was 16.0. running mean: 6.45558258998109\n",
      "resetting env. episode reward total was 7.0. running mean: 6.4610267640812795\n",
      "resetting env. episode reward total was 4.0. running mean: 6.436416496440467\n",
      "resetting env. episode reward total was 13.0. running mean: 6.502052331476062\n",
      "resetting env. episode reward total was 13.0. running mean: 6.567031808161301\n",
      "resetting env. episode reward total was -7.0. running mean: 6.431361490079687\n",
      "resetting env. episode reward total was 13.0. running mean: 6.49704787517889\n",
      "resetting env. episode reward total was 9.0. running mean: 6.5220773964271\n",
      "resetting env. episode reward total was 9.0. running mean: 6.546856622462829\n",
      "resetting env. episode reward total was 8.0. running mean: 6.561388056238201\n",
      "resetting env. episode reward total was 5.0. running mean: 6.5457741756758185\n",
      "resetting env. episode reward total was -5.0. running mean: 6.43031643391906\n",
      "resetting env. episode reward total was 2.0. running mean: 6.386013269579869\n",
      "resetting env. episode reward total was 7.0. running mean: 6.392153136884071\n",
      "resetting env. episode reward total was 7.0. running mean: 6.39823160551523\n",
      "resetting env. episode reward total was 13.0. running mean: 6.464249289460078\n",
      "resetting env. episode reward total was -5.0. running mean: 6.349606796565477\n",
      "resetting env. episode reward total was -1.0. running mean: 6.276110728599822\n",
      "resetting env. episode reward total was 16.0. running mean: 6.3733496213138245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 6.419616125100687\n",
      "resetting env. episode reward total was 1.0. running mean: 6.365419963849679\n",
      "resetting env. episode reward total was 15.0. running mean: 6.451765764211183\n",
      "resetting env. episode reward total was 9.0. running mean: 6.477248106569071\n",
      "resetting env. episode reward total was 9.0. running mean: 6.50247562550338\n",
      "resetting env. episode reward total was -1.0. running mean: 6.4274508692483465\n",
      "resetting env. episode reward total was 11.0. running mean: 6.473176360555863\n",
      "resetting env. episode reward total was -11.0. running mean: 6.298444596950304\n",
      "resetting env. episode reward total was 13.0. running mean: 6.365460150980801\n",
      "resetting env. episode reward total was 4.0. running mean: 6.341805549470993\n",
      "resetting env. episode reward total was 10.0. running mean: 6.378387493976283\n",
      "resetting env. episode reward total was 13.0. running mean: 6.44460361903652\n",
      "resetting env. episode reward total was -5.0. running mean: 6.330157582846154\n",
      "resetting env. episode reward total was 14.0. running mean: 6.4068560070176925\n",
      "resetting env. episode reward total was 8.0. running mean: 6.422787446947516\n",
      "resetting env. episode reward total was 13.0. running mean: 6.4885595724780405\n",
      "resetting env. episode reward total was 3.0. running mean: 6.453673976753261\n",
      "resetting env. episode reward total was 13.0. running mean: 6.519137236985728\n",
      "resetting env. episode reward total was 4.0. running mean: 6.4939458646158705\n",
      "resetting env. episode reward total was 10.0. running mean: 6.529006405969711\n",
      "resetting env. episode reward total was 7.0. running mean: 6.533716341910014\n",
      "resetting env. episode reward total was 12.0. running mean: 6.588379178490914\n",
      "resetting env. episode reward total was 11.0. running mean: 6.6324953867060055\n",
      "resetting env. episode reward total was 3.0. running mean: 6.596170432838946\n",
      "resetting env. episode reward total was 8.0. running mean: 6.610208728510557\n",
      "resetting env. episode reward total was 8.0. running mean: 6.624106641225452\n",
      "resetting env. episode reward total was 9.0. running mean: 6.647865574813197\n",
      "resetting env. episode reward total was 4.0. running mean: 6.621386919065065\n",
      "resetting env. episode reward total was 11.0. running mean: 6.665173049874415\n",
      "resetting env. episode reward total was 3.0. running mean: 6.628521319375671\n",
      "resetting env. episode reward total was 8.0. running mean: 6.642236106181914\n",
      "resetting env. episode reward total was 10.0. running mean: 6.675813745120095\n",
      "resetting env. episode reward total was 8.0. running mean: 6.6890556076688945\n",
      "resetting env. episode reward total was 12.0. running mean: 6.742165051592206\n",
      "resetting env. episode reward total was 5.0. running mean: 6.724743401076283\n",
      "resetting env. episode reward total was 7.0. running mean: 6.727495967065521\n",
      "resetting env. episode reward total was 7.0. running mean: 6.730221007394866\n",
      "resetting env. episode reward total was 19.0. running mean: 6.852918797320918\n",
      "resetting env. episode reward total was 7.0. running mean: 6.854389609347709\n",
      "resetting env. episode reward total was 16.0. running mean: 6.945845713254232\n",
      "resetting env. episode reward total was -2.0. running mean: 6.85638725612169\n",
      "resetting env. episode reward total was 12.0. running mean: 6.907823383560473\n",
      "resetting env. episode reward total was 4.0. running mean: 6.878745149724868\n",
      "resetting env. episode reward total was 8.0. running mean: 6.88995769822762\n",
      "resetting env. episode reward total was 13.0. running mean: 6.951058121245343\n",
      "resetting env. episode reward total was 6.0. running mean: 6.941547540032889\n",
      "resetting env. episode reward total was 5.0. running mean: 6.92213206463256\n",
      "resetting env. episode reward total was 11.0. running mean: 6.962910743986235\n",
      "resetting env. episode reward total was 9.0. running mean: 6.983281636546373\n",
      "resetting env. episode reward total was 11.0. running mean: 7.023448820180909\n",
      "resetting env. episode reward total was 3.0. running mean: 6.9832143319791005\n",
      "resetting env. episode reward total was 12.0. running mean: 7.033382188659309\n",
      "resetting env. episode reward total was -1.0. running mean: 6.953048366772716\n",
      "resetting env. episode reward total was 11.0. running mean: 6.993517883104989\n",
      "resetting env. episode reward total was -6.0. running mean: 6.86358270427394\n",
      "resetting env. episode reward total was 5.0. running mean: 6.8449468772312\n",
      "resetting env. episode reward total was 2.0. running mean: 6.796497408458888\n",
      "resetting env. episode reward total was 4.0. running mean: 6.768532434374299\n",
      "resetting env. episode reward total was 1.0. running mean: 6.710847110030556\n",
      "resetting env. episode reward total was 13.0. running mean: 6.77373863893025\n",
      "resetting env. episode reward total was 13.0. running mean: 6.836001252540947\n",
      "resetting env. episode reward total was 16.0. running mean: 6.927641240015538\n",
      "resetting env. episode reward total was 9.0. running mean: 6.948364827615382\n",
      "resetting env. episode reward total was 8.0. running mean: 6.958881179339229\n",
      "resetting env. episode reward total was 7.0. running mean: 6.959292367545837\n",
      "resetting env. episode reward total was 3.0. running mean: 6.919699443870379\n",
      "resetting env. episode reward total was 16.0. running mean: 7.010502449431676\n",
      "resetting env. episode reward total was 15.0. running mean: 7.090397424937359\n",
      "resetting env. episode reward total was 18.0. running mean: 7.199493450687985\n",
      "resetting env. episode reward total was 12.0. running mean: 7.247498516181105\n",
      "resetting env. episode reward total was 7.0. running mean: 7.245023531019294\n",
      "resetting env. episode reward total was 8.0. running mean: 7.252573295709102\n",
      "resetting env. episode reward total was 4.0. running mean: 7.22004756275201\n",
      "resetting env. episode reward total was 13.0. running mean: 7.27784708712449\n",
      "resetting env. episode reward total was 9.0. running mean: 7.295068616253245\n",
      "resetting env. episode reward total was 7.0. running mean: 7.292117930090713\n",
      "resetting env. episode reward total was 8.0. running mean: 7.299196750789806\n",
      "resetting env. episode reward total was 7.0. running mean: 7.296204783281908\n",
      "resetting env. episode reward total was 12.0. running mean: 7.343242735449089\n",
      "resetting env. episode reward total was 5.0. running mean: 7.319810308094598\n",
      "resetting env. episode reward total was 16.0. running mean: 7.406612205013652\n",
      "resetting env. episode reward total was 7.0. running mean: 7.402546082963516\n",
      "resetting env. episode reward total was 11.0. running mean: 7.438520622133881\n",
      "resetting env. episode reward total was 11.0. running mean: 7.474135415912542\n",
      "resetting env. episode reward total was 10.0. running mean: 7.499394061753416\n",
      "resetting env. episode reward total was -1.0. running mean: 7.414400121135882\n",
      "resetting env. episode reward total was 2.0. running mean: 7.360256119924523\n",
      "resetting env. episode reward total was 13.0. running mean: 7.416653558725278\n",
      "resetting env. episode reward total was -1.0. running mean: 7.332487023138025\n",
      "resetting env. episode reward total was 10.0. running mean: 7.359162152906644\n",
      "resetting env. episode reward total was 5.0. running mean: 7.335570531377577\n",
      "resetting env. episode reward total was 8.0. running mean: 7.342214826063802\n",
      "resetting env. episode reward total was -1.0. running mean: 7.2587926778031635\n",
      "resetting env. episode reward total was 4.0. running mean: 7.226204751025132\n",
      "resetting env. episode reward total was 2.0. running mean: 7.17394270351488\n",
      "resetting env. episode reward total was 2.0. running mean: 7.122203276479731\n",
      "resetting env. episode reward total was 9.0. running mean: 7.140981243714934\n",
      "resetting env. episode reward total was 11.0. running mean: 7.179571431277784\n",
      "resetting env. episode reward total was -1.0. running mean: 7.097775716965007\n",
      "resetting env. episode reward total was 9.0. running mean: 7.116797959795357\n",
      "resetting env. episode reward total was 2.0. running mean: 7.065629980197403\n",
      "resetting env. episode reward total was 8.0. running mean: 7.074973680395429\n",
      "resetting env. episode reward total was 6.0. running mean: 7.064223943591474\n",
      "resetting env. episode reward total was 2.0. running mean: 7.013581704155559\n",
      "resetting env. episode reward total was 5.0. running mean: 6.993445887114003\n",
      "resetting env. episode reward total was 13.0. running mean: 7.053511428242863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: 7.012976313960435\n",
      "resetting env. episode reward total was 2.0. running mean: 6.96284655082083\n",
      "resetting env. episode reward total was 11.0. running mean: 7.003218085312621\n",
      "resetting env. episode reward total was 12.0. running mean: 7.053185904459495\n",
      "resetting env. episode reward total was -7.0. running mean: 6.912654045414899\n",
      "resetting env. episode reward total was 9.0. running mean: 6.93352750496075\n",
      "resetting env. episode reward total was 9.0. running mean: 6.9541922299111425\n",
      "resetting env. episode reward total was 11.0. running mean: 6.994650307612031\n",
      "resetting env. episode reward total was -1.0. running mean: 6.914703804535911\n",
      "resetting env. episode reward total was 12.0. running mean: 6.965556766490552\n",
      "resetting env. episode reward total was 4.0. running mean: 6.935901198825647\n",
      "resetting env. episode reward total was 11.0. running mean: 6.976542186837391\n",
      "resetting env. episode reward total was 9.0. running mean: 6.996776764969017\n",
      "resetting env. episode reward total was 13.0. running mean: 7.056808997319326\n",
      "resetting env. episode reward total was 7.0. running mean: 7.056240907346133\n",
      "resetting env. episode reward total was 5.0. running mean: 7.035678498272672\n",
      "resetting env. episode reward total was 11.0. running mean: 7.075321713289945\n",
      "resetting env. episode reward total was 7.0. running mean: 7.074568496157045\n",
      "resetting env. episode reward total was 9.0. running mean: 7.093822811195475\n",
      "resetting env. episode reward total was 17.0. running mean: 7.1928845830835195\n",
      "resetting env. episode reward total was 4.0. running mean: 7.160955737252684\n",
      "resetting env. episode reward total was 5.0. running mean: 7.139346179880157\n",
      "resetting env. episode reward total was 6.0. running mean: 7.127952718081355\n",
      "resetting env. episode reward total was 6.0. running mean: 7.116673190900541\n",
      "resetting env. episode reward total was 13.0. running mean: 7.175506458991536\n",
      "resetting env. episode reward total was -4.0. running mean: 7.063751394401621\n",
      "resetting env. episode reward total was 5.0. running mean: 7.043113880457605\n",
      "resetting env. episode reward total was 6.0. running mean: 7.032682741653028\n",
      "resetting env. episode reward total was -7.0. running mean: 6.892355914236497\n",
      "resetting env. episode reward total was -2.0. running mean: 6.803432355094133\n",
      "resetting env. episode reward total was 12.0. running mean: 6.855398031543191\n",
      "resetting env. episode reward total was 5.0. running mean: 6.836844051227759\n",
      "resetting env. episode reward total was -5.0. running mean: 6.7184756107154815\n",
      "resetting env. episode reward total was 14.0. running mean: 6.791290854608326\n",
      "resetting env. episode reward total was 7.0. running mean: 6.793377946062243\n",
      "resetting env. episode reward total was 13.0. running mean: 6.855444166601621\n",
      "resetting env. episode reward total was 6.0. running mean: 6.846889724935604\n",
      "resetting env. episode reward total was 5.0. running mean: 6.828420827686248\n",
      "resetting env. episode reward total was 1.0. running mean: 6.770136619409385\n",
      "resetting env. episode reward total was 8.0. running mean: 6.782435253215291\n",
      "resetting env. episode reward total was 2.0. running mean: 6.734610900683138\n",
      "resetting env. episode reward total was 6.0. running mean: 6.727264791676306\n",
      "resetting env. episode reward total was 9.0. running mean: 6.749992143759543\n",
      "resetting env. episode reward total was 5.0. running mean: 6.732492222321947\n",
      "resetting env. episode reward total was 8.0. running mean: 6.745167300098728\n",
      "resetting env. episode reward total was 15.0. running mean: 6.82771562709774\n",
      "resetting env. episode reward total was 2.0. running mean: 6.779438470826762\n",
      "resetting env. episode reward total was 8.0. running mean: 6.791644086118494\n",
      "resetting env. episode reward total was -1.0. running mean: 6.713727645257309\n",
      "resetting env. episode reward total was 14.0. running mean: 6.7865903688047355\n",
      "resetting env. episode reward total was -3.0. running mean: 6.688724465116688\n",
      "resetting env. episode reward total was 15.0. running mean: 6.771837220465521\n",
      "resetting env. episode reward total was 9.0. running mean: 6.794118848260865\n",
      "resetting env. episode reward total was 15.0. running mean: 6.876177659778257\n",
      "resetting env. episode reward total was -1.0. running mean: 6.7974158831804745\n",
      "resetting env. episode reward total was 8.0. running mean: 6.80944172434867\n",
      "resetting env. episode reward total was -1.0. running mean: 6.731347307105183\n",
      "resetting env. episode reward total was 6.0. running mean: 6.72403383403413\n",
      "resetting env. episode reward total was 4.0. running mean: 6.696793495693789\n",
      "resetting env. episode reward total was 12.0. running mean: 6.749825560736851\n",
      "resetting env. episode reward total was 8.0. running mean: 6.7623273051294825\n",
      "resetting env. episode reward total was 3.0. running mean: 6.724704032078188\n",
      "resetting env. episode reward total was 10.0. running mean: 6.757456991757405\n",
      "resetting env. episode reward total was -3.0. running mean: 6.659882421839831\n",
      "resetting env. episode reward total was 11.0. running mean: 6.703283597621433\n",
      "resetting env. episode reward total was 12.0. running mean: 6.7562507616452185\n",
      "resetting env. episode reward total was 16.0. running mean: 6.848688254028766\n",
      "resetting env. episode reward total was 1.0. running mean: 6.790201371488478\n",
      "resetting env. episode reward total was 8.0. running mean: 6.8022993577735935\n",
      "resetting env. episode reward total was 6.0. running mean: 6.7942763641958575\n",
      "resetting env. episode reward total was -2.0. running mean: 6.706333600553899\n",
      "resetting env. episode reward total was 3.0. running mean: 6.66927026454836\n",
      "resetting env. episode reward total was 10.0. running mean: 6.702577561902876\n",
      "resetting env. episode reward total was 11.0. running mean: 6.745551786283848\n",
      "resetting env. episode reward total was 5.0. running mean: 6.728096268421009\n",
      "resetting env. episode reward total was 11.0. running mean: 6.770815305736799\n",
      "resetting env. episode reward total was 13.0. running mean: 6.833107152679431\n",
      "resetting env. episode reward total was 10.0. running mean: 6.864776081152637\n",
      "resetting env. episode reward total was -5.0. running mean: 6.746128320341111\n",
      "resetting env. episode reward total was 5.0. running mean: 6.728667037137699\n",
      "resetting env. episode reward total was 14.0. running mean: 6.801380366766321\n",
      "resetting env. episode reward total was -3.0. running mean: 6.703366563098657\n",
      "resetting env. episode reward total was 11.0. running mean: 6.7463328974676715\n",
      "resetting env. episode reward total was 12.0. running mean: 6.798869568492995\n",
      "resetting env. episode reward total was 8.0. running mean: 6.810880872808065\n",
      "resetting env. episode reward total was 12.0. running mean: 6.8627720640799845\n",
      "resetting env. episode reward total was 4.0. running mean: 6.834144343439185\n",
      "resetting env. episode reward total was 5.0. running mean: 6.815802900004793\n",
      "resetting env. episode reward total was 10.0. running mean: 6.847644871004745\n",
      "resetting env. episode reward total was 7.0. running mean: 6.849168422294698\n",
      "resetting env. episode reward total was 5.0. running mean: 6.830676738071751\n",
      "resetting env. episode reward total was -8.0. running mean: 6.682369970691033\n",
      "resetting env. episode reward total was -3.0. running mean: 6.585546270984122\n",
      "resetting env. episode reward total was 14.0. running mean: 6.659690808274281\n",
      "resetting env. episode reward total was 6.0. running mean: 6.6530939001915375\n",
      "resetting env. episode reward total was 7.0. running mean: 6.656562961189622\n",
      "resetting env. episode reward total was 3.0. running mean: 6.619997331577726\n",
      "resetting env. episode reward total was 8.0. running mean: 6.6337973582619485\n",
      "resetting env. episode reward total was 5.0. running mean: 6.617459384679329\n",
      "resetting env. episode reward total was -2.0. running mean: 6.531284790832536\n",
      "resetting env. episode reward total was -1.0. running mean: 6.455971942924211\n",
      "resetting env. episode reward total was 4.0. running mean: 6.431412223494968\n",
      "resetting env. episode reward total was 7.0. running mean: 6.437098101260019\n",
      "resetting env. episode reward total was 7.0. running mean: 6.442727120247419\n",
      "resetting env. episode reward total was 10.0. running mean: 6.478299849044944\n",
      "resetting env. episode reward total was 6.0. running mean: 6.473516850554494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 6.478781682048949\n",
      "resetting env. episode reward total was 6.0. running mean: 6.47399386522846\n",
      "resetting env. episode reward total was 7.0. running mean: 6.479253926576176\n",
      "resetting env. episode reward total was -1.0. running mean: 6.404461387310414\n",
      "resetting env. episode reward total was 13.0. running mean: 6.47041677343731\n",
      "resetting env. episode reward total was 7.0. running mean: 6.475712605702937\n",
      "resetting env. episode reward total was 3.0. running mean: 6.4409554796459085\n",
      "resetting env. episode reward total was 7.0. running mean: 6.44654592484945\n",
      "resetting env. episode reward total was 15.0. running mean: 6.532080465600956\n",
      "resetting env. episode reward total was 3.0. running mean: 6.496759660944947\n",
      "resetting env. episode reward total was 9.0. running mean: 6.521792064335497\n",
      "resetting env. episode reward total was 2.0. running mean: 6.476574143692142\n",
      "resetting env. episode reward total was 5.0. running mean: 6.461808402255221\n",
      "resetting env. episode reward total was -2.0. running mean: 6.377190318232669\n",
      "resetting env. episode reward total was 12.0. running mean: 6.433418415050342\n",
      "resetting env. episode reward total was 10.0. running mean: 6.469084230899838\n",
      "resetting env. episode reward total was 5.0. running mean: 6.45439338859084\n",
      "resetting env. episode reward total was 9.0. running mean: 6.479849454704931\n",
      "resetting env. episode reward total was 16.0. running mean: 6.575050960157882\n",
      "resetting env. episode reward total was 9.0. running mean: 6.599300450556303\n",
      "resetting env. episode reward total was -3.0. running mean: 6.50330744605074\n",
      "resetting env. episode reward total was 4.0. running mean: 6.478274371590232\n",
      "resetting env. episode reward total was 13.0. running mean: 6.54349162787433\n",
      "resetting env. episode reward total was 7.0. running mean: 6.548056711595587\n",
      "resetting env. episode reward total was 13.0. running mean: 6.612576144479631\n",
      "resetting env. episode reward total was 9.0. running mean: 6.636450383034834\n",
      "resetting env. episode reward total was 6.0. running mean: 6.630085879204485\n",
      "resetting env. episode reward total was 1.0. running mean: 6.573785020412441\n",
      "resetting env. episode reward total was 11.0. running mean: 6.618047170208317\n",
      "resetting env. episode reward total was 7.0. running mean: 6.621866698506234\n",
      "resetting env. episode reward total was 12.0. running mean: 6.675648031521172\n",
      "resetting env. episode reward total was 11.0. running mean: 6.718891551205961\n",
      "resetting env. episode reward total was 5.0. running mean: 6.701702635693901\n",
      "resetting env. episode reward total was 8.0. running mean: 6.7146856093369625\n",
      "resetting env. episode reward total was 4.0. running mean: 6.687538753243593\n",
      "resetting env. episode reward total was -3.0. running mean: 6.590663365711157\n",
      "resetting env. episode reward total was 4.0. running mean: 6.564756732054045\n",
      "resetting env. episode reward total was 13.0. running mean: 6.629109164733505\n",
      "resetting env. episode reward total was 5.0. running mean: 6.61281807308617\n",
      "resetting env. episode reward total was 3.0. running mean: 6.576689892355309\n",
      "resetting env. episode reward total was 5.0. running mean: 6.560922993431755\n",
      "resetting env. episode reward total was 11.0. running mean: 6.605313763497438\n",
      "resetting env. episode reward total was 15.0. running mean: 6.689260625862464\n",
      "resetting env. episode reward total was 7.0. running mean: 6.6923680196038395\n",
      "resetting env. episode reward total was 5.0. running mean: 6.675444339407801\n",
      "resetting env. episode reward total was 4.0. running mean: 6.648689896013723\n",
      "resetting env. episode reward total was 8.0. running mean: 6.662202997053585\n",
      "resetting env. episode reward total was -4.0. running mean: 6.555580967083049\n",
      "resetting env. episode reward total was 7.0. running mean: 6.560025157412219\n",
      "resetting env. episode reward total was 8.0. running mean: 6.574424905838097\n",
      "resetting env. episode reward total was -2.0. running mean: 6.488680656779716\n",
      "resetting env. episode reward total was 9.0. running mean: 6.513793850211919\n",
      "resetting env. episode reward total was 8.0. running mean: 6.5286559117098\n",
      "resetting env. episode reward total was 2.0. running mean: 6.483369352592701\n",
      "resetting env. episode reward total was 8.0. running mean: 6.498535659066774\n",
      "resetting env. episode reward total was 10.0. running mean: 6.5335503024761055\n",
      "resetting env. episode reward total was 17.0. running mean: 6.638214799451344\n",
      "resetting env. episode reward total was 4.0. running mean: 6.61183265145683\n",
      "resetting env. episode reward total was 13.0. running mean: 6.675714324942262\n",
      "resetting env. episode reward total was 6.0. running mean: 6.668957181692838\n",
      "resetting env. episode reward total was 7.0. running mean: 6.67226760987591\n",
      "resetting env. episode reward total was 9.0. running mean: 6.695544933777151\n",
      "resetting env. episode reward total was 11.0. running mean: 6.738589484439379\n",
      "resetting env. episode reward total was 14.0. running mean: 6.811203589594985\n",
      "resetting env. episode reward total was -1.0. running mean: 6.733091553699036\n",
      "resetting env. episode reward total was 2.0. running mean: 6.685760638162045\n",
      "resetting env. episode reward total was 11.0. running mean: 6.728903031780425\n",
      "resetting env. episode reward total was -5.0. running mean: 6.6116140014626215\n",
      "resetting env. episode reward total was -1.0. running mean: 6.535497861447995\n",
      "resetting env. episode reward total was 5.0. running mean: 6.520142882833515\n",
      "resetting env. episode reward total was 8.0. running mean: 6.534941454005179\n",
      "resetting env. episode reward total was 11.0. running mean: 6.579592039465128\n",
      "resetting env. episode reward total was 11.0. running mean: 6.623796119070477\n",
      "resetting env. episode reward total was 16.0. running mean: 6.717558157879772\n",
      "resetting env. episode reward total was 7.0. running mean: 6.720382576300974\n",
      "resetting env. episode reward total was -1.0. running mean: 6.643178750537964\n",
      "resetting env. episode reward total was 7.0. running mean: 6.646746963032585\n",
      "resetting env. episode reward total was 7.0. running mean: 6.650279493402259\n",
      "resetting env. episode reward total was 7.0. running mean: 6.653776698468237\n",
      "resetting env. episode reward total was 1.0. running mean: 6.597238931483554\n",
      "resetting env. episode reward total was 10.0. running mean: 6.631266542168718\n",
      "resetting env. episode reward total was 15.0. running mean: 6.714953876747031\n",
      "resetting env. episode reward total was 5.0. running mean: 6.69780433797956\n",
      "resetting env. episode reward total was 8.0. running mean: 6.710826294599765\n",
      "resetting env. episode reward total was 6.0. running mean: 6.703718031653767\n",
      "resetting env. episode reward total was -3.0. running mean: 6.606680851337229\n",
      "resetting env. episode reward total was 5.0. running mean: 6.590614042823857\n",
      "resetting env. episode reward total was 6.0. running mean: 6.584707902395618\n",
      "resetting env. episode reward total was 3.0. running mean: 6.548860823371662\n",
      "resetting env. episode reward total was -9.0. running mean: 6.393372215137945\n",
      "resetting env. episode reward total was 13.0. running mean: 6.459438492986566\n",
      "resetting env. episode reward total was 2.0. running mean: 6.4148441080567\n",
      "resetting env. episode reward total was 12.0. running mean: 6.470695666976133\n",
      "resetting env. episode reward total was 6.0. running mean: 6.465988710306371\n",
      "resetting env. episode reward total was 5.0. running mean: 6.4513288232033075\n",
      "resetting env. episode reward total was -1.0. running mean: 6.376815534971275\n",
      "resetting env. episode reward total was 1.0. running mean: 6.323047379621562\n",
      "resetting env. episode reward total was 4.0. running mean: 6.299816905825346\n",
      "resetting env. episode reward total was 14.0. running mean: 6.376818736767092\n",
      "resetting env. episode reward total was 14.0. running mean: 6.45305054939942\n",
      "resetting env. episode reward total was 7.0. running mean: 6.458520043905426\n",
      "resetting env. episode reward total was 5.0. running mean: 6.443934843466372\n",
      "resetting env. episode reward total was 3.0. running mean: 6.409495495031709\n",
      "resetting env. episode reward total was -3.0. running mean: 6.3154005400813915\n",
      "resetting env. episode reward total was 2.0. running mean: 6.272246534680577\n",
      "resetting env. episode reward total was 14.0. running mean: 6.349524069333771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 6.356028828640434\n",
      "resetting env. episode reward total was 13.0. running mean: 6.422468540354029\n",
      "resetting env. episode reward total was 13.0. running mean: 6.488243854950489\n",
      "resetting env. episode reward total was 1.0. running mean: 6.433361416400984\n",
      "resetting env. episode reward total was 4.0. running mean: 6.409027802236974\n",
      "resetting env. episode reward total was 6.0. running mean: 6.404937524214604\n",
      "resetting env. episode reward total was -1.0. running mean: 6.330888148972457\n",
      "resetting env. episode reward total was -2.0. running mean: 6.247579267482733\n",
      "resetting env. episode reward total was 1.0. running mean: 6.1951034748079055\n",
      "resetting env. episode reward total was 7.0. running mean: 6.203152440059827\n",
      "resetting env. episode reward total was 13.0. running mean: 6.271120915659228\n",
      "resetting env. episode reward total was -5.0. running mean: 6.158409706502636\n",
      "resetting env. episode reward total was 3.0. running mean: 6.12682560943761\n",
      "resetting env. episode reward total was 9.0. running mean: 6.155557353343234\n",
      "resetting env. episode reward total was -1.0. running mean: 6.084001779809801\n",
      "resetting env. episode reward total was 9.0. running mean: 6.113161762011703\n",
      "resetting env. episode reward total was 4.0. running mean: 6.092030144391586\n",
      "resetting env. episode reward total was 2.0. running mean: 6.051109842947669\n",
      "resetting env. episode reward total was 8.0. running mean: 6.070598744518192\n",
      "resetting env. episode reward total was 4.0. running mean: 6.04989275707301\n",
      "resetting env. episode reward total was 10.0. running mean: 6.08939382950228\n",
      "resetting env. episode reward total was 4.0. running mean: 6.0684998912072565\n",
      "resetting env. episode reward total was 3.0. running mean: 6.037814892295184\n",
      "resetting env. episode reward total was -1.0. running mean: 5.967436743372232\n",
      "resetting env. episode reward total was -3.0. running mean: 5.877762375938509\n",
      "resetting env. episode reward total was 2.0. running mean: 5.838984752179123\n",
      "resetting env. episode reward total was 11.0. running mean: 5.890594904657332\n",
      "resetting env. episode reward total was 8.0. running mean: 5.911688955610759\n",
      "resetting env. episode reward total was -3.0. running mean: 5.822572066054652\n",
      "resetting env. episode reward total was 9.0. running mean: 5.854346345394105\n",
      "resetting env. episode reward total was 12.0. running mean: 5.915802881940164\n",
      "resetting env. episode reward total was 6.0. running mean: 5.916644853120761\n",
      "resetting env. episode reward total was -4.0. running mean: 5.817478404589553\n",
      "resetting env. episode reward total was 7.0. running mean: 5.829303620543658\n",
      "resetting env. episode reward total was -8.0. running mean: 5.691010584338221\n",
      "resetting env. episode reward total was 5.0. running mean: 5.684100478494838\n",
      "resetting env. episode reward total was 7.0. running mean: 5.69725947370989\n",
      "resetting env. episode reward total was 6.0. running mean: 5.700286878972791\n",
      "resetting env. episode reward total was -1.0. running mean: 5.633284010183063\n",
      "resetting env. episode reward total was 3.0. running mean: 5.606951170081232\n",
      "resetting env. episode reward total was 8.0. running mean: 5.63088165838042\n",
      "resetting env. episode reward total was -3.0. running mean: 5.544572841796615\n",
      "resetting env. episode reward total was -3.0. running mean: 5.459127113378648\n",
      "resetting env. episode reward total was 5.0. running mean: 5.454535842244861\n",
      "resetting env. episode reward total was 2.0. running mean: 5.419990483822413\n",
      "resetting env. episode reward total was 6.0. running mean: 5.425790578984188\n",
      "resetting env. episode reward total was 3.0. running mean: 5.401532673194346\n",
      "resetting env. episode reward total was 3.0. running mean: 5.377517346462403\n",
      "resetting env. episode reward total was 10.0. running mean: 5.423742172997779\n",
      "resetting env. episode reward total was 14.0. running mean: 5.509504751267801\n",
      "resetting env. episode reward total was 12.0. running mean: 5.574409703755123\n",
      "resetting env. episode reward total was 5.0. running mean: 5.5686656067175715\n",
      "resetting env. episode reward total was 10.0. running mean: 5.612978950650396\n",
      "resetting env. episode reward total was 10.0. running mean: 5.656849161143891\n",
      "resetting env. episode reward total was 6.0. running mean: 5.660280669532452\n",
      "resetting env. episode reward total was 9.0. running mean: 5.693677862837127\n",
      "resetting env. episode reward total was 7.0. running mean: 5.7067410842087565\n",
      "resetting env. episode reward total was 1.0. running mean: 5.659673673366669\n",
      "resetting env. episode reward total was -3.0. running mean: 5.573076936633002\n",
      "resetting env. episode reward total was 4.0. running mean: 5.5573461672666715\n",
      "resetting env. episode reward total was 1.0. running mean: 5.511772705594004\n",
      "resetting env. episode reward total was -6.0. running mean: 5.396654978538065\n",
      "resetting env. episode reward total was 16.0. running mean: 5.502688428752684\n",
      "resetting env. episode reward total was 3.0. running mean: 5.477661544465158\n",
      "resetting env. episode reward total was 1.0. running mean: 5.4328849290205055\n",
      "resetting env. episode reward total was -3.0. running mean: 5.3485560797303\n",
      "resetting env. episode reward total was 7.0. running mean: 5.365070518932997\n",
      "resetting env. episode reward total was 5.0. running mean: 5.361419813743667\n",
      "resetting env. episode reward total was 9.0. running mean: 5.39780561560623\n",
      "resetting env. episode reward total was 13.0. running mean: 5.473827559450167\n",
      "resetting env. episode reward total was 9.0. running mean: 5.5090892838556655\n",
      "resetting env. episode reward total was 2.0. running mean: 5.473998391017108\n",
      "resetting env. episode reward total was 6.0. running mean: 5.479258407106937\n",
      "resetting env. episode reward total was 5.0. running mean: 5.474465823035867\n",
      "resetting env. episode reward total was 14.0. running mean: 5.5597211648055085\n",
      "resetting env. episode reward total was 5.0. running mean: 5.554123953157453\n",
      "resetting env. episode reward total was 9.0. running mean: 5.588582713625878\n",
      "resetting env. episode reward total was -1.0. running mean: 5.522696886489619\n",
      "resetting env. episode reward total was 2.0. running mean: 5.487469917624723\n",
      "resetting env. episode reward total was 8.0. running mean: 5.512595218448475\n",
      "resetting env. episode reward total was 10.0. running mean: 5.557469266263991\n",
      "resetting env. episode reward total was 13.0. running mean: 5.63189457360135\n",
      "resetting env. episode reward total was 1.0. running mean: 5.585575627865337\n",
      "resetting env. episode reward total was 10.0. running mean: 5.629719871586683\n",
      "resetting env. episode reward total was 13.0. running mean: 5.703422672870817\n",
      "resetting env. episode reward total was 15.0. running mean: 5.7963884461421085\n",
      "resetting env. episode reward total was -3.0. running mean: 5.708424561680687\n",
      "resetting env. episode reward total was 4.0. running mean: 5.69134031606388\n",
      "resetting env. episode reward total was 3.0. running mean: 5.664426912903242\n",
      "resetting env. episode reward total was 10.0. running mean: 5.707782643774209\n",
      "resetting env. episode reward total was 15.0. running mean: 5.8007048173364675\n",
      "resetting env. episode reward total was 12.0. running mean: 5.862697769163103\n",
      "resetting env. episode reward total was 11.0. running mean: 5.914070791471472\n",
      "resetting env. episode reward total was 4.0. running mean: 5.8949300835567575\n",
      "resetting env. episode reward total was 10.0. running mean: 5.93598078272119\n",
      "resetting env. episode reward total was 8.0. running mean: 5.956620974893978\n",
      "resetting env. episode reward total was 2.0. running mean: 5.917054765145037\n",
      "resetting env. episode reward total was 1.0. running mean: 5.867884217493587\n",
      "resetting env. episode reward total was 8.0. running mean: 5.889205375318651\n",
      "resetting env. episode reward total was 4.0. running mean: 5.870313321565464\n",
      "resetting env. episode reward total was 7.0. running mean: 5.88161018834981\n",
      "resetting env. episode reward total was -8.0. running mean: 5.742794086466311\n",
      "resetting env. episode reward total was 6.0. running mean: 5.745366145601648\n",
      "resetting env. episode reward total was 4.0. running mean: 5.727912484145631\n",
      "resetting env. episode reward total was 10.0. running mean: 5.770633359304174\n",
      "resetting env. episode reward total was 11.0. running mean: 5.822927025711133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -2.0. running mean: 5.7446977554540215\n",
      "resetting env. episode reward total was 8.0. running mean: 5.7672507778994815\n",
      "resetting env. episode reward total was 5.0. running mean: 5.759578270120486\n",
      "resetting env. episode reward total was 6.0. running mean: 5.761982487419281\n",
      "resetting env. episode reward total was 10.0. running mean: 5.8043626625450875\n",
      "resetting env. episode reward total was 6.0. running mean: 5.806319035919636\n",
      "resetting env. episode reward total was 6.0. running mean: 5.808255845560439\n",
      "resetting env. episode reward total was 3.0. running mean: 5.7801732871048355\n",
      "resetting env. episode reward total was 10.0. running mean: 5.822371554233786\n",
      "resetting env. episode reward total was -7.0. running mean: 5.694147838691448\n",
      "resetting env. episode reward total was -3.0. running mean: 5.6072063603045335\n",
      "resetting env. episode reward total was 2.0. running mean: 5.571134296701488\n",
      "resetting env. episode reward total was 10.0. running mean: 5.615422953734472\n",
      "resetting env. episode reward total was -5.0. running mean: 5.509268724197128\n",
      "resetting env. episode reward total was 5.0. running mean: 5.5041760369551564\n",
      "resetting env. episode reward total was 14.0. running mean: 5.589134276585605\n",
      "resetting env. episode reward total was 6.0. running mean: 5.593242933819748\n",
      "resetting env. episode reward total was 6.0. running mean: 5.59731050448155\n",
      "resetting env. episode reward total was 5.0. running mean: 5.591337399436735\n",
      "resetting env. episode reward total was 1.0. running mean: 5.545424025442367\n",
      "resetting env. episode reward total was 4.0. running mean: 5.5299697851879435\n",
      "resetting env. episode reward total was 14.0. running mean: 5.614670087336064\n",
      "resetting env. episode reward total was 5.0. running mean: 5.6085233864627035\n",
      "resetting env. episode reward total was -4.0. running mean: 5.512438152598077\n",
      "resetting env. episode reward total was 4.0. running mean: 5.497313771072096\n",
      "resetting env. episode reward total was 9.0. running mean: 5.5323406333613745\n",
      "resetting env. episode reward total was 6.0. running mean: 5.537017227027761\n",
      "resetting env. episode reward total was 8.0. running mean: 5.561647054757483\n",
      "resetting env. episode reward total was 6.0. running mean: 5.566030584209908\n",
      "resetting env. episode reward total was -1.0. running mean: 5.500370278367809\n",
      "resetting env. episode reward total was 4.0. running mean: 5.4853665755841305\n",
      "resetting env. episode reward total was 11.0. running mean: 5.54051290982829\n",
      "resetting env. episode reward total was 2.0. running mean: 5.505107780730007\n",
      "resetting env. episode reward total was 11.0. running mean: 5.560056702922707\n",
      "resetting env. episode reward total was 2.0. running mean: 5.524456135893479\n",
      "resetting env. episode reward total was 13.0. running mean: 5.599211574534545\n",
      "resetting env. episode reward total was 12.0. running mean: 5.663219458789199\n",
      "resetting env. episode reward total was 6.0. running mean: 5.666587264201307\n",
      "resetting env. episode reward total was 9.0. running mean: 5.699921391559293\n",
      "resetting env. episode reward total was 7.0. running mean: 5.7129221776437005\n",
      "resetting env. episode reward total was 7.0. running mean: 5.725792955867264\n",
      "resetting env. episode reward total was 3.0. running mean: 5.698535026308591\n",
      "resetting env. episode reward total was 3.0. running mean: 5.6715496760455055\n",
      "resetting env. episode reward total was -1.0. running mean: 5.60483417928505\n",
      "resetting env. episode reward total was 6.0. running mean: 5.608785837492199\n",
      "resetting env. episode reward total was 5.0. running mean: 5.602697979117277\n",
      "resetting env. episode reward total was 5.0. running mean: 5.596670999326104\n",
      "resetting env. episode reward total was 2.0. running mean: 5.560704289332842\n",
      "resetting env. episode reward total was 7.0. running mean: 5.5750972464395145\n",
      "resetting env. episode reward total was 4.0. running mean: 5.55934627397512\n",
      "resetting env. episode reward total was 14.0. running mean: 5.643752811235368\n",
      "resetting env. episode reward total was 2.0. running mean: 5.607315283123014\n",
      "resetting env. episode reward total was 8.0. running mean: 5.631242130291784\n",
      "resetting env. episode reward total was 6.0. running mean: 5.6349297089888655\n",
      "resetting env. episode reward total was 12.0. running mean: 5.698580411898977\n",
      "resetting env. episode reward total was -5.0. running mean: 5.591594607779987\n",
      "resetting env. episode reward total was 5.0. running mean: 5.585678661702187\n",
      "resetting env. episode reward total was 13.0. running mean: 5.659821875085165\n",
      "resetting env. episode reward total was 10.0. running mean: 5.7032236563343135\n",
      "resetting env. episode reward total was 11.0. running mean: 5.75619141977097\n",
      "resetting env. episode reward total was 3.0. running mean: 5.72862950557326\n",
      "resetting env. episode reward total was -4.0. running mean: 5.631343210517528\n",
      "resetting env. episode reward total was 5.0. running mean: 5.625029778412353\n",
      "resetting env. episode reward total was 4.0. running mean: 5.608779480628229\n",
      "resetting env. episode reward total was 12.0. running mean: 5.672691685821947\n",
      "resetting env. episode reward total was 7.0. running mean: 5.685964768963728\n",
      "resetting env. episode reward total was 1.0. running mean: 5.63910512127409\n",
      "resetting env. episode reward total was -2.0. running mean: 5.562714070061349\n",
      "resetting env. episode reward total was 9.0. running mean: 5.597086929360736\n",
      "resetting env. episode reward total was 9.0. running mean: 5.631116060067129\n",
      "resetting env. episode reward total was 5.0. running mean: 5.624804899466457\n",
      "resetting env. episode reward total was 8.0. running mean: 5.648556850471793\n",
      "resetting env. episode reward total was -1.0. running mean: 5.582071281967075\n",
      "resetting env. episode reward total was 10.0. running mean: 5.626250569147404\n",
      "resetting env. episode reward total was 3.0. running mean: 5.59998806345593\n",
      "resetting env. episode reward total was 3.0. running mean: 5.573988182821371\n",
      "resetting env. episode reward total was 15.0. running mean: 5.668248300993158\n",
      "resetting env. episode reward total was -1.0. running mean: 5.601565817983226\n",
      "resetting env. episode reward total was 15.0. running mean: 5.695550159803394\n",
      "resetting env. episode reward total was -3.0. running mean: 5.6085946582053605\n",
      "resetting env. episode reward total was 10.0. running mean: 5.652508711623306\n",
      "resetting env. episode reward total was 7.0. running mean: 5.665983624507073\n",
      "resetting env. episode reward total was 6.0. running mean: 5.669323788262002\n",
      "resetting env. episode reward total was 1.0. running mean: 5.622630550379381\n",
      "resetting env. episode reward total was 9.0. running mean: 5.656404244875588\n",
      "resetting env. episode reward total was -7.0. running mean: 5.529840202426831\n",
      "resetting env. episode reward total was -3.0. running mean: 5.444541800402562\n",
      "resetting env. episode reward total was 12.0. running mean: 5.510096382398537\n",
      "resetting env. episode reward total was 2.0. running mean: 5.474995418574551\n",
      "resetting env. episode reward total was -9.0. running mean: 5.330245464388805\n",
      "resetting env. episode reward total was 3.0. running mean: 5.306943009744917\n",
      "resetting env. episode reward total was 10.0. running mean: 5.353873579647468\n",
      "resetting env. episode reward total was 4.0. running mean: 5.340334843850993\n",
      "resetting env. episode reward total was 1.0. running mean: 5.296931495412482\n",
      "resetting env. episode reward total was 9.0. running mean: 5.333962180458357\n",
      "resetting env. episode reward total was 8.0. running mean: 5.360622558653774\n",
      "resetting env. episode reward total was 8.0. running mean: 5.387016333067236\n",
      "resetting env. episode reward total was 8.0. running mean: 5.413146169736564\n",
      "resetting env. episode reward total was 12.0. running mean: 5.479014708039198\n",
      "resetting env. episode reward total was 6.0. running mean: 5.484224560958806\n",
      "resetting env. episode reward total was 5.0. running mean: 5.479382315349217\n",
      "resetting env. episode reward total was 9.0. running mean: 5.514588492195725\n",
      "resetting env. episode reward total was 11.0. running mean: 5.569442607273768\n",
      "resetting env. episode reward total was 9.0. running mean: 5.60374818120103\n",
      "resetting env. episode reward total was 16.0. running mean: 5.707710699389019\n",
      "resetting env. episode reward total was 8.0. running mean: 5.730633592395129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 5.7833272564711775\n",
      "resetting env. episode reward total was 7.0. running mean: 5.795493983906466\n",
      "resetting env. episode reward total was 4.0. running mean: 5.777539044067401\n",
      "resetting env. episode reward total was 8.0. running mean: 5.799763653626727\n",
      "resetting env. episode reward total was 8.0. running mean: 5.82176601709046\n",
      "resetting env. episode reward total was 1.0. running mean: 5.773548356919555\n",
      "resetting env. episode reward total was 3.0. running mean: 5.74581287335036\n",
      "resetting env. episode reward total was 8.0. running mean: 5.768354744616857\n",
      "resetting env. episode reward total was 8.0. running mean: 5.790671197170688\n",
      "resetting env. episode reward total was 3.0. running mean: 5.762764485198982\n",
      "resetting env. episode reward total was 4.0. running mean: 5.7451368403469925\n",
      "resetting env. episode reward total was 2.0. running mean: 5.707685471943522\n",
      "resetting env. episode reward total was -4.0. running mean: 5.610608617224087\n",
      "resetting env. episode reward total was 5.0. running mean: 5.604502531051846\n",
      "resetting env. episode reward total was 8.0. running mean: 5.628457505741328\n",
      "resetting env. episode reward total was 4.0. running mean: 5.612172930683915\n",
      "resetting env. episode reward total was 13.0. running mean: 5.686051201377076\n",
      "resetting env. episode reward total was 6.0. running mean: 5.689190689363305\n",
      "resetting env. episode reward total was 15.0. running mean: 5.782298782469672\n",
      "resetting env. episode reward total was 4.0. running mean: 5.764475794644976\n",
      "resetting env. episode reward total was 10.0. running mean: 5.806831036698526\n",
      "resetting env. episode reward total was 19.0. running mean: 5.938762726331541\n",
      "resetting env. episode reward total was 1.0. running mean: 5.889375099068226\n",
      "resetting env. episode reward total was 12.0. running mean: 5.950481348077544\n",
      "resetting env. episode reward total was 11.0. running mean: 6.000976534596768\n",
      "resetting env. episode reward total was 10.0. running mean: 6.0409667692508\n",
      "resetting env. episode reward total was -1.0. running mean: 5.970557101558292\n",
      "resetting env. episode reward total was -5.0. running mean: 5.860851530542709\n",
      "resetting env. episode reward total was 11.0. running mean: 5.912243015237282\n",
      "resetting env. episode reward total was 1.0. running mean: 5.863120585084909\n",
      "resetting env. episode reward total was 6.0. running mean: 5.864489379234059\n",
      "resetting env. episode reward total was 8.0. running mean: 5.8858444854417185\n",
      "resetting env. episode reward total was 5.0. running mean: 5.876986040587301\n",
      "resetting env. episode reward total was 10.0. running mean: 5.918216180181428\n",
      "resetting env. episode reward total was -11.0. running mean: 5.749034018379613\n",
      "resetting env. episode reward total was 11.0. running mean: 5.801543678195817\n",
      "resetting env. episode reward total was 7.0. running mean: 5.813528241413859\n",
      "resetting env. episode reward total was -3.0. running mean: 5.725392958999721\n",
      "resetting env. episode reward total was 8.0. running mean: 5.748139029409724\n",
      "resetting env. episode reward total was 1.0. running mean: 5.700657639115626\n",
      "resetting env. episode reward total was 16.0. running mean: 5.8036510627244695\n",
      "resetting env. episode reward total was -3.0. running mean: 5.715614552097224\n",
      "resetting env. episode reward total was 3.0. running mean: 5.6884584065762525\n",
      "resetting env. episode reward total was 11.0. running mean: 5.741573822510491\n",
      "resetting env. episode reward total was 4.0. running mean: 5.724158084285386\n",
      "resetting env. episode reward total was 1.0. running mean: 5.6769165034425315\n",
      "resetting env. episode reward total was 12.0. running mean: 5.740147338408106\n",
      "resetting env. episode reward total was 2.0. running mean: 5.702745865024025\n",
      "resetting env. episode reward total was 3.0. running mean: 5.675718406373785\n",
      "resetting env. episode reward total was 3.0. running mean: 5.648961222310048\n",
      "resetting env. episode reward total was 10.0. running mean: 5.692471610086947\n",
      "resetting env. episode reward total was 8.0. running mean: 5.715546893986077\n",
      "resetting env. episode reward total was 8.0. running mean: 5.738391425046216\n",
      "resetting env. episode reward total was 10.0. running mean: 5.781007510795753\n",
      "resetting env. episode reward total was 12.0. running mean: 5.843197435687795\n",
      "resetting env. episode reward total was 1.0. running mean: 5.7947654613309165\n",
      "resetting env. episode reward total was 5.0. running mean: 5.7868178067176075\n",
      "resetting env. episode reward total was 15.0. running mean: 5.878949628650432\n",
      "resetting env. episode reward total was 13.0. running mean: 5.950160132363927\n",
      "resetting env. episode reward total was 10.0. running mean: 5.990658531040288\n",
      "resetting env. episode reward total was 7.0. running mean: 6.000751945729886\n",
      "resetting env. episode reward total was 7.0. running mean: 6.010744426272587\n",
      "resetting env. episode reward total was 8.0. running mean: 6.030636982009861\n",
      "resetting env. episode reward total was 10.0. running mean: 6.070330612189762\n",
      "resetting env. episode reward total was -4.0. running mean: 5.969627306067864\n",
      "resetting env. episode reward total was 8.0. running mean: 5.989931033007186\n",
      "resetting env. episode reward total was -5.0. running mean: 5.880031722677114\n",
      "resetting env. episode reward total was 3.0. running mean: 5.851231405450344\n",
      "resetting env. episode reward total was 13.0. running mean: 5.92271909139584\n",
      "resetting env. episode reward total was 5.0. running mean: 5.913491900481882\n",
      "resetting env. episode reward total was 9.0. running mean: 5.944356981477062\n",
      "resetting env. episode reward total was 5.0. running mean: 5.934913411662292\n",
      "resetting env. episode reward total was 9.0. running mean: 5.965564277545669\n",
      "resetting env. episode reward total was 4.0. running mean: 5.945908634770212\n",
      "resetting env. episode reward total was 7.0. running mean: 5.95644954842251\n",
      "resetting env. episode reward total was 2.0. running mean: 5.916885052938285\n",
      "resetting env. episode reward total was -3.0. running mean: 5.827716202408902\n",
      "resetting env. episode reward total was 9.0. running mean: 5.859439040384813\n",
      "resetting env. episode reward total was 7.0. running mean: 5.870844649980965\n",
      "resetting env. episode reward total was 1.0. running mean: 5.822136203481155\n",
      "resetting env. episode reward total was 3.0. running mean: 5.793914841446344\n",
      "resetting env. episode reward total was 1.0. running mean: 5.74597569303188\n",
      "resetting env. episode reward total was 17.0. running mean: 5.858515936101561\n",
      "resetting env. episode reward total was -2.0. running mean: 5.779930776740546\n",
      "resetting env. episode reward total was 8.0. running mean: 5.8021314689731405\n",
      "resetting env. episode reward total was -3.0. running mean: 5.714110154283409\n",
      "resetting env. episode reward total was 15.0. running mean: 5.806969052740575\n",
      "resetting env. episode reward total was 6.0. running mean: 5.808899362213169\n",
      "resetting env. episode reward total was 10.0. running mean: 5.850810368591037\n",
      "resetting env. episode reward total was -11.0. running mean: 5.682302264905126\n",
      "resetting env. episode reward total was 10.0. running mean: 5.725479242256075\n",
      "resetting env. episode reward total was -1.0. running mean: 5.658224449833514\n",
      "resetting env. episode reward total was 14.0. running mean: 5.741642205335179\n",
      "resetting env. episode reward total was 6.0. running mean: 5.744225783281826\n",
      "resetting env. episode reward total was 1.0. running mean: 5.696783525449008\n",
      "resetting env. episode reward total was 8.0. running mean: 5.719815690194518\n",
      "resetting env. episode reward total was 7.0. running mean: 5.732617533292573\n",
      "resetting env. episode reward total was 15.0. running mean: 5.825291357959648\n",
      "resetting env. episode reward total was 13.0. running mean: 5.897038444380051\n",
      "resetting env. episode reward total was 17.0. running mean: 6.00806805993625\n",
      "resetting env. episode reward total was -1.0. running mean: 5.937987379336888\n",
      "resetting env. episode reward total was 10.0. running mean: 5.978607505543518\n",
      "resetting env. episode reward total was 9.0. running mean: 6.008821430488083\n",
      "resetting env. episode reward total was 12.0. running mean: 6.068733216183202\n",
      "resetting env. episode reward total was 9.0. running mean: 6.09804588402137\n",
      "resetting env. episode reward total was 4.0. running mean: 6.077065425181156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 6.076294770929344\n",
      "resetting env. episode reward total was -7.0. running mean: 5.94553182322005\n",
      "resetting env. episode reward total was 14.0. running mean: 6.0260765049878495\n",
      "resetting env. episode reward total was 5.0. running mean: 6.01581573993797\n",
      "resetting env. episode reward total was 11.0. running mean: 6.0656575825385906\n",
      "resetting env. episode reward total was 13.0. running mean: 6.135001006713204\n",
      "resetting env. episode reward total was 1.0. running mean: 6.083650996646072\n",
      "resetting env. episode reward total was 1.0. running mean: 6.0328144866796105\n",
      "resetting env. episode reward total was 9.0. running mean: 6.062486341812814\n",
      "resetting env. episode reward total was 7.0. running mean: 6.071861478394687\n",
      "resetting env. episode reward total was 5.0. running mean: 6.06114286361074\n",
      "resetting env. episode reward total was -1.0. running mean: 5.990531434974632\n",
      "resetting env. episode reward total was 6.0. running mean: 5.990626120624885\n",
      "resetting env. episode reward total was 11.0. running mean: 6.040719859418636\n",
      "resetting env. episode reward total was 2.0. running mean: 6.0003126608244495\n",
      "resetting env. episode reward total was 9.0. running mean: 6.0303095342162045\n",
      "resetting env. episode reward total was 14.0. running mean: 6.110006438874042\n",
      "resetting env. episode reward total was 8.0. running mean: 6.128906374485302\n",
      "resetting env. episode reward total was 2.0. running mean: 6.087617310740448\n",
      "resetting env. episode reward total was 10.0. running mean: 6.126741137633044\n",
      "resetting env. episode reward total was 9.0. running mean: 6.155473726256713\n",
      "resetting env. episode reward total was 1.0. running mean: 6.103918988994145\n",
      "resetting env. episode reward total was 4.0. running mean: 6.082879799104204\n",
      "resetting env. episode reward total was 7.0. running mean: 6.092051001113163\n",
      "resetting env. episode reward total was 4.0. running mean: 6.071130491102031\n",
      "resetting env. episode reward total was 10.0. running mean: 6.11041918619101\n",
      "resetting env. episode reward total was 8.0. running mean: 6.129314994329101\n",
      "resetting env. episode reward total was 10.0. running mean: 6.16802184438581\n",
      "resetting env. episode reward total was 8.0. running mean: 6.186341625941951\n",
      "resetting env. episode reward total was 8.0. running mean: 6.204478209682532\n",
      "resetting env. episode reward total was 7.0. running mean: 6.212433427585706\n",
      "resetting env. episode reward total was 8.0. running mean: 6.230309093309849\n",
      "resetting env. episode reward total was 8.0. running mean: 6.2480060023767505\n",
      "resetting env. episode reward total was 7.0. running mean: 6.255525942352984\n",
      "resetting env. episode reward total was -1.0. running mean: 6.182970682929454\n",
      "resetting env. episode reward total was 6.0. running mean: 6.181140976100159\n",
      "resetting env. episode reward total was 10.0. running mean: 6.219329566339157\n",
      "resetting env. episode reward total was 10.0. running mean: 6.257136270675765\n",
      "resetting env. episode reward total was 1.0. running mean: 6.204564907969007\n",
      "resetting env. episode reward total was 9.0. running mean: 6.232519258889317\n",
      "resetting env. episode reward total was 5.0. running mean: 6.220194066300424\n",
      "resetting env. episode reward total was -2.0. running mean: 6.13799212563742\n",
      "resetting env. episode reward total was 7.0. running mean: 6.1466122043810465\n",
      "resetting env. episode reward total was 11.0. running mean: 6.195146082337236\n",
      "resetting env. episode reward total was 8.0. running mean: 6.213194621513864\n",
      "resetting env. episode reward total was 7.0. running mean: 6.221062675298725\n",
      "resetting env. episode reward total was 14.0. running mean: 6.298852048545737\n",
      "resetting env. episode reward total was 6.0. running mean: 6.29586352806028\n",
      "resetting env. episode reward total was -5.0. running mean: 6.1829048927796775\n",
      "resetting env. episode reward total was 3.0. running mean: 6.151075843851881\n",
      "resetting env. episode reward total was 2.0. running mean: 6.109565085413362\n",
      "resetting env. episode reward total was 15.0. running mean: 6.198469434559228\n",
      "resetting env. episode reward total was -8.0. running mean: 6.0564847402136355\n",
      "resetting env. episode reward total was 7.0. running mean: 6.0659198928114995\n",
      "resetting env. episode reward total was -11.0. running mean: 5.895260693883384\n",
      "resetting env. episode reward total was 7.0. running mean: 5.90630808694455\n",
      "resetting env. episode reward total was 2.0. running mean: 5.8672450060751045\n",
      "resetting env. episode reward total was 5.0. running mean: 5.858572556014353\n",
      "resetting env. episode reward total was 12.0. running mean: 5.91998683045421\n",
      "resetting env. episode reward total was 8.0. running mean: 5.940786962149668\n",
      "resetting env. episode reward total was 13.0. running mean: 6.011379092528171\n",
      "resetting env. episode reward total was 10.0. running mean: 6.051265301602888\n",
      "resetting env. episode reward total was 4.0. running mean: 6.030752648586859\n",
      "resetting env. episode reward total was 15.0. running mean: 6.120445122100991\n",
      "resetting env. episode reward total was 11.0. running mean: 6.169240670879981\n",
      "resetting env. episode reward total was 9.0. running mean: 6.197548264171181\n",
      "resetting env. episode reward total was 11.0. running mean: 6.24557278152947\n",
      "resetting env. episode reward total was 8.0. running mean: 6.263117053714175\n",
      "resetting env. episode reward total was 14.0. running mean: 6.340485883177033\n",
      "resetting env. episode reward total was 9.0. running mean: 6.3670810243452625\n",
      "resetting env. episode reward total was 7.0. running mean: 6.37341021410181\n",
      "resetting env. episode reward total was 7.0. running mean: 6.379676111960792\n",
      "resetting env. episode reward total was 9.0. running mean: 6.405879350841183\n",
      "resetting env. episode reward total was -3.0. running mean: 6.311820557332771\n",
      "resetting env. episode reward total was 14.0. running mean: 6.388702351759443\n",
      "resetting env. episode reward total was 9.0. running mean: 6.414815328241849\n",
      "resetting env. episode reward total was 7.0. running mean: 6.420667174959431\n",
      "resetting env. episode reward total was 11.0. running mean: 6.466460503209837\n",
      "resetting env. episode reward total was 9.0. running mean: 6.491795898177738\n",
      "resetting env. episode reward total was 3.0. running mean: 6.4568779391959605\n",
      "resetting env. episode reward total was 11.0. running mean: 6.5023091598040015\n",
      "resetting env. episode reward total was 8.0. running mean: 6.517286068205961\n",
      "resetting env. episode reward total was 10.0. running mean: 6.5521132075239015\n",
      "resetting env. episode reward total was 3.0. running mean: 6.516592075448663\n",
      "resetting env. episode reward total was 4.0. running mean: 6.491426154694176\n",
      "resetting env. episode reward total was 7.0. running mean: 6.496511893147234\n",
      "resetting env. episode reward total was 9.0. running mean: 6.521546774215762\n",
      "resetting env. episode reward total was -3.0. running mean: 6.426331306473604\n",
      "resetting env. episode reward total was 4.0. running mean: 6.402067993408868\n",
      "resetting env. episode reward total was 11.0. running mean: 6.448047313474779\n",
      "resetting env. episode reward total was 10.0. running mean: 6.483566840340031\n",
      "resetting env. episode reward total was 10.0. running mean: 6.51873117193663\n",
      "resetting env. episode reward total was 6.0. running mean: 6.513543860217263\n",
      "resetting env. episode reward total was -4.0. running mean: 6.40840842161509\n",
      "resetting env. episode reward total was 7.0. running mean: 6.41432433739894\n",
      "resetting env. episode reward total was 9.0. running mean: 6.44018109402495\n",
      "resetting env. episode reward total was 7.0. running mean: 6.445779283084701\n",
      "resetting env. episode reward total was -4.0. running mean: 6.341321490253854\n",
      "resetting env. episode reward total was -6.0. running mean: 6.2179082753513155\n",
      "resetting env. episode reward total was 7.0. running mean: 6.225729192597803\n",
      "resetting env. episode reward total was 7.0. running mean: 6.233471900671825\n",
      "resetting env. episode reward total was 8.0. running mean: 6.251137181665107\n",
      "resetting env. episode reward total was -1.0. running mean: 6.178625809848456\n",
      "resetting env. episode reward total was 8.0. running mean: 6.196839551749972\n",
      "resetting env. episode reward total was 11.0. running mean: 6.244871156232472\n",
      "resetting env. episode reward total was 9.0. running mean: 6.2724224446701475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -6.0. running mean: 6.1496982202234465\n",
      "resetting env. episode reward total was 13.0. running mean: 6.218201238021212\n",
      "resetting env. episode reward total was 14.0. running mean: 6.2960192256409995\n",
      "resetting env. episode reward total was 9.0. running mean: 6.323059033384589\n",
      "resetting env. episode reward total was 8.0. running mean: 6.3398284430507434\n",
      "resetting env. episode reward total was 3.0. running mean: 6.306430158620236\n",
      "resetting env. episode reward total was 7.0. running mean: 6.313365857034034\n",
      "resetting env. episode reward total was 14.0. running mean: 6.390232198463694\n",
      "resetting env. episode reward total was 18.0. running mean: 6.5063298764790565\n",
      "resetting env. episode reward total was 6.0. running mean: 6.501266577714265\n",
      "resetting env. episode reward total was 13.0. running mean: 6.566253911937122\n",
      "resetting env. episode reward total was 3.0. running mean: 6.530591372817751\n",
      "resetting env. episode reward total was 14.0. running mean: 6.605285459089573\n",
      "resetting env. episode reward total was 9.0. running mean: 6.629232604498677\n",
      "resetting env. episode reward total was 6.0. running mean: 6.622940278453689\n",
      "resetting env. episode reward total was 8.0. running mean: 6.636710875669152\n",
      "resetting env. episode reward total was 8.0. running mean: 6.650343766912461\n",
      "resetting env. episode reward total was 12.0. running mean: 6.703840329243336\n",
      "resetting env. episode reward total was 3.0. running mean: 6.666801925950903\n",
      "resetting env. episode reward total was 1.0. running mean: 6.610133906691393\n",
      "resetting env. episode reward total was 2.0. running mean: 6.564032567624479\n",
      "resetting env. episode reward total was 12.0. running mean: 6.618392241948234\n",
      "resetting env. episode reward total was 8.0. running mean: 6.632208319528751\n",
      "resetting env. episode reward total was 14.0. running mean: 6.7058862363334635\n",
      "resetting env. episode reward total was 8.0. running mean: 6.718827373970129\n",
      "resetting env. episode reward total was 7.0. running mean: 6.721639100230428\n",
      "resetting env. episode reward total was 6.0. running mean: 6.714422709228123\n",
      "resetting env. episode reward total was -1.0. running mean: 6.637278482135843\n",
      "resetting env. episode reward total was 15.0. running mean: 6.7209056973144845\n",
      "resetting env. episode reward total was 6.0. running mean: 6.71369664034134\n",
      "resetting env. episode reward total was 13.0. running mean: 6.776559673937926\n",
      "resetting env. episode reward total was 15.0. running mean: 6.858794077198547\n",
      "resetting env. episode reward total was -3.0. running mean: 6.760206136426561\n",
      "resetting env. episode reward total was 8.0. running mean: 6.772604075062295\n",
      "resetting env. episode reward total was 12.0. running mean: 6.824878034311673\n",
      "resetting env. episode reward total was 9.0. running mean: 6.846629253968556\n",
      "resetting env. episode reward total was 7.0. running mean: 6.84816296142887\n",
      "resetting env. episode reward total was -2.0. running mean: 6.759681331814582\n",
      "resetting env. episode reward total was -1.0. running mean: 6.682084518496436\n",
      "resetting env. episode reward total was 8.0. running mean: 6.695263673311471\n",
      "resetting env. episode reward total was -2.0. running mean: 6.608311036578357\n",
      "resetting env. episode reward total was 15.0. running mean: 6.692227926212573\n",
      "resetting env. episode reward total was -5.0. running mean: 6.575305646950448\n",
      "resetting env. episode reward total was -6.0. running mean: 6.449552590480944\n",
      "resetting env. episode reward total was 6.0. running mean: 6.445057064576134\n",
      "resetting env. episode reward total was 13.0. running mean: 6.510606493930372\n",
      "resetting env. episode reward total was 11.0. running mean: 6.555500428991069\n",
      "resetting env. episode reward total was 4.0. running mean: 6.529945424701158\n",
      "resetting env. episode reward total was 11.0. running mean: 6.574645970454147\n",
      "resetting env. episode reward total was 13.0. running mean: 6.638899510749605\n",
      "resetting env. episode reward total was 6.0. running mean: 6.6325105156421085\n",
      "resetting env. episode reward total was 5.0. running mean: 6.616185410485687\n",
      "resetting env. episode reward total was 7.0. running mean: 6.62002355638083\n",
      "resetting env. episode reward total was 6.0. running mean: 6.613823320817021\n",
      "resetting env. episode reward total was 11.0. running mean: 6.657685087608851\n",
      "resetting env. episode reward total was 16.0. running mean: 6.751108236732763\n",
      "resetting env. episode reward total was -5.0. running mean: 6.633597154365435\n",
      "resetting env. episode reward total was 6.0. running mean: 6.627261182821781\n",
      "resetting env. episode reward total was 6.0. running mean: 6.620988570993562\n",
      "resetting env. episode reward total was 5.0. running mean: 6.604778685283627\n",
      "resetting env. episode reward total was 2.0. running mean: 6.55873089843079\n",
      "resetting env. episode reward total was 10.0. running mean: 6.593143589446481\n",
      "resetting env. episode reward total was 11.0. running mean: 6.637212153552017\n",
      "resetting env. episode reward total was 2.0. running mean: 6.590840032016496\n",
      "resetting env. episode reward total was 1.0. running mean: 6.534931631696331\n",
      "resetting env. episode reward total was 11.0. running mean: 6.579582315379368\n",
      "resetting env. episode reward total was 3.0. running mean: 6.543786492225575\n",
      "resetting env. episode reward total was 11.0. running mean: 6.588348627303319\n",
      "resetting env. episode reward total was -5.0. running mean: 6.472465141030287\n",
      "resetting env. episode reward total was 11.0. running mean: 6.517740489619984\n",
      "resetting env. episode reward total was 10.0. running mean: 6.552563084723785\n",
      "resetting env. episode reward total was 17.0. running mean: 6.657037453876547\n",
      "resetting env. episode reward total was -7.0. running mean: 6.520467079337781\n",
      "resetting env. episode reward total was 12.0. running mean: 6.575262408544403\n",
      "resetting env. episode reward total was 9.0. running mean: 6.5995097844589585\n",
      "resetting env. episode reward total was 15.0. running mean: 6.6835146866143695\n",
      "resetting env. episode reward total was 10.0. running mean: 6.716679539748226\n",
      "resetting env. episode reward total was 9.0. running mean: 6.739512744350743\n",
      "resetting env. episode reward total was 6.0. running mean: 6.732117616907235\n",
      "resetting env. episode reward total was 6.0. running mean: 6.724796440738162\n",
      "resetting env. episode reward total was 5.0. running mean: 6.70754847633078\n",
      "resetting env. episode reward total was -10.0. running mean: 6.540472991567473\n",
      "resetting env. episode reward total was 1.0. running mean: 6.485068261651798\n",
      "resetting env. episode reward total was 16.0. running mean: 6.58021757903528\n",
      "resetting env. episode reward total was 11.0. running mean: 6.624415403244928\n",
      "resetting env. episode reward total was 5.0. running mean: 6.608171249212479\n",
      "resetting env. episode reward total was 3.0. running mean: 6.5720895367203545\n",
      "resetting env. episode reward total was 4.0. running mean: 6.546368641353151\n",
      "resetting env. episode reward total was 12.0. running mean: 6.60090495493962\n",
      "resetting env. episode reward total was 5.0. running mean: 6.584895905390224\n",
      "resetting env. episode reward total was 1.0. running mean: 6.529046946336321\n",
      "resetting env. episode reward total was 7.0. running mean: 6.533756476872958\n",
      "resetting env. episode reward total was 1.0. running mean: 6.478418912104228\n",
      "resetting env. episode reward total was 3.0. running mean: 6.443634722983186\n",
      "resetting env. episode reward total was -3.0. running mean: 6.349198375753353\n",
      "resetting env. episode reward total was 4.0. running mean: 6.32570639199582\n",
      "resetting env. episode reward total was 10.0. running mean: 6.362449328075861\n",
      "resetting env. episode reward total was 11.0. running mean: 6.408824834795103\n",
      "resetting env. episode reward total was -7.0. running mean: 6.274736586447152\n",
      "resetting env. episode reward total was 8.0. running mean: 6.29198922058268\n",
      "resetting env. episode reward total was 4.0. running mean: 6.269069328376854\n",
      "resetting env. episode reward total was 7.0. running mean: 6.276378635093085\n",
      "resetting env. episode reward total was 15.0. running mean: 6.363614848742155\n",
      "resetting env. episode reward total was 9.0. running mean: 6.3899787002547335\n",
      "resetting env. episode reward total was -1.0. running mean: 6.316078913252186\n",
      "resetting env. episode reward total was 9.0. running mean: 6.342918124119664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 6.389488942878468\n",
      "resetting env. episode reward total was 4.0. running mean: 6.3655940534496835\n",
      "resetting env. episode reward total was 3.0. running mean: 6.331938112915187\n",
      "resetting env. episode reward total was 8.0. running mean: 6.3486187317860345\n",
      "resetting env. episode reward total was -6.0. running mean: 6.225132544468175\n",
      "resetting env. episode reward total was -5.0. running mean: 6.112881219023493\n",
      "resetting env. episode reward total was 14.0. running mean: 6.191752406833258\n",
      "resetting env. episode reward total was -1.0. running mean: 6.119834882764925\n",
      "resetting env. episode reward total was 13.0. running mean: 6.1886365339372755\n",
      "resetting env. episode reward total was 15.0. running mean: 6.2767501685979035\n",
      "resetting env. episode reward total was 7.0. running mean: 6.283982666911925\n",
      "resetting env. episode reward total was -15.0. running mean: 6.071142840242805\n",
      "resetting env. episode reward total was 7.0. running mean: 6.080431411840378\n",
      "resetting env. episode reward total was 4.0. running mean: 6.0596270977219735\n",
      "resetting env. episode reward total was 13.0. running mean: 6.129030826744754\n",
      "resetting env. episode reward total was 8.0. running mean: 6.147740518477306\n",
      "resetting env. episode reward total was 5.0. running mean: 6.136263113292533\n",
      "resetting env. episode reward total was 3.0. running mean: 6.104900482159608\n",
      "resetting env. episode reward total was 5.0. running mean: 6.093851477338012\n",
      "resetting env. episode reward total was 9.0. running mean: 6.122912962564631\n",
      "resetting env. episode reward total was 7.0. running mean: 6.131683832938985\n",
      "resetting env. episode reward total was -6.0. running mean: 6.010366994609596\n",
      "resetting env. episode reward total was 15.0. running mean: 6.1002633246635005\n",
      "resetting env. episode reward total was 13.0. running mean: 6.1692606914168655\n",
      "resetting env. episode reward total was 3.0. running mean: 6.137568084502697\n",
      "resetting env. episode reward total was 10.0. running mean: 6.176192403657669\n",
      "resetting env. episode reward total was 11.0. running mean: 6.224430479621093\n",
      "resetting env. episode reward total was 2.0. running mean: 6.182186174824881\n",
      "resetting env. episode reward total was 9.0. running mean: 6.210364313076632\n",
      "resetting env. episode reward total was 10.0. running mean: 6.248260669945866\n",
      "resetting env. episode reward total was 14.0. running mean: 6.325778063246407\n",
      "resetting env. episode reward total was 4.0. running mean: 6.302520282613942\n",
      "resetting env. episode reward total was 8.0. running mean: 6.319495079787803\n",
      "resetting env. episode reward total was 13.0. running mean: 6.386300128989925\n",
      "resetting env. episode reward total was 5.0. running mean: 6.372437127700025\n",
      "resetting env. episode reward total was 7.0. running mean: 6.378712756423026\n",
      "resetting env. episode reward total was 6.0. running mean: 6.374925628858795\n",
      "resetting env. episode reward total was 8.0. running mean: 6.391176372570207\n",
      "resetting env. episode reward total was 6.0. running mean: 6.387264608844505\n",
      "resetting env. episode reward total was 12.0. running mean: 6.44339196275606\n",
      "resetting env. episode reward total was -1.0. running mean: 6.368958043128499\n",
      "resetting env. episode reward total was 5.0. running mean: 6.355268462697214\n",
      "resetting env. episode reward total was -3.0. running mean: 6.261715778070241\n",
      "resetting env. episode reward total was -5.0. running mean: 6.149098620289538\n",
      "resetting env. episode reward total was 6.0. running mean: 6.147607634086643\n",
      "resetting env. episode reward total was 12.0. running mean: 6.206131557745776\n",
      "resetting env. episode reward total was 1.0. running mean: 6.154070242168318\n",
      "resetting env. episode reward total was -1.0. running mean: 6.082529539746635\n",
      "resetting env. episode reward total was 12.0. running mean: 6.141704244349168\n",
      "resetting env. episode reward total was 8.0. running mean: 6.1602872019056765\n",
      "resetting env. episode reward total was 9.0. running mean: 6.18868432988662\n",
      "resetting env. episode reward total was 5.0. running mean: 6.176797486587753\n",
      "resetting env. episode reward total was 7.0. running mean: 6.185029511721876\n",
      "resetting env. episode reward total was -7.0. running mean: 6.053179216604657\n",
      "resetting env. episode reward total was 9.0. running mean: 6.08264742443861\n",
      "resetting env. episode reward total was 4.0. running mean: 6.061820950194224\n",
      "resetting env. episode reward total was 4.0. running mean: 6.041202740692282\n",
      "resetting env. episode reward total was 11.0. running mean: 6.090790713285359\n",
      "resetting env. episode reward total was 5.0. running mean: 6.079882806152505\n",
      "resetting env. episode reward total was 6.0. running mean: 6.07908397809098\n",
      "resetting env. episode reward total was 5.0. running mean: 6.06829313831007\n",
      "resetting env. episode reward total was 9.0. running mean: 6.097610206926969\n",
      "resetting env. episode reward total was 13.0. running mean: 6.1666341048577\n",
      "resetting env. episode reward total was 6.0. running mean: 6.1649677638091225\n",
      "resetting env. episode reward total was 10.0. running mean: 6.203318086171031\n",
      "resetting env. episode reward total was 5.0. running mean: 6.19128490530932\n",
      "resetting env. episode reward total was -1.0. running mean: 6.1193720562562275\n",
      "resetting env. episode reward total was 8.0. running mean: 6.138178335693666\n",
      "resetting env. episode reward total was 10.0. running mean: 6.176796552336729\n",
      "resetting env. episode reward total was 4.0. running mean: 6.155028586813361\n",
      "resetting env. episode reward total was 11.0. running mean: 6.2034783009452275\n",
      "resetting env. episode reward total was 9.0. running mean: 6.231443517935775\n",
      "resetting env. episode reward total was 11.0. running mean: 6.279129082756417\n",
      "resetting env. episode reward total was 5.0. running mean: 6.266337791928852\n",
      "resetting env. episode reward total was 6.0. running mean: 6.2636744140095635\n",
      "resetting env. episode reward total was 14.0. running mean: 6.3410376698694675\n",
      "resetting env. episode reward total was 2.0. running mean: 6.297627293170772\n",
      "resetting env. episode reward total was 8.0. running mean: 6.314651020239065\n",
      "resetting env. episode reward total was 11.0. running mean: 6.361504510036674\n",
      "resetting env. episode reward total was 16.0. running mean: 6.457889464936308\n",
      "resetting env. episode reward total was 2.0. running mean: 6.413310570286944\n",
      "resetting env. episode reward total was 6.0. running mean: 6.409177464584074\n",
      "resetting env. episode reward total was 3.0. running mean: 6.375085689938233\n",
      "resetting env. episode reward total was 10.0. running mean: 6.41133483303885\n",
      "resetting env. episode reward total was -7.0. running mean: 6.277221484708462\n",
      "resetting env. episode reward total was 7.0. running mean: 6.284449269861377\n",
      "resetting env. episode reward total was 3.0. running mean: 6.251604777162764\n",
      "resetting env. episode reward total was 5.0. running mean: 6.239088729391136\n",
      "resetting env. episode reward total was 9.0. running mean: 6.266697842097224\n",
      "resetting env. episode reward total was -3.0. running mean: 6.1740308636762515\n",
      "resetting env. episode reward total was 9.0. running mean: 6.202290555039489\n",
      "resetting env. episode reward total was 7.0. running mean: 6.210267649489094\n",
      "resetting env. episode reward total was 12.0. running mean: 6.268164972994203\n",
      "resetting env. episode reward total was 9.0. running mean: 6.295483323264261\n",
      "resetting env. episode reward total was 3.0. running mean: 6.2625284900316185\n",
      "resetting env. episode reward total was 16.0. running mean: 6.359903205131302\n",
      "resetting env. episode reward total was 12.0. running mean: 6.41630417307999\n",
      "resetting env. episode reward total was 4.0. running mean: 6.39214113134919\n",
      "resetting env. episode reward total was 4.0. running mean: 6.368219720035698\n",
      "resetting env. episode reward total was 6.0. running mean: 6.36453752283534\n",
      "resetting env. episode reward total was 4.0. running mean: 6.340892147606986\n",
      "resetting env. episode reward total was 5.0. running mean: 6.327483226130917\n",
      "resetting env. episode reward total was 4.0. running mean: 6.304208393869607\n",
      "resetting env. episode reward total was 8.0. running mean: 6.321166309930911\n",
      "resetting env. episode reward total was 9.0. running mean: 6.347954646831601\n",
      "resetting env. episode reward total was 4.0. running mean: 6.324475100363285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 6.401230349359652\n",
      "resetting env. episode reward total was 9.0. running mean: 6.427218045866056\n",
      "resetting env. episode reward total was 3.0. running mean: 6.392945865407396\n",
      "resetting env. episode reward total was 11.0. running mean: 6.439016406753322\n",
      "resetting env. episode reward total was 9.0. running mean: 6.464626242685789\n",
      "resetting env. episode reward total was 5.0. running mean: 6.449979980258931\n",
      "resetting env. episode reward total was -1.0. running mean: 6.375480180456342\n",
      "resetting env. episode reward total was 16.0. running mean: 6.4717253786517785\n",
      "resetting env. episode reward total was 4.0. running mean: 6.447008124865261\n",
      "resetting env. episode reward total was 10.0. running mean: 6.482538043616608\n",
      "resetting env. episode reward total was 14.0. running mean: 6.557712663180442\n",
      "resetting env. episode reward total was 4.0. running mean: 6.532135536548637\n",
      "resetting env. episode reward total was 6.0. running mean: 6.52681418118315\n",
      "resetting env. episode reward total was 9.0. running mean: 6.551546039371319\n",
      "resetting env. episode reward total was 4.0. running mean: 6.526030578977606\n",
      "resetting env. episode reward total was 8.0. running mean: 6.54077027318783\n",
      "resetting env. episode reward total was 10.0. running mean: 6.575362570455951\n",
      "resetting env. episode reward total was 11.0. running mean: 6.619608944751392\n",
      "resetting env. episode reward total was 11.0. running mean: 6.6634128553038785\n",
      "resetting env. episode reward total was 6.0. running mean: 6.656778726750839\n",
      "resetting env. episode reward total was 17.0. running mean: 6.760210939483331\n",
      "resetting env. episode reward total was 2.0. running mean: 6.712608830088497\n",
      "resetting env. episode reward total was 12.0. running mean: 6.765482741787612\n",
      "resetting env. episode reward total was 7.0. running mean: 6.767827914369736\n",
      "resetting env. episode reward total was 9.0. running mean: 6.790149635226038\n",
      "resetting env. episode reward total was 3.0. running mean: 6.752248138873778\n",
      "resetting env. episode reward total was 6.0. running mean: 6.74472565748504\n",
      "resetting env. episode reward total was 8.0. running mean: 6.757278400910189\n",
      "resetting env. episode reward total was 2.0. running mean: 6.709705616901086\n",
      "resetting env. episode reward total was 5.0. running mean: 6.692608560732075\n",
      "resetting env. episode reward total was 7.0. running mean: 6.695682475124754\n",
      "resetting env. episode reward total was -1.0. running mean: 6.618725650373507\n",
      "resetting env. episode reward total was 8.0. running mean: 6.632538393869772\n",
      "resetting env. episode reward total was 6.0. running mean: 6.626213009931074\n",
      "resetting env. episode reward total was -6.0. running mean: 6.499950879831763\n",
      "resetting env. episode reward total was 12.0. running mean: 6.554951371033446\n",
      "resetting env. episode reward total was 7.0. running mean: 6.559401857323111\n",
      "resetting env. episode reward total was 8.0. running mean: 6.573807838749881\n",
      "resetting env. episode reward total was -3.0. running mean: 6.478069760362382\n",
      "resetting env. episode reward total was 7.0. running mean: 6.483289062758758\n",
      "resetting env. episode reward total was 9.0. running mean: 6.5084561721311704\n",
      "resetting env. episode reward total was 11.0. running mean: 6.553371610409859\n",
      "resetting env. episode reward total was 3.0. running mean: 6.51783789430576\n",
      "resetting env. episode reward total was -6.0. running mean: 6.392659515362703\n",
      "resetting env. episode reward total was 14.0. running mean: 6.468732920209075\n",
      "resetting env. episode reward total was 7.0. running mean: 6.474045591006985\n",
      "resetting env. episode reward total was 5.0. running mean: 6.459305135096915\n",
      "resetting env. episode reward total was 2.0. running mean: 6.414712083745945\n",
      "resetting env. episode reward total was 8.0. running mean: 6.430564962908486\n",
      "resetting env. episode reward total was 5.0. running mean: 6.416259313279401\n",
      "resetting env. episode reward total was 11.0. running mean: 6.462096720146607\n",
      "resetting env. episode reward total was 10.0. running mean: 6.497475752945141\n",
      "resetting env. episode reward total was -3.0. running mean: 6.402500995415689\n",
      "resetting env. episode reward total was 4.0. running mean: 6.378475985461533\n",
      "resetting env. episode reward total was 9.0. running mean: 6.404691225606917\n",
      "resetting env. episode reward total was 6.0. running mean: 6.400644313350847\n",
      "resetting env. episode reward total was 7.0. running mean: 6.406637870217339\n",
      "resetting env. episode reward total was 5.0. running mean: 6.392571491515166\n",
      "resetting env. episode reward total was 15.0. running mean: 6.478645776600015\n",
      "resetting env. episode reward total was 11.0. running mean: 6.523859318834015\n",
      "resetting env. episode reward total was 9.0. running mean: 6.548620725645675\n",
      "resetting env. episode reward total was 11.0. running mean: 6.593134518389219\n",
      "resetting env. episode reward total was 10.0. running mean: 6.627203173205326\n",
      "resetting env. episode reward total was 7.0. running mean: 6.6309311414732734\n",
      "resetting env. episode reward total was 2.0. running mean: 6.58462183005854\n",
      "resetting env. episode reward total was 3.0. running mean: 6.548775611757955\n",
      "resetting env. episode reward total was 4.0. running mean: 6.523287855640376\n",
      "resetting env. episode reward total was 7.0. running mean: 6.528054977083973\n",
      "resetting env. episode reward total was 6.0. running mean: 6.5227744273131325\n",
      "resetting env. episode reward total was 1.0. running mean: 6.467546683040001\n",
      "resetting env. episode reward total was 6.0. running mean: 6.4628712162096\n",
      "resetting env. episode reward total was 14.0. running mean: 6.538242504047504\n",
      "resetting env. episode reward total was 10.0. running mean: 6.572860079007028\n",
      "resetting env. episode reward total was 13.0. running mean: 6.637131478216958\n",
      "resetting env. episode reward total was 11.0. running mean: 6.680760163434789\n",
      "resetting env. episode reward total was 4.0. running mean: 6.653952561800441\n",
      "resetting env. episode reward total was -1.0. running mean: 6.577413036182437\n",
      "resetting env. episode reward total was 15.0. running mean: 6.661638905820612\n",
      "resetting env. episode reward total was 11.0. running mean: 6.705022516762407\n",
      "resetting env. episode reward total was 6.0. running mean: 6.697972291594782\n",
      "resetting env. episode reward total was 14.0. running mean: 6.770992568678834\n",
      "resetting env. episode reward total was 10.0. running mean: 6.803282642992046\n",
      "resetting env. episode reward total was 1.0. running mean: 6.745249816562125\n",
      "resetting env. episode reward total was 4.0. running mean: 6.717797318396504\n",
      "resetting env. episode reward total was 10.0. running mean: 6.750619345212538\n",
      "resetting env. episode reward total was -3.0. running mean: 6.6531131517604125\n",
      "resetting env. episode reward total was 1.0. running mean: 6.596582020242808\n",
      "resetting env. episode reward total was -7.0. running mean: 6.46061620004038\n",
      "resetting env. episode reward total was 14.0. running mean: 6.536010038039976\n",
      "resetting env. episode reward total was 3.0. running mean: 6.500649937659576\n",
      "resetting env. episode reward total was 9.0. running mean: 6.52564343828298\n",
      "resetting env. episode reward total was 11.0. running mean: 6.570387003900151\n",
      "resetting env. episode reward total was 8.0. running mean: 6.584683133861149\n",
      "resetting env. episode reward total was 8.0. running mean: 6.598836302522537\n",
      "resetting env. episode reward total was 9.0. running mean: 6.622847939497311\n",
      "resetting env. episode reward total was 11.0. running mean: 6.666619460102338\n",
      "resetting env. episode reward total was 6.0. running mean: 6.659953265501314\n",
      "resetting env. episode reward total was 8.0. running mean: 6.673353732846301\n",
      "resetting env. episode reward total was 12.0. running mean: 6.726620195517838\n",
      "resetting env. episode reward total was 15.0. running mean: 6.8093539935626595\n",
      "resetting env. episode reward total was 3.0. running mean: 6.771260453627033\n",
      "resetting env. episode reward total was 11.0. running mean: 6.813547849090763\n",
      "resetting env. episode reward total was 3.0. running mean: 6.775412370599855\n",
      "resetting env. episode reward total was 6.0. running mean: 6.767658246893856\n",
      "resetting env. episode reward total was 5.0. running mean: 6.749981664424918\n",
      "resetting env. episode reward total was 11.0. running mean: 6.792481847780669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 6.864557029302862\n",
      "resetting env. episode reward total was 9.0. running mean: 6.885911459009833\n",
      "resetting env. episode reward total was 5.0. running mean: 6.867052344419735\n",
      "resetting env. episode reward total was 3.0. running mean: 6.828381820975538\n",
      "resetting env. episode reward total was 3.0. running mean: 6.790098002765783\n",
      "resetting env. episode reward total was 12.0. running mean: 6.842197022738125\n",
      "resetting env. episode reward total was 3.0. running mean: 6.803775052510744\n",
      "resetting env. episode reward total was 10.0. running mean: 6.8357373019856364\n",
      "resetting env. episode reward total was -1.0. running mean: 6.75737992896578\n",
      "resetting env. episode reward total was 14.0. running mean: 6.829806129676122\n",
      "resetting env. episode reward total was -1.0. running mean: 6.751508068379361\n",
      "resetting env. episode reward total was 14.0. running mean: 6.823992987695567\n",
      "resetting env. episode reward total was 7.0. running mean: 6.825753057818611\n",
      "resetting env. episode reward total was 10.0. running mean: 6.857495527240425\n",
      "resetting env. episode reward total was -3.0. running mean: 6.75892057196802\n",
      "resetting env. episode reward total was 13.0. running mean: 6.82133136624834\n",
      "resetting env. episode reward total was 6.0. running mean: 6.813118052585856\n",
      "resetting env. episode reward total was 7.0. running mean: 6.814986872059998\n",
      "resetting env. episode reward total was 3.0. running mean: 6.776837003339398\n",
      "resetting env. episode reward total was 7.0. running mean: 6.779068633306004\n",
      "resetting env. episode reward total was 9.0. running mean: 6.801277946972943\n",
      "resetting env. episode reward total was 5.0. running mean: 6.783265167503214\n",
      "resetting env. episode reward total was 3.0. running mean: 6.745432515828182\n",
      "resetting env. episode reward total was 8.0. running mean: 6.7579781906699\n",
      "resetting env. episode reward total was 5.0. running mean: 6.740398408763201\n",
      "resetting env. episode reward total was 17.0. running mean: 6.8429944246755685\n",
      "resetting env. episode reward total was 11.0. running mean: 6.884564480428813\n",
      "resetting env. episode reward total was -6.0. running mean: 6.755718835624526\n",
      "resetting env. episode reward total was 8.0. running mean: 6.768161647268281\n",
      "resetting env. episode reward total was 9.0. running mean: 6.790480030795598\n",
      "resetting env. episode reward total was 10.0. running mean: 6.822575230487641\n",
      "resetting env. episode reward total was 5.0. running mean: 6.804349478182765\n",
      "resetting env. episode reward total was 8.0. running mean: 6.816305983400937\n",
      "resetting env. episode reward total was 10.0. running mean: 6.848142923566928\n",
      "resetting env. episode reward total was 11.0. running mean: 6.889661494331259\n",
      "resetting env. episode reward total was 7.0. running mean: 6.890764879387946\n",
      "resetting env. episode reward total was 11.0. running mean: 6.931857230594067\n",
      "resetting env. episode reward total was 5.0. running mean: 6.912538658288127\n",
      "resetting env. episode reward total was 12.0. running mean: 6.963413271705246\n",
      "resetting env. episode reward total was 8.0. running mean: 6.973779138988194\n",
      "resetting env. episode reward total was 9.0. running mean: 6.994041347598312\n",
      "resetting env. episode reward total was 10.0. running mean: 7.024100934122329\n",
      "resetting env. episode reward total was 5.0. running mean: 7.003859924781105\n",
      "resetting env. episode reward total was 9.0. running mean: 7.023821325533294\n",
      "resetting env. episode reward total was 15.0. running mean: 7.103583112277962\n",
      "resetting env. episode reward total was 14.0. running mean: 7.172547281155182\n",
      "resetting env. episode reward total was 7.0. running mean: 7.17082180834363\n",
      "resetting env. episode reward total was 12.0. running mean: 7.219113590260194\n",
      "resetting env. episode reward total was 4.0. running mean: 7.186922454357592\n",
      "resetting env. episode reward total was 3.0. running mean: 7.145053229814016\n",
      "resetting env. episode reward total was 2.0. running mean: 7.093602697515875\n",
      "resetting env. episode reward total was 11.0. running mean: 7.132666670540717\n",
      "resetting env. episode reward total was 14.0. running mean: 7.201340003835309\n",
      "resetting env. episode reward total was 13.0. running mean: 7.259326603796956\n",
      "resetting env. episode reward total was 13.0. running mean: 7.316733337758986\n",
      "resetting env. episode reward total was 5.0. running mean: 7.293566004381396\n",
      "resetting env. episode reward total was 14.0. running mean: 7.360630344337581\n",
      "resetting env. episode reward total was 11.0. running mean: 7.397024040894205\n",
      "resetting env. episode reward total was 11.0. running mean: 7.433053800485264\n",
      "resetting env. episode reward total was 9.0. running mean: 7.448723262480411\n",
      "resetting env. episode reward total was 12.0. running mean: 7.494236029855607\n",
      "resetting env. episode reward total was 15.0. running mean: 7.569293669557051\n",
      "resetting env. episode reward total was 9.0. running mean: 7.58360073286148\n",
      "resetting env. episode reward total was 11.0. running mean: 7.617764725532865\n",
      "resetting env. episode reward total was 17.0. running mean: 7.711587078277536\n",
      "resetting env. episode reward total was 11.0. running mean: 7.744471207494761\n",
      "resetting env. episode reward total was 13.0. running mean: 7.797026495419813\n",
      "resetting env. episode reward total was 9.0. running mean: 7.8090562304656155\n",
      "resetting env. episode reward total was 10.0. running mean: 7.8309656681609585\n",
      "resetting env. episode reward total was 12.0. running mean: 7.872656011479349\n",
      "resetting env. episode reward total was 10.0. running mean: 7.8939294513645555\n",
      "resetting env. episode reward total was 11.0. running mean: 7.92499015685091\n",
      "resetting env. episode reward total was 10.0. running mean: 7.9457402552824\n",
      "resetting env. episode reward total was 12.0. running mean: 7.986282852729577\n",
      "resetting env. episode reward total was 2.0. running mean: 7.92642002420228\n",
      "resetting env. episode reward total was 12.0. running mean: 7.967155823960257\n",
      "resetting env. episode reward total was 5.0. running mean: 7.937484265720655\n",
      "resetting env. episode reward total was -3.0. running mean: 7.828109423063448\n",
      "resetting env. episode reward total was 8.0. running mean: 7.829828328832813\n",
      "resetting env. episode reward total was 5.0. running mean: 7.801530045544485\n",
      "resetting env. episode reward total was 13.0. running mean: 7.85351474508904\n",
      "resetting env. episode reward total was 13.0. running mean: 7.90497959763815\n",
      "resetting env. episode reward total was 7.0. running mean: 7.895929801661769\n",
      "resetting env. episode reward total was 5.0. running mean: 7.866970503645151\n",
      "resetting env. episode reward total was 9.0. running mean: 7.878300798608699\n",
      "resetting env. episode reward total was 1.0. running mean: 7.809517790622611\n",
      "resetting env. episode reward total was 7.0. running mean: 7.801422612716386\n",
      "resetting env. episode reward total was 3.0. running mean: 7.753408386589222\n",
      "resetting env. episode reward total was 15.0. running mean: 7.825874302723331\n",
      "resetting env. episode reward total was 7.0. running mean: 7.8176155596960974\n",
      "resetting env. episode reward total was 5.0. running mean: 7.789439404099136\n",
      "resetting env. episode reward total was 6.0. running mean: 7.771545010058144\n",
      "resetting env. episode reward total was 10.0. running mean: 7.793829559957563\n",
      "resetting env. episode reward total was 15.0. running mean: 7.8658912643579875\n",
      "resetting env. episode reward total was 10.0. running mean: 7.887232351714407\n",
      "resetting env. episode reward total was 18.0. running mean: 7.988360028197262\n",
      "resetting env. episode reward total was -2.0. running mean: 7.888476427915291\n",
      "resetting env. episode reward total was 11.0. running mean: 7.919591663636138\n",
      "resetting env. episode reward total was 12.0. running mean: 7.960395746999776\n",
      "resetting env. episode reward total was 12.0. running mean: 8.000791789529778\n",
      "resetting env. episode reward total was 3.0. running mean: 7.9507838716344805\n",
      "resetting env. episode reward total was 12.0. running mean: 7.991276032918136\n",
      "resetting env. episode reward total was 8.0. running mean: 7.991363272588955\n",
      "resetting env. episode reward total was 1.0. running mean: 7.921449639863065\n",
      "resetting env. episode reward total was 9.0. running mean: 7.932235143464434\n",
      "resetting env. episode reward total was 7.0. running mean: 7.9229127920297895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 7.863683664109491\n",
      "resetting env. episode reward total was 4.0. running mean: 7.825046827468396\n",
      "resetting env. episode reward total was 12.0. running mean: 7.866796359193713\n",
      "resetting env. episode reward total was 16.0. running mean: 7.948128395601776\n",
      "resetting env. episode reward total was 9.0. running mean: 7.9586471116457576\n",
      "resetting env. episode reward total was 8.0. running mean: 7.9590606405293\n",
      "resetting env. episode reward total was 6.0. running mean: 7.939470034124007\n",
      "resetting env. episode reward total was 10.0. running mean: 7.9600753337827665\n",
      "resetting env. episode reward total was 4.0. running mean: 7.920474580444939\n",
      "resetting env. episode reward total was 1.0. running mean: 7.851269834640489\n",
      "resetting env. episode reward total was 6.0. running mean: 7.832757136294084\n",
      "resetting env. episode reward total was 16.0. running mean: 7.914429564931144\n",
      "resetting env. episode reward total was 14.0. running mean: 7.975285269281832\n",
      "resetting env. episode reward total was 11.0. running mean: 8.005532416589013\n",
      "resetting env. episode reward total was 9.0. running mean: 8.015477092423122\n",
      "resetting env. episode reward total was 9.0. running mean: 8.02532232149889\n",
      "resetting env. episode reward total was 14.0. running mean: 8.085069098283903\n",
      "resetting env. episode reward total was 13.0. running mean: 8.134218407301065\n",
      "resetting env. episode reward total was 6.0. running mean: 8.112876223228055\n",
      "resetting env. episode reward total was 9.0. running mean: 8.121747460995774\n",
      "resetting env. episode reward total was -6.0. running mean: 7.980529986385817\n",
      "resetting env. episode reward total was 1.0. running mean: 7.9107246865219585\n",
      "resetting env. episode reward total was 13.0. running mean: 7.961617439656739\n",
      "resetting env. episode reward total was 16.0. running mean: 8.042001265260172\n",
      "resetting env. episode reward total was 5.0. running mean: 8.01158125260757\n",
      "resetting env. episode reward total was 15.0. running mean: 8.081465440081494\n",
      "resetting env. episode reward total was -7.0. running mean: 7.93065078568068\n",
      "resetting env. episode reward total was 3.0. running mean: 7.881344277823873\n",
      "resetting env. episode reward total was 1.0. running mean: 7.812530835045633\n",
      "resetting env. episode reward total was 2.0. running mean: 7.754405526695177\n",
      "resetting env. episode reward total was 4.0. running mean: 7.716861471428225\n",
      "resetting env. episode reward total was 15.0. running mean: 7.789692856713943\n",
      "resetting env. episode reward total was 9.0. running mean: 7.801795928146803\n",
      "resetting env. episode reward total was 15.0. running mean: 7.873777968865335\n",
      "resetting env. episode reward total was 16.0. running mean: 7.955040189176682\n",
      "resetting env. episode reward total was 2.0. running mean: 7.895489787284914\n",
      "resetting env. episode reward total was 6.0. running mean: 7.876534889412064\n",
      "resetting env. episode reward total was 9.0. running mean: 7.887769540517944\n",
      "resetting env. episode reward total was 8.0. running mean: 7.888891845112765\n",
      "resetting env. episode reward total was 9.0. running mean: 7.900002926661637\n",
      "resetting env. episode reward total was 11.0. running mean: 7.931002897395021\n",
      "resetting env. episode reward total was 1.0. running mean: 7.861692868421071\n",
      "resetting env. episode reward total was 10.0. running mean: 7.88307593973686\n",
      "resetting env. episode reward total was 8.0. running mean: 7.884245180339491\n",
      "resetting env. episode reward total was 15.0. running mean: 7.955402728536097\n",
      "resetting env. episode reward total was 2.0. running mean: 7.895848701250735\n",
      "resetting env. episode reward total was 5.0. running mean: 7.866890214238227\n",
      "resetting env. episode reward total was 5.0. running mean: 7.838221312095844\n",
      "resetting env. episode reward total was 10.0. running mean: 7.859839098974885\n",
      "resetting env. episode reward total was 11.0. running mean: 7.891240707985137\n",
      "resetting env. episode reward total was 16.0. running mean: 7.972328300905286\n",
      "resetting env. episode reward total was 15.0. running mean: 8.042605017896232\n",
      "resetting env. episode reward total was 2.0. running mean: 7.982178967717269\n",
      "resetting env. episode reward total was 6.0. running mean: 7.962357178040096\n",
      "resetting env. episode reward total was 9.0. running mean: 7.972733606259695\n",
      "resetting env. episode reward total was 6.0. running mean: 7.953006270197097\n",
      "resetting env. episode reward total was 10.0. running mean: 7.973476207495126\n",
      "resetting env. episode reward total was 6.0. running mean: 7.9537414454201745\n",
      "resetting env. episode reward total was 10.0. running mean: 7.974204030965972\n",
      "resetting env. episode reward total was 10.0. running mean: 7.994461990656312\n",
      "resetting env. episode reward total was 13.0. running mean: 8.04451737074975\n",
      "resetting env. episode reward total was 11.0. running mean: 8.074072197042252\n",
      "resetting env. episode reward total was 6.0. running mean: 8.053331475071829\n",
      "resetting env. episode reward total was 13.0. running mean: 8.102798160321111\n",
      "resetting env. episode reward total was 2.0. running mean: 8.041770178717899\n",
      "resetting env. episode reward total was 8.0. running mean: 8.041352476930719\n",
      "resetting env. episode reward total was 8.0. running mean: 8.040938952161412\n",
      "resetting env. episode reward total was 9.0. running mean: 8.050529562639797\n",
      "resetting env. episode reward total was 6.0. running mean: 8.030024267013399\n",
      "resetting env. episode reward total was -2.0. running mean: 7.929724024343265\n",
      "resetting env. episode reward total was 10.0. running mean: 7.950426784099832\n",
      "resetting env. episode reward total was 7.0. running mean: 7.940922516258834\n",
      "resetting env. episode reward total was 1.0. running mean: 7.871513291096246\n",
      "resetting env. episode reward total was 15.0. running mean: 7.942798158185284\n",
      "resetting env. episode reward total was 9.0. running mean: 7.953370176603431\n",
      "resetting env. episode reward total was -5.0. running mean: 7.823836474837397\n",
      "resetting env. episode reward total was 4.0. running mean: 7.785598110089023\n",
      "resetting env. episode reward total was 1.0. running mean: 7.7177421289881325\n",
      "resetting env. episode reward total was 9.0. running mean: 7.730564707698251\n",
      "resetting env. episode reward total was 10.0. running mean: 7.753259060621269\n",
      "resetting env. episode reward total was 1.0. running mean: 7.685726470015056\n",
      "resetting env. episode reward total was 10.0. running mean: 7.7088692053149055\n",
      "resetting env. episode reward total was -3.0. running mean: 7.601780513261756\n",
      "resetting env. episode reward total was 9.0. running mean: 7.615762708129139\n",
      "resetting env. episode reward total was 15.0. running mean: 7.689605081047848\n",
      "resetting env. episode reward total was 10.0. running mean: 7.712709030237369\n",
      "resetting env. episode reward total was 11.0. running mean: 7.745581939934996\n",
      "resetting env. episode reward total was 5.0. running mean: 7.718126120535646\n",
      "resetting env. episode reward total was 3.0. running mean: 7.67094485933029\n",
      "resetting env. episode reward total was 12.0. running mean: 7.714235410736987\n",
      "resetting env. episode reward total was 15.0. running mean: 7.787093056629617\n",
      "resetting env. episode reward total was -5.0. running mean: 7.659222126063321\n",
      "resetting env. episode reward total was 13.0. running mean: 7.712629904802688\n",
      "resetting env. episode reward total was 13.0. running mean: 7.7655036057546605\n",
      "resetting env. episode reward total was 9.0. running mean: 7.777848569697114\n",
      "resetting env. episode reward total was 1.0. running mean: 7.710070084000143\n",
      "resetting env. episode reward total was 14.0. running mean: 7.772969383160141\n",
      "resetting env. episode reward total was 9.0. running mean: 7.785239689328539\n",
      "resetting env. episode reward total was 7.0. running mean: 7.777387292435254\n",
      "resetting env. episode reward total was 12.0. running mean: 7.819613419510901\n",
      "resetting env. episode reward total was 11.0. running mean: 7.851417285315792\n",
      "resetting env. episode reward total was 4.0. running mean: 7.812903112462634\n",
      "resetting env. episode reward total was 6.0. running mean: 7.794774081338008\n",
      "resetting env. episode reward total was 14.0. running mean: 7.856826340524627\n",
      "resetting env. episode reward total was 7.0. running mean: 7.848258077119381\n",
      "resetting env. episode reward total was 10.0. running mean: 7.869775496348186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 7.891077741384704\n",
      "resetting env. episode reward total was 8.0. running mean: 7.892166963970857\n",
      "resetting env. episode reward total was 3.0. running mean: 7.843245294331149\n",
      "resetting env. episode reward total was 8.0. running mean: 7.844812841387838\n",
      "resetting env. episode reward total was 9.0. running mean: 7.856364712973959\n",
      "resetting env. episode reward total was 10.0. running mean: 7.877801065844219\n",
      "resetting env. episode reward total was 7.0. running mean: 7.869023055185777\n",
      "resetting env. episode reward total was 12.0. running mean: 7.91033282463392\n",
      "resetting env. episode reward total was 3.0. running mean: 7.861229496387581\n",
      "resetting env. episode reward total was 8.0. running mean: 7.862617201423705\n",
      "resetting env. episode reward total was 15.0. running mean: 7.9339910294094675\n",
      "resetting env. episode reward total was 8.0. running mean: 7.934651119115373\n",
      "resetting env. episode reward total was 9.0. running mean: 7.9453046079242196\n",
      "resetting env. episode reward total was 15.0. running mean: 8.015851561844977\n",
      "resetting env. episode reward total was 9.0. running mean: 8.025693046226527\n",
      "resetting env. episode reward total was 9.0. running mean: 8.035436115764261\n",
      "resetting env. episode reward total was 12.0. running mean: 8.075081754606618\n",
      "resetting env. episode reward total was 7.0. running mean: 8.064330937060552\n",
      "resetting env. episode reward total was 1.0. running mean: 7.993687627689946\n",
      "resetting env. episode reward total was 2.0. running mean: 7.933750751413045\n",
      "resetting env. episode reward total was 8.0. running mean: 7.934413243898915\n",
      "resetting env. episode reward total was 16.0. running mean: 8.015069111459924\n",
      "resetting env. episode reward total was 2.0. running mean: 7.954918420345325\n",
      "resetting env. episode reward total was -1.0. running mean: 7.865369236141872\n",
      "resetting env. episode reward total was 7.0. running mean: 7.856715543780453\n",
      "resetting env. episode reward total was 1.0. running mean: 7.788148388342648\n",
      "resetting env. episode reward total was 9.0. running mean: 7.800266904459222\n",
      "resetting env. episode reward total was 1.0. running mean: 7.73226423541463\n",
      "resetting env. episode reward total was 12.0. running mean: 7.7749415930604835\n",
      "resetting env. episode reward total was 3.0. running mean: 7.727192177129879\n",
      "resetting env. episode reward total was 9.0. running mean: 7.73992025535858\n",
      "resetting env. episode reward total was -1.0. running mean: 7.652521052804994\n",
      "resetting env. episode reward total was 13.0. running mean: 7.705995842276944\n",
      "resetting env. episode reward total was 4.0. running mean: 7.668935883854174\n",
      "resetting env. episode reward total was 4.0. running mean: 7.632246525015632\n",
      "resetting env. episode reward total was -1.0. running mean: 7.545924059765476\n",
      "resetting env. episode reward total was 4.0. running mean: 7.510464819167821\n",
      "resetting env. episode reward total was 10.0. running mean: 7.535360170976142\n",
      "resetting env. episode reward total was 9.0. running mean: 7.5500065692663805\n",
      "resetting env. episode reward total was 4.0. running mean: 7.514506503573717\n",
      "resetting env. episode reward total was 3.0. running mean: 7.46936143853798\n",
      "resetting env. episode reward total was -1.0. running mean: 7.384667824152601\n",
      "resetting env. episode reward total was -5.0. running mean: 7.260821145911075\n",
      "resetting env. episode reward total was 10.0. running mean: 7.288212934451964\n",
      "resetting env. episode reward total was 1.0. running mean: 7.225330805107444\n",
      "resetting env. episode reward total was 10.0. running mean: 7.25307749705637\n",
      "resetting env. episode reward total was 6.0. running mean: 7.2405467220858055\n",
      "resetting env. episode reward total was 8.0. running mean: 7.248141254864947\n",
      "resetting env. episode reward total was 10.0. running mean: 7.275659842316298\n",
      "resetting env. episode reward total was -8.0. running mean: 7.122903243893135\n",
      "resetting env. episode reward total was 16.0. running mean: 7.211674211454204\n",
      "resetting env. episode reward total was 7.0. running mean: 7.2095574693396625\n",
      "resetting env. episode reward total was 3.0. running mean: 7.167461894646266\n",
      "resetting env. episode reward total was 14.0. running mean: 7.235787275699803\n",
      "resetting env. episode reward total was 9.0. running mean: 7.253429402942804\n",
      "resetting env. episode reward total was 9.0. running mean: 7.2708951089133755\n",
      "resetting env. episode reward total was 7.0. running mean: 7.268186157824242\n",
      "resetting env. episode reward total was 11.0. running mean: 7.305504296245999\n",
      "resetting env. episode reward total was 11.0. running mean: 7.342449253283539\n",
      "resetting env. episode reward total was 3.0. running mean: 7.299024760750704\n",
      "resetting env. episode reward total was 8.0. running mean: 7.306034513143198\n",
      "resetting env. episode reward total was 7.0. running mean: 7.302974168011766\n",
      "resetting env. episode reward total was 6.0. running mean: 7.289944426331648\n",
      "resetting env. episode reward total was 9.0. running mean: 7.307044982068332\n",
      "resetting env. episode reward total was 7.0. running mean: 7.303974532247649\n",
      "resetting env. episode reward total was 2.0. running mean: 7.250934786925172\n",
      "resetting env. episode reward total was 18.0. running mean: 7.35842543905592\n",
      "resetting env. episode reward total was 3.0. running mean: 7.314841184665361\n",
      "resetting env. episode reward total was 9.0. running mean: 7.331692772818707\n",
      "resetting env. episode reward total was 2.0. running mean: 7.27837584509052\n",
      "resetting env. episode reward total was 5.0. running mean: 7.255592086639615\n",
      "resetting env. episode reward total was 6.0. running mean: 7.243036165773218\n",
      "resetting env. episode reward total was 6.0. running mean: 7.230605804115486\n",
      "resetting env. episode reward total was 5.0. running mean: 7.2082997460743305\n",
      "resetting env. episode reward total was 14.0. running mean: 7.276216748613587\n",
      "resetting env. episode reward total was 2.0. running mean: 7.22345458112745\n",
      "resetting env. episode reward total was 3.0. running mean: 7.181220035316176\n",
      "resetting env. episode reward total was -1.0. running mean: 7.0994078349630145\n",
      "resetting env. episode reward total was 13.0. running mean: 7.158413756613384\n",
      "resetting env. episode reward total was 14.0. running mean: 7.226829619047249\n",
      "resetting env. episode reward total was 3.0. running mean: 7.184561322856777\n",
      "resetting env. episode reward total was 10.0. running mean: 7.212715709628209\n",
      "resetting env. episode reward total was 7.0. running mean: 7.210588552531927\n",
      "resetting env. episode reward total was 2.0. running mean: 7.1584826670066075\n",
      "resetting env. episode reward total was 12.0. running mean: 7.206897840336541\n",
      "resetting env. episode reward total was 12.0. running mean: 7.254828861933176\n",
      "resetting env. episode reward total was 6.0. running mean: 7.242280573313844\n",
      "resetting env. episode reward total was 3.0. running mean: 7.199857767580705\n",
      "resetting env. episode reward total was 12.0. running mean: 7.247859189904898\n",
      "resetting env. episode reward total was 15.0. running mean: 7.325380598005849\n",
      "resetting env. episode reward total was -1.0. running mean: 7.242126792025791\n",
      "resetting env. episode reward total was 5.0. running mean: 7.219705524105533\n",
      "resetting env. episode reward total was 12.0. running mean: 7.267508468864477\n",
      "resetting env. episode reward total was 6.0. running mean: 7.254833384175832\n",
      "resetting env. episode reward total was 8.0. running mean: 7.262285050334074\n",
      "resetting env. episode reward total was 7.0. running mean: 7.259662199830734\n",
      "resetting env. episode reward total was 11.0. running mean: 7.297065577832427\n",
      "resetting env. episode reward total was 6.0. running mean: 7.284094922054102\n",
      "resetting env. episode reward total was 10.0. running mean: 7.31125397283356\n",
      "resetting env. episode reward total was 5.0. running mean: 7.288141433105224\n",
      "resetting env. episode reward total was 6.0. running mean: 7.275260018774172\n",
      "resetting env. episode reward total was 7.0. running mean: 7.2725074185864305\n",
      "resetting env. episode reward total was 11.0. running mean: 7.309782344400566\n",
      "resetting env. episode reward total was 5.0. running mean: 7.28668452095656\n",
      "resetting env. episode reward total was 12.0. running mean: 7.333817675746994\n",
      "resetting env. episode reward total was 6.0. running mean: 7.320479498989524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 7.3672747039996285\n",
      "resetting env. episode reward total was 3.0. running mean: 7.3236019569596325\n",
      "resetting env. episode reward total was 3.0. running mean: 7.2803659373900365\n",
      "resetting env. episode reward total was -3.0. running mean: 7.1775622780161354\n",
      "resetting env. episode reward total was 2.0. running mean: 7.125786655235974\n",
      "resetting env. episode reward total was 3.0. running mean: 7.084528788683614\n",
      "resetting env. episode reward total was 7.0. running mean: 7.083683500796778\n",
      "resetting env. episode reward total was 1.0. running mean: 7.02284666578881\n",
      "resetting env. episode reward total was 12.0. running mean: 7.072618199130922\n",
      "resetting env. episode reward total was -4.0. running mean: 6.961892017139612\n",
      "resetting env. episode reward total was 7.0. running mean: 6.962273096968216\n",
      "resetting env. episode reward total was -2.0. running mean: 6.872650365998535\n",
      "resetting env. episode reward total was 15.0. running mean: 6.9539238623385495\n",
      "resetting env. episode reward total was 4.0. running mean: 6.924384623715164\n",
      "resetting env. episode reward total was 10.0. running mean: 6.955140777478012\n",
      "resetting env. episode reward total was 8.0. running mean: 6.965589369703232\n",
      "resetting env. episode reward total was -3.0. running mean: 6.8659334760062\n",
      "resetting env. episode reward total was 13.0. running mean: 6.927274141246138\n",
      "resetting env. episode reward total was 2.0. running mean: 6.878001399833676\n",
      "resetting env. episode reward total was -5.0. running mean: 6.759221385835339\n",
      "resetting env. episode reward total was 3.0. running mean: 6.721629171976986\n",
      "resetting env. episode reward total was 9.0. running mean: 6.744412880257215\n",
      "resetting env. episode reward total was 15.0. running mean: 6.826968751454643\n",
      "resetting env. episode reward total was 13.0. running mean: 6.888699063940097\n",
      "resetting env. episode reward total was -5.0. running mean: 6.769812073300696\n",
      "resetting env. episode reward total was 17.0. running mean: 6.872113952567689\n",
      "resetting env. episode reward total was 2.0. running mean: 6.823392813042012\n",
      "resetting env. episode reward total was 4.0. running mean: 6.795158884911592\n",
      "resetting env. episode reward total was 6.0. running mean: 6.787207296062475\n",
      "resetting env. episode reward total was 6.0. running mean: 6.77933522310185\n",
      "resetting env. episode reward total was 8.0. running mean: 6.791541870870832\n",
      "resetting env. episode reward total was 8.0. running mean: 6.803626452162123\n",
      "resetting env. episode reward total was 7.0. running mean: 6.805590187640502\n",
      "resetting env. episode reward total was 9.0. running mean: 6.827534285764097\n",
      "resetting env. episode reward total was 8.0. running mean: 6.839258942906456\n",
      "resetting env. episode reward total was 9.0. running mean: 6.860866353477391\n",
      "resetting env. episode reward total was 8.0. running mean: 6.872257689942617\n",
      "resetting env. episode reward total was 5.0. running mean: 6.853535113043191\n",
      "resetting env. episode reward total was 17.0. running mean: 6.954999761912759\n",
      "resetting env. episode reward total was 8.0. running mean: 6.965449764293631\n",
      "resetting env. episode reward total was 13.0. running mean: 7.025795266650694\n",
      "resetting env. episode reward total was 12.0. running mean: 7.075537313984187\n",
      "resetting env. episode reward total was 3.0. running mean: 7.034781940844345\n",
      "resetting env. episode reward total was 8.0. running mean: 7.044434121435902\n",
      "resetting env. episode reward total was 10.0. running mean: 7.073989780221543\n",
      "resetting env. episode reward total was 5.0. running mean: 7.053249882419327\n",
      "resetting env. episode reward total was 8.0. running mean: 7.062717383595134\n",
      "resetting env. episode reward total was 17.0. running mean: 7.1620902097591825\n",
      "resetting env. episode reward total was 7.0. running mean: 7.160469307661591\n",
      "resetting env. episode reward total was 12.0. running mean: 7.208864614584975\n",
      "resetting env. episode reward total was -2.0. running mean: 7.116775968439126\n",
      "resetting env. episode reward total was -4.0. running mean: 7.005608208754735\n",
      "resetting env. episode reward total was 7.0. running mean: 7.005552126667188\n",
      "resetting env. episode reward total was 7.0. running mean: 7.005496605400516\n",
      "resetting env. episode reward total was 7.0. running mean: 7.005441639346511\n",
      "resetting env. episode reward total was 7.0. running mean: 7.005387222953046\n",
      "resetting env. episode reward total was 8.0. running mean: 7.015333350723515\n",
      "resetting env. episode reward total was 16.0. running mean: 7.10518001721628\n",
      "resetting env. episode reward total was 13.0. running mean: 7.164128217044117\n",
      "resetting env. episode reward total was 7.0. running mean: 7.162486934873676\n",
      "resetting env. episode reward total was 6.0. running mean: 7.150862065524938\n",
      "resetting env. episode reward total was 6.0. running mean: 7.1393534448696885\n",
      "resetting env. episode reward total was 11.0. running mean: 7.1779599104209915\n",
      "resetting env. episode reward total was 5.0. running mean: 7.156180311316781\n",
      "resetting env. episode reward total was 5.0. running mean: 7.134618508203613\n",
      "resetting env. episode reward total was 7.0. running mean: 7.133272323121577\n",
      "resetting env. episode reward total was 13.0. running mean: 7.191939599890361\n",
      "resetting env. episode reward total was 4.0. running mean: 7.160020203891458\n",
      "resetting env. episode reward total was 4.0. running mean: 7.128420001852543\n",
      "resetting env. episode reward total was 8.0. running mean: 7.137135801834018\n",
      "resetting env. episode reward total was 8.0. running mean: 7.145764443815677\n",
      "resetting env. episode reward total was 8.0. running mean: 7.154306799377521\n",
      "resetting env. episode reward total was 2.0. running mean: 7.102763731383745\n",
      "resetting env. episode reward total was 15.0. running mean: 7.181736094069908\n",
      "resetting env. episode reward total was 8.0. running mean: 7.189918733129209\n",
      "resetting env. episode reward total was 13.0. running mean: 7.248019545797917\n",
      "resetting env. episode reward total was 15.0. running mean: 7.325539350339938\n",
      "resetting env. episode reward total was 10.0. running mean: 7.352283956836539\n",
      "resetting env. episode reward total was 13.0. running mean: 7.408761117268173\n",
      "resetting env. episode reward total was -5.0. running mean: 7.2846735060954915\n",
      "resetting env. episode reward total was -1.0. running mean: 7.201826771034536\n",
      "resetting env. episode reward total was 5.0. running mean: 7.179808503324191\n",
      "resetting env. episode reward total was 6.0. running mean: 7.168010418290948\n",
      "resetting env. episode reward total was 8.0. running mean: 7.176330314108039\n",
      "resetting env. episode reward total was -2.0. running mean: 7.08456701096696\n",
      "resetting env. episode reward total was 4.0. running mean: 7.05372134085729\n",
      "resetting env. episode reward total was 6.0. running mean: 7.043184127448717\n",
      "resetting env. episode reward total was 6.0. running mean: 7.032752286174229\n",
      "resetting env. episode reward total was 7.0. running mean: 7.032424763312487\n",
      "resetting env. episode reward total was 6.0. running mean: 7.022100515679361\n",
      "resetting env. episode reward total was 4.0. running mean: 6.991879510522568\n",
      "resetting env. episode reward total was 12.0. running mean: 7.041960715417343\n",
      "resetting env. episode reward total was 13.0. running mean: 7.101541108263169\n",
      "resetting env. episode reward total was 2.0. running mean: 7.050525697180537\n",
      "resetting env. episode reward total was 8.0. running mean: 7.060020440208731\n",
      "resetting env. episode reward total was -3.0. running mean: 6.959420235806644\n",
      "resetting env. episode reward total was 6.0. running mean: 6.949826033448577\n",
      "resetting env. episode reward total was 15.0. running mean: 7.030327773114092\n",
      "resetting env. episode reward total was 6.0. running mean: 7.02002449538295\n",
      "resetting env. episode reward total was 7.0. running mean: 7.019824250429121\n",
      "resetting env. episode reward total was 6.0. running mean: 7.00962600792483\n",
      "resetting env. episode reward total was 4.0. running mean: 6.979529747845581\n",
      "resetting env. episode reward total was 10.0. running mean: 7.009734450367125\n",
      "resetting env. episode reward total was 5.0. running mean: 6.989637105863453\n",
      "resetting env. episode reward total was -9.0. running mean: 6.829740734804819\n",
      "resetting env. episode reward total was 10.0. running mean: 6.8614433274567705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 6.922828894182203\n",
      "resetting env. episode reward total was 12.0. running mean: 6.973600605240381\n",
      "resetting env. episode reward total was 14.0. running mean: 7.043864599187977\n",
      "resetting env. episode reward total was 7.0. running mean: 7.043425953196097\n",
      "resetting env. episode reward total was 11.0. running mean: 7.082991693664137\n",
      "resetting env. episode reward total was 12.0. running mean: 7.132161776727496\n",
      "resetting env. episode reward total was 16.0. running mean: 7.220840158960221\n",
      "resetting env. episode reward total was 5.0. running mean: 7.1986317573706184\n",
      "resetting env. episode reward total was 5.0. running mean: 7.176645439796912\n",
      "resetting env. episode reward total was -7.0. running mean: 7.034878985398943\n",
      "resetting env. episode reward total was -2.0. running mean: 6.944530195544954\n",
      "resetting env. episode reward total was 10.0. running mean: 6.975084893589504\n",
      "resetting env. episode reward total was 14.0. running mean: 7.045334044653608\n",
      "resetting env. episode reward total was 8.0. running mean: 7.054880704207072\n",
      "resetting env. episode reward total was 14.0. running mean: 7.124331897165001\n",
      "resetting env. episode reward total was -2.0. running mean: 7.033088578193351\n",
      "resetting env. episode reward total was 14.0. running mean: 7.1027576924114175\n",
      "resetting env. episode reward total was 6.0. running mean: 7.0917301154873025\n",
      "resetting env. episode reward total was 2.0. running mean: 7.040812814332429\n",
      "resetting env. episode reward total was -2.0. running mean: 6.950404686189105\n",
      "resetting env. episode reward total was 11.0. running mean: 6.990900639327214\n",
      "resetting env. episode reward total was 6.0. running mean: 6.980991632933941\n",
      "resetting env. episode reward total was 16.0. running mean: 7.071181716604602\n",
      "resetting env. episode reward total was 9.0. running mean: 7.090469899438555\n",
      "resetting env. episode reward total was 6.0. running mean: 7.079565200444169\n",
      "resetting env. episode reward total was 3.0. running mean: 7.038769548439728\n",
      "resetting env. episode reward total was 10.0. running mean: 7.06838185295533\n",
      "resetting env. episode reward total was 7.0. running mean: 7.067698034425777\n",
      "resetting env. episode reward total was -1.0. running mean: 6.987021054081519\n",
      "resetting env. episode reward total was 8.0. running mean: 6.997150843540704\n",
      "resetting env. episode reward total was 7.0. running mean: 6.997179335105297\n",
      "resetting env. episode reward total was 12.0. running mean: 7.047207541754244\n",
      "resetting env. episode reward total was -4.0. running mean: 6.936735466336702\n",
      "resetting env. episode reward total was -8.0. running mean: 6.787368111673335\n",
      "resetting env. episode reward total was 10.0. running mean: 6.819494430556602\n",
      "resetting env. episode reward total was 7.0. running mean: 6.821299486251036\n",
      "resetting env. episode reward total was 8.0. running mean: 6.833086491388525\n",
      "resetting env. episode reward total was 13.0. running mean: 6.89475562647464\n",
      "resetting env. episode reward total was -5.0. running mean: 6.7758080702098935\n",
      "resetting env. episode reward total was 1.0. running mean: 6.7180499895077945\n",
      "resetting env. episode reward total was 15.0. running mean: 6.800869489612717\n",
      "resetting env. episode reward total was 3.0. running mean: 6.76286079471659\n",
      "resetting env. episode reward total was -1.0. running mean: 6.685232186769425\n",
      "resetting env. episode reward total was 11.0. running mean: 6.728379864901731\n",
      "resetting env. episode reward total was 9.0. running mean: 6.751096066252713\n",
      "resetting env. episode reward total was 8.0. running mean: 6.763585105590186\n",
      "resetting env. episode reward total was -3.0. running mean: 6.665949254534284\n",
      "resetting env. episode reward total was 3.0. running mean: 6.629289761988941\n",
      "resetting env. episode reward total was -1.0. running mean: 6.552996864369052\n",
      "resetting env. episode reward total was 5.0. running mean: 6.537466895725362\n",
      "resetting env. episode reward total was 6.0. running mean: 6.532092226768108\n",
      "resetting env. episode reward total was 8.0. running mean: 6.546771304500427\n",
      "resetting env. episode reward total was 9.0. running mean: 6.571303591455423\n",
      "resetting env. episode reward total was 9.0. running mean: 6.595590555540868\n",
      "resetting env. episode reward total was -9.0. running mean: 6.439634649985459\n",
      "resetting env. episode reward total was 9.0. running mean: 6.465238303485604\n",
      "resetting env. episode reward total was 12.0. running mean: 6.520585920450748\n",
      "resetting env. episode reward total was 13.0. running mean: 6.585380061246241\n",
      "resetting env. episode reward total was 11.0. running mean: 6.629526260633779\n",
      "resetting env. episode reward total was 10.0. running mean: 6.663230998027441\n",
      "resetting env. episode reward total was 11.0. running mean: 6.706598688047166\n",
      "resetting env. episode reward total was 15.0. running mean: 6.789532701166695\n",
      "resetting env. episode reward total was 8.0. running mean: 6.801637374155028\n",
      "resetting env. episode reward total was 6.0. running mean: 6.793621000413477\n",
      "resetting env. episode reward total was 10.0. running mean: 6.825684790409342\n",
      "resetting env. episode reward total was 9.0. running mean: 6.847427942505249\n",
      "resetting env. episode reward total was 9.0. running mean: 6.868953663080196\n",
      "resetting env. episode reward total was 11.0. running mean: 6.910264126449395\n",
      "resetting env. episode reward total was 1.0. running mean: 6.8511614851849005\n",
      "resetting env. episode reward total was 6.0. running mean: 6.842649870333051\n",
      "resetting env. episode reward total was 7.0. running mean: 6.84422337162972\n",
      "resetting env. episode reward total was 5.0. running mean: 6.825781137913423\n",
      "resetting env. episode reward total was 6.0. running mean: 6.817523326534288\n",
      "resetting env. episode reward total was 4.0. running mean: 6.789348093268945\n",
      "resetting env. episode reward total was 10.0. running mean: 6.821454612336255\n",
      "resetting env. episode reward total was -9.0. running mean: 6.663240066212892\n",
      "resetting env. episode reward total was 8.0. running mean: 6.676607665550764\n",
      "resetting env. episode reward total was 4.0. running mean: 6.649841588895256\n",
      "resetting env. episode reward total was 16.0. running mean: 6.743343173006303\n",
      "resetting env. episode reward total was 16.0. running mean: 6.83590974127624\n",
      "resetting env. episode reward total was 4.0. running mean: 6.807550643863478\n",
      "resetting env. episode reward total was 11.0. running mean: 6.849475137424844\n",
      "resetting env. episode reward total was 8.0. running mean: 6.860980386050596\n",
      "resetting env. episode reward total was -1.0. running mean: 6.78237058219009\n",
      "resetting env. episode reward total was 11.0. running mean: 6.824546876368189\n",
      "resetting env. episode reward total was 6.0. running mean: 6.816301407604507\n",
      "resetting env. episode reward total was 12.0. running mean: 6.8681383935284614\n",
      "resetting env. episode reward total was 1.0. running mean: 6.809457009593176\n",
      "resetting env. episode reward total was 13.0. running mean: 6.871362439497244\n",
      "resetting env. episode reward total was 9.0. running mean: 6.892648815102271\n",
      "resetting env. episode reward total was 6.0. running mean: 6.883722326951248\n",
      "resetting env. episode reward total was 1.0. running mean: 6.824885103681735\n",
      "resetting env. episode reward total was 9.0. running mean: 6.846636252644918\n",
      "resetting env. episode reward total was 6.0. running mean: 6.8381698901184675\n",
      "resetting env. episode reward total was 13.0. running mean: 6.899788191217283\n",
      "resetting env. episode reward total was 13.0. running mean: 6.96079030930511\n",
      "resetting env. episode reward total was 8.0. running mean: 6.971182406212058\n",
      "resetting env. episode reward total was 4.0. running mean: 6.941470582149938\n",
      "resetting env. episode reward total was 13.0. running mean: 7.002055876328439\n",
      "resetting env. episode reward total was 9.0. running mean: 7.022035317565154\n",
      "resetting env. episode reward total was 18.0. running mean: 7.131814964389503\n",
      "resetting env. episode reward total was 19.0. running mean: 7.250496814745608\n",
      "resetting env. episode reward total was 3.0. running mean: 7.207991846598152\n",
      "resetting env. episode reward total was 11.0. running mean: 7.245911928132171\n",
      "resetting env. episode reward total was 6.0. running mean: 7.233452808850848\n",
      "resetting env. episode reward total was 7.0. running mean: 7.23111828076234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: 7.188807097954717\n",
      "resetting env. episode reward total was 9.0. running mean: 7.20691902697517\n",
      "resetting env. episode reward total was 4.0. running mean: 7.174849836705418\n",
      "resetting env. episode reward total was 12.0. running mean: 7.223101338338363\n",
      "resetting env. episode reward total was 11.0. running mean: 7.26087032495498\n",
      "resetting env. episode reward total was 6.0. running mean: 7.24826162170543\n",
      "resetting env. episode reward total was 12.0. running mean: 7.2957790054883755\n",
      "resetting env. episode reward total was 9.0. running mean: 7.312821215433492\n",
      "resetting env. episode reward total was 9.0. running mean: 7.329693003279157\n",
      "resetting env. episode reward total was 9.0. running mean: 7.346396073246366\n",
      "resetting env. episode reward total was 5.0. running mean: 7.322932112513902\n",
      "resetting env. episode reward total was 9.0. running mean: 7.3397027913887625\n",
      "resetting env. episode reward total was 9.0. running mean: 7.356305763474874\n",
      "resetting env. episode reward total was 13.0. running mean: 7.412742705840126\n",
      "resetting env. episode reward total was 4.0. running mean: 7.378615278781725\n",
      "resetting env. episode reward total was 3.0. running mean: 7.334829125993908\n",
      "resetting env. episode reward total was 12.0. running mean: 7.381480834733969\n",
      "resetting env. episode reward total was 6.0. running mean: 7.367666026386629\n",
      "resetting env. episode reward total was 7.0. running mean: 7.3639893661227624\n",
      "resetting env. episode reward total was 9.0. running mean: 7.380349472461535\n",
      "resetting env. episode reward total was 9.0. running mean: 7.396545977736919\n",
      "resetting env. episode reward total was 7.0. running mean: 7.39258051795955\n",
      "resetting env. episode reward total was 8.0. running mean: 7.398654712779954\n",
      "resetting env. episode reward total was 8.0. running mean: 7.404668165652154\n",
      "resetting env. episode reward total was 5.0. running mean: 7.380621483995633\n",
      "resetting env. episode reward total was 6.0. running mean: 7.366815269155675\n",
      "resetting env. episode reward total was 6.0. running mean: 7.353147116464118\n",
      "resetting env. episode reward total was 3.0. running mean: 7.309615645299477\n",
      "resetting env. episode reward total was 6.0. running mean: 7.2965194888464815\n",
      "resetting env. episode reward total was 9.0. running mean: 7.313554293958016\n",
      "resetting env. episode reward total was 6.0. running mean: 7.3004187510184355\n",
      "resetting env. episode reward total was 8.0. running mean: 7.307414563508251\n",
      "resetting env. episode reward total was 9.0. running mean: 7.324340417873168\n",
      "resetting env. episode reward total was 7.0. running mean: 7.321097013694437\n",
      "resetting env. episode reward total was 2.0. running mean: 7.267886043557492\n",
      "resetting env. episode reward total was 12.0. running mean: 7.315207183121917\n",
      "resetting env. episode reward total was -4.0. running mean: 7.202055111290697\n",
      "resetting env. episode reward total was 12.0. running mean: 7.250034560177791\n",
      "resetting env. episode reward total was -1.0. running mean: 7.167534214576013\n",
      "resetting env. episode reward total was 7.0. running mean: 7.1658588724302525\n",
      "resetting env. episode reward total was 9.0. running mean: 7.18420028370595\n",
      "resetting env. episode reward total was 10.0. running mean: 7.21235828086889\n",
      "resetting env. episode reward total was 7.0. running mean: 7.2102346980602015\n",
      "resetting env. episode reward total was -1.0. running mean: 7.1281323510796\n",
      "resetting env. episode reward total was 4.0. running mean: 7.096851027568804\n",
      "resetting env. episode reward total was -1.0. running mean: 7.015882517293116\n",
      "resetting env. episode reward total was 9.0. running mean: 7.035723692120185\n",
      "resetting env. episode reward total was -1.0. running mean: 6.955366455198983\n",
      "resetting env. episode reward total was 9.0. running mean: 6.975812790646993\n",
      "resetting env. episode reward total was 12.0. running mean: 7.026054662740523\n",
      "resetting env. episode reward total was 9.0. running mean: 7.045794116113118\n",
      "resetting env. episode reward total was 2.0. running mean: 6.995336174951986\n",
      "resetting env. episode reward total was 5.0. running mean: 6.975382813202466\n",
      "resetting env. episode reward total was 10.0. running mean: 7.005628985070441\n",
      "resetting env. episode reward total was -5.0. running mean: 6.885572695219737\n",
      "resetting env. episode reward total was 9.0. running mean: 6.906716968267539\n",
      "resetting env. episode reward total was 6.0. running mean: 6.8976497985848635\n",
      "resetting env. episode reward total was 8.0. running mean: 6.908673300599015\n",
      "resetting env. episode reward total was 4.0. running mean: 6.879586567593025\n",
      "resetting env. episode reward total was 3.0. running mean: 6.840790701917094\n",
      "resetting env. episode reward total was 12.0. running mean: 6.892382794897923\n",
      "resetting env. episode reward total was 5.0. running mean: 6.873458966948943\n",
      "resetting env. episode reward total was 9.0. running mean: 6.894724377279454\n",
      "resetting env. episode reward total was 8.0. running mean: 6.90577713350666\n",
      "resetting env. episode reward total was 12.0. running mean: 6.956719362171593\n",
      "resetting env. episode reward total was 11.0. running mean: 6.997152168549877\n",
      "resetting env. episode reward total was 8.0. running mean: 7.007180646864378\n",
      "resetting env. episode reward total was 7.0. running mean: 7.007108840395735\n",
      "resetting env. episode reward total was 15.0. running mean: 7.087037751991778\n",
      "resetting env. episode reward total was 5.0. running mean: 7.06616737447186\n",
      "resetting env. episode reward total was 9.0. running mean: 7.085505700727141\n",
      "resetting env. episode reward total was -6.0. running mean: 6.954650643719869\n",
      "resetting env. episode reward total was 13.0. running mean: 7.015104137282671\n",
      "resetting env. episode reward total was 9.0. running mean: 7.034953095909843\n",
      "resetting env. episode reward total was -3.0. running mean: 6.934603564950745\n",
      "resetting env. episode reward total was 9.0. running mean: 6.955257529301237\n",
      "resetting env. episode reward total was 7.0. running mean: 6.955704954008225\n",
      "resetting env. episode reward total was -6.0. running mean: 6.826147904468144\n",
      "resetting env. episode reward total was 16.0. running mean: 6.917886425423462\n",
      "resetting env. episode reward total was 13.0. running mean: 6.9787075611692275\n",
      "resetting env. episode reward total was 11.0. running mean: 7.018920485557535\n",
      "resetting env. episode reward total was -1.0. running mean: 6.93873128070196\n",
      "resetting env. episode reward total was 13.0. running mean: 6.999343967894941\n",
      "resetting env. episode reward total was 5.0. running mean: 6.979350528215991\n",
      "resetting env. episode reward total was 9.0. running mean: 6.999557022933831\n",
      "resetting env. episode reward total was 2.0. running mean: 6.949561452704493\n",
      "resetting env. episode reward total was 6.0. running mean: 6.940065838177447\n",
      "resetting env. episode reward total was 11.0. running mean: 6.980665179795673\n",
      "resetting env. episode reward total was -2.0. running mean: 6.890858527997716\n",
      "resetting env. episode reward total was 1.0. running mean: 6.831949942717739\n",
      "resetting env. episode reward total was -5.0. running mean: 6.713630443290562\n",
      "resetting env. episode reward total was 7.0. running mean: 6.716494138857656\n",
      "resetting env. episode reward total was 6.0. running mean: 6.709329197469079\n",
      "resetting env. episode reward total was 9.0. running mean: 6.732235905494388\n",
      "resetting env. episode reward total was 1.0. running mean: 6.674913546439444\n",
      "resetting env. episode reward total was 7.0. running mean: 6.67816441097505\n",
      "resetting env. episode reward total was 15.0. running mean: 6.7613827668653\n",
      "resetting env. episode reward total was 10.0. running mean: 6.793768939196647\n",
      "resetting env. episode reward total was 10.0. running mean: 6.82583124980468\n",
      "resetting env. episode reward total was -1.0. running mean: 6.747572937306633\n",
      "resetting env. episode reward total was 11.0. running mean: 6.790097207933567\n",
      "resetting env. episode reward total was 9.0. running mean: 6.8121962358542305\n",
      "resetting env. episode reward total was 8.0. running mean: 6.824074273495688\n",
      "resetting env. episode reward total was 12.0. running mean: 6.8758335307607314\n",
      "resetting env. episode reward total was -5.0. running mean: 6.757075195453124\n",
      "resetting env. episode reward total was 3.0. running mean: 6.719504443498593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 6.7523093990636065\n",
      "resetting env. episode reward total was 9.0. running mean: 6.77478630507297\n",
      "resetting env. episode reward total was 6.0. running mean: 6.7670384420222405\n",
      "resetting env. episode reward total was 13.0. running mean: 6.829368057602018\n",
      "resetting env. episode reward total was 15.0. running mean: 6.911074377025998\n",
      "resetting env. episode reward total was 11.0. running mean: 6.951963633255739\n",
      "resetting env. episode reward total was 15.0. running mean: 7.032443996923181\n",
      "resetting env. episode reward total was 8.0. running mean: 7.042119556953949\n",
      "resetting env. episode reward total was 7.0. running mean: 7.04169836138441\n",
      "resetting env. episode reward total was 6.0. running mean: 7.031281377770565\n",
      "resetting env. episode reward total was 12.0. running mean: 7.080968563992859\n",
      "resetting env. episode reward total was 9.0. running mean: 7.10015887835293\n",
      "resetting env. episode reward total was 12.0. running mean: 7.149157289569401\n",
      "resetting env. episode reward total was 7.0. running mean: 7.147665716673707\n",
      "resetting env. episode reward total was 12.0. running mean: 7.1961890595069695\n",
      "resetting env. episode reward total was 4.0. running mean: 7.1642271689119\n",
      "resetting env. episode reward total was 18.0. running mean: 7.272584897222781\n",
      "resetting env. episode reward total was 5.0. running mean: 7.249859048250553\n",
      "resetting env. episode reward total was 6.0. running mean: 7.237360457768046\n",
      "resetting env. episode reward total was 3.0. running mean: 7.1949868531903665\n",
      "resetting env. episode reward total was 5.0. running mean: 7.173036984658463\n",
      "resetting env. episode reward total was 3.0. running mean: 7.131306614811878\n",
      "resetting env. episode reward total was -6.0. running mean: 6.99999354866376\n",
      "resetting env. episode reward total was 5.0. running mean: 6.979993613177122\n",
      "resetting env. episode reward total was 6.0. running mean: 6.9701936770453505\n",
      "resetting env. episode reward total was 4.0. running mean: 6.940491740274897\n",
      "resetting env. episode reward total was 8.0. running mean: 6.951086822872148\n",
      "resetting env. episode reward total was 1.0. running mean: 6.891575954643427\n",
      "resetting env. episode reward total was 10.0. running mean: 6.922660195096992\n",
      "resetting env. episode reward total was 5.0. running mean: 6.903433593146022\n",
      "resetting env. episode reward total was 2.0. running mean: 6.854399257214561\n",
      "resetting env. episode reward total was 3.0. running mean: 6.8158552646424155\n",
      "resetting env. episode reward total was 13.0. running mean: 6.877696711995991\n",
      "resetting env. episode reward total was 8.0. running mean: 6.8889197448760315\n",
      "resetting env. episode reward total was 6.0. running mean: 6.880030547427271\n",
      "resetting env. episode reward total was 15.0. running mean: 6.9612302419529986\n",
      "resetting env. episode reward total was 10.0. running mean: 6.9916179395334686\n",
      "resetting env. episode reward total was 8.0. running mean: 7.0017017601381335\n",
      "resetting env. episode reward total was 14.0. running mean: 7.0716847425367515\n",
      "resetting env. episode reward total was 8.0. running mean: 7.080967895111384\n",
      "resetting env. episode reward total was 16.0. running mean: 7.170158216160271\n",
      "resetting env. episode reward total was 12.0. running mean: 7.218456633998668\n",
      "resetting env. episode reward total was 6.0. running mean: 7.206272067658682\n",
      "resetting env. episode reward total was 15.0. running mean: 7.284209346982095\n",
      "resetting env. episode reward total was 10.0. running mean: 7.311367253512274\n",
      "resetting env. episode reward total was 11.0. running mean: 7.348253580977151\n",
      "resetting env. episode reward total was -4.0. running mean: 7.2347710451673795\n",
      "resetting env. episode reward total was 3.0. running mean: 7.192423334715706\n",
      "resetting env. episode reward total was -1.0. running mean: 7.110499101368549\n",
      "resetting env. episode reward total was 12.0. running mean: 7.159394110354864\n",
      "resetting env. episode reward total was 11.0. running mean: 7.197800169251315\n",
      "resetting env. episode reward total was 20.0. running mean: 7.325822167558802\n",
      "resetting env. episode reward total was 13.0. running mean: 7.382563945883214\n",
      "resetting env. episode reward total was 7.0. running mean: 7.378738306424382\n",
      "resetting env. episode reward total was 13.0. running mean: 7.434950923360138\n",
      "resetting env. episode reward total was 4.0. running mean: 7.400601414126537\n",
      "resetting env. episode reward total was 3.0. running mean: 7.356595399985271\n",
      "resetting env. episode reward total was 3.0. running mean: 7.313029445985419\n",
      "resetting env. episode reward total was 8.0. running mean: 7.319899151525564\n",
      "resetting env. episode reward total was 7.0. running mean: 7.316700160010309\n",
      "resetting env. episode reward total was 6.0. running mean: 7.303533158410206\n",
      "resetting env. episode reward total was 7.0. running mean: 7.300497826826104\n",
      "resetting env. episode reward total was 2.0. running mean: 7.247492848557842\n",
      "resetting env. episode reward total was 12.0. running mean: 7.295017920072263\n",
      "resetting env. episode reward total was 6.0. running mean: 7.282067740871541\n",
      "resetting env. episode reward total was 16.0. running mean: 7.369247063462825\n",
      "resetting env. episode reward total was 9.0. running mean: 7.385554592828196\n",
      "resetting env. episode reward total was -7.0. running mean: 7.241699046899914\n",
      "resetting env. episode reward total was 8.0. running mean: 7.249282056430915\n",
      "resetting env. episode reward total was 5.0. running mean: 7.2267892358666055\n",
      "resetting env. episode reward total was 15.0. running mean: 7.30452134350794\n",
      "resetting env. episode reward total was 5.0. running mean: 7.28147613007286\n",
      "resetting env. episode reward total was 8.0. running mean: 7.288661368772131\n",
      "resetting env. episode reward total was 16.0. running mean: 7.37577475508441\n",
      "resetting env. episode reward total was 11.0. running mean: 7.412017007533566\n",
      "resetting env. episode reward total was 7.0. running mean: 7.407896837458231\n",
      "resetting env. episode reward total was 13.0. running mean: 7.463817869083648\n",
      "resetting env. episode reward total was 4.0. running mean: 7.429179690392812\n",
      "resetting env. episode reward total was -3.0. running mean: 7.324887893488883\n",
      "resetting env. episode reward total was 7.0. running mean: 7.321639014553995\n",
      "resetting env. episode reward total was 12.0. running mean: 7.3684226244084545\n",
      "resetting env. episode reward total was -1.0. running mean: 7.28473839816437\n",
      "resetting env. episode reward total was 4.0. running mean: 7.251891014182726\n",
      "resetting env. episode reward total was 3.0. running mean: 7.209372104040899\n",
      "resetting env. episode reward total was 7.0. running mean: 7.20727838300049\n",
      "resetting env. episode reward total was 14.0. running mean: 7.2752055991704845\n",
      "resetting env. episode reward total was 14.0. running mean: 7.342453543178779\n",
      "resetting env. episode reward total was -4.0. running mean: 7.229029007746991\n",
      "resetting env. episode reward total was 7.0. running mean: 7.226738717669521\n",
      "resetting env. episode reward total was 5.0. running mean: 7.204471330492826\n",
      "resetting env. episode reward total was 7.0. running mean: 7.202426617187898\n",
      "resetting env. episode reward total was 1.0. running mean: 7.140402351016019\n",
      "resetting env. episode reward total was 13.0. running mean: 7.198998327505858\n",
      "resetting env. episode reward total was 6.0. running mean: 7.187008344230799\n",
      "resetting env. episode reward total was 8.0. running mean: 7.195138260788491\n",
      "resetting env. episode reward total was 14.0. running mean: 7.263186878180606\n",
      "resetting env. episode reward total was -5.0. running mean: 7.1405550093988\n",
      "resetting env. episode reward total was 12.0. running mean: 7.189149459304812\n",
      "resetting env. episode reward total was 12.0. running mean: 7.237257964711764\n",
      "resetting env. episode reward total was -7.0. running mean: 7.0948853850646465\n",
      "resetting env. episode reward total was 7.0. running mean: 7.093936531214\n",
      "resetting env. episode reward total was 4.0. running mean: 7.06299716590186\n",
      "resetting env. episode reward total was 11.0. running mean: 7.102367194242842\n",
      "resetting env. episode reward total was 8.0. running mean: 7.111343522300414\n",
      "resetting env. episode reward total was 4.0. running mean: 7.08023008707741\n",
      "resetting env. episode reward total was 10.0. running mean: 7.109427786206636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 7.14833350834457\n",
      "resetting env. episode reward total was 12.0. running mean: 7.196850173261124\n",
      "resetting env. episode reward total was 7.0. running mean: 7.194881671528513\n",
      "resetting env. episode reward total was 15.0. running mean: 7.272932854813228\n",
      "resetting env. episode reward total was 4.0. running mean: 7.240203526265096\n",
      "resetting env. episode reward total was 10.0. running mean: 7.267801491002444\n",
      "resetting env. episode reward total was 2.0. running mean: 7.21512347609242\n",
      "resetting env. episode reward total was 8.0. running mean: 7.222972241331496\n",
      "resetting env. episode reward total was 5.0. running mean: 7.20074251891818\n",
      "resetting env. episode reward total was 4.0. running mean: 7.168735093728999\n",
      "resetting env. episode reward total was 8.0. running mean: 7.177047742791709\n",
      "resetting env. episode reward total was 13.0. running mean: 7.235277265363791\n",
      "resetting env. episode reward total was 10.0. running mean: 7.262924492710153\n",
      "resetting env. episode reward total was 1.0. running mean: 7.200295247783051\n",
      "resetting env. episode reward total was 8.0. running mean: 7.20829229530522\n",
      "resetting env. episode reward total was 10.0. running mean: 7.236209372352167\n",
      "resetting env. episode reward total was 10.0. running mean: 7.263847278628646\n",
      "resetting env. episode reward total was 15.0. running mean: 7.34120880584236\n",
      "resetting env. episode reward total was 9.0. running mean: 7.357796717783936\n",
      "resetting env. episode reward total was 3.0. running mean: 7.314218750606097\n",
      "resetting env. episode reward total was 3.0. running mean: 7.271076563100036\n",
      "resetting env. episode reward total was 15.0. running mean: 7.348365797469036\n",
      "resetting env. episode reward total was 10.0. running mean: 7.374882139494345\n",
      "resetting env. episode reward total was 2.0. running mean: 7.321133318099402\n",
      "resetting env. episode reward total was 10.0. running mean: 7.347921984918407\n",
      "resetting env. episode reward total was 2.0. running mean: 7.294442765069222\n",
      "resetting env. episode reward total was 7.0. running mean: 7.29149833741853\n",
      "resetting env. episode reward total was 17.0. running mean: 7.388583354044345\n",
      "resetting env. episode reward total was 9.0. running mean: 7.404697520503901\n",
      "resetting env. episode reward total was 11.0. running mean: 7.440650545298862\n",
      "resetting env. episode reward total was 7.0. running mean: 7.436244039845874\n",
      "resetting env. episode reward total was 18.0. running mean: 7.541881599447414\n",
      "resetting env. episode reward total was 4.0. running mean: 7.50646278345294\n",
      "resetting env. episode reward total was 10.0. running mean: 7.53139815561841\n",
      "resetting env. episode reward total was 7.0. running mean: 7.526084174062226\n",
      "resetting env. episode reward total was 15.0. running mean: 7.600823332321604\n",
      "resetting env. episode reward total was 12.0. running mean: 7.6448150989983885\n",
      "resetting env. episode reward total was 4.0. running mean: 7.608366948008404\n",
      "resetting env. episode reward total was 2.0. running mean: 7.55228327852832\n",
      "resetting env. episode reward total was 18.0. running mean: 7.6567604457430365\n",
      "resetting env. episode reward total was 16.0. running mean: 7.740192841285606\n",
      "resetting env. episode reward total was 19.0. running mean: 7.85279091287275\n",
      "resetting env. episode reward total was 11.0. running mean: 7.884263003744024\n",
      "resetting env. episode reward total was 12.0. running mean: 7.925420373706583\n",
      "resetting env. episode reward total was 12.0. running mean: 7.966166169969517\n",
      "resetting env. episode reward total was 5.0. running mean: 7.936504508269822\n",
      "resetting env. episode reward total was 1.0. running mean: 7.867139463187123\n",
      "resetting env. episode reward total was 9.0. running mean: 7.878468068555252\n",
      "resetting env. episode reward total was 6.0. running mean: 7.859683387869699\n",
      "resetting env. episode reward total was 4.0. running mean: 7.821086553991002\n",
      "resetting env. episode reward total was 4.0. running mean: 7.7828756884510915\n",
      "resetting env. episode reward total was 7.0. running mean: 7.775046931566581\n",
      "resetting env. episode reward total was 11.0. running mean: 7.807296462250915\n",
      "resetting env. episode reward total was 9.0. running mean: 7.819223497628405\n",
      "resetting env. episode reward total was -5.0. running mean: 7.691031262652121\n",
      "resetting env. episode reward total was 10.0. running mean: 7.7141209500256\n",
      "resetting env. episode reward total was 15.0. running mean: 7.786979740525344\n",
      "resetting env. episode reward total was 8.0. running mean: 7.78910994312009\n",
      "resetting env. episode reward total was 12.0. running mean: 7.831218843688889\n",
      "resetting env. episode reward total was 10.0. running mean: 7.852906655252\n",
      "resetting env. episode reward total was 9.0. running mean: 7.86437758869948\n",
      "resetting env. episode reward total was 6.0. running mean: 7.845733812812484\n",
      "resetting env. episode reward total was 12.0. running mean: 7.887276474684359\n",
      "resetting env. episode reward total was 2.0. running mean: 7.828403709937516\n",
      "resetting env. episode reward total was 13.0. running mean: 7.88011967283814\n",
      "resetting env. episode reward total was 12.0. running mean: 7.921318476109759\n",
      "resetting env. episode reward total was 8.0. running mean: 7.922105291348662\n",
      "resetting env. episode reward total was 14.0. running mean: 7.982884238435175\n",
      "resetting env. episode reward total was 4.0. running mean: 7.9430553960508234\n",
      "resetting env. episode reward total was 2.0. running mean: 7.883624842090315\n",
      "resetting env. episode reward total was 16.0. running mean: 7.964788593669412\n",
      "resetting env. episode reward total was 18.0. running mean: 8.065140707732718\n",
      "resetting env. episode reward total was 16.0. running mean: 8.14448930065539\n",
      "resetting env. episode reward total was 4.0. running mean: 8.103044407648836\n",
      "resetting env. episode reward total was 9.0. running mean: 8.112013963572348\n",
      "resetting env. episode reward total was 10.0. running mean: 8.130893823936624\n",
      "resetting env. episode reward total was 2.0. running mean: 8.069584885697257\n",
      "resetting env. episode reward total was 2.0. running mean: 8.008889036840284\n",
      "resetting env. episode reward total was 7.0. running mean: 7.998800146471881\n",
      "resetting env. episode reward total was 11.0. running mean: 8.028812145007162\n",
      "resetting env. episode reward total was 10.0. running mean: 8.048524023557091\n",
      "resetting env. episode reward total was 4.0. running mean: 8.008038783321519\n",
      "resetting env. episode reward total was 9.0. running mean: 8.017958395488304\n",
      "resetting env. episode reward total was 2.0. running mean: 7.95777881153342\n",
      "resetting env. episode reward total was 10.0. running mean: 7.978201023418086\n",
      "resetting env. episode reward total was 10.0. running mean: 7.998419013183904\n",
      "resetting env. episode reward total was 10.0. running mean: 8.018434823052065\n",
      "resetting env. episode reward total was 1.0. running mean: 7.948250474821544\n",
      "resetting env. episode reward total was 7.0. running mean: 7.938767970073329\n",
      "resetting env. episode reward total was 7.0. running mean: 7.929380290372595\n",
      "resetting env. episode reward total was 12.0. running mean: 7.970086487468869\n",
      "resetting env. episode reward total was 12.0. running mean: 8.01038562259418\n",
      "resetting env. episode reward total was 5.0. running mean: 7.980281766368238\n",
      "resetting env. episode reward total was 13.0. running mean: 8.030478948704555\n",
      "resetting env. episode reward total was -1.0. running mean: 7.94017415921751\n",
      "resetting env. episode reward total was 10.0. running mean: 7.960772417625335\n",
      "resetting env. episode reward total was 11.0. running mean: 7.991164693449082\n",
      "resetting env. episode reward total was 16.0. running mean: 8.07125304651459\n",
      "resetting env. episode reward total was 8.0. running mean: 8.070540516049444\n",
      "resetting env. episode reward total was 14.0. running mean: 8.12983511088895\n",
      "resetting env. episode reward total was 5.0. running mean: 8.09853675978006\n",
      "resetting env. episode reward total was 12.0. running mean: 8.137551392182258\n",
      "resetting env. episode reward total was -1.0. running mean: 8.046175878260437\n",
      "resetting env. episode reward total was 7.0. running mean: 8.035714119477833\n",
      "resetting env. episode reward total was 15.0. running mean: 8.105356978283053\n",
      "resetting env. episode reward total was 10.0. running mean: 8.124303408500221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 8.11306037441522\n",
      "resetting env. episode reward total was -3.0. running mean: 8.001929770671069\n",
      "resetting env. episode reward total was 3.0. running mean: 7.951910472964358\n",
      "resetting env. episode reward total was 4.0. running mean: 7.912391368234714\n",
      "resetting env. episode reward total was 12.0. running mean: 7.953267454552367\n",
      "resetting env. episode reward total was 11.0. running mean: 7.983734780006843\n",
      "resetting env. episode reward total was 5.0. running mean: 7.953897432206775\n",
      "resetting env. episode reward total was 5.0. running mean: 7.924358457884707\n",
      "resetting env. episode reward total was -3.0. running mean: 7.815114873305859\n",
      "resetting env. episode reward total was 1.0. running mean: 7.7469637245728\n",
      "resetting env. episode reward total was 11.0. running mean: 7.779494087327072\n",
      "resetting env. episode reward total was 4.0. running mean: 7.741699146453802\n",
      "resetting env. episode reward total was 2.0. running mean: 7.684282154989263\n",
      "resetting env. episode reward total was 12.0. running mean: 7.72743933343937\n",
      "resetting env. episode reward total was 9.0. running mean: 7.740164940104976\n",
      "resetting env. episode reward total was 9.0. running mean: 7.752763290703927\n",
      "resetting env. episode reward total was 6.0. running mean: 7.735235657796887\n",
      "resetting env. episode reward total was 9.0. running mean: 7.747883301218917\n",
      "resetting env. episode reward total was 8.0. running mean: 7.750404468206728\n",
      "resetting env. episode reward total was 6.0. running mean: 7.732900423524661\n",
      "resetting env. episode reward total was 8.0. running mean: 7.735571419289414\n",
      "resetting env. episode reward total was -3.0. running mean: 7.62821570509652\n",
      "resetting env. episode reward total was 9.0. running mean: 7.641933548045555\n",
      "resetting env. episode reward total was 15.0. running mean: 7.7155142125650995\n",
      "resetting env. episode reward total was 11.0. running mean: 7.748359070439449\n",
      "resetting env. episode reward total was 5.0. running mean: 7.720875479735054\n",
      "resetting env. episode reward total was 9.0. running mean: 7.733666724937703\n",
      "resetting env. episode reward total was 14.0. running mean: 7.796330057688325\n",
      "resetting env. episode reward total was 15.0. running mean: 7.868366757111443\n",
      "resetting env. episode reward total was 9.0. running mean: 7.879683089540328\n",
      "resetting env. episode reward total was 14.0. running mean: 7.940886258644924\n",
      "resetting env. episode reward total was 15.0. running mean: 8.011477396058474\n",
      "resetting env. episode reward total was 5.0. running mean: 7.9813626220978895\n",
      "resetting env. episode reward total was 12.0. running mean: 8.02154899587691\n",
      "resetting env. episode reward total was 15.0. running mean: 8.091333505918142\n",
      "resetting env. episode reward total was 8.0. running mean: 8.09042017085896\n",
      "resetting env. episode reward total was 10.0. running mean: 8.10951596915037\n",
      "resetting env. episode reward total was 10.0. running mean: 8.128420809458866\n",
      "resetting env. episode reward total was 12.0. running mean: 8.167136601364277\n",
      "resetting env. episode reward total was 2.0. running mean: 8.105465235350634\n",
      "resetting env. episode reward total was 11.0. running mean: 8.134410582997127\n",
      "resetting env. episode reward total was 4.0. running mean: 8.093066477167154\n",
      "resetting env. episode reward total was -2.0. running mean: 7.9921358123954835\n",
      "resetting env. episode reward total was 15.0. running mean: 8.062214454271528\n",
      "resetting env. episode reward total was 9.0. running mean: 8.071592309728812\n",
      "resetting env. episode reward total was 9.0. running mean: 8.080876386631525\n",
      "resetting env. episode reward total was 4.0. running mean: 8.040067622765209\n",
      "resetting env. episode reward total was 13.0. running mean: 8.089666946537557\n",
      "resetting env. episode reward total was 11.0. running mean: 8.118770277072182\n",
      "resetting env. episode reward total was 9.0. running mean: 8.12758257430146\n",
      "resetting env. episode reward total was 7.0. running mean: 8.116306748558445\n",
      "resetting env. episode reward total was 14.0. running mean: 8.17514368107286\n",
      "resetting env. episode reward total was -4.0. running mean: 8.053392244262133\n",
      "resetting env. episode reward total was 4.0. running mean: 8.012858321819511\n",
      "resetting env. episode reward total was 5.0. running mean: 7.982729738601316\n",
      "resetting env. episode reward total was 12.0. running mean: 8.022902441215303\n",
      "resetting env. episode reward total was 14.0. running mean: 8.08267341680315\n",
      "resetting env. episode reward total was 13.0. running mean: 8.13184668263512\n",
      "resetting env. episode reward total was 7.0. running mean: 8.120528215808768\n",
      "resetting env. episode reward total was 7.0. running mean: 8.109322933650681\n",
      "resetting env. episode reward total was 10.0. running mean: 8.128229704314174\n",
      "resetting env. episode reward total was 7.0. running mean: 8.116947407271033\n",
      "resetting env. episode reward total was 9.0. running mean: 8.125777933198322\n",
      "resetting env. episode reward total was -5.0. running mean: 7.994520153866339\n",
      "resetting env. episode reward total was 15.0. running mean: 8.064574952327675\n",
      "resetting env. episode reward total was 6.0. running mean: 8.043929202804398\n",
      "resetting env. episode reward total was 7.0. running mean: 8.033489910776353\n",
      "resetting env. episode reward total was 11.0. running mean: 8.06315501166859\n",
      "resetting env. episode reward total was -1.0. running mean: 7.972523461551904\n",
      "resetting env. episode reward total was 10.0. running mean: 7.992798226936385\n",
      "resetting env. episode reward total was -7.0. running mean: 7.84287024466702\n",
      "resetting env. episode reward total was 11.0. running mean: 7.87444154222035\n",
      "resetting env. episode reward total was 5.0. running mean: 7.845697126798147\n",
      "resetting env. episode reward total was 11.0. running mean: 7.877240155530165\n",
      "resetting env. episode reward total was 4.0. running mean: 7.8384677539748635\n",
      "resetting env. episode reward total was 7.0. running mean: 7.830083076435115\n",
      "resetting env. episode reward total was 8.0. running mean: 7.831782245670764\n",
      "resetting env. episode reward total was 9.0. running mean: 7.843464423214057\n",
      "resetting env. episode reward total was 7.0. running mean: 7.835029778981917\n",
      "resetting env. episode reward total was 10.0. running mean: 7.8566794811920975\n",
      "resetting env. episode reward total was 7.0. running mean: 7.848112686380177\n",
      "resetting env. episode reward total was 3.0. running mean: 7.799631559516375\n",
      "resetting env. episode reward total was 9.0. running mean: 7.811635243921211\n",
      "resetting env. episode reward total was 7.0. running mean: 7.803518891481999\n",
      "resetting env. episode reward total was 6.0. running mean: 7.785483702567179\n",
      "resetting env. episode reward total was -1.0. running mean: 7.697628865541507\n",
      "resetting env. episode reward total was 9.0. running mean: 7.710652576886091\n",
      "resetting env. episode reward total was 5.0. running mean: 7.68354605111723\n",
      "resetting env. episode reward total was 10.0. running mean: 7.706710590606058\n",
      "resetting env. episode reward total was 12.0. running mean: 7.749643484699997\n",
      "resetting env. episode reward total was 8.0. running mean: 7.752147049852997\n",
      "resetting env. episode reward total was 8.0. running mean: 7.754625579354467\n",
      "resetting env. episode reward total was 15.0. running mean: 7.827079323560923\n",
      "resetting env. episode reward total was -4.0. running mean: 7.708808530325314\n",
      "resetting env. episode reward total was 15.0. running mean: 7.781720445022061\n",
      "resetting env. episode reward total was 15.0. running mean: 7.8539032405718405\n",
      "resetting env. episode reward total was 9.0. running mean: 7.865364208166122\n",
      "resetting env. episode reward total was 17.0. running mean: 7.95671056608446\n",
      "resetting env. episode reward total was 11.0. running mean: 7.987143460423616\n",
      "resetting env. episode reward total was 12.0. running mean: 8.02727202581938\n",
      "resetting env. episode reward total was 15.0. running mean: 8.096999305561186\n",
      "resetting env. episode reward total was 3.0. running mean: 8.046029312505572\n",
      "resetting env. episode reward total was 13.0. running mean: 8.095569019380516\n",
      "resetting env. episode reward total was 1.0. running mean: 8.02461332918671\n",
      "resetting env. episode reward total was 3.0. running mean: 7.974367195894843\n",
      "resetting env. episode reward total was 13.0. running mean: 8.024623523935896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 8.074377288696537\n",
      "resetting env. episode reward total was 6.0. running mean: 8.053633515809572\n",
      "resetting env. episode reward total was 12.0. running mean: 8.093097180651476\n",
      "resetting env. episode reward total was 9.0. running mean: 8.102166208844961\n",
      "resetting env. episode reward total was 10.0. running mean: 8.121144546756511\n",
      "resetting env. episode reward total was 15.0. running mean: 8.189933101288947\n",
      "resetting env. episode reward total was 10.0. running mean: 8.208033770276057\n",
      "resetting env. episode reward total was -1.0. running mean: 8.115953432573296\n",
      "resetting env. episode reward total was -6.0. running mean: 7.974793898247563\n",
      "resetting env. episode reward total was 18.0. running mean: 8.075045959265086\n",
      "resetting env. episode reward total was 7.0. running mean: 8.064295499672435\n",
      "resetting env. episode reward total was 5.0. running mean: 8.03365254467571\n",
      "resetting env. episode reward total was 5.0. running mean: 8.003316019228954\n",
      "resetting env. episode reward total was 2.0. running mean: 7.943282859036664\n",
      "resetting env. episode reward total was 13.0. running mean: 7.993850030446297\n",
      "resetting env. episode reward total was 15.0. running mean: 8.063911530141834\n",
      "resetting env. episode reward total was 14.0. running mean: 8.123272414840415\n",
      "resetting env. episode reward total was 8.0. running mean: 8.122039690692011\n",
      "resetting env. episode reward total was 14.0. running mean: 8.180819293785092\n",
      "resetting env. episode reward total was -6.0. running mean: 8.03901110084724\n",
      "resetting env. episode reward total was 8.0. running mean: 8.038620989838767\n",
      "resetting env. episode reward total was 15.0. running mean: 8.10823477994038\n",
      "resetting env. episode reward total was 2.0. running mean: 8.047152432140976\n",
      "resetting env. episode reward total was 12.0. running mean: 8.086680907819566\n",
      "resetting env. episode reward total was 15.0. running mean: 8.155814098741372\n",
      "resetting env. episode reward total was 9.0. running mean: 8.164255957753959\n",
      "resetting env. episode reward total was 5.0. running mean: 8.132613398176419\n",
      "resetting env. episode reward total was 9.0. running mean: 8.141287264194654\n",
      "resetting env. episode reward total was 13.0. running mean: 8.189874391552708\n",
      "resetting env. episode reward total was 17.0. running mean: 8.27797564763718\n",
      "resetting env. episode reward total was 10.0. running mean: 8.295195891160809\n",
      "resetting env. episode reward total was 6.0. running mean: 8.272243932249202\n",
      "resetting env. episode reward total was 13.0. running mean: 8.319521492926711\n",
      "resetting env. episode reward total was 6.0. running mean: 8.296326277997444\n",
      "resetting env. episode reward total was 7.0. running mean: 8.28336301521747\n",
      "resetting env. episode reward total was 4.0. running mean: 8.240529385065294\n",
      "resetting env. episode reward total was 3.0. running mean: 8.18812409121464\n",
      "resetting env. episode reward total was 10.0. running mean: 8.206242850302493\n",
      "resetting env. episode reward total was 3.0. running mean: 8.154180421799467\n",
      "resetting env. episode reward total was 7.0. running mean: 8.142638617581472\n",
      "resetting env. episode reward total was 1.0. running mean: 8.071212231405656\n",
      "resetting env. episode reward total was 13.0. running mean: 8.1205001090916\n",
      "resetting env. episode reward total was 9.0. running mean: 8.129295108000683\n",
      "resetting env. episode reward total was 8.0. running mean: 8.128002156920676\n",
      "resetting env. episode reward total was 10.0. running mean: 8.14672213535147\n",
      "resetting env. episode reward total was -3.0. running mean: 8.035254913997955\n",
      "resetting env. episode reward total was 11.0. running mean: 8.064902364857975\n",
      "resetting env. episode reward total was 10.0. running mean: 8.084253341209395\n",
      "resetting env. episode reward total was 8.0. running mean: 8.083410807797302\n",
      "resetting env. episode reward total was 1.0. running mean: 8.012576699719329\n",
      "resetting env. episode reward total was 4.0. running mean: 7.972450932722135\n",
      "resetting env. episode reward total was 15.0. running mean: 8.042726423394914\n",
      "resetting env. episode reward total was -1.0. running mean: 7.952299159160964\n",
      "resetting env. episode reward total was 4.0. running mean: 7.912776167569355\n",
      "resetting env. episode reward total was 1.0. running mean: 7.843648405893661\n",
      "resetting env. episode reward total was 11.0. running mean: 7.875211921834724\n",
      "resetting env. episode reward total was 5.0. running mean: 7.846459802616377\n",
      "resetting env. episode reward total was 9.0. running mean: 7.857995204590213\n",
      "resetting env. episode reward total was 4.0. running mean: 7.819415252544311\n",
      "resetting env. episode reward total was 2.0. running mean: 7.761221100018868\n",
      "resetting env. episode reward total was 9.0. running mean: 7.7736088890186785\n",
      "resetting env. episode reward total was 18.0. running mean: 7.875872800128492\n",
      "resetting env. episode reward total was 13.0. running mean: 7.927114072127207\n",
      "resetting env. episode reward total was 9.0. running mean: 7.937842931405934\n",
      "resetting env. episode reward total was 11.0. running mean: 7.968464502091876\n",
      "resetting env. episode reward total was 2.0. running mean: 7.908779857070956\n",
      "resetting env. episode reward total was 7.0. running mean: 7.899692058500247\n",
      "resetting env. episode reward total was 8.0. running mean: 7.900695137915244\n",
      "resetting env. episode reward total was 8.0. running mean: 7.9016881865360915\n",
      "resetting env. episode reward total was 13.0. running mean: 7.95267130467073\n",
      "resetting env. episode reward total was 10.0. running mean: 7.973144591624022\n",
      "resetting env. episode reward total was 13.0. running mean: 8.023413145707782\n",
      "resetting env. episode reward total was 13.0. running mean: 8.073179014250703\n",
      "resetting env. episode reward total was -1.0. running mean: 7.9824472241081965\n",
      "resetting env. episode reward total was 7.0. running mean: 7.972622751867115\n",
      "resetting env. episode reward total was 12.0. running mean: 8.012896524348443\n",
      "resetting env. episode reward total was 11.0. running mean: 8.04276755910496\n",
      "resetting env. episode reward total was 1.0. running mean: 7.972339883513909\n",
      "resetting env. episode reward total was 4.0. running mean: 7.9326164846787695\n",
      "resetting env. episode reward total was 12.0. running mean: 7.973290319831982\n",
      "resetting env. episode reward total was 6.0. running mean: 7.953557416633662\n",
      "resetting env. episode reward total was 12.0. running mean: 7.994021842467325\n",
      "resetting env. episode reward total was 1.0. running mean: 7.9240816240426515\n",
      "resetting env. episode reward total was 13.0. running mean: 7.974840807802225\n",
      "resetting env. episode reward total was 12.0. running mean: 8.015092399724201\n",
      "resetting env. episode reward total was 9.0. running mean: 8.02494147572696\n",
      "resetting env. episode reward total was 9.0. running mean: 8.034692060969691\n",
      "resetting env. episode reward total was 13.0. running mean: 8.084345140359995\n",
      "resetting env. episode reward total was 7.0. running mean: 8.073501688956394\n",
      "resetting env. episode reward total was 4.0. running mean: 8.03276667206683\n",
      "resetting env. episode reward total was 8.0. running mean: 8.032439005346161\n",
      "resetting env. episode reward total was 6.0. running mean: 8.012114615292699\n",
      "resetting env. episode reward total was 11.0. running mean: 8.041993469139772\n",
      "resetting env. episode reward total was 11.0. running mean: 8.071573534448374\n",
      "resetting env. episode reward total was -1.0. running mean: 7.980857799103891\n",
      "resetting env. episode reward total was 11.0. running mean: 8.011049221112852\n",
      "resetting env. episode reward total was 13.0. running mean: 8.060938728901725\n",
      "resetting env. episode reward total was 7.0. running mean: 8.050329341612708\n",
      "resetting env. episode reward total was 11.0. running mean: 8.07982604819658\n",
      "resetting env. episode reward total was 8.0. running mean: 8.079027787714613\n",
      "resetting env. episode reward total was 9.0. running mean: 8.088237509837468\n",
      "resetting env. episode reward total was 6.0. running mean: 8.067355134739094\n",
      "resetting env. episode reward total was 15.0. running mean: 8.136681583391702\n",
      "resetting env. episode reward total was 14.0. running mean: 8.195314767557786\n",
      "resetting env. episode reward total was 4.0. running mean: 8.153361619882206\n",
      "resetting env. episode reward total was 11.0. running mean: 8.181828003683384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 8.15000972364655\n",
      "resetting env. episode reward total was 11.0. running mean: 8.178509626410083\n",
      "resetting env. episode reward total was 12.0. running mean: 8.216724530145981\n",
      "resetting env. episode reward total was 10.0. running mean: 8.234557284844522\n",
      "resetting env. episode reward total was -5.0. running mean: 8.102211711996075\n",
      "resetting env. episode reward total was 9.0. running mean: 8.111189594876114\n",
      "resetting env. episode reward total was -1.0. running mean: 8.020077698927354\n",
      "resetting env. episode reward total was 5.0. running mean: 7.98987692193808\n",
      "resetting env. episode reward total was 2.0. running mean: 7.929978152718699\n",
      "resetting env. episode reward total was 2.0. running mean: 7.870678371191512\n",
      "resetting env. episode reward total was 13.0. running mean: 7.921971587479597\n",
      "resetting env. episode reward total was 13.0. running mean: 7.9727518716048005\n",
      "resetting env. episode reward total was 2.0. running mean: 7.913024352888752\n",
      "resetting env. episode reward total was -1.0. running mean: 7.823894109359864\n",
      "resetting env. episode reward total was -4.0. running mean: 7.705655168266266\n",
      "resetting env. episode reward total was 2.0. running mean: 7.648598616583603\n",
      "resetting env. episode reward total was 4.0. running mean: 7.612112630417767\n",
      "resetting env. episode reward total was 5.0. running mean: 7.585991504113589\n",
      "resetting env. episode reward total was 6.0. running mean: 7.570131589072453\n",
      "resetting env. episode reward total was 1.0. running mean: 7.504430273181728\n",
      "resetting env. episode reward total was 8.0. running mean: 7.509385970449911\n",
      "resetting env. episode reward total was 14.0. running mean: 7.574292110745411\n",
      "resetting env. episode reward total was 2.0. running mean: 7.518549189637956\n",
      "resetting env. episode reward total was 2.0. running mean: 7.463363697741576\n",
      "resetting env. episode reward total was 13.0. running mean: 7.51873006076416\n",
      "resetting env. episode reward total was 8.0. running mean: 7.523542760156518\n",
      "resetting env. episode reward total was 13.0. running mean: 7.578307332554953\n",
      "resetting env. episode reward total was 13.0. running mean: 7.632524259229403\n",
      "resetting env. episode reward total was 7.0. running mean: 7.626199016637109\n",
      "resetting env. episode reward total was 5.0. running mean: 7.599937026470738\n",
      "resetting env. episode reward total was 8.0. running mean: 7.603937656206031\n",
      "resetting env. episode reward total was 5.0. running mean: 7.5778982796439704\n",
      "resetting env. episode reward total was 1.0. running mean: 7.512119296847531\n",
      "resetting env. episode reward total was 11.0. running mean: 7.546998103879056\n",
      "resetting env. episode reward total was 9.0. running mean: 7.561528122840265\n",
      "resetting env. episode reward total was -3.0. running mean: 7.4559128416118625\n",
      "resetting env. episode reward total was 18.0. running mean: 7.561353713195744\n",
      "resetting env. episode reward total was 14.0. running mean: 7.625740176063786\n",
      "resetting env. episode reward total was 1.0. running mean: 7.559482774303148\n",
      "resetting env. episode reward total was 13.0. running mean: 7.613887946560117\n",
      "resetting env. episode reward total was 4.0. running mean: 7.577749067094516\n",
      "resetting env. episode reward total was 4.0. running mean: 7.54197157642357\n",
      "resetting env. episode reward total was 6.0. running mean: 7.5265518606593345\n",
      "resetting env. episode reward total was 14.0. running mean: 7.591286342052741\n",
      "resetting env. episode reward total was 9.0. running mean: 7.605373478632213\n",
      "resetting env. episode reward total was 12.0. running mean: 7.649319743845891\n",
      "resetting env. episode reward total was 12.0. running mean: 7.692826546407432\n",
      "resetting env. episode reward total was 8.0. running mean: 7.695898280943358\n",
      "resetting env. episode reward total was 8.0. running mean: 7.698939298133925\n",
      "resetting env. episode reward total was 6.0. running mean: 7.681949905152585\n",
      "resetting env. episode reward total was 8.0. running mean: 7.6851304061010595\n",
      "resetting env. episode reward total was -5.0. running mean: 7.558279102040049\n",
      "resetting env. episode reward total was 12.0. running mean: 7.602696311019648\n",
      "resetting env. episode reward total was 9.0. running mean: 7.616669347909451\n",
      "resetting env. episode reward total was 3.0. running mean: 7.570502654430357\n",
      "resetting env. episode reward total was 7.0. running mean: 7.564797627886054\n",
      "resetting env. episode reward total was 9.0. running mean: 7.579149651607193\n",
      "resetting env. episode reward total was 11.0. running mean: 7.613358155091121\n",
      "resetting env. episode reward total was -3.0. running mean: 7.50722457354021\n",
      "resetting env. episode reward total was 13.0. running mean: 7.5621523278048075\n",
      "resetting env. episode reward total was 4.0. running mean: 7.526530804526759\n",
      "resetting env. episode reward total was 1.0. running mean: 7.4612654964814915\n",
      "resetting env. episode reward total was 9.0. running mean: 7.476652841516676\n",
      "resetting env. episode reward total was 6.0. running mean: 7.461886313101509\n",
      "resetting env. episode reward total was 4.0. running mean: 7.427267449970494\n",
      "resetting env. episode reward total was 7.0. running mean: 7.42299477547079\n",
      "resetting env. episode reward total was -4.0. running mean: 7.3087648277160815\n",
      "resetting env. episode reward total was 6.0. running mean: 7.29567717943892\n",
      "resetting env. episode reward total was 8.0. running mean: 7.302720407644531\n",
      "resetting env. episode reward total was -5.0. running mean: 7.179693203568086\n",
      "resetting env. episode reward total was -6.0. running mean: 7.047896271532406\n",
      "resetting env. episode reward total was 4.0. running mean: 7.017417308817082\n",
      "resetting env. episode reward total was 10.0. running mean: 7.047243135728911\n",
      "resetting env. episode reward total was 1.0. running mean: 6.986770704371621\n",
      "resetting env. episode reward total was -6.0. running mean: 6.856902997327905\n",
      "resetting env. episode reward total was 13.0. running mean: 6.918333967354626\n",
      "resetting env. episode reward total was 5.0. running mean: 6.89915062768108\n",
      "resetting env. episode reward total was 15.0. running mean: 6.980159121404269\n",
      "resetting env. episode reward total was 9.0. running mean: 7.000357530190226\n",
      "resetting env. episode reward total was 10.0. running mean: 7.030353954888324\n",
      "resetting env. episode reward total was 3.0. running mean: 6.990050415339441\n",
      "resetting env. episode reward total was 8.0. running mean: 7.000149911186047\n",
      "resetting env. episode reward total was 7.0. running mean: 7.000148412074187\n",
      "resetting env. episode reward total was 15.0. running mean: 7.080146927953445\n",
      "resetting env. episode reward total was 9.0. running mean: 7.09934545867391\n",
      "resetting env. episode reward total was 13.0. running mean: 7.15835200408717\n",
      "resetting env. episode reward total was 10.0. running mean: 7.186768484046298\n",
      "resetting env. episode reward total was 2.0. running mean: 7.134900799205835\n",
      "resetting env. episode reward total was 1.0. running mean: 7.073551791213776\n",
      "resetting env. episode reward total was 14.0. running mean: 7.142816273301638\n",
      "resetting env. episode reward total was 6.0. running mean: 7.131388110568621\n",
      "resetting env. episode reward total was 13.0. running mean: 7.190074229462935\n",
      "resetting env. episode reward total was 18.0. running mean: 7.298173487168305\n",
      "resetting env. episode reward total was 9.0. running mean: 7.315191752296622\n",
      "resetting env. episode reward total was 10.0. running mean: 7.342039834773655\n",
      "resetting env. episode reward total was 10.0. running mean: 7.368619436425918\n",
      "resetting env. episode reward total was -2.0. running mean: 7.2749332420616595\n",
      "resetting env. episode reward total was 9.0. running mean: 7.292183909641043\n",
      "resetting env. episode reward total was 8.0. running mean: 7.299262070544633\n",
      "resetting env. episode reward total was 16.0. running mean: 7.386269449839187\n",
      "resetting env. episode reward total was 13.0. running mean: 7.442406755340794\n",
      "resetting env. episode reward total was 10.0. running mean: 7.467982687787386\n",
      "resetting env. episode reward total was -3.0. running mean: 7.363302860909512\n",
      "resetting env. episode reward total was 8.0. running mean: 7.369669832300416\n",
      "resetting env. episode reward total was 8.0. running mean: 7.375973133977412\n",
      "resetting env. episode reward total was 10.0. running mean: 7.402213402637638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 7.348191268611261\n",
      "resetting env. episode reward total was 14.0. running mean: 7.414709355925148\n",
      "resetting env. episode reward total was 5.0. running mean: 7.390562262365896\n",
      "resetting env. episode reward total was 12.0. running mean: 7.436656639742237\n",
      "resetting env. episode reward total was 9.0. running mean: 7.452290073344814\n",
      "resetting env. episode reward total was 10.0. running mean: 7.477767172611366\n",
      "resetting env. episode reward total was 8.0. running mean: 7.482989500885252\n",
      "resetting env. episode reward total was 15.0. running mean: 7.5581596058764005\n",
      "resetting env. episode reward total was 14.0. running mean: 7.622578009817636\n",
      "resetting env. episode reward total was 7.0. running mean: 7.61635222971946\n",
      "resetting env. episode reward total was 10.0. running mean: 7.640188707422265\n",
      "resetting env. episode reward total was 4.0. running mean: 7.603786820348042\n",
      "resetting env. episode reward total was 7.0. running mean: 7.5977489521445625\n",
      "resetting env. episode reward total was -2.0. running mean: 7.501771462623117\n",
      "resetting env. episode reward total was 10.0. running mean: 7.526753747996886\n",
      "resetting env. episode reward total was 12.0. running mean: 7.571486210516917\n",
      "resetting env. episode reward total was 10.0. running mean: 7.5957713484117475\n",
      "resetting env. episode reward total was 9.0. running mean: 7.6098136349276295\n",
      "resetting env. episode reward total was 13.0. running mean: 7.663715498578353\n",
      "resetting env. episode reward total was 9.0. running mean: 7.677078343592569\n",
      "resetting env. episode reward total was 5.0. running mean: 7.6503075601566435\n",
      "resetting env. episode reward total was 1.0. running mean: 7.583804484555077\n",
      "resetting env. episode reward total was 8.0. running mean: 7.587966439709526\n",
      "resetting env. episode reward total was 13.0. running mean: 7.642086775312431\n",
      "resetting env. episode reward total was 8.0. running mean: 7.645665907559307\n",
      "resetting env. episode reward total was 8.0. running mean: 7.6492092484837135\n",
      "resetting env. episode reward total was 7.0. running mean: 7.642717155998876\n",
      "resetting env. episode reward total was 9.0. running mean: 7.656289984438887\n",
      "resetting env. episode reward total was -2.0. running mean: 7.559727084594498\n",
      "resetting env. episode reward total was 6.0. running mean: 7.544129813748553\n",
      "resetting env. episode reward total was 12.0. running mean: 7.588688515611067\n",
      "resetting env. episode reward total was 12.0. running mean: 7.632801630454956\n",
      "resetting env. episode reward total was 10.0. running mean: 7.656473614150406\n",
      "resetting env. episode reward total was 4.0. running mean: 7.619908878008902\n",
      "resetting env. episode reward total was 16.0. running mean: 7.703709789228813\n",
      "resetting env. episode reward total was 5.0. running mean: 7.676672691336525\n",
      "resetting env. episode reward total was 7.0. running mean: 7.66990596442316\n",
      "resetting env. episode reward total was 7.0. running mean: 7.663206904778929\n",
      "resetting env. episode reward total was 5.0. running mean: 7.636574835731139\n",
      "resetting env. episode reward total was 8.0. running mean: 7.640209087373828\n",
      "resetting env. episode reward total was 7.0. running mean: 7.633806996500089\n",
      "resetting env. episode reward total was 5.0. running mean: 7.6074689265350885\n",
      "resetting env. episode reward total was 14.0. running mean: 7.6713942372697375\n",
      "resetting env. episode reward total was 5.0. running mean: 7.64468029489704\n",
      "resetting env. episode reward total was 7.0. running mean: 7.63823349194807\n",
      "resetting env. episode reward total was 7.0. running mean: 7.631851157028589\n",
      "resetting env. episode reward total was 11.0. running mean: 7.6655326454583035\n",
      "resetting env. episode reward total was -7.0. running mean: 7.51887731900372\n",
      "resetting env. episode reward total was -5.0. running mean: 7.393688545813683\n",
      "resetting env. episode reward total was 8.0. running mean: 7.399751660355546\n",
      "resetting env. episode reward total was 11.0. running mean: 7.435754143751991\n",
      "resetting env. episode reward total was 5.0. running mean: 7.411396602314471\n",
      "resetting env. episode reward total was 13.0. running mean: 7.467282636291326\n",
      "resetting env. episode reward total was 12.0. running mean: 7.512609809928413\n",
      "resetting env. episode reward total was 10.0. running mean: 7.537483711829128\n",
      "resetting env. episode reward total was 7.0. running mean: 7.532108874710837\n",
      "resetting env. episode reward total was 10.0. running mean: 7.556787785963729\n",
      "resetting env. episode reward total was 2.0. running mean: 7.501219908104091\n",
      "resetting env. episode reward total was 9.0. running mean: 7.516207709023051\n",
      "resetting env. episode reward total was -4.0. running mean: 7.40104563193282\n",
      "resetting env. episode reward total was 1.0. running mean: 7.337035175613491\n",
      "resetting env. episode reward total was 10.0. running mean: 7.363664823857356\n",
      "resetting env. episode reward total was 1.0. running mean: 7.300028175618782\n",
      "resetting env. episode reward total was 5.0. running mean: 7.277027893862594\n",
      "resetting env. episode reward total was 7.0. running mean: 7.274257614923968\n",
      "resetting env. episode reward total was 12.0. running mean: 7.321515038774728\n",
      "resetting env. episode reward total was 14.0. running mean: 7.388299888386981\n",
      "resetting env. episode reward total was 13.0. running mean: 7.444416889503111\n",
      "resetting env. episode reward total was 17.0. running mean: 7.5399727206080795\n",
      "resetting env. episode reward total was 10.0. running mean: 7.564572993401998\n",
      "resetting env. episode reward total was 12.0. running mean: 7.6089272634679785\n",
      "resetting env. episode reward total was 14.0. running mean: 7.672837990833298\n",
      "resetting env. episode reward total was 5.0. running mean: 7.646109610924965\n",
      "resetting env. episode reward total was 16.0. running mean: 7.7296485148157155\n",
      "resetting env. episode reward total was 4.0. running mean: 7.692352029667559\n",
      "resetting env. episode reward total was 11.0. running mean: 7.725428509370883\n",
      "resetting env. episode reward total was 14.0. running mean: 7.788174224277174\n",
      "resetting env. episode reward total was 8.0. running mean: 7.790292482034403\n",
      "resetting env. episode reward total was 6.0. running mean: 7.772389557214058\n",
      "resetting env. episode reward total was 16.0. running mean: 7.854665661641918\n",
      "resetting env. episode reward total was 10.0. running mean: 7.876119005025498\n",
      "resetting env. episode reward total was 5.0. running mean: 7.847357814975243\n",
      "resetting env. episode reward total was 15.0. running mean: 7.918884236825491\n",
      "resetting env. episode reward total was -1.0. running mean: 7.829695394457236\n",
      "resetting env. episode reward total was 6.0. running mean: 7.811398440512663\n",
      "resetting env. episode reward total was 8.0. running mean: 7.813284456107537\n",
      "resetting env. episode reward total was 11.0. running mean: 7.845151611546462\n",
      "resetting env. episode reward total was 10.0. running mean: 7.866700095430997\n",
      "resetting env. episode reward total was 11.0. running mean: 7.898033094476688\n",
      "resetting env. episode reward total was 10.0. running mean: 7.91905276353192\n",
      "resetting env. episode reward total was 13.0. running mean: 7.969862235896601\n",
      "resetting env. episode reward total was 8.0. running mean: 7.970163613537635\n",
      "resetting env. episode reward total was -4.0. running mean: 7.850461977402259\n",
      "resetting env. episode reward total was -3.0. running mean: 7.741957357628236\n",
      "resetting env. episode reward total was 15.0. running mean: 7.814537784051954\n",
      "resetting env. episode reward total was 9.0. running mean: 7.826392406211434\n",
      "resetting env. episode reward total was 7.0. running mean: 7.818128482149319\n",
      "resetting env. episode reward total was 3.0. running mean: 7.769947197327826\n",
      "resetting env. episode reward total was 15.0. running mean: 7.842247725354548\n",
      "resetting env. episode reward total was 10.0. running mean: 7.863825248101002\n",
      "resetting env. episode reward total was 9.0. running mean: 7.875186995619992\n",
      "resetting env. episode reward total was 16.0. running mean: 7.956435125663792\n",
      "resetting env. episode reward total was 11.0. running mean: 7.986870774407154\n",
      "resetting env. episode reward total was 10.0. running mean: 8.007002066663082\n",
      "resetting env. episode reward total was 10.0. running mean: 8.026932045996451\n",
      "resetting env. episode reward total was 11.0. running mean: 8.056662725536487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 8.086096098281121\n",
      "resetting env. episode reward total was 4.0. running mean: 8.04523513729831\n",
      "resetting env. episode reward total was 4.0. running mean: 8.004782785925325\n",
      "resetting env. episode reward total was 14.0. running mean: 8.064734958066072\n",
      "resetting env. episode reward total was 15.0. running mean: 8.13408760848541\n",
      "resetting env. episode reward total was 3.0. running mean: 8.082746732400556\n",
      "resetting env. episode reward total was -1.0. running mean: 7.99191926507655\n",
      "resetting env. episode reward total was 15.0. running mean: 8.062000072425784\n",
      "resetting env. episode reward total was 6.0. running mean: 8.041380071701527\n",
      "resetting env. episode reward total was 3.0. running mean: 7.9909662709845115\n",
      "resetting env. episode reward total was 13.0. running mean: 8.041056608274667\n",
      "resetting env. episode reward total was 7.0. running mean: 8.03064604219192\n",
      "resetting env. episode reward total was 11.0. running mean: 8.06033958177\n",
      "resetting env. episode reward total was 7.0. running mean: 8.0497361859523\n",
      "resetting env. episode reward total was 8.0. running mean: 8.049238824092777\n",
      "resetting env. episode reward total was 11.0. running mean: 8.07874643585185\n",
      "resetting env. episode reward total was 5.0. running mean: 8.047958971493332\n",
      "resetting env. episode reward total was 9.0. running mean: 8.057479381778398\n",
      "resetting env. episode reward total was 9.0. running mean: 8.066904587960614\n",
      "resetting env. episode reward total was 5.0. running mean: 8.036235542081009\n",
      "resetting env. episode reward total was 10.0. running mean: 8.055873186660198\n",
      "resetting env. episode reward total was 11.0. running mean: 8.085314454793597\n",
      "resetting env. episode reward total was 8.0. running mean: 8.084461310245661\n",
      "resetting env. episode reward total was 8.0. running mean: 8.083616697143205\n",
      "resetting env. episode reward total was 8.0. running mean: 8.082780530171773\n",
      "resetting env. episode reward total was 9.0. running mean: 8.091952724870055\n",
      "resetting env. episode reward total was 13.0. running mean: 8.141033197621354\n",
      "resetting env. episode reward total was 6.0. running mean: 8.119622865645141\n",
      "resetting env. episode reward total was 17.0. running mean: 8.208426636988689\n",
      "resetting env. episode reward total was 3.0. running mean: 8.156342370618802\n",
      "resetting env. episode reward total was 3.0. running mean: 8.104778946912614\n",
      "resetting env. episode reward total was 9.0. running mean: 8.113731157443487\n",
      "resetting env. episode reward total was 11.0. running mean: 8.142593845869051\n",
      "resetting env. episode reward total was 9.0. running mean: 8.151167907410361\n",
      "resetting env. episode reward total was 7.0. running mean: 8.139656228336257\n",
      "resetting env. episode reward total was 2.0. running mean: 8.078259666052894\n",
      "resetting env. episode reward total was 4.0. running mean: 8.037477069392365\n",
      "resetting env. episode reward total was 12.0. running mean: 8.07710229869844\n",
      "resetting env. episode reward total was 14.0. running mean: 8.136331275711456\n",
      "resetting env. episode reward total was 12.0. running mean: 8.17496796295434\n",
      "resetting env. episode reward total was 2.0. running mean: 8.113218283324796\n",
      "resetting env. episode reward total was 13.0. running mean: 8.16208610049155\n",
      "resetting env. episode reward total was 7.0. running mean: 8.150465239486634\n",
      "resetting env. episode reward total was 16.0. running mean: 8.228960587091768\n",
      "resetting env. episode reward total was 9.0. running mean: 8.23667098122085\n",
      "resetting env. episode reward total was 2.0. running mean: 8.17430427140864\n",
      "resetting env. episode reward total was 11.0. running mean: 8.202561228694554\n",
      "resetting env. episode reward total was 6.0. running mean: 8.180535616407608\n",
      "resetting env. episode reward total was 8.0. running mean: 8.178730260243531\n",
      "resetting env. episode reward total was 5.0. running mean: 8.146942957641096\n",
      "resetting env. episode reward total was -5.0. running mean: 8.015473528064685\n",
      "resetting env. episode reward total was 3.0. running mean: 7.965318792784038\n",
      "resetting env. episode reward total was 7.0. running mean: 7.955665604856198\n",
      "resetting env. episode reward total was 6.0. running mean: 7.936108948807635\n",
      "resetting env. episode reward total was 11.0. running mean: 7.966747859319559\n",
      "resetting env. episode reward total was 9.0. running mean: 7.977080380726363\n",
      "resetting env. episode reward total was 16.0. running mean: 8.0573095769191\n",
      "resetting env. episode reward total was 13.0. running mean: 8.106736481149909\n",
      "resetting env. episode reward total was 6.0. running mean: 8.08566911633841\n",
      "resetting env. episode reward total was 16.0. running mean: 8.164812425175025\n",
      "resetting env. episode reward total was 8.0. running mean: 8.163164300923276\n",
      "resetting env. episode reward total was 17.0. running mean: 8.251532657914042\n",
      "resetting env. episode reward total was 6.0. running mean: 8.229017331334903\n",
      "resetting env. episode reward total was 6.0. running mean: 8.206727158021554\n",
      "resetting env. episode reward total was 9.0. running mean: 8.214659886441337\n",
      "resetting env. episode reward total was 5.0. running mean: 8.182513287576924\n",
      "resetting env. episode reward total was 7.0. running mean: 8.170688154701155\n",
      "resetting env. episode reward total was 9.0. running mean: 8.178981273154143\n",
      "resetting env. episode reward total was 15.0. running mean: 8.247191460422602\n",
      "resetting env. episode reward total was 9.0. running mean: 8.254719545818375\n",
      "resetting env. episode reward total was 13.0. running mean: 8.302172350360191\n",
      "resetting env. episode reward total was -1.0. running mean: 8.209150626856589\n",
      "resetting env. episode reward total was 3.0. running mean: 8.157059120588022\n",
      "resetting env. episode reward total was 10.0. running mean: 8.175488529382141\n",
      "resetting env. episode reward total was 9.0. running mean: 8.183733644088319\n",
      "resetting env. episode reward total was 11.0. running mean: 8.211896307647436\n",
      "resetting env. episode reward total was 7.0. running mean: 8.199777344570961\n",
      "resetting env. episode reward total was 9.0. running mean: 8.20777957112525\n",
      "resetting env. episode reward total was 2.0. running mean: 8.145701775413997\n",
      "resetting env. episode reward total was -1.0. running mean: 8.054244757659857\n",
      "resetting env. episode reward total was 13.0. running mean: 8.103702310083259\n",
      "resetting env. episode reward total was 7.0. running mean: 8.092665286982426\n",
      "resetting env. episode reward total was 11.0. running mean: 8.121738634112601\n",
      "resetting env. episode reward total was 13.0. running mean: 8.170521247771475\n",
      "resetting env. episode reward total was 13.0. running mean: 8.218816035293761\n",
      "resetting env. episode reward total was 3.0. running mean: 8.166627874940822\n",
      "resetting env. episode reward total was 5.0. running mean: 8.134961596191415\n",
      "resetting env. episode reward total was 9.0. running mean: 8.143611980229501\n",
      "resetting env. episode reward total was 6.0. running mean: 8.122175860427207\n",
      "resetting env. episode reward total was 11.0. running mean: 8.150954101822935\n",
      "resetting env. episode reward total was 8.0. running mean: 8.149444560804705\n",
      "resetting env. episode reward total was 12.0. running mean: 8.187950115196656\n",
      "resetting env. episode reward total was 10.0. running mean: 8.20607061404469\n",
      "resetting env. episode reward total was 12.0. running mean: 8.24400990790424\n",
      "resetting env. episode reward total was 5.0. running mean: 8.2115698088252\n",
      "resetting env. episode reward total was 9.0. running mean: 8.219454110736947\n",
      "resetting env. episode reward total was 8.0. running mean: 8.217259569629578\n",
      "resetting env. episode reward total was 7.0. running mean: 8.205086973933282\n",
      "resetting env. episode reward total was 7.0. running mean: 8.193036104193949\n",
      "resetting env. episode reward total was 8.0. running mean: 8.19110574315201\n",
      "resetting env. episode reward total was 1.0. running mean: 8.119194685720489\n",
      "resetting env. episode reward total was -3.0. running mean: 8.008002738863285\n",
      "resetting env. episode reward total was 12.0. running mean: 8.047922711474651\n",
      "resetting env. episode reward total was 5.0. running mean: 8.017443484359905\n",
      "resetting env. episode reward total was 12.0. running mean: 8.057269049516306\n",
      "resetting env. episode reward total was 10.0. running mean: 8.076696359021142\n",
      "resetting env. episode reward total was 7.0. running mean: 8.06592939543093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 8.065270101476619\n",
      "resetting env. episode reward total was 6.0. running mean: 8.044617400461853\n",
      "resetting env. episode reward total was -3.0. running mean: 7.9341712264572335\n",
      "resetting env. episode reward total was 10.0. running mean: 7.954829514192661\n",
      "resetting env. episode reward total was 6.0. running mean: 7.935281219050734\n",
      "resetting env. episode reward total was 13.0. running mean: 7.985928406860226\n",
      "resetting env. episode reward total was 4.0. running mean: 7.946069122791624\n",
      "resetting env. episode reward total was 16.0. running mean: 8.026608431563707\n",
      "resetting env. episode reward total was -1.0. running mean: 7.93634234724807\n",
      "resetting env. episode reward total was 4.0. running mean: 7.896978923775589\n",
      "resetting env. episode reward total was 10.0. running mean: 7.918009134537833\n",
      "resetting env. episode reward total was 1.0. running mean: 7.848829043192454\n",
      "resetting env. episode reward total was 12.0. running mean: 7.89034075276053\n",
      "resetting env. episode reward total was 8.0. running mean: 7.891437345232925\n",
      "resetting env. episode reward total was 17.0. running mean: 7.982522971780595\n",
      "resetting env. episode reward total was 4.0. running mean: 7.942697742062789\n",
      "resetting env. episode reward total was 7.0. running mean: 7.933270764642161\n",
      "resetting env. episode reward total was 5.0. running mean: 7.90393805699574\n",
      "resetting env. episode reward total was 8.0. running mean: 7.904898676425782\n",
      "resetting env. episode reward total was 12.0. running mean: 7.945849689661524\n",
      "resetting env. episode reward total was 2.0. running mean: 7.886391192764909\n",
      "resetting env. episode reward total was 10.0. running mean: 7.907527280837259\n",
      "resetting env. episode reward total was 14.0. running mean: 7.968452008028886\n",
      "resetting env. episode reward total was 14.0. running mean: 8.028767487948597\n",
      "resetting env. episode reward total was 7.0. running mean: 8.018479813069112\n",
      "resetting env. episode reward total was 17.0. running mean: 8.10829501493842\n",
      "resetting env. episode reward total was -3.0. running mean: 7.997212064789037\n",
      "resetting env. episode reward total was 5.0. running mean: 7.967239944141146\n",
      "resetting env. episode reward total was 5.0. running mean: 7.937567544699734\n",
      "resetting env. episode reward total was 4.0. running mean: 7.898191869252736\n",
      "resetting env. episode reward total was 7.0. running mean: 7.889209950560209\n",
      "resetting env. episode reward total was 11.0. running mean: 7.920317851054608\n",
      "resetting env. episode reward total was 16.0. running mean: 8.00111467254406\n",
      "resetting env. episode reward total was 11.0. running mean: 8.03110352581862\n",
      "resetting env. episode reward total was 7.0. running mean: 8.020792490560433\n",
      "resetting env. episode reward total was 9.0. running mean: 8.030584565654829\n",
      "resetting env. episode reward total was 8.0. running mean: 8.03027871999828\n",
      "resetting env. episode reward total was 8.0. running mean: 8.029975932798298\n",
      "resetting env. episode reward total was 2.0. running mean: 7.969676173470314\n",
      "resetting env. episode reward total was 7.0. running mean: 7.9599794117356115\n",
      "resetting env. episode reward total was 14.0. running mean: 8.020379617618255\n",
      "resetting env. episode reward total was 11.0. running mean: 8.050175821442073\n",
      "resetting env. episode reward total was -4.0. running mean: 7.929674063227652\n",
      "resetting env. episode reward total was 13.0. running mean: 7.980377322595375\n",
      "resetting env. episode reward total was -1.0. running mean: 7.890573549369422\n",
      "resetting env. episode reward total was 7.0. running mean: 7.881667813875728\n",
      "resetting env. episode reward total was 4.0. running mean: 7.842851135736971\n",
      "resetting env. episode reward total was 2.0. running mean: 7.784422624379601\n",
      "resetting env. episode reward total was 10.0. running mean: 7.806578398135804\n",
      "resetting env. episode reward total was 6.0. running mean: 7.788512614154445\n",
      "resetting env. episode reward total was 11.0. running mean: 7.820627488012901\n",
      "resetting env. episode reward total was 8.0. running mean: 7.822421213132772\n",
      "resetting env. episode reward total was -4.0. running mean: 7.704197001001444\n",
      "resetting env. episode reward total was 15.0. running mean: 7.7771550309914295\n",
      "resetting env. episode reward total was 6.0. running mean: 7.759383480681515\n",
      "resetting env. episode reward total was 14.0. running mean: 7.821789645874699\n",
      "resetting env. episode reward total was 1.0. running mean: 7.753571749415952\n",
      "resetting env. episode reward total was 14.0. running mean: 7.816036031921793\n",
      "resetting env. episode reward total was 13.0. running mean: 7.867875671602575\n",
      "resetting env. episode reward total was -1.0. running mean: 7.779196914886549\n",
      "resetting env. episode reward total was 13.0. running mean: 7.831404945737684\n",
      "resetting env. episode reward total was 17.0. running mean: 7.923090896280307\n",
      "resetting env. episode reward total was 6.0. running mean: 7.903859987317504\n",
      "resetting env. episode reward total was 13.0. running mean: 7.954821387444329\n",
      "resetting env. episode reward total was 3.0. running mean: 7.905273173569886\n",
      "resetting env. episode reward total was 5.0. running mean: 7.876220441834187\n",
      "resetting env. episode reward total was 4.0. running mean: 7.837458237415845\n",
      "resetting env. episode reward total was 4.0. running mean: 7.799083655041686\n",
      "resetting env. episode reward total was 15.0. running mean: 7.871092818491269\n",
      "resetting env. episode reward total was 9.0. running mean: 7.882381890306356\n",
      "resetting env. episode reward total was 8.0. running mean: 7.883558071403293\n",
      "resetting env. episode reward total was 14.0. running mean: 7.9447224906892595\n",
      "resetting env. episode reward total was 15.0. running mean: 8.015275265782368\n",
      "resetting env. episode reward total was 2.0. running mean: 7.955122513124543\n",
      "resetting env. episode reward total was 11.0. running mean: 7.985571287993298\n",
      "resetting env. episode reward total was 1.0. running mean: 7.9157155751133645\n",
      "resetting env. episode reward total was 11.0. running mean: 7.946558419362231\n",
      "resetting env. episode reward total was 8.0. running mean: 7.9470928351686085\n",
      "resetting env. episode reward total was 8.0. running mean: 7.947621906816923\n",
      "resetting env. episode reward total was 3.0. running mean: 7.8981456877487535\n",
      "resetting env. episode reward total was 8.0. running mean: 7.899164230871266\n",
      "resetting env. episode reward total was 11.0. running mean: 7.930172588562553\n",
      "resetting env. episode reward total was 12.0. running mean: 7.970870862676928\n",
      "resetting env. episode reward total was 5.0. running mean: 7.941162154050159\n",
      "resetting env. episode reward total was 8.0. running mean: 7.941750532509657\n",
      "resetting env. episode reward total was 5.0. running mean: 7.91233302718456\n",
      "resetting env. episode reward total was 4.0. running mean: 7.873209696912714\n",
      "resetting env. episode reward total was 6.0. running mean: 7.8544775999435865\n",
      "resetting env. episode reward total was 10.0. running mean: 7.87593282394415\n",
      "resetting env. episode reward total was 14.0. running mean: 7.937173495704708\n",
      "resetting env. episode reward total was -4.0. running mean: 7.817801760747661\n",
      "resetting env. episode reward total was 16.0. running mean: 7.899623743140184\n",
      "resetting env. episode reward total was 8.0. running mean: 7.9006275057087825\n",
      "resetting env. episode reward total was 16.0. running mean: 7.981621230651695\n",
      "resetting env. episode reward total was 13.0. running mean: 8.031805018345178\n",
      "resetting env. episode reward total was 15.0. running mean: 8.101486968161726\n",
      "resetting env. episode reward total was -2.0. running mean: 8.00047209848011\n",
      "resetting env. episode reward total was 12.0. running mean: 8.040467377495307\n",
      "resetting env. episode reward total was 10.0. running mean: 8.060062703720355\n",
      "resetting env. episode reward total was 12.0. running mean: 8.099462076683151\n",
      "resetting env. episode reward total was 10.0. running mean: 8.118467455916319\n",
      "resetting env. episode reward total was 11.0. running mean: 8.147282781357156\n",
      "resetting env. episode reward total was 10.0. running mean: 8.165809953543583\n",
      "resetting env. episode reward total was 1.0. running mean: 8.094151854008146\n",
      "resetting env. episode reward total was 9.0. running mean: 8.103210335468065\n",
      "resetting env. episode reward total was 10.0. running mean: 8.122178232113384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 8.06095644979225\n",
      "resetting env. episode reward total was 19.0. running mean: 8.170346885294327\n",
      "resetting env. episode reward total was 13.0. running mean: 8.218643416441385\n",
      "resetting env. episode reward total was 6.0. running mean: 8.19645698227697\n",
      "resetting env. episode reward total was 13.0. running mean: 8.244492412454202\n",
      "resetting env. episode reward total was 8.0. running mean: 8.242047488329659\n",
      "resetting env. episode reward total was 10.0. running mean: 8.259627013446362\n",
      "resetting env. episode reward total was 10.0. running mean: 8.277030743311899\n",
      "resetting env. episode reward total was 14.0. running mean: 8.33426043587878\n",
      "resetting env. episode reward total was 5.0. running mean: 8.300917831519994\n",
      "resetting env. episode reward total was 4.0. running mean: 8.257908653204794\n",
      "resetting env. episode reward total was 8.0. running mean: 8.255329566672746\n",
      "resetting env. episode reward total was 6.0. running mean: 8.232776271006019\n",
      "resetting env. episode reward total was 8.0. running mean: 8.230448508295959\n",
      "resetting env. episode reward total was 3.0. running mean: 8.178144023213\n",
      "resetting env. episode reward total was 10.0. running mean: 8.19636258298087\n",
      "resetting env. episode reward total was 5.0. running mean: 8.164398957151061\n",
      "resetting env. episode reward total was 10.0. running mean: 8.18275496757955\n",
      "resetting env. episode reward total was 13.0. running mean: 8.230927417903755\n",
      "resetting env. episode reward total was 11.0. running mean: 8.258618143724718\n",
      "resetting env. episode reward total was 4.0. running mean: 8.21603196228747\n",
      "resetting env. episode reward total was 8.0. running mean: 8.213871642664596\n",
      "resetting env. episode reward total was 5.0. running mean: 8.18173292623795\n",
      "resetting env. episode reward total was 14.0. running mean: 8.239915596975571\n",
      "resetting env. episode reward total was 1.0. running mean: 8.167516441005816\n",
      "resetting env. episode reward total was -2.0. running mean: 8.065841276595759\n",
      "resetting env. episode reward total was 5.0. running mean: 8.035182863829801\n",
      "resetting env. episode reward total was 6.0. running mean: 8.014831035191504\n",
      "resetting env. episode reward total was 9.0. running mean: 8.02468272483959\n",
      "resetting env. episode reward total was 10.0. running mean: 8.044435897591194\n",
      "resetting env. episode reward total was 12.0. running mean: 8.083991538615281\n",
      "resetting env. episode reward total was 1.0. running mean: 8.013151623229128\n",
      "resetting env. episode reward total was -1.0. running mean: 7.9230201069968365\n",
      "resetting env. episode reward total was 6.0. running mean: 7.9037899059268675\n",
      "resetting env. episode reward total was 5.0. running mean: 7.874752006867599\n",
      "resetting env. episode reward total was 8.0. running mean: 7.876004486798923\n",
      "resetting env. episode reward total was 7.0. running mean: 7.867244441930934\n",
      "resetting env. episode reward total was 10.0. running mean: 7.888571997511624\n",
      "resetting env. episode reward total was 10.0. running mean: 7.909686277536507\n",
      "resetting env. episode reward total was 3.0. running mean: 7.860589414761143\n",
      "resetting env. episode reward total was 2.0. running mean: 7.801983520613531\n",
      "resetting env. episode reward total was 6.0. running mean: 7.783963685407395\n",
      "resetting env. episode reward total was -2.0. running mean: 7.686124048553321\n",
      "resetting env. episode reward total was 8.0. running mean: 7.689262808067788\n",
      "resetting env. episode reward total was 5.0. running mean: 7.66237017998711\n",
      "resetting env. episode reward total was 12.0. running mean: 7.705746478187239\n",
      "resetting env. episode reward total was 12.0. running mean: 7.748689013405366\n",
      "resetting env. episode reward total was 12.0. running mean: 7.7912021232713125\n",
      "resetting env. episode reward total was 3.0. running mean: 7.7432901020386\n",
      "resetting env. episode reward total was -1.0. running mean: 7.655857201018214\n",
      "resetting env. episode reward total was 10.0. running mean: 7.679298629008032\n",
      "resetting env. episode reward total was 6.0. running mean: 7.662505642717951\n",
      "resetting env. episode reward total was 9.0. running mean: 7.675880586290772\n",
      "resetting env. episode reward total was 8.0. running mean: 7.679121780427864\n",
      "resetting env. episode reward total was 5.0. running mean: 7.652330562623585\n",
      "resetting env. episode reward total was 14.0. running mean: 7.715807256997349\n",
      "resetting env. episode reward total was 8.0. running mean: 7.718649184427375\n",
      "resetting env. episode reward total was 11.0. running mean: 7.751462692583101\n",
      "resetting env. episode reward total was 9.0. running mean: 7.76394806565727\n",
      "resetting env. episode reward total was 14.0. running mean: 7.826308585000697\n",
      "resetting env. episode reward total was 1.0. running mean: 7.75804549915069\n",
      "resetting env. episode reward total was 8.0. running mean: 7.760465044159183\n",
      "resetting env. episode reward total was -5.0. running mean: 7.632860393717591\n",
      "resetting env. episode reward total was 2.0. running mean: 7.5765317897804145\n",
      "resetting env. episode reward total was 5.0. running mean: 7.55076647188261\n",
      "resetting env. episode reward total was 12.0. running mean: 7.595258807163784\n",
      "resetting env. episode reward total was 15.0. running mean: 7.669306219092147\n",
      "resetting env. episode reward total was 11.0. running mean: 7.702613156901226\n",
      "resetting env. episode reward total was 10.0. running mean: 7.725587025332213\n",
      "resetting env. episode reward total was -1.0. running mean: 7.638331155078891\n",
      "resetting env. episode reward total was 3.0. running mean: 7.591947843528103\n",
      "resetting env. episode reward total was 12.0. running mean: 7.636028365092821\n",
      "resetting env. episode reward total was 8.0. running mean: 7.639668081441894\n",
      "resetting env. episode reward total was -1.0. running mean: 7.553271400627475\n",
      "resetting env. episode reward total was 8.0. running mean: 7.5577386866212\n",
      "resetting env. episode reward total was 10.0. running mean: 7.582161299754988\n",
      "resetting env. episode reward total was 9.0. running mean: 7.596339686757438\n",
      "resetting env. episode reward total was 17.0. running mean: 7.690376289889864\n",
      "resetting env. episode reward total was 11.0. running mean: 7.723472526990966\n",
      "resetting env. episode reward total was 10.0. running mean: 7.746237801721056\n",
      "resetting env. episode reward total was 8.0. running mean: 7.748775423703845\n",
      "resetting env. episode reward total was 11.0. running mean: 7.781287669466806\n",
      "resetting env. episode reward total was 3.0. running mean: 7.733474792772139\n",
      "resetting env. episode reward total was 9.0. running mean: 7.7461400448444175\n",
      "resetting env. episode reward total was 9.0. running mean: 7.758678644395973\n",
      "resetting env. episode reward total was 12.0. running mean: 7.801091857952013\n",
      "resetting env. episode reward total was 9.0. running mean: 7.813080939372493\n",
      "resetting env. episode reward total was -1.0. running mean: 7.724950129978768\n",
      "resetting env. episode reward total was 6.0. running mean: 7.70770062867898\n",
      "resetting env. episode reward total was 8.0. running mean: 7.71062362239219\n",
      "resetting env. episode reward total was 12.0. running mean: 7.7535173861682685\n",
      "resetting env. episode reward total was 8.0. running mean: 7.755982212306586\n",
      "resetting env. episode reward total was 7.0. running mean: 7.748422390183521\n",
      "resetting env. episode reward total was 13.0. running mean: 7.800938166281686\n",
      "resetting env. episode reward total was -1.0. running mean: 7.712928784618869\n",
      "resetting env. episode reward total was 11.0. running mean: 7.745799496772681\n",
      "resetting env. episode reward total was 11.0. running mean: 7.778341501804954\n",
      "resetting env. episode reward total was 12.0. running mean: 7.820558086786905\n",
      "resetting env. episode reward total was 9.0. running mean: 7.832352505919036\n",
      "resetting env. episode reward total was 9.0. running mean: 7.844028980859846\n",
      "resetting env. episode reward total was 10.0. running mean: 7.865588691051246\n",
      "resetting env. episode reward total was 2.0. running mean: 7.806932804140733\n",
      "resetting env. episode reward total was 11.0. running mean: 7.838863476099326\n",
      "resetting env. episode reward total was 6.0. running mean: 7.820474841338332\n",
      "resetting env. episode reward total was -2.0. running mean: 7.7222700929249495\n",
      "resetting env. episode reward total was 8.0. running mean: 7.7250473919957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 7.787796918075743\n",
      "resetting env. episode reward total was -3.0. running mean: 7.679918948894985\n",
      "resetting env. episode reward total was 3.0. running mean: 7.633119759406035\n",
      "resetting env. episode reward total was 12.0. running mean: 7.676788561811974\n",
      "resetting env. episode reward total was 5.0. running mean: 7.650020676193854\n",
      "resetting env. episode reward total was 2.0. running mean: 7.593520469431915\n",
      "resetting env. episode reward total was 12.0. running mean: 7.637585264737596\n",
      "resetting env. episode reward total was 7.0. running mean: 7.63120941209022\n",
      "resetting env. episode reward total was 5.0. running mean: 7.604897317969318\n",
      "resetting env. episode reward total was 2.0. running mean: 7.548848344789624\n",
      "resetting env. episode reward total was 14.0. running mean: 7.613359861341728\n",
      "resetting env. episode reward total was 10.0. running mean: 7.63722626272831\n",
      "resetting env. episode reward total was 12.0. running mean: 7.680854000101027\n",
      "resetting env. episode reward total was 10.0. running mean: 7.704045460100017\n",
      "resetting env. episode reward total was 14.0. running mean: 7.767005005499016\n",
      "resetting env. episode reward total was 6.0. running mean: 7.749334955444025\n",
      "resetting env. episode reward total was 6.0. running mean: 7.731841605889585\n",
      "resetting env. episode reward total was 8.0. running mean: 7.734523189830689\n",
      "resetting env. episode reward total was 15.0. running mean: 7.807177957932383\n",
      "resetting env. episode reward total was 15.0. running mean: 7.879106178353059\n",
      "resetting env. episode reward total was 8.0. running mean: 7.880315116569528\n",
      "resetting env. episode reward total was 8.0. running mean: 7.881511965403832\n",
      "resetting env. episode reward total was 8.0. running mean: 7.882696845749794\n",
      "resetting env. episode reward total was 5.0. running mean: 7.853869877292296\n",
      "resetting env. episode reward total was 13.0. running mean: 7.905331178519373\n",
      "resetting env. episode reward total was 9.0. running mean: 7.916277866734179\n",
      "resetting env. episode reward total was 12.0. running mean: 7.957115088066837\n",
      "resetting env. episode reward total was 4.0. running mean: 7.917543937186169\n",
      "resetting env. episode reward total was 1.0. running mean: 7.848368497814307\n",
      "resetting env. episode reward total was 6.0. running mean: 7.8298848128361636\n",
      "resetting env. episode reward total was 14.0. running mean: 7.891585964707802\n",
      "resetting env. episode reward total was -5.0. running mean: 7.762670105060724\n",
      "resetting env. episode reward total was 12.0. running mean: 7.805043404010116\n",
      "resetting env. episode reward total was 12.0. running mean: 7.846992969970016\n",
      "resetting env. episode reward total was 15.0. running mean: 7.9185230402703155\n",
      "resetting env. episode reward total was -4.0. running mean: 7.7993378098676125\n",
      "resetting env. episode reward total was 8.0. running mean: 7.801344431768936\n",
      "resetting env. episode reward total was 8.0. running mean: 7.803330987451247\n",
      "resetting env. episode reward total was 12.0. running mean: 7.845297677576735\n",
      "resetting env. episode reward total was -7.0. running mean: 7.696844700800967\n",
      "resetting env. episode reward total was 14.0. running mean: 7.759876253792957\n",
      "resetting env. episode reward total was 8.0. running mean: 7.762277491255027\n",
      "resetting env. episode reward total was 9.0. running mean: 7.774654716342477\n",
      "resetting env. episode reward total was 14.0. running mean: 7.836908169179051\n",
      "resetting env. episode reward total was 11.0. running mean: 7.868539087487261\n",
      "resetting env. episode reward total was 3.0. running mean: 7.819853696612388\n",
      "resetting env. episode reward total was -1.0. running mean: 7.731655159646265\n",
      "resetting env. episode reward total was 5.0. running mean: 7.704338608049802\n",
      "resetting env. episode reward total was 11.0. running mean: 7.737295221969305\n",
      "resetting env. episode reward total was 8.0. running mean: 7.739922269749612\n",
      "resetting env. episode reward total was 13.0. running mean: 7.792523047052116\n",
      "resetting env. episode reward total was 17.0. running mean: 7.884597816581595\n",
      "resetting env. episode reward total was 10.0. running mean: 7.905751838415778\n",
      "resetting env. episode reward total was 10.0. running mean: 7.92669432003162\n",
      "resetting env. episode reward total was -3.0. running mean: 7.817427376831303\n",
      "resetting env. episode reward total was 15.0. running mean: 7.88925310306299\n",
      "resetting env. episode reward total was 8.0. running mean: 7.89036057203236\n",
      "resetting env. episode reward total was 12.0. running mean: 7.9314569663120364\n",
      "resetting env. episode reward total was -7.0. running mean: 7.782142396648916\n",
      "resetting env. episode reward total was 5.0. running mean: 7.754320972682426\n",
      "resetting env. episode reward total was 9.0. running mean: 7.766777762955601\n",
      "resetting env. episode reward total was 8.0. running mean: 7.769109985326045\n",
      "resetting env. episode reward total was 4.0. running mean: 7.7314188854727846\n",
      "resetting env. episode reward total was 12.0. running mean: 7.774104696618057\n",
      "resetting env. episode reward total was 11.0. running mean: 7.8063636496518765\n",
      "resetting env. episode reward total was 11.0. running mean: 7.838300013155358\n",
      "resetting env. episode reward total was 11.0. running mean: 7.869917013023804\n",
      "resetting env. episode reward total was 4.0. running mean: 7.831217842893566\n",
      "resetting env. episode reward total was 10.0. running mean: 7.85290566446463\n",
      "resetting env. episode reward total was 10.0. running mean: 7.8743766078199835\n",
      "resetting env. episode reward total was 6.0. running mean: 7.855632841741783\n",
      "resetting env. episode reward total was 17.0. running mean: 7.947076513324365\n",
      "resetting env. episode reward total was 15.0. running mean: 8.017605748191121\n",
      "resetting env. episode reward total was 5.0. running mean: 7.9874296907092095\n",
      "resetting env. episode reward total was 8.0. running mean: 7.9875553938021175\n",
      "resetting env. episode reward total was 1.0. running mean: 7.917679839864096\n",
      "resetting env. episode reward total was 14.0. running mean: 7.978503041465455\n",
      "resetting env. episode reward total was 12.0. running mean: 8.0187180110508\n",
      "resetting env. episode reward total was 4.0. running mean: 7.978530830940291\n",
      "resetting env. episode reward total was 3.0. running mean: 7.928745522630888\n",
      "resetting env. episode reward total was 4.0. running mean: 7.889458067404579\n",
      "resetting env. episode reward total was 5.0. running mean: 7.860563486730533\n",
      "resetting env. episode reward total was 8.0. running mean: 7.861957851863228\n",
      "resetting env. episode reward total was 7.0. running mean: 7.853338273344596\n",
      "resetting env. episode reward total was 9.0. running mean: 7.86480489061115\n",
      "resetting env. episode reward total was 12.0. running mean: 7.906156841705038\n",
      "resetting env. episode reward total was 12.0. running mean: 7.947095273287988\n",
      "resetting env. episode reward total was 3.0. running mean: 7.897624320555108\n",
      "resetting env. episode reward total was 14.0. running mean: 7.958648077349557\n",
      "resetting env. episode reward total was 9.0. running mean: 7.969061596576061\n",
      "resetting env. episode reward total was 8.0. running mean: 7.969370980610301\n",
      "resetting env. episode reward total was 9.0. running mean: 7.979677270804197\n",
      "resetting env. episode reward total was 6.0. running mean: 7.959880498096155\n",
      "resetting env. episode reward total was 10.0. running mean: 7.9802816931151925\n",
      "resetting env. episode reward total was 15.0. running mean: 8.050478876184041\n",
      "resetting env. episode reward total was 6.0. running mean: 8.0299740874222\n",
      "resetting env. episode reward total was 5.0. running mean: 7.9996743465479785\n",
      "resetting env. episode reward total was 9.0. running mean: 8.0096776030825\n",
      "resetting env. episode reward total was 7.0. running mean: 7.999580827051675\n",
      "resetting env. episode reward total was 10.0. running mean: 8.019585018781159\n",
      "resetting env. episode reward total was 11.0. running mean: 8.049389168593347\n",
      "resetting env. episode reward total was 6.0. running mean: 8.028895276907413\n",
      "resetting env. episode reward total was -2.0. running mean: 7.9286063241383395\n",
      "resetting env. episode reward total was 11.0. running mean: 7.959320260896956\n",
      "resetting env. episode reward total was 5.0. running mean: 7.929727058287987\n",
      "resetting env. episode reward total was 14.0. running mean: 7.990429787705106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 7.970525489828055\n",
      "resetting env. episode reward total was 10.0. running mean: 7.990820234929774\n",
      "resetting env. episode reward total was 13.0. running mean: 8.040912032580476\n",
      "resetting env. episode reward total was 12.0. running mean: 8.080502912254671\n",
      "resetting env. episode reward total was 13.0. running mean: 8.129697883132124\n",
      "resetting env. episode reward total was 11.0. running mean: 8.158400904300802\n",
      "resetting env. episode reward total was 8.0. running mean: 8.156816895257794\n",
      "resetting env. episode reward total was 11.0. running mean: 8.185248726305215\n",
      "resetting env. episode reward total was 5.0. running mean: 8.153396239042163\n",
      "resetting env. episode reward total was 11.0. running mean: 8.18186227665174\n",
      "resetting env. episode reward total was 7.0. running mean: 8.170043653885223\n",
      "resetting env. episode reward total was 9.0. running mean: 8.17834321734637\n",
      "resetting env. episode reward total was 5.0. running mean: 8.146559785172908\n",
      "resetting env. episode reward total was 6.0. running mean: 8.12509418732118\n",
      "resetting env. episode reward total was 6.0. running mean: 8.103843245447969\n",
      "resetting env. episode reward total was 3.0. running mean: 8.052804812993488\n",
      "resetting env. episode reward total was 10.0. running mean: 8.072276764863553\n",
      "resetting env. episode reward total was 12.0. running mean: 8.111553997214916\n",
      "resetting env. episode reward total was 9.0. running mean: 8.120438457242766\n",
      "resetting env. episode reward total was 9.0. running mean: 8.129234072670338\n",
      "resetting env. episode reward total was 7.0. running mean: 8.117941731943635\n",
      "resetting env. episode reward total was 9.0. running mean: 8.126762314624198\n",
      "resetting env. episode reward total was 9.0. running mean: 8.135494691477955\n",
      "resetting env. episode reward total was -3.0. running mean: 8.024139744563175\n",
      "resetting env. episode reward total was 12.0. running mean: 8.063898347117544\n",
      "resetting env. episode reward total was 4.0. running mean: 8.023259363646368\n",
      "resetting env. episode reward total was 3.0. running mean: 7.973026770009904\n",
      "resetting env. episode reward total was 12.0. running mean: 8.013296502309805\n",
      "resetting env. episode reward total was 2.0. running mean: 7.953163537286707\n",
      "resetting env. episode reward total was 13.0. running mean: 8.00363190191384\n",
      "resetting env. episode reward total was 3.0. running mean: 7.953595582894701\n",
      "resetting env. episode reward total was 10.0. running mean: 7.9740596270657536\n",
      "resetting env. episode reward total was 12.0. running mean: 8.014319030795095\n",
      "resetting env. episode reward total was 9.0. running mean: 8.024175840487144\n",
      "resetting env. episode reward total was -1.0. running mean: 7.933934082082273\n",
      "resetting env. episode reward total was 8.0. running mean: 7.93459474126145\n",
      "resetting env. episode reward total was 5.0. running mean: 7.905248793848836\n",
      "resetting env. episode reward total was -8.0. running mean: 7.746196305910347\n",
      "resetting env. episode reward total was 10.0. running mean: 7.768734342851244\n",
      "resetting env. episode reward total was 7.0. running mean: 7.761046999422732\n",
      "resetting env. episode reward total was 12.0. running mean: 7.803436529428504\n",
      "resetting env. episode reward total was 6.0. running mean: 7.785402164134219\n",
      "resetting env. episode reward total was 3.0. running mean: 7.7375481424928765\n",
      "resetting env. episode reward total was 12.0. running mean: 7.780172661067947\n",
      "resetting env. episode reward total was 6.0. running mean: 7.762370934457268\n",
      "resetting env. episode reward total was 11.0. running mean: 7.794747225112696\n",
      "resetting env. episode reward total was -3.0. running mean: 7.686799752861568\n",
      "resetting env. episode reward total was 14.0. running mean: 7.749931755332952\n",
      "resetting env. episode reward total was -3.0. running mean: 7.642432437779622\n",
      "resetting env. episode reward total was 6.0. running mean: 7.626008113401825\n",
      "resetting env. episode reward total was 11.0. running mean: 7.6597480322678075\n",
      "resetting env. episode reward total was 3.0. running mean: 7.61315055194513\n",
      "resetting env. episode reward total was 7.0. running mean: 7.607019046425679\n",
      "resetting env. episode reward total was 13.0. running mean: 7.660948855961422\n",
      "resetting env. episode reward total was 3.0. running mean: 7.614339367401808\n",
      "resetting env. episode reward total was 3.0. running mean: 7.56819597372779\n",
      "resetting env. episode reward total was 1.0. running mean: 7.502514013990512\n",
      "resetting env. episode reward total was 5.0. running mean: 7.477488873850607\n",
      "resetting env. episode reward total was 16.0. running mean: 7.562713985112101\n",
      "resetting env. episode reward total was 15.0. running mean: 7.63708684526098\n",
      "resetting env. episode reward total was 11.0. running mean: 7.670715976808371\n",
      "resetting env. episode reward total was 10.0. running mean: 7.694008817040286\n",
      "resetting env. episode reward total was 9.0. running mean: 7.707068728869883\n",
      "resetting env. episode reward total was 4.0. running mean: 7.669998041581184\n",
      "resetting env. episode reward total was 11.0. running mean: 7.7032980611653725\n",
      "resetting env. episode reward total was 4.0. running mean: 7.6662650805537185\n",
      "resetting env. episode reward total was 5.0. running mean: 7.639602429748181\n",
      "resetting env. episode reward total was 1.0. running mean: 7.573206405450699\n",
      "resetting env. episode reward total was 11.0. running mean: 7.607474341396192\n",
      "resetting env. episode reward total was 6.0. running mean: 7.59139959798223\n",
      "resetting env. episode reward total was 10.0. running mean: 7.6154856020024075\n",
      "resetting env. episode reward total was 2.0. running mean: 7.559330745982383\n",
      "resetting env. episode reward total was 6.0. running mean: 7.543737438522558\n",
      "resetting env. episode reward total was 11.0. running mean: 7.578300064137332\n",
      "resetting env. episode reward total was 9.0. running mean: 7.592517063495959\n",
      "resetting env. episode reward total was -2.0. running mean: 7.496591892861\n",
      "resetting env. episode reward total was 10.0. running mean: 7.521625973932389\n",
      "resetting env. episode reward total was 9.0. running mean: 7.5364097141930655\n",
      "resetting env. episode reward total was 14.0. running mean: 7.601045617051135\n",
      "resetting env. episode reward total was 5.0. running mean: 7.575035160880623\n",
      "resetting env. episode reward total was 10.0. running mean: 7.599284809271817\n",
      "resetting env. episode reward total was 7.0. running mean: 7.593291961179099\n",
      "resetting env. episode reward total was 1.0. running mean: 7.5273590415673075\n",
      "resetting env. episode reward total was 8.0. running mean: 7.532085451151635\n",
      "resetting env. episode reward total was 12.0. running mean: 7.5767645966401185\n",
      "resetting env. episode reward total was 6.0. running mean: 7.560996950673717\n",
      "resetting env. episode reward total was 1.0. running mean: 7.4953869811669795\n",
      "resetting env. episode reward total was 6.0. running mean: 7.4804331113553095\n",
      "resetting env. episode reward total was 2.0. running mean: 7.425628780241756\n",
      "resetting env. episode reward total was 10.0. running mean: 7.451372492439338\n",
      "resetting env. episode reward total was 9.0. running mean: 7.466858767514945\n",
      "resetting env. episode reward total was 10.0. running mean: 7.492190179839795\n",
      "resetting env. episode reward total was 3.0. running mean: 7.447268278041397\n",
      "resetting env. episode reward total was 13.0. running mean: 7.5027955952609835\n",
      "resetting env. episode reward total was 4.0. running mean: 7.467767639308374\n",
      "resetting env. episode reward total was 11.0. running mean: 7.50308996291529\n",
      "resetting env. episode reward total was 2.0. running mean: 7.448059063286136\n",
      "resetting env. episode reward total was 16.0. running mean: 7.533578472653275\n",
      "resetting env. episode reward total was 1.0. running mean: 7.468242687926742\n",
      "resetting env. episode reward total was 8.0. running mean: 7.473560261047475\n",
      "resetting env. episode reward total was 5.0. running mean: 7.448824658437\n",
      "resetting env. episode reward total was 4.0. running mean: 7.41433641185263\n",
      "resetting env. episode reward total was 9.0. running mean: 7.430193047734103\n",
      "resetting env. episode reward total was 16.0. running mean: 7.515891117256762\n",
      "resetting env. episode reward total was 10.0. running mean: 7.540732206084194\n",
      "resetting env. episode reward total was 8.0. running mean: 7.545324884023352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 7.609871635183119\n",
      "resetting env. episode reward total was 9.0. running mean: 7.623772918831287\n",
      "resetting env. episode reward total was 7.0. running mean: 7.617535189642974\n",
      "resetting env. episode reward total was 4.0. running mean: 7.581359837746545\n",
      "resetting env. episode reward total was 2.0. running mean: 7.525546239369079\n",
      "resetting env. episode reward total was 2.0. running mean: 7.4702907769753875\n",
      "resetting env. episode reward total was 9.0. running mean: 7.4855878692056335\n",
      "resetting env. episode reward total was 9.0. running mean: 7.500731990513577\n",
      "resetting env. episode reward total was 10.0. running mean: 7.525724670608441\n",
      "resetting env. episode reward total was 12.0. running mean: 7.570467423902357\n",
      "resetting env. episode reward total was 8.0. running mean: 7.574762749663333\n",
      "resetting env. episode reward total was 15.0. running mean: 7.6490151221667\n",
      "resetting env. episode reward total was 15.0. running mean: 7.722524970945034\n",
      "resetting env. episode reward total was 11.0. running mean: 7.755299721235583\n",
      "resetting env. episode reward total was 7.0. running mean: 7.747746724023227\n",
      "resetting env. episode reward total was 12.0. running mean: 7.790269256782995\n",
      "resetting env. episode reward total was 8.0. running mean: 7.792366564215166\n",
      "resetting env. episode reward total was 2.0. running mean: 7.734442898573014\n",
      "resetting env. episode reward total was -3.0. running mean: 7.627098469587283\n",
      "resetting env. episode reward total was 9.0. running mean: 7.64082748489141\n",
      "resetting env. episode reward total was 9.0. running mean: 7.654419210042496\n",
      "resetting env. episode reward total was -1.0. running mean: 7.567875017942072\n",
      "resetting env. episode reward total was 12.0. running mean: 7.612196267762651\n",
      "resetting env. episode reward total was 14.0. running mean: 7.676074305085025\n",
      "resetting env. episode reward total was 15.0. running mean: 7.749313562034175\n",
      "resetting env. episode reward total was 15.0. running mean: 7.821820426413833\n",
      "resetting env. episode reward total was 4.0. running mean: 7.783602222149694\n",
      "resetting env. episode reward total was 13.0. running mean: 7.835766199928197\n",
      "resetting env. episode reward total was 2.0. running mean: 7.777408537928915\n",
      "resetting env. episode reward total was 10.0. running mean: 7.7996344525496255\n",
      "resetting env. episode reward total was 9.0. running mean: 7.811638108024129\n",
      "resetting env. episode reward total was 17.0. running mean: 7.903521726943887\n",
      "resetting env. episode reward total was 12.0. running mean: 7.944486509674448\n",
      "resetting env. episode reward total was 14.0. running mean: 8.005041644577704\n",
      "resetting env. episode reward total was 14.0. running mean: 8.064991228131927\n",
      "resetting env. episode reward total was 10.0. running mean: 8.084341315850608\n",
      "resetting env. episode reward total was -5.0. running mean: 7.953497902692102\n",
      "resetting env. episode reward total was 12.0. running mean: 7.993962923665181\n",
      "resetting env. episode reward total was 4.0. running mean: 7.954023294428529\n",
      "resetting env. episode reward total was 14.0. running mean: 8.014483061484244\n",
      "resetting env. episode reward total was 12.0. running mean: 8.054338230869401\n",
      "resetting env. episode reward total was 7.0. running mean: 8.043794848560706\n",
      "resetting env. episode reward total was 10.0. running mean: 8.0633569000751\n",
      "resetting env. episode reward total was 14.0. running mean: 8.122723331074349\n",
      "resetting env. episode reward total was 9.0. running mean: 8.131496097763605\n",
      "resetting env. episode reward total was -5.0. running mean: 8.000181136785969\n",
      "resetting env. episode reward total was 3.0. running mean: 7.95017932541811\n",
      "resetting env. episode reward total was 5.0. running mean: 7.9206775321639284\n",
      "resetting env. episode reward total was 13.0. running mean: 7.971470756842289\n",
      "resetting env. episode reward total was 18.0. running mean: 8.071756049273867\n",
      "resetting env. episode reward total was 2.0. running mean: 8.011038488781129\n",
      "resetting env. episode reward total was 11.0. running mean: 8.040928103893316\n",
      "resetting env. episode reward total was 12.0. running mean: 8.080518822854383\n",
      "resetting env. episode reward total was 2.0. running mean: 8.01971363462584\n",
      "resetting env. episode reward total was 8.0. running mean: 8.01951649827958\n",
      "resetting env. episode reward total was -1.0. running mean: 7.929321333296785\n",
      "resetting env. episode reward total was -1.0. running mean: 7.840028119963817\n",
      "resetting env. episode reward total was 10.0. running mean: 7.8616278387641785\n",
      "resetting env. episode reward total was 10.0. running mean: 7.883011560376536\n",
      "resetting env. episode reward total was 10.0. running mean: 7.90418144477277\n",
      "resetting env. episode reward total was 2.0. running mean: 7.845139630325042\n",
      "resetting env. episode reward total was -2.0. running mean: 7.746688234021792\n",
      "resetting env. episode reward total was 8.0. running mean: 7.749221351681574\n",
      "resetting env. episode reward total was 12.0. running mean: 7.791729138164758\n",
      "resetting env. episode reward total was -1.0. running mean: 7.70381184678311\n",
      "resetting env. episode reward total was 14.0. running mean: 7.766773728315279\n",
      "resetting env. episode reward total was 8.0. running mean: 7.769105991032126\n",
      "resetting env. episode reward total was 5.0. running mean: 7.741414931121804\n",
      "resetting env. episode reward total was 6.0. running mean: 7.724000781810586\n",
      "resetting env. episode reward total was 6.0. running mean: 7.70676077399248\n",
      "resetting env. episode reward total was 10.0. running mean: 7.729693166252555\n",
      "resetting env. episode reward total was 6.0. running mean: 7.712396234590029\n",
      "resetting env. episode reward total was 6.0. running mean: 7.695272272244129\n",
      "resetting env. episode reward total was 12.0. running mean: 7.738319549521687\n",
      "resetting env. episode reward total was 8.0. running mean: 7.740936354026471\n",
      "resetting env. episode reward total was 9.0. running mean: 7.753526990486206\n",
      "resetting env. episode reward total was 10.0. running mean: 7.775991720581343\n",
      "resetting env. episode reward total was 4.0. running mean: 7.7382318033755295\n",
      "resetting env. episode reward total was 15.0. running mean: 7.810849485341775\n",
      "resetting env. episode reward total was 16.0. running mean: 7.892740990488357\n",
      "resetting env. episode reward total was 13.0. running mean: 7.943813580583473\n",
      "resetting env. episode reward total was 10.0. running mean: 7.964375444777638\n",
      "resetting env. episode reward total was -4.0. running mean: 7.844731690329862\n",
      "resetting env. episode reward total was 7.0. running mean: 7.8362843734265635\n",
      "resetting env. episode reward total was 11.0. running mean: 7.867921529692298\n",
      "resetting env. episode reward total was 15.0. running mean: 7.939242314395376\n",
      "resetting env. episode reward total was 6.0. running mean: 7.919849891251421\n",
      "resetting env. episode reward total was 6.0. running mean: 7.900651392338907\n",
      "resetting env. episode reward total was 6.0. running mean: 7.881644878415518\n",
      "resetting env. episode reward total was 6.0. running mean: 7.862828429631362\n",
      "resetting env. episode reward total was 9.0. running mean: 7.874200145335048\n",
      "resetting env. episode reward total was 6.0. running mean: 7.855458143881697\n",
      "resetting env. episode reward total was 12.0. running mean: 7.896903562442881\n",
      "resetting env. episode reward total was 4.0. running mean: 7.857934526818452\n",
      "resetting env. episode reward total was 8.0. running mean: 7.859355181550268\n",
      "resetting env. episode reward total was 12.0. running mean: 7.900761629734766\n",
      "resetting env. episode reward total was 10.0. running mean: 7.921754013437417\n",
      "resetting env. episode reward total was 8.0. running mean: 7.922536473303043\n",
      "resetting env. episode reward total was 7.0. running mean: 7.913311108570013\n",
      "resetting env. episode reward total was 17.0. running mean: 8.004177997484312\n",
      "resetting env. episode reward total was 14.0. running mean: 8.06413621750947\n",
      "resetting env. episode reward total was 9.0. running mean: 8.073494855334374\n",
      "resetting env. episode reward total was 9.0. running mean: 8.08275990678103\n",
      "resetting env. episode reward total was 6.0. running mean: 8.06193230771322\n",
      "resetting env. episode reward total was 5.0. running mean: 8.031312984636088\n",
      "resetting env. episode reward total was 9.0. running mean: 8.040999854789728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: 7.910589856241831\n",
      "resetting env. episode reward total was -9.0. running mean: 7.741483957679413\n",
      "resetting env. episode reward total was 12.0. running mean: 7.784069118102619\n",
      "resetting env. episode reward total was 4.0. running mean: 7.746228426921593\n",
      "resetting env. episode reward total was 8.0. running mean: 7.748766142652377\n",
      "resetting env. episode reward total was 6.0. running mean: 7.731278481225853\n",
      "resetting env. episode reward total was 5.0. running mean: 7.703965696413594\n",
      "resetting env. episode reward total was 12.0. running mean: 7.746926039449458\n",
      "resetting env. episode reward total was 1.0. running mean: 7.679456779054963\n",
      "resetting env. episode reward total was 3.0. running mean: 7.632662211264414\n",
      "resetting env. episode reward total was 1.0. running mean: 7.56633558915177\n",
      "resetting env. episode reward total was 2.0. running mean: 7.510672233260252\n",
      "resetting env. episode reward total was 11.0. running mean: 7.545565510927649\n",
      "resetting env. episode reward total was 6.0. running mean: 7.530109855818372\n",
      "resetting env. episode reward total was 11.0. running mean: 7.564808757260189\n",
      "resetting env. episode reward total was 9.0. running mean: 7.579160669687587\n",
      "resetting env. episode reward total was 5.0. running mean: 7.553369062990711\n",
      "resetting env. episode reward total was 4.0. running mean: 7.517835372360804\n",
      "resetting env. episode reward total was 7.0. running mean: 7.512657018637197\n",
      "resetting env. episode reward total was 14.0. running mean: 7.577530448450824\n",
      "resetting env. episode reward total was 2.0. running mean: 7.521755143966316\n",
      "resetting env. episode reward total was 5.0. running mean: 7.496537592526653\n",
      "resetting env. episode reward total was 15.0. running mean: 7.571572216601386\n",
      "resetting env. episode reward total was 15.0. running mean: 7.645856494435373\n",
      "resetting env. episode reward total was 4.0. running mean: 7.609397929491019\n",
      "resetting env. episode reward total was 11.0. running mean: 7.643303950196109\n",
      "resetting env. episode reward total was 11.0. running mean: 7.676870910694148\n",
      "resetting env. episode reward total was 4.0. running mean: 7.640102201587206\n",
      "resetting env. episode reward total was 9.0. running mean: 7.653701179571334\n",
      "resetting env. episode reward total was 6.0. running mean: 7.6371641677756195\n",
      "resetting env. episode reward total was 4.0. running mean: 7.600792526097863\n",
      "resetting env. episode reward total was 10.0. running mean: 7.624784600836884\n",
      "resetting env. episode reward total was 11.0. running mean: 7.658536754828516\n",
      "resetting env. episode reward total was 5.0. running mean: 7.631951387280231\n",
      "resetting env. episode reward total was 11.0. running mean: 7.6656318734074285\n",
      "resetting env. episode reward total was 6.0. running mean: 7.6489755546733535\n",
      "resetting env. episode reward total was 4.0. running mean: 7.61248579912662\n",
      "resetting env. episode reward total was 4.0. running mean: 7.576360941135354\n",
      "resetting env. episode reward total was 8.0. running mean: 7.580597331724\n",
      "resetting env. episode reward total was 7.0. running mean: 7.5747913584067605\n",
      "resetting env. episode reward total was 10.0. running mean: 7.5990434448226925\n",
      "resetting env. episode reward total was 16.0. running mean: 7.683053010374466\n",
      "resetting env. episode reward total was 7.0. running mean: 7.676222480270721\n",
      "resetting env. episode reward total was 7.0. running mean: 7.669460255468014\n",
      "resetting env. episode reward total was 9.0. running mean: 7.682765652913333\n",
      "resetting env. episode reward total was 6.0. running mean: 7.6659379963842\n",
      "resetting env. episode reward total was 2.0. running mean: 7.609278616420357\n",
      "resetting env. episode reward total was 11.0. running mean: 7.6431858302561535\n",
      "resetting env. episode reward total was 5.0. running mean: 7.6167539719535915\n",
      "resetting env. episode reward total was 7.0. running mean: 7.610586432234056\n",
      "resetting env. episode reward total was 11.0. running mean: 7.644480567911716\n",
      "resetting env. episode reward total was 8.0. running mean: 7.648035762232598\n",
      "resetting env. episode reward total was 7.0. running mean: 7.641555404610273\n",
      "resetting env. episode reward total was -6.0. running mean: 7.50513985056417\n",
      "resetting env. episode reward total was 9.0. running mean: 7.520088452058528\n",
      "resetting env. episode reward total was 10.0. running mean: 7.544887567537942\n",
      "resetting env. episode reward total was 4.0. running mean: 7.509438691862563\n",
      "resetting env. episode reward total was 2.0. running mean: 7.454344304943937\n",
      "resetting env. episode reward total was 13.0. running mean: 7.509800861894497\n",
      "resetting env. episode reward total was 9.0. running mean: 7.524702853275552\n",
      "resetting env. episode reward total was -7.0. running mean: 7.379455824742796\n",
      "resetting env. episode reward total was 13.0. running mean: 7.435661266495368\n",
      "resetting env. episode reward total was 8.0. running mean: 7.441304653830414\n",
      "resetting env. episode reward total was 6.0. running mean: 7.426891607292109\n",
      "resetting env. episode reward total was 4.0. running mean: 7.392622691219188\n",
      "resetting env. episode reward total was 14.0. running mean: 7.458696464306995\n",
      "resetting env. episode reward total was -3.0. running mean: 7.354109499663925\n",
      "resetting env. episode reward total was 5.0. running mean: 7.330568404667285\n",
      "resetting env. episode reward total was 5.0. running mean: 7.307262720620612\n",
      "resetting env. episode reward total was 2.0. running mean: 7.2541900934144055\n",
      "resetting env. episode reward total was 8.0. running mean: 7.261648192480261\n",
      "resetting env. episode reward total was 13.0. running mean: 7.319031710555459\n",
      "resetting env. episode reward total was 7.0. running mean: 7.3158413934499045\n",
      "resetting env. episode reward total was 11.0. running mean: 7.352682979515405\n",
      "resetting env. episode reward total was 14.0. running mean: 7.419156149720251\n",
      "resetting env. episode reward total was -2.0. running mean: 7.324964588223049\n",
      "resetting env. episode reward total was 6.0. running mean: 7.311714942340818\n",
      "resetting env. episode reward total was 12.0. running mean: 7.35859779291741\n",
      "resetting env. episode reward total was 4.0. running mean: 7.325011814988235\n",
      "resetting env. episode reward total was -1.0. running mean: 7.241761696838353\n",
      "resetting env. episode reward total was 14.0. running mean: 7.309344079869969\n",
      "resetting env. episode reward total was 3.0. running mean: 7.266250639071269\n",
      "resetting env. episode reward total was 7.0. running mean: 7.263588132680557\n",
      "resetting env. episode reward total was 15.0. running mean: 7.340952251353752\n",
      "resetting env. episode reward total was 15.0. running mean: 7.417542728840215\n",
      "resetting env. episode reward total was 12.0. running mean: 7.463367301551813\n",
      "resetting env. episode reward total was 3.0. running mean: 7.418733628536295\n",
      "resetting env. episode reward total was 6.0. running mean: 7.404546292250931\n",
      "resetting env. episode reward total was 1.0. running mean: 7.3405008293284215\n",
      "resetting env. episode reward total was 8.0. running mean: 7.347095821035137\n",
      "resetting env. episode reward total was 9.0. running mean: 7.363624862824786\n",
      "resetting env. episode reward total was 13.0. running mean: 7.419988614196537\n",
      "resetting env. episode reward total was 12.0. running mean: 7.465788728054572\n",
      "resetting env. episode reward total was 6.0. running mean: 7.4511308407740255\n",
      "resetting env. episode reward total was 9.0. running mean: 7.466619532366285\n",
      "resetting env. episode reward total was 4.0. running mean: 7.431953337042622\n",
      "resetting env. episode reward total was 13.0. running mean: 7.487633803672196\n",
      "resetting env. episode reward total was 7.0. running mean: 7.4827574656354745\n",
      "resetting env. episode reward total was 10.0. running mean: 7.50792989097912\n",
      "resetting env. episode reward total was 11.0. running mean: 7.542850592069328\n",
      "resetting env. episode reward total was 2.0. running mean: 7.4874220861486345\n",
      "resetting env. episode reward total was 1.0. running mean: 7.4225478652871475\n",
      "resetting env. episode reward total was 7.0. running mean: 7.4183223866342765\n",
      "resetting env. episode reward total was 10.0. running mean: 7.444139162767933\n",
      "resetting env. episode reward total was 8.0. running mean: 7.449697771140253\n",
      "resetting env. episode reward total was -1.0. running mean: 7.365200793428851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 7.381548785494562\n",
      "resetting env. episode reward total was 14.0. running mean: 7.4477332976396164\n",
      "resetting env. episode reward total was 8.0. running mean: 7.45325596466322\n",
      "resetting env. episode reward total was 10.0. running mean: 7.478723405016587\n",
      "resetting env. episode reward total was 9.0. running mean: 7.493936170966421\n",
      "resetting env. episode reward total was 6.0. running mean: 7.478996809256756\n",
      "resetting env. episode reward total was 2.0. running mean: 7.424206841164188\n",
      "resetting env. episode reward total was 5.0. running mean: 7.399964772752546\n",
      "resetting env. episode reward total was -3.0. running mean: 7.29596512502502\n",
      "resetting env. episode reward total was 7.0. running mean: 7.2930054737747705\n",
      "resetting env. episode reward total was 11.0. running mean: 7.330075419037023\n",
      "resetting env. episode reward total was 6.0. running mean: 7.316774664846652\n",
      "resetting env. episode reward total was 4.0. running mean: 7.283606918198186\n",
      "resetting env. episode reward total was 10.0. running mean: 7.310770849016204\n",
      "resetting env. episode reward total was 10.0. running mean: 7.3376631405260415\n",
      "resetting env. episode reward total was 5.0. running mean: 7.314286509120781\n",
      "resetting env. episode reward total was 4.0. running mean: 7.281143644029573\n",
      "resetting env. episode reward total was 3.0. running mean: 7.238332207589277\n",
      "resetting env. episode reward total was 1.0. running mean: 7.175948885513384\n",
      "resetting env. episode reward total was 13.0. running mean: 7.23418939665825\n",
      "resetting env. episode reward total was 14.0. running mean: 7.301847502691667\n",
      "resetting env. episode reward total was 12.0. running mean: 7.348829027664751\n",
      "resetting env. episode reward total was 4.0. running mean: 7.315340737388103\n",
      "resetting env. episode reward total was 11.0. running mean: 7.352187330014223\n",
      "resetting env. episode reward total was 9.0. running mean: 7.368665456714081\n",
      "resetting env. episode reward total was -7.0. running mean: 7.224978802146939\n",
      "resetting env. episode reward total was 4.0. running mean: 7.19272901412547\n",
      "resetting env. episode reward total was 6.0. running mean: 7.180801723984215\n",
      "resetting env. episode reward total was 12.0. running mean: 7.228993706744372\n",
      "resetting env. episode reward total was 4.0. running mean: 7.196703769676929\n",
      "resetting env. episode reward total was 13.0. running mean: 7.2547367319801594\n",
      "resetting env. episode reward total was 9.0. running mean: 7.272189364660358\n",
      "resetting env. episode reward total was 12.0. running mean: 7.319467471013755\n",
      "resetting env. episode reward total was 9.0. running mean: 7.336272796303617\n",
      "resetting env. episode reward total was 7.0. running mean: 7.332910068340581\n",
      "resetting env. episode reward total was -4.0. running mean: 7.219580967657175\n",
      "resetting env. episode reward total was 9.0. running mean: 7.2373851579806034\n",
      "resetting env. episode reward total was 10.0. running mean: 7.265011306400797\n",
      "resetting env. episode reward total was 19.0. running mean: 7.382361193336789\n",
      "resetting env. episode reward total was 4.0. running mean: 7.348537581403421\n",
      "resetting env. episode reward total was 3.0. running mean: 7.305052205589387\n",
      "resetting env. episode reward total was 11.0. running mean: 7.342001683533494\n",
      "resetting env. episode reward total was 7.0. running mean: 7.3385816666981585\n",
      "resetting env. episode reward total was 11.0. running mean: 7.375195850031177\n",
      "resetting env. episode reward total was 8.0. running mean: 7.381443891530865\n",
      "resetting env. episode reward total was 13.0. running mean: 7.437629452615556\n",
      "resetting env. episode reward total was 9.0. running mean: 7.4532531580894\n",
      "resetting env. episode reward total was 11.0. running mean: 7.488720626508506\n",
      "resetting env. episode reward total was 6.0. running mean: 7.4738334202434205\n",
      "resetting env. episode reward total was -1.0. running mean: 7.389095086040986\n",
      "resetting env. episode reward total was 1.0. running mean: 7.325204135180576\n",
      "resetting env. episode reward total was 4.0. running mean: 7.291952093828771\n",
      "resetting env. episode reward total was 9.0. running mean: 7.309032572890483\n",
      "resetting env. episode reward total was 5.0. running mean: 7.285942247161578\n",
      "resetting env. episode reward total was 4.0. running mean: 7.253082824689962\n",
      "resetting env. episode reward total was 16.0. running mean: 7.340551996443062\n",
      "resetting env. episode reward total was 4.0. running mean: 7.307146476478631\n",
      "resetting env. episode reward total was 10.0. running mean: 7.3340750117138445\n",
      "resetting env. episode reward total was 4.0. running mean: 7.300734261596706\n",
      "resetting env. episode reward total was 14.0. running mean: 7.367726918980739\n",
      "resetting env. episode reward total was 6.0. running mean: 7.354049649790931\n",
      "resetting env. episode reward total was -3.0. running mean: 7.250509153293022\n",
      "resetting env. episode reward total was 4.0. running mean: 7.218004061760092\n",
      "resetting env. episode reward total was 1.0. running mean: 7.15582402114249\n",
      "resetting env. episode reward total was -6.0. running mean: 7.024265780931066\n",
      "resetting env. episode reward total was 10.0. running mean: 7.054023123121755\n",
      "resetting env. episode reward total was 14.0. running mean: 7.1234828918905375\n",
      "resetting env. episode reward total was 11.0. running mean: 7.162248062971632\n",
      "resetting env. episode reward total was 11.0. running mean: 7.2006255823419165\n",
      "resetting env. episode reward total was 14.0. running mean: 7.268619326518497\n",
      "resetting env. episode reward total was 3.0. running mean: 7.225933133253312\n",
      "resetting env. episode reward total was 6.0. running mean: 7.213673801920779\n",
      "resetting env. episode reward total was 3.0. running mean: 7.171537063901571\n",
      "resetting env. episode reward total was 7.0. running mean: 7.169821693262556\n",
      "resetting env. episode reward total was 6.0. running mean: 7.15812347632993\n",
      "resetting env. episode reward total was 4.0. running mean: 7.12654224156663\n",
      "resetting env. episode reward total was 10.0. running mean: 7.155276819150964\n",
      "resetting env. episode reward total was 4.0. running mean: 7.123724050959454\n",
      "resetting env. episode reward total was 11.0. running mean: 7.16248681044986\n",
      "resetting env. episode reward total was 11.0. running mean: 7.2008619423453615\n",
      "resetting env. episode reward total was 8.0. running mean: 7.208853322921908\n",
      "resetting env. episode reward total was 11.0. running mean: 7.24676478969269\n",
      "resetting env. episode reward total was 9.0. running mean: 7.264297141795763\n",
      "resetting env. episode reward total was -3.0. running mean: 7.161654170377805\n",
      "resetting env. episode reward total was 14.0. running mean: 7.230037628674026\n",
      "resetting env. episode reward total was 14.0. running mean: 7.297737252387285\n",
      "resetting env. episode reward total was 14.0. running mean: 7.364759879863412\n",
      "resetting env. episode reward total was 8.0. running mean: 7.371112281064778\n",
      "resetting env. episode reward total was 15.0. running mean: 7.44740115825413\n",
      "resetting env. episode reward total was 9.0. running mean: 7.462927146671588\n",
      "resetting env. episode reward total was 4.0. running mean: 7.428297875204873\n",
      "resetting env. episode reward total was 12.0. running mean: 7.474014896452824\n",
      "resetting env. episode reward total was 9.0. running mean: 7.489274747488296\n",
      "resetting env. episode reward total was 11.0. running mean: 7.524382000013413\n",
      "resetting env. episode reward total was -2.0. running mean: 7.42913818001328\n",
      "resetting env. episode reward total was 8.0. running mean: 7.434846798213147\n",
      "resetting env. episode reward total was 5.0. running mean: 7.4104983302310155\n",
      "resetting env. episode reward total was 7.0. running mean: 7.406393346928706\n",
      "resetting env. episode reward total was 9.0. running mean: 7.422329413459418\n",
      "resetting env. episode reward total was -3.0. running mean: 7.318106119324824\n",
      "resetting env. episode reward total was 9.0. running mean: 7.334925058131575\n",
      "resetting env. episode reward total was 15.0. running mean: 7.41157580755026\n",
      "resetting env. episode reward total was 16.0. running mean: 7.497460049474757\n",
      "resetting env. episode reward total was -1.0. running mean: 7.41248544898001\n",
      "resetting env. episode reward total was 6.0. running mean: 7.398360594490209\n",
      "resetting env. episode reward total was 4.0. running mean: 7.364376988545307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -9.0. running mean: 7.200733218659854\n",
      "resetting env. episode reward total was 14.0. running mean: 7.268725886473256\n",
      "resetting env. episode reward total was 8.0. running mean: 7.276038627608523\n",
      "resetting env. episode reward total was 11.0. running mean: 7.313278241332438\n",
      "resetting env. episode reward total was 11.0. running mean: 7.350145458919114\n",
      "resetting env. episode reward total was 4.0. running mean: 7.316644004329922\n",
      "resetting env. episode reward total was 8.0. running mean: 7.323477564286623\n",
      "resetting env. episode reward total was 8.0. running mean: 7.330242788643757\n",
      "resetting env. episode reward total was 9.0. running mean: 7.346940360757319\n",
      "resetting env. episode reward total was 4.0. running mean: 7.313470957149746\n",
      "resetting env. episode reward total was 6.0. running mean: 7.300336247578248\n",
      "resetting env. episode reward total was 2.0. running mean: 7.247332885102465\n",
      "resetting env. episode reward total was 1.0. running mean: 7.18485955625144\n",
      "resetting env. episode reward total was 9.0. running mean: 7.203010960688926\n",
      "resetting env. episode reward total was 1.0. running mean: 7.140980851082036\n",
      "resetting env. episode reward total was 2.0. running mean: 7.089571042571215\n",
      "resetting env. episode reward total was 10.0. running mean: 7.118675332145503\n",
      "resetting env. episode reward total was -2.0. running mean: 7.027488578824048\n",
      "resetting env. episode reward total was 6.0. running mean: 7.017213693035807\n",
      "resetting env. episode reward total was 9.0. running mean: 7.037041556105449\n",
      "resetting env. episode reward total was 11.0. running mean: 7.076671140544395\n",
      "resetting env. episode reward total was 12.0. running mean: 7.125904429138951\n",
      "resetting env. episode reward total was 13.0. running mean: 7.1846453848475615\n",
      "resetting env. episode reward total was 8.0. running mean: 7.192798930999086\n",
      "resetting env. episode reward total was 11.0. running mean: 7.230870941689095\n",
      "resetting env. episode reward total was 7.0. running mean: 7.228562232272204\n",
      "resetting env. episode reward total was 8.0. running mean: 7.236276609949482\n",
      "resetting env. episode reward total was 3.0. running mean: 7.193913843849987\n",
      "resetting env. episode reward total was 4.0. running mean: 7.161974705411487\n",
      "resetting env. episode reward total was 13.0. running mean: 7.2203549583573725\n",
      "resetting env. episode reward total was 8.0. running mean: 7.228151408773798\n",
      "resetting env. episode reward total was 6.0. running mean: 7.21586989468606\n",
      "resetting env. episode reward total was 10.0. running mean: 7.243711195739199\n",
      "resetting env. episode reward total was 13.0. running mean: 7.3012740837818075\n",
      "resetting env. episode reward total was 3.0. running mean: 7.25826134294399\n",
      "resetting env. episode reward total was 3.0. running mean: 7.21567872951455\n",
      "resetting env. episode reward total was 8.0. running mean: 7.223521942219405\n",
      "resetting env. episode reward total was 17.0. running mean: 7.32128672279721\n",
      "resetting env. episode reward total was 7.0. running mean: 7.318073855569239\n",
      "resetting env. episode reward total was 11.0. running mean: 7.354893117013546\n",
      "resetting env. episode reward total was 7.0. running mean: 7.351344185843411\n",
      "resetting env. episode reward total was 17.0. running mean: 7.4478307439849765\n",
      "resetting env. episode reward total was 8.0. running mean: 7.453352436545127\n",
      "resetting env. episode reward total was 11.0. running mean: 7.488818912179676\n",
      "resetting env. episode reward total was 6.0. running mean: 7.473930723057879\n",
      "resetting env. episode reward total was 9.0. running mean: 7.4891914158273\n",
      "resetting env. episode reward total was 9.0. running mean: 7.504299501669027\n",
      "resetting env. episode reward total was 9.0. running mean: 7.5192565066523365\n",
      "resetting env. episode reward total was -7.0. running mean: 7.3740639415858125\n",
      "resetting env. episode reward total was 7.0. running mean: 7.370323302169955\n",
      "resetting env. episode reward total was 3.0. running mean: 7.326620069148255\n",
      "resetting env. episode reward total was 10.0. running mean: 7.3533538684567725\n",
      "resetting env. episode reward total was 7.0. running mean: 7.349820329772205\n",
      "resetting env. episode reward total was 4.0. running mean: 7.316322126474483\n",
      "resetting env. episode reward total was 5.0. running mean: 7.293158905209737\n",
      "resetting env. episode reward total was 9.0. running mean: 7.31022731615764\n",
      "resetting env. episode reward total was 1.0. running mean: 7.247125042996063\n",
      "resetting env. episode reward total was -1.0. running mean: 7.164653792566103\n",
      "resetting env. episode reward total was 12.0. running mean: 7.213007254640442\n",
      "resetting env. episode reward total was 1.0. running mean: 7.150877182094037\n",
      "resetting env. episode reward total was 12.0. running mean: 7.199368410273097\n",
      "resetting env. episode reward total was 13.0. running mean: 7.257374726170366\n",
      "resetting env. episode reward total was 12.0. running mean: 7.304800978908663\n",
      "resetting env. episode reward total was 1.0. running mean: 7.241752969119576\n",
      "resetting env. episode reward total was 12.0. running mean: 7.28933543942838\n",
      "resetting env. episode reward total was 1.0. running mean: 7.226442085034096\n",
      "resetting env. episode reward total was 8.0. running mean: 7.234177664183755\n",
      "resetting env. episode reward total was 12.0. running mean: 7.281835887541917\n",
      "resetting env. episode reward total was 15.0. running mean: 7.359017528666499\n",
      "resetting env. episode reward total was 10.0. running mean: 7.385427353379833\n",
      "resetting env. episode reward total was 3.0. running mean: 7.341573079846035\n",
      "resetting env. episode reward total was 1.0. running mean: 7.278157349047574\n",
      "resetting env. episode reward total was 5.0. running mean: 7.2553757755570985\n",
      "resetting env. episode reward total was 10.0. running mean: 7.282822017801527\n",
      "resetting env. episode reward total was 14.0. running mean: 7.349993797623511\n",
      "resetting env. episode reward total was 4.0. running mean: 7.3164938596472755\n",
      "resetting env. episode reward total was 9.0. running mean: 7.333328921050803\n",
      "resetting env. episode reward total was 1.0. running mean: 7.2699956318402945\n",
      "resetting env. episode reward total was 11.0. running mean: 7.307295675521892\n",
      "resetting env. episode reward total was 14.0. running mean: 7.3742227187666725\n",
      "resetting env. episode reward total was 13.0. running mean: 7.430480491579005\n",
      "resetting env. episode reward total was 9.0. running mean: 7.446175686663215\n",
      "resetting env. episode reward total was 15.0. running mean: 7.521713929796584\n",
      "resetting env. episode reward total was 19.0. running mean: 7.636496790498619\n",
      "resetting env. episode reward total was 6.0. running mean: 7.620131822593632\n",
      "resetting env. episode reward total was 7.0. running mean: 7.613930504367696\n",
      "resetting env. episode reward total was 5.0. running mean: 7.587791199324019\n",
      "resetting env. episode reward total was 4.0. running mean: 7.551913287330779\n",
      "resetting env. episode reward total was -10.0. running mean: 7.376394154457471\n",
      "resetting env. episode reward total was 5.0. running mean: 7.352630212912896\n",
      "resetting env. episode reward total was 5.0. running mean: 7.3291039107837666\n",
      "resetting env. episode reward total was 11.0. running mean: 7.365812871675929\n",
      "resetting env. episode reward total was 10.0. running mean: 7.392154742959169\n",
      "resetting env. episode reward total was 4.0. running mean: 7.358233195529578\n",
      "resetting env. episode reward total was 8.0. running mean: 7.364650863574282\n",
      "resetting env. episode reward total was 9.0. running mean: 7.381004354938539\n",
      "resetting env. episode reward total was -7.0. running mean: 7.237194311389153\n",
      "resetting env. episode reward total was 10.0. running mean: 7.2648223682752615\n",
      "resetting env. episode reward total was 16.0. running mean: 7.352174144592509\n",
      "resetting env. episode reward total was 7.0. running mean: 7.348652403146584\n",
      "resetting env. episode reward total was 10.0. running mean: 7.375165879115118\n",
      "resetting env. episode reward total was 2.0. running mean: 7.321414220323966\n",
      "resetting env. episode reward total was 3.0. running mean: 7.278200078120727\n",
      "resetting env. episode reward total was 10.0. running mean: 7.305418077339519\n",
      "resetting env. episode reward total was 6.0. running mean: 7.2923638965661235\n",
      "resetting env. episode reward total was 9.0. running mean: 7.309440257600462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 7.326345855024457\n",
      "resetting env. episode reward total was 13.0. running mean: 7.3830823964742125\n",
      "resetting env. episode reward total was 6.0. running mean: 7.36925157250947\n",
      "resetting env. episode reward total was 9.0. running mean: 7.385559056784375\n",
      "resetting env. episode reward total was 12.0. running mean: 7.431703466216532\n",
      "resetting env. episode reward total was 14.0. running mean: 7.497386431554366\n",
      "resetting env. episode reward total was 15.0. running mean: 7.572412567238823\n",
      "resetting env. episode reward total was 4.0. running mean: 7.536688441566435\n",
      "resetting env. episode reward total was 1.0. running mean: 7.4713215571507705\n",
      "resetting env. episode reward total was 3.0. running mean: 7.426608341579263\n",
      "resetting env. episode reward total was 15.0. running mean: 7.502342258163471\n",
      "resetting env. episode reward total was 13.0. running mean: 7.557318835581836\n",
      "resetting env. episode reward total was 8.0. running mean: 7.561745647226018\n",
      "resetting env. episode reward total was 10.0. running mean: 7.586128190753757\n",
      "resetting env. episode reward total was -4.0. running mean: 7.470266908846219\n",
      "resetting env. episode reward total was 20.0. running mean: 7.595564239757757\n",
      "resetting env. episode reward total was 7.0. running mean: 7.58960859736018\n",
      "resetting env. episode reward total was 4.0. running mean: 7.553712511386578\n",
      "resetting env. episode reward total was 14.0. running mean: 7.618175386272712\n",
      "resetting env. episode reward total was 10.0. running mean: 7.641993632409985\n",
      "resetting env. episode reward total was 4.0. running mean: 7.6055736960858855\n",
      "resetting env. episode reward total was 6.0. running mean: 7.589517959125026\n",
      "resetting env. episode reward total was 6.0. running mean: 7.573622779533776\n",
      "resetting env. episode reward total was -5.0. running mean: 7.447886551738438\n",
      "resetting env. episode reward total was 4.0. running mean: 7.413407686221054\n",
      "resetting env. episode reward total was 13.0. running mean: 7.469273609358843\n",
      "resetting env. episode reward total was 4.0. running mean: 7.434580873265254\n",
      "resetting env. episode reward total was 10.0. running mean: 7.460235064532601\n",
      "resetting env. episode reward total was 10.0. running mean: 7.485632713887275\n",
      "resetting env. episode reward total was 4.0. running mean: 7.4507763867484025\n",
      "resetting env. episode reward total was 8.0. running mean: 7.456268622880918\n",
      "resetting env. episode reward total was 2.0. running mean: 7.4017059366521085\n",
      "resetting env. episode reward total was 7.0. running mean: 7.397688877285588\n",
      "resetting env. episode reward total was -1.0. running mean: 7.313711988512732\n",
      "resetting env. episode reward total was 7.0. running mean: 7.310574868627604\n",
      "resetting env. episode reward total was 5.0. running mean: 7.287469119941328\n",
      "resetting env. episode reward total was 7.0. running mean: 7.284594428741915\n",
      "resetting env. episode reward total was 5.0. running mean: 7.261748484454496\n",
      "resetting env. episode reward total was 3.0. running mean: 7.219130999609951\n",
      "resetting env. episode reward total was 10.0. running mean: 7.246939689613851\n",
      "resetting env. episode reward total was 8.0. running mean: 7.254470292717712\n",
      "resetting env. episode reward total was 9.0. running mean: 7.271925589790534\n",
      "resetting env. episode reward total was 9.0. running mean: 7.289206333892628\n",
      "resetting env. episode reward total was 9.0. running mean: 7.306314270553702\n",
      "resetting env. episode reward total was 2.0. running mean: 7.253251127848164\n",
      "resetting env. episode reward total was 7.0. running mean: 7.250718616569682\n",
      "resetting env. episode reward total was 8.0. running mean: 7.2582114304039855\n",
      "resetting env. episode reward total was 9.0. running mean: 7.275629316099946\n",
      "resetting env. episode reward total was 7.0. running mean: 7.272873022938946\n",
      "resetting env. episode reward total was 8.0. running mean: 7.280144292709557\n",
      "resetting env. episode reward total was 5.0. running mean: 7.257342849782461\n",
      "resetting env. episode reward total was 8.0. running mean: 7.264769421284636\n",
      "resetting env. episode reward total was 9.0. running mean: 7.2821217270717895\n",
      "resetting env. episode reward total was 8.0. running mean: 7.2893005098010715\n",
      "resetting env. episode reward total was 7.0. running mean: 7.286407504703061\n",
      "resetting env. episode reward total was 11.0. running mean: 7.323543429656031\n",
      "resetting env. episode reward total was 8.0. running mean: 7.330307995359471\n",
      "resetting env. episode reward total was 11.0. running mean: 7.367004915405876\n",
      "resetting env. episode reward total was 11.0. running mean: 7.403334866251818\n",
      "resetting env. episode reward total was 9.0. running mean: 7.419301517589299\n",
      "resetting env. episode reward total was 7.0. running mean: 7.415108502413407\n",
      "resetting env. episode reward total was 1.0. running mean: 7.350957417389273\n",
      "resetting env. episode reward total was 7.0. running mean: 7.34744784321538\n",
      "resetting env. episode reward total was 5.0. running mean: 7.323973364783226\n",
      "resetting env. episode reward total was 9.0. running mean: 7.340733631135394\n",
      "resetting env. episode reward total was 6.0. running mean: 7.327326294824039\n",
      "resetting env. episode reward total was 1.0. running mean: 7.2640530318757985\n",
      "resetting env. episode reward total was 6.0. running mean: 7.2514125015570405\n",
      "resetting env. episode reward total was 12.0. running mean: 7.29889837654147\n",
      "resetting env. episode reward total was 9.0. running mean: 7.315909392776056\n",
      "resetting env. episode reward total was 7.0. running mean: 7.312750298848296\n",
      "resetting env. episode reward total was 10.0. running mean: 7.339622795859812\n",
      "resetting env. episode reward total was 6.0. running mean: 7.326226567901213\n",
      "resetting env. episode reward total was -3.0. running mean: 7.222964302222201\n",
      "resetting env. episode reward total was 5.0. running mean: 7.200734659199979\n",
      "resetting env. episode reward total was 5.0. running mean: 7.178727312607979\n",
      "resetting env. episode reward total was 10.0. running mean: 7.206940039481899\n",
      "resetting env. episode reward total was 15.0. running mean: 7.28487063908708\n",
      "resetting env. episode reward total was 5.0. running mean: 7.262021932696209\n",
      "resetting env. episode reward total was 16.0. running mean: 7.349401713369247\n",
      "resetting env. episode reward total was 4.0. running mean: 7.315907696235554\n",
      "resetting env. episode reward total was 12.0. running mean: 7.362748619273198\n",
      "resetting env. episode reward total was 3.0. running mean: 7.319121133080466\n",
      "resetting env. episode reward total was 14.0. running mean: 7.385929921749661\n",
      "resetting env. episode reward total was 14.0. running mean: 7.452070622532164\n",
      "resetting env. episode reward total was 3.0. running mean: 7.407549916306842\n",
      "resetting env. episode reward total was 1.0. running mean: 7.343474417143773\n",
      "resetting env. episode reward total was 6.0. running mean: 7.330039672972335\n",
      "resetting env. episode reward total was 10.0. running mean: 7.356739276242611\n",
      "resetting env. episode reward total was 12.0. running mean: 7.403171883480185\n",
      "resetting env. episode reward total was 9.0. running mean: 7.419140164645383\n",
      "resetting env. episode reward total was 2.0. running mean: 7.364948762998929\n",
      "resetting env. episode reward total was -2.0. running mean: 7.27129927536894\n",
      "resetting env. episode reward total was 7.0. running mean: 7.268586282615251\n",
      "resetting env. episode reward total was -6.0. running mean: 7.135900419789099\n",
      "resetting env. episode reward total was 6.0. running mean: 7.1245414155912075\n",
      "resetting env. episode reward total was 8.0. running mean: 7.133296001435295\n",
      "resetting env. episode reward total was 7.0. running mean: 7.131963041420942\n",
      "resetting env. episode reward total was 8.0. running mean: 7.1406434110067325\n",
      "resetting env. episode reward total was 13.0. running mean: 7.199236976896665\n",
      "resetting env. episode reward total was 7.0. running mean: 7.197244607127699\n",
      "resetting env. episode reward total was 3.0. running mean: 7.155272161056422\n",
      "resetting env. episode reward total was 14.0. running mean: 7.223719439445857\n",
      "resetting env. episode reward total was 4.0. running mean: 7.191482245051398\n",
      "resetting env. episode reward total was 9.0. running mean: 7.209567422600884\n",
      "resetting env. episode reward total was 8.0. running mean: 7.217471748374875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 7.275297030891126\n",
      "resetting env. episode reward total was 2.0. running mean: 7.222544060582215\n",
      "resetting env. episode reward total was 1.0. running mean: 7.160318619976392\n",
      "resetting env. episode reward total was 5.0. running mean: 7.138715433776628\n",
      "resetting env. episode reward total was 5.0. running mean: 7.117328279438862\n",
      "resetting env. episode reward total was 1.0. running mean: 7.056154996644473\n",
      "resetting env. episode reward total was 9.0. running mean: 7.075593446678028\n",
      "resetting env. episode reward total was 10.0. running mean: 7.1048375122112475\n",
      "resetting env. episode reward total was 5.0. running mean: 7.083789137089135\n",
      "resetting env. episode reward total was 6.0. running mean: 7.072951245718243\n",
      "resetting env. episode reward total was 10.0. running mean: 7.10222173326106\n",
      "resetting env. episode reward total was 8.0. running mean: 7.111199515928449\n",
      "resetting env. episode reward total was -7.0. running mean: 6.970087520769164\n",
      "resetting env. episode reward total was 9.0. running mean: 6.990386645561473\n",
      "resetting env. episode reward total was 12.0. running mean: 7.040482779105858\n",
      "resetting env. episode reward total was 9.0. running mean: 7.060077951314799\n",
      "resetting env. episode reward total was 15.0. running mean: 7.139477171801651\n",
      "resetting env. episode reward total was 10.0. running mean: 7.168082400083635\n",
      "resetting env. episode reward total was 14.0. running mean: 7.236401576082798\n",
      "resetting env. episode reward total was 12.0. running mean: 7.284037560321971\n",
      "resetting env. episode reward total was 8.0. running mean: 7.291197184718751\n",
      "resetting env. episode reward total was 1.0. running mean: 7.228285212871563\n",
      "resetting env. episode reward total was 10.0. running mean: 7.256002360742847\n",
      "resetting env. episode reward total was 9.0. running mean: 7.273442337135418\n",
      "resetting env. episode reward total was 12.0. running mean: 7.320707913764064\n",
      "resetting env. episode reward total was 15.0. running mean: 7.397500834626424\n",
      "resetting env. episode reward total was 6.0. running mean: 7.3835258262801595\n",
      "resetting env. episode reward total was 16.0. running mean: 7.469690568017358\n",
      "resetting env. episode reward total was 16.0. running mean: 7.554993662337185\n",
      "resetting env. episode reward total was 13.0. running mean: 7.609443725713812\n",
      "resetting env. episode reward total was 10.0. running mean: 7.633349288456674\n",
      "resetting env. episode reward total was 9.0. running mean: 7.6470157955721065\n",
      "resetting env. episode reward total was 8.0. running mean: 7.650545637616386\n",
      "resetting env. episode reward total was 13.0. running mean: 7.704040181240222\n",
      "resetting env. episode reward total was 6.0. running mean: 7.686999779427819\n",
      "resetting env. episode reward total was 9.0. running mean: 7.700129781633541\n",
      "resetting env. episode reward total was 3.0. running mean: 7.653128483817206\n",
      "resetting env. episode reward total was 6.0. running mean: 7.636597198979033\n",
      "resetting env. episode reward total was 5.0. running mean: 7.610231226989243\n",
      "resetting env. episode reward total was 8.0. running mean: 7.614128914719351\n",
      "resetting env. episode reward total was 3.0. running mean: 7.567987625572157\n",
      "resetting env. episode reward total was 2.0. running mean: 7.512307749316435\n",
      "resetting env. episode reward total was 2.0. running mean: 7.457184671823271\n",
      "resetting env. episode reward total was 2.0. running mean: 7.402612825105037\n",
      "resetting env. episode reward total was -4.0. running mean: 7.2885866968539865\n",
      "resetting env. episode reward total was 12.0. running mean: 7.335700829885447\n",
      "resetting env. episode reward total was 1.0. running mean: 7.272343821586592\n",
      "resetting env. episode reward total was 8.0. running mean: 7.279620383370726\n",
      "resetting env. episode reward total was 9.0. running mean: 7.296824179537018\n",
      "resetting env. episode reward total was 10.0. running mean: 7.323855937741648\n",
      "resetting env. episode reward total was 9.0. running mean: 7.3406173783642314\n",
      "resetting env. episode reward total was 12.0. running mean: 7.3872112045805896\n",
      "resetting env. episode reward total was 4.0. running mean: 7.3533390925347835\n",
      "resetting env. episode reward total was 6.0. running mean: 7.339805701609436\n",
      "resetting env. episode reward total was 4.0. running mean: 7.3064076445933415\n",
      "resetting env. episode reward total was 6.0. running mean: 7.2933435681474075\n",
      "resetting env. episode reward total was 2.0. running mean: 7.240410132465933\n",
      "resetting env. episode reward total was 12.0. running mean: 7.288006031141274\n",
      "resetting env. episode reward total was 4.0. running mean: 7.255125970829861\n",
      "resetting env. episode reward total was 1.0. running mean: 7.192574711121562\n",
      "resetting env. episode reward total was 16.0. running mean: 7.2806489640103464\n",
      "resetting env. episode reward total was 4.0. running mean: 7.247842474370243\n",
      "resetting env. episode reward total was 13.0. running mean: 7.30536404962654\n",
      "resetting env. episode reward total was 12.0. running mean: 7.352310409130275\n",
      "resetting env. episode reward total was 9.0. running mean: 7.368787305038972\n",
      "resetting env. episode reward total was 11.0. running mean: 7.405099431988583\n",
      "resetting env. episode reward total was 5.0. running mean: 7.381048437668697\n",
      "resetting env. episode reward total was 1.0. running mean: 7.317237953292009\n",
      "resetting env. episode reward total was 10.0. running mean: 7.344065573759089\n",
      "resetting env. episode reward total was 7.0. running mean: 7.340624918021498\n",
      "resetting env. episode reward total was 9.0. running mean: 7.357218668841282\n",
      "resetting env. episode reward total was 4.0. running mean: 7.32364648215287\n",
      "resetting env. episode reward total was 7.0. running mean: 7.320410017331342\n",
      "resetting env. episode reward total was 7.0. running mean: 7.317205917158028\n",
      "resetting env. episode reward total was 6.0. running mean: 7.304033857986448\n",
      "resetting env. episode reward total was 11.0. running mean: 7.340993519406584\n",
      "resetting env. episode reward total was 6.0. running mean: 7.327583584212517\n",
      "resetting env. episode reward total was 8.0. running mean: 7.334307748370392\n",
      "resetting env. episode reward total was 4.0. running mean: 7.300964670886688\n",
      "resetting env. episode reward total was 3.0. running mean: 7.2579550241778215\n",
      "resetting env. episode reward total was 11.0. running mean: 7.295375473936043\n",
      "resetting env. episode reward total was 7.0. running mean: 7.292421719196683\n",
      "resetting env. episode reward total was 9.0. running mean: 7.3094975020047155\n",
      "resetting env. episode reward total was 3.0. running mean: 7.266402526984669\n",
      "resetting env. episode reward total was 14.0. running mean: 7.333738501714821\n",
      "resetting env. episode reward total was 5.0. running mean: 7.310401116697673\n",
      "resetting env. episode reward total was 12.0. running mean: 7.357297105530696\n",
      "resetting env. episode reward total was 12.0. running mean: 7.4037241344753895\n",
      "resetting env. episode reward total was 13.0. running mean: 7.459686893130636\n",
      "resetting env. episode reward total was 11.0. running mean: 7.49509002419933\n",
      "resetting env. episode reward total was 7.0. running mean: 7.490139123957337\n",
      "resetting env. episode reward total was 5.0. running mean: 7.465237732717763\n",
      "resetting env. episode reward total was 3.0. running mean: 7.420585355390585\n",
      "resetting env. episode reward total was 14.0. running mean: 7.486379501836679\n",
      "resetting env. episode reward total was 2.0. running mean: 7.4315157068183115\n",
      "resetting env. episode reward total was 12.0. running mean: 7.477200549750129\n",
      "resetting env. episode reward total was 14.0. running mean: 7.542428544252627\n",
      "resetting env. episode reward total was 6.0. running mean: 7.5270042588101\n",
      "resetting env. episode reward total was -5.0. running mean: 7.401734216222\n",
      "resetting env. episode reward total was 3.0. running mean: 7.35771687405978\n",
      "resetting env. episode reward total was 10.0. running mean: 7.384139705319182\n",
      "resetting env. episode reward total was 8.0. running mean: 7.39029830826599\n",
      "resetting env. episode reward total was -3.0. running mean: 7.28639532518333\n",
      "resetting env. episode reward total was 8.0. running mean: 7.293531371931497\n",
      "resetting env. episode reward total was 3.0. running mean: 7.2505960582121824\n",
      "resetting env. episode reward total was 12.0. running mean: 7.298090097630061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 7.33510919665376\n",
      "resetting env. episode reward total was 9.0. running mean: 7.351758104687222\n",
      "resetting env. episode reward total was 10.0. running mean: 7.378240523640349\n",
      "resetting env. episode reward total was 11.0. running mean: 7.414458118403946\n",
      "resetting env. episode reward total was 8.0. running mean: 7.420313537219907\n",
      "resetting env. episode reward total was 6.0. running mean: 7.406110401847707\n",
      "resetting env. episode reward total was 2.0. running mean: 7.35204929782923\n",
      "resetting env. episode reward total was 17.0. running mean: 7.4485288048509375\n",
      "resetting env. episode reward total was 11.0. running mean: 7.484043516802428\n",
      "resetting env. episode reward total was 8.0. running mean: 7.489203081634404\n",
      "resetting env. episode reward total was 5.0. running mean: 7.4643110508180595\n",
      "resetting env. episode reward total was -7.0. running mean: 7.319667940309879\n",
      "resetting env. episode reward total was 3.0. running mean: 7.2764712609067805\n",
      "resetting env. episode reward total was 10.0. running mean: 7.303706548297712\n",
      "resetting env. episode reward total was 15.0. running mean: 7.380669482814735\n",
      "resetting env. episode reward total was 9.0. running mean: 7.396862787986588\n",
      "resetting env. episode reward total was 15.0. running mean: 7.472894160106722\n",
      "resetting env. episode reward total was 5.0. running mean: 7.448165218505654\n",
      "resetting env. episode reward total was 7.0. running mean: 7.443683566320598\n",
      "resetting env. episode reward total was 8.0. running mean: 7.449246730657392\n",
      "resetting env. episode reward total was 4.0. running mean: 7.414754263350818\n",
      "resetting env. episode reward total was 6.0. running mean: 7.40060672071731\n",
      "resetting env. episode reward total was 11.0. running mean: 7.436600653510137\n",
      "resetting env. episode reward total was 4.0. running mean: 7.402234646975035\n",
      "resetting env. episode reward total was 5.0. running mean: 7.378212300505285\n",
      "resetting env. episode reward total was 15.0. running mean: 7.454430177500233\n",
      "resetting env. episode reward total was 7.0. running mean: 7.44988587572523\n",
      "resetting env. episode reward total was 5.0. running mean: 7.425387016967978\n",
      "resetting env. episode reward total was 8.0. running mean: 7.431133146798298\n",
      "resetting env. episode reward total was 13.0. running mean: 7.486821815330315\n",
      "resetting env. episode reward total was 6.0. running mean: 7.471953597177012\n",
      "resetting env. episode reward total was 3.0. running mean: 7.427234061205242\n",
      "resetting env. episode reward total was 8.0. running mean: 7.432961720593189\n",
      "resetting env. episode reward total was 7.0. running mean: 7.428632103387257\n",
      "resetting env. episode reward total was 6.0. running mean: 7.414345782353385\n",
      "resetting env. episode reward total was 1.0. running mean: 7.3502023245298505\n",
      "resetting env. episode reward total was 4.0. running mean: 7.316700301284552\n",
      "resetting env. episode reward total was -3.0. running mean: 7.213533298271706\n",
      "resetting env. episode reward total was 4.0. running mean: 7.181397965288989\n",
      "resetting env. episode reward total was 1.0. running mean: 7.1195839856360985\n",
      "resetting env. episode reward total was 2.0. running mean: 7.068388145779737\n",
      "resetting env. episode reward total was 7.0. running mean: 7.06770426432194\n",
      "resetting env. episode reward total was 1.0. running mean: 7.007027221678721\n",
      "resetting env. episode reward total was 5.0. running mean: 6.986956949461933\n",
      "resetting env. episode reward total was 4.0. running mean: 6.957087379967314\n",
      "resetting env. episode reward total was 6.0. running mean: 6.9475165061676405\n",
      "resetting env. episode reward total was 9.0. running mean: 6.968041341105964\n",
      "resetting env. episode reward total was 15.0. running mean: 7.048360927694905\n",
      "resetting env. episode reward total was 12.0. running mean: 7.0978773184179555\n",
      "resetting env. episode reward total was 2.0. running mean: 7.046898545233775\n",
      "resetting env. episode reward total was 6.0. running mean: 7.036429559781437\n",
      "resetting env. episode reward total was 6.0. running mean: 7.0260652641836225\n",
      "resetting env. episode reward total was -3.0. running mean: 6.925804611541786\n",
      "resetting env. episode reward total was 6.0. running mean: 6.916546565426368\n",
      "resetting env. episode reward total was 11.0. running mean: 6.957381099772105\n",
      "resetting env. episode reward total was -6.0. running mean: 6.827807288774384\n",
      "resetting env. episode reward total was 7.0. running mean: 6.82952921588664\n",
      "resetting env. episode reward total was 8.0. running mean: 6.841233923727773\n",
      "resetting env. episode reward total was 7.0. running mean: 6.842821584490496\n",
      "resetting env. episode reward total was 10.0. running mean: 6.87439336864559\n",
      "resetting env. episode reward total was 10.0. running mean: 6.905649434959134\n",
      "resetting env. episode reward total was 9.0. running mean: 6.926592940609543\n",
      "resetting env. episode reward total was 7.0. running mean: 6.927327011203447\n",
      "resetting env. episode reward total was 13.0. running mean: 6.988053741091412\n",
      "resetting env. episode reward total was 10.0. running mean: 7.018173203680497\n",
      "resetting env. episode reward total was 6.0. running mean: 7.007991471643692\n",
      "resetting env. episode reward total was 6.0. running mean: 6.997911556927255\n",
      "resetting env. episode reward total was 8.0. running mean: 7.007932441357982\n",
      "resetting env. episode reward total was 5.0. running mean: 6.987853116944402\n",
      "resetting env. episode reward total was -2.0. running mean: 6.897974585774959\n",
      "resetting env. episode reward total was 8.0. running mean: 6.908994839917209\n",
      "resetting env. episode reward total was 2.0. running mean: 6.8599048915180365\n",
      "resetting env. episode reward total was 12.0. running mean: 6.911305842602856\n",
      "resetting env. episode reward total was -4.0. running mean: 6.802192784176828\n",
      "resetting env. episode reward total was 15.0. running mean: 6.88417085633506\n",
      "resetting env. episode reward total was 2.0. running mean: 6.835329147771708\n",
      "resetting env. episode reward total was 11.0. running mean: 6.876975856293992\n",
      "resetting env. episode reward total was -14.0. running mean: 6.668206097731052\n",
      "resetting env. episode reward total was 9.0. running mean: 6.691524036753742\n",
      "resetting env. episode reward total was 11.0. running mean: 6.734608796386205\n",
      "resetting env. episode reward total was 14.0. running mean: 6.807262708422342\n",
      "resetting env. episode reward total was 7.0. running mean: 6.8091900813381185\n",
      "resetting env. episode reward total was -4.0. running mean: 6.701098180524737\n",
      "resetting env. episode reward total was 8.0. running mean: 6.71408719871949\n",
      "resetting env. episode reward total was 8.0. running mean: 6.726946326732295\n",
      "resetting env. episode reward total was 9.0. running mean: 6.749676863464972\n",
      "resetting env. episode reward total was 6.0. running mean: 6.7421800948303225\n",
      "resetting env. episode reward total was 13.0. running mean: 6.804758293882019\n",
      "resetting env. episode reward total was 6.0. running mean: 6.796710710943199\n",
      "resetting env. episode reward total was 8.0. running mean: 6.808743603833767\n",
      "resetting env. episode reward total was -5.0. running mean: 6.690656167795429\n",
      "resetting env. episode reward total was 6.0. running mean: 6.683749606117474\n",
      "resetting env. episode reward total was 12.0. running mean: 6.736912110056299\n",
      "resetting env. episode reward total was 13.0. running mean: 6.799542988955737\n",
      "resetting env. episode reward total was 11.0. running mean: 6.841547559066179\n",
      "resetting env. episode reward total was 9.0. running mean: 6.863132083475517\n",
      "resetting env. episode reward total was 4.0. running mean: 6.834500762640762\n",
      "resetting env. episode reward total was 8.0. running mean: 6.846155755014355\n",
      "resetting env. episode reward total was -1.0. running mean: 6.767694197464211\n",
      "resetting env. episode reward total was 9.0. running mean: 6.790017255489569\n",
      "resetting env. episode reward total was 6.0. running mean: 6.782117082934673\n",
      "resetting env. episode reward total was 7.0. running mean: 6.784295912105327\n",
      "resetting env. episode reward total was 11.0. running mean: 6.8264529529842735\n",
      "resetting env. episode reward total was -1.0. running mean: 6.7481884234544305\n",
      "resetting env. episode reward total was -1.0. running mean: 6.6707065392198865\n",
      "resetting env. episode reward total was 10.0. running mean: 6.703999473827687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 6.73695947908941\n",
      "resetting env. episode reward total was 1.0. running mean: 6.679589884298515\n",
      "resetting env. episode reward total was 3.0. running mean: 6.642793985455531\n",
      "resetting env. episode reward total was 8.0. running mean: 6.656366045600976\n",
      "resetting env. episode reward total was 6.0. running mean: 6.649802385144965\n",
      "resetting env. episode reward total was 15.0. running mean: 6.7333043612935155\n",
      "resetting env. episode reward total was 11.0. running mean: 6.775971317680581\n",
      "resetting env. episode reward total was 10.0. running mean: 6.808211604503774\n",
      "resetting env. episode reward total was 12.0. running mean: 6.860129488458736\n",
      "resetting env. episode reward total was 13.0. running mean: 6.921528193574149\n",
      "resetting env. episode reward total was 10.0. running mean: 6.9523129116384075\n",
      "resetting env. episode reward total was 15.0. running mean: 7.032789782522023\n",
      "resetting env. episode reward total was 9.0. running mean: 7.052461884696803\n",
      "resetting env. episode reward total was 6.0. running mean: 7.0419372658498345\n",
      "resetting env. episode reward total was 7.0. running mean: 7.041517893191337\n",
      "resetting env. episode reward total was 14.0. running mean: 7.111102714259423\n",
      "resetting env. episode reward total was -1.0. running mean: 7.029991687116829\n",
      "resetting env. episode reward total was -2.0. running mean: 6.939691770245661\n",
      "resetting env. episode reward total was 10.0. running mean: 6.970294852543204\n",
      "resetting env. episode reward total was -3.0. running mean: 6.870591904017772\n",
      "resetting env. episode reward total was 4.0. running mean: 6.841885984977594\n",
      "resetting env. episode reward total was 9.0. running mean: 6.863467125127818\n",
      "resetting env. episode reward total was -1.0. running mean: 6.7848324538765405\n",
      "resetting env. episode reward total was 12.0. running mean: 6.836984129337775\n",
      "resetting env. episode reward total was 14.0. running mean: 6.908614288044397\n",
      "resetting env. episode reward total was 5.0. running mean: 6.889528145163953\n",
      "resetting env. episode reward total was 13.0. running mean: 6.950632863712314\n",
      "resetting env. episode reward total was 11.0. running mean: 6.991126535075191\n",
      "resetting env. episode reward total was 13.0. running mean: 7.051215269724438\n",
      "resetting env. episode reward total was 18.0. running mean: 7.160703117027194\n",
      "resetting env. episode reward total was 8.0. running mean: 7.169096085856922\n",
      "resetting env. episode reward total was 11.0. running mean: 7.2074051249983535\n",
      "resetting env. episode reward total was 4.0. running mean: 7.17533107374837\n",
      "resetting env. episode reward total was 8.0. running mean: 7.183577763010886\n",
      "resetting env. episode reward total was 1.0. running mean: 7.121741985380777\n",
      "resetting env. episode reward total was 5.0. running mean: 7.100524565526969\n",
      "resetting env. episode reward total was 11.0. running mean: 7.1395193198717\n",
      "resetting env. episode reward total was 9.0. running mean: 7.158124126672982\n",
      "resetting env. episode reward total was 4.0. running mean: 7.126542885406252\n",
      "resetting env. episode reward total was 10.0. running mean: 7.155277456552189\n",
      "resetting env. episode reward total was 7.0. running mean: 7.1537246819866676\n",
      "resetting env. episode reward total was 9.0. running mean: 7.1721874351668005\n",
      "resetting env. episode reward total was 7.0. running mean: 7.170465560815133\n",
      "resetting env. episode reward total was -1.0. running mean: 7.088760905206982\n",
      "resetting env. episode reward total was 17.0. running mean: 7.187873296154912\n",
      "resetting env. episode reward total was 4.0. running mean: 7.155994563193363\n",
      "resetting env. episode reward total was 11.0. running mean: 7.19443461756143\n",
      "resetting env. episode reward total was 2.0. running mean: 7.142490271385815\n",
      "resetting env. episode reward total was 4.0. running mean: 7.111065368671957\n",
      "resetting env. episode reward total was 13.0. running mean: 7.169954714985237\n",
      "resetting env. episode reward total was -1.0. running mean: 7.088255167835385\n",
      "resetting env. episode reward total was 9.0. running mean: 7.107372616157031\n",
      "resetting env. episode reward total was 8.0. running mean: 7.116298889995461\n",
      "resetting env. episode reward total was 6.0. running mean: 7.1051359010955055\n",
      "resetting env. episode reward total was 6.0. running mean: 7.09408454208455\n",
      "resetting env. episode reward total was 4.0. running mean: 7.063143696663705\n",
      "resetting env. episode reward total was 14.0. running mean: 7.132512259697068\n",
      "resetting env. episode reward total was 13.0. running mean: 7.191187137100097\n",
      "resetting env. episode reward total was 10.0. running mean: 7.219275265729095\n",
      "resetting env. episode reward total was 14.0. running mean: 7.2870825130718035\n",
      "resetting env. episode reward total was 11.0. running mean: 7.3242116879410855\n",
      "resetting env. episode reward total was 12.0. running mean: 7.370969571061675\n",
      "resetting env. episode reward total was 13.0. running mean: 7.427259875351058\n",
      "resetting env. episode reward total was 12.0. running mean: 7.472987276597547\n",
      "resetting env. episode reward total was 13.0. running mean: 7.528257403831572\n",
      "resetting env. episode reward total was 5.0. running mean: 7.5029748297932555\n",
      "resetting env. episode reward total was 1.0. running mean: 7.4379450814953225\n",
      "resetting env. episode reward total was 3.0. running mean: 7.39356563068037\n",
      "resetting env. episode reward total was 9.0. running mean: 7.409629974373566\n",
      "resetting env. episode reward total was -3.0. running mean: 7.30553367462983\n",
      "resetting env. episode reward total was 4.0. running mean: 7.272478337883531\n",
      "resetting env. episode reward total was 3.0. running mean: 7.229753554504696\n",
      "resetting env. episode reward total was 8.0. running mean: 7.237456018959649\n",
      "resetting env. episode reward total was 11.0. running mean: 7.275081458770052\n",
      "resetting env. episode reward total was 7.0. running mean: 7.272330644182352\n",
      "resetting env. episode reward total was -10.0. running mean: 7.099607337740529\n",
      "resetting env. episode reward total was 8.0. running mean: 7.108611264363123\n",
      "resetting env. episode reward total was 11.0. running mean: 7.147525151719492\n",
      "resetting env. episode reward total was 15.0. running mean: 7.226049900202297\n",
      "resetting env. episode reward total was 13.0. running mean: 7.283789401200274\n",
      "resetting env. episode reward total was 4.0. running mean: 7.2509515071882715\n",
      "resetting env. episode reward total was 3.0. running mean: 7.208441992116389\n",
      "resetting env. episode reward total was 14.0. running mean: 7.2763575721952245\n",
      "resetting env. episode reward total was 13.0. running mean: 7.333593996473272\n",
      "resetting env. episode reward total was 1.0. running mean: 7.270258056508539\n",
      "resetting env. episode reward total was 10.0. running mean: 7.2975554759434536\n",
      "resetting env. episode reward total was 7.0. running mean: 7.294579921184019\n",
      "resetting env. episode reward total was 8.0. running mean: 7.301634121972179\n",
      "resetting env. episode reward total was 7.0. running mean: 7.2986177807524575\n",
      "resetting env. episode reward total was 10.0. running mean: 7.325631602944933\n",
      "resetting env. episode reward total was 7.0. running mean: 7.3223752869154834\n",
      "resetting env. episode reward total was 5.0. running mean: 7.299151534046328\n",
      "resetting env. episode reward total was 1.0. running mean: 7.236160018705864\n",
      "resetting env. episode reward total was 5.0. running mean: 7.213798418518805\n",
      "resetting env. episode reward total was 3.0. running mean: 7.171660434333617\n",
      "resetting env. episode reward total was 8.0. running mean: 7.179943829990281\n",
      "resetting env. episode reward total was 14.0. running mean: 7.248144391690378\n",
      "resetting env. episode reward total was 5.0. running mean: 7.225662947773474\n",
      "resetting env. episode reward total was 2.0. running mean: 7.173406318295738\n",
      "resetting env. episode reward total was 6.0. running mean: 7.16167225511278\n",
      "resetting env. episode reward total was 7.0. running mean: 7.160055532561652\n",
      "resetting env. episode reward total was 10.0. running mean: 7.188454977236035\n",
      "resetting env. episode reward total was 10.0. running mean: 7.216570427463674\n",
      "resetting env. episode reward total was 13.0. running mean: 7.274404723189037\n",
      "resetting env. episode reward total was 10.0. running mean: 7.301660675957146\n",
      "resetting env. episode reward total was 1.0. running mean: 7.238644069197575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 7.226257628505598\n",
      "resetting env. episode reward total was 9.0. running mean: 7.243995052220542\n",
      "resetting env. episode reward total was 7.0. running mean: 7.241555101698337\n",
      "resetting env. episode reward total was 10.0. running mean: 7.269139550681353\n",
      "resetting env. episode reward total was 15.0. running mean: 7.3464481551745395\n",
      "resetting env. episode reward total was 4.0. running mean: 7.312983673622794\n",
      "resetting env. episode reward total was 4.0. running mean: 7.279853836886566\n",
      "resetting env. episode reward total was 5.0. running mean: 7.257055298517701\n",
      "resetting env. episode reward total was 6.0. running mean: 7.244484745532523\n",
      "resetting env. episode reward total was 7.0. running mean: 7.242039898077198\n",
      "resetting env. episode reward total was 6.0. running mean: 7.229619499096425\n",
      "resetting env. episode reward total was 16.0. running mean: 7.317323304105461\n",
      "resetting env. episode reward total was 1.0. running mean: 7.254150071064406\n",
      "resetting env. episode reward total was 5.0. running mean: 7.231608570353762\n",
      "resetting env. episode reward total was -8.0. running mean: 7.0792924846502245\n",
      "resetting env. episode reward total was 4.0. running mean: 7.048499559803722\n",
      "resetting env. episode reward total was 13.0. running mean: 7.108014564205685\n",
      "resetting env. episode reward total was 8.0. running mean: 7.116934418563628\n",
      "resetting env. episode reward total was -2.0. running mean: 7.025765074377992\n",
      "resetting env. episode reward total was 4.0. running mean: 6.995507423634212\n",
      "resetting env. episode reward total was 10.0. running mean: 7.025552349397869\n",
      "resetting env. episode reward total was 10.0. running mean: 7.05529682590389\n",
      "resetting env. episode reward total was 6.0. running mean: 7.044743857644851\n",
      "resetting env. episode reward total was 2.0. running mean: 6.994296419068402\n",
      "resetting env. episode reward total was 3.0. running mean: 6.954353454877718\n",
      "resetting env. episode reward total was -4.0. running mean: 6.844809920328941\n",
      "resetting env. episode reward total was 13.0. running mean: 6.9063618211256514\n",
      "resetting env. episode reward total was 9.0. running mean: 6.927298202914395\n",
      "resetting env. episode reward total was 5.0. running mean: 6.908025220885251\n",
      "resetting env. episode reward total was 13.0. running mean: 6.968944968676398\n",
      "resetting env. episode reward total was 7.0. running mean: 6.969255518989635\n",
      "resetting env. episode reward total was 8.0. running mean: 6.979562963799738\n",
      "resetting env. episode reward total was 5.0. running mean: 6.95976733416174\n",
      "resetting env. episode reward total was 11.0. running mean: 7.000169660820124\n",
      "resetting env. episode reward total was 3.0. running mean: 6.960167964211923\n",
      "resetting env. episode reward total was 5.0. running mean: 6.940566284569804\n",
      "resetting env. episode reward total was 2.0. running mean: 6.891160621724105\n",
      "resetting env. episode reward total was 11.0. running mean: 6.932249015506865\n",
      "resetting env. episode reward total was 9.0. running mean: 6.952926525351796\n",
      "resetting env. episode reward total was 11.0. running mean: 6.993397260098278\n",
      "resetting env. episode reward total was -7.0. running mean: 6.853463287497295\n",
      "resetting env. episode reward total was 10.0. running mean: 6.884928654622321\n",
      "resetting env. episode reward total was 14.0. running mean: 6.9560793680760975\n",
      "resetting env. episode reward total was 9.0. running mean: 6.976518574395336\n",
      "resetting env. episode reward total was 5.0. running mean: 6.956753388651382\n",
      "resetting env. episode reward total was 9.0. running mean: 6.977185854764868\n",
      "resetting env. episode reward total was 15.0. running mean: 7.05741399621722\n",
      "resetting env. episode reward total was 3.0. running mean: 7.016839856255048\n",
      "resetting env. episode reward total was 12.0. running mean: 7.066671457692498\n",
      "resetting env. episode reward total was 13.0. running mean: 7.126004743115573\n",
      "resetting env. episode reward total was 5.0. running mean: 7.104744695684417\n",
      "resetting env. episode reward total was 7.0. running mean: 7.103697248727573\n",
      "resetting env. episode reward total was 10.0. running mean: 7.132660276240297\n",
      "resetting env. episode reward total was 13.0. running mean: 7.191333673477894\n",
      "resetting env. episode reward total was 8.0. running mean: 7.199420336743115\n",
      "resetting env. episode reward total was 11.0. running mean: 7.237426133375684\n",
      "resetting env. episode reward total was 8.0. running mean: 7.245051872041927\n",
      "resetting env. episode reward total was 7.0. running mean: 7.242601353321508\n",
      "resetting env. episode reward total was 5.0. running mean: 7.220175339788292\n",
      "resetting env. episode reward total was 10.0. running mean: 7.247973586390408\n",
      "resetting env. episode reward total was -3.0. running mean: 7.1454938505265035\n",
      "resetting env. episode reward total was 10.0. running mean: 7.1740389120212384\n",
      "resetting env. episode reward total was 12.0. running mean: 7.222298522901026\n",
      "resetting env. episode reward total was 5.0. running mean: 7.200075537672015\n",
      "resetting env. episode reward total was 12.0. running mean: 7.248074782295295\n",
      "resetting env. episode reward total was 17.0. running mean: 7.345594034472342\n",
      "resetting env. episode reward total was 16.0. running mean: 7.432138094127618\n",
      "resetting env. episode reward total was 12.0. running mean: 7.477816713186342\n",
      "resetting env. episode reward total was 1.0. running mean: 7.413038546054478\n",
      "resetting env. episode reward total was 11.0. running mean: 7.448908160593934\n",
      "resetting env. episode reward total was 14.0. running mean: 7.514419078987994\n",
      "resetting env. episode reward total was 13.0. running mean: 7.569274888198114\n",
      "resetting env. episode reward total was 16.0. running mean: 7.653582139316133\n",
      "resetting env. episode reward total was 1.0. running mean: 7.5870463179229715\n",
      "resetting env. episode reward total was 16.0. running mean: 7.671175854743741\n",
      "resetting env. episode reward total was 7.0. running mean: 7.664464096196304\n",
      "resetting env. episode reward total was 12.0. running mean: 7.707819455234341\n",
      "resetting env. episode reward total was 3.0. running mean: 7.660741260681998\n",
      "resetting env. episode reward total was 12.0. running mean: 7.704133848075178\n",
      "resetting env. episode reward total was 12.0. running mean: 7.747092509594426\n",
      "resetting env. episode reward total was 7.0. running mean: 7.739621584498481\n",
      "resetting env. episode reward total was 1.0. running mean: 7.672225368653496\n",
      "resetting env. episode reward total was 11.0. running mean: 7.7055031149669615\n",
      "resetting env. episode reward total was 2.0. running mean: 7.648448083817291\n",
      "resetting env. episode reward total was 4.0. running mean: 7.6119636029791184\n",
      "resetting env. episode reward total was 13.0. running mean: 7.6658439669493275\n",
      "resetting env. episode reward total was 6.0. running mean: 7.649185527279834\n",
      "resetting env. episode reward total was 3.0. running mean: 7.602693672007036\n",
      "resetting env. episode reward total was 1.0. running mean: 7.536666735286966\n",
      "resetting env. episode reward total was 13.0. running mean: 7.591300067934096\n",
      "resetting env. episode reward total was 11.0. running mean: 7.6253870672547555\n",
      "resetting env. episode reward total was 8.0. running mean: 7.629133196582208\n",
      "resetting env. episode reward total was 18.0. running mean: 7.732841864616385\n",
      "resetting env. episode reward total was 5.0. running mean: 7.7055134459702215\n",
      "resetting env. episode reward total was 7.0. running mean: 7.698458311510519\n",
      "resetting env. episode reward total was 12.0. running mean: 7.741473728395414\n",
      "resetting env. episode reward total was 16.0. running mean: 7.82405899111146\n",
      "resetting env. episode reward total was -8.0. running mean: 7.665818401200346\n",
      "resetting env. episode reward total was 12.0. running mean: 7.709160217188343\n",
      "resetting env. episode reward total was 7.0. running mean: 7.70206861501646\n",
      "resetting env. episode reward total was 10.0. running mean: 7.725047928866295\n",
      "resetting env. episode reward total was 10.0. running mean: 7.747797449577631\n",
      "resetting env. episode reward total was 9.0. running mean: 7.760319475081855\n",
      "resetting env. episode reward total was 3.0. running mean: 7.712716280331036\n",
      "resetting env. episode reward total was 13.0. running mean: 7.765589117527726\n",
      "resetting env. episode reward total was 14.0. running mean: 7.827933226352448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 7.839653894088923\n",
      "resetting env. episode reward total was 8.0. running mean: 7.841257355148034\n",
      "resetting env. episode reward total was 4.0. running mean: 7.802844781596554\n",
      "resetting env. episode reward total was 6.0. running mean: 7.784816333780588\n",
      "resetting env. episode reward total was -5.0. running mean: 7.6569681704427826\n",
      "resetting env. episode reward total was 4.0. running mean: 7.6203984887383545\n",
      "resetting env. episode reward total was 2.0. running mean: 7.56419450385097\n",
      "resetting env. episode reward total was 8.0. running mean: 7.568552558812461\n",
      "resetting env. episode reward total was 7.0. running mean: 7.562867033224336\n",
      "resetting env. episode reward total was 8.0. running mean: 7.567238362892093\n",
      "resetting env. episode reward total was 16.0. running mean: 7.6515659792631725\n",
      "resetting env. episode reward total was -5.0. running mean: 7.525050319470541\n",
      "resetting env. episode reward total was 9.0. running mean: 7.539799816275836\n",
      "resetting env. episode reward total was 9.0. running mean: 7.554401818113077\n",
      "resetting env. episode reward total was 6.0. running mean: 7.538857799931946\n",
      "resetting env. episode reward total was 10.0. running mean: 7.563469221932626\n",
      "resetting env. episode reward total was -1.0. running mean: 7.4778345297132995\n",
      "resetting env. episode reward total was 11.0. running mean: 7.5130561844161665\n",
      "resetting env. episode reward total was 12.0. running mean: 7.557925622572005\n",
      "resetting env. episode reward total was 10.0. running mean: 7.582346366346284\n",
      "resetting env. episode reward total was 6.0. running mean: 7.566522902682821\n",
      "resetting env. episode reward total was 4.0. running mean: 7.5308576736559925\n",
      "resetting env. episode reward total was 12.0. running mean: 7.575549096919433\n",
      "resetting env. episode reward total was 10.0. running mean: 7.5997936059502385\n",
      "resetting env. episode reward total was 11.0. running mean: 7.633795669890736\n",
      "resetting env. episode reward total was 5.0. running mean: 7.607457713191828\n",
      "resetting env. episode reward total was 7.0. running mean: 7.60138313605991\n",
      "resetting env. episode reward total was 18.0. running mean: 7.70536930469931\n",
      "resetting env. episode reward total was -7.0. running mean: 7.558315611652317\n",
      "resetting env. episode reward total was 7.0. running mean: 7.552732455535794\n",
      "resetting env. episode reward total was -2.0. running mean: 7.457205130980436\n",
      "resetting env. episode reward total was 13.0. running mean: 7.512633079670632\n",
      "resetting env. episode reward total was -8.0. running mean: 7.357506748873925\n",
      "resetting env. episode reward total was 10.0. running mean: 7.383931681385186\n",
      "resetting env. episode reward total was 8.0. running mean: 7.390092364571334\n",
      "resetting env. episode reward total was -6.0. running mean: 7.256191440925621\n",
      "resetting env. episode reward total was 7.0. running mean: 7.253629526516365\n",
      "resetting env. episode reward total was 11.0. running mean: 7.291093231251201\n",
      "resetting env. episode reward total was 10.0. running mean: 7.318182298938689\n",
      "resetting env. episode reward total was 9.0. running mean: 7.335000475949302\n",
      "resetting env. episode reward total was 4.0. running mean: 7.301650471189809\n",
      "resetting env. episode reward total was 9.0. running mean: 7.318633966477911\n",
      "resetting env. episode reward total was 7.0. running mean: 7.315447626813132\n",
      "resetting env. episode reward total was 6.0. running mean: 7.302293150545\n",
      "resetting env. episode reward total was 4.0. running mean: 7.26927021903955\n",
      "resetting env. episode reward total was -5.0. running mean: 7.146577516849154\n",
      "resetting env. episode reward total was 1.0. running mean: 7.085111741680662\n",
      "resetting env. episode reward total was 6.0. running mean: 7.0742606242638555\n",
      "resetting env. episode reward total was 18.0. running mean: 7.183518018021217\n",
      "resetting env. episode reward total was 1.0. running mean: 7.121682837841004\n",
      "resetting env. episode reward total was 14.0. running mean: 7.190466009462594\n",
      "resetting env. episode reward total was 1.0. running mean: 7.128561349367968\n",
      "resetting env. episode reward total was 9.0. running mean: 7.147275735874288\n",
      "resetting env. episode reward total was 1.0. running mean: 7.085802978515545\n",
      "resetting env. episode reward total was 12.0. running mean: 7.13494494873039\n",
      "resetting env. episode reward total was -6.0. running mean: 7.003595499243087\n",
      "resetting env. episode reward total was 1.0. running mean: 6.943559544250656\n",
      "resetting env. episode reward total was 11.0. running mean: 6.98412394880815\n",
      "resetting env. episode reward total was 18.0. running mean: 7.094282709320068\n",
      "resetting env. episode reward total was 4.0. running mean: 7.063339882226868\n",
      "resetting env. episode reward total was 5.0. running mean: 7.042706483404599\n",
      "resetting env. episode reward total was -4.0. running mean: 6.932279418570553\n",
      "resetting env. episode reward total was 9.0. running mean: 6.952956624384847\n",
      "resetting env. episode reward total was 6.0. running mean: 6.9434270581409985\n",
      "resetting env. episode reward total was 15.0. running mean: 7.023992787559589\n",
      "resetting env. episode reward total was -10.0. running mean: 6.853752859683993\n",
      "resetting env. episode reward total was 4.0. running mean: 6.825215331087153\n",
      "resetting env. episode reward total was 3.0. running mean: 6.786963177776282\n",
      "resetting env. episode reward total was 14.0. running mean: 6.859093545998519\n",
      "resetting env. episode reward total was 1.0. running mean: 6.800502610538533\n",
      "resetting env. episode reward total was 12.0. running mean: 6.852497584433148\n",
      "resetting env. episode reward total was 2.0. running mean: 6.803972608588816\n",
      "resetting env. episode reward total was 10.0. running mean: 6.835932882502927\n",
      "resetting env. episode reward total was 11.0. running mean: 6.877573553677898\n",
      "resetting env. episode reward total was 10.0. running mean: 6.908797818141119\n",
      "resetting env. episode reward total was 9.0. running mean: 6.929709839959708\n",
      "resetting env. episode reward total was 6.0. running mean: 6.92041274156011\n",
      "resetting env. episode reward total was 13.0. running mean: 6.981208614144509\n",
      "resetting env. episode reward total was 5.0. running mean: 6.961396528003064\n",
      "resetting env. episode reward total was 3.0. running mean: 6.921782562723034\n",
      "resetting env. episode reward total was 14.0. running mean: 6.992564737095803\n",
      "resetting env. episode reward total was 5.0. running mean: 6.9726390897248445\n",
      "resetting env. episode reward total was 11.0. running mean: 7.012912698827597\n",
      "resetting env. episode reward total was 8.0. running mean: 7.02278357183932\n",
      "resetting env. episode reward total was 7.0. running mean: 7.022555736120927\n",
      "resetting env. episode reward total was 6.0. running mean: 7.012330178759718\n",
      "resetting env. episode reward total was 1.0. running mean: 6.95220687697212\n",
      "resetting env. episode reward total was -6.0. running mean: 6.822684808202399\n",
      "resetting env. episode reward total was 5.0. running mean: 6.8044579601203745\n",
      "resetting env. episode reward total was 10.0. running mean: 6.83641338051917\n",
      "resetting env. episode reward total was 13.0. running mean: 6.8980492467139785\n",
      "resetting env. episode reward total was 2.0. running mean: 6.849068754246838\n",
      "resetting env. episode reward total was 10.0. running mean: 6.88057806670437\n",
      "resetting env. episode reward total was 5.0. running mean: 6.861772286037326\n",
      "resetting env. episode reward total was 11.0. running mean: 6.903154563176953\n",
      "resetting env. episode reward total was 18.0. running mean: 7.014123017545183\n",
      "resetting env. episode reward total was 4.0. running mean: 6.983981787369731\n",
      "resetting env. episode reward total was 14.0. running mean: 7.054141969496033\n",
      "resetting env. episode reward total was 9.0. running mean: 7.073600549801073\n",
      "resetting env. episode reward total was 15.0. running mean: 7.152864544303062\n",
      "resetting env. episode reward total was 3.0. running mean: 7.111335898860032\n",
      "resetting env. episode reward total was 9.0. running mean: 7.130222539871432\n",
      "resetting env. episode reward total was 12.0. running mean: 7.178920314472718\n",
      "resetting env. episode reward total was 14.0. running mean: 7.24713111132799\n",
      "resetting env. episode reward total was 2.0. running mean: 7.194659800214709\n",
      "resetting env. episode reward total was 12.0. running mean: 7.242713202212562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 7.220286070190436\n",
      "resetting env. episode reward total was 11.0. running mean: 7.258083209488532\n",
      "resetting env. episode reward total was -2.0. running mean: 7.165502377393647\n",
      "resetting env. episode reward total was 14.0. running mean: 7.23384735361971\n",
      "resetting env. episode reward total was 3.0. running mean: 7.191508880083513\n",
      "resetting env. episode reward total was 11.0. running mean: 7.229593791282679\n",
      "resetting env. episode reward total was 14.0. running mean: 7.297297853369852\n",
      "resetting env. episode reward total was 13.0. running mean: 7.354324874836153\n",
      "resetting env. episode reward total was 8.0. running mean: 7.360781626087792\n",
      "resetting env. episode reward total was 9.0. running mean: 7.377173809826913\n",
      "resetting env. episode reward total was 13.0. running mean: 7.4334020717286435\n",
      "resetting env. episode reward total was 6.0. running mean: 7.419068051011356\n",
      "resetting env. episode reward total was 15.0. running mean: 7.494877370501243\n",
      "resetting env. episode reward total was 9.0. running mean: 7.509928596796231\n",
      "resetting env. episode reward total was 12.0. running mean: 7.554829310828269\n",
      "resetting env. episode reward total was 16.0. running mean: 7.639281017719986\n",
      "resetting env. episode reward total was 4.0. running mean: 7.602888207542786\n",
      "resetting env. episode reward total was 4.0. running mean: 7.566859325467358\n",
      "resetting env. episode reward total was 7.0. running mean: 7.561190732212685\n",
      "resetting env. episode reward total was 16.0. running mean: 7.645578824890558\n",
      "resetting env. episode reward total was 14.0. running mean: 7.709123036641652\n",
      "resetting env. episode reward total was 3.0. running mean: 7.662031806275236\n",
      "resetting env. episode reward total was 8.0. running mean: 7.6654114882124835\n",
      "resetting env. episode reward total was -4.0. running mean: 7.548757373330359\n",
      "resetting env. episode reward total was 6.0. running mean: 7.533269799597055\n",
      "resetting env. episode reward total was 4.0. running mean: 7.497937101601084\n",
      "resetting env. episode reward total was 13.0. running mean: 7.5529577305850735\n",
      "resetting env. episode reward total was 12.0. running mean: 7.597428153279223\n",
      "resetting env. episode reward total was 12.0. running mean: 7.641453871746431\n",
      "resetting env. episode reward total was 15.0. running mean: 7.715039333028967\n",
      "resetting env. episode reward total was 11.0. running mean: 7.747888939698678\n",
      "resetting env. episode reward total was 7.0. running mean: 7.7404100503016915\n",
      "resetting env. episode reward total was 7.0. running mean: 7.733005949798675\n",
      "resetting env. episode reward total was 10.0. running mean: 7.7556758903006875\n",
      "resetting env. episode reward total was 10.0. running mean: 7.7781191313976805\n",
      "resetting env. episode reward total was 10.0. running mean: 7.800337940083703\n",
      "resetting env. episode reward total was 6.0. running mean: 7.782334560682866\n",
      "resetting env. episode reward total was 14.0. running mean: 7.844511215076037\n",
      "resetting env. episode reward total was 8.0. running mean: 7.846066102925277\n",
      "resetting env. episode reward total was 15.0. running mean: 7.917605441896025\n",
      "resetting env. episode reward total was 11.0. running mean: 7.948429387477065\n",
      "resetting env. episode reward total was 8.0. running mean: 7.948945093602294\n",
      "resetting env. episode reward total was -3.0. running mean: 7.8394556426662705\n",
      "resetting env. episode reward total was 12.0. running mean: 7.881061086239608\n",
      "resetting env. episode reward total was 12.0. running mean: 7.922250475377212\n",
      "resetting env. episode reward total was 4.0. running mean: 7.8830279706234405\n",
      "resetting env. episode reward total was -3.0. running mean: 7.774197690917206\n",
      "resetting env. episode reward total was 10.0. running mean: 7.796455714008034\n",
      "resetting env. episode reward total was 8.0. running mean: 7.798491156867954\n",
      "resetting env. episode reward total was 7.0. running mean: 7.790506245299274\n",
      "resetting env. episode reward total was 8.0. running mean: 7.792601182846282\n",
      "resetting env. episode reward total was 9.0. running mean: 7.804675171017818\n",
      "resetting env. episode reward total was 1.0. running mean: 7.73662841930764\n",
      "resetting env. episode reward total was 8.0. running mean: 7.739262135114563\n",
      "resetting env. episode reward total was 10.0. running mean: 7.7618695137634175\n",
      "resetting env. episode reward total was 9.0. running mean: 7.7742508186257835\n",
      "resetting env. episode reward total was 15.0. running mean: 7.846508310439526\n",
      "resetting env. episode reward total was 7.0. running mean: 7.838043227335131\n",
      "resetting env. episode reward total was 4.0. running mean: 7.79966279506178\n",
      "resetting env. episode reward total was -13.0. running mean: 7.591666167111162\n",
      "resetting env. episode reward total was 13.0. running mean: 7.64574950544005\n",
      "resetting env. episode reward total was 5.0. running mean: 7.619292010385649\n",
      "resetting env. episode reward total was 8.0. running mean: 7.6230990902817926\n",
      "resetting env. episode reward total was 9.0. running mean: 7.636868099378974\n",
      "resetting env. episode reward total was 9.0. running mean: 7.650499418385184\n",
      "resetting env. episode reward total was 3.0. running mean: 7.603994424201333\n",
      "resetting env. episode reward total was 8.0. running mean: 7.60795447995932\n",
      "resetting env. episode reward total was 14.0. running mean: 7.671874935159726\n",
      "resetting env. episode reward total was 15.0. running mean: 7.7451561858081295\n",
      "resetting env. episode reward total was 10.0. running mean: 7.767704623950047\n",
      "resetting env. episode reward total was 9.0. running mean: 7.7800275777105465\n",
      "resetting env. episode reward total was 11.0. running mean: 7.812227301933441\n",
      "resetting env. episode reward total was 14.0. running mean: 7.874105028914106\n",
      "resetting env. episode reward total was 14.0. running mean: 7.935363978624965\n",
      "resetting env. episode reward total was 7.0. running mean: 7.926010338838715\n",
      "resetting env. episode reward total was 15.0. running mean: 7.996750235450328\n",
      "resetting env. episode reward total was 16.0. running mean: 8.076782733095824\n",
      "resetting env. episode reward total was 5.0. running mean: 8.046014905764865\n",
      "resetting env. episode reward total was 5.0. running mean: 8.015554756707218\n",
      "resetting env. episode reward total was 9.0. running mean: 8.025399209140145\n",
      "resetting env. episode reward total was -4.0. running mean: 7.9051452170487435\n",
      "resetting env. episode reward total was 7.0. running mean: 7.896093764878256\n",
      "resetting env. episode reward total was 16.0. running mean: 7.9771328272294735\n",
      "resetting env. episode reward total was 6.0. running mean: 7.957361498957178\n",
      "resetting env. episode reward total was 9.0. running mean: 7.967787883967606\n",
      "resetting env. episode reward total was 11.0. running mean: 7.998110005127931\n",
      "resetting env. episode reward total was 7.0. running mean: 7.9881289050766515\n",
      "resetting env. episode reward total was 9.0. running mean: 7.998247616025885\n",
      "resetting env. episode reward total was 14.0. running mean: 8.058265139865625\n",
      "resetting env. episode reward total was 14.0. running mean: 8.117682488466968\n",
      "resetting env. episode reward total was 14.0. running mean: 8.176505663582299\n",
      "resetting env. episode reward total was 13.0. running mean: 8.224740606946476\n",
      "resetting env. episode reward total was 7.0. running mean: 8.212493200877011\n",
      "resetting env. episode reward total was 7.0. running mean: 8.20036826886824\n",
      "resetting env. episode reward total was 9.0. running mean: 8.208364586179558\n",
      "resetting env. episode reward total was 8.0. running mean: 8.206280940317763\n",
      "resetting env. episode reward total was 12.0. running mean: 8.244218130914584\n",
      "resetting env. episode reward total was 7.0. running mean: 8.231775949605439\n",
      "resetting env. episode reward total was -1.0. running mean: 8.139458190109384\n",
      "resetting env. episode reward total was 8.0. running mean: 8.13806360820829\n",
      "resetting env. episode reward total was 4.0. running mean: 8.096682972126207\n",
      "resetting env. episode reward total was 7.0. running mean: 8.085716142404944\n",
      "resetting env. episode reward total was 10.0. running mean: 8.104858980980895\n",
      "resetting env. episode reward total was -9.0. running mean: 7.933810391171086\n",
      "resetting env. episode reward total was 14.0. running mean: 7.9944722872593745\n",
      "resetting env. episode reward total was 2.0. running mean: 7.93452756438678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 7.875182288742912\n",
      "resetting env. episode reward total was 8.0. running mean: 7.876430465855483\n",
      "resetting env. episode reward total was 9.0. running mean: 7.887666161196928\n",
      "resetting env. episode reward total was -3.0. running mean: 7.778789499584959\n",
      "resetting env. episode reward total was 11.0. running mean: 7.8110016045891095\n",
      "resetting env. episode reward total was 11.0. running mean: 7.842891588543218\n",
      "resetting env. episode reward total was 4.0. running mean: 7.804462672657786\n",
      "resetting env. episode reward total was 16.0. running mean: 7.886418045931209\n",
      "resetting env. episode reward total was 8.0. running mean: 7.887553865471897\n",
      "resetting env. episode reward total was 9.0. running mean: 7.898678326817178\n",
      "resetting env. episode reward total was -3.0. running mean: 7.789691543549006\n",
      "resetting env. episode reward total was 5.0. running mean: 7.761794628113516\n",
      "resetting env. episode reward total was 10.0. running mean: 7.78417668183238\n",
      "resetting env. episode reward total was 11.0. running mean: 7.816334915014057\n",
      "resetting env. episode reward total was 8.0. running mean: 7.818171565863916\n",
      "resetting env. episode reward total was -2.0. running mean: 7.719989850205278\n",
      "resetting env. episode reward total was 10.0. running mean: 7.742789951703225\n",
      "resetting env. episode reward total was 16.0. running mean: 7.825362052186192\n",
      "resetting env. episode reward total was 7.0. running mean: 7.817108431664331\n",
      "resetting env. episode reward total was 9.0. running mean: 7.828937347347687\n",
      "resetting env. episode reward total was 11.0. running mean: 7.860647973874211\n",
      "resetting env. episode reward total was 13.0. running mean: 7.912041494135469\n",
      "resetting env. episode reward total was 9.0. running mean: 7.922921079194114\n",
      "resetting env. episode reward total was 1.0. running mean: 7.853691868402173\n",
      "resetting env. episode reward total was 7.0. running mean: 7.845154949718151\n",
      "resetting env. episode reward total was 9.0. running mean: 7.85670340022097\n",
      "resetting env. episode reward total was -3.0. running mean: 7.74813636621876\n",
      "resetting env. episode reward total was 6.0. running mean: 7.7306550025565715\n",
      "resetting env. episode reward total was 1.0. running mean: 7.663348452531006\n",
      "resetting env. episode reward total was 6.0. running mean: 7.646714968005695\n",
      "resetting env. episode reward total was 1.0. running mean: 7.580247818325638\n",
      "resetting env. episode reward total was 11.0. running mean: 7.614445340142383\n",
      "resetting env. episode reward total was 3.0. running mean: 7.568300886740959\n",
      "resetting env. episode reward total was 10.0. running mean: 7.592617877873549\n",
      "resetting env. episode reward total was 5.0. running mean: 7.566691699094813\n",
      "resetting env. episode reward total was 8.0. running mean: 7.571024782103865\n",
      "resetting env. episode reward total was 10.0. running mean: 7.595314534282826\n",
      "resetting env. episode reward total was 7.0. running mean: 7.589361388939998\n",
      "resetting env. episode reward total was 10.0. running mean: 7.613467775050597\n",
      "resetting env. episode reward total was 2.0. running mean: 7.5573330973000905\n",
      "resetting env. episode reward total was 8.0. running mean: 7.561759766327089\n",
      "resetting env. episode reward total was 13.0. running mean: 7.616142168663818\n",
      "resetting env. episode reward total was -5.0. running mean: 7.48998074697718\n",
      "resetting env. episode reward total was 9.0. running mean: 7.505080939507407\n",
      "resetting env. episode reward total was 12.0. running mean: 7.550030130112333\n",
      "resetting env. episode reward total was 8.0. running mean: 7.5545298288112095\n",
      "resetting env. episode reward total was 10.0. running mean: 7.578984530523097\n",
      "resetting env. episode reward total was 18.0. running mean: 7.683194685217865\n",
      "resetting env. episode reward total was 5.0. running mean: 7.6563627383656865\n",
      "resetting env. episode reward total was 8.0. running mean: 7.659799110982029\n",
      "resetting env. episode reward total was 12.0. running mean: 7.703201119872209\n",
      "resetting env. episode reward total was 10.0. running mean: 7.726169108673487\n",
      "resetting env. episode reward total was 9.0. running mean: 7.738907417586752\n",
      "resetting env. episode reward total was 13.0. running mean: 7.791518343410885\n",
      "resetting env. episode reward total was -10.0. running mean: 7.613603159976776\n",
      "resetting env. episode reward total was 9.0. running mean: 7.627467128377008\n",
      "resetting env. episode reward total was 7.0. running mean: 7.621192457093238\n",
      "resetting env. episode reward total was 8.0. running mean: 7.624980532522305\n",
      "resetting env. episode reward total was 8.0. running mean: 7.628730727197082\n",
      "resetting env. episode reward total was 18.0. running mean: 7.732443419925111\n",
      "resetting env. episode reward total was 15.0. running mean: 7.805118985725859\n",
      "resetting env. episode reward total was 15.0. running mean: 7.8770677958686015\n",
      "resetting env. episode reward total was -4.0. running mean: 7.758297117909915\n",
      "resetting env. episode reward total was 12.0. running mean: 7.800714146730816\n",
      "resetting env. episode reward total was 8.0. running mean: 7.802707005263508\n",
      "resetting env. episode reward total was 5.0. running mean: 7.774679935210872\n",
      "resetting env. episode reward total was 17.0. running mean: 7.866933135858764\n",
      "resetting env. episode reward total was -3.0. running mean: 7.758263804500176\n",
      "resetting env. episode reward total was 11.0. running mean: 7.790681166455174\n",
      "resetting env. episode reward total was 15.0. running mean: 7.862774354790623\n",
      "resetting env. episode reward total was -3.0. running mean: 7.754146611242716\n",
      "resetting env. episode reward total was 6.0. running mean: 7.736605145130289\n",
      "resetting env. episode reward total was 11.0. running mean: 7.769239093678986\n",
      "resetting env. episode reward total was 8.0. running mean: 7.771546702742196\n",
      "resetting env. episode reward total was 1.0. running mean: 7.703831235714774\n",
      "resetting env. episode reward total was 14.0. running mean: 7.766792923357626\n",
      "resetting env. episode reward total was 11.0. running mean: 7.79912499412405\n",
      "resetting env. episode reward total was 12.0. running mean: 7.841133744182809\n",
      "resetting env. episode reward total was 9.0. running mean: 7.85272240674098\n",
      "resetting env. episode reward total was 10.0. running mean: 7.87419518267357\n",
      "resetting env. episode reward total was -1.0. running mean: 7.7854532308468345\n",
      "resetting env. episode reward total was 13.0. running mean: 7.837598698538366\n",
      "resetting env. episode reward total was 12.0. running mean: 7.879222711552982\n",
      "resetting env. episode reward total was 10.0. running mean: 7.900430484437452\n",
      "resetting env. episode reward total was 12.0. running mean: 7.941426179593077\n",
      "resetting env. episode reward total was 12.0. running mean: 7.982011917797147\n",
      "resetting env. episode reward total was 3.0. running mean: 7.932191798619176\n",
      "resetting env. episode reward total was 4.0. running mean: 7.892869880632984\n",
      "resetting env. episode reward total was 9.0. running mean: 7.903941181826654\n",
      "resetting env. episode reward total was 13.0. running mean: 7.954901770008387\n",
      "resetting env. episode reward total was 16.0. running mean: 8.035352752308302\n",
      "resetting env. episode reward total was 9.0. running mean: 8.04499922478522\n",
      "resetting env. episode reward total was 13.0. running mean: 8.094549232537368\n",
      "resetting env. episode reward total was 10.0. running mean: 8.113603740211994\n",
      "resetting env. episode reward total was 12.0. running mean: 8.152467702809874\n",
      "resetting env. episode reward total was 9.0. running mean: 8.160943025781775\n",
      "resetting env. episode reward total was 12.0. running mean: 8.199333595523957\n",
      "resetting env. episode reward total was 10.0. running mean: 8.217340259568717\n",
      "resetting env. episode reward total was 16.0. running mean: 8.29516685697303\n",
      "resetting env. episode reward total was 11.0. running mean: 8.322215188403298\n",
      "resetting env. episode reward total was 14.0. running mean: 8.378993036519265\n",
      "resetting env. episode reward total was 15.0. running mean: 8.445203106154073\n",
      "resetting env. episode reward total was 13.0. running mean: 8.490751075092533\n",
      "resetting env. episode reward total was 11.0. running mean: 8.515843564341607\n",
      "resetting env. episode reward total was 12.0. running mean: 8.55068512869819\n",
      "resetting env. episode reward total was 1.0. running mean: 8.475178277411207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 8.440426494637094\n",
      "resetting env. episode reward total was 10.0. running mean: 8.456022229690722\n",
      "resetting env. episode reward total was 7.0. running mean: 8.441462007393815\n",
      "resetting env. episode reward total was 13.0. running mean: 8.487047387319878\n",
      "resetting env. episode reward total was 8.0. running mean: 8.48217691344668\n",
      "resetting env. episode reward total was 11.0. running mean: 8.507355144312212\n",
      "resetting env. episode reward total was 10.0. running mean: 8.52228159286909\n",
      "resetting env. episode reward total was 9.0. running mean: 8.527058776940398\n",
      "resetting env. episode reward total was 17.0. running mean: 8.611788189170994\n",
      "resetting env. episode reward total was 3.0. running mean: 8.555670307279284\n",
      "resetting env. episode reward total was 8.0. running mean: 8.55011360420649\n",
      "resetting env. episode reward total was 1.0. running mean: 8.474612468164425\n",
      "resetting env. episode reward total was 18.0. running mean: 8.569866343482781\n",
      "resetting env. episode reward total was 8.0. running mean: 8.564167680047953\n",
      "resetting env. episode reward total was 13.0. running mean: 8.608526003247475\n",
      "resetting env. episode reward total was 2.0. running mean: 8.542440743215\n",
      "resetting env. episode reward total was 11.0. running mean: 8.56701633578285\n",
      "resetting env. episode reward total was 17.0. running mean: 8.65134617242502\n",
      "resetting env. episode reward total was 14.0. running mean: 8.70483271070077\n",
      "resetting env. episode reward total was 10.0. running mean: 8.717784383593763\n",
      "resetting env. episode reward total was -2.0. running mean: 8.610606539757825\n",
      "resetting env. episode reward total was 13.0. running mean: 8.654500474360248\n",
      "resetting env. episode reward total was 5.0. running mean: 8.617955469616646\n",
      "resetting env. episode reward total was 11.0. running mean: 8.64177591492048\n",
      "resetting env. episode reward total was 2.0. running mean: 8.575358155771275\n",
      "resetting env. episode reward total was 3.0. running mean: 8.519604574213561\n",
      "resetting env. episode reward total was 9.0. running mean: 8.524408528471426\n",
      "resetting env. episode reward total was 2.0. running mean: 8.459164443186712\n",
      "resetting env. episode reward total was 6.0. running mean: 8.434572798754845\n",
      "resetting env. episode reward total was 6.0. running mean: 8.410227070767297\n",
      "resetting env. episode reward total was 10.0. running mean: 8.426124800059624\n",
      "resetting env. episode reward total was 9.0. running mean: 8.431863552059028\n",
      "resetting env. episode reward total was 16.0. running mean: 8.507544916538437\n",
      "resetting env. episode reward total was 12.0. running mean: 8.542469467373053\n",
      "resetting env. episode reward total was 4.0. running mean: 8.497044772699322\n",
      "resetting env. episode reward total was 4.0. running mean: 8.452074324972328\n",
      "resetting env. episode reward total was 7.0. running mean: 8.437553581722606\n",
      "resetting env. episode reward total was 7.0. running mean: 8.423178045905379\n",
      "resetting env. episode reward total was 4.0. running mean: 8.378946265446324\n",
      "resetting env. episode reward total was 7.0. running mean: 8.36515680279186\n",
      "resetting env. episode reward total was 10.0. running mean: 8.38150523476394\n",
      "resetting env. episode reward total was 12.0. running mean: 8.417690182416301\n",
      "resetting env. episode reward total was 14.0. running mean: 8.473513280592138\n",
      "resetting env. episode reward total was 11.0. running mean: 8.498778147786217\n",
      "resetting env. episode reward total was 3.0. running mean: 8.443790366308354\n",
      "resetting env. episode reward total was 8.0. running mean: 8.439352462645271\n",
      "resetting env. episode reward total was 8.0. running mean: 8.434958938018818\n",
      "resetting env. episode reward total was 6.0. running mean: 8.41060934863863\n",
      "resetting env. episode reward total was 7.0. running mean: 8.396503255152243\n",
      "resetting env. episode reward total was 11.0. running mean: 8.42253822260072\n",
      "resetting env. episode reward total was -2.0. running mean: 8.318312840374713\n",
      "resetting env. episode reward total was 11.0. running mean: 8.345129711970964\n",
      "resetting env. episode reward total was 8.0. running mean: 8.341678414851254\n",
      "resetting env. episode reward total was 4.0. running mean: 8.29826163070274\n",
      "resetting env. episode reward total was 6.0. running mean: 8.275279014395712\n",
      "resetting env. episode reward total was 6.0. running mean: 8.252526224251756\n",
      "resetting env. episode reward total was 7.0. running mean: 8.240000962009239\n",
      "resetting env. episode reward total was 12.0. running mean: 8.277600952389145\n",
      "resetting env. episode reward total was 5.0. running mean: 8.244824942865254\n",
      "resetting env. episode reward total was 11.0. running mean: 8.2723766934366\n",
      "resetting env. episode reward total was 1.0. running mean: 8.199652926502234\n",
      "resetting env. episode reward total was -5.0. running mean: 8.06765639723721\n",
      "resetting env. episode reward total was 12.0. running mean: 8.106979833264838\n",
      "resetting env. episode reward total was 12.0. running mean: 8.145910034932188\n",
      "resetting env. episode reward total was -2.0. running mean: 8.044450934582866\n",
      "resetting env. episode reward total was 8.0. running mean: 8.044006425237036\n",
      "resetting env. episode reward total was 7.0. running mean: 8.033566360984665\n",
      "resetting env. episode reward total was 9.0. running mean: 8.043230697374819\n",
      "resetting env. episode reward total was 3.0. running mean: 7.99279839040107\n",
      "resetting env. episode reward total was 15.0. running mean: 8.06287040649706\n",
      "resetting env. episode reward total was 11.0. running mean: 8.092241702432089\n",
      "resetting env. episode reward total was 8.0. running mean: 8.091319285407769\n",
      "resetting env. episode reward total was -8.0. running mean: 7.9304060925536906\n",
      "resetting env. episode reward total was 8.0. running mean: 7.9311020316281535\n",
      "resetting env. episode reward total was 11.0. running mean: 7.961791011311872\n",
      "resetting env. episode reward total was 17.0. running mean: 8.052173101198754\n",
      "resetting env. episode reward total was 4.0. running mean: 8.011651370186765\n",
      "resetting env. episode reward total was 14.0. running mean: 8.071534856484897\n",
      "resetting env. episode reward total was 7.0. running mean: 8.060819507920048\n",
      "resetting env. episode reward total was 9.0. running mean: 8.070211312840847\n",
      "resetting env. episode reward total was 7.0. running mean: 8.059509199712439\n",
      "resetting env. episode reward total was 7.0. running mean: 8.048914107715314\n",
      "resetting env. episode reward total was 1.0. running mean: 7.97842496663816\n",
      "resetting env. episode reward total was 12.0. running mean: 8.018640716971777\n",
      "resetting env. episode reward total was 8.0. running mean: 8.01845430980206\n",
      "resetting env. episode reward total was 6.0. running mean: 7.9982697667040386\n",
      "resetting env. episode reward total was 15.0. running mean: 8.068287069036998\n",
      "resetting env. episode reward total was 10.0. running mean: 8.087604198346629\n",
      "resetting env. episode reward total was 13.0. running mean: 8.136728156363164\n",
      "resetting env. episode reward total was 3.0. running mean: 8.085360874799532\n",
      "resetting env. episode reward total was 4.0. running mean: 8.044507266051536\n",
      "resetting env. episode reward total was 3.0. running mean: 7.994062193391021\n",
      "resetting env. episode reward total was 16.0. running mean: 8.07412157145711\n",
      "resetting env. episode reward total was 1.0. running mean: 8.00338035574254\n",
      "resetting env. episode reward total was 2.0. running mean: 7.943346552185114\n",
      "resetting env. episode reward total was 4.0. running mean: 7.9039130866632625\n",
      "resetting env. episode reward total was 15.0. running mean: 7.97487395579663\n",
      "resetting env. episode reward total was 8.0. running mean: 7.975125216238664\n",
      "resetting env. episode reward total was 4.0. running mean: 7.935373964076277\n",
      "resetting env. episode reward total was 15.0. running mean: 8.006020224435513\n",
      "resetting env. episode reward total was 11.0. running mean: 8.035960022191158\n",
      "resetting env. episode reward total was 8.0. running mean: 8.035600421969246\n",
      "resetting env. episode reward total was 7.0. running mean: 8.025244417749553\n",
      "resetting env. episode reward total was 7.0. running mean: 8.014991973572057\n",
      "resetting env. episode reward total was 4.0. running mean: 7.974842053836336\n",
      "resetting env. episode reward total was 10.0. running mean: 7.995093633297972\n",
      "resetting env. episode reward total was 9.0. running mean: 8.005142696964992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 8.055091269995343\n",
      "resetting env. episode reward total was 7.0. running mean: 8.04454035729539\n",
      "resetting env. episode reward total was 6.0. running mean: 8.024094953722436\n",
      "resetting env. episode reward total was 11.0. running mean: 8.053854004185212\n",
      "resetting env. episode reward total was 14.0. running mean: 8.11331546414336\n",
      "resetting env. episode reward total was 5.0. running mean: 8.082182309501928\n",
      "resetting env. episode reward total was 14.0. running mean: 8.141360486406908\n",
      "resetting env. episode reward total was 2.0. running mean: 8.079946881542838\n",
      "resetting env. episode reward total was 5.0. running mean: 8.049147412727411\n",
      "resetting env. episode reward total was 12.0. running mean: 8.088655938600137\n",
      "resetting env. episode reward total was 14.0. running mean: 8.147769379214136\n",
      "resetting env. episode reward total was -3.0. running mean: 8.036291685421995\n",
      "resetting env. episode reward total was 16.0. running mean: 8.115928768567775\n",
      "resetting env. episode reward total was 17.0. running mean: 8.204769480882097\n",
      "resetting env. episode reward total was 8.0. running mean: 8.202721786073276\n",
      "resetting env. episode reward total was 9.0. running mean: 8.210694568212544\n",
      "resetting env. episode reward total was 9.0. running mean: 8.218587622530418\n",
      "resetting env. episode reward total was 9.0. running mean: 8.226401746305113\n",
      "resetting env. episode reward total was -6.0. running mean: 8.08413772884206\n",
      "resetting env. episode reward total was 5.0. running mean: 8.05329635155364\n",
      "resetting env. episode reward total was 8.0. running mean: 8.052763388038104\n",
      "resetting env. episode reward total was 13.0. running mean: 8.102235754157723\n",
      "resetting env. episode reward total was 10.0. running mean: 8.121213396616145\n",
      "resetting env. episode reward total was 11.0. running mean: 8.150001262649983\n",
      "resetting env. episode reward total was 12.0. running mean: 8.188501250023483\n",
      "resetting env. episode reward total was -2.0. running mean: 8.086616237523248\n",
      "resetting env. episode reward total was -3.0. running mean: 7.975750075148016\n",
      "resetting env. episode reward total was 6.0. running mean: 7.955992574396536\n",
      "resetting env. episode reward total was 13.0. running mean: 8.00643264865257\n",
      "resetting env. episode reward total was 4.0. running mean: 7.966368322166044\n",
      "resetting env. episode reward total was 8.0. running mean: 7.966704638944384\n",
      "resetting env. episode reward total was 5.0. running mean: 7.9370375925549395\n",
      "resetting env. episode reward total was 10.0. running mean: 7.95766721662939\n",
      "resetting env. episode reward total was 15.0. running mean: 8.028090544463096\n",
      "resetting env. episode reward total was 17.0. running mean: 8.117809639018464\n",
      "resetting env. episode reward total was 3.0. running mean: 8.06663154262828\n",
      "resetting env. episode reward total was 14.0. running mean: 8.125965227201997\n",
      "resetting env. episode reward total was 7.0. running mean: 8.114705574929976\n",
      "resetting env. episode reward total was -5.0. running mean: 7.983558519180677\n",
      "resetting env. episode reward total was 17.0. running mean: 8.07372293398887\n",
      "resetting env. episode reward total was -1.0. running mean: 7.982985704648982\n",
      "resetting env. episode reward total was 6.0. running mean: 7.963155847602492\n",
      "resetting env. episode reward total was 9.0. running mean: 7.973524289126467\n",
      "resetting env. episode reward total was 11.0. running mean: 8.003789046235202\n",
      "resetting env. episode reward total was 14.0. running mean: 8.06375115577285\n",
      "resetting env. episode reward total was 16.0. running mean: 8.143113644215122\n",
      "resetting env. episode reward total was 6.0. running mean: 8.12168250777297\n",
      "resetting env. episode reward total was 9.0. running mean: 8.13046568269524\n",
      "resetting env. episode reward total was 5.0. running mean: 8.099161025868288\n",
      "resetting env. episode reward total was 7.0. running mean: 8.088169415609604\n",
      "resetting env. episode reward total was 8.0. running mean: 8.087287721453508\n",
      "resetting env. episode reward total was 11.0. running mean: 8.116414844238973\n",
      "resetting env. episode reward total was 5.0. running mean: 8.085250695796583\n",
      "resetting env. episode reward total was 5.0. running mean: 8.054398188838618\n",
      "resetting env. episode reward total was 10.0. running mean: 8.073854206950232\n",
      "resetting env. episode reward total was 6.0. running mean: 8.05311566488073\n",
      "resetting env. episode reward total was 14.0. running mean: 8.112584508231922\n",
      "resetting env. episode reward total was 13.0. running mean: 8.161458663149604\n",
      "resetting env. episode reward total was 10.0. running mean: 8.179844076518108\n",
      "resetting env. episode reward total was -3.0. running mean: 8.068045635752927\n",
      "resetting env. episode reward total was 6.0. running mean: 8.047365179395397\n",
      "resetting env. episode reward total was 11.0. running mean: 8.076891527601443\n",
      "resetting env. episode reward total was 8.0. running mean: 8.076122612325427\n",
      "resetting env. episode reward total was 14.0. running mean: 8.135361386202174\n",
      "resetting env. episode reward total was -1.0. running mean: 8.044007772340152\n",
      "resetting env. episode reward total was 9.0. running mean: 8.053567694616751\n",
      "resetting env. episode reward total was 8.0. running mean: 8.053032017670583\n",
      "resetting env. episode reward total was 9.0. running mean: 8.062501697493877\n",
      "resetting env. episode reward total was 10.0. running mean: 8.081876680518938\n",
      "resetting env. episode reward total was 3.0. running mean: 8.031057913713749\n",
      "resetting env. episode reward total was 16.0. running mean: 8.110747334576612\n",
      "resetting env. episode reward total was 4.0. running mean: 8.069639861230845\n",
      "resetting env. episode reward total was 11.0. running mean: 8.098943462618537\n",
      "resetting env. episode reward total was 5.0. running mean: 8.067954027992354\n",
      "resetting env. episode reward total was 9.0. running mean: 8.07727448771243\n",
      "resetting env. episode reward total was 5.0. running mean: 8.046501742835305\n",
      "resetting env. episode reward total was 12.0. running mean: 8.086036725406952\n",
      "resetting env. episode reward total was 8.0. running mean: 8.085176358152882\n",
      "resetting env. episode reward total was -1.0. running mean: 7.994324594571353\n",
      "resetting env. episode reward total was 10.0. running mean: 8.014381348625639\n",
      "resetting env. episode reward total was 10.0. running mean: 8.034237535139383\n",
      "resetting env. episode reward total was 6.0. running mean: 8.013895159787989\n",
      "resetting env. episode reward total was 8.0. running mean: 8.013756208190108\n",
      "resetting env. episode reward total was 10.0. running mean: 8.033618646108206\n",
      "resetting env. episode reward total was 11.0. running mean: 8.063282459647123\n",
      "resetting env. episode reward total was 11.0. running mean: 8.092649635050652\n",
      "resetting env. episode reward total was 14.0. running mean: 8.151723138700145\n",
      "resetting env. episode reward total was 11.0. running mean: 8.180205907313143\n",
      "resetting env. episode reward total was 3.0. running mean: 8.12840384824001\n",
      "resetting env. episode reward total was 7.0. running mean: 8.117119809757611\n",
      "resetting env. episode reward total was 11.0. running mean: 8.145948611660033\n",
      "resetting env. episode reward total was 9.0. running mean: 8.154489125543433\n",
      "resetting env. episode reward total was 8.0. running mean: 8.152944234287999\n",
      "resetting env. episode reward total was 5.0. running mean: 8.121414791945119\n",
      "resetting env. episode reward total was 19.0. running mean: 8.230200644025667\n",
      "resetting env. episode reward total was 6.0. running mean: 8.20789863758541\n",
      "resetting env. episode reward total was 15.0. running mean: 8.275819651209556\n",
      "resetting env. episode reward total was 15.0. running mean: 8.34306145469746\n",
      "resetting env. episode reward total was 2.0. running mean: 8.279630840150485\n",
      "resetting env. episode reward total was 14.0. running mean: 8.33683453174898\n",
      "resetting env. episode reward total was 11.0. running mean: 8.36346618643149\n",
      "resetting env. episode reward total was 10.0. running mean: 8.379831524567175\n",
      "resetting env. episode reward total was 4.0. running mean: 8.336033209321503\n",
      "resetting env. episode reward total was 11.0. running mean: 8.362672877228286\n",
      "resetting env. episode reward total was 17.0. running mean: 8.449046148456004\n",
      "resetting env. episode reward total was 10.0. running mean: 8.464555686971444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 17.0. running mean: 8.549910130101729\n",
      "resetting env. episode reward total was 9.0. running mean: 8.554411028800711\n",
      "resetting env. episode reward total was 13.0. running mean: 8.598866918512705\n",
      "resetting env. episode reward total was 18.0. running mean: 8.692878249327578\n",
      "resetting env. episode reward total was 8.0. running mean: 8.685949466834302\n",
      "resetting env. episode reward total was 1.0. running mean: 8.60908997216596\n",
      "resetting env. episode reward total was 7.0. running mean: 8.5929990724443\n",
      "resetting env. episode reward total was 8.0. running mean: 8.587069081719857\n",
      "resetting env. episode reward total was 4.0. running mean: 8.541198390902657\n",
      "resetting env. episode reward total was 2.0. running mean: 8.475786406993631\n",
      "resetting env. episode reward total was 5.0. running mean: 8.441028542923695\n",
      "resetting env. episode reward total was 9.0. running mean: 8.446618257494457\n",
      "resetting env. episode reward total was 13.0. running mean: 8.492152074919513\n",
      "resetting env. episode reward total was 12.0. running mean: 8.527230554170318\n",
      "resetting env. episode reward total was 9.0. running mean: 8.531958248628614\n",
      "resetting env. episode reward total was 10.0. running mean: 8.546638666142327\n",
      "resetting env. episode reward total was -3.0. running mean: 8.431172279480904\n",
      "resetting env. episode reward total was 8.0. running mean: 8.426860556686096\n",
      "resetting env. episode reward total was 2.0. running mean: 8.362591951119235\n",
      "resetting env. episode reward total was 11.0. running mean: 8.388966031608042\n",
      "resetting env. episode reward total was 9.0. running mean: 8.395076371291962\n",
      "resetting env. episode reward total was 6.0. running mean: 8.371125607579042\n",
      "resetting env. episode reward total was -7.0. running mean: 8.217414351503251\n",
      "resetting env. episode reward total was 3.0. running mean: 8.165240207988218\n",
      "resetting env. episode reward total was 10.0. running mean: 8.183587805908335\n",
      "resetting env. episode reward total was 12.0. running mean: 8.221751927849251\n",
      "resetting env. episode reward total was 7.0. running mean: 8.20953440857076\n",
      "resetting env. episode reward total was 5.0. running mean: 8.177439064485052\n",
      "resetting env. episode reward total was 12.0. running mean: 8.2156646738402\n",
      "resetting env. episode reward total was 3.0. running mean: 8.163508027101797\n",
      "resetting env. episode reward total was 12.0. running mean: 8.201872946830777\n",
      "resetting env. episode reward total was 12.0. running mean: 8.239854217362469\n",
      "resetting env. episode reward total was 14.0. running mean: 8.297455675188845\n",
      "resetting env. episode reward total was 6.0. running mean: 8.274481118436956\n",
      "resetting env. episode reward total was 11.0. running mean: 8.301736307252586\n",
      "resetting env. episode reward total was 16.0. running mean: 8.37871894418006\n",
      "resetting env. episode reward total was 12.0. running mean: 8.414931754738259\n",
      "resetting env. episode reward total was 10.0. running mean: 8.430782437190876\n",
      "resetting env. episode reward total was 5.0. running mean: 8.396474612818968\n",
      "resetting env. episode reward total was 2.0. running mean: 8.332509866690778\n",
      "resetting env. episode reward total was 10.0. running mean: 8.34918476802387\n",
      "resetting env. episode reward total was 8.0. running mean: 8.34569292034363\n",
      "resetting env. episode reward total was 7.0. running mean: 8.332235991140195\n",
      "resetting env. episode reward total was 3.0. running mean: 8.278913631228791\n",
      "resetting env. episode reward total was 14.0. running mean: 8.336124494916504\n",
      "resetting env. episode reward total was 7.0. running mean: 8.32276324996734\n",
      "resetting env. episode reward total was 5.0. running mean: 8.289535617467667\n",
      "resetting env. episode reward total was 6.0. running mean: 8.266640261292991\n",
      "resetting env. episode reward total was 1.0. running mean: 8.193973858680062\n",
      "resetting env. episode reward total was -4.0. running mean: 8.072034120093262\n",
      "resetting env. episode reward total was 12.0. running mean: 8.11131377889233\n",
      "resetting env. episode reward total was 7.0. running mean: 8.100200641103406\n",
      "resetting env. episode reward total was -5.0. running mean: 7.969198634692373\n",
      "resetting env. episode reward total was 7.0. running mean: 7.9595066483454495\n",
      "resetting env. episode reward total was 13.0. running mean: 8.009911581861996\n",
      "resetting env. episode reward total was 8.0. running mean: 8.009812466043375\n",
      "resetting env. episode reward total was 10.0. running mean: 8.029714341382942\n",
      "resetting env. episode reward total was 12.0. running mean: 8.069417197969113\n",
      "resetting env. episode reward total was 9.0. running mean: 8.078723025989422\n",
      "resetting env. episode reward total was 11.0. running mean: 8.107935795729528\n",
      "resetting env. episode reward total was 3.0. running mean: 8.056856437772232\n",
      "resetting env. episode reward total was 8.0. running mean: 8.05628787339451\n",
      "resetting env. episode reward total was 12.0. running mean: 8.095724994660564\n",
      "resetting env. episode reward total was 14.0. running mean: 8.15476774471396\n",
      "resetting env. episode reward total was -9.0. running mean: 7.983220067266821\n",
      "resetting env. episode reward total was 12.0. running mean: 8.023387866594152\n",
      "resetting env. episode reward total was 14.0. running mean: 8.083153987928211\n",
      "resetting env. episode reward total was 4.0. running mean: 8.042322448048928\n",
      "resetting env. episode reward total was 16.0. running mean: 8.12189922356844\n",
      "resetting env. episode reward total was 12.0. running mean: 8.160680231332755\n",
      "resetting env. episode reward total was 7.0. running mean: 8.149073429019428\n",
      "resetting env. episode reward total was -3.0. running mean: 8.037582694729235\n",
      "resetting env. episode reward total was 5.0. running mean: 8.007206867781942\n",
      "resetting env. episode reward total was 8.0. running mean: 8.007134799104122\n",
      "resetting env. episode reward total was -3.0. running mean: 7.89706345111308\n",
      "resetting env. episode reward total was 8.0. running mean: 7.89809281660195\n",
      "resetting env. episode reward total was 10.0. running mean: 7.91911188843593\n",
      "resetting env. episode reward total was 13.0. running mean: 7.969920769551571\n",
      "resetting env. episode reward total was 16.0. running mean: 8.050221561856056\n",
      "resetting env. episode reward total was 15.0. running mean: 8.119719346237495\n",
      "resetting env. episode reward total was 11.0. running mean: 8.14852215277512\n",
      "resetting env. episode reward total was 6.0. running mean: 8.12703693124737\n",
      "resetting env. episode reward total was 7.0. running mean: 8.115766561934896\n",
      "resetting env. episode reward total was 15.0. running mean: 8.184608896315547\n",
      "resetting env. episode reward total was 3.0. running mean: 8.13276280735239\n",
      "resetting env. episode reward total was 7.0. running mean: 8.121435179278867\n",
      "resetting env. episode reward total was -1.0. running mean: 8.03022082748608\n",
      "resetting env. episode reward total was 7.0. running mean: 8.019918619211218\n",
      "resetting env. episode reward total was 6.0. running mean: 7.999719433019106\n",
      "resetting env. episode reward total was 4.0. running mean: 7.959722238688915\n",
      "resetting env. episode reward total was -3.0. running mean: 7.850125016302026\n",
      "resetting env. episode reward total was 11.0. running mean: 7.881623766139006\n",
      "resetting env. episode reward total was 8.0. running mean: 7.882807528477616\n",
      "resetting env. episode reward total was 10.0. running mean: 7.903979453192839\n",
      "resetting env. episode reward total was 5.0. running mean: 7.874939658660911\n",
      "resetting env. episode reward total was 17.0. running mean: 7.966190262074302\n",
      "resetting env. episode reward total was 6.0. running mean: 7.946528359453558\n",
      "resetting env. episode reward total was 4.0. running mean: 7.907063075859023\n",
      "resetting env. episode reward total was 11.0. running mean: 7.937992445100433\n",
      "resetting env. episode reward total was 8.0. running mean: 7.938612520649429\n",
      "resetting env. episode reward total was 15.0. running mean: 8.009226395442935\n",
      "resetting env. episode reward total was 7.0. running mean: 7.999134131488506\n",
      "resetting env. episode reward total was 11.0. running mean: 8.029142790173621\n",
      "resetting env. episode reward total was 13.0. running mean: 8.078851362271886\n",
      "resetting env. episode reward total was 13.0. running mean: 8.128062848649167\n",
      "resetting env. episode reward total was 7.0. running mean: 8.116782220162676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 8.13561439796105\n",
      "resetting env. episode reward total was 2.0. running mean: 8.074258253981439\n",
      "resetting env. episode reward total was 10.0. running mean: 8.093515671441624\n",
      "resetting env. episode reward total was 15.0. running mean: 8.162580514727209\n",
      "resetting env. episode reward total was 7.0. running mean: 8.150954709579937\n",
      "resetting env. episode reward total was 11.0. running mean: 8.179445162484136\n",
      "resetting env. episode reward total was 5.0. running mean: 8.147650710859295\n",
      "resetting env. episode reward total was 6.0. running mean: 8.126174203750702\n",
      "resetting env. episode reward total was 11.0. running mean: 8.154912461713195\n",
      "resetting env. episode reward total was -5.0. running mean: 8.023363337096063\n",
      "resetting env. episode reward total was 13.0. running mean: 8.073129703725103\n",
      "resetting env. episode reward total was 9.0. running mean: 8.082398406687853\n",
      "resetting env. episode reward total was 3.0. running mean: 8.031574422620974\n",
      "resetting env. episode reward total was 7.0. running mean: 8.021258678394764\n",
      "resetting env. episode reward total was 8.0. running mean: 8.021046091610815\n",
      "resetting env. episode reward total was 12.0. running mean: 8.060835630694706\n",
      "resetting env. episode reward total was 8.0. running mean: 8.060227274387758\n",
      "resetting env. episode reward total was 7.0. running mean: 8.04962500164388\n",
      "resetting env. episode reward total was 3.0. running mean: 7.999128751627442\n",
      "resetting env. episode reward total was 12.0. running mean: 8.039137464111167\n",
      "resetting env. episode reward total was 8.0. running mean: 8.038746089470056\n",
      "resetting env. episode reward total was 17.0. running mean: 8.128358628575356\n",
      "resetting env. episode reward total was -2.0. running mean: 8.027075042289603\n",
      "resetting env. episode reward total was -2.0. running mean: 7.926804291866707\n",
      "resetting env. episode reward total was 12.0. running mean: 7.967536248948041\n",
      "resetting env. episode reward total was 11.0. running mean: 7.997860886458561\n",
      "resetting env. episode reward total was 12.0. running mean: 8.037882277593974\n",
      "resetting env. episode reward total was 12.0. running mean: 8.077503454818034\n",
      "resetting env. episode reward total was 7.0. running mean: 8.066728420269854\n",
      "resetting env. episode reward total was 1.0. running mean: 7.996061136067155\n",
      "resetting env. episode reward total was 10.0. running mean: 8.016100524706484\n",
      "resetting env. episode reward total was 15.0. running mean: 8.08593951945942\n",
      "resetting env. episode reward total was 12.0. running mean: 8.125080124264825\n",
      "resetting env. episode reward total was 6.0. running mean: 8.103829323022177\n",
      "resetting env. episode reward total was 10.0. running mean: 8.122791029791955\n",
      "resetting env. episode reward total was -7.0. running mean: 7.971563119494036\n",
      "resetting env. episode reward total was 12.0. running mean: 8.011847488299095\n",
      "resetting env. episode reward total was 9.0. running mean: 8.021729013416104\n",
      "resetting env. episode reward total was 11.0. running mean: 8.051511723281942\n",
      "resetting env. episode reward total was 13.0. running mean: 8.100996606049124\n",
      "resetting env. episode reward total was 11.0. running mean: 8.129986639988632\n",
      "resetting env. episode reward total was 14.0. running mean: 8.188686773588746\n",
      "resetting env. episode reward total was -2.0. running mean: 8.086799905852859\n",
      "resetting env. episode reward total was 9.0. running mean: 8.09593190679433\n",
      "resetting env. episode reward total was 5.0. running mean: 8.064972587726388\n",
      "resetting env. episode reward total was 10.0. running mean: 8.084322861849124\n",
      "resetting env. episode reward total was 12.0. running mean: 8.123479633230632\n",
      "resetting env. episode reward total was 11.0. running mean: 8.152244836898324\n",
      "resetting env. episode reward total was 10.0. running mean: 8.170722388529342\n",
      "resetting env. episode reward total was 14.0. running mean: 8.229015164644048\n",
      "resetting env. episode reward total was 11.0. running mean: 8.256725012997608\n",
      "resetting env. episode reward total was 14.0. running mean: 8.314157762867632\n",
      "resetting env. episode reward total was 4.0. running mean: 8.271016185238954\n",
      "resetting env. episode reward total was 18.0. running mean: 8.368306023386564\n",
      "resetting env. episode reward total was 10.0. running mean: 8.384622963152697\n",
      "resetting env. episode reward total was 12.0. running mean: 8.42077673352117\n",
      "resetting env. episode reward total was 10.0. running mean: 8.436568966185957\n",
      "resetting env. episode reward total was 10.0. running mean: 8.452203276524097\n",
      "resetting env. episode reward total was 9.0. running mean: 8.457681243758856\n",
      "resetting env. episode reward total was 3.0. running mean: 8.403104431321266\n",
      "resetting env. episode reward total was 10.0. running mean: 8.419073387008053\n",
      "resetting env. episode reward total was 17.0. running mean: 8.504882653137972\n",
      "resetting env. episode reward total was 14.0. running mean: 8.559833826606592\n",
      "resetting env. episode reward total was 7.0. running mean: 8.544235488340526\n",
      "resetting env. episode reward total was 10.0. running mean: 8.55879313345712\n",
      "resetting env. episode reward total was 10.0. running mean: 8.57320520212255\n",
      "resetting env. episode reward total was 15.0. running mean: 8.637473150101325\n",
      "resetting env. episode reward total was 3.0. running mean: 8.58109841860031\n",
      "resetting env. episode reward total was 6.0. running mean: 8.555287434414309\n",
      "resetting env. episode reward total was 13.0. running mean: 8.599734560070166\n",
      "resetting env. episode reward total was 7.0. running mean: 8.583737214469464\n",
      "resetting env. episode reward total was 10.0. running mean: 8.597899842324768\n",
      "resetting env. episode reward total was 7.0. running mean: 8.581920843901521\n",
      "resetting env. episode reward total was 11.0. running mean: 8.606101635462505\n",
      "resetting env. episode reward total was 8.0. running mean: 8.60004061910788\n",
      "resetting env. episode reward total was 10.0. running mean: 8.6140402129168\n",
      "resetting env. episode reward total was 3.0. running mean: 8.557899810787632\n",
      "resetting env. episode reward total was 15.0. running mean: 8.622320812679755\n",
      "resetting env. episode reward total was 12.0. running mean: 8.656097604552956\n",
      "resetting env. episode reward total was 11.0. running mean: 8.679536628507426\n",
      "resetting env. episode reward total was 4.0. running mean: 8.632741262222352\n",
      "resetting env. episode reward total was 15.0. running mean: 8.696413849600129\n",
      "resetting env. episode reward total was 13.0. running mean: 8.739449711104129\n",
      "resetting env. episode reward total was 14.0. running mean: 8.792055213993088\n",
      "resetting env. episode reward total was -2.0. running mean: 8.684134661853157\n",
      "resetting env. episode reward total was 6.0. running mean: 8.657293315234627\n",
      "resetting env. episode reward total was 10.0. running mean: 8.67072038208228\n",
      "resetting env. episode reward total was 14.0. running mean: 8.724013178261458\n",
      "resetting env. episode reward total was 8.0. running mean: 8.716773046478844\n",
      "resetting env. episode reward total was 1.0. running mean: 8.639605316014055\n",
      "resetting env. episode reward total was 12.0. running mean: 8.673209262853915\n",
      "resetting env. episode reward total was 13.0. running mean: 8.716477170225376\n",
      "resetting env. episode reward total was 6.0. running mean: 8.689312398523123\n",
      "resetting env. episode reward total was 7.0. running mean: 8.672419274537893\n",
      "resetting env. episode reward total was 2.0. running mean: 8.605695081792513\n",
      "resetting env. episode reward total was 15.0. running mean: 8.669638130974588\n",
      "resetting env. episode reward total was 12.0. running mean: 8.702941749664841\n",
      "resetting env. episode reward total was 6.0. running mean: 8.675912332168194\n",
      "resetting env. episode reward total was 4.0. running mean: 8.62915320884651\n",
      "resetting env. episode reward total was 10.0. running mean: 8.642861676758045\n",
      "resetting env. episode reward total was 14.0. running mean: 8.696433059990465\n",
      "resetting env. episode reward total was 7.0. running mean: 8.67946872939056\n",
      "resetting env. episode reward total was 8.0. running mean: 8.672674042096654\n",
      "resetting env. episode reward total was 1.0. running mean: 8.595947301675688\n",
      "resetting env. episode reward total was 12.0. running mean: 8.62998782865893\n",
      "resetting env. episode reward total was 13.0. running mean: 8.673687950372342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 8.626951070868618\n",
      "resetting env. episode reward total was 11.0. running mean: 8.650681560159931\n",
      "resetting env. episode reward total was 9.0. running mean: 8.654174744558333\n",
      "resetting env. episode reward total was 6.0. running mean: 8.62763299711275\n",
      "resetting env. episode reward total was 10.0. running mean: 8.641356667141622\n",
      "resetting env. episode reward total was 8.0. running mean: 8.634943100470206\n",
      "resetting env. episode reward total was -9.0. running mean: 8.458593669465504\n",
      "resetting env. episode reward total was 15.0. running mean: 8.52400773277085\n",
      "resetting env. episode reward total was 5.0. running mean: 8.48876765544314\n",
      "resetting env. episode reward total was 1.0. running mean: 8.413879978888708\n",
      "resetting env. episode reward total was 14.0. running mean: 8.469741179099822\n",
      "resetting env. episode reward total was 9.0. running mean: 8.475043767308824\n",
      "resetting env. episode reward total was 7.0. running mean: 8.460293329635736\n",
      "resetting env. episode reward total was 9.0. running mean: 8.465690396339378\n",
      "resetting env. episode reward total was 8.0. running mean: 8.461033492375984\n",
      "resetting env. episode reward total was 6.0. running mean: 8.436423157452225\n",
      "resetting env. episode reward total was 12.0. running mean: 8.472058925877702\n",
      "resetting env. episode reward total was 10.0. running mean: 8.487338336618924\n",
      "resetting env. episode reward total was -9.0. running mean: 8.312464953252736\n",
      "resetting env. episode reward total was 12.0. running mean: 8.349340303720208\n",
      "resetting env. episode reward total was -3.0. running mean: 8.235846900683006\n",
      "resetting env. episode reward total was 7.0. running mean: 8.223488431676175\n",
      "resetting env. episode reward total was 11.0. running mean: 8.251253547359413\n",
      "resetting env. episode reward total was 4.0. running mean: 8.208741011885818\n",
      "resetting env. episode reward total was 6.0. running mean: 8.186653601766961\n",
      "resetting env. episode reward total was 9.0. running mean: 8.194787065749292\n",
      "resetting env. episode reward total was 12.0. running mean: 8.232839195091799\n",
      "resetting env. episode reward total was 3.0. running mean: 8.18051080314088\n",
      "resetting env. episode reward total was 15.0. running mean: 8.248705695109471\n",
      "resetting env. episode reward total was 13.0. running mean: 8.296218638158377\n",
      "resetting env. episode reward total was 6.0. running mean: 8.273256451776794\n",
      "resetting env. episode reward total was 14.0. running mean: 8.330523887259027\n",
      "resetting env. episode reward total was 6.0. running mean: 8.307218648386437\n",
      "resetting env. episode reward total was 5.0. running mean: 8.274146461902573\n",
      "resetting env. episode reward total was 10.0. running mean: 8.291404997283546\n",
      "resetting env. episode reward total was 15.0. running mean: 8.358490947310711\n",
      "resetting env. episode reward total was 8.0. running mean: 8.354906037837605\n",
      "resetting env. episode reward total was 10.0. running mean: 8.371356977459229\n",
      "resetting env. episode reward total was 2.0. running mean: 8.307643407684635\n",
      "resetting env. episode reward total was 8.0. running mean: 8.30456697360779\n",
      "resetting env. episode reward total was 17.0. running mean: 8.391521303871711\n",
      "resetting env. episode reward total was 18.0. running mean: 8.487606090832994\n",
      "resetting env. episode reward total was 4.0. running mean: 8.442730029924663\n",
      "resetting env. episode reward total was 14.0. running mean: 8.498302729625417\n",
      "resetting env. episode reward total was 12.0. running mean: 8.533319702329162\n",
      "resetting env. episode reward total was 10.0. running mean: 8.54798650530587\n",
      "resetting env. episode reward total was 3.0. running mean: 8.492506640252811\n",
      "resetting env. episode reward total was 2.0. running mean: 8.427581573850283\n",
      "resetting env. episode reward total was 9.0. running mean: 8.43330575811178\n",
      "resetting env. episode reward total was 9.0. running mean: 8.438972700530663\n",
      "resetting env. episode reward total was 14.0. running mean: 8.494582973525356\n",
      "resetting env. episode reward total was 11.0. running mean: 8.519637143790101\n",
      "resetting env. episode reward total was 14.0. running mean: 8.574440772352201\n",
      "resetting env. episode reward total was 16.0. running mean: 8.648696364628679\n",
      "resetting env. episode reward total was 14.0. running mean: 8.702209400982392\n",
      "resetting env. episode reward total was 9.0. running mean: 8.705187306972569\n",
      "resetting env. episode reward total was 14.0. running mean: 8.758135433902844\n",
      "resetting env. episode reward total was 6.0. running mean: 8.730554079563815\n",
      "resetting env. episode reward total was 11.0. running mean: 8.753248538768176\n",
      "resetting env. episode reward total was 7.0. running mean: 8.735716053380495\n",
      "resetting env. episode reward total was 1.0. running mean: 8.658358892846689\n",
      "resetting env. episode reward total was 15.0. running mean: 8.721775303918221\n",
      "resetting env. episode reward total was 11.0. running mean: 8.744557550879039\n",
      "resetting env. episode reward total was 3.0. running mean: 8.687111975370248\n",
      "resetting env. episode reward total was 11.0. running mean: 8.710240855616545\n",
      "resetting env. episode reward total was 12.0. running mean: 8.74313844706038\n",
      "resetting env. episode reward total was 4.0. running mean: 8.695707062589776\n",
      "resetting env. episode reward total was 2.0. running mean: 8.628749991963877\n",
      "resetting env. episode reward total was 12.0. running mean: 8.662462492044238\n",
      "resetting env. episode reward total was 5.0. running mean: 8.625837867123796\n",
      "resetting env. episode reward total was 13.0. running mean: 8.669579488452559\n",
      "resetting env. episode reward total was 17.0. running mean: 8.752883693568034\n",
      "resetting env. episode reward total was 6.0. running mean: 8.725354856632354\n",
      "resetting env. episode reward total was 8.0. running mean: 8.71810130806603\n",
      "resetting env. episode reward total was -11.0. running mean: 8.52092029498537\n",
      "resetting env. episode reward total was 9.0. running mean: 8.525711092035516\n",
      "resetting env. episode reward total was -5.0. running mean: 8.39045398111516\n",
      "resetting env. episode reward total was 6.0. running mean: 8.36654944130401\n",
      "resetting env. episode reward total was -1.0. running mean: 8.27288394689097\n",
      "resetting env. episode reward total was 14.0. running mean: 8.33015510742206\n",
      "resetting env. episode reward total was 9.0. running mean: 8.336853556347839\n",
      "resetting env. episode reward total was 5.0. running mean: 8.303485020784361\n",
      "resetting env. episode reward total was 1.0. running mean: 8.230450170576518\n",
      "resetting env. episode reward total was -1.0. running mean: 8.138145668870752\n",
      "resetting env. episode reward total was 15.0. running mean: 8.206764212182046\n",
      "resetting env. episode reward total was 9.0. running mean: 8.214696570060225\n",
      "resetting env. episode reward total was 10.0. running mean: 8.232549604359622\n",
      "resetting env. episode reward total was 14.0. running mean: 8.290224108316027\n",
      "resetting env. episode reward total was 6.0. running mean: 8.267321867232868\n",
      "resetting env. episode reward total was 13.0. running mean: 8.31464864856054\n",
      "resetting env. episode reward total was 11.0. running mean: 8.341502162074935\n",
      "resetting env. episode reward total was 9.0. running mean: 8.348087140454185\n",
      "resetting env. episode reward total was 12.0. running mean: 8.384606269049643\n",
      "resetting env. episode reward total was 2.0. running mean: 8.320760206359147\n",
      "resetting env. episode reward total was 13.0. running mean: 8.367552604295556\n",
      "resetting env. episode reward total was 15.0. running mean: 8.4338770782526\n",
      "resetting env. episode reward total was 6.0. running mean: 8.409538307470074\n",
      "resetting env. episode reward total was 4.0. running mean: 8.365442924395373\n",
      "resetting env. episode reward total was 3.0. running mean: 8.311788495151418\n",
      "resetting env. episode reward total was 10.0. running mean: 8.328670610199904\n",
      "resetting env. episode reward total was 15.0. running mean: 8.395383904097905\n",
      "resetting env. episode reward total was 13.0. running mean: 8.441430065056926\n",
      "resetting env. episode reward total was 10.0. running mean: 8.457015764406355\n",
      "resetting env. episode reward total was 13.0. running mean: 8.502445606762292\n",
      "resetting env. episode reward total was 7.0. running mean: 8.487421150694669\n",
      "resetting env. episode reward total was 9.0. running mean: 8.492546939187722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 8.447621469795845\n",
      "resetting env. episode reward total was 14.0. running mean: 8.503145255097886\n",
      "resetting env. episode reward total was 10.0. running mean: 8.518113802546907\n",
      "resetting env. episode reward total was 14.0. running mean: 8.572932664521439\n",
      "resetting env. episode reward total was 16.0. running mean: 8.647203337876224\n",
      "resetting env. episode reward total was 6.0. running mean: 8.620731304497463\n",
      "resetting env. episode reward total was 8.0. running mean: 8.614523991452488\n",
      "resetting env. episode reward total was 6.0. running mean: 8.588378751537963\n",
      "resetting env. episode reward total was 8.0. running mean: 8.582494964022583\n",
      "resetting env. episode reward total was 6.0. running mean: 8.556670014382357\n",
      "resetting env. episode reward total was 5.0. running mean: 8.521103314238534\n",
      "resetting env. episode reward total was 6.0. running mean: 8.495892281096149\n",
      "resetting env. episode reward total was 11.0. running mean: 8.520933358285186\n",
      "resetting env. episode reward total was 7.0. running mean: 8.505724024702333\n",
      "resetting env. episode reward total was 11.0. running mean: 8.53066678445531\n",
      "resetting env. episode reward total was 9.0. running mean: 8.535360116610756\n",
      "resetting env. episode reward total was 6.0. running mean: 8.510006515444648\n",
      "resetting env. episode reward total was 7.0. running mean: 8.494906450290202\n",
      "resetting env. episode reward total was 15.0. running mean: 8.5599573857873\n",
      "resetting env. episode reward total was 12.0. running mean: 8.594357811929425\n",
      "resetting env. episode reward total was 10.0. running mean: 8.60841423381013\n",
      "resetting env. episode reward total was 11.0. running mean: 8.632330091472028\n",
      "resetting env. episode reward total was 2.0. running mean: 8.566006790557307\n",
      "resetting env. episode reward total was 13.0. running mean: 8.610346722651734\n",
      "resetting env. episode reward total was 7.0. running mean: 8.594243255425217\n",
      "resetting env. episode reward total was 11.0. running mean: 8.618300822870964\n",
      "resetting env. episode reward total was 8.0. running mean: 8.612117814642254\n",
      "resetting env. episode reward total was 6.0. running mean: 8.585996636495832\n",
      "resetting env. episode reward total was 13.0. running mean: 8.630136670130874\n",
      "resetting env. episode reward total was 15.0. running mean: 8.693835303429566\n",
      "resetting env. episode reward total was 15.0. running mean: 8.756896950395271\n",
      "resetting env. episode reward total was 5.0. running mean: 8.719327980891318\n",
      "resetting env. episode reward total was 13.0. running mean: 8.762134701082406\n",
      "resetting env. episode reward total was -1.0. running mean: 8.664513354071582\n",
      "resetting env. episode reward total was 10.0. running mean: 8.677868220530867\n",
      "resetting env. episode reward total was 15.0. running mean: 8.741089538325559\n",
      "resetting env. episode reward total was 10.0. running mean: 8.753678642942303\n",
      "resetting env. episode reward total was 8.0. running mean: 8.74614185651288\n",
      "resetting env. episode reward total was 7.0. running mean: 8.728680437947752\n",
      "resetting env. episode reward total was 11.0. running mean: 8.751393633568274\n",
      "resetting env. episode reward total was 14.0. running mean: 8.803879697232592\n",
      "resetting env. episode reward total was 9.0. running mean: 8.805840900260266\n",
      "resetting env. episode reward total was 10.0. running mean: 8.817782491257663\n",
      "resetting env. episode reward total was 8.0. running mean: 8.809604666345086\n",
      "resetting env. episode reward total was 15.0. running mean: 8.871508619681636\n",
      "resetting env. episode reward total was 9.0. running mean: 8.87279353348482\n",
      "resetting env. episode reward total was 9.0. running mean: 8.874065598149972\n",
      "resetting env. episode reward total was 13.0. running mean: 8.915324942168473\n",
      "resetting env. episode reward total was 14.0. running mean: 8.966171692746789\n",
      "resetting env. episode reward total was -3.0. running mean: 8.846509975819322\n",
      "resetting env. episode reward total was 2.0. running mean: 8.778044876061127\n",
      "resetting env. episode reward total was 8.0. running mean: 8.770264427300516\n",
      "resetting env. episode reward total was -5.0. running mean: 8.63256178302751\n",
      "resetting env. episode reward total was 12.0. running mean: 8.666236165197235\n",
      "resetting env. episode reward total was 6.0. running mean: 8.639573803545263\n",
      "resetting env. episode reward total was 14.0. running mean: 8.69317806550981\n",
      "resetting env. episode reward total was 15.0. running mean: 8.756246284854713\n",
      "resetting env. episode reward total was 12.0. running mean: 8.788683822006165\n",
      "resetting env. episode reward total was 8.0. running mean: 8.780796983786104\n",
      "resetting env. episode reward total was 17.0. running mean: 8.862989013948242\n",
      "resetting env. episode reward total was 5.0. running mean: 8.82435912380876\n",
      "resetting env. episode reward total was 5.0. running mean: 8.786115532570673\n",
      "resetting env. episode reward total was 10.0. running mean: 8.798254377244966\n",
      "resetting env. episode reward total was 11.0. running mean: 8.820271833472516\n",
      "resetting env. episode reward total was 15.0. running mean: 8.88206911513779\n",
      "resetting env. episode reward total was 7.0. running mean: 8.863248423986413\n",
      "resetting env. episode reward total was 13.0. running mean: 8.904615939746549\n",
      "resetting env. episode reward total was 8.0. running mean: 8.895569780349083\n",
      "resetting env. episode reward total was 2.0. running mean: 8.826614082545591\n",
      "resetting env. episode reward total was 14.0. running mean: 8.878347941720136\n",
      "resetting env. episode reward total was 12.0. running mean: 8.909564462302933\n",
      "resetting env. episode reward total was 5.0. running mean: 8.870468817679905\n",
      "resetting env. episode reward total was 6.0. running mean: 8.841764129503106\n",
      "resetting env. episode reward total was 5.0. running mean: 8.803346488208076\n",
      "resetting env. episode reward total was 11.0. running mean: 8.825313023325995\n",
      "resetting env. episode reward total was 16.0. running mean: 8.897059893092734\n",
      "resetting env. episode reward total was 10.0. running mean: 8.908089294161806\n",
      "resetting env. episode reward total was 13.0. running mean: 8.949008401220189\n",
      "resetting env. episode reward total was 1.0. running mean: 8.869518317207987\n",
      "resetting env. episode reward total was 8.0. running mean: 8.860823134035908\n",
      "resetting env. episode reward total was 9.0. running mean: 8.862214902695548\n",
      "resetting env. episode reward total was 4.0. running mean: 8.813592753668592\n",
      "resetting env. episode reward total was 7.0. running mean: 8.795456826131906\n",
      "resetting env. episode reward total was 14.0. running mean: 8.847502257870588\n",
      "resetting env. episode reward total was 11.0. running mean: 8.869027235291881\n",
      "resetting env. episode reward total was 2.0. running mean: 8.800336962938962\n",
      "resetting env. episode reward total was 12.0. running mean: 8.832333593309572\n",
      "resetting env. episode reward total was 2.0. running mean: 8.764010257376476\n",
      "resetting env. episode reward total was 9.0. running mean: 8.766370154802711\n",
      "resetting env. episode reward total was 6.0. running mean: 8.738706453254684\n",
      "resetting env. episode reward total was 10.0. running mean: 8.751319388722138\n",
      "resetting env. episode reward total was 3.0. running mean: 8.693806194834915\n",
      "resetting env. episode reward total was 12.0. running mean: 8.726868132886565\n",
      "resetting env. episode reward total was 7.0. running mean: 8.7095994515577\n",
      "resetting env. episode reward total was 12.0. running mean: 8.742503457042123\n",
      "resetting env. episode reward total was 6.0. running mean: 8.715078422471702\n",
      "resetting env. episode reward total was 9.0. running mean: 8.717927638246985\n",
      "resetting env. episode reward total was 4.0. running mean: 8.670748361864515\n",
      "resetting env. episode reward total was 12.0. running mean: 8.704040878245868\n",
      "resetting env. episode reward total was -1.0. running mean: 8.60700046946341\n",
      "resetting env. episode reward total was 9.0. running mean: 8.610930464768776\n",
      "resetting env. episode reward total was 11.0. running mean: 8.634821160121088\n",
      "resetting env. episode reward total was -2.0. running mean: 8.528472948519878\n",
      "resetting env. episode reward total was 1.0. running mean: 8.45318821903468\n",
      "resetting env. episode reward total was 13.0. running mean: 8.498656336844332\n",
      "resetting env. episode reward total was 9.0. running mean: 8.503669773475888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 8.528633075741128\n",
      "resetting env. episode reward total was 11.0. running mean: 8.553346744983717\n",
      "resetting env. episode reward total was 5.0. running mean: 8.51781327753388\n",
      "resetting env. episode reward total was 14.0. running mean: 8.572635144758543\n",
      "resetting env. episode reward total was -7.0. running mean: 8.416908793310958\n",
      "resetting env. episode reward total was 8.0. running mean: 8.412739705377849\n",
      "resetting env. episode reward total was 16.0. running mean: 8.48861230832407\n",
      "resetting env. episode reward total was 8.0. running mean: 8.48372618524083\n",
      "resetting env. episode reward total was 13.0. running mean: 8.528888923388422\n",
      "resetting env. episode reward total was 13.0. running mean: 8.573600034154538\n",
      "resetting env. episode reward total was 6.0. running mean: 8.547864033812992\n",
      "resetting env. episode reward total was 9.0. running mean: 8.552385393474863\n",
      "resetting env. episode reward total was 2.0. running mean: 8.486861539540113\n",
      "resetting env. episode reward total was 18.0. running mean: 8.581992924144712\n",
      "resetting env. episode reward total was 9.0. running mean: 8.586172994903265\n",
      "resetting env. episode reward total was 8.0. running mean: 8.580311264954233\n",
      "resetting env. episode reward total was 4.0. running mean: 8.53450815230469\n",
      "resetting env. episode reward total was 12.0. running mean: 8.569163070781643\n",
      "resetting env. episode reward total was 14.0. running mean: 8.623471440073827\n",
      "resetting env. episode reward total was 11.0. running mean: 8.647236725673087\n",
      "resetting env. episode reward total was 11.0. running mean: 8.670764358416356\n",
      "resetting env. episode reward total was 10.0. running mean: 8.684056714832192\n",
      "resetting env. episode reward total was 11.0. running mean: 8.70721614768387\n",
      "resetting env. episode reward total was 13.0. running mean: 8.750143986207032\n",
      "resetting env. episode reward total was 11.0. running mean: 8.772642546344962\n",
      "resetting env. episode reward total was 11.0. running mean: 8.794916120881512\n",
      "resetting env. episode reward total was 7.0. running mean: 8.776966959672697\n",
      "resetting env. episode reward total was 8.0. running mean: 8.76919729007597\n",
      "resetting env. episode reward total was 11.0. running mean: 8.79150531717521\n",
      "resetting env. episode reward total was 12.0. running mean: 8.823590264003457\n",
      "resetting env. episode reward total was 10.0. running mean: 8.835354361363422\n",
      "resetting env. episode reward total was 13.0. running mean: 8.877000817749789\n",
      "resetting env. episode reward total was 11.0. running mean: 8.89823080957229\n",
      "resetting env. episode reward total was 11.0. running mean: 8.919248501476567\n",
      "resetting env. episode reward total was 2.0. running mean: 8.850056016461801\n",
      "resetting env. episode reward total was 9.0. running mean: 8.851555456297183\n",
      "resetting env. episode reward total was 12.0. running mean: 8.88303990173421\n",
      "resetting env. episode reward total was 1.0. running mean: 8.804209502716867\n",
      "resetting env. episode reward total was 16.0. running mean: 8.8761674076897\n",
      "resetting env. episode reward total was 11.0. running mean: 8.897405733612802\n",
      "resetting env. episode reward total was 9.0. running mean: 8.898431676276674\n",
      "resetting env. episode reward total was 6.0. running mean: 8.869447359513908\n",
      "resetting env. episode reward total was 11.0. running mean: 8.890752885918769\n",
      "resetting env. episode reward total was 10.0. running mean: 8.90184535705958\n",
      "resetting env. episode reward total was 9.0. running mean: 8.902826903488984\n",
      "resetting env. episode reward total was 1.0. running mean: 8.823798634454095\n",
      "resetting env. episode reward total was 14.0. running mean: 8.875560648109554\n",
      "resetting env. episode reward total was 3.0. running mean: 8.816805041628458\n",
      "resetting env. episode reward total was 7.0. running mean: 8.798636991212174\n",
      "resetting env. episode reward total was 5.0. running mean: 8.760650621300053\n",
      "resetting env. episode reward total was 12.0. running mean: 8.793044115087051\n",
      "resetting env. episode reward total was 5.0. running mean: 8.755113673936181\n",
      "resetting env. episode reward total was 6.0. running mean: 8.72756253719682\n",
      "resetting env. episode reward total was 11.0. running mean: 8.750286911824851\n",
      "resetting env. episode reward total was 9.0. running mean: 8.752784042706603\n",
      "resetting env. episode reward total was 5.0. running mean: 8.715256202279537\n",
      "resetting env. episode reward total was 10.0. running mean: 8.728103640256741\n",
      "resetting env. episode reward total was 14.0. running mean: 8.780822603854174\n",
      "resetting env. episode reward total was 9.0. running mean: 8.783014377815633\n",
      "resetting env. episode reward total was 10.0. running mean: 8.795184234037476\n",
      "resetting env. episode reward total was 10.0. running mean: 8.8072323916971\n",
      "resetting env. episode reward total was 6.0. running mean: 8.77916006778013\n",
      "resetting env. episode reward total was 14.0. running mean: 8.831368467102328\n",
      "resetting env. episode reward total was -1.0. running mean: 8.733054782431305\n",
      "resetting env. episode reward total was 5.0. running mean: 8.695724234606992\n",
      "resetting env. episode reward total was 12.0. running mean: 8.72876699226092\n",
      "resetting env. episode reward total was 9.0. running mean: 8.731479322338311\n",
      "resetting env. episode reward total was -7.0. running mean: 8.574164529114928\n",
      "resetting env. episode reward total was 14.0. running mean: 8.628422883823779\n",
      "resetting env. episode reward total was 15.0. running mean: 8.692138654985541\n",
      "resetting env. episode reward total was 13.0. running mean: 8.735217268435687\n",
      "resetting env. episode reward total was 11.0. running mean: 8.75786509575133\n",
      "resetting env. episode reward total was 5.0. running mean: 8.720286444793818\n",
      "resetting env. episode reward total was 13.0. running mean: 8.76308358034588\n",
      "resetting env. episode reward total was 13.0. running mean: 8.805452744542421\n",
      "resetting env. episode reward total was 8.0. running mean: 8.797398217096998\n",
      "resetting env. episode reward total was 8.0. running mean: 8.789424234926027\n",
      "resetting env. episode reward total was 3.0. running mean: 8.731529992576766\n",
      "resetting env. episode reward total was 13.0. running mean: 8.774214692650999\n",
      "resetting env. episode reward total was 1.0. running mean: 8.696472545724488\n",
      "resetting env. episode reward total was -2.0. running mean: 8.589507820267244\n",
      "resetting env. episode reward total was 6.0. running mean: 8.563612742064572\n",
      "resetting env. episode reward total was 16.0. running mean: 8.637976614643927\n",
      "resetting env. episode reward total was 13.0. running mean: 8.681596848497488\n",
      "resetting env. episode reward total was 15.0. running mean: 8.744780880012513\n",
      "resetting env. episode reward total was 5.0. running mean: 8.707333071212389\n",
      "resetting env. episode reward total was 12.0. running mean: 8.740259740500264\n",
      "resetting env. episode reward total was 12.0. running mean: 8.77285714309526\n",
      "resetting env. episode reward total was 9.0. running mean: 8.775128571664307\n",
      "resetting env. episode reward total was 11.0. running mean: 8.797377285947663\n",
      "resetting env. episode reward total was 2.0. running mean: 8.729403513088187\n",
      "resetting env. episode reward total was -6.0. running mean: 8.582109477957305\n",
      "resetting env. episode reward total was 16.0. running mean: 8.656288383177731\n",
      "resetting env. episode reward total was 5.0. running mean: 8.619725499345954\n",
      "resetting env. episode reward total was 8.0. running mean: 8.613528244352494\n",
      "resetting env. episode reward total was 5.0. running mean: 8.57739296190897\n",
      "resetting env. episode reward total was 13.0. running mean: 8.621619032289882\n",
      "resetting env. episode reward total was 14.0. running mean: 8.675402841966983\n",
      "resetting env. episode reward total was 15.0. running mean: 8.738648813547314\n",
      "resetting env. episode reward total was -2.0. running mean: 8.631262325411841\n",
      "resetting env. episode reward total was 12.0. running mean: 8.664949702157722\n",
      "resetting env. episode reward total was 7.0. running mean: 8.648300205136145\n",
      "resetting env. episode reward total was 10.0. running mean: 8.661817203084784\n",
      "resetting env. episode reward total was 1.0. running mean: 8.585199031053936\n",
      "resetting env. episode reward total was -2.0. running mean: 8.479347040743397\n",
      "resetting env. episode reward total was 7.0. running mean: 8.464553570335964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 8.509908034632605\n",
      "resetting env. episode reward total was 5.0. running mean: 8.47480895428628\n",
      "resetting env. episode reward total was 9.0. running mean: 8.480060864743416\n",
      "resetting env. episode reward total was 6.0. running mean: 8.455260256095983\n",
      "resetting env. episode reward total was 4.0. running mean: 8.410707653535022\n",
      "resetting env. episode reward total was 7.0. running mean: 8.396600576999672\n",
      "resetting env. episode reward total was 7.0. running mean: 8.382634571229676\n",
      "resetting env. episode reward total was 11.0. running mean: 8.40880822551738\n",
      "resetting env. episode reward total was 12.0. running mean: 8.444720143262204\n",
      "resetting env. episode reward total was 9.0. running mean: 8.450272941829581\n",
      "resetting env. episode reward total was 6.0. running mean: 8.425770212411287\n",
      "resetting env. episode reward total was 14.0. running mean: 8.481512510287175\n",
      "resetting env. episode reward total was 13.0. running mean: 8.526697385184304\n",
      "resetting env. episode reward total was 10.0. running mean: 8.541430411332462\n",
      "resetting env. episode reward total was 12.0. running mean: 8.576016107219136\n",
      "resetting env. episode reward total was 8.0. running mean: 8.570255946146945\n",
      "resetting env. episode reward total was 16.0. running mean: 8.644553386685477\n",
      "resetting env. episode reward total was 15.0. running mean: 8.708107852818623\n",
      "resetting env. episode reward total was 13.0. running mean: 8.751026774290438\n",
      "resetting env. episode reward total was 15.0. running mean: 8.813516506547533\n",
      "resetting env. episode reward total was 1.0. running mean: 8.735381341482057\n",
      "resetting env. episode reward total was 3.0. running mean: 8.678027528067236\n",
      "resetting env. episode reward total was 5.0. running mean: 8.641247252786565\n",
      "resetting env. episode reward total was 8.0. running mean: 8.6348347802587\n",
      "resetting env. episode reward total was 14.0. running mean: 8.688486432456113\n",
      "resetting env. episode reward total was 11.0. running mean: 8.71160156813155\n",
      "resetting env. episode reward total was 13.0. running mean: 8.754485552450236\n",
      "resetting env. episode reward total was 7.0. running mean: 8.736940696925734\n",
      "resetting env. episode reward total was 10.0. running mean: 8.749571289956476\n",
      "resetting env. episode reward total was 10.0. running mean: 8.76207557705691\n",
      "resetting env. episode reward total was 14.0. running mean: 8.814454821286342\n",
      "resetting env. episode reward total was 9.0. running mean: 8.816310273073478\n",
      "resetting env. episode reward total was 17.0. running mean: 8.898147170342742\n",
      "resetting env. episode reward total was 2.0. running mean: 8.829165698639315\n",
      "resetting env. episode reward total was 12.0. running mean: 8.86087404165292\n",
      "resetting env. episode reward total was 1.0. running mean: 8.782265301236391\n",
      "resetting env. episode reward total was 14.0. running mean: 8.834442648224028\n",
      "resetting env. episode reward total was 6.0. running mean: 8.806098221741788\n",
      "resetting env. episode reward total was 12.0. running mean: 8.83803723952437\n",
      "resetting env. episode reward total was 9.0. running mean: 8.839656867129126\n",
      "resetting env. episode reward total was 12.0. running mean: 8.871260298457834\n",
      "resetting env. episode reward total was 10.0. running mean: 8.882547695473255\n",
      "resetting env. episode reward total was 9.0. running mean: 8.883722218518521\n",
      "resetting env. episode reward total was 15.0. running mean: 8.944884996333336\n",
      "resetting env. episode reward total was 2.0. running mean: 8.875436146370003\n",
      "resetting env. episode reward total was -3.0. running mean: 8.756681784906304\n",
      "resetting env. episode reward total was 11.0. running mean: 8.77911496705724\n",
      "resetting env. episode reward total was 17.0. running mean: 8.861323817386667\n",
      "resetting env. episode reward total was 2.0. running mean: 8.7927105792128\n",
      "resetting env. episode reward total was 12.0. running mean: 8.824783473420672\n",
      "resetting env. episode reward total was 8.0. running mean: 8.816535638686466\n",
      "resetting env. episode reward total was 11.0. running mean: 8.8383702822996\n",
      "resetting env. episode reward total was 11.0. running mean: 8.859986579476603\n",
      "resetting env. episode reward total was 9.0. running mean: 8.861386713681837\n",
      "resetting env. episode reward total was 16.0. running mean: 8.932772846545019\n",
      "resetting env. episode reward total was 6.0. running mean: 8.903445118079569\n",
      "resetting env. episode reward total was 8.0. running mean: 8.894410666898773\n",
      "resetting env. episode reward total was -5.0. running mean: 8.755466560229785\n",
      "resetting env. episode reward total was 5.0. running mean: 8.717911894627488\n",
      "resetting env. episode reward total was 5.0. running mean: 8.680732775681212\n",
      "resetting env. episode reward total was 5.0. running mean: 8.643925447924401\n",
      "resetting env. episode reward total was 15.0. running mean: 8.707486193445158\n",
      "resetting env. episode reward total was 7.0. running mean: 8.690411331510706\n",
      "resetting env. episode reward total was -4.0. running mean: 8.5635072181956\n",
      "resetting env. episode reward total was 5.0. running mean: 8.527872146013644\n",
      "resetting env. episode reward total was 10.0. running mean: 8.542593424553507\n",
      "resetting env. episode reward total was -1.0. running mean: 8.447167490307972\n",
      "resetting env. episode reward total was 9.0. running mean: 8.452695815404892\n",
      "resetting env. episode reward total was 11.0. running mean: 8.478168857250843\n",
      "resetting env. episode reward total was 15.0. running mean: 8.543387168678334\n",
      "resetting env. episode reward total was 5.0. running mean: 8.507953296991552\n",
      "resetting env. episode reward total was 13.0. running mean: 8.552873764021637\n",
      "resetting env. episode reward total was 4.0. running mean: 8.50734502638142\n",
      "resetting env. episode reward total was 12.0. running mean: 8.542271576117605\n",
      "resetting env. episode reward total was 17.0. running mean: 8.626848860356429\n",
      "resetting env. episode reward total was 14.0. running mean: 8.680580371752864\n",
      "resetting env. episode reward total was 13.0. running mean: 8.723774568035337\n",
      "resetting env. episode reward total was -9.0. running mean: 8.546536822354984\n",
      "resetting env. episode reward total was 9.0. running mean: 8.551071454131433\n",
      "resetting env. episode reward total was 11.0. running mean: 8.575560739590118\n",
      "resetting env. episode reward total was 5.0. running mean: 8.539805132194218\n",
      "resetting env. episode reward total was 11.0. running mean: 8.564407080872275\n",
      "resetting env. episode reward total was 10.0. running mean: 8.578763010063552\n",
      "resetting env. episode reward total was 6.0. running mean: 8.552975379962916\n",
      "resetting env. episode reward total was 11.0. running mean: 8.577445626163286\n",
      "resetting env. episode reward total was -7.0. running mean: 8.421671169901652\n",
      "resetting env. episode reward total was 14.0. running mean: 8.477454458202637\n",
      "resetting env. episode reward total was 6.0. running mean: 8.45267991362061\n",
      "resetting env. episode reward total was 8.0. running mean: 8.448153114484404\n",
      "resetting env. episode reward total was 2.0. running mean: 8.38367158333956\n",
      "resetting env. episode reward total was 11.0. running mean: 8.409834867506163\n",
      "resetting env. episode reward total was 3.0. running mean: 8.355736518831101\n",
      "resetting env. episode reward total was 7.0. running mean: 8.34217915364279\n",
      "resetting env. episode reward total was 14.0. running mean: 8.398757362106362\n",
      "resetting env. episode reward total was 12.0. running mean: 8.434769788485298\n",
      "resetting env. episode reward total was 8.0. running mean: 8.430422090600445\n",
      "resetting env. episode reward total was 13.0. running mean: 8.476117869694441\n",
      "resetting env. episode reward total was 10.0. running mean: 8.491356690997497\n",
      "resetting env. episode reward total was -1.0. running mean: 8.396443124087522\n",
      "resetting env. episode reward total was 9.0. running mean: 8.402478692846646\n",
      "resetting env. episode reward total was 11.0. running mean: 8.428453905918179\n",
      "resetting env. episode reward total was 8.0. running mean: 8.424169366858997\n",
      "resetting env. episode reward total was 10.0. running mean: 8.439927673190407\n",
      "resetting env. episode reward total was 9.0. running mean: 8.445528396458503\n",
      "resetting env. episode reward total was 4.0. running mean: 8.401073112493917\n",
      "resetting env. episode reward total was 15.0. running mean: 8.467062381368978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 8.522391757555289\n",
      "resetting env. episode reward total was 17.0. running mean: 8.607167839979736\n",
      "resetting env. episode reward total was 7.0. running mean: 8.591096161579939\n",
      "resetting env. episode reward total was 6.0. running mean: 8.56518519996414\n",
      "resetting env. episode reward total was 7.0. running mean: 8.5495333479645\n",
      "resetting env. episode reward total was -3.0. running mean: 8.434038014484855\n",
      "resetting env. episode reward total was -3.0. running mean: 8.319697634340008\n",
      "resetting env. episode reward total was 10.0. running mean: 8.336500657996607\n",
      "resetting env. episode reward total was 10.0. running mean: 8.353135651416641\n",
      "resetting env. episode reward total was 8.0. running mean: 8.349604294902475\n",
      "resetting env. episode reward total was 15.0. running mean: 8.416108251953451\n",
      "resetting env. episode reward total was 5.0. running mean: 8.381947169433918\n",
      "resetting env. episode reward total was 12.0. running mean: 8.418127697739578\n",
      "resetting env. episode reward total was 7.0. running mean: 8.403946420762182\n",
      "resetting env. episode reward total was -9.0. running mean: 8.22990695655456\n",
      "resetting env. episode reward total was 5.0. running mean: 8.197607886989015\n",
      "resetting env. episode reward total was 3.0. running mean: 8.145631808119123\n",
      "resetting env. episode reward total was 11.0. running mean: 8.174175490037932\n",
      "resetting env. episode reward total was 13.0. running mean: 8.222433735137553\n",
      "resetting env. episode reward total was 6.0. running mean: 8.200209397786178\n",
      "resetting env. episode reward total was 3.0. running mean: 8.148207303808316\n",
      "resetting env. episode reward total was 10.0. running mean: 8.166725230770233\n",
      "resetting env. episode reward total was 6.0. running mean: 8.14505797846253\n",
      "resetting env. episode reward total was 5.0. running mean: 8.113607398677905\n",
      "resetting env. episode reward total was 9.0. running mean: 8.122471324691126\n",
      "resetting env. episode reward total was 10.0. running mean: 8.141246611444215\n",
      "resetting env. episode reward total was 3.0. running mean: 8.089834145329773\n",
      "resetting env. episode reward total was 6.0. running mean: 8.068935803876476\n",
      "resetting env. episode reward total was 9.0. running mean: 8.078246445837712\n",
      "resetting env. episode reward total was 3.0. running mean: 8.027463981379334\n",
      "resetting env. episode reward total was 14.0. running mean: 8.08718934156554\n",
      "resetting env. episode reward total was 2.0. running mean: 8.026317448149884\n",
      "resetting env. episode reward total was 6.0. running mean: 8.006054273668385\n",
      "resetting env. episode reward total was 11.0. running mean: 8.0359937309317\n",
      "resetting env. episode reward total was 14.0. running mean: 8.095633793622383\n",
      "resetting env. episode reward total was 9.0. running mean: 8.10467745568616\n",
      "resetting env. episode reward total was 11.0. running mean: 8.133630681129297\n",
      "resetting env. episode reward total was 10.0. running mean: 8.152294374318004\n",
      "resetting env. episode reward total was 8.0. running mean: 8.150771430574824\n",
      "resetting env. episode reward total was -6.0. running mean: 8.009263716269075\n",
      "resetting env. episode reward total was 9.0. running mean: 8.019171079106384\n",
      "resetting env. episode reward total was 6.0. running mean: 7.998979368315319\n",
      "resetting env. episode reward total was 8.0. running mean: 7.998989574632166\n",
      "resetting env. episode reward total was 15.0. running mean: 8.068999678885843\n",
      "resetting env. episode reward total was 13.0. running mean: 8.118309682096985\n",
      "resetting env. episode reward total was 5.0. running mean: 8.087126585276016\n",
      "resetting env. episode reward total was 11.0. running mean: 8.116255319423255\n",
      "resetting env. episode reward total was 14.0. running mean: 8.175092766229023\n",
      "resetting env. episode reward total was 14.0. running mean: 8.233341838566734\n",
      "resetting env. episode reward total was 11.0. running mean: 8.261008420181065\n",
      "resetting env. episode reward total was 13.0. running mean: 8.308398335979255\n",
      "resetting env. episode reward total was 8.0. running mean: 8.305314352619463\n",
      "resetting env. episode reward total was 8.0. running mean: 8.302261209093269\n",
      "resetting env. episode reward total was 13.0. running mean: 8.349238597002337\n",
      "resetting env. episode reward total was 6.0. running mean: 8.325746211032314\n",
      "resetting env. episode reward total was 6.0. running mean: 8.302488748921991\n",
      "resetting env. episode reward total was 10.0. running mean: 8.319463861432771\n",
      "resetting env. episode reward total was 11.0. running mean: 8.346269222818442\n",
      "resetting env. episode reward total was 12.0. running mean: 8.382806530590257\n",
      "resetting env. episode reward total was 9.0. running mean: 8.388978465284353\n",
      "resetting env. episode reward total was 2.0. running mean: 8.32508868063151\n",
      "resetting env. episode reward total was 10.0. running mean: 8.341837793825194\n",
      "resetting env. episode reward total was 6.0. running mean: 8.318419415886943\n",
      "resetting env. episode reward total was 8.0. running mean: 8.315235221728074\n",
      "resetting env. episode reward total was 6.0. running mean: 8.292082869510793\n",
      "resetting env. episode reward total was 4.0. running mean: 8.249162040815683\n",
      "resetting env. episode reward total was 8.0. running mean: 8.246670420407527\n",
      "resetting env. episode reward total was -6.0. running mean: 8.104203716203452\n",
      "resetting env. episode reward total was 6.0. running mean: 8.083161679041417\n",
      "resetting env. episode reward total was 8.0. running mean: 8.082330062251003\n",
      "resetting env. episode reward total was 6.0. running mean: 8.061506761628493\n",
      "resetting env. episode reward total was 11.0. running mean: 8.090891694012209\n",
      "resetting env. episode reward total was 1.0. running mean: 8.019982777072086\n",
      "resetting env. episode reward total was 10.0. running mean: 8.039782949301365\n",
      "resetting env. episode reward total was 5.0. running mean: 8.009385119808352\n",
      "resetting env. episode reward total was 13.0. running mean: 8.059291268610268\n",
      "resetting env. episode reward total was 17.0. running mean: 8.148698355924166\n",
      "resetting env. episode reward total was 10.0. running mean: 8.167211372364925\n",
      "resetting env. episode reward total was 5.0. running mean: 8.135539258641277\n",
      "resetting env. episode reward total was 7.0. running mean: 8.124183866054864\n",
      "resetting env. episode reward total was 11.0. running mean: 8.152942027394314\n",
      "resetting env. episode reward total was 5.0. running mean: 8.121412607120371\n",
      "resetting env. episode reward total was 15.0. running mean: 8.190198481049167\n",
      "resetting env. episode reward total was 7.0. running mean: 8.178296496238676\n",
      "resetting env. episode reward total was 10.0. running mean: 8.19651353127629\n",
      "resetting env. episode reward total was 10.0. running mean: 8.214548395963527\n",
      "resetting env. episode reward total was 16.0. running mean: 8.292402912003892\n",
      "resetting env. episode reward total was 8.0. running mean: 8.289478882883854\n",
      "resetting env. episode reward total was 11.0. running mean: 8.316584094055015\n",
      "resetting env. episode reward total was 10.0. running mean: 8.333418253114464\n",
      "resetting env. episode reward total was 11.0. running mean: 8.36008407058332\n",
      "resetting env. episode reward total was 13.0. running mean: 8.406483229877487\n",
      "resetting env. episode reward total was 11.0. running mean: 8.432418397578711\n",
      "resetting env. episode reward total was 8.0. running mean: 8.428094213602924\n",
      "resetting env. episode reward total was 10.0. running mean: 8.443813271466894\n",
      "resetting env. episode reward total was 10.0. running mean: 8.459375138752225\n",
      "resetting env. episode reward total was 15.0. running mean: 8.524781387364703\n",
      "resetting env. episode reward total was 10.0. running mean: 8.539533573491056\n",
      "resetting env. episode reward total was -1.0. running mean: 8.444138237756146\n",
      "resetting env. episode reward total was 1.0. running mean: 8.369696855378585\n",
      "resetting env. episode reward total was 13.0. running mean: 8.4159998868248\n",
      "resetting env. episode reward total was 13.0. running mean: 8.461839887956552\n",
      "resetting env. episode reward total was 7.0. running mean: 8.447221489076988\n",
      "resetting env. episode reward total was 6.0. running mean: 8.422749274186218\n",
      "resetting env. episode reward total was 15.0. running mean: 8.488521781444357\n",
      "resetting env. episode reward total was 11.0. running mean: 8.513636563629913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 8.538500197993613\n",
      "resetting env. episode reward total was -1.0. running mean: 8.443115196013677\n",
      "resetting env. episode reward total was 11.0. running mean: 8.46868404405354\n",
      "resetting env. episode reward total was 14.0. running mean: 8.523997203613003\n",
      "resetting env. episode reward total was 11.0. running mean: 8.548757231576873\n",
      "resetting env. episode reward total was 5.0. running mean: 8.513269659261105\n",
      "resetting env. episode reward total was 14.0. running mean: 8.568136962668495\n",
      "resetting env. episode reward total was 11.0. running mean: 8.592455593041809\n",
      "resetting env. episode reward total was -7.0. running mean: 8.43653103711139\n",
      "resetting env. episode reward total was 13.0. running mean: 8.482165726740277\n",
      "resetting env. episode reward total was 8.0. running mean: 8.477344069472874\n",
      "resetting env. episode reward total was 10.0. running mean: 8.492570628778145\n",
      "resetting env. episode reward total was 1.0. running mean: 8.417644922490362\n",
      "resetting env. episode reward total was 9.0. running mean: 8.423468473265459\n",
      "resetting env. episode reward total was 10.0. running mean: 8.439233788532803\n",
      "resetting env. episode reward total was 5.0. running mean: 8.404841450647476\n",
      "resetting env. episode reward total was 6.0. running mean: 8.380793036141002\n",
      "resetting env. episode reward total was 18.0. running mean: 8.476985105779592\n",
      "resetting env. episode reward total was 10.0. running mean: 8.492215254721796\n",
      "resetting env. episode reward total was 10.0. running mean: 8.507293102174577\n",
      "resetting env. episode reward total was 4.0. running mean: 8.46222017115283\n",
      "resetting env. episode reward total was 6.0. running mean: 8.437597969441303\n",
      "resetting env. episode reward total was 12.0. running mean: 8.47322198974689\n",
      "resetting env. episode reward total was 10.0. running mean: 8.48848976984942\n",
      "resetting env. episode reward total was 14.0. running mean: 8.543604872150926\n",
      "resetting env. episode reward total was 1.0. running mean: 8.468168823429416\n",
      "resetting env. episode reward total was 8.0. running mean: 8.463487135195122\n",
      "resetting env. episode reward total was 10.0. running mean: 8.47885226384317\n",
      "resetting env. episode reward total was 12.0. running mean: 8.514063741204737\n",
      "resetting env. episode reward total was 10.0. running mean: 8.528923103792689\n",
      "resetting env. episode reward total was 14.0. running mean: 8.583633872754762\n",
      "resetting env. episode reward total was 5.0. running mean: 8.547797534027215\n",
      "resetting env. episode reward total was 8.0. running mean: 8.542319558686943\n",
      "resetting env. episode reward total was 3.0. running mean: 8.486896363100072\n",
      "resetting env. episode reward total was 13.0. running mean: 8.532027399469072\n",
      "resetting env. episode reward total was 6.0. running mean: 8.506707125474382\n",
      "resetting env. episode reward total was 9.0. running mean: 8.511640054219637\n",
      "resetting env. episode reward total was 7.0. running mean: 8.496523653677441\n",
      "resetting env. episode reward total was 17.0. running mean: 8.581558417140666\n",
      "resetting env. episode reward total was 2.0. running mean: 8.51574283296926\n",
      "resetting env. episode reward total was 11.0. running mean: 8.540585404639566\n",
      "resetting env. episode reward total was 10.0. running mean: 8.55517955059317\n",
      "resetting env. episode reward total was 12.0. running mean: 8.589627755087237\n",
      "resetting env. episode reward total was 7.0. running mean: 8.573731477536365\n",
      "resetting env. episode reward total was 9.0. running mean: 8.577994162761001\n",
      "resetting env. episode reward total was 10.0. running mean: 8.592214221133391\n",
      "resetting env. episode reward total was -3.0. running mean: 8.476292078922057\n",
      "resetting env. episode reward total was 12.0. running mean: 8.511529158132836\n",
      "resetting env. episode reward total was 10.0. running mean: 8.526413866551508\n",
      "resetting env. episode reward total was 15.0. running mean: 8.591149727885993\n",
      "resetting env. episode reward total was 7.0. running mean: 8.575238230607134\n",
      "resetting env. episode reward total was -2.0. running mean: 8.469485848301064\n",
      "resetting env. episode reward total was 9.0. running mean: 8.474790989818054\n",
      "resetting env. episode reward total was 11.0. running mean: 8.500043079919873\n",
      "resetting env. episode reward total was 11.0. running mean: 8.525042649120675\n",
      "resetting env. episode reward total was 16.0. running mean: 8.599792222629468\n",
      "resetting env. episode reward total was 12.0. running mean: 8.633794300403173\n",
      "resetting env. episode reward total was 6.0. running mean: 8.60745635739914\n",
      "resetting env. episode reward total was 8.0. running mean: 8.60138179382515\n",
      "resetting env. episode reward total was 7.0. running mean: 8.585367975886898\n",
      "resetting env. episode reward total was 7.0. running mean: 8.569514296128029\n",
      "resetting env. episode reward total was 10.0. running mean: 8.583819153166749\n",
      "resetting env. episode reward total was 10.0. running mean: 8.59798096163508\n",
      "resetting env. episode reward total was 6.0. running mean: 8.57200115201873\n",
      "resetting env. episode reward total was 11.0. running mean: 8.596281140498542\n",
      "resetting env. episode reward total was 7.0. running mean: 8.580318329093556\n",
      "resetting env. episode reward total was 14.0. running mean: 8.63451514580262\n",
      "resetting env. episode reward total was 7.0. running mean: 8.618169994344594\n",
      "resetting env. episode reward total was 13.0. running mean: 8.66198829440115\n",
      "resetting env. episode reward total was 17.0. running mean: 8.745368411457138\n",
      "resetting env. episode reward total was 13.0. running mean: 8.787914727342567\n",
      "resetting env. episode reward total was 10.0. running mean: 8.80003558006914\n",
      "resetting env. episode reward total was 7.0. running mean: 8.78203522426845\n",
      "resetting env. episode reward total was 6.0. running mean: 8.754214872025766\n",
      "resetting env. episode reward total was 4.0. running mean: 8.706672723305507\n",
      "resetting env. episode reward total was 9.0. running mean: 8.709605996072453\n",
      "resetting env. episode reward total was 6.0. running mean: 8.682509936111728\n",
      "resetting env. episode reward total was 9.0. running mean: 8.68568483675061\n",
      "resetting env. episode reward total was -2.0. running mean: 8.578827988383104\n",
      "resetting env. episode reward total was 7.0. running mean: 8.563039708499273\n",
      "resetting env. episode reward total was 9.0. running mean: 8.56740931141428\n",
      "resetting env. episode reward total was 18.0. running mean: 8.661735218300137\n",
      "resetting env. episode reward total was 11.0. running mean: 8.685117866117135\n",
      "resetting env. episode reward total was 13.0. running mean: 8.728266687455964\n",
      "resetting env. episode reward total was 9.0. running mean: 8.730984020581404\n",
      "resetting env. episode reward total was 14.0. running mean: 8.783674180375591\n",
      "resetting env. episode reward total was 8.0. running mean: 8.775837438571836\n",
      "resetting env. episode reward total was 17.0. running mean: 8.858079064186118\n",
      "resetting env. episode reward total was 12.0. running mean: 8.889498273544255\n",
      "resetting env. episode reward total was 14.0. running mean: 8.940603290808813\n",
      "resetting env. episode reward total was 5.0. running mean: 8.901197257900725\n",
      "resetting env. episode reward total was 11.0. running mean: 8.922185285321717\n",
      "resetting env. episode reward total was 4.0. running mean: 8.872963432468499\n",
      "resetting env. episode reward total was 11.0. running mean: 8.894233798143812\n",
      "resetting env. episode reward total was 7.0. running mean: 8.875291460162375\n",
      "resetting env. episode reward total was 1.0. running mean: 8.79653854556075\n",
      "resetting env. episode reward total was 7.0. running mean: 8.778573160105143\n",
      "resetting env. episode reward total was 15.0. running mean: 8.840787428504091\n",
      "resetting env. episode reward total was 11.0. running mean: 8.86237955421905\n",
      "resetting env. episode reward total was 11.0. running mean: 8.883755758676859\n",
      "resetting env. episode reward total was 15.0. running mean: 8.94491820109009\n",
      "resetting env. episode reward total was 5.0. running mean: 8.90546901907919\n",
      "resetting env. episode reward total was 8.0. running mean: 8.896414328888397\n",
      "resetting env. episode reward total was 12.0. running mean: 8.927450185599513\n",
      "resetting env. episode reward total was 8.0. running mean: 8.918175683743518\n",
      "resetting env. episode reward total was 11.0. running mean: 8.938993926906083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 8.979603987637022\n",
      "resetting env. episode reward total was 9.0. running mean: 8.979807947760651\n",
      "resetting env. episode reward total was 13.0. running mean: 9.020009868283045\n",
      "resetting env. episode reward total was 12.0. running mean: 9.049809769600214\n",
      "resetting env. episode reward total was 5.0. running mean: 9.009311671904213\n",
      "resetting env. episode reward total was 2.0. running mean: 8.93921855518517\n",
      "resetting env. episode reward total was 5.0. running mean: 8.899826369633319\n",
      "resetting env. episode reward total was 4.0. running mean: 8.850828105936985\n",
      "resetting env. episode reward total was 11.0. running mean: 8.872319824877614\n",
      "resetting env. episode reward total was 8.0. running mean: 8.863596626628839\n",
      "resetting env. episode reward total was -3.0. running mean: 8.744960660362551\n",
      "resetting env. episode reward total was -2.0. running mean: 8.637511053758926\n",
      "resetting env. episode reward total was 12.0. running mean: 8.671135943221335\n",
      "resetting env. episode reward total was 4.0. running mean: 8.624424583789121\n",
      "resetting env. episode reward total was 14.0. running mean: 8.67818033795123\n",
      "resetting env. episode reward total was 7.0. running mean: 8.661398534571719\n",
      "resetting env. episode reward total was 6.0. running mean: 8.634784549226001\n",
      "resetting env. episode reward total was 13.0. running mean: 8.678436703733743\n",
      "resetting env. episode reward total was 5.0. running mean: 8.641652336696406\n",
      "resetting env. episode reward total was 11.0. running mean: 8.665235813329442\n",
      "resetting env. episode reward total was 5.0. running mean: 8.628583455196148\n",
      "resetting env. episode reward total was 9.0. running mean: 8.632297620644186\n",
      "resetting env. episode reward total was 14.0. running mean: 8.685974644437744\n",
      "resetting env. episode reward total was 7.0. running mean: 8.669114897993367\n",
      "resetting env. episode reward total was 14.0. running mean: 8.722423749013434\n",
      "resetting env. episode reward total was 13.0. running mean: 8.7651995115233\n",
      "resetting env. episode reward total was 15.0. running mean: 8.827547516408066\n",
      "resetting env. episode reward total was 13.0. running mean: 8.869272041243986\n",
      "resetting env. episode reward total was 9.0. running mean: 8.870579320831546\n",
      "resetting env. episode reward total was 6.0. running mean: 8.84187352762323\n",
      "resetting env. episode reward total was 10.0. running mean: 8.853454792346998\n",
      "resetting env. episode reward total was 13.0. running mean: 8.89492024442353\n",
      "resetting env. episode reward total was 9.0. running mean: 8.895971041979294\n",
      "resetting env. episode reward total was 10.0. running mean: 8.9070113315595\n",
      "resetting env. episode reward total was 7.0. running mean: 8.887941218243906\n",
      "resetting env. episode reward total was -2.0. running mean: 8.779061806061467\n",
      "resetting env. episode reward total was 6.0. running mean: 8.751271188000853\n",
      "resetting env. episode reward total was 5.0. running mean: 8.713758476120844\n",
      "resetting env. episode reward total was 11.0. running mean: 8.736620891359635\n",
      "resetting env. episode reward total was 18.0. running mean: 8.829254682446038\n",
      "resetting env. episode reward total was 9.0. running mean: 8.830962135621578\n",
      "resetting env. episode reward total was 12.0. running mean: 8.862652514265362\n",
      "resetting env. episode reward total was 13.0. running mean: 8.904025989122708\n",
      "resetting env. episode reward total was 15.0. running mean: 8.964985729231481\n",
      "resetting env. episode reward total was 5.0. running mean: 8.925335871939167\n",
      "resetting env. episode reward total was 7.0. running mean: 8.906082513219776\n",
      "resetting env. episode reward total was 6.0. running mean: 8.877021688087579\n",
      "resetting env. episode reward total was 5.0. running mean: 8.838251471206704\n",
      "resetting env. episode reward total was 8.0. running mean: 8.829868956494636\n",
      "resetting env. episode reward total was 13.0. running mean: 8.871570266929691\n",
      "resetting env. episode reward total was 7.0. running mean: 8.852854564260394\n",
      "resetting env. episode reward total was 6.0. running mean: 8.824326018617791\n",
      "resetting env. episode reward total was 11.0. running mean: 8.846082758431612\n",
      "resetting env. episode reward total was 4.0. running mean: 8.797621930847294\n",
      "resetting env. episode reward total was 3.0. running mean: 8.73964571153882\n",
      "resetting env. episode reward total was 12.0. running mean: 8.77224925442343\n",
      "resetting env. episode reward total was 14.0. running mean: 8.824526761879197\n",
      "resetting env. episode reward total was 12.0. running mean: 8.856281494260404\n",
      "resetting env. episode reward total was 3.0. running mean: 8.7977186793178\n",
      "resetting env. episode reward total was 11.0. running mean: 8.81974149252462\n",
      "resetting env. episode reward total was 14.0. running mean: 8.871544077599374\n",
      "resetting env. episode reward total was 9.0. running mean: 8.87282863682338\n",
      "resetting env. episode reward total was 14.0. running mean: 8.924100350455147\n",
      "resetting env. episode reward total was -6.0. running mean: 8.774859346950596\n",
      "resetting env. episode reward total was 4.0. running mean: 8.727110753481089\n",
      "resetting env. episode reward total was 4.0. running mean: 8.679839645946277\n",
      "resetting env. episode reward total was 4.0. running mean: 8.633041249486814\n",
      "resetting env. episode reward total was 14.0. running mean: 8.686710836991946\n",
      "resetting env. episode reward total was 8.0. running mean: 8.679843728622027\n",
      "resetting env. episode reward total was 14.0. running mean: 8.733045291335808\n",
      "resetting env. episode reward total was 8.0. running mean: 8.72571483842245\n",
      "resetting env. episode reward total was 9.0. running mean: 8.728457690038224\n",
      "resetting env. episode reward total was 9.0. running mean: 8.731173113137842\n",
      "resetting env. episode reward total was 17.0. running mean: 8.813861382006463\n",
      "resetting env. episode reward total was 8.0. running mean: 8.8057227681864\n",
      "resetting env. episode reward total was 4.0. running mean: 8.757665540504535\n",
      "resetting env. episode reward total was 6.0. running mean: 8.730088885099489\n",
      "resetting env. episode reward total was 13.0. running mean: 8.772787996248494\n",
      "resetting env. episode reward total was 3.0. running mean: 8.71506011628601\n",
      "resetting env. episode reward total was 5.0. running mean: 8.677909515123151\n",
      "resetting env. episode reward total was 11.0. running mean: 8.70113041997192\n",
      "resetting env. episode reward total was 5.0. running mean: 8.6641191157722\n",
      "resetting env. episode reward total was 12.0. running mean: 8.697477924614477\n",
      "resetting env. episode reward total was 3.0. running mean: 8.640503145368331\n",
      "resetting env. episode reward total was 19.0. running mean: 8.744098113914648\n",
      "resetting env. episode reward total was 7.0. running mean: 8.726657132775502\n",
      "resetting env. episode reward total was 11.0. running mean: 8.749390561447747\n",
      "resetting env. episode reward total was 5.0. running mean: 8.71189665583327\n",
      "resetting env. episode reward total was 14.0. running mean: 8.764777689274938\n",
      "resetting env. episode reward total was 1.0. running mean: 8.687129912382188\n",
      "resetting env. episode reward total was 12.0. running mean: 8.720258613258366\n",
      "resetting env. episode reward total was 11.0. running mean: 8.743056027125782\n",
      "resetting env. episode reward total was 9.0. running mean: 8.745625466854523\n",
      "resetting env. episode reward total was 12.0. running mean: 8.778169212185977\n",
      "resetting env. episode reward total was 10.0. running mean: 8.790387520064117\n",
      "resetting env. episode reward total was 8.0. running mean: 8.782483644863476\n",
      "resetting env. episode reward total was 13.0. running mean: 8.824658808414842\n",
      "resetting env. episode reward total was 16.0. running mean: 8.896412220330694\n",
      "resetting env. episode reward total was 9.0. running mean: 8.897448098127386\n",
      "resetting env. episode reward total was 2.0. running mean: 8.828473617146111\n",
      "resetting env. episode reward total was 13.0. running mean: 8.87018888097465\n",
      "resetting env. episode reward total was 12.0. running mean: 8.901486992164903\n",
      "resetting env. episode reward total was 14.0. running mean: 8.952472122243254\n",
      "resetting env. episode reward total was 12.0. running mean: 8.982947401020821\n",
      "resetting env. episode reward total was 12.0. running mean: 9.013117927010612\n",
      "resetting env. episode reward total was 16.0. running mean: 9.082986747740506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 9.1121568802631\n",
      "resetting env. episode reward total was 9.0. running mean: 9.11103531146047\n",
      "resetting env. episode reward total was 6.0. running mean: 9.079924958345865\n",
      "resetting env. episode reward total was 6.0. running mean: 9.049125708762407\n",
      "resetting env. episode reward total was 11.0. running mean: 9.068634451674782\n",
      "resetting env. episode reward total was 4.0. running mean: 9.017948107158034\n",
      "resetting env. episode reward total was 12.0. running mean: 9.047768626086453\n",
      "resetting env. episode reward total was 11.0. running mean: 9.067290939825588\n",
      "resetting env. episode reward total was 3.0. running mean: 9.006618030427331\n",
      "resetting env. episode reward total was 10.0. running mean: 9.016551850123058\n",
      "resetting env. episode reward total was 3.0. running mean: 8.956386331621827\n",
      "resetting env. episode reward total was 4.0. running mean: 8.906822468305608\n",
      "resetting env. episode reward total was 6.0. running mean: 8.877754243622553\n",
      "resetting env. episode reward total was 15.0. running mean: 8.938976701186327\n",
      "resetting env. episode reward total was 7.0. running mean: 8.919586934174465\n",
      "resetting env. episode reward total was 10.0. running mean: 8.930391064832719\n",
      "resetting env. episode reward total was 9.0. running mean: 8.931087154184391\n",
      "resetting env. episode reward total was 11.0. running mean: 8.951776282642546\n",
      "resetting env. episode reward total was 9.0. running mean: 8.952258519816121\n",
      "resetting env. episode reward total was 13.0. running mean: 8.992735934617961\n",
      "resetting env. episode reward total was 14.0. running mean: 9.042808575271783\n",
      "resetting env. episode reward total was 13.0. running mean: 9.082380489519066\n",
      "resetting env. episode reward total was 9.0. running mean: 9.081556684623875\n",
      "resetting env. episode reward total was 9.0. running mean: 9.080741117777636\n",
      "resetting env. episode reward total was 7.0. running mean: 9.05993370659986\n",
      "resetting env. episode reward total was 2.0. running mean: 8.98933436953386\n",
      "resetting env. episode reward total was 14.0. running mean: 9.039441025838522\n",
      "resetting env. episode reward total was 14.0. running mean: 9.089046615580138\n",
      "resetting env. episode reward total was -8.0. running mean: 8.918156149424336\n",
      "resetting env. episode reward total was 5.0. running mean: 8.878974587930093\n",
      "resetting env. episode reward total was 14.0. running mean: 8.930184842050792\n",
      "resetting env. episode reward total was 11.0. running mean: 8.950882993630284\n",
      "resetting env. episode reward total was 11.0. running mean: 8.97137416369398\n",
      "resetting env. episode reward total was 5.0. running mean: 8.93166042205704\n",
      "resetting env. episode reward total was 2.0. running mean: 8.86234381783647\n",
      "resetting env. episode reward total was 6.0. running mean: 8.833720379658105\n",
      "resetting env. episode reward total was 17.0. running mean: 8.915383175861525\n",
      "resetting env. episode reward total was 9.0. running mean: 8.91622934410291\n",
      "resetting env. episode reward total was 13.0. running mean: 8.95706705066188\n",
      "resetting env. episode reward total was 13.0. running mean: 8.997496380155262\n",
      "resetting env. episode reward total was 12.0. running mean: 9.027521416353709\n",
      "resetting env. episode reward total was 11.0. running mean: 9.047246202190172\n",
      "resetting env. episode reward total was 4.0. running mean: 8.996773740168269\n",
      "resetting env. episode reward total was 8.0. running mean: 8.986806002766587\n",
      "resetting env. episode reward total was -5.0. running mean: 8.84693794273892\n",
      "resetting env. episode reward total was 16.0. running mean: 8.918468563311531\n",
      "resetting env. episode reward total was 7.0. running mean: 8.899283877678416\n",
      "resetting env. episode reward total was 12.0. running mean: 8.93029103890163\n",
      "resetting env. episode reward total was 14.0. running mean: 8.980988128512616\n",
      "resetting env. episode reward total was 13.0. running mean: 9.02117824722749\n",
      "resetting env. episode reward total was 10.0. running mean: 9.030966464755215\n",
      "resetting env. episode reward total was 13.0. running mean: 9.070656800107663\n",
      "resetting env. episode reward total was 15.0. running mean: 9.129950232106587\n",
      "resetting env. episode reward total was 2.0. running mean: 9.058650729785521\n",
      "resetting env. episode reward total was 8.0. running mean: 9.048064222487666\n",
      "resetting env. episode reward total was 2.0. running mean: 8.977583580262788\n",
      "resetting env. episode reward total was 9.0. running mean: 8.97780774446016\n",
      "resetting env. episode reward total was 12.0. running mean: 9.008029667015558\n",
      "resetting env. episode reward total was 8.0. running mean: 8.997949370345403\n",
      "resetting env. episode reward total was 5.0. running mean: 8.957969876641949\n",
      "resetting env. episode reward total was 12.0. running mean: 8.988390177875528\n",
      "resetting env. episode reward total was 12.0. running mean: 9.018506276096772\n",
      "resetting env. episode reward total was 17.0. running mean: 9.098321213335804\n",
      "resetting env. episode reward total was 11.0. running mean: 9.117338001202446\n",
      "resetting env. episode reward total was 9.0. running mean: 9.116164621190421\n",
      "resetting env. episode reward total was 8.0. running mean: 9.105002974978516\n",
      "resetting env. episode reward total was 9.0. running mean: 9.10395294522873\n",
      "resetting env. episode reward total was 12.0. running mean: 9.132913415776443\n",
      "resetting env. episode reward total was 5.0. running mean: 9.09158428161868\n",
      "resetting env. episode reward total was 13.0. running mean: 9.130668438802493\n",
      "resetting env. episode reward total was 14.0. running mean: 9.179361754414469\n",
      "resetting env. episode reward total was 9.0. running mean: 9.177568136870324\n",
      "resetting env. episode reward total was -3.0. running mean: 9.05579245550162\n",
      "resetting env. episode reward total was 2.0. running mean: 8.985234530946604\n",
      "resetting env. episode reward total was 4.0. running mean: 8.935382185637136\n",
      "resetting env. episode reward total was 4.0. running mean: 8.886028363780763\n",
      "resetting env. episode reward total was -3.0. running mean: 8.767168080142957\n",
      "resetting env. episode reward total was 11.0. running mean: 8.789496399341527\n",
      "resetting env. episode reward total was 7.0. running mean: 8.771601435348112\n",
      "resetting env. episode reward total was 14.0. running mean: 8.823885420994632\n",
      "resetting env. episode reward total was 8.0. running mean: 8.815646566784686\n",
      "resetting env. episode reward total was 8.0. running mean: 8.807490101116839\n",
      "resetting env. episode reward total was 11.0. running mean: 8.82941520010567\n",
      "resetting env. episode reward total was 16.0. running mean: 8.901121048104613\n",
      "resetting env. episode reward total was 9.0. running mean: 8.902109837623566\n",
      "resetting env. episode reward total was 12.0. running mean: 8.93308873924733\n",
      "resetting env. episode reward total was 13.0. running mean: 8.973757851854858\n",
      "resetting env. episode reward total was 7.0. running mean: 8.95402027333631\n",
      "resetting env. episode reward total was 11.0. running mean: 8.974480070602946\n",
      "resetting env. episode reward total was 3.0. running mean: 8.914735269896916\n",
      "resetting env. episode reward total was 18.0. running mean: 9.005587917197946\n",
      "resetting env. episode reward total was 6.0. running mean: 8.975532038025968\n",
      "resetting env. episode reward total was 17.0. running mean: 9.055776717645708\n",
      "resetting env. episode reward total was 18.0. running mean: 9.14521895046925\n",
      "resetting env. episode reward total was 8.0. running mean: 9.133766760964557\n",
      "resetting env. episode reward total was 12.0. running mean: 9.16242909335491\n",
      "resetting env. episode reward total was 15.0. running mean: 9.220804802421362\n",
      "resetting env. episode reward total was 5.0. running mean: 9.17859675439715\n",
      "resetting env. episode reward total was 1.0. running mean: 9.096810786853178\n",
      "resetting env. episode reward total was 13.0. running mean: 9.135842678984647\n",
      "resetting env. episode reward total was 2.0. running mean: 9.0644842521948\n",
      "resetting env. episode reward total was 4.0. running mean: 9.013839409672851\n",
      "resetting env. episode reward total was 8.0. running mean: 9.003701015576123\n",
      "resetting env. episode reward total was 7.0. running mean: 8.983664005420362\n",
      "resetting env. episode reward total was 9.0. running mean: 8.983827365366158\n",
      "resetting env. episode reward total was 13.0. running mean: 9.023989091712497\n",
      "resetting env. episode reward total was 9.0. running mean: 9.023749200795372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 9.073511708787418\n",
      "resetting env. episode reward total was -3.0. running mean: 8.952776591699545\n",
      "resetting env. episode reward total was 16.0. running mean: 9.023248825782549\n",
      "resetting env. episode reward total was 11.0. running mean: 9.043016337524723\n",
      "resetting env. episode reward total was 9.0. running mean: 9.042586174149475\n",
      "resetting env. episode reward total was 12.0. running mean: 9.072160312407979\n",
      "resetting env. episode reward total was 10.0. running mean: 9.081438709283898\n",
      "resetting env. episode reward total was 8.0. running mean: 9.070624322191058\n",
      "resetting env. episode reward total was 11.0. running mean: 9.089918078969147\n",
      "resetting env. episode reward total was 11.0. running mean: 9.109018898179455\n",
      "resetting env. episode reward total was -9.0. running mean: 8.92792870919766\n",
      "resetting env. episode reward total was 6.0. running mean: 8.898649422105684\n",
      "resetting env. episode reward total was 14.0. running mean: 8.949662927884628\n",
      "resetting env. episode reward total was 8.0. running mean: 8.940166298605781\n",
      "resetting env. episode reward total was 9.0. running mean: 8.940764635619724\n",
      "resetting env. episode reward total was 13.0. running mean: 8.981356989263528\n",
      "resetting env. episode reward total was 9.0. running mean: 8.981543419370892\n",
      "resetting env. episode reward total was 12.0. running mean: 9.011727985177183\n",
      "resetting env. episode reward total was 2.0. running mean: 8.941610705325411\n",
      "resetting env. episode reward total was 2.0. running mean: 8.872194598272158\n",
      "resetting env. episode reward total was -1.0. running mean: 8.773472652289437\n",
      "resetting env. episode reward total was 11.0. running mean: 8.795737925766542\n",
      "resetting env. episode reward total was 15.0. running mean: 8.857780546508877\n",
      "resetting env. episode reward total was 6.0. running mean: 8.829202741043789\n",
      "resetting env. episode reward total was 10.0. running mean: 8.84091071363335\n",
      "resetting env. episode reward total was -1.0. running mean: 8.742501606497017\n",
      "resetting env. episode reward total was 14.0. running mean: 8.795076590432048\n",
      "resetting env. episode reward total was 7.0. running mean: 8.777125824527728\n",
      "resetting env. episode reward total was 1.0. running mean: 8.69935456628245\n",
      "resetting env. episode reward total was 10.0. running mean: 8.712361020619625\n",
      "resetting env. episode reward total was -2.0. running mean: 8.605237410413428\n",
      "resetting env. episode reward total was 14.0. running mean: 8.659185036309294\n",
      "resetting env. episode reward total was 8.0. running mean: 8.652593185946202\n",
      "resetting env. episode reward total was 15.0. running mean: 8.71606725408674\n",
      "resetting env. episode reward total was 14.0. running mean: 8.768906581545872\n",
      "resetting env. episode reward total was 8.0. running mean: 8.761217515730413\n",
      "resetting env. episode reward total was 8.0. running mean: 8.75360534057311\n",
      "resetting env. episode reward total was 13.0. running mean: 8.796069287167379\n",
      "resetting env. episode reward total was 6.0. running mean: 8.768108594295706\n",
      "resetting env. episode reward total was 9.0. running mean: 8.770427508352748\n",
      "resetting env. episode reward total was 5.0. running mean: 8.73272323326922\n",
      "resetting env. episode reward total was 15.0. running mean: 8.79539600093653\n",
      "resetting env. episode reward total was 3.0. running mean: 8.737442040927164\n",
      "resetting env. episode reward total was 6.0. running mean: 8.710067620517892\n",
      "resetting env. episode reward total was 10.0. running mean: 8.722966944312713\n",
      "resetting env. episode reward total was 11.0. running mean: 8.745737274869585\n",
      "resetting env. episode reward total was 9.0. running mean: 8.748279902120888\n",
      "resetting env. episode reward total was 8.0. running mean: 8.740797103099679\n",
      "resetting env. episode reward total was 8.0. running mean: 8.733389132068682\n",
      "resetting env. episode reward total was 8.0. running mean: 8.726055240747995\n",
      "resetting env. episode reward total was 6.0. running mean: 8.698794688340515\n",
      "resetting env. episode reward total was 9.0. running mean: 8.701806741457109\n",
      "resetting env. episode reward total was 9.0. running mean: 8.704788674042538\n",
      "resetting env. episode reward total was 3.0. running mean: 8.647740787302112\n",
      "resetting env. episode reward total was 7.0. running mean: 8.631263379429091\n",
      "resetting env. episode reward total was 15.0. running mean: 8.6949507456348\n",
      "resetting env. episode reward total was 10.0. running mean: 8.708001238178452\n",
      "resetting env. episode reward total was 3.0. running mean: 8.650921225796667\n",
      "resetting env. episode reward total was 11.0. running mean: 8.6744120135387\n",
      "resetting env. episode reward total was 7.0. running mean: 8.657667893403312\n",
      "resetting env. episode reward total was 11.0. running mean: 8.681091214469278\n",
      "resetting env. episode reward total was 8.0. running mean: 8.674280302324586\n",
      "resetting env. episode reward total was 10.0. running mean: 8.68753749930134\n",
      "resetting env. episode reward total was 9.0. running mean: 8.690662124308327\n",
      "resetting env. episode reward total was 13.0. running mean: 8.733755503065245\n",
      "resetting env. episode reward total was 9.0. running mean: 8.736417948034592\n",
      "resetting env. episode reward total was 6.0. running mean: 8.709053768554247\n",
      "resetting env. episode reward total was 13.0. running mean: 8.751963230868705\n",
      "resetting env. episode reward total was 8.0. running mean: 8.744443598560018\n",
      "resetting env. episode reward total was 9.0. running mean: 8.746999162574417\n",
      "resetting env. episode reward total was 9.0. running mean: 8.749529170948673\n",
      "resetting env. episode reward total was 7.0. running mean: 8.732033879239186\n",
      "resetting env. episode reward total was 3.0. running mean: 8.674713540446794\n",
      "resetting env. episode reward total was 5.0. running mean: 8.637966405042325\n",
      "resetting env. episode reward total was 15.0. running mean: 8.701586740991903\n",
      "resetting env. episode reward total was 14.0. running mean: 8.754570873581985\n",
      "resetting env. episode reward total was 15.0. running mean: 8.817025164846164\n",
      "resetting env. episode reward total was 17.0. running mean: 8.898854913197702\n",
      "resetting env. episode reward total was 10.0. running mean: 8.909866364065724\n",
      "resetting env. episode reward total was 13.0. running mean: 8.950767700425068\n",
      "resetting env. episode reward total was 16.0. running mean: 9.021260023420817\n",
      "resetting env. episode reward total was 12.0. running mean: 9.051047423186608\n",
      "resetting env. episode reward total was 9.0. running mean: 9.050536948954742\n",
      "resetting env. episode reward total was 16.0. running mean: 9.120031579465195\n",
      "resetting env. episode reward total was 9.0. running mean: 9.118831263670543\n",
      "resetting env. episode reward total was 3.0. running mean: 9.057642951033838\n",
      "resetting env. episode reward total was 11.0. running mean: 9.077066521523498\n",
      "resetting env. episode reward total was 12.0. running mean: 9.106295856308263\n",
      "resetting env. episode reward total was 6.0. running mean: 9.075232897745181\n",
      "resetting env. episode reward total was 17.0. running mean: 9.15448056876773\n",
      "resetting env. episode reward total was 11.0. running mean: 9.172935763080051\n",
      "resetting env. episode reward total was 3.0. running mean: 9.11120640544925\n",
      "resetting env. episode reward total was 4.0. running mean: 9.060094341394757\n",
      "resetting env. episode reward total was 8.0. running mean: 9.04949339798081\n",
      "resetting env. episode reward total was 10.0. running mean: 9.058998464001\n",
      "resetting env. episode reward total was 8.0. running mean: 9.04840847936099\n",
      "resetting env. episode reward total was 6.0. running mean: 9.01792439456738\n",
      "resetting env. episode reward total was -3.0. running mean: 8.897745150621708\n",
      "resetting env. episode reward total was 14.0. running mean: 8.948767699115491\n",
      "resetting env. episode reward total was 11.0. running mean: 8.969280022124336\n",
      "resetting env. episode reward total was 10.0. running mean: 8.979587221903092\n",
      "resetting env. episode reward total was 5.0. running mean: 8.93979134968406\n",
      "resetting env. episode reward total was 2.0. running mean: 8.87039343618722\n",
      "resetting env. episode reward total was 12.0. running mean: 8.901689501825347\n",
      "resetting env. episode reward total was 15.0. running mean: 8.962672606807093\n",
      "resetting env. episode reward total was 8.0. running mean: 8.953045880739023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 9.003515421931633\n",
      "resetting env. episode reward total was 13.0. running mean: 9.043480267712317\n",
      "resetting env. episode reward total was 4.0. running mean: 8.993045465035193\n",
      "resetting env. episode reward total was 10.0. running mean: 9.00311501038484\n",
      "resetting env. episode reward total was 11.0. running mean: 9.023083860280991\n",
      "resetting env. episode reward total was 5.0. running mean: 8.982853021678181\n",
      "resetting env. episode reward total was 11.0. running mean: 9.0030244914614\n",
      "resetting env. episode reward total was 10.0. running mean: 9.012994246546786\n",
      "resetting env. episode reward total was 1.0. running mean: 8.932864304081317\n",
      "resetting env. episode reward total was 13.0. running mean: 8.973535661040504\n",
      "resetting env. episode reward total was 8.0. running mean: 8.9638003044301\n",
      "resetting env. episode reward total was 5.0. running mean: 8.924162301385799\n",
      "resetting env. episode reward total was 11.0. running mean: 8.94492067837194\n",
      "resetting env. episode reward total was 13.0. running mean: 8.985471471588221\n",
      "resetting env. episode reward total was 14.0. running mean: 9.03561675687234\n",
      "resetting env. episode reward total was 11.0. running mean: 9.055260589303616\n",
      "resetting env. episode reward total was 9.0. running mean: 9.05470798341058\n",
      "resetting env. episode reward total was 6.0. running mean: 9.024160903576474\n",
      "resetting env. episode reward total was 12.0. running mean: 9.053919294540709\n",
      "resetting env. episode reward total was 11.0. running mean: 9.073380101595301\n",
      "resetting env. episode reward total was 9.0. running mean: 9.072646300579349\n",
      "resetting env. episode reward total was 13.0. running mean: 9.111919837573556\n",
      "resetting env. episode reward total was 15.0. running mean: 9.17080063919782\n",
      "resetting env. episode reward total was 7.0. running mean: 9.149092632805841\n",
      "resetting env. episode reward total was 11.0. running mean: 9.167601706477782\n",
      "resetting env. episode reward total was 7.0. running mean: 9.145925689413005\n",
      "resetting env. episode reward total was 7.0. running mean: 9.124466432518876\n",
      "resetting env. episode reward total was 13.0. running mean: 9.163221768193688\n",
      "resetting env. episode reward total was 11.0. running mean: 9.18158955051175\n",
      "resetting env. episode reward total was 12.0. running mean: 9.209773655006632\n",
      "resetting env. episode reward total was 11.0. running mean: 9.227675918456566\n",
      "resetting env. episode reward total was 6.0. running mean: 9.195399159272\n",
      "resetting env. episode reward total was 6.0. running mean: 9.163445167679281\n",
      "resetting env. episode reward total was 4.0. running mean: 9.111810716002488\n",
      "resetting env. episode reward total was 13.0. running mean: 9.150692608842464\n",
      "resetting env. episode reward total was 4.0. running mean: 9.099185682754038\n",
      "resetting env. episode reward total was 9.0. running mean: 9.098193825926497\n",
      "resetting env. episode reward total was 8.0. running mean: 9.087211887667232\n",
      "resetting env. episode reward total was 14.0. running mean: 9.13633976879056\n",
      "resetting env. episode reward total was 12.0. running mean: 9.164976371102654\n",
      "resetting env. episode reward total was 2.0. running mean: 9.093326607391626\n",
      "resetting env. episode reward total was 8.0. running mean: 9.08239334131771\n",
      "resetting env. episode reward total was 12.0. running mean: 9.111569407904533\n",
      "resetting env. episode reward total was 7.0. running mean: 9.090453713825488\n",
      "resetting env. episode reward total was 15.0. running mean: 9.149549176687232\n",
      "resetting env. episode reward total was 9.0. running mean: 9.14805368492036\n",
      "resetting env. episode reward total was 11.0. running mean: 9.166573148071155\n",
      "resetting env. episode reward total was 12.0. running mean: 9.194907416590443\n",
      "resetting env. episode reward total was 11.0. running mean: 9.212958342424537\n",
      "resetting env. episode reward total was 9.0. running mean: 9.210828759000291\n",
      "resetting env. episode reward total was 10.0. running mean: 9.218720471410288\n",
      "resetting env. episode reward total was 7.0. running mean: 9.196533266696186\n",
      "resetting env. episode reward total was 15.0. running mean: 9.254567934029224\n",
      "resetting env. episode reward total was -3.0. running mean: 9.132022254688932\n",
      "resetting env. episode reward total was 3.0. running mean: 9.070702032142043\n",
      "resetting env. episode reward total was 4.0. running mean: 9.01999501182062\n",
      "resetting env. episode reward total was 13.0. running mean: 9.059795061702415\n",
      "resetting env. episode reward total was 16.0. running mean: 9.129197111085391\n",
      "resetting env. episode reward total was 15.0. running mean: 9.187905139974538\n",
      "resetting env. episode reward total was 12.0. running mean: 9.216026088574791\n",
      "resetting env. episode reward total was 13.0. running mean: 9.253865827689044\n",
      "resetting env. episode reward total was 5.0. running mean: 9.211327169412154\n",
      "resetting env. episode reward total was 1.0. running mean: 9.129213897718033\n",
      "resetting env. episode reward total was 12.0. running mean: 9.157921758740851\n",
      "resetting env. episode reward total was 11.0. running mean: 9.176342541153442\n",
      "resetting env. episode reward total was 19.0. running mean: 9.274579115741908\n",
      "resetting env. episode reward total was 3.0. running mean: 9.211833324584488\n",
      "resetting env. episode reward total was 8.0. running mean: 9.199714991338643\n",
      "resetting env. episode reward total was 7.0. running mean: 9.177717841425258\n",
      "resetting env. episode reward total was 16.0. running mean: 9.245940663011005\n",
      "resetting env. episode reward total was 8.0. running mean: 9.233481256380895\n",
      "resetting env. episode reward total was 4.0. running mean: 9.181146443817084\n",
      "resetting env. episode reward total was 10.0. running mean: 9.189334979378913\n",
      "resetting env. episode reward total was 7.0. running mean: 9.167441629585124\n",
      "resetting env. episode reward total was 11.0. running mean: 9.185767213289273\n",
      "resetting env. episode reward total was 8.0. running mean: 9.17390954115638\n",
      "resetting env. episode reward total was 11.0. running mean: 9.192170445744816\n",
      "resetting env. episode reward total was 12.0. running mean: 9.220248741287367\n",
      "resetting env. episode reward total was 7.0. running mean: 9.198046253874494\n",
      "resetting env. episode reward total was 17.0. running mean: 9.27606579133575\n",
      "resetting env. episode reward total was 3.0. running mean: 9.213305133422391\n",
      "resetting env. episode reward total was 7.0. running mean: 9.191172082088167\n",
      "resetting env. episode reward total was 3.0. running mean: 9.129260361267285\n",
      "resetting env. episode reward total was 11.0. running mean: 9.14796775765461\n",
      "resetting env. episode reward total was 14.0. running mean: 9.196488080078066\n",
      "resetting env. episode reward total was 7.0. running mean: 9.174523199277285\n",
      "resetting env. episode reward total was 6.0. running mean: 9.142777967284513\n",
      "resetting env. episode reward total was -1.0. running mean: 9.041350187611668\n",
      "resetting env. episode reward total was 4.0. running mean: 8.99093668573555\n",
      "resetting env. episode reward total was 11.0. running mean: 9.011027318878194\n",
      "resetting env. episode reward total was 10.0. running mean: 9.02091704568941\n",
      "resetting env. episode reward total was 12.0. running mean: 9.050707875232515\n",
      "resetting env. episode reward total was 12.0. running mean: 9.080200796480188\n",
      "resetting env. episode reward total was 6.0. running mean: 9.049398788515386\n",
      "resetting env. episode reward total was 9.0. running mean: 9.048904800630233\n",
      "resetting env. episode reward total was 16.0. running mean: 9.11841575262393\n",
      "resetting env. episode reward total was 16.0. running mean: 9.18723159509769\n",
      "resetting env. episode reward total was 9.0. running mean: 9.185359279146713\n",
      "resetting env. episode reward total was 10.0. running mean: 9.193505686355245\n",
      "resetting env. episode reward total was 10.0. running mean: 9.201570629491691\n",
      "resetting env. episode reward total was 6.0. running mean: 9.169554923196774\n",
      "resetting env. episode reward total was 16.0. running mean: 9.237859373964806\n",
      "resetting env. episode reward total was 10.0. running mean: 9.245480780225158\n",
      "resetting env. episode reward total was -3.0. running mean: 9.123025972422907\n",
      "resetting env. episode reward total was 10.0. running mean: 9.131795712698677\n",
      "resetting env. episode reward total was 13.0. running mean: 9.17047775557169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 16.0. running mean: 9.238772978015973\n",
      "resetting env. episode reward total was 3.0. running mean: 9.176385248235812\n",
      "resetting env. episode reward total was 15.0. running mean: 9.234621395753454\n",
      "resetting env. episode reward total was 5.0. running mean: 9.19227518179592\n",
      "resetting env. episode reward total was 4.0. running mean: 9.140352429977959\n",
      "resetting env. episode reward total was 7.0. running mean: 9.11894890567818\n",
      "resetting env. episode reward total was 9.0. running mean: 9.117759416621396\n",
      "resetting env. episode reward total was 14.0. running mean: 9.166581822455184\n",
      "resetting env. episode reward total was 8.0. running mean: 9.154916004230632\n",
      "resetting env. episode reward total was 6.0. running mean: 9.123366844188325\n",
      "resetting env. episode reward total was 7.0. running mean: 9.102133175746442\n",
      "resetting env. episode reward total was 16.0. running mean: 9.171111843988978\n",
      "resetting env. episode reward total was 10.0. running mean: 9.179400725549089\n",
      "resetting env. episode reward total was 13.0. running mean: 9.217606718293599\n",
      "resetting env. episode reward total was 4.0. running mean: 9.165430651110661\n",
      "resetting env. episode reward total was 9.0. running mean: 9.163776344599555\n",
      "resetting env. episode reward total was 16.0. running mean: 9.23213858115356\n",
      "resetting env. episode reward total was 5.0. running mean: 9.189817195342025\n",
      "resetting env. episode reward total was 3.0. running mean: 9.127919023388603\n",
      "resetting env. episode reward total was 4.0. running mean: 9.076639833154717\n",
      "resetting env. episode reward total was 8.0. running mean: 9.06587343482317\n",
      "resetting env. episode reward total was 5.0. running mean: 9.025214700474939\n",
      "resetting env. episode reward total was -3.0. running mean: 8.90496255347019\n",
      "resetting env. episode reward total was 8.0. running mean: 8.895912927935488\n",
      "resetting env. episode reward total was 10.0. running mean: 8.906953798656133\n",
      "resetting env. episode reward total was 15.0. running mean: 8.967884260669571\n",
      "resetting env. episode reward total was 1.0. running mean: 8.888205418062874\n",
      "resetting env. episode reward total was 13.0. running mean: 8.929323363882245\n",
      "resetting env. episode reward total was 15.0. running mean: 8.990030130243424\n",
      "resetting env. episode reward total was 15.0. running mean: 9.05012982894099\n",
      "resetting env. episode reward total was 13.0. running mean: 9.08962853065158\n",
      "resetting env. episode reward total was 5.0. running mean: 9.048732245345066\n",
      "resetting env. episode reward total was 3.0. running mean: 8.988244922891615\n",
      "resetting env. episode reward total was 10.0. running mean: 8.998362473662699\n",
      "resetting env. episode reward total was 5.0. running mean: 8.958378848926072\n",
      "resetting env. episode reward total was 14.0. running mean: 9.008795060436812\n",
      "resetting env. episode reward total was 3.0. running mean: 8.948707109832442\n",
      "resetting env. episode reward total was 11.0. running mean: 8.969220038734118\n",
      "resetting env. episode reward total was 6.0. running mean: 8.939527838346777\n",
      "resetting env. episode reward total was 15.0. running mean: 9.00013255996331\n",
      "resetting env. episode reward total was 15.0. running mean: 9.060131234363677\n",
      "resetting env. episode reward total was 15.0. running mean: 9.11952992202004\n",
      "resetting env. episode reward total was 15.0. running mean: 9.178334622799841\n",
      "resetting env. episode reward total was 8.0. running mean: 9.166551276571843\n",
      "resetting env. episode reward total was 1.0. running mean: 9.084885763806124\n",
      "resetting env. episode reward total was 12.0. running mean: 9.114036906168062\n",
      "resetting env. episode reward total was 10.0. running mean: 9.122896537106381\n",
      "resetting env. episode reward total was 11.0. running mean: 9.141667571735317\n",
      "resetting env. episode reward total was 12.0. running mean: 9.170250896017963\n",
      "resetting env. episode reward total was 4.0. running mean: 9.118548387057782\n",
      "resetting env. episode reward total was 15.0. running mean: 9.177362903187204\n",
      "resetting env. episode reward total was 14.0. running mean: 9.225589274155332\n",
      "resetting env. episode reward total was 10.0. running mean: 9.233333381413779\n",
      "resetting env. episode reward total was 7.0. running mean: 9.211000047599642\n",
      "resetting env. episode reward total was 7.0. running mean: 9.188890047123646\n",
      "resetting env. episode reward total was 7.0. running mean: 9.16700114665241\n",
      "resetting env. episode reward total was 9.0. running mean: 9.165331135185886\n",
      "resetting env. episode reward total was 15.0. running mean: 9.223677823834027\n",
      "resetting env. episode reward total was 11.0. running mean: 9.241441045595685\n",
      "resetting env. episode reward total was 13.0. running mean: 9.27902663513973\n",
      "resetting env. episode reward total was 12.0. running mean: 9.306236368788332\n",
      "resetting env. episode reward total was 13.0. running mean: 9.34317400510045\n",
      "resetting env. episode reward total was 6.0. running mean: 9.309742265049445\n",
      "resetting env. episode reward total was 10.0. running mean: 9.31664484239895\n",
      "resetting env. episode reward total was 3.0. running mean: 9.25347839397496\n",
      "resetting env. episode reward total was 5.0. running mean: 9.210943610035212\n",
      "resetting env. episode reward total was 9.0. running mean: 9.208834173934859\n",
      "resetting env. episode reward total was 3.0. running mean: 9.14674583219551\n",
      "resetting env. episode reward total was 7.0. running mean: 9.125278373873556\n",
      "resetting env. episode reward total was 4.0. running mean: 9.07402559013482\n",
      "resetting env. episode reward total was 7.0. running mean: 9.053285334233472\n",
      "resetting env. episode reward total was 15.0. running mean: 9.112752480891137\n",
      "resetting env. episode reward total was 6.0. running mean: 9.081624956082226\n",
      "resetting env. episode reward total was 4.0. running mean: 9.030808706521404\n",
      "resetting env. episode reward total was 2.0. running mean: 8.96050061945619\n",
      "resetting env. episode reward total was 10.0. running mean: 8.970895613261627\n",
      "resetting env. episode reward total was 13.0. running mean: 9.011186657129011\n",
      "resetting env. episode reward total was 11.0. running mean: 9.031074790557721\n",
      "resetting env. episode reward total was 13.0. running mean: 9.070764042652144\n",
      "resetting env. episode reward total was 11.0. running mean: 9.090056402225622\n",
      "resetting env. episode reward total was 13.0. running mean: 9.129155838203367\n",
      "resetting env. episode reward total was 10.0. running mean: 9.137864279821333\n",
      "resetting env. episode reward total was 9.0. running mean: 9.136485637023119\n",
      "resetting env. episode reward total was 15.0. running mean: 9.195120780652887\n",
      "resetting env. episode reward total was 7.0. running mean: 9.173169572846358\n",
      "resetting env. episode reward total was 5.0. running mean: 9.131437877117895\n",
      "resetting env. episode reward total was 12.0. running mean: 9.160123498346715\n",
      "resetting env. episode reward total was 2.0. running mean: 9.088522263363247\n",
      "resetting env. episode reward total was 7.0. running mean: 9.067637040729615\n",
      "resetting env. episode reward total was 14.0. running mean: 9.11696067032232\n",
      "resetting env. episode reward total was 1.0. running mean: 9.035791063619095\n",
      "resetting env. episode reward total was 11.0. running mean: 9.055433152982904\n",
      "resetting env. episode reward total was 14.0. running mean: 9.104878821453076\n",
      "resetting env. episode reward total was 10.0. running mean: 9.113830033238544\n",
      "resetting env. episode reward total was 2.0. running mean: 9.042691732906158\n",
      "resetting env. episode reward total was 16.0. running mean: 9.112264815577097\n",
      "resetting env. episode reward total was 15.0. running mean: 9.171142167421326\n",
      "resetting env. episode reward total was 9.0. running mean: 9.169430745747112\n",
      "resetting env. episode reward total was 4.0. running mean: 9.11773643828964\n",
      "resetting env. episode reward total was 5.0. running mean: 9.076559073906743\n",
      "resetting env. episode reward total was 7.0. running mean: 9.055793483167676\n",
      "resetting env. episode reward total was 3.0. running mean: 8.995235548335998\n",
      "resetting env. episode reward total was 4.0. running mean: 8.945283192852637\n",
      "resetting env. episode reward total was 13.0. running mean: 8.985830360924112\n",
      "resetting env. episode reward total was -5.0. running mean: 8.84597205731487\n",
      "resetting env. episode reward total was 10.0. running mean: 8.857512336741722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 18.0. running mean: 8.948937213374304\n",
      "resetting env. episode reward total was 8.0. running mean: 8.939447841240561\n",
      "resetting env. episode reward total was 13.0. running mean: 8.980053362828157\n",
      "resetting env. episode reward total was 13.0. running mean: 9.020252829199876\n",
      "resetting env. episode reward total was 6.0. running mean: 8.990050300907878\n",
      "resetting env. episode reward total was 4.0. running mean: 8.9401497978988\n",
      "resetting env. episode reward total was 14.0. running mean: 8.990748299919812\n",
      "resetting env. episode reward total was 10.0. running mean: 9.000840816920613\n",
      "resetting env. episode reward total was 13.0. running mean: 9.040832408751408\n",
      "resetting env. episode reward total was 11.0. running mean: 9.060424084663893\n",
      "resetting env. episode reward total was 6.0. running mean: 9.029819843817254\n",
      "resetting env. episode reward total was 15.0. running mean: 9.089521645379081\n",
      "resetting env. episode reward total was 14.0. running mean: 9.13862642892529\n",
      "resetting env. episode reward total was 2.0. running mean: 9.067240164636036\n",
      "resetting env. episode reward total was 14.0. running mean: 9.116567762989677\n",
      "resetting env. episode reward total was 15.0. running mean: 9.17540208535978\n",
      "resetting env. episode reward total was 9.0. running mean: 9.173648064506182\n",
      "resetting env. episode reward total was 11.0. running mean: 9.191911583861119\n",
      "resetting env. episode reward total was 10.0. running mean: 9.199992468022508\n",
      "resetting env. episode reward total was 15.0. running mean: 9.257992543342283\n",
      "resetting env. episode reward total was 2.0. running mean: 9.18541261790886\n",
      "resetting env. episode reward total was 8.0. running mean: 9.173558491729771\n",
      "resetting env. episode reward total was 9.0. running mean: 9.171822906812473\n",
      "resetting env. episode reward total was 5.0. running mean: 9.130104677744349\n",
      "resetting env. episode reward total was 5.0. running mean: 9.088803630966906\n",
      "resetting env. episode reward total was 14.0. running mean: 9.137915594657237\n",
      "resetting env. episode reward total was 10.0. running mean: 9.146536438710664\n",
      "resetting env. episode reward total was -1.0. running mean: 9.045071074323557\n",
      "resetting env. episode reward total was 11.0. running mean: 9.064620363580321\n",
      "resetting env. episode reward total was 4.0. running mean: 9.013974159944517\n",
      "resetting env. episode reward total was 9.0. running mean: 9.013834418345072\n",
      "resetting env. episode reward total was 10.0. running mean: 9.02369607416162\n",
      "resetting env. episode reward total was -3.0. running mean: 8.903459113420004\n",
      "resetting env. episode reward total was 4.0. running mean: 8.854424522285802\n",
      "resetting env. episode reward total was 8.0. running mean: 8.845880277062944\n",
      "resetting env. episode reward total was 7.0. running mean: 8.827421474292315\n",
      "resetting env. episode reward total was 18.0. running mean: 8.91914725954939\n",
      "resetting env. episode reward total was 8.0. running mean: 8.909955786953896\n",
      "resetting env. episode reward total was 9.0. running mean: 8.910856229084358\n",
      "resetting env. episode reward total was -6.0. running mean: 8.761747666793513\n",
      "resetting env. episode reward total was 8.0. running mean: 8.754130190125577\n",
      "resetting env. episode reward total was 4.0. running mean: 8.70658888822432\n",
      "resetting env. episode reward total was 15.0. running mean: 8.769522999342078\n",
      "resetting env. episode reward total was 12.0. running mean: 8.801827769348655\n",
      "resetting env. episode reward total was 5.0. running mean: 8.76380949165517\n",
      "resetting env. episode reward total was 7.0. running mean: 8.74617139673862\n",
      "resetting env. episode reward total was 11.0. running mean: 8.768709682771233\n",
      "resetting env. episode reward total was 10.0. running mean: 8.78102258594352\n",
      "resetting env. episode reward total was 10.0. running mean: 8.793212360084084\n",
      "resetting env. episode reward total was 12.0. running mean: 8.825280236483243\n",
      "resetting env. episode reward total was 20.0. running mean: 8.93702743411841\n",
      "resetting env. episode reward total was 14.0. running mean: 8.987657159777225\n",
      "resetting env. episode reward total was 8.0. running mean: 8.977780588179453\n",
      "resetting env. episode reward total was 15.0. running mean: 9.038002782297658\n",
      "resetting env. episode reward total was 13.0. running mean: 9.077622754474682\n",
      "resetting env. episode reward total was 12.0. running mean: 9.106846526929933\n",
      "resetting env. episode reward total was 13.0. running mean: 9.145778061660636\n",
      "resetting env. episode reward total was 13.0. running mean: 9.18432028104403\n",
      "resetting env. episode reward total was 10.0. running mean: 9.192477078233589\n",
      "resetting env. episode reward total was 14.0. running mean: 9.240552307451253\n",
      "resetting env. episode reward total was 8.0. running mean: 9.22814678437674\n",
      "resetting env. episode reward total was 12.0. running mean: 9.255865316532972\n",
      "resetting env. episode reward total was 5.0. running mean: 9.213306663367643\n",
      "resetting env. episode reward total was 13.0. running mean: 9.251173596733967\n",
      "resetting env. episode reward total was 16.0. running mean: 9.318661860766627\n",
      "resetting env. episode reward total was 11.0. running mean: 9.33547524215896\n",
      "resetting env. episode reward total was 15.0. running mean: 9.392120489737371\n",
      "resetting env. episode reward total was 14.0. running mean: 9.438199284839998\n",
      "resetting env. episode reward total was 7.0. running mean: 9.413817291991599\n",
      "resetting env. episode reward total was 3.0. running mean: 9.349679119071682\n",
      "resetting env. episode reward total was 12.0. running mean: 9.376182327880965\n",
      "resetting env. episode reward total was 9.0. running mean: 9.372420504602156\n",
      "resetting env. episode reward total was 8.0. running mean: 9.358696299556135\n",
      "resetting env. episode reward total was 9.0. running mean: 9.355109336560574\n",
      "resetting env. episode reward total was 5.0. running mean: 9.311558243194968\n",
      "resetting env. episode reward total was 15.0. running mean: 9.36844266076302\n",
      "resetting env. episode reward total was -2.0. running mean: 9.25475823415539\n",
      "resetting env. episode reward total was 4.0. running mean: 9.202210651813834\n",
      "resetting env. episode reward total was 1.0. running mean: 9.120188545295695\n",
      "resetting env. episode reward total was 5.0. running mean: 9.07898665984274\n",
      "resetting env. episode reward total was 3.0. running mean: 9.01819679324431\n",
      "resetting env. episode reward total was 11.0. running mean: 9.038014825311867\n",
      "resetting env. episode reward total was 9.0. running mean: 9.03763467705875\n",
      "resetting env. episode reward total was 16.0. running mean: 9.107258330288161\n",
      "resetting env. episode reward total was 6.0. running mean: 9.07618574698528\n",
      "resetting env. episode reward total was 4.0. running mean: 9.025423889515427\n",
      "resetting env. episode reward total was 10.0. running mean: 9.035169650620272\n",
      "resetting env. episode reward total was 8.0. running mean: 9.02481795411407\n",
      "resetting env. episode reward total was 13.0. running mean: 9.06456977457293\n",
      "resetting env. episode reward total was 10.0. running mean: 9.0739240768272\n",
      "resetting env. episode reward total was 15.0. running mean: 9.133184836058929\n",
      "resetting env. episode reward total was -2.0. running mean: 9.02185298769834\n",
      "resetting env. episode reward total was 9.0. running mean: 9.021634457821357\n",
      "resetting env. episode reward total was 10.0. running mean: 9.031418113243143\n",
      "resetting env. episode reward total was 14.0. running mean: 9.081103932110713\n",
      "resetting env. episode reward total was 6.0. running mean: 9.050292892789606\n",
      "resetting env. episode reward total was 5.0. running mean: 9.009789963861712\n",
      "resetting env. episode reward total was 15.0. running mean: 9.069692064223094\n",
      "resetting env. episode reward total was 7.0. running mean: 9.048995143580864\n",
      "resetting env. episode reward total was 15.0. running mean: 9.108505192145056\n",
      "resetting env. episode reward total was 6.0. running mean: 9.077420140223607\n",
      "resetting env. episode reward total was 9.0. running mean: 9.07664593882137\n",
      "resetting env. episode reward total was 7.0. running mean: 9.055879479433157\n",
      "resetting env. episode reward total was 12.0. running mean: 9.085320684638825\n",
      "resetting env. episode reward total was 3.0. running mean: 9.024467477792436\n",
      "resetting env. episode reward total was 8.0. running mean: 9.014222803014512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 9.014080574984366\n",
      "resetting env. episode reward total was 12.0. running mean: 9.043939769234521\n",
      "resetting env. episode reward total was 11.0. running mean: 9.063500371542176\n",
      "resetting env. episode reward total was 10.0. running mean: 9.072865367826754\n",
      "resetting env. episode reward total was 1.0. running mean: 8.992136714148486\n",
      "resetting env. episode reward total was 13.0. running mean: 9.032215347007002\n",
      "resetting env. episode reward total was 10.0. running mean: 9.04189319353693\n",
      "resetting env. episode reward total was 6.0. running mean: 9.011474261601562\n",
      "resetting env. episode reward total was -5.0. running mean: 8.871359518985544\n",
      "resetting env. episode reward total was 10.0. running mean: 8.882645923795689\n",
      "resetting env. episode reward total was 11.0. running mean: 8.903819464557731\n",
      "resetting env. episode reward total was 17.0. running mean: 8.984781269912153\n",
      "resetting env. episode reward total was 12.0. running mean: 9.014933457213031\n",
      "resetting env. episode reward total was 7.0. running mean: 8.994784122640901\n",
      "resetting env. episode reward total was 13.0. running mean: 9.034836281414492\n",
      "resetting env. episode reward total was 7.0. running mean: 9.014487918600347\n",
      "resetting env. episode reward total was 15.0. running mean: 9.074343039414345\n",
      "resetting env. episode reward total was 8.0. running mean: 9.063599609020201\n",
      "resetting env. episode reward total was 3.0. running mean: 9.00296361293\n",
      "resetting env. episode reward total was 2.0. running mean: 8.9329339768007\n",
      "resetting env. episode reward total was 7.0. running mean: 8.913604637032693\n",
      "resetting env. episode reward total was 13.0. running mean: 8.954468590662367\n",
      "resetting env. episode reward total was 4.0. running mean: 8.904923904755742\n",
      "resetting env. episode reward total was 6.0. running mean: 8.875874665708185\n",
      "resetting env. episode reward total was 15.0. running mean: 8.937115919051104\n",
      "resetting env. episode reward total was 14.0. running mean: 8.987744759860593\n",
      "resetting env. episode reward total was 11.0. running mean: 9.007867312261986\n",
      "resetting env. episode reward total was 15.0. running mean: 9.067788639139367\n",
      "resetting env. episode reward total was -2.0. running mean: 8.957110752747974\n",
      "resetting env. episode reward total was 13.0. running mean: 8.997539645220495\n",
      "resetting env. episode reward total was 11.0. running mean: 9.01756424876829\n",
      "resetting env. episode reward total was 8.0. running mean: 9.007388606280607\n",
      "resetting env. episode reward total was 6.0. running mean: 8.977314720217802\n",
      "resetting env. episode reward total was 13.0. running mean: 9.017541573015624\n",
      "resetting env. episode reward total was 11.0. running mean: 9.037366157285467\n",
      "resetting env. episode reward total was 8.0. running mean: 9.026992495712612\n",
      "resetting env. episode reward total was 13.0. running mean: 9.066722570755486\n",
      "resetting env. episode reward total was 14.0. running mean: 9.116055345047931\n",
      "resetting env. episode reward total was 11.0. running mean: 9.134894791597452\n",
      "resetting env. episode reward total was 10.0. running mean: 9.143545843681476\n",
      "resetting env. episode reward total was 13.0. running mean: 9.182110385244663\n",
      "resetting env. episode reward total was 13.0. running mean: 9.220289281392217\n",
      "resetting env. episode reward total was 2.0. running mean: 9.148086388578294\n",
      "resetting env. episode reward total was 8.0. running mean: 9.136605524692511\n",
      "resetting env. episode reward total was 15.0. running mean: 9.195239469445585\n",
      "resetting env. episode reward total was 18.0. running mean: 9.28328707475113\n",
      "resetting env. episode reward total was -9.0. running mean: 9.100454204003618\n",
      "resetting env. episode reward total was 5.0. running mean: 9.059449661963583\n",
      "resetting env. episode reward total was 13.0. running mean: 9.098855165343949\n",
      "resetting env. episode reward total was 10.0. running mean: 9.10786661369051\n",
      "resetting env. episode reward total was 13.0. running mean: 9.146787947553605\n",
      "resetting env. episode reward total was 4.0. running mean: 9.095320068078069\n",
      "resetting env. episode reward total was 13.0. running mean: 9.134366867397288\n",
      "resetting env. episode reward total was 8.0. running mean: 9.123023198723315\n",
      "resetting env. episode reward total was 5.0. running mean: 9.081792966736083\n",
      "resetting env. episode reward total was 14.0. running mean: 9.130975037068723\n",
      "resetting env. episode reward total was 9.0. running mean: 9.129665286698035\n",
      "resetting env. episode reward total was 14.0. running mean: 9.178368633831056\n",
      "resetting env. episode reward total was 16.0. running mean: 9.246584947492746\n",
      "resetting env. episode reward total was 8.0. running mean: 9.234119098017818\n",
      "resetting env. episode reward total was 4.0. running mean: 9.181777907037638\n",
      "resetting env. episode reward total was 8.0. running mean: 9.169960127967261\n",
      "resetting env. episode reward total was 11.0. running mean: 9.188260526687587\n",
      "resetting env. episode reward total was 7.0. running mean: 9.166377921420711\n",
      "resetting env. episode reward total was 14.0. running mean: 9.214714142206505\n",
      "resetting env. episode reward total was 10.0. running mean: 9.222567000784439\n",
      "resetting env. episode reward total was 7.0. running mean: 9.200341330776595\n",
      "resetting env. episode reward total was 11.0. running mean: 9.218337917468828\n",
      "resetting env. episode reward total was 12.0. running mean: 9.246154538294139\n",
      "resetting env. episode reward total was 14.0. running mean: 9.293692992911199\n",
      "resetting env. episode reward total was 14.0. running mean: 9.340756062982088\n",
      "resetting env. episode reward total was 5.0. running mean: 9.297348502352268\n",
      "resetting env. episode reward total was 3.0. running mean: 9.234375017328745\n",
      "resetting env. episode reward total was 8.0. running mean: 9.222031267155458\n",
      "resetting env. episode reward total was 12.0. running mean: 9.249810954483902\n",
      "resetting env. episode reward total was 14.0. running mean: 9.297312844939063\n",
      "resetting env. episode reward total was 8.0. running mean: 9.284339716489672\n",
      "resetting env. episode reward total was 8.0. running mean: 9.271496319324775\n",
      "resetting env. episode reward total was 6.0. running mean: 9.238781356131527\n",
      "resetting env. episode reward total was 3.0. running mean: 9.176393542570212\n",
      "resetting env. episode reward total was 5.0. running mean: 9.134629607144511\n",
      "resetting env. episode reward total was 15.0. running mean: 9.193283311073067\n",
      "resetting env. episode reward total was 11.0. running mean: 9.211350477962336\n",
      "resetting env. episode reward total was 10.0. running mean: 9.219236973182712\n",
      "resetting env. episode reward total was -1.0. running mean: 9.117044603450886\n",
      "resetting env. episode reward total was 9.0. running mean: 9.115874157416377\n",
      "resetting env. episode reward total was 4.0. running mean: 9.064715415842212\n",
      "resetting env. episode reward total was 8.0. running mean: 9.05406826168379\n",
      "resetting env. episode reward total was 10.0. running mean: 9.063527579066951\n",
      "resetting env. episode reward total was 11.0. running mean: 9.082892303276282\n",
      "resetting env. episode reward total was -3.0. running mean: 8.962063380243519\n",
      "resetting env. episode reward total was 4.0. running mean: 8.912442746441084\n",
      "resetting env. episode reward total was 12.0. running mean: 8.943318318976672\n",
      "resetting env. episode reward total was 6.0. running mean: 8.913885135786906\n",
      "resetting env. episode reward total was 6.0. running mean: 8.884746284429037\n",
      "resetting env. episode reward total was 6.0. running mean: 8.855898821584747\n",
      "resetting env. episode reward total was 10.0. running mean: 8.867339833368899\n",
      "resetting env. episode reward total was 8.0. running mean: 8.85866643503521\n",
      "resetting env. episode reward total was 9.0. running mean: 8.860079770684857\n",
      "resetting env. episode reward total was 8.0. running mean: 8.851478972978008\n",
      "resetting env. episode reward total was 12.0. running mean: 8.882964183248227\n",
      "resetting env. episode reward total was 4.0. running mean: 8.834134541415743\n",
      "resetting env. episode reward total was 11.0. running mean: 8.855793196001585\n",
      "resetting env. episode reward total was 9.0. running mean: 8.857235264041568\n",
      "resetting env. episode reward total was 11.0. running mean: 8.878662911401152\n",
      "resetting env. episode reward total was 12.0. running mean: 8.90987628228714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 8.840777519464268\n",
      "resetting env. episode reward total was 7.0. running mean: 8.822369744269626\n",
      "resetting env. episode reward total was 10.0. running mean: 8.834146046826929\n",
      "resetting env. episode reward total was 7.0. running mean: 8.81580458635866\n",
      "resetting env. episode reward total was 12.0. running mean: 8.847646540495072\n",
      "resetting env. episode reward total was 15.0. running mean: 8.909170075090122\n",
      "resetting env. episode reward total was 7.0. running mean: 8.890078374339222\n",
      "resetting env. episode reward total was 5.0. running mean: 8.85117759059583\n",
      "resetting env. episode reward total was 16.0. running mean: 8.922665814689871\n",
      "resetting env. episode reward total was 11.0. running mean: 8.943439156542972\n",
      "resetting env. episode reward total was 9.0. running mean: 8.944004764977542\n",
      "resetting env. episode reward total was 8.0. running mean: 8.934564717327767\n",
      "resetting env. episode reward total was 4.0. running mean: 8.885219070154488\n",
      "resetting env. episode reward total was 9.0. running mean: 8.886366879452943\n",
      "resetting env. episode reward total was 13.0. running mean: 8.927503210658415\n",
      "resetting env. episode reward total was 18.0. running mean: 9.01822817855183\n",
      "resetting env. episode reward total was 14.0. running mean: 9.068045896766312\n",
      "resetting env. episode reward total was 6.0. running mean: 9.03736543779865\n",
      "resetting env. episode reward total was 1.0. running mean: 8.956991783420664\n",
      "resetting env. episode reward total was 6.0. running mean: 8.927421865586458\n",
      "resetting env. episode reward total was 9.0. running mean: 8.928147646930594\n",
      "resetting env. episode reward total was 9.0. running mean: 8.928866170461287\n",
      "resetting env. episode reward total was 4.0. running mean: 8.879577508756674\n",
      "resetting env. episode reward total was 9.0. running mean: 8.880781733669107\n",
      "resetting env. episode reward total was 7.0. running mean: 8.861973916332415\n",
      "resetting env. episode reward total was 8.0. running mean: 8.853354177169091\n",
      "resetting env. episode reward total was 9.0. running mean: 8.8548206353974\n",
      "resetting env. episode reward total was 14.0. running mean: 8.906272429043428\n",
      "resetting env. episode reward total was 1.0. running mean: 8.827209704752994\n",
      "resetting env. episode reward total was 11.0. running mean: 8.848937607705462\n",
      "resetting env. episode reward total was 5.0. running mean: 8.810448231628408\n",
      "resetting env. episode reward total was 8.0. running mean: 8.802343749312124\n",
      "resetting env. episode reward total was 12.0. running mean: 8.834320311819003\n",
      "resetting env. episode reward total was 8.0. running mean: 8.825977108700812\n",
      "resetting env. episode reward total was 8.0. running mean: 8.817717337613804\n",
      "resetting env. episode reward total was 15.0. running mean: 8.879540164237666\n",
      "resetting env. episode reward total was 9.0. running mean: 8.880744762595288\n",
      "resetting env. episode reward total was 13.0. running mean: 8.921937314969336\n",
      "resetting env. episode reward total was 7.0. running mean: 8.902717941819642\n",
      "resetting env. episode reward total was 16.0. running mean: 8.973690762401445\n",
      "resetting env. episode reward total was 12.0. running mean: 9.003953854777428\n",
      "resetting env. episode reward total was 8.0. running mean: 8.993914316229654\n",
      "resetting env. episode reward total was 14.0. running mean: 9.043975173067357\n",
      "resetting env. episode reward total was 6.0. running mean: 9.013535421336684\n",
      "resetting env. episode reward total was 11.0. running mean: 9.033400067123317\n",
      "resetting env. episode reward total was 13.0. running mean: 9.073066066452084\n",
      "resetting env. episode reward total was 2.0. running mean: 9.002335405787562\n",
      "resetting env. episode reward total was 4.0. running mean: 8.952312051729686\n",
      "resetting env. episode reward total was 13.0. running mean: 8.99278893121239\n",
      "resetting env. episode reward total was 12.0. running mean: 9.022861041900265\n",
      "resetting env. episode reward total was 7.0. running mean: 9.002632431481263\n",
      "resetting env. episode reward total was 8.0. running mean: 8.99260610716645\n",
      "resetting env. episode reward total was 10.0. running mean: 9.002680046094785\n",
      "resetting env. episode reward total was 18.0. running mean: 9.092653245633837\n",
      "resetting env. episode reward total was 7.0. running mean: 9.0717267131775\n",
      "resetting env. episode reward total was 13.0. running mean: 9.111009446045726\n",
      "resetting env. episode reward total was 5.0. running mean: 9.069899351585269\n",
      "resetting env. episode reward total was 10.0. running mean: 9.079200358069416\n",
      "resetting env. episode reward total was 9.0. running mean: 9.078408354488722\n",
      "resetting env. episode reward total was 7.0. running mean: 9.057624270943835\n",
      "resetting env. episode reward total was 8.0. running mean: 9.047048028234396\n",
      "resetting env. episode reward total was 5.0. running mean: 9.006577547952054\n",
      "resetting env. episode reward total was 8.0. running mean: 8.996511772472534\n",
      "resetting env. episode reward total was 7.0. running mean: 8.976546654747809\n",
      "resetting env. episode reward total was 8.0. running mean: 8.966781188200331\n",
      "resetting env. episode reward total was 6.0. running mean: 8.937113376318328\n",
      "resetting env. episode reward total was 12.0. running mean: 8.967742242555143\n",
      "resetting env. episode reward total was 13.0. running mean: 9.008064820129592\n",
      "resetting env. episode reward total was 7.0. running mean: 8.987984171928296\n",
      "resetting env. episode reward total was 8.0. running mean: 8.978104330209014\n",
      "resetting env. episode reward total was 6.0. running mean: 8.948323286906925\n",
      "resetting env. episode reward total was 16.0. running mean: 9.018840054037856\n",
      "resetting env. episode reward total was 10.0. running mean: 9.028651653497477\n",
      "resetting env. episode reward total was 14.0. running mean: 9.078365136962502\n",
      "resetting env. episode reward total was 11.0. running mean: 9.097581485592876\n",
      "resetting env. episode reward total was 9.0. running mean: 9.096605670736947\n",
      "resetting env. episode reward total was 9.0. running mean: 9.095639614029578\n",
      "resetting env. episode reward total was 12.0. running mean: 9.124683217889281\n",
      "resetting env. episode reward total was 10.0. running mean: 9.133436385710388\n",
      "resetting env. episode reward total was -4.0. running mean: 9.002102021853284\n",
      "resetting env. episode reward total was 11.0. running mean: 9.022081001634751\n",
      "resetting env. episode reward total was 11.0. running mean: 9.041860191618403\n",
      "resetting env. episode reward total was 6.0. running mean: 9.011441589702219\n",
      "resetting env. episode reward total was 8.0. running mean: 9.001327173805198\n",
      "resetting env. episode reward total was 11.0. running mean: 9.021313902067146\n",
      "resetting env. episode reward total was 2.0. running mean: 8.951100763046474\n",
      "resetting env. episode reward total was 15.0. running mean: 9.01158975541601\n",
      "resetting env. episode reward total was 15.0. running mean: 9.07147385786185\n",
      "resetting env. episode reward total was 13.0. running mean: 9.110759119283232\n",
      "resetting env. episode reward total was 3.0. running mean: 9.049651528090399\n",
      "resetting env. episode reward total was 10.0. running mean: 9.059155012809494\n",
      "resetting env. episode reward total was 11.0. running mean: 9.078563462681398\n",
      "resetting env. episode reward total was 12.0. running mean: 9.107777828054584\n",
      "resetting env. episode reward total was 8.0. running mean: 9.096700049774038\n",
      "resetting env. episode reward total was 14.0. running mean: 9.145733049276298\n",
      "resetting env. episode reward total was 7.0. running mean: 9.124275718783535\n",
      "resetting env. episode reward total was 17.0. running mean: 9.2030329615957\n",
      "resetting env. episode reward total was 7.0. running mean: 9.181002631979743\n",
      "resetting env. episode reward total was 11.0. running mean: 9.199192605659945\n",
      "resetting env. episode reward total was 10.0. running mean: 9.207200679603346\n",
      "resetting env. episode reward total was 9.0. running mean: 9.205128672807312\n",
      "resetting env. episode reward total was 7.0. running mean: 9.183077386079239\n",
      "resetting env. episode reward total was 6.0. running mean: 9.151246612218447\n",
      "resetting env. episode reward total was 1.0. running mean: 9.069734146096263\n",
      "resetting env. episode reward total was 17.0. running mean: 9.1490368046353\n",
      "resetting env. episode reward total was -1.0. running mean: 9.047546436588947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 9.057070972223057\n",
      "resetting env. episode reward total was 15.0. running mean: 9.116500262500827\n",
      "resetting env. episode reward total was 15.0. running mean: 9.175335259875819\n",
      "resetting env. episode reward total was 9.0. running mean: 9.173581907277061\n",
      "resetting env. episode reward total was 17.0. running mean: 9.25184608820429\n",
      "resetting env. episode reward total was 5.0. running mean: 9.209327627322248\n",
      "resetting env. episode reward total was 9.0. running mean: 9.207234351049024\n",
      "resetting env. episode reward total was 7.0. running mean: 9.185162007538533\n",
      "resetting env. episode reward total was 11.0. running mean: 9.203310387463148\n",
      "resetting env. episode reward total was 14.0. running mean: 9.251277283588516\n",
      "resetting env. episode reward total was 9.0. running mean: 9.24876451075263\n",
      "resetting env. episode reward total was 12.0. running mean: 9.276276865645103\n",
      "resetting env. episode reward total was 10.0. running mean: 9.283514096988652\n",
      "resetting env. episode reward total was 12.0. running mean: 9.310678956018764\n",
      "resetting env. episode reward total was 2.0. running mean: 9.237572166458575\n",
      "resetting env. episode reward total was 12.0. running mean: 9.265196444793988\n",
      "resetting env. episode reward total was 9.0. running mean: 9.262544480346047\n",
      "resetting env. episode reward total was -1.0. running mean: 9.159919035542588\n",
      "resetting env. episode reward total was 12.0. running mean: 9.188319845187161\n",
      "resetting env. episode reward total was 11.0. running mean: 9.20643664673529\n",
      "resetting env. episode reward total was 8.0. running mean: 9.194372280267936\n",
      "resetting env. episode reward total was 3.0. running mean: 9.132428557465257\n",
      "resetting env. episode reward total was 17.0. running mean: 9.211104271890605\n",
      "resetting env. episode reward total was 11.0. running mean: 9.228993229171698\n",
      "resetting env. episode reward total was 13.0. running mean: 9.266703296879982\n",
      "resetting env. episode reward total was 14.0. running mean: 9.314036263911182\n",
      "resetting env. episode reward total was 1.0. running mean: 9.23089590127207\n",
      "resetting env. episode reward total was 12.0. running mean: 9.258586942259349\n",
      "resetting env. episode reward total was 11.0. running mean: 9.276001072836754\n",
      "resetting env. episode reward total was 8.0. running mean: 9.263241062108387\n",
      "resetting env. episode reward total was 10.0. running mean: 9.270608651487303\n",
      "resetting env. episode reward total was 11.0. running mean: 9.287902564972429\n",
      "resetting env. episode reward total was 6.0. running mean: 9.255023539322705\n",
      "resetting env. episode reward total was 10.0. running mean: 9.262473303929477\n",
      "resetting env. episode reward total was 3.0. running mean: 9.199848570890182\n",
      "resetting env. episode reward total was 17.0. running mean: 9.27785008518128\n",
      "resetting env. episode reward total was 14.0. running mean: 9.325071584329468\n",
      "resetting env. episode reward total was 8.0. running mean: 9.311820868486173\n",
      "resetting env. episode reward total was 11.0. running mean: 9.32870265980131\n",
      "resetting env. episode reward total was 14.0. running mean: 9.375415633203298\n",
      "resetting env. episode reward total was -1.0. running mean: 9.271661476871266\n",
      "resetting env. episode reward total was 13.0. running mean: 9.308944862102553\n",
      "resetting env. episode reward total was 13.0. running mean: 9.345855413481528\n",
      "resetting env. episode reward total was 10.0. running mean: 9.352396859346713\n",
      "resetting env. episode reward total was 9.0. running mean: 9.348872890753245\n",
      "resetting env. episode reward total was 10.0. running mean: 9.355384161845713\n",
      "resetting env. episode reward total was 9.0. running mean: 9.351830320227256\n",
      "resetting env. episode reward total was 13.0. running mean: 9.388312017024983\n",
      "resetting env. episode reward total was 14.0. running mean: 9.434428896854733\n",
      "resetting env. episode reward total was 9.0. running mean: 9.430084607886185\n",
      "resetting env. episode reward total was 5.0. running mean: 9.385783761807323\n",
      "resetting env. episode reward total was 11.0. running mean: 9.40192592418925\n",
      "resetting env. episode reward total was 11.0. running mean: 9.417906664947356\n",
      "resetting env. episode reward total was 16.0. running mean: 9.483727598297882\n",
      "resetting env. episode reward total was 4.0. running mean: 9.428890322314903\n",
      "resetting env. episode reward total was 11.0. running mean: 9.444601419091754\n",
      "resetting env. episode reward total was 8.0. running mean: 9.430155404900836\n",
      "resetting env. episode reward total was 10.0. running mean: 9.435853850851826\n",
      "resetting env. episode reward total was 9.0. running mean: 9.431495312343309\n",
      "resetting env. episode reward total was 14.0. running mean: 9.477180359219876\n",
      "resetting env. episode reward total was 6.0. running mean: 9.442408555627678\n",
      "resetting env. episode reward total was 6.0. running mean: 9.407984470071401\n",
      "resetting env. episode reward total was -1.0. running mean: 9.303904625370688\n",
      "resetting env. episode reward total was 8.0. running mean: 9.29086557911698\n",
      "resetting env. episode reward total was 8.0. running mean: 9.27795692332581\n",
      "resetting env. episode reward total was -4.0. running mean: 9.145177354092553\n",
      "resetting env. episode reward total was 9.0. running mean: 9.143725580551628\n",
      "resetting env. episode reward total was 15.0. running mean: 9.202288324746112\n",
      "resetting env. episode reward total was 15.0. running mean: 9.260265441498651\n",
      "resetting env. episode reward total was 10.0. running mean: 9.267662787083664\n",
      "resetting env. episode reward total was -3.0. running mean: 9.144986159212827\n",
      "resetting env. episode reward total was 9.0. running mean: 9.143536297620699\n",
      "resetting env. episode reward total was 13.0. running mean: 9.182100934644492\n",
      "resetting env. episode reward total was 12.0. running mean: 9.210279925298046\n",
      "resetting env. episode reward total was 8.0. running mean: 9.198177126045065\n",
      "resetting env. episode reward total was 8.0. running mean: 9.186195354784614\n",
      "resetting env. episode reward total was 9.0. running mean: 9.184333401236767\n",
      "resetting env. episode reward total was 6.0. running mean: 9.1524900672244\n",
      "resetting env. episode reward total was 11.0. running mean: 9.170965166552156\n",
      "resetting env. episode reward total was 10.0. running mean: 9.179255514886634\n",
      "resetting env. episode reward total was 8.0. running mean: 9.167462959737767\n",
      "resetting env. episode reward total was 14.0. running mean: 9.21578833014039\n",
      "resetting env. episode reward total was 6.0. running mean: 9.183630446838986\n",
      "resetting env. episode reward total was 13.0. running mean: 9.221794142370596\n",
      "resetting env. episode reward total was 12.0. running mean: 9.249576200946889\n",
      "resetting env. episode reward total was 12.0. running mean: 9.27708043893742\n",
      "resetting env. episode reward total was 12.0. running mean: 9.304309634548044\n",
      "resetting env. episode reward total was 10.0. running mean: 9.311266538202563\n",
      "resetting env. episode reward total was 12.0. running mean: 9.338153872820536\n",
      "resetting env. episode reward total was 8.0. running mean: 9.32477233409233\n",
      "resetting env. episode reward total was 20.0. running mean: 9.431524610751406\n",
      "resetting env. episode reward total was 14.0. running mean: 9.477209364643892\n",
      "resetting env. episode reward total was 8.0. running mean: 9.462437270997453\n",
      "resetting env. episode reward total was 11.0. running mean: 9.477812898287478\n",
      "resetting env. episode reward total was 4.0. running mean: 9.423034769304602\n",
      "resetting env. episode reward total was 9.0. running mean: 9.418804421611556\n",
      "resetting env. episode reward total was 11.0. running mean: 9.43461637739544\n",
      "resetting env. episode reward total was 17.0. running mean: 9.510270213621485\n",
      "resetting env. episode reward total was -3.0. running mean: 9.385167511485271\n",
      "resetting env. episode reward total was 12.0. running mean: 9.411315836370418\n",
      "resetting env. episode reward total was 12.0. running mean: 9.437202678006713\n",
      "resetting env. episode reward total was 9.0. running mean: 9.432830651226645\n",
      "resetting env. episode reward total was -8.0. running mean: 9.258502344714378\n",
      "resetting env. episode reward total was 11.0. running mean: 9.275917321267233\n",
      "resetting env. episode reward total was 5.0. running mean: 9.233158148054562\n",
      "resetting env. episode reward total was 17.0. running mean: 9.310826566574017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 9.287718300908276\n",
      "resetting env. episode reward total was 12.0. running mean: 9.314841117899192\n",
      "resetting env. episode reward total was 14.0. running mean: 9.3616927067202\n",
      "resetting env. episode reward total was 8.0. running mean: 9.348075779652998\n",
      "resetting env. episode reward total was 9.0. running mean: 9.344595021856467\n",
      "resetting env. episode reward total was 8.0. running mean: 9.331149071637903\n",
      "resetting env. episode reward total was 14.0. running mean: 9.377837580921524\n",
      "resetting env. episode reward total was 11.0. running mean: 9.394059205112308\n",
      "resetting env. episode reward total was 9.0. running mean: 9.390118613061185\n",
      "resetting env. episode reward total was 10.0. running mean: 9.396217426930573\n",
      "resetting env. episode reward total was 16.0. running mean: 9.462255252661267\n",
      "resetting env. episode reward total was 4.0. running mean: 9.407632700134654\n",
      "resetting env. episode reward total was 11.0. running mean: 9.423556373133307\n",
      "resetting env. episode reward total was 12.0. running mean: 9.449320809401973\n",
      "resetting env. episode reward total was 6.0. running mean: 9.414827601307953\n",
      "resetting env. episode reward total was 15.0. running mean: 9.470679325294874\n",
      "resetting env. episode reward total was 10.0. running mean: 9.475972532041926\n",
      "resetting env. episode reward total was 11.0. running mean: 9.491212806721506\n",
      "resetting env. episode reward total was -2.0. running mean: 9.376300678654292\n",
      "resetting env. episode reward total was 8.0. running mean: 9.362537671867749\n",
      "resetting env. episode reward total was 4.0. running mean: 9.30891229514907\n",
      "resetting env. episode reward total was 14.0. running mean: 9.35582317219758\n",
      "resetting env. episode reward total was 8.0. running mean: 9.342264940475603\n",
      "resetting env. episode reward total was 13.0. running mean: 9.378842291070848\n",
      "resetting env. episode reward total was 7.0. running mean: 9.35505386816014\n",
      "resetting env. episode reward total was 10.0. running mean: 9.361503329478538\n",
      "resetting env. episode reward total was -1.0. running mean: 9.257888296183753\n",
      "resetting env. episode reward total was 5.0. running mean: 9.215309413221915\n",
      "resetting env. episode reward total was 7.0. running mean: 9.193156319089695\n",
      "resetting env. episode reward total was 15.0. running mean: 9.251224755898798\n",
      "resetting env. episode reward total was 6.0. running mean: 9.218712508339811\n",
      "resetting env. episode reward total was 9.0. running mean: 9.216525383256412\n",
      "resetting env. episode reward total was 12.0. running mean: 9.244360129423848\n",
      "resetting env. episode reward total was 6.0. running mean: 9.21191652812961\n",
      "resetting env. episode reward total was 15.0. running mean: 9.269797362848314\n",
      "resetting env. episode reward total was 15.0. running mean: 9.32709938921983\n",
      "resetting env. episode reward total was 12.0. running mean: 9.35382839532763\n",
      "resetting env. episode reward total was 5.0. running mean: 9.310290111374355\n",
      "resetting env. episode reward total was 12.0. running mean: 9.33718721026061\n",
      "resetting env. episode reward total was 3.0. running mean: 9.273815338158004\n",
      "resetting env. episode reward total was 15.0. running mean: 9.331077184776424\n",
      "resetting env. episode reward total was 10.0. running mean: 9.337766412928659\n",
      "resetting env. episode reward total was -9.0. running mean: 9.154388748799372\n",
      "resetting env. episode reward total was 7.0. running mean: 9.132844861311378\n",
      "resetting env. episode reward total was 1.0. running mean: 9.051516412698264\n",
      "resetting env. episode reward total was 8.0. running mean: 9.041001248571282\n",
      "resetting env. episode reward total was 11.0. running mean: 9.06059123608557\n",
      "resetting env. episode reward total was 16.0. running mean: 9.129985323724714\n",
      "resetting env. episode reward total was 14.0. running mean: 9.178685470487467\n",
      "resetting env. episode reward total was 10.0. running mean: 9.186898615782592\n",
      "resetting env. episode reward total was 13.0. running mean: 9.225029629624768\n",
      "resetting env. episode reward total was 9.0. running mean: 9.22277933332852\n",
      "resetting env. episode reward total was 5.0. running mean: 9.180551539995236\n",
      "resetting env. episode reward total was 4.0. running mean: 9.128746024595282\n",
      "resetting env. episode reward total was 11.0. running mean: 9.147458564349328\n",
      "resetting env. episode reward total was 5.0. running mean: 9.105983978705837\n",
      "resetting env. episode reward total was 16.0. running mean: 9.174924138918778\n",
      "resetting env. episode reward total was 19.0. running mean: 9.27317489752959\n",
      "resetting env. episode reward total was 8.0. running mean: 9.260443148554293\n",
      "resetting env. episode reward total was 5.0. running mean: 9.21783871706875\n",
      "resetting env. episode reward total was 14.0. running mean: 9.265660329898063\n",
      "resetting env. episode reward total was 14.0. running mean: 9.313003726599083\n",
      "resetting env. episode reward total was 15.0. running mean: 9.369873689333092\n",
      "resetting env. episode reward total was 8.0. running mean: 9.356174952439762\n",
      "resetting env. episode reward total was 9.0. running mean: 9.352613202915364\n",
      "resetting env. episode reward total was 12.0. running mean: 9.379087070886209\n",
      "resetting env. episode reward total was 7.0. running mean: 9.355296200177348\n",
      "resetting env. episode reward total was 14.0. running mean: 9.401743238175575\n",
      "resetting env. episode reward total was 2.0. running mean: 9.327725805793818\n",
      "resetting env. episode reward total was 10.0. running mean: 9.33444854773588\n",
      "resetting env. episode reward total was 6.0. running mean: 9.30110406225852\n",
      "resetting env. episode reward total was 14.0. running mean: 9.348093021635936\n",
      "resetting env. episode reward total was 2.0. running mean: 9.274612091419577\n",
      "resetting env. episode reward total was 4.0. running mean: 9.22186597050538\n",
      "resetting env. episode reward total was 11.0. running mean: 9.239647310800326\n",
      "resetting env. episode reward total was 8.0. running mean: 9.227250837692322\n",
      "resetting env. episode reward total was 18.0. running mean: 9.314978329315398\n",
      "resetting env. episode reward total was 13.0. running mean: 9.351828546022245\n",
      "resetting env. episode reward total was 11.0. running mean: 9.368310260562023\n",
      "resetting env. episode reward total was 5.0. running mean: 9.324627157956403\n",
      "resetting env. episode reward total was 8.0. running mean: 9.311380886376838\n",
      "resetting env. episode reward total was 11.0. running mean: 9.32826707751307\n",
      "resetting env. episode reward total was 10.0. running mean: 9.33498440673794\n",
      "resetting env. episode reward total was 2.0. running mean: 9.26163456267056\n",
      "resetting env. episode reward total was 17.0. running mean: 9.339018217043854\n",
      "resetting env. episode reward total was -2.0. running mean: 9.225628034873417\n",
      "resetting env. episode reward total was 15.0. running mean: 9.283371754524683\n",
      "resetting env. episode reward total was 10.0. running mean: 9.290538036979436\n",
      "resetting env. episode reward total was 5.0. running mean: 9.247632656609643\n",
      "resetting env. episode reward total was 11.0. running mean: 9.265156330043546\n",
      "resetting env. episode reward total was 12.0. running mean: 9.292504766743109\n",
      "resetting env. episode reward total was 16.0. running mean: 9.359579719075677\n",
      "resetting env. episode reward total was 8.0. running mean: 9.34598392188492\n",
      "resetting env. episode reward total was 8.0. running mean: 9.33252408266607\n",
      "resetting env. episode reward total was 2.0. running mean: 9.25919884183941\n",
      "resetting env. episode reward total was 10.0. running mean: 9.266606853421015\n",
      "resetting env. episode reward total was 6.0. running mean: 9.233940784886805\n",
      "resetting env. episode reward total was 12.0. running mean: 9.261601377037936\n",
      "resetting env. episode reward total was 10.0. running mean: 9.268985363267555\n",
      "resetting env. episode reward total was 15.0. running mean: 9.32629550963488\n",
      "resetting env. episode reward total was 10.0. running mean: 9.33303255453853\n",
      "resetting env. episode reward total was 9.0. running mean: 9.329702228993144\n",
      "resetting env. episode reward total was 6.0. running mean: 9.296405206703213\n",
      "resetting env. episode reward total was 10.0. running mean: 9.30344115463618\n",
      "resetting env. episode reward total was 4.0. running mean: 9.250406743089817\n",
      "resetting env. episode reward total was 5.0. running mean: 9.20790267565892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 9.24582364890233\n",
      "resetting env. episode reward total was 14.0. running mean: 9.293365412413308\n",
      "resetting env. episode reward total was -2.0. running mean: 9.180431758289176\n",
      "resetting env. episode reward total was 6.0. running mean: 9.148627440706285\n",
      "resetting env. episode reward total was -5.0. running mean: 9.007141166299222\n",
      "resetting env. episode reward total was 6.0. running mean: 8.977069754636231\n",
      "resetting env. episode reward total was 10.0. running mean: 8.987299057089869\n",
      "resetting env. episode reward total was 4.0. running mean: 8.93742606651897\n",
      "resetting env. episode reward total was 11.0. running mean: 8.95805180585378\n",
      "resetting env. episode reward total was 2.0. running mean: 8.888471287795241\n",
      "resetting env. episode reward total was 7.0. running mean: 8.869586574917289\n",
      "resetting env. episode reward total was 14.0. running mean: 8.920890709168116\n",
      "resetting env. episode reward total was 4.0. running mean: 8.871681802076434\n",
      "resetting env. episode reward total was 13.0. running mean: 8.912964984055671\n",
      "resetting env. episode reward total was 6.0. running mean: 8.883835334215116\n",
      "resetting env. episode reward total was 4.0. running mean: 8.834996980872964\n",
      "resetting env. episode reward total was 9.0. running mean: 8.836647011064233\n",
      "resetting env. episode reward total was 13.0. running mean: 8.878280540953591\n",
      "resetting env. episode reward total was 11.0. running mean: 8.899497735544054\n",
      "resetting env. episode reward total was 7.0. running mean: 8.880502758188614\n",
      "resetting env. episode reward total was 17.0. running mean: 8.961697730606728\n",
      "resetting env. episode reward total was 14.0. running mean: 9.012080753300662\n",
      "resetting env. episode reward total was 8.0. running mean: 9.001959945767656\n",
      "resetting env. episode reward total was 7.0. running mean: 8.98194034630998\n",
      "resetting env. episode reward total was 1.0. running mean: 8.90212094284688\n",
      "resetting env. episode reward total was 14.0. running mean: 8.953099733418412\n",
      "resetting env. episode reward total was 7.0. running mean: 8.933568736084228\n",
      "resetting env. episode reward total was -1.0. running mean: 8.834233048723386\n",
      "resetting env. episode reward total was -3.0. running mean: 8.715890718236153\n",
      "resetting env. episode reward total was 8.0. running mean: 8.708731811053791\n",
      "resetting env. episode reward total was 3.0. running mean: 8.651644492943253\n",
      "resetting env. episode reward total was 12.0. running mean: 8.68512804801382\n",
      "resetting env. episode reward total was 9.0. running mean: 8.688276767533681\n",
      "resetting env. episode reward total was 6.0. running mean: 8.661393999858344\n",
      "resetting env. episode reward total was 11.0. running mean: 8.68478005985976\n",
      "resetting env. episode reward total was 2.0. running mean: 8.617932259261162\n",
      "resetting env. episode reward total was 12.0. running mean: 8.651752936668549\n",
      "resetting env. episode reward total was 4.0. running mean: 8.605235407301862\n",
      "resetting env. episode reward total was 16.0. running mean: 8.679183053228844\n",
      "resetting env. episode reward total was 15.0. running mean: 8.742391222696556\n",
      "resetting env. episode reward total was 13.0. running mean: 8.784967310469591\n",
      "resetting env. episode reward total was 6.0. running mean: 8.757117637364896\n",
      "resetting env. episode reward total was 8.0. running mean: 8.749546460991247\n",
      "resetting env. episode reward total was 14.0. running mean: 8.802050996381336\n",
      "resetting env. episode reward total was 3.0. running mean: 8.744030486417522\n",
      "resetting env. episode reward total was 14.0. running mean: 8.796590181553347\n",
      "resetting env. episode reward total was 10.0. running mean: 8.808624279737813\n",
      "resetting env. episode reward total was 7.0. running mean: 8.790538036940436\n",
      "resetting env. episode reward total was 4.0. running mean: 8.74263265657103\n",
      "resetting env. episode reward total was 6.0. running mean: 8.715206330005321\n",
      "resetting env. episode reward total was 9.0. running mean: 8.718054266705268\n",
      "resetting env. episode reward total was 6.0. running mean: 8.690873724038216\n",
      "resetting env. episode reward total was 11.0. running mean: 8.713964986797833\n",
      "resetting env. episode reward total was 8.0. running mean: 8.706825336929855\n",
      "resetting env. episode reward total was 8.0. running mean: 8.699757083560556\n",
      "resetting env. episode reward total was 19.0. running mean: 8.80275951272495\n",
      "resetting env. episode reward total was 1.0. running mean: 8.724731917597701\n",
      "resetting env. episode reward total was 12.0. running mean: 8.757484598421723\n",
      "resetting env. episode reward total was 14.0. running mean: 8.809909752437505\n",
      "resetting env. episode reward total was 16.0. running mean: 8.88181065491313\n",
      "resetting env. episode reward total was 5.0. running mean: 8.842992548363998\n",
      "resetting env. episode reward total was 14.0. running mean: 8.89456262288036\n",
      "resetting env. episode reward total was 14.0. running mean: 8.945616996651557\n",
      "resetting env. episode reward total was 5.0. running mean: 8.906160826685042\n",
      "resetting env. episode reward total was 12.0. running mean: 8.93709921841819\n",
      "resetting env. episode reward total was 13.0. running mean: 8.977728226234008\n",
      "resetting env. episode reward total was 7.0. running mean: 8.95795094397167\n",
      "resetting env. episode reward total was 17.0. running mean: 9.038371434531951\n",
      "resetting env. episode reward total was 7.0. running mean: 9.017987720186632\n",
      "resetting env. episode reward total was 15.0. running mean: 9.077807842984766\n",
      "resetting env. episode reward total was 5.0. running mean: 9.03702976455492\n",
      "resetting env. episode reward total was 2.0. running mean: 8.96665946690937\n",
      "resetting env. episode reward total was 7.0. running mean: 8.946992872240276\n",
      "resetting env. episode reward total was 18.0. running mean: 9.037522943517873\n",
      "resetting env. episode reward total was 17.0. running mean: 9.117147714082694\n",
      "resetting env. episode reward total was 9.0. running mean: 9.115976236941867\n",
      "resetting env. episode reward total was 16.0. running mean: 9.184816474572449\n",
      "resetting env. episode reward total was 6.0. running mean: 9.152968309826724\n",
      "resetting env. episode reward total was 7.0. running mean: 9.131438626728457\n",
      "resetting env. episode reward total was 11.0. running mean: 9.150124240461171\n",
      "resetting env. episode reward total was 8.0. running mean: 9.13862299805656\n",
      "resetting env. episode reward total was -2.0. running mean: 9.027236768075994\n",
      "resetting env. episode reward total was 9.0. running mean: 9.026964400395235\n",
      "resetting env. episode reward total was 13.0. running mean: 9.066694756391284\n",
      "resetting env. episode reward total was 12.0. running mean: 9.09602780882737\n",
      "resetting env. episode reward total was -1.0. running mean: 8.995067530739098\n",
      "resetting env. episode reward total was 14.0. running mean: 9.045116855431708\n",
      "resetting env. episode reward total was -3.0. running mean: 8.924665686877391\n",
      "resetting env. episode reward total was 17.0. running mean: 9.005419030008618\n",
      "resetting env. episode reward total was 7.0. running mean: 8.98536483970853\n",
      "resetting env. episode reward total was 12.0. running mean: 9.015511191311445\n",
      "resetting env. episode reward total was 7.0. running mean: 8.99535607939833\n",
      "resetting env. episode reward total was 11.0. running mean: 9.015402518604347\n",
      "resetting env. episode reward total was 2.0. running mean: 8.945248493418303\n",
      "resetting env. episode reward total was 9.0. running mean: 8.94579600848412\n",
      "resetting env. episode reward total was 5.0. running mean: 8.90633804839928\n",
      "resetting env. episode reward total was -3.0. running mean: 8.787274667915288\n",
      "resetting env. episode reward total was 10.0. running mean: 8.799401921236134\n",
      "resetting env. episode reward total was 13.0. running mean: 8.841407902023773\n",
      "resetting env. episode reward total was 9.0. running mean: 8.842993823003535\n",
      "resetting env. episode reward total was 1.0. running mean: 8.7645638847735\n",
      "resetting env. episode reward total was 6.0. running mean: 8.736918245925764\n",
      "resetting env. episode reward total was 11.0. running mean: 8.759549063466507\n",
      "resetting env. episode reward total was 18.0. running mean: 8.85195357283184\n",
      "resetting env. episode reward total was 5.0. running mean: 8.813434037103523\n",
      "resetting env. episode reward total was 5.0. running mean: 8.775299696732489\n",
      "resetting env. episode reward total was 16.0. running mean: 8.847546699765164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 8.879071232767512\n",
      "resetting env. episode reward total was 17.0. running mean: 8.960280520439836\n",
      "resetting env. episode reward total was 14.0. running mean: 9.010677715235438\n",
      "resetting env. episode reward total was 13.0. running mean: 9.050570938083085\n",
      "resetting env. episode reward total was 9.0. running mean: 9.050065228702254\n",
      "resetting env. episode reward total was 15.0. running mean: 9.10956457641523\n",
      "resetting env. episode reward total was 3.0. running mean: 9.048468930651078\n",
      "resetting env. episode reward total was 16.0. running mean: 9.117984241344567\n",
      "resetting env. episode reward total was -6.0. running mean: 8.96680439893112\n",
      "resetting env. episode reward total was 12.0. running mean: 8.997136354941809\n",
      "resetting env. episode reward total was 9.0. running mean: 8.99716499139239\n",
      "resetting env. episode reward total was 8.0. running mean: 8.987193341478466\n",
      "resetting env. episode reward total was 6.0. running mean: 8.957321408063683\n",
      "resetting env. episode reward total was 11.0. running mean: 8.977748193983045\n",
      "resetting env. episode reward total was 11.0. running mean: 8.997970712043214\n",
      "resetting env. episode reward total was 7.0. running mean: 8.977991004922782\n",
      "resetting env. episode reward total was 4.0. running mean: 8.928211094873554\n",
      "resetting env. episode reward total was 9.0. running mean: 8.928928983924818\n",
      "resetting env. episode reward total was 8.0. running mean: 8.91963969408557\n",
      "resetting env. episode reward total was 13.0. running mean: 8.960443297144714\n",
      "resetting env. episode reward total was 17.0. running mean: 9.040838864173267\n",
      "resetting env. episode reward total was 15.0. running mean: 9.100430475531535\n",
      "resetting env. episode reward total was 10.0. running mean: 9.109426170776219\n",
      "resetting env. episode reward total was 13.0. running mean: 9.148331909068457\n",
      "resetting env. episode reward total was 7.0. running mean: 9.126848589977772\n",
      "resetting env. episode reward total was 12.0. running mean: 9.155580104077993\n",
      "resetting env. episode reward total was 12.0. running mean: 9.184024303037212\n",
      "resetting env. episode reward total was 13.0. running mean: 9.22218406000684\n",
      "resetting env. episode reward total was 12.0. running mean: 9.249962219406772\n",
      "resetting env. episode reward total was 13.0. running mean: 9.287462597212706\n",
      "resetting env. episode reward total was 13.0. running mean: 9.324587971240579\n",
      "resetting env. episode reward total was 9.0. running mean: 9.321342091528173\n",
      "resetting env. episode reward total was 8.0. running mean: 9.308128670612891\n",
      "resetting env. episode reward total was 14.0. running mean: 9.355047383906763\n",
      "resetting env. episode reward total was 6.0. running mean: 9.321496910067696\n",
      "resetting env. episode reward total was 5.0. running mean: 9.27828194096702\n",
      "resetting env. episode reward total was 11.0. running mean: 9.295499121557349\n",
      "resetting env. episode reward total was 13.0. running mean: 9.332544130341775\n",
      "resetting env. episode reward total was 5.0. running mean: 9.289218689038359\n",
      "resetting env. episode reward total was 15.0. running mean: 9.346326502147976\n",
      "resetting env. episode reward total was 7.0. running mean: 9.322863237126496\n",
      "resetting env. episode reward total was 9.0. running mean: 9.319634604755231\n",
      "resetting env. episode reward total was 6.0. running mean: 9.28643825870768\n",
      "resetting env. episode reward total was -1.0. running mean: 9.183573876120603\n",
      "resetting env. episode reward total was 13.0. running mean: 9.221738137359397\n",
      "resetting env. episode reward total was 12.0. running mean: 9.249520755985802\n",
      "resetting env. episode reward total was 8.0. running mean: 9.237025548425944\n",
      "resetting env. episode reward total was 14.0. running mean: 9.284655292941684\n",
      "resetting env. episode reward total was 13.0. running mean: 9.321808740012267\n",
      "resetting env. episode reward total was 8.0. running mean: 9.308590652612144\n",
      "resetting env. episode reward total was 20.0. running mean: 9.415504746086022\n",
      "resetting env. episode reward total was 9.0. running mean: 9.41134969862516\n",
      "resetting env. episode reward total was 13.0. running mean: 9.44723620163891\n",
      "resetting env. episode reward total was 7.0. running mean: 9.42276383962252\n",
      "resetting env. episode reward total was 11.0. running mean: 9.438536201226295\n",
      "resetting env. episode reward total was 15.0. running mean: 9.494150839214033\n",
      "resetting env. episode reward total was 6.0. running mean: 9.459209330821892\n",
      "resetting env. episode reward total was 4.0. running mean: 9.404617237513673\n",
      "resetting env. episode reward total was 8.0. running mean: 9.390571065138536\n",
      "resetting env. episode reward total was 6.0. running mean: 9.35666535448715\n",
      "resetting env. episode reward total was 9.0. running mean: 9.35309870094228\n",
      "resetting env. episode reward total was 5.0. running mean: 9.309567713932857\n",
      "resetting env. episode reward total was 7.0. running mean: 9.286472036793528\n",
      "resetting env. episode reward total was -1.0. running mean: 9.183607316425594\n",
      "resetting env. episode reward total was 11.0. running mean: 9.201771243261337\n",
      "resetting env. episode reward total was 5.0. running mean: 9.159753530828725\n",
      "resetting env. episode reward total was 5.0. running mean: 9.11815599552044\n",
      "resetting env. episode reward total was 16.0. running mean: 9.186974435565235\n",
      "resetting env. episode reward total was 14.0. running mean: 9.235104691209584\n",
      "resetting env. episode reward total was 5.0. running mean: 9.192753644297488\n",
      "resetting env. episode reward total was 12.0. running mean: 9.220826107854512\n",
      "resetting env. episode reward total was 5.0. running mean: 9.178617846775968\n",
      "resetting env. episode reward total was 17.0. running mean: 9.256831668308207\n",
      "resetting env. episode reward total was 6.0. running mean: 9.224263351625126\n",
      "resetting env. episode reward total was 8.0. running mean: 9.212020718108874\n",
      "resetting env. episode reward total was 8.0. running mean: 9.199900510927785\n",
      "resetting env. episode reward total was 12.0. running mean: 9.227901505818506\n",
      "resetting env. episode reward total was 11.0. running mean: 9.24562249076032\n",
      "resetting env. episode reward total was 7.0. running mean: 9.223166265852717\n",
      "resetting env. episode reward total was 10.0. running mean: 9.23093460319419\n",
      "resetting env. episode reward total was 5.0. running mean: 9.188625257162247\n",
      "resetting env. episode reward total was 8.0. running mean: 9.176739004590624\n",
      "resetting env. episode reward total was 15.0. running mean: 9.234971614544719\n",
      "resetting env. episode reward total was 9.0. running mean: 9.232621898399271\n",
      "resetting env. episode reward total was 13.0. running mean: 9.270295679415279\n",
      "resetting env. episode reward total was 13.0. running mean: 9.307592722621127\n",
      "resetting env. episode reward total was 5.0. running mean: 9.264516795394917\n",
      "resetting env. episode reward total was 9.0. running mean: 9.261871627440968\n",
      "resetting env. episode reward total was 14.0. running mean: 9.309252911166558\n",
      "resetting env. episode reward total was 14.0. running mean: 9.356160382054894\n",
      "resetting env. episode reward total was 7.0. running mean: 9.332598778234345\n",
      "resetting env. episode reward total was 10.0. running mean: 9.339272790452002\n",
      "resetting env. episode reward total was 10.0. running mean: 9.345880062547481\n",
      "resetting env. episode reward total was 8.0. running mean: 9.332421261922006\n",
      "resetting env. episode reward total was -4.0. running mean: 9.199097049302786\n",
      "resetting env. episode reward total was 10.0. running mean: 9.207106078809758\n",
      "resetting env. episode reward total was 18.0. running mean: 9.295035018021661\n",
      "resetting env. episode reward total was 9.0. running mean: 9.292084667841443\n",
      "resetting env. episode reward total was 16.0. running mean: 9.35916382116303\n",
      "resetting env. episode reward total was 4.0. running mean: 9.305572182951398\n",
      "resetting env. episode reward total was 6.0. running mean: 9.272516461121883\n",
      "resetting env. episode reward total was 9.0. running mean: 9.269791296510665\n",
      "resetting env. episode reward total was 5.0. running mean: 9.227093383545558\n",
      "resetting env. episode reward total was 11.0. running mean: 9.244822449710101\n",
      "resetting env. episode reward total was 5.0. running mean: 9.202374225213001\n",
      "resetting env. episode reward total was 13.0. running mean: 9.240350482960872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 9.297946978131264\n",
      "resetting env. episode reward total was 15.0. running mean: 9.354967508349953\n",
      "resetting env. episode reward total was 9.0. running mean: 9.351417833266453\n",
      "resetting env. episode reward total was 8.0. running mean: 9.337903654933788\n",
      "resetting env. episode reward total was 7.0. running mean: 9.31452461838445\n",
      "resetting env. episode reward total was 12.0. running mean: 9.341379372200604\n",
      "resetting env. episode reward total was 10.0. running mean: 9.347965578478599\n",
      "resetting env. episode reward total was 16.0. running mean: 9.414485922693812\n",
      "resetting env. episode reward total was 7.0. running mean: 9.390341063466874\n",
      "resetting env. episode reward total was 4.0. running mean: 9.336437652832204\n",
      "resetting env. episode reward total was 10.0. running mean: 9.343073276303882\n",
      "resetting env. episode reward total was 6.0. running mean: 9.309642543540843\n",
      "resetting env. episode reward total was 6.0. running mean: 9.276546118105435\n",
      "resetting env. episode reward total was 8.0. running mean: 9.26378065692438\n",
      "resetting env. episode reward total was 6.0. running mean: 9.231142850355138\n",
      "resetting env. episode reward total was 12.0. running mean: 9.258831421851585\n",
      "resetting env. episode reward total was 6.0. running mean: 9.22624310763307\n",
      "resetting env. episode reward total was 5.0. running mean: 9.183980676556741\n",
      "resetting env. episode reward total was 14.0. running mean: 9.232140869791174\n",
      "resetting env. episode reward total was -11.0. running mean: 9.029819461093263\n",
      "resetting env. episode reward total was 16.0. running mean: 9.09952126648233\n",
      "resetting env. episode reward total was 9.0. running mean: 9.098526053817507\n",
      "resetting env. episode reward total was 15.0. running mean: 9.157540793279331\n",
      "resetting env. episode reward total was 15.0. running mean: 9.215965385346538\n",
      "resetting env. episode reward total was 10.0. running mean: 9.223805731493071\n",
      "resetting env. episode reward total was 1.0. running mean: 9.14156767417814\n",
      "resetting env. episode reward total was 14.0. running mean: 9.190151997436358\n",
      "resetting env. episode reward total was 6.0. running mean: 9.158250477461994\n",
      "resetting env. episode reward total was 16.0. running mean: 9.226667972687375\n",
      "resetting env. episode reward total was 14.0. running mean: 9.274401292960501\n",
      "resetting env. episode reward total was 12.0. running mean: 9.301657280030895\n",
      "resetting env. episode reward total was 13.0. running mean: 9.338640707230587\n",
      "resetting env. episode reward total was 12.0. running mean: 9.36525430015828\n",
      "resetting env. episode reward total was 1.0. running mean: 9.281601757156697\n",
      "resetting env. episode reward total was 8.0. running mean: 9.26878573958513\n",
      "resetting env. episode reward total was 15.0. running mean: 9.326097882189279\n",
      "resetting env. episode reward total was 11.0. running mean: 9.342836903367385\n",
      "resetting env. episode reward total was 6.0. running mean: 9.309408534333711\n",
      "resetting env. episode reward total was 10.0. running mean: 9.316314448990374\n",
      "resetting env. episode reward total was 8.0. running mean: 9.30315130450047\n",
      "resetting env. episode reward total was 10.0. running mean: 9.310119791455465\n",
      "resetting env. episode reward total was 8.0. running mean: 9.29701859354091\n",
      "resetting env. episode reward total was 14.0. running mean: 9.344048407605502\n",
      "resetting env. episode reward total was 14.0. running mean: 9.390607923529448\n",
      "resetting env. episode reward total was 8.0. running mean: 9.376701844294153\n",
      "resetting env. episode reward total was 2.0. running mean: 9.302934825851212\n",
      "resetting env. episode reward total was 16.0. running mean: 9.3699054775927\n",
      "resetting env. episode reward total was 14.0. running mean: 9.416206422816774\n",
      "resetting env. episode reward total was 15.0. running mean: 9.472044358588606\n",
      "resetting env. episode reward total was 13.0. running mean: 9.50732391500272\n",
      "resetting env. episode reward total was 5.0. running mean: 9.462250675852694\n",
      "resetting env. episode reward total was 15.0. running mean: 9.517628169094166\n",
      "resetting env. episode reward total was 9.0. running mean: 9.512451887403225\n",
      "resetting env. episode reward total was 14.0. running mean: 9.557327368529194\n",
      "resetting env. episode reward total was 17.0. running mean: 9.631754094843902\n",
      "resetting env. episode reward total was -3.0. running mean: 9.505436553895464\n",
      "resetting env. episode reward total was 6.0. running mean: 9.47038218835651\n",
      "resetting env. episode reward total was 5.0. running mean: 9.425678366472946\n",
      "resetting env. episode reward total was 4.0. running mean: 9.371421582808216\n",
      "resetting env. episode reward total was 7.0. running mean: 9.347707366980133\n",
      "resetting env. episode reward total was 7.0. running mean: 9.324230293310332\n",
      "resetting env. episode reward total was 7.0. running mean: 9.30098799037723\n",
      "resetting env. episode reward total was 5.0. running mean: 9.25797811047346\n",
      "resetting env. episode reward total was 4.0. running mean: 9.205398329368723\n",
      "resetting env. episode reward total was 18.0. running mean: 9.293344346075035\n",
      "resetting env. episode reward total was 13.0. running mean: 9.330410902614284\n",
      "resetting env. episode reward total was 6.0. running mean: 9.297106793588142\n",
      "resetting env. episode reward total was 11.0. running mean: 9.31413572565226\n",
      "resetting env. episode reward total was 4.0. running mean: 9.260994368395737\n",
      "resetting env. episode reward total was 15.0. running mean: 9.31838442471178\n",
      "resetting env. episode reward total was 13.0. running mean: 9.355200580464663\n",
      "resetting env. episode reward total was 9.0. running mean: 9.351648574660016\n",
      "resetting env. episode reward total was 10.0. running mean: 9.358132088913417\n",
      "resetting env. episode reward total was 11.0. running mean: 9.374550768024282\n",
      "resetting env. episode reward total was 13.0. running mean: 9.41080526034404\n",
      "resetting env. episode reward total was 8.0. running mean: 9.3966972077406\n",
      "resetting env. episode reward total was 12.0. running mean: 9.422730235663193\n",
      "resetting env. episode reward total was 7.0. running mean: 9.398502933306562\n",
      "resetting env. episode reward total was 6.0. running mean: 9.364517903973496\n",
      "resetting env. episode reward total was 8.0. running mean: 9.350872724933762\n",
      "resetting env. episode reward total was 5.0. running mean: 9.307363997684424\n",
      "resetting env. episode reward total was 13.0. running mean: 9.344290357707582\n",
      "resetting env. episode reward total was 16.0. running mean: 9.410847454130506\n",
      "resetting env. episode reward total was 9.0. running mean: 9.406738979589202\n",
      "resetting env. episode reward total was 9.0. running mean: 9.402671589793309\n",
      "resetting env. episode reward total was 13.0. running mean: 9.438644873895377\n",
      "resetting env. episode reward total was 1.0. running mean: 9.354258425156424\n",
      "resetting env. episode reward total was 4.0. running mean: 9.300715840904859\n",
      "resetting env. episode reward total was 12.0. running mean: 9.327708682495809\n",
      "resetting env. episode reward total was 10.0. running mean: 9.33443159567085\n",
      "resetting env. episode reward total was -7.0. running mean: 9.171087279714142\n",
      "resetting env. episode reward total was 9.0. running mean: 9.169376406917\n",
      "resetting env. episode reward total was 7.0. running mean: 9.14768264284783\n",
      "resetting env. episode reward total was 11.0. running mean: 9.166205816419351\n",
      "resetting env. episode reward total was 10.0. running mean: 9.174543758255158\n",
      "resetting env. episode reward total was 13.0. running mean: 9.212798320672608\n",
      "resetting env. episode reward total was 11.0. running mean: 9.230670337465881\n",
      "resetting env. episode reward total was 10.0. running mean: 9.238363634091222\n",
      "resetting env. episode reward total was 11.0. running mean: 9.255979997750309\n",
      "resetting env. episode reward total was 15.0. running mean: 9.313420197772807\n",
      "resetting env. episode reward total was 7.0. running mean: 9.29028599579508\n",
      "resetting env. episode reward total was 11.0. running mean: 9.307383135837128\n",
      "resetting env. episode reward total was 13.0. running mean: 9.344309304478758\n",
      "resetting env. episode reward total was 13.0. running mean: 9.38086621143397\n",
      "resetting env. episode reward total was 9.0. running mean: 9.37705754931963\n",
      "resetting env. episode reward total was 8.0. running mean: 9.363286973826433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 9.39965410408817\n",
      "resetting env. episode reward total was 13.0. running mean: 9.435657563047288\n",
      "resetting env. episode reward total was 13.0. running mean: 9.471300987416816\n",
      "resetting env. episode reward total was 17.0. running mean: 9.546587977542648\n",
      "resetting env. episode reward total was 11.0. running mean: 9.561122097767221\n",
      "resetting env. episode reward total was 11.0. running mean: 9.575510876789549\n",
      "resetting env. episode reward total was 13.0. running mean: 9.609755768021655\n",
      "resetting env. episode reward total was 8.0. running mean: 9.593658210341438\n",
      "resetting env. episode reward total was 10.0. running mean: 9.597721628238023\n",
      "resetting env. episode reward total was 13.0. running mean: 9.631744411955644\n",
      "resetting env. episode reward total was 12.0. running mean: 9.655426967836087\n",
      "resetting env. episode reward total was 13.0. running mean: 9.688872698157727\n",
      "resetting env. episode reward total was 12.0. running mean: 9.71198397117615\n",
      "resetting env. episode reward total was 7.0. running mean: 9.684864131464389\n",
      "resetting env. episode reward total was 15.0. running mean: 9.738015490149746\n",
      "resetting env. episode reward total was 12.0. running mean: 9.760635335248248\n",
      "resetting env. episode reward total was 12.0. running mean: 9.783028981895765\n",
      "resetting env. episode reward total was 8.0. running mean: 9.765198692076806\n",
      "resetting env. episode reward total was 13.0. running mean: 9.797546705156039\n",
      "resetting env. episode reward total was 10.0. running mean: 9.799571238104479\n",
      "resetting env. episode reward total was 14.0. running mean: 9.841575525723435\n",
      "resetting env. episode reward total was 10.0. running mean: 9.843159770466201\n",
      "resetting env. episode reward total was 10.0. running mean: 9.844728172761538\n",
      "resetting env. episode reward total was 12.0. running mean: 9.866280891033922\n",
      "resetting env. episode reward total was 5.0. running mean: 9.817618082123584\n",
      "resetting env. episode reward total was 14.0. running mean: 9.859441901302349\n",
      "resetting env. episode reward total was 16.0. running mean: 9.920847482289325\n",
      "resetting env. episode reward total was 12.0. running mean: 9.941639007466431\n",
      "resetting env. episode reward total was 16.0. running mean: 10.002222617391768\n",
      "resetting env. episode reward total was 7.0. running mean: 9.97220039121785\n",
      "resetting env. episode reward total was 12.0. running mean: 9.99247838730567\n",
      "resetting env. episode reward total was 8.0. running mean: 9.972553603432614\n",
      "resetting env. episode reward total was 10.0. running mean: 9.972828067398288\n",
      "resetting env. episode reward total was 7.0. running mean: 9.943099786724305\n",
      "resetting env. episode reward total was 11.0. running mean: 9.953668788857062\n",
      "resetting env. episode reward total was 11.0. running mean: 9.96413210096849\n",
      "resetting env. episode reward total was 5.0. running mean: 9.914490779958806\n",
      "resetting env. episode reward total was 14.0. running mean: 9.955345872159219\n",
      "resetting env. episode reward total was 8.0. running mean: 9.935792413437627\n",
      "resetting env. episode reward total was 17.0. running mean: 10.00643448930325\n",
      "resetting env. episode reward total was 11.0. running mean: 10.016370144410217\n",
      "resetting env. episode reward total was 14.0. running mean: 10.056206442966115\n",
      "resetting env. episode reward total was 6.0. running mean: 10.015644378536454\n",
      "resetting env. episode reward total was 14.0. running mean: 10.05548793475109\n",
      "resetting env. episode reward total was 9.0. running mean: 10.044933055403579\n",
      "resetting env. episode reward total was 18.0. running mean: 10.124483724849544\n",
      "resetting env. episode reward total was 11.0. running mean: 10.133238887601047\n",
      "resetting env. episode reward total was 18.0. running mean: 10.211906498725037\n",
      "resetting env. episode reward total was 15.0. running mean: 10.259787433737786\n",
      "resetting env. episode reward total was 5.0. running mean: 10.207189559400408\n",
      "resetting env. episode reward total was 5.0. running mean: 10.155117663806404\n",
      "resetting env. episode reward total was 10.0. running mean: 10.153566487168339\n",
      "resetting env. episode reward total was 14.0. running mean: 10.192030822296656\n",
      "resetting env. episode reward total was -1.0. running mean: 10.08011051407369\n",
      "resetting env. episode reward total was 10.0. running mean: 10.079309408932952\n",
      "resetting env. episode reward total was 13.0. running mean: 10.108516314843623\n",
      "resetting env. episode reward total was 10.0. running mean: 10.107431151695186\n",
      "resetting env. episode reward total was 15.0. running mean: 10.156356840178235\n",
      "resetting env. episode reward total was 6.0. running mean: 10.114793271776453\n",
      "resetting env. episode reward total was 4.0. running mean: 10.053645339058686\n",
      "resetting env. episode reward total was 1.0. running mean: 9.963108885668099\n",
      "resetting env. episode reward total was 10.0. running mean: 9.963477796811418\n",
      "resetting env. episode reward total was 7.0. running mean: 9.933843018843303\n",
      "resetting env. episode reward total was 21.0. running mean: 10.04450458865487\n",
      "resetting env. episode reward total was 8.0. running mean: 10.024059542768322\n",
      "resetting env. episode reward total was 5.0. running mean: 9.97381894734064\n",
      "resetting env. episode reward total was 10.0. running mean: 9.974080757867233\n",
      "resetting env. episode reward total was 11.0. running mean: 9.98433995028856\n",
      "resetting env. episode reward total was 6.0. running mean: 9.944496550785674\n",
      "resetting env. episode reward total was 14.0. running mean: 9.985051585277818\n",
      "resetting env. episode reward total was 12.0. running mean: 10.00520106942504\n",
      "resetting env. episode reward total was 12.0. running mean: 10.025149058730788\n",
      "resetting env. episode reward total was 7.0. running mean: 9.99489756814348\n",
      "resetting env. episode reward total was 4.0. running mean: 9.934948592462044\n",
      "resetting env. episode reward total was 12.0. running mean: 9.955599106537424\n",
      "resetting env. episode reward total was 7.0. running mean: 9.92604311547205\n",
      "resetting env. episode reward total was 5.0. running mean: 9.87678268431733\n",
      "resetting env. episode reward total was 9.0. running mean: 9.868014857474156\n",
      "resetting env. episode reward total was 11.0. running mean: 9.879334708899414\n",
      "resetting env. episode reward total was 14.0. running mean: 9.92054136181042\n",
      "resetting env. episode reward total was -1.0. running mean: 9.811335948192315\n",
      "resetting env. episode reward total was 14.0. running mean: 9.853222588710393\n",
      "resetting env. episode reward total was 13.0. running mean: 9.88469036282329\n",
      "resetting env. episode reward total was 1.0. running mean: 9.795843459195057\n",
      "resetting env. episode reward total was 7.0. running mean: 9.767885024603107\n",
      "resetting env. episode reward total was 10.0. running mean: 9.770206174357075\n",
      "resetting env. episode reward total was 12.0. running mean: 9.792504112613504\n",
      "resetting env. episode reward total was 4.0. running mean: 9.734579071487367\n",
      "resetting env. episode reward total was 10.0. running mean: 9.737233280772493\n",
      "resetting env. episode reward total was 12.0. running mean: 9.759860947964768\n",
      "resetting env. episode reward total was -3.0. running mean: 9.63226233848512\n",
      "resetting env. episode reward total was 8.0. running mean: 9.615939715100268\n",
      "resetting env. episode reward total was 14.0. running mean: 9.659780317949267\n",
      "resetting env. episode reward total was 14.0. running mean: 9.703182514769773\n",
      "resetting env. episode reward total was 10.0. running mean: 9.706150689622076\n",
      "resetting env. episode reward total was 13.0. running mean: 9.739089182725856\n",
      "resetting env. episode reward total was 5.0. running mean: 9.691698290898598\n",
      "resetting env. episode reward total was 4.0. running mean: 9.634781307989611\n",
      "resetting env. episode reward total was 15.0. running mean: 9.688433494909715\n",
      "resetting env. episode reward total was 11.0. running mean: 9.701549159960617\n",
      "resetting env. episode reward total was 9.0. running mean: 9.69453366836101\n",
      "resetting env. episode reward total was 16.0. running mean: 9.7575883316774\n",
      "resetting env. episode reward total was 12.0. running mean: 9.780012448360626\n",
      "resetting env. episode reward total was 6.0. running mean: 9.74221232387702\n",
      "resetting env. episode reward total was 7.0. running mean: 9.71479020063825\n",
      "resetting env. episode reward total was 1.0. running mean: 9.627642298631867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 9.661365875645549\n",
      "resetting env. episode reward total was 8.0. running mean: 9.644752216889094\n",
      "resetting env. episode reward total was 15.0. running mean: 9.698304694720203\n",
      "resetting env. episode reward total was 14.0. running mean: 9.741321647773002\n",
      "resetting env. episode reward total was 19.0. running mean: 9.833908431295272\n",
      "resetting env. episode reward total was 13.0. running mean: 9.865569346982321\n",
      "resetting env. episode reward total was 16.0. running mean: 9.926913653512498\n",
      "resetting env. episode reward total was 9.0. running mean: 9.917644516977372\n",
      "resetting env. episode reward total was 4.0. running mean: 9.858468071807598\n",
      "resetting env. episode reward total was 13.0. running mean: 9.889883391089523\n",
      "resetting env. episode reward total was 10.0. running mean: 9.890984557178626\n",
      "resetting env. episode reward total was 14.0. running mean: 9.932074711606841\n",
      "resetting env. episode reward total was 15.0. running mean: 9.982753964490772\n",
      "resetting env. episode reward total was 12.0. running mean: 10.002926424845864\n",
      "resetting env. episode reward total was 5.0. running mean: 9.952897160597406\n",
      "resetting env. episode reward total was 1.0. running mean: 9.863368188991432\n",
      "resetting env. episode reward total was 12.0. running mean: 9.884734507101516\n",
      "resetting env. episode reward total was 11.0. running mean: 9.895887162030501\n",
      "resetting env. episode reward total was 10.0. running mean: 9.896928290410196\n",
      "resetting env. episode reward total was 12.0. running mean: 9.917959007506093\n",
      "resetting env. episode reward total was -3.0. running mean: 9.788779417431034\n",
      "resetting env. episode reward total was 13.0. running mean: 9.820891623256724\n",
      "resetting env. episode reward total was 10.0. running mean: 9.822682707024157\n",
      "resetting env. episode reward total was 14.0. running mean: 9.864455879953915\n",
      "resetting env. episode reward total was 16.0. running mean: 9.925811321154377\n",
      "resetting env. episode reward total was 12.0. running mean: 9.946553207942832\n",
      "resetting env. episode reward total was 3.0. running mean: 9.877087675863404\n",
      "resetting env. episode reward total was 12.0. running mean: 9.89831679910477\n",
      "resetting env. episode reward total was 7.0. running mean: 9.869333631113722\n",
      "resetting env. episode reward total was 12.0. running mean: 9.890640294802584\n",
      "resetting env. episode reward total was 8.0. running mean: 9.871733891854557\n",
      "resetting env. episode reward total was -2.0. running mean: 9.753016552936012\n",
      "resetting env. episode reward total was 3.0. running mean: 9.685486387406652\n",
      "resetting env. episode reward total was 9.0. running mean: 9.678631523532585\n",
      "resetting env. episode reward total was 5.0. running mean: 9.63184520829726\n",
      "resetting env. episode reward total was 16.0. running mean: 9.695526756214289\n",
      "resetting env. episode reward total was 3.0. running mean: 9.628571488652145\n",
      "resetting env. episode reward total was 11.0. running mean: 9.642285773765623\n",
      "resetting env. episode reward total was 7.0. running mean: 9.615862916027968\n",
      "resetting env. episode reward total was 12.0. running mean: 9.639704286867687\n",
      "resetting env. episode reward total was 9.0. running mean: 9.63330724399901\n",
      "resetting env. episode reward total was 5.0. running mean: 9.58697417155902\n",
      "resetting env. episode reward total was 15.0. running mean: 9.64110442984343\n",
      "resetting env. episode reward total was 15.0. running mean: 9.694693385544996\n",
      "resetting env. episode reward total was 13.0. running mean: 9.727746451689546\n",
      "resetting env. episode reward total was 7.0. running mean: 9.70046898717265\n",
      "resetting env. episode reward total was 13.0. running mean: 9.733464297300925\n",
      "resetting env. episode reward total was 15.0. running mean: 9.786129654327915\n",
      "resetting env. episode reward total was 6.0. running mean: 9.748268357784637\n",
      "resetting env. episode reward total was 2.0. running mean: 9.67078567420679\n",
      "resetting env. episode reward total was 9.0. running mean: 9.664077817464722\n",
      "resetting env. episode reward total was 13.0. running mean: 9.697437039290076\n",
      "resetting env. episode reward total was 6.0. running mean: 9.660462668897175\n",
      "resetting env. episode reward total was 10.0. running mean: 9.663858042208203\n",
      "resetting env. episode reward total was 15.0. running mean: 9.71721946178612\n",
      "resetting env. episode reward total was 9.0. running mean: 9.710047267168259\n",
      "resetting env. episode reward total was 9.0. running mean: 9.702946794496576\n",
      "resetting env. episode reward total was 11.0. running mean: 9.71591732655161\n",
      "resetting env. episode reward total was 10.0. running mean: 9.718758153286092\n",
      "resetting env. episode reward total was 12.0. running mean: 9.74157057175323\n",
      "resetting env. episode reward total was 10.0. running mean: 9.744154866035698\n",
      "resetting env. episode reward total was 11.0. running mean: 9.75671331737534\n",
      "resetting env. episode reward total was 10.0. running mean: 9.759146184201587\n",
      "resetting env. episode reward total was 12.0. running mean: 9.78155472235957\n",
      "resetting env. episode reward total was 15.0. running mean: 9.833739175135975\n",
      "resetting env. episode reward total was 14.0. running mean: 9.875401783384616\n",
      "resetting env. episode reward total was 18.0. running mean: 9.95664776555077\n",
      "resetting env. episode reward total was 10.0. running mean: 9.957081287895262\n",
      "resetting env. episode reward total was 7.0. running mean: 9.927510475016309\n",
      "resetting env. episode reward total was 11.0. running mean: 9.938235370266145\n",
      "resetting env. episode reward total was 3.0. running mean: 9.868853016563483\n",
      "resetting env. episode reward total was 14.0. running mean: 9.910164486397848\n",
      "resetting env. episode reward total was 14.0. running mean: 9.95106284153387\n",
      "resetting env. episode reward total was 14.0. running mean: 9.991552213118533\n",
      "resetting env. episode reward total was 10.0. running mean: 9.991636690987347\n",
      "resetting env. episode reward total was 10.0. running mean: 9.991720324077473\n",
      "resetting env. episode reward total was 9.0. running mean: 9.981803120836698\n",
      "resetting env. episode reward total was 8.0. running mean: 9.961985089628332\n",
      "resetting env. episode reward total was 6.0. running mean: 9.922365238732048\n",
      "resetting env. episode reward total was 8.0. running mean: 9.903141586344727\n",
      "resetting env. episode reward total was 11.0. running mean: 9.91411017048128\n",
      "resetting env. episode reward total was 7.0. running mean: 9.884969068776467\n",
      "resetting env. episode reward total was -4.0. running mean: 9.746119378088704\n",
      "resetting env. episode reward total was 8.0. running mean: 9.728658184307816\n",
      "resetting env. episode reward total was 7.0. running mean: 9.701371602464738\n",
      "resetting env. episode reward total was 4.0. running mean: 9.644357886440089\n",
      "resetting env. episode reward total was 14.0. running mean: 9.687914307575689\n",
      "resetting env. episode reward total was 18.0. running mean: 9.771035164499931\n",
      "resetting env. episode reward total was 11.0. running mean: 9.783324812854932\n",
      "resetting env. episode reward total was 9.0. running mean: 9.775491564726382\n",
      "resetting env. episode reward total was 3.0. running mean: 9.707736649079118\n",
      "resetting env. episode reward total was 12.0. running mean: 9.730659282588325\n",
      "resetting env. episode reward total was 13.0. running mean: 9.763352689762442\n",
      "resetting env. episode reward total was 12.0. running mean: 9.785719162864817\n",
      "resetting env. episode reward total was 9.0. running mean: 9.777861971236169\n",
      "resetting env. episode reward total was 8.0. running mean: 9.760083351523807\n",
      "resetting env. episode reward total was 6.0. running mean: 9.722482518008569\n",
      "resetting env. episode reward total was 10.0. running mean: 9.725257692828484\n",
      "resetting env. episode reward total was 6.0. running mean: 9.688005115900198\n",
      "resetting env. episode reward total was 16.0. running mean: 9.751125064741196\n",
      "resetting env. episode reward total was 11.0. running mean: 9.763613814093784\n",
      "resetting env. episode reward total was 9.0. running mean: 9.755977675952845\n",
      "resetting env. episode reward total was 11.0. running mean: 9.768417899193317\n",
      "resetting env. episode reward total was 19.0. running mean: 9.860733720201383\n",
      "resetting env. episode reward total was 14.0. running mean: 9.90212638299937\n",
      "resetting env. episode reward total was 15.0. running mean: 9.953105119169377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 9.953574067977684\n",
      "resetting env. episode reward total was 15.0. running mean: 10.004038327297907\n",
      "resetting env. episode reward total was 7.0. running mean: 9.973997944024928\n",
      "resetting env. episode reward total was 13.0. running mean: 10.00425796458468\n",
      "resetting env. episode reward total was 7.0. running mean: 9.974215384938834\n",
      "resetting env. episode reward total was 11.0. running mean: 9.984473231089444\n",
      "resetting env. episode reward total was 19.0. running mean: 10.07462849877855\n",
      "resetting env. episode reward total was 14.0. running mean: 10.113882213790765\n",
      "resetting env. episode reward total was 14.0. running mean: 10.152743391652857\n",
      "resetting env. episode reward total was 5.0. running mean: 10.10121595773633\n",
      "resetting env. episode reward total was 15.0. running mean: 10.150203798158966\n",
      "resetting env. episode reward total was 6.0. running mean: 10.108701760177377\n",
      "resetting env. episode reward total was 17.0. running mean: 10.177614742575603\n",
      "resetting env. episode reward total was 7.0. running mean: 10.145838595149847\n",
      "resetting env. episode reward total was 9.0. running mean: 10.134380209198348\n",
      "resetting env. episode reward total was 1.0. running mean: 10.043036407106364\n",
      "resetting env. episode reward total was 4.0. running mean: 9.982606043035299\n",
      "resetting env. episode reward total was 10.0. running mean: 9.982779982604946\n",
      "resetting env. episode reward total was 15.0. running mean: 10.032952182778896\n",
      "resetting env. episode reward total was 9.0. running mean: 10.022622660951107\n",
      "resetting env. episode reward total was 13.0. running mean: 10.052396434341597\n",
      "resetting env. episode reward total was 11.0. running mean: 10.06187246999818\n",
      "resetting env. episode reward total was 7.0. running mean: 10.031253745298198\n",
      "resetting env. episode reward total was 5.0. running mean: 9.980941207845216\n",
      "resetting env. episode reward total was 12.0. running mean: 10.001131795766764\n",
      "resetting env. episode reward total was 11.0. running mean: 10.011120477809095\n",
      "resetting env. episode reward total was 16.0. running mean: 10.071009273031004\n",
      "resetting env. episode reward total was 10.0. running mean: 10.070299180300694\n",
      "resetting env. episode reward total was 2.0. running mean: 9.989596188497686\n",
      "resetting env. episode reward total was 10.0. running mean: 9.989700226612708\n",
      "resetting env. episode reward total was 10.0. running mean: 9.98980322434658\n",
      "resetting env. episode reward total was 17.0. running mean: 10.059905192103114\n",
      "resetting env. episode reward total was 5.0. running mean: 10.009306140182083\n",
      "resetting env. episode reward total was 6.0. running mean: 9.969213078780262\n",
      "resetting env. episode reward total was 7.0. running mean: 9.93952094799246\n",
      "resetting env. episode reward total was 16.0. running mean: 10.000125738512535\n",
      "resetting env. episode reward total was 7.0. running mean: 9.97012448112741\n",
      "resetting env. episode reward total was 9.0. running mean: 9.960423236316135\n",
      "resetting env. episode reward total was 9.0. running mean: 9.950819003952974\n",
      "resetting env. episode reward total was 4.0. running mean: 9.891310813913444\n",
      "resetting env. episode reward total was 1.0. running mean: 9.80239770577431\n",
      "resetting env. episode reward total was 12.0. running mean: 9.824373728716566\n",
      "resetting env. episode reward total was 11.0. running mean: 9.836129991429399\n",
      "resetting env. episode reward total was 6.0. running mean: 9.797768691515104\n",
      "resetting env. episode reward total was 14.0. running mean: 9.839791004599954\n",
      "resetting env. episode reward total was 5.0. running mean: 9.791393094553955\n",
      "resetting env. episode reward total was 4.0. running mean: 9.733479163608415\n",
      "resetting env. episode reward total was 14.0. running mean: 9.77614437197233\n",
      "resetting env. episode reward total was 12.0. running mean: 9.798382928252607\n",
      "resetting env. episode reward total was 7.0. running mean: 9.770399098970081\n",
      "resetting env. episode reward total was 15.0. running mean: 9.822695107980381\n",
      "resetting env. episode reward total was 8.0. running mean: 9.804468156900578\n",
      "resetting env. episode reward total was 7.0. running mean: 9.776423475331573\n",
      "resetting env. episode reward total was 12.0. running mean: 9.798659240578257\n",
      "resetting env. episode reward total was 12.0. running mean: 9.820672648172474\n",
      "resetting env. episode reward total was 12.0. running mean: 9.842465921690748\n",
      "resetting env. episode reward total was 8.0. running mean: 9.82404126247384\n",
      "resetting env. episode reward total was 12.0. running mean: 9.8458008498491\n",
      "resetting env. episode reward total was 10.0. running mean: 9.847342841350608\n",
      "resetting env. episode reward total was 8.0. running mean: 9.828869412937102\n",
      "resetting env. episode reward total was 17.0. running mean: 9.900580718807731\n",
      "resetting env. episode reward total was 5.0. running mean: 9.851574911619654\n",
      "resetting env. episode reward total was 10.0. running mean: 9.853059162503456\n",
      "resetting env. episode reward total was 13.0. running mean: 9.884528570878421\n",
      "resetting env. episode reward total was 10.0. running mean: 9.885683285169637\n",
      "resetting env. episode reward total was 15.0. running mean: 9.936826452317941\n",
      "resetting env. episode reward total was 12.0. running mean: 9.95745818779476\n",
      "resetting env. episode reward total was 14.0. running mean: 9.997883605916813\n",
      "resetting env. episode reward total was 12.0. running mean: 10.017904769857644\n",
      "resetting env. episode reward total was 12.0. running mean: 10.037725722159067\n",
      "resetting env. episode reward total was 4.0. running mean: 9.977348464937474\n",
      "resetting env. episode reward total was 3.0. running mean: 9.907574980288098\n",
      "resetting env. episode reward total was 15.0. running mean: 9.958499230485218\n",
      "resetting env. episode reward total was 11.0. running mean: 9.968914238180366\n",
      "resetting env. episode reward total was 8.0. running mean: 9.949225095798562\n",
      "resetting env. episode reward total was 3.0. running mean: 9.879732844840575\n",
      "resetting env. episode reward total was 7.0. running mean: 9.85093551639217\n",
      "resetting env. episode reward total was 14.0. running mean: 9.892426161228249\n",
      "resetting env. episode reward total was 12.0. running mean: 9.913501899615966\n",
      "resetting env. episode reward total was 14.0. running mean: 9.954366880619807\n",
      "resetting env. episode reward total was 6.0. running mean: 9.914823211813609\n",
      "resetting env. episode reward total was 6.0. running mean: 9.875674979695473\n",
      "resetting env. episode reward total was 5.0. running mean: 9.826918229898519\n",
      "resetting env. episode reward total was 11.0. running mean: 9.838649047599533\n",
      "resetting env. episode reward total was 5.0. running mean: 9.790262557123539\n",
      "resetting env. episode reward total was 10.0. running mean: 9.792359931552303\n",
      "resetting env. episode reward total was 10.0. running mean: 9.79443633223678\n",
      "resetting env. episode reward total was 8.0. running mean: 9.776491968914412\n",
      "resetting env. episode reward total was 17.0. running mean: 9.848727049225268\n",
      "resetting env. episode reward total was 16.0. running mean: 9.910239778733015\n",
      "resetting env. episode reward total was 9.0. running mean: 9.901137380945684\n",
      "resetting env. episode reward total was 11.0. running mean: 9.912126007136226\n",
      "resetting env. episode reward total was 7.0. running mean: 9.883004747064865\n",
      "resetting env. episode reward total was 10.0. running mean: 9.884174699594215\n",
      "resetting env. episode reward total was 13.0. running mean: 9.915332952598273\n",
      "resetting env. episode reward total was 10.0. running mean: 9.91617962307229\n",
      "resetting env. episode reward total was 13.0. running mean: 9.947017826841568\n",
      "resetting env. episode reward total was 2.0. running mean: 9.867547648573153\n",
      "resetting env. episode reward total was 12.0. running mean: 9.88887217208742\n",
      "resetting env. episode reward total was 17.0. running mean: 9.959983450366547\n",
      "resetting env. episode reward total was 12.0. running mean: 9.98038361586288\n",
      "resetting env. episode reward total was 4.0. running mean: 9.920579779704251\n",
      "resetting env. episode reward total was 1.0. running mean: 9.831373981907209\n",
      "resetting env. episode reward total was 2.0. running mean: 9.753060242088136\n",
      "resetting env. episode reward total was 14.0. running mean: 9.795529639667254\n",
      "resetting env. episode reward total was 7.0. running mean: 9.767574343270581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 9.779898599837875\n",
      "resetting env. episode reward total was 10.0. running mean: 9.782099613839495\n",
      "resetting env. episode reward total was 14.0. running mean: 9.8242786177011\n",
      "resetting env. episode reward total was 12.0. running mean: 9.84603583152409\n",
      "resetting env. episode reward total was 2.0. running mean: 9.767575473208847\n",
      "resetting env. episode reward total was 9.0. running mean: 9.759899718476758\n",
      "resetting env. episode reward total was 12.0. running mean: 9.782300721291989\n",
      "resetting env. episode reward total was 7.0. running mean: 9.75447771407907\n",
      "resetting env. episode reward total was 11.0. running mean: 9.766932936938279\n",
      "resetting env. episode reward total was 13.0. running mean: 9.799263607568896\n",
      "resetting env. episode reward total was 11.0. running mean: 9.811270971493206\n",
      "resetting env. episode reward total was 7.0. running mean: 9.783158261778274\n",
      "resetting env. episode reward total was 17.0. running mean: 9.855326679160491\n",
      "resetting env. episode reward total was 15.0. running mean: 9.906773412368887\n",
      "resetting env. episode reward total was 18.0. running mean: 9.987705678245197\n",
      "resetting env. episode reward total was 11.0. running mean: 9.997828621462745\n",
      "resetting env. episode reward total was 14.0. running mean: 10.037850335248118\n",
      "resetting env. episode reward total was 14.0. running mean: 10.077471831895638\n",
      "resetting env. episode reward total was 14.0. running mean: 10.116697113576683\n",
      "resetting env. episode reward total was 15.0. running mean: 10.165530142440916\n",
      "resetting env. episode reward total was 11.0. running mean: 10.173874841016506\n",
      "resetting env. episode reward total was -1.0. running mean: 10.062136092606341\n",
      "resetting env. episode reward total was 11.0. running mean: 10.071514731680278\n",
      "resetting env. episode reward total was 12.0. running mean: 10.090799584363474\n",
      "resetting env. episode reward total was 6.0. running mean: 10.04989158851984\n",
      "resetting env. episode reward total was 12.0. running mean: 10.06939267263464\n",
      "resetting env. episode reward total was 13.0. running mean: 10.098698745908294\n",
      "resetting env. episode reward total was 6.0. running mean: 10.057711758449212\n",
      "resetting env. episode reward total was 8.0. running mean: 10.03713464086472\n",
      "resetting env. episode reward total was 12.0. running mean: 10.056763294456072\n",
      "resetting env. episode reward total was 14.0. running mean: 10.096195661511512\n",
      "resetting env. episode reward total was 7.0. running mean: 10.065233704896396\n",
      "resetting env. episode reward total was 11.0. running mean: 10.074581367847431\n",
      "resetting env. episode reward total was 11.0. running mean: 10.083835554168957\n",
      "resetting env. episode reward total was 17.0. running mean: 10.152997198627267\n",
      "resetting env. episode reward total was 12.0. running mean: 10.171467226640994\n",
      "resetting env. episode reward total was 7.0. running mean: 10.139752554374583\n",
      "resetting env. episode reward total was -3.0. running mean: 10.008355028830838\n",
      "resetting env. episode reward total was 15.0. running mean: 10.05827147854253\n",
      "resetting env. episode reward total was 17.0. running mean: 10.127688763757105\n",
      "resetting env. episode reward total was 10.0. running mean: 10.126411876119533\n",
      "resetting env. episode reward total was 11.0. running mean: 10.135147757358338\n",
      "resetting env. episode reward total was 15.0. running mean: 10.183796279784755\n",
      "resetting env. episode reward total was 16.0. running mean: 10.241958316986906\n",
      "resetting env. episode reward total was 6.0. running mean: 10.199538733817038\n",
      "resetting env. episode reward total was -6.0. running mean: 10.037543346478866\n",
      "resetting env. episode reward total was 9.0. running mean: 10.027167913014077\n",
      "resetting env. episode reward total was 13.0. running mean: 10.056896233883936\n",
      "resetting env. episode reward total was 7.0. running mean: 10.026327271545098\n",
      "resetting env. episode reward total was 8.0. running mean: 10.006063998829648\n",
      "resetting env. episode reward total was 3.0. running mean: 9.93600335884135\n",
      "resetting env. episode reward total was 8.0. running mean: 9.916643325252938\n",
      "resetting env. episode reward total was 13.0. running mean: 9.94747689200041\n",
      "resetting env. episode reward total was 14.0. running mean: 9.988002123080406\n",
      "resetting env. episode reward total was 12.0. running mean: 10.008122101849601\n",
      "resetting env. episode reward total was 15.0. running mean: 10.058040880831106\n",
      "resetting env. episode reward total was 9.0. running mean: 10.047460472022795\n",
      "resetting env. episode reward total was 10.0. running mean: 10.046985867302567\n",
      "resetting env. episode reward total was 10.0. running mean: 10.04651600862954\n",
      "resetting env. episode reward total was 12.0. running mean: 10.066050848543243\n",
      "resetting env. episode reward total was 13.0. running mean: 10.095390340057811\n",
      "resetting env. episode reward total was 7.0. running mean: 10.064436436657234\n",
      "resetting env. episode reward total was 14.0. running mean: 10.103792072290661\n",
      "resetting env. episode reward total was 11.0. running mean: 10.112754151567753\n",
      "resetting env. episode reward total was 6.0. running mean: 10.071626610052075\n",
      "resetting env. episode reward total was 17.0. running mean: 10.140910343951553\n",
      "resetting env. episode reward total was 7.0. running mean: 10.109501240512039\n",
      "resetting env. episode reward total was 11.0. running mean: 10.118406228106917\n",
      "resetting env. episode reward total was 12.0. running mean: 10.137222165825847\n",
      "resetting env. episode reward total was 12.0. running mean: 10.155849944167587\n",
      "resetting env. episode reward total was 14.0. running mean: 10.194291444725911\n",
      "resetting env. episode reward total was 8.0. running mean: 10.172348530278652\n",
      "resetting env. episode reward total was 14.0. running mean: 10.210625044975867\n",
      "resetting env. episode reward total was 9.0. running mean: 10.198518794526107\n",
      "resetting env. episode reward total was 12.0. running mean: 10.216533606580844\n",
      "resetting env. episode reward total was 6.0. running mean: 10.174368270515036\n",
      "resetting env. episode reward total was 13.0. running mean: 10.202624587809886\n",
      "resetting env. episode reward total was 4.0. running mean: 10.140598341931787\n",
      "resetting env. episode reward total was 13.0. running mean: 10.16919235851247\n",
      "resetting env. episode reward total was 10.0. running mean: 10.167500434927344\n",
      "resetting env. episode reward total was 7.0. running mean: 10.135825430578072\n",
      "resetting env. episode reward total was 14.0. running mean: 10.174467176272291\n",
      "resetting env. episode reward total was 11.0. running mean: 10.182722504509567\n",
      "resetting env. episode reward total was 12.0. running mean: 10.20089527946447\n",
      "resetting env. episode reward total was 6.0. running mean: 10.158886326669826\n",
      "resetting env. episode reward total was 3.0. running mean: 10.087297463403127\n",
      "resetting env. episode reward total was 13.0. running mean: 10.116424488769097\n",
      "resetting env. episode reward total was 16.0. running mean: 10.175260243881405\n",
      "resetting env. episode reward total was 6.0. running mean: 10.133507641442591\n",
      "resetting env. episode reward total was 11.0. running mean: 10.142172565028165\n",
      "resetting env. episode reward total was 16.0. running mean: 10.200750839377884\n",
      "resetting env. episode reward total was 16.0. running mean: 10.258743330984105\n",
      "resetting env. episode reward total was 12.0. running mean: 10.276155897674263\n",
      "resetting env. episode reward total was 9.0. running mean: 10.26339433869752\n",
      "resetting env. episode reward total was 9.0. running mean: 10.250760395310545\n",
      "resetting env. episode reward total was 12.0. running mean: 10.268252791357439\n",
      "resetting env. episode reward total was 12.0. running mean: 10.285570263443864\n",
      "resetting env. episode reward total was 5.0. running mean: 10.232714560809425\n",
      "resetting env. episode reward total was 8.0. running mean: 10.21038741520133\n",
      "resetting env. episode reward total was 13.0. running mean: 10.238283541049318\n",
      "resetting env. episode reward total was 13.0. running mean: 10.265900705638826\n",
      "resetting env. episode reward total was 8.0. running mean: 10.243241698582437\n",
      "resetting env. episode reward total was 16.0. running mean: 10.300809281596614\n",
      "resetting env. episode reward total was -12.0. running mean: 10.077801188780649\n",
      "resetting env. episode reward total was 13.0. running mean: 10.107023176892843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 10.135952945123915\n",
      "resetting env. episode reward total was 8.0. running mean: 10.114593415672676\n",
      "resetting env. episode reward total was 8.0. running mean: 10.09344748151595\n",
      "resetting env. episode reward total was 11.0. running mean: 10.10251300670079\n",
      "resetting env. episode reward total was 10.0. running mean: 10.101487876633781\n",
      "resetting env. episode reward total was 15.0. running mean: 10.150472997867444\n",
      "resetting env. episode reward total was 17.0. running mean: 10.21896826788877\n",
      "resetting env. episode reward total was 7.0. running mean: 10.18677858520988\n",
      "resetting env. episode reward total was 12.0. running mean: 10.204910799357782\n",
      "resetting env. episode reward total was 11.0. running mean: 10.212861691364203\n",
      "resetting env. episode reward total was 14.0. running mean: 10.250733074450562\n",
      "resetting env. episode reward total was 13.0. running mean: 10.278225743706056\n",
      "resetting env. episode reward total was 1.0. running mean: 10.185443486268994\n",
      "resetting env. episode reward total was 4.0. running mean: 10.123589051406304\n",
      "resetting env. episode reward total was 12.0. running mean: 10.14235316089224\n",
      "resetting env. episode reward total was 13.0. running mean: 10.170929629283318\n",
      "resetting env. episode reward total was 17.0. running mean: 10.239220332990485\n",
      "resetting env. episode reward total was 6.0. running mean: 10.196828129660581\n",
      "resetting env. episode reward total was 4.0. running mean: 10.134859848363973\n",
      "resetting env. episode reward total was 15.0. running mean: 10.183511249880334\n",
      "resetting env. episode reward total was 11.0. running mean: 10.191676137381531\n",
      "resetting env. episode reward total was 10.0. running mean: 10.189759376007716\n",
      "resetting env. episode reward total was 15.0. running mean: 10.23786178224764\n",
      "resetting env. episode reward total was 7.0. running mean: 10.205483164425164\n",
      "resetting env. episode reward total was 4.0. running mean: 10.143428332780912\n",
      "resetting env. episode reward total was 5.0. running mean: 10.091994049453104\n",
      "resetting env. episode reward total was 10.0. running mean: 10.091074108958573\n",
      "resetting env. episode reward total was 14.0. running mean: 10.130163367868988\n",
      "resetting env. episode reward total was 15.0. running mean: 10.1788617341903\n",
      "resetting env. episode reward total was 7.0. running mean: 10.147073116848397\n",
      "resetting env. episode reward total was 14.0. running mean: 10.185602385679912\n",
      "resetting env. episode reward total was 6.0. running mean: 10.143746361823114\n",
      "resetting env. episode reward total was 7.0. running mean: 10.112308898204883\n",
      "resetting env. episode reward total was 13.0. running mean: 10.141185809222835\n",
      "resetting env. episode reward total was 9.0. running mean: 10.129773951130606\n",
      "resetting env. episode reward total was -3.0. running mean: 9.9984762116193\n",
      "resetting env. episode reward total was -1.0. running mean: 9.888491449503107\n",
      "resetting env. episode reward total was 8.0. running mean: 9.869606535008076\n",
      "resetting env. episode reward total was 10.0. running mean: 9.870910469657995\n",
      "resetting env. episode reward total was 4.0. running mean: 9.812201364961414\n",
      "resetting env. episode reward total was 8.0. running mean: 9.7940793513118\n",
      "resetting env. episode reward total was 7.0. running mean: 9.766138557798682\n",
      "resetting env. episode reward total was 14.0. running mean: 9.808477172220694\n",
      "resetting env. episode reward total was 3.0. running mean: 9.740392400498488\n",
      "resetting env. episode reward total was 9.0. running mean: 9.732988476493503\n",
      "resetting env. episode reward total was 8.0. running mean: 9.715658591728568\n",
      "resetting env. episode reward total was 10.0. running mean: 9.718502005811281\n",
      "resetting env. episode reward total was 7.0. running mean: 9.691316985753168\n",
      "resetting env. episode reward total was 20.0. running mean: 9.794403815895636\n",
      "resetting env. episode reward total was 7.0. running mean: 9.76645977773668\n",
      "resetting env. episode reward total was 14.0. running mean: 9.808795179959313\n",
      "resetting env. episode reward total was 11.0. running mean: 9.82070722815972\n",
      "resetting env. episode reward total was 8.0. running mean: 9.802500155878121\n",
      "resetting env. episode reward total was 4.0. running mean: 9.744475154319339\n",
      "resetting env. episode reward total was 7.0. running mean: 9.717030402776146\n",
      "resetting env. episode reward total was 2.0. running mean: 9.639860098748384\n",
      "resetting env. episode reward total was 13.0. running mean: 9.6734614977609\n",
      "resetting env. episode reward total was 14.0. running mean: 9.716726882783291\n",
      "resetting env. episode reward total was 12.0. running mean: 9.739559613955457\n",
      "resetting env. episode reward total was 8.0. running mean: 9.722164017815903\n",
      "resetting env. episode reward total was 8.0. running mean: 9.704942377637744\n",
      "resetting env. episode reward total was 6.0. running mean: 9.667892953861367\n",
      "resetting env. episode reward total was 16.0. running mean: 9.731214024322753\n",
      "resetting env. episode reward total was -1.0. running mean: 9.623901884079526\n",
      "resetting env. episode reward total was 6.0. running mean: 9.58766286523873\n",
      "resetting env. episode reward total was 6.0. running mean: 9.551786236586343\n",
      "resetting env. episode reward total was 5.0. running mean: 9.50626837422048\n",
      "resetting env. episode reward total was 17.0. running mean: 9.581205690478276\n",
      "resetting env. episode reward total was 13.0. running mean: 9.615393633573493\n",
      "resetting env. episode reward total was 15.0. running mean: 9.669239697237758\n",
      "resetting env. episode reward total was 2.0. running mean: 9.59254730026538\n",
      "resetting env. episode reward total was 11.0. running mean: 9.606621827262726\n",
      "resetting env. episode reward total was 12.0. running mean: 9.630555608990099\n",
      "resetting env. episode reward total was 15.0. running mean: 9.684250052900198\n",
      "resetting env. episode reward total was 7.0. running mean: 9.657407552371197\n",
      "resetting env. episode reward total was 11.0. running mean: 9.670833476847484\n",
      "resetting env. episode reward total was 14.0. running mean: 9.71412514207901\n",
      "resetting env. episode reward total was 11.0. running mean: 9.726983890658218\n",
      "resetting env. episode reward total was 13.0. running mean: 9.759714051751637\n",
      "resetting env. episode reward total was 16.0. running mean: 9.82211691123412\n",
      "resetting env. episode reward total was 15.0. running mean: 9.87389574212178\n",
      "resetting env. episode reward total was 11.0. running mean: 9.88515678470056\n",
      "resetting env. episode reward total was 10.0. running mean: 9.886305216853554\n",
      "resetting env. episode reward total was 15.0. running mean: 9.937442164685018\n",
      "resetting env. episode reward total was -1.0. running mean: 9.828067743038169\n",
      "resetting env. episode reward total was 7.0. running mean: 9.799787065607788\n",
      "resetting env. episode reward total was 14.0. running mean: 9.84178919495171\n",
      "resetting env. episode reward total was 6.0. running mean: 9.803371303002194\n",
      "resetting env. episode reward total was 15.0. running mean: 9.855337589972173\n",
      "resetting env. episode reward total was 13.0. running mean: 9.886784214072453\n",
      "resetting env. episode reward total was 14.0. running mean: 9.927916371931728\n",
      "resetting env. episode reward total was 11.0. running mean: 9.938637208212409\n",
      "resetting env. episode reward total was 11.0. running mean: 9.949250836130284\n",
      "resetting env. episode reward total was 14.0. running mean: 9.989758327768982\n",
      "resetting env. episode reward total was 10.0. running mean: 9.989860744491292\n",
      "resetting env. episode reward total was 9.0. running mean: 9.979962137046378\n",
      "resetting env. episode reward total was 15.0. running mean: 10.030162515675915\n",
      "resetting env. episode reward total was 8.0. running mean: 10.009860890519155\n",
      "resetting env. episode reward total was 8.0. running mean: 9.989762281613963\n",
      "resetting env. episode reward total was 2.0. running mean: 9.909864658797822\n",
      "resetting env. episode reward total was 17.0. running mean: 9.980766012209845\n",
      "resetting env. episode reward total was 14.0. running mean: 10.020958352087746\n",
      "resetting env. episode reward total was 10.0. running mean: 10.020748768566868\n",
      "resetting env. episode reward total was 7.0. running mean: 9.9905412808812\n",
      "resetting env. episode reward total was 12.0. running mean: 10.010635868072386\n",
      "resetting env. episode reward total was 16.0. running mean: 10.070529509391662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 10.039824214297745\n",
      "resetting env. episode reward total was 10.0. running mean: 10.039425972154767\n",
      "resetting env. episode reward total was 11.0. running mean: 10.04903171243322\n",
      "resetting env. episode reward total was 9.0. running mean: 10.038541395308886\n",
      "resetting env. episode reward total was 15.0. running mean: 10.088155981355797\n",
      "resetting env. episode reward total was 5.0. running mean: 10.03727442154224\n",
      "resetting env. episode reward total was 1.0. running mean: 9.946901677326817\n",
      "resetting env. episode reward total was 6.0. running mean: 9.90743266055355\n",
      "resetting env. episode reward total was 14.0. running mean: 9.948358333948015\n",
      "resetting env. episode reward total was 13.0. running mean: 9.978874750608535\n",
      "resetting env. episode reward total was 8.0. running mean: 9.959086003102449\n",
      "resetting env. episode reward total was 13.0. running mean: 9.989495143071425\n",
      "resetting env. episode reward total was 16.0. running mean: 10.04960019164071\n",
      "resetting env. episode reward total was 14.0. running mean: 10.089104189724303\n",
      "resetting env. episode reward total was 15.0. running mean: 10.13821314782706\n",
      "resetting env. episode reward total was 14.0. running mean: 10.176831016348789\n",
      "resetting env. episode reward total was 13.0. running mean: 10.205062706185302\n",
      "resetting env. episode reward total was 15.0. running mean: 10.25301207912345\n",
      "resetting env. episode reward total was 14.0. running mean: 10.290481958332215\n",
      "resetting env. episode reward total was 11.0. running mean: 10.297577138748892\n",
      "resetting env. episode reward total was 11.0. running mean: 10.304601367361402\n",
      "resetting env. episode reward total was 18.0. running mean: 10.381555353687787\n",
      "resetting env. episode reward total was 9.0. running mean: 10.36773980015091\n",
      "resetting env. episode reward total was 2.0. running mean: 10.2840624021494\n",
      "resetting env. episode reward total was 13.0. running mean: 10.311221778127907\n",
      "resetting env. episode reward total was 17.0. running mean: 10.378109560346628\n",
      "resetting env. episode reward total was 15.0. running mean: 10.424328464743162\n",
      "resetting env. episode reward total was 11.0. running mean: 10.43008518009573\n",
      "resetting env. episode reward total was 2.0. running mean: 10.345784328294773\n",
      "resetting env. episode reward total was 12.0. running mean: 10.362326485011824\n",
      "resetting env. episode reward total was 16.0. running mean: 10.418703220161706\n",
      "resetting env. episode reward total was 14.0. running mean: 10.45451618796009\n",
      "resetting env. episode reward total was 5.0. running mean: 10.39997102608049\n",
      "resetting env. episode reward total was -4.0. running mean: 10.255971315819686\n",
      "resetting env. episode reward total was 14.0. running mean: 10.29341160266149\n",
      "resetting env. episode reward total was 8.0. running mean: 10.270477486634874\n",
      "resetting env. episode reward total was 9.0. running mean: 10.257772711768526\n",
      "resetting env. episode reward total was 13.0. running mean: 10.285194984650841\n",
      "resetting env. episode reward total was 12.0. running mean: 10.302343034804332\n",
      "resetting env. episode reward total was 9.0. running mean: 10.289319604456288\n",
      "resetting env. episode reward total was 9.0. running mean: 10.276426408411725\n",
      "resetting env. episode reward total was 9.0. running mean: 10.263662144327608\n",
      "resetting env. episode reward total was 11.0. running mean: 10.271025522884331\n",
      "resetting env. episode reward total was 12.0. running mean: 10.288315267655488\n",
      "resetting env. episode reward total was 7.0. running mean: 10.255432114978934\n",
      "resetting env. episode reward total was 10.0. running mean: 10.252877793829144\n",
      "resetting env. episode reward total was 11.0. running mean: 10.260349015890853\n",
      "resetting env. episode reward total was 15.0. running mean: 10.307745525731944\n",
      "resetting env. episode reward total was 13.0. running mean: 10.334668070474626\n",
      "resetting env. episode reward total was 9.0. running mean: 10.32132138976988\n",
      "resetting env. episode reward total was 6.0. running mean: 10.27810817587218\n",
      "resetting env. episode reward total was 11.0. running mean: 10.285327094113457\n",
      "resetting env. episode reward total was 10.0. running mean: 10.282473823172323\n",
      "resetting env. episode reward total was 1.0. running mean: 10.1896490849406\n",
      "resetting env. episode reward total was 10.0. running mean: 10.187752594091194\n",
      "resetting env. episode reward total was 11.0. running mean: 10.195875068150281\n",
      "resetting env. episode reward total was 7.0. running mean: 10.163916317468779\n",
      "resetting env. episode reward total was 11.0. running mean: 10.17227715429409\n",
      "resetting env. episode reward total was 3.0. running mean: 10.100554382751149\n",
      "resetting env. episode reward total was 4.0. running mean: 10.039548838923636\n",
      "resetting env. episode reward total was 14.0. running mean: 10.0791533505344\n",
      "resetting env. episode reward total was 2.0. running mean: 9.998361817029055\n",
      "resetting env. episode reward total was 9.0. running mean: 9.988378198858765\n",
      "resetting env. episode reward total was 6.0. running mean: 9.948494416870178\n",
      "resetting env. episode reward total was 21.0. running mean: 10.059009472701476\n",
      "resetting env. episode reward total was 8.0. running mean: 10.038419377974462\n",
      "resetting env. episode reward total was 7.0. running mean: 10.008035184194718\n",
      "resetting env. episode reward total was 9.0. running mean: 9.99795483235277\n",
      "resetting env. episode reward total was 18.0. running mean: 10.077975284029241\n",
      "resetting env. episode reward total was 10.0. running mean: 10.077195531188949\n",
      "resetting env. episode reward total was 2.0. running mean: 9.996423575877058\n",
      "resetting env. episode reward total was 5.0. running mean: 9.946459340118288\n",
      "resetting env. episode reward total was 12.0. running mean: 9.966994746717104\n",
      "resetting env. episode reward total was 9.0. running mean: 9.957324799249932\n",
      "resetting env. episode reward total was 10.0. running mean: 9.957751551257433\n",
      "resetting env. episode reward total was 7.0. running mean: 9.928174035744858\n",
      "resetting env. episode reward total was -5.0. running mean: 9.778892295387408\n",
      "resetting env. episode reward total was 5.0. running mean: 9.731103372433534\n",
      "resetting env. episode reward total was 6.0. running mean: 9.6937923387092\n",
      "resetting env. episode reward total was 6.0. running mean: 9.656854415322108\n",
      "resetting env. episode reward total was 14.0. running mean: 9.700285871168887\n",
      "resetting env. episode reward total was 14.0. running mean: 9.7432830124572\n",
      "resetting env. episode reward total was 10.0. running mean: 9.745850182332628\n",
      "resetting env. episode reward total was 16.0. running mean: 9.808391680509303\n",
      "resetting env. episode reward total was 4.0. running mean: 9.750307763704209\n",
      "resetting env. episode reward total was 15.0. running mean: 9.802804686067168\n",
      "resetting env. episode reward total was 7.0. running mean: 9.774776639206497\n",
      "resetting env. episode reward total was 16.0. running mean: 9.837028872814432\n",
      "resetting env. episode reward total was 5.0. running mean: 9.788658584086289\n",
      "resetting env. episode reward total was 15.0. running mean: 9.840771998245426\n",
      "resetting env. episode reward total was 6.0. running mean: 9.802364278262973\n",
      "resetting env. episode reward total was 8.0. running mean: 9.784340635480342\n",
      "resetting env. episode reward total was 10.0. running mean: 9.786497229125539\n",
      "resetting env. episode reward total was 12.0. running mean: 9.808632256834283\n",
      "resetting env. episode reward total was 15.0. running mean: 9.860545934265941\n",
      "resetting env. episode reward total was 17.0. running mean: 9.931940474923282\n",
      "resetting env. episode reward total was 9.0. running mean: 9.92262107017405\n",
      "resetting env. episode reward total was 18.0. running mean: 10.003394859472309\n",
      "resetting env. episode reward total was 8.0. running mean: 9.983360910877586\n",
      "resetting env. episode reward total was 16.0. running mean: 10.04352730176881\n",
      "resetting env. episode reward total was 4.0. running mean: 9.983092028751122\n",
      "resetting env. episode reward total was 16.0. running mean: 10.04326110846361\n",
      "resetting env. episode reward total was 9.0. running mean: 10.032828497378974\n",
      "resetting env. episode reward total was 7.0. running mean: 10.002500212405184\n",
      "resetting env. episode reward total was 13.0. running mean: 10.032475210281133\n",
      "resetting env. episode reward total was 9.0. running mean: 10.022150458178322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 10.051928953596539\n",
      "resetting env. episode reward total was 9.0. running mean: 10.041409664060573\n",
      "resetting env. episode reward total was 12.0. running mean: 10.060995567419967\n",
      "resetting env. episode reward total was 10.0. running mean: 10.060385611745767\n",
      "resetting env. episode reward total was 3.0. running mean: 9.989781755628309\n",
      "resetting env. episode reward total was 16.0. running mean: 10.049883938072027\n",
      "resetting env. episode reward total was 15.0. running mean: 10.099385098691307\n",
      "resetting env. episode reward total was 5.0. running mean: 10.048391247704394\n",
      "resetting env. episode reward total was 12.0. running mean: 10.06790733522735\n",
      "resetting env. episode reward total was 4.0. running mean: 10.007228261875076\n",
      "resetting env. episode reward total was 10.0. running mean: 10.007155979256325\n",
      "resetting env. episode reward total was 12.0. running mean: 10.02708441946376\n",
      "resetting env. episode reward total was 8.0. running mean: 10.006813575269122\n",
      "resetting env. episode reward total was 11.0. running mean: 10.01674543951643\n",
      "resetting env. episode reward total was 10.0. running mean: 10.016577985121266\n",
      "resetting env. episode reward total was 11.0. running mean: 10.026412205270052\n",
      "resetting env. episode reward total was 9.0. running mean: 10.01614808321735\n",
      "resetting env. episode reward total was 10.0. running mean: 10.015986602385176\n",
      "resetting env. episode reward total was 10.0. running mean: 10.015826736361324\n",
      "resetting env. episode reward total was 1.0. running mean: 9.925668468997712\n",
      "resetting env. episode reward total was 15.0. running mean: 9.976411784307734\n",
      "resetting env. episode reward total was 6.0. running mean: 9.936647666464657\n",
      "resetting env. episode reward total was 8.0. running mean: 9.91728118980001\n",
      "resetting env. episode reward total was 11.0. running mean: 9.928108377902008\n",
      "resetting env. episode reward total was 11.0. running mean: 9.938827294122987\n",
      "resetting env. episode reward total was 13.0. running mean: 9.969439021181758\n",
      "resetting env. episode reward total was 9.0. running mean: 9.95974463096994\n",
      "resetting env. episode reward total was -3.0. running mean: 9.830147184660241\n",
      "resetting env. episode reward total was 6.0. running mean: 9.79184571281364\n",
      "resetting env. episode reward total was 6.0. running mean: 9.753927255685504\n",
      "resetting env. episode reward total was 3.0. running mean: 9.686387983128649\n",
      "resetting env. episode reward total was 12.0. running mean: 9.709524103297362\n",
      "resetting env. episode reward total was 11.0. running mean: 9.722428862264387\n",
      "resetting env. episode reward total was 14.0. running mean: 9.765204573641743\n",
      "resetting env. episode reward total was 6.0. running mean: 9.727552527905326\n",
      "resetting env. episode reward total was 13.0. running mean: 9.760277002626273\n",
      "resetting env. episode reward total was 5.0. running mean: 9.71267423260001\n",
      "resetting env. episode reward total was 10.0. running mean: 9.715547490274009\n",
      "resetting env. episode reward total was 11.0. running mean: 9.728392015371268\n",
      "resetting env. episode reward total was 9.0. running mean: 9.721108095217556\n",
      "resetting env. episode reward total was 7.0. running mean: 9.69389701426538\n",
      "resetting env. episode reward total was 6.0. running mean: 9.656958044122726\n",
      "resetting env. episode reward total was 11.0. running mean: 9.670388463681498\n",
      "resetting env. episode reward total was 13.0. running mean: 9.703684579044683\n",
      "resetting env. episode reward total was 8.0. running mean: 9.686647733254237\n",
      "resetting env. episode reward total was 13.0. running mean: 9.719781255921696\n",
      "resetting env. episode reward total was 7.0. running mean: 9.692583443362478\n",
      "resetting env. episode reward total was 7.0. running mean: 9.665657608928854\n",
      "resetting env. episode reward total was 15.0. running mean: 9.719001032839564\n",
      "resetting env. episode reward total was 3.0. running mean: 9.651811022511168\n",
      "resetting env. episode reward total was 12.0. running mean: 9.675292912286055\n",
      "resetting env. episode reward total was 7.0. running mean: 9.648539983163195\n",
      "resetting env. episode reward total was 6.0. running mean: 9.612054583331563\n",
      "resetting env. episode reward total was 10.0. running mean: 9.615934037498247\n",
      "resetting env. episode reward total was 12.0. running mean: 9.639774697123263\n",
      "resetting env. episode reward total was 8.0. running mean: 9.62337695015203\n",
      "resetting env. episode reward total was 7.0. running mean: 9.59714318065051\n",
      "resetting env. episode reward total was 18.0. running mean: 9.681171748844005\n",
      "resetting env. episode reward total was 12.0. running mean: 9.704360031355563\n",
      "resetting env. episode reward total was 12.0. running mean: 9.727316431042006\n",
      "resetting env. episode reward total was 12.0. running mean: 9.750043266731584\n",
      "resetting env. episode reward total was 14.0. running mean: 9.79254283406427\n",
      "resetting env. episode reward total was 17.0. running mean: 9.864617405723626\n",
      "resetting env. episode reward total was 2.0. running mean: 9.78597123166639\n",
      "resetting env. episode reward total was 13.0. running mean: 9.818111519349726\n",
      "resetting env. episode reward total was 11.0. running mean: 9.829930404156228\n",
      "resetting env. episode reward total was 14.0. running mean: 9.871631100114666\n",
      "resetting env. episode reward total was 14.0. running mean: 9.91291478911352\n",
      "resetting env. episode reward total was 8.0. running mean: 9.893785641222385\n",
      "resetting env. episode reward total was 4.0. running mean: 9.83484778481016\n",
      "resetting env. episode reward total was 13.0. running mean: 9.866499306962059\n",
      "resetting env. episode reward total was 14.0. running mean: 9.907834313892439\n",
      "resetting env. episode reward total was 12.0. running mean: 9.928755970753514\n",
      "resetting env. episode reward total was 16.0. running mean: 9.989468411045978\n",
      "resetting env. episode reward total was 5.0. running mean: 9.939573726935519\n",
      "resetting env. episode reward total was 7.0. running mean: 9.910177989666163\n",
      "resetting env. episode reward total was 13.0. running mean: 9.941076209769502\n",
      "resetting env. episode reward total was 10.0. running mean: 9.941665447671806\n",
      "resetting env. episode reward total was 18.0. running mean: 10.022248793195088\n",
      "resetting env. episode reward total was 6.0. running mean: 9.982026305263137\n",
      "resetting env. episode reward total was 5.0. running mean: 9.932206042210506\n",
      "resetting env. episode reward total was 7.0. running mean: 9.902883981788401\n",
      "resetting env. episode reward total was 12.0. running mean: 9.923855141970517\n",
      "resetting env. episode reward total was 12.0. running mean: 9.94461659055081\n",
      "resetting env. episode reward total was 6.0. running mean: 9.905170424645302\n",
      "resetting env. episode reward total was 8.0. running mean: 9.88611872039885\n",
      "resetting env. episode reward total was 6.0. running mean: 9.847257533194862\n",
      "resetting env. episode reward total was 14.0. running mean: 9.888784957862914\n",
      "resetting env. episode reward total was 6.0. running mean: 9.849897108284285\n",
      "resetting env. episode reward total was 10.0. running mean: 9.851398137201441\n",
      "resetting env. episode reward total was 11.0. running mean: 9.862884155829425\n",
      "resetting env. episode reward total was 11.0. running mean: 9.87425531427113\n",
      "resetting env. episode reward total was 5.0. running mean: 9.825512761128419\n",
      "resetting env. episode reward total was 8.0. running mean: 9.807257633517134\n",
      "resetting env. episode reward total was 7.0. running mean: 9.779185057181962\n",
      "resetting env. episode reward total was 16.0. running mean: 9.841393206610142\n",
      "resetting env. episode reward total was 7.0. running mean: 9.812979274544041\n",
      "resetting env. episode reward total was 10.0. running mean: 9.8148494817986\n",
      "resetting env. episode reward total was 10.0. running mean: 9.816700986980614\n",
      "resetting env. episode reward total was 10.0. running mean: 9.818533977110807\n",
      "resetting env. episode reward total was 12.0. running mean: 9.840348637339698\n",
      "resetting env. episode reward total was 18.0. running mean: 9.9219451509663\n",
      "resetting env. episode reward total was 10.0. running mean: 9.922725699456636\n",
      "resetting env. episode reward total was 9.0. running mean: 9.91349844246207\n",
      "resetting env. episode reward total was 5.0. running mean: 9.864363458037449\n",
      "resetting env. episode reward total was 10.0. running mean: 9.865719823457074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 9.867062625222502\n",
      "resetting env. episode reward total was 4.0. running mean: 9.808391998970276\n",
      "resetting env. episode reward total was 12.0. running mean: 9.830308078980572\n",
      "resetting env. episode reward total was 13.0. running mean: 9.862004998190766\n",
      "resetting env. episode reward total was 15.0. running mean: 9.91338494820886\n",
      "resetting env. episode reward total was 8.0. running mean: 9.894251098726771\n",
      "resetting env. episode reward total was 7.0. running mean: 9.865308587739504\n",
      "resetting env. episode reward total was 14.0. running mean: 9.90665550186211\n",
      "resetting env. episode reward total was 13.0. running mean: 9.937588946843489\n",
      "resetting env. episode reward total was 4.0. running mean: 9.878213057375053\n",
      "resetting env. episode reward total was 14.0. running mean: 9.919430926801303\n",
      "resetting env. episode reward total was 5.0. running mean: 9.87023661753329\n",
      "resetting env. episode reward total was 8.0. running mean: 9.851534251357958\n",
      "resetting env. episode reward total was -7.0. running mean: 9.683018908844378\n",
      "resetting env. episode reward total was 7.0. running mean: 9.656188719755935\n",
      "resetting env. episode reward total was 13.0. running mean: 9.689626832558377\n",
      "resetting env. episode reward total was 16.0. running mean: 9.752730564232793\n",
      "resetting env. episode reward total was 12.0. running mean: 9.775203258590464\n",
      "resetting env. episode reward total was 8.0. running mean: 9.757451226004559\n",
      "resetting env. episode reward total was 4.0. running mean: 9.699876713744512\n",
      "resetting env. episode reward total was 6.0. running mean: 9.662877946607068\n",
      "resetting env. episode reward total was 8.0. running mean: 9.646249167140997\n",
      "resetting env. episode reward total was 11.0. running mean: 9.659786675469586\n",
      "resetting env. episode reward total was 10.0. running mean: 9.66318880871489\n",
      "resetting env. episode reward total was 16.0. running mean: 9.726556920627742\n",
      "resetting env. episode reward total was 15.0. running mean: 9.779291351421465\n",
      "resetting env. episode reward total was 9.0. running mean: 9.77149843790725\n",
      "resetting env. episode reward total was 14.0. running mean: 9.813783453528178\n",
      "resetting env. episode reward total was 9.0. running mean: 9.805645618992896\n",
      "resetting env. episode reward total was 11.0. running mean: 9.817589162802967\n",
      "resetting env. episode reward total was 12.0. running mean: 9.839413271174937\n",
      "resetting env. episode reward total was 17.0. running mean: 9.911019138463187\n",
      "resetting env. episode reward total was 6.0. running mean: 9.871908947078555\n",
      "resetting env. episode reward total was 15.0. running mean: 9.92318985760777\n",
      "resetting env. episode reward total was -11.0. running mean: 9.713957959031694\n",
      "resetting env. episode reward total was 12.0. running mean: 9.736818379441376\n",
      "resetting env. episode reward total was 9.0. running mean: 9.729450195646962\n",
      "resetting env. episode reward total was 15.0. running mean: 9.782155693690493\n",
      "resetting env. episode reward total was 12.0. running mean: 9.804334136753587\n",
      "resetting env. episode reward total was 6.0. running mean: 9.766290795386052\n",
      "resetting env. episode reward total was 10.0. running mean: 9.76862788743219\n",
      "resetting env. episode reward total was 12.0. running mean: 9.790941608557867\n",
      "resetting env. episode reward total was -1.0. running mean: 9.68303219247229\n",
      "resetting env. episode reward total was 13.0. running mean: 9.716201870547568\n",
      "resetting env. episode reward total was 8.0. running mean: 9.699039851842093\n",
      "resetting env. episode reward total was 1.0. running mean: 9.612049453323671\n",
      "resetting env. episode reward total was 7.0. running mean: 9.585928958790435\n",
      "resetting env. episode reward total was 11.0. running mean: 9.60006966920253\n",
      "resetting env. episode reward total was 10.0. running mean: 9.604068972510504\n",
      "resetting env. episode reward total was 9.0. running mean: 9.598028282785398\n",
      "resetting env. episode reward total was 14.0. running mean: 9.642047999957544\n",
      "resetting env. episode reward total was 9.0. running mean: 9.635627519957968\n",
      "resetting env. episode reward total was 16.0. running mean: 9.699271244758387\n",
      "resetting env. episode reward total was 4.0. running mean: 9.642278532310803\n",
      "resetting env. episode reward total was 18.0. running mean: 9.725855746987694\n",
      "resetting env. episode reward total was 11.0. running mean: 9.738597189517817\n",
      "resetting env. episode reward total was 6.0. running mean: 9.701211217622639\n",
      "resetting env. episode reward total was 7.0. running mean: 9.674199105446412\n",
      "resetting env. episode reward total was 2.0. running mean: 9.597457114391947\n",
      "resetting env. episode reward total was 9.0. running mean: 9.591482543248027\n",
      "resetting env. episode reward total was 11.0. running mean: 9.605567717815546\n",
      "resetting env. episode reward total was -1.0. running mean: 9.499512040637391\n",
      "resetting env. episode reward total was 12.0. running mean: 9.524516920231017\n",
      "resetting env. episode reward total was 4.0. running mean: 9.469271751028705\n",
      "resetting env. episode reward total was 18.0. running mean: 9.554579033518417\n",
      "resetting env. episode reward total was 7.0. running mean: 9.529033243183234\n",
      "resetting env. episode reward total was 12.0. running mean: 9.553742910751401\n",
      "resetting env. episode reward total was 13.0. running mean: 9.588205481643888\n",
      "resetting env. episode reward total was 13.0. running mean: 9.62232342682745\n",
      "resetting env. episode reward total was 9.0. running mean: 9.616100192559175\n",
      "resetting env. episode reward total was 14.0. running mean: 9.659939190633583\n",
      "resetting env. episode reward total was 6.0. running mean: 9.623339798727248\n",
      "resetting env. episode reward total was 10.0. running mean: 9.627106400739974\n",
      "resetting env. episode reward total was 3.0. running mean: 9.560835336732573\n",
      "resetting env. episode reward total was 9.0. running mean: 9.555226983365248\n",
      "resetting env. episode reward total was 12.0. running mean: 9.579674713531595\n",
      "resetting env. episode reward total was 5.0. running mean: 9.53387796639628\n",
      "resetting env. episode reward total was 13.0. running mean: 9.568539186732318\n",
      "resetting env. episode reward total was 11.0. running mean: 9.582853794864993\n",
      "resetting env. episode reward total was 8.0. running mean: 9.567025256916343\n",
      "resetting env. episode reward total was 2.0. running mean: 9.491355004347179\n",
      "resetting env. episode reward total was 5.0. running mean: 9.446441454303708\n",
      "resetting env. episode reward total was 9.0. running mean: 9.44197703976067\n",
      "resetting env. episode reward total was 11.0. running mean: 9.457557269363063\n",
      "resetting env. episode reward total was -3.0. running mean: 9.332981696669433\n",
      "resetting env. episode reward total was 8.0. running mean: 9.31965187970274\n",
      "resetting env. episode reward total was -5.0. running mean: 9.176455360905711\n",
      "resetting env. episode reward total was 15.0. running mean: 9.234690807296655\n",
      "resetting env. episode reward total was 14.0. running mean: 9.282343899223688\n",
      "resetting env. episode reward total was 8.0. running mean: 9.269520460231451\n",
      "resetting env. episode reward total was 15.0. running mean: 9.326825255629137\n",
      "resetting env. episode reward total was 8.0. running mean: 9.313557003072846\n",
      "resetting env. episode reward total was 13.0. running mean: 9.350421433042118\n",
      "resetting env. episode reward total was 9.0. running mean: 9.346917218711697\n",
      "resetting env. episode reward total was 12.0. running mean: 9.37344804652458\n",
      "resetting env. episode reward total was 12.0. running mean: 9.399713566059333\n",
      "resetting env. episode reward total was 8.0. running mean: 9.38571643039874\n",
      "resetting env. episode reward total was 7.0. running mean: 9.361859266094752\n",
      "resetting env. episode reward total was 9.0. running mean: 9.358240673433805\n",
      "resetting env. episode reward total was 8.0. running mean: 9.344658266699467\n",
      "resetting env. episode reward total was 15.0. running mean: 9.401211684032473\n",
      "resetting env. episode reward total was 5.0. running mean: 9.357199567192149\n",
      "resetting env. episode reward total was 13.0. running mean: 9.393627571520229\n",
      "resetting env. episode reward total was 9.0. running mean: 9.389691295805026\n",
      "resetting env. episode reward total was 3.0. running mean: 9.325794382846976\n",
      "resetting env. episode reward total was 13.0. running mean: 9.362536439018507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 9.308911074628321\n",
      "resetting env. episode reward total was 5.0. running mean: 9.265821963882038\n",
      "resetting env. episode reward total was 4.0. running mean: 9.213163744243216\n",
      "resetting env. episode reward total was 16.0. running mean: 9.281032106800785\n",
      "resetting env. episode reward total was 12.0. running mean: 9.308221785732776\n",
      "resetting env. episode reward total was 1.0. running mean: 9.225139567875448\n",
      "resetting env. episode reward total was 17.0. running mean: 9.302888172196694\n",
      "resetting env. episode reward total was 10.0. running mean: 9.309859290474726\n",
      "resetting env. episode reward total was 11.0. running mean: 9.326760697569979\n",
      "resetting env. episode reward total was 8.0. running mean: 9.31349309059428\n",
      "resetting env. episode reward total was 10.0. running mean: 9.320358159688336\n",
      "resetting env. episode reward total was 3.0. running mean: 9.257154578091452\n",
      "resetting env. episode reward total was 11.0. running mean: 9.274583032310536\n",
      "resetting env. episode reward total was 12.0. running mean: 9.30183720198743\n",
      "resetting env. episode reward total was 13.0. running mean: 9.338818829967556\n",
      "resetting env. episode reward total was 11.0. running mean: 9.35543064166788\n",
      "resetting env. episode reward total was 11.0. running mean: 9.3718763352512\n",
      "resetting env. episode reward total was 9.0. running mean: 9.368157571898687\n",
      "resetting env. episode reward total was 12.0. running mean: 9.394475996179699\n",
      "resetting env. episode reward total was 15.0. running mean: 9.450531236217902\n",
      "resetting env. episode reward total was 11.0. running mean: 9.466025923855723\n",
      "resetting env. episode reward total was 15.0. running mean: 9.521365664617166\n",
      "resetting env. episode reward total was 4.0. running mean: 9.466152007970994\n",
      "resetting env. episode reward total was 8.0. running mean: 9.451490487891284\n",
      "resetting env. episode reward total was 6.0. running mean: 9.416975583012372\n",
      "resetting env. episode reward total was 17.0. running mean: 9.492805827182247\n",
      "resetting env. episode reward total was 13.0. running mean: 9.527877768910425\n",
      "resetting env. episode reward total was 6.0. running mean: 9.492598991221321\n",
      "resetting env. episode reward total was 8.0. running mean: 9.477673001309109\n",
      "resetting env. episode reward total was 15.0. running mean: 9.532896271296018\n",
      "resetting env. episode reward total was 10.0. running mean: 9.537567308583057\n",
      "resetting env. episode reward total was 15.0. running mean: 9.592191635497226\n",
      "resetting env. episode reward total was 9.0. running mean: 9.586269719142253\n",
      "resetting env. episode reward total was 13.0. running mean: 9.62040702195083\n",
      "resetting env. episode reward total was 14.0. running mean: 9.664202951731323\n",
      "resetting env. episode reward total was 13.0. running mean: 9.69756092221401\n",
      "resetting env. episode reward total was 11.0. running mean: 9.710585312991869\n",
      "resetting env. episode reward total was 16.0. running mean: 9.77347945986195\n",
      "resetting env. episode reward total was 11.0. running mean: 9.78574466526333\n",
      "resetting env. episode reward total was 12.0. running mean: 9.807887218610697\n",
      "resetting env. episode reward total was 13.0. running mean: 9.83980834642459\n",
      "resetting env. episode reward total was 8.0. running mean: 9.821410262960343\n",
      "resetting env. episode reward total was 12.0. running mean: 9.84319616033074\n",
      "resetting env. episode reward total was 16.0. running mean: 9.904764198727433\n",
      "resetting env. episode reward total was 16.0. running mean: 9.965716556740158\n",
      "resetting env. episode reward total was 11.0. running mean: 9.976059391172756\n",
      "resetting env. episode reward total was 8.0. running mean: 9.956298797261029\n",
      "resetting env. episode reward total was -1.0. running mean: 9.846735809288418\n",
      "resetting env. episode reward total was 1.0. running mean: 9.758268451195534\n",
      "resetting env. episode reward total was 16.0. running mean: 9.820685766683578\n",
      "resetting env. episode reward total was 14.0. running mean: 9.862478909016742\n",
      "resetting env. episode reward total was 11.0. running mean: 9.873854119926573\n",
      "resetting env. episode reward total was 6.0. running mean: 9.835115578727308\n",
      "resetting env. episode reward total was 2.0. running mean: 9.756764422940034\n",
      "resetting env. episode reward total was 3.0. running mean: 9.689196778710633\n",
      "resetting env. episode reward total was 13.0. running mean: 9.722304810923527\n",
      "resetting env. episode reward total was 17.0. running mean: 9.795081762814291\n",
      "resetting env. episode reward total was 11.0. running mean: 9.807130945186147\n",
      "resetting env. episode reward total was 12.0. running mean: 9.829059635734284\n",
      "resetting env. episode reward total was 12.0. running mean: 9.85076903937694\n",
      "resetting env. episode reward total was 12.0. running mean: 9.87226134898317\n",
      "resetting env. episode reward total was 13.0. running mean: 9.903538735493338\n",
      "resetting env. episode reward total was 9.0. running mean: 9.894503348138405\n",
      "resetting env. episode reward total was 11.0. running mean: 9.905558314657021\n",
      "resetting env. episode reward total was 5.0. running mean: 9.856502731510451\n",
      "resetting env. episode reward total was 8.0. running mean: 9.837937704195348\n",
      "resetting env. episode reward total was 6.0. running mean: 9.799558327153395\n",
      "resetting env. episode reward total was 10.0. running mean: 9.801562743881862\n",
      "resetting env. episode reward total was 11.0. running mean: 9.813547116443042\n",
      "resetting env. episode reward total was 7.0. running mean: 9.78541164527861\n",
      "resetting env. episode reward total was 10.0. running mean: 9.787557528825824\n",
      "resetting env. episode reward total was 3.0. running mean: 9.719681953537565\n",
      "resetting env. episode reward total was 6.0. running mean: 9.68248513400219\n",
      "resetting env. episode reward total was 10.0. running mean: 9.685660282662168\n",
      "resetting env. episode reward total was 14.0. running mean: 9.728803679835547\n",
      "resetting env. episode reward total was 7.0. running mean: 9.701515643037192\n",
      "resetting env. episode reward total was 12.0. running mean: 9.72450048660682\n",
      "resetting env. episode reward total was 14.0. running mean: 9.767255481740753\n",
      "resetting env. episode reward total was 10.0. running mean: 9.769582926923345\n",
      "resetting env. episode reward total was 8.0. running mean: 9.751887097654112\n",
      "resetting env. episode reward total was 16.0. running mean: 9.814368226677571\n",
      "resetting env. episode reward total was 6.0. running mean: 9.776224544410796\n",
      "resetting env. episode reward total was 9.0. running mean: 9.76846229896669\n",
      "resetting env. episode reward total was 5.0. running mean: 9.720777675977024\n",
      "resetting env. episode reward total was 12.0. running mean: 9.743569899217253\n",
      "resetting env. episode reward total was 13.0. running mean: 9.77613420022508\n",
      "resetting env. episode reward total was 5.0. running mean: 9.72837285822283\n",
      "resetting env. episode reward total was 7.0. running mean: 9.701089129640602\n",
      "resetting env. episode reward total was 13.0. running mean: 9.734078238344196\n",
      "resetting env. episode reward total was 1.0. running mean: 9.646737455960753\n",
      "resetting env. episode reward total was 9.0. running mean: 9.640270081401146\n",
      "resetting env. episode reward total was 14.0. running mean: 9.683867380587136\n",
      "resetting env. episode reward total was 11.0. running mean: 9.697028706781264\n",
      "resetting env. episode reward total was 9.0. running mean: 9.690058419713452\n",
      "resetting env. episode reward total was 7.0. running mean: 9.663157835516317\n",
      "resetting env. episode reward total was 4.0. running mean: 9.606526257161153\n",
      "resetting env. episode reward total was 8.0. running mean: 9.590460994589542\n",
      "resetting env. episode reward total was 12.0. running mean: 9.614556384643645\n",
      "resetting env. episode reward total was 8.0. running mean: 9.59841082079721\n",
      "resetting env. episode reward total was 17.0. running mean: 9.672426712589237\n",
      "resetting env. episode reward total was 2.0. running mean: 9.595702445463344\n",
      "resetting env. episode reward total was 17.0. running mean: 9.66974542100871\n",
      "resetting env. episode reward total was 14.0. running mean: 9.713047966798623\n",
      "resetting env. episode reward total was 1.0. running mean: 9.625917487130636\n",
      "resetting env. episode reward total was 9.0. running mean: 9.619658312259329\n",
      "resetting env. episode reward total was 8.0. running mean: 9.603461729136736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 16.0. running mean: 9.667427111845369\n",
      "resetting env. episode reward total was 9.0. running mean: 9.660752840726914\n",
      "resetting env. episode reward total was 13.0. running mean: 9.694145312319646\n",
      "resetting env. episode reward total was 6.0. running mean: 9.65720385919645\n",
      "resetting env. episode reward total was 8.0. running mean: 9.640631820604485\n",
      "resetting env. episode reward total was 10.0. running mean: 9.64422550239844\n",
      "resetting env. episode reward total was 19.0. running mean: 9.737783247374455\n",
      "resetting env. episode reward total was 10.0. running mean: 9.74040541490071\n",
      "resetting env. episode reward total was 15.0. running mean: 9.793001360751703\n",
      "resetting env. episode reward total was 8.0. running mean: 9.775071347144186\n",
      "resetting env. episode reward total was 9.0. running mean: 9.767320633672744\n",
      "resetting env. episode reward total was 10.0. running mean: 9.769647427336016\n",
      "resetting env. episode reward total was 13.0. running mean: 9.801950953062656\n",
      "resetting env. episode reward total was 2.0. running mean: 9.72393144353203\n",
      "resetting env. episode reward total was 18.0. running mean: 9.806692129096708\n",
      "resetting env. episode reward total was 11.0. running mean: 9.818625207805741\n",
      "resetting env. episode reward total was 15.0. running mean: 9.870438955727684\n",
      "resetting env. episode reward total was 8.0. running mean: 9.851734566170407\n",
      "resetting env. episode reward total was 13.0. running mean: 9.883217220508703\n",
      "resetting env. episode reward total was 15.0. running mean: 9.934385048303616\n",
      "resetting env. episode reward total was 11.0. running mean: 9.94504119782058\n",
      "resetting env. episode reward total was 12.0. running mean: 9.965590785842373\n",
      "resetting env. episode reward total was 4.0. running mean: 9.905934877983949\n",
      "resetting env. episode reward total was 2.0. running mean: 9.82687552920411\n",
      "resetting env. episode reward total was 6.0. running mean: 9.788606773912068\n",
      "resetting env. episode reward total was 3.0. running mean: 9.720720706172948\n",
      "resetting env. episode reward total was 4.0. running mean: 9.663513499111218\n",
      "resetting env. episode reward total was 8.0. running mean: 9.646878364120106\n",
      "resetting env. episode reward total was 13.0. running mean: 9.680409580478905\n",
      "resetting env. episode reward total was 13.0. running mean: 9.713605484674117\n",
      "resetting env. episode reward total was 2.0. running mean: 9.636469429827375\n",
      "resetting env. episode reward total was -6.0. running mean: 9.480104735529101\n",
      "resetting env. episode reward total was 8.0. running mean: 9.46530368817381\n",
      "resetting env. episode reward total was 3.0. running mean: 9.400650651292072\n",
      "resetting env. episode reward total was 13.0. running mean: 9.436644144779152\n",
      "resetting env. episode reward total was 12.0. running mean: 9.46227770333136\n",
      "resetting env. episode reward total was 6.0. running mean: 9.427654926298047\n",
      "resetting env. episode reward total was -4.0. running mean: 9.293378377035067\n",
      "resetting env. episode reward total was 7.0. running mean: 9.270444593264717\n",
      "resetting env. episode reward total was 4.0. running mean: 9.21774014733207\n",
      "resetting env. episode reward total was 14.0. running mean: 9.265562745858748\n",
      "resetting env. episode reward total was 14.0. running mean: 9.312907118400162\n",
      "resetting env. episode reward total was 4.0. running mean: 9.259778047216159\n",
      "resetting env. episode reward total was 2.0. running mean: 9.187180266743997\n",
      "resetting env. episode reward total was 18.0. running mean: 9.275308464076558\n",
      "resetting env. episode reward total was 10.0. running mean: 9.282555379435792\n",
      "resetting env. episode reward total was 19.0. running mean: 9.379729825641434\n",
      "resetting env. episode reward total was 9.0. running mean: 9.37593252738502\n",
      "resetting env. episode reward total was 14.0. running mean: 9.42217320211117\n",
      "resetting env. episode reward total was 12.0. running mean: 9.447951470090057\n",
      "resetting env. episode reward total was 2.0. running mean: 9.373471955389157\n",
      "resetting env. episode reward total was 7.0. running mean: 9.349737235835265\n",
      "resetting env. episode reward total was 11.0. running mean: 9.366239863476912\n",
      "resetting env. episode reward total was -4.0. running mean: 9.232577464842143\n",
      "resetting env. episode reward total was 15.0. running mean: 9.290251690193722\n",
      "resetting env. episode reward total was 10.0. running mean: 9.297349173291785\n",
      "resetting env. episode reward total was 13.0. running mean: 9.334375681558868\n",
      "resetting env. episode reward total was 2.0. running mean: 9.261031924743278\n",
      "resetting env. episode reward total was 13.0. running mean: 9.298421605495847\n",
      "resetting env. episode reward total was 8.0. running mean: 9.285437389440888\n",
      "resetting env. episode reward total was 9.0. running mean: 9.282583015546479\n",
      "resetting env. episode reward total was 13.0. running mean: 9.319757185391014\n",
      "resetting env. episode reward total was 11.0. running mean: 9.336559613537103\n",
      "resetting env. episode reward total was -3.0. running mean: 9.213194017401733\n",
      "resetting env. episode reward total was 4.0. running mean: 9.161062077227715\n",
      "resetting env. episode reward total was -1.0. running mean: 9.059451456455438\n",
      "resetting env. episode reward total was 5.0. running mean: 9.018856941890885\n",
      "resetting env. episode reward total was 6.0. running mean: 8.988668372471976\n",
      "resetting env. episode reward total was -3.0. running mean: 8.868781688747257\n",
      "resetting env. episode reward total was 7.0. running mean: 8.850093871859784\n",
      "resetting env. episode reward total was 5.0. running mean: 8.811592933141187\n",
      "resetting env. episode reward total was 17.0. running mean: 8.893477003809775\n",
      "resetting env. episode reward total was 13.0. running mean: 8.934542233771678\n",
      "resetting env. episode reward total was 15.0. running mean: 8.995196811433962\n",
      "resetting env. episode reward total was 5.0. running mean: 8.955244843319623\n",
      "resetting env. episode reward total was 12.0. running mean: 8.985692394886426\n",
      "resetting env. episode reward total was 11.0. running mean: 9.00583547093756\n",
      "resetting env. episode reward total was 6.0. running mean: 8.975777116228185\n",
      "resetting env. episode reward total was 9.0. running mean: 8.976019345065904\n",
      "resetting env. episode reward total was 7.0. running mean: 8.956259151615244\n",
      "resetting env. episode reward total was 13.0. running mean: 8.996696560099092\n",
      "resetting env. episode reward total was 8.0. running mean: 8.986729594498101\n",
      "resetting env. episode reward total was 12.0. running mean: 9.01686229855312\n",
      "resetting env. episode reward total was 10.0. running mean: 9.026693675567588\n",
      "resetting env. episode reward total was 10.0. running mean: 9.036426738811912\n",
      "resetting env. episode reward total was 12.0. running mean: 9.066062471423791\n",
      "resetting env. episode reward total was 10.0. running mean: 9.075401846709553\n",
      "resetting env. episode reward total was 18.0. running mean: 9.164647828242458\n",
      "resetting env. episode reward total was 13.0. running mean: 9.203001349960035\n",
      "resetting env. episode reward total was 13.0. running mean: 9.240971336460435\n",
      "resetting env. episode reward total was 10.0. running mean: 9.24856162309583\n",
      "resetting env. episode reward total was -2.0. running mean: 9.136076006864872\n",
      "resetting env. episode reward total was 14.0. running mean: 9.184715246796223\n",
      "resetting env. episode reward total was 6.0. running mean: 9.15286809432826\n",
      "resetting env. episode reward total was 10.0. running mean: 9.161339413384978\n",
      "resetting env. episode reward total was 17.0. running mean: 9.239726019251128\n",
      "resetting env. episode reward total was 3.0. running mean: 9.177328759058616\n",
      "resetting env. episode reward total was 10.0. running mean: 9.18555547146803\n",
      "resetting env. episode reward total was 10.0. running mean: 9.19369991675335\n",
      "resetting env. episode reward total was 10.0. running mean: 9.201762917585816\n",
      "resetting env. episode reward total was 12.0. running mean: 9.229745288409957\n",
      "resetting env. episode reward total was 14.0. running mean: 9.277447835525857\n",
      "resetting env. episode reward total was 8.0. running mean: 9.264673357170599\n",
      "resetting env. episode reward total was 9.0. running mean: 9.262026623598892\n",
      "resetting env. episode reward total was 13.0. running mean: 9.299406357362903\n",
      "resetting env. episode reward total was 13.0. running mean: 9.336412293789275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 9.383048170851383\n",
      "resetting env. episode reward total was -9.0. running mean: 9.19921768914287\n",
      "resetting env. episode reward total was 8.0. running mean: 9.187225512251441\n",
      "resetting env. episode reward total was 2.0. running mean: 9.115353257128927\n",
      "resetting env. episode reward total was 12.0. running mean: 9.144199724557637\n",
      "resetting env. episode reward total was 8.0. running mean: 9.132757727312061\n",
      "resetting env. episode reward total was 14.0. running mean: 9.18143015003894\n",
      "resetting env. episode reward total was 15.0. running mean: 9.23961584853855\n",
      "resetting env. episode reward total was 13.0. running mean: 9.277219690053165\n",
      "resetting env. episode reward total was 10.0. running mean: 9.284447493152634\n",
      "resetting env. episode reward total was 16.0. running mean: 9.351603018221107\n",
      "resetting env. episode reward total was 5.0. running mean: 9.308086988038896\n",
      "resetting env. episode reward total was 10.0. running mean: 9.315006118158507\n",
      "resetting env. episode reward total was 3.0. running mean: 9.251856056976921\n",
      "resetting env. episode reward total was 11.0. running mean: 9.269337496407152\n",
      "resetting env. episode reward total was 9.0. running mean: 9.26664412144308\n",
      "resetting env. episode reward total was -2.0. running mean: 9.15397768022865\n",
      "resetting env. episode reward total was 14.0. running mean: 9.202437903426363\n",
      "resetting env. episode reward total was 1.0. running mean: 9.120413524392099\n",
      "resetting env. episode reward total was 9.0. running mean: 9.119209389148178\n",
      "resetting env. episode reward total was 16.0. running mean: 9.188017295256696\n",
      "resetting env. episode reward total was 7.0. running mean: 9.166137122304129\n",
      "resetting env. episode reward total was 7.0. running mean: 9.144475751081087\n",
      "resetting env. episode reward total was 15.0. running mean: 9.203030993570277\n",
      "resetting env. episode reward total was 8.0. running mean: 9.191000683634574\n",
      "resetting env. episode reward total was 6.0. running mean: 9.159090676798229\n",
      "resetting env. episode reward total was 16.0. running mean: 9.227499770030247\n",
      "resetting env. episode reward total was 12.0. running mean: 9.255224772329944\n",
      "resetting env. episode reward total was 10.0. running mean: 9.262672524606645\n",
      "resetting env. episode reward total was 14.0. running mean: 9.310045799360578\n",
      "resetting env. episode reward total was 6.0. running mean: 9.276945341366973\n",
      "resetting env. episode reward total was 2.0. running mean: 9.204175887953303\n",
      "resetting env. episode reward total was 3.0. running mean: 9.142134129073769\n",
      "resetting env. episode reward total was 4.0. running mean: 9.09071278778303\n",
      "resetting env. episode reward total was 7.0. running mean: 9.0698056599052\n",
      "resetting env. episode reward total was 8.0. running mean: 9.059107603306147\n",
      "resetting env. episode reward total was 13.0. running mean: 9.098516527273086\n",
      "resetting env. episode reward total was 11.0. running mean: 9.117531362000355\n",
      "resetting env. episode reward total was 14.0. running mean: 9.16635604838035\n",
      "resetting env. episode reward total was 13.0. running mean: 9.204692487896548\n",
      "resetting env. episode reward total was 12.0. running mean: 9.23264556301758\n",
      "resetting env. episode reward total was 9.0. running mean: 9.230319107387405\n",
      "resetting env. episode reward total was 4.0. running mean: 9.17801591631353\n",
      "resetting env. episode reward total was 4.0. running mean: 9.126235757150393\n",
      "resetting env. episode reward total was 13.0. running mean: 9.16497339957889\n",
      "resetting env. episode reward total was 12.0. running mean: 9.193323665583101\n",
      "resetting env. episode reward total was 10.0. running mean: 9.201390428927269\n",
      "resetting env. episode reward total was 10.0. running mean: 9.209376524637996\n",
      "resetting env. episode reward total was 13.0. running mean: 9.247282759391616\n",
      "resetting env. episode reward total was 11.0. running mean: 9.2648099317977\n",
      "resetting env. episode reward total was 13.0. running mean: 9.302161832479724\n",
      "resetting env. episode reward total was 1.0. running mean: 9.219140214154926\n",
      "resetting env. episode reward total was 15.0. running mean: 9.276948812013377\n",
      "resetting env. episode reward total was 12.0. running mean: 9.304179323893242\n",
      "resetting env. episode reward total was 10.0. running mean: 9.31113753065431\n",
      "resetting env. episode reward total was 13.0. running mean: 9.348026155347767\n",
      "resetting env. episode reward total was 2.0. running mean: 9.27454589379429\n",
      "resetting env. episode reward total was 11.0. running mean: 9.291800434856347\n",
      "resetting env. episode reward total was 10.0. running mean: 9.298882430507783\n",
      "resetting env. episode reward total was 13.0. running mean: 9.335893606202706\n",
      "resetting env. episode reward total was 13.0. running mean: 9.37253467014068\n",
      "resetting env. episode reward total was 5.0. running mean: 9.328809323439275\n",
      "resetting env. episode reward total was 8.0. running mean: 9.315521230204883\n",
      "resetting env. episode reward total was 3.0. running mean: 9.252366017902833\n",
      "resetting env. episode reward total was 13.0. running mean: 9.289842357723806\n",
      "resetting env. episode reward total was 16.0. running mean: 9.356943934146567\n",
      "resetting env. episode reward total was 11.0. running mean: 9.373374494805102\n",
      "resetting env. episode reward total was 8.0. running mean: 9.35964074985705\n",
      "resetting env. episode reward total was 11.0. running mean: 9.37604434235848\n",
      "resetting env. episode reward total was 14.0. running mean: 9.422283898934895\n",
      "resetting env. episode reward total was 10.0. running mean: 9.428061059945545\n",
      "resetting env. episode reward total was 15.0. running mean: 9.48378044934609\n",
      "resetting env. episode reward total was 13.0. running mean: 9.51894264485263\n",
      "resetting env. episode reward total was 13.0. running mean: 9.553753218404106\n",
      "resetting env. episode reward total was 10.0. running mean: 9.558215686220064\n",
      "resetting env. episode reward total was 9.0. running mean: 9.552633529357864\n",
      "resetting env. episode reward total was 15.0. running mean: 9.607107194064286\n",
      "resetting env. episode reward total was 6.0. running mean: 9.571036122123644\n",
      "resetting env. episode reward total was 11.0. running mean: 9.585325760902407\n",
      "resetting env. episode reward total was 4.0. running mean: 9.529472503293382\n",
      "resetting env. episode reward total was 7.0. running mean: 9.504177778260448\n",
      "resetting env. episode reward total was 10.0. running mean: 9.509136000477843\n",
      "resetting env. episode reward total was 6.0. running mean: 9.474044640473066\n",
      "resetting env. episode reward total was 11.0. running mean: 9.489304194068335\n",
      "resetting env. episode reward total was 14.0. running mean: 9.534411152127653\n",
      "resetting env. episode reward total was 8.0. running mean: 9.519067040606377\n",
      "resetting env. episode reward total was 14.0. running mean: 9.563876370200314\n",
      "resetting env. episode reward total was 13.0. running mean: 9.59823760649831\n",
      "resetting env. episode reward total was 10.0. running mean: 9.602255230433327\n",
      "resetting env. episode reward total was 11.0. running mean: 9.616232678128993\n",
      "resetting env. episode reward total was 12.0. running mean: 9.640070351347703\n",
      "resetting env. episode reward total was 15.0. running mean: 9.693669647834225\n",
      "resetting env. episode reward total was 13.0. running mean: 9.726732951355883\n",
      "resetting env. episode reward total was 5.0. running mean: 9.679465621842326\n",
      "resetting env. episode reward total was 10.0. running mean: 9.682670965623903\n",
      "resetting env. episode reward total was 11.0. running mean: 9.695844255967662\n",
      "resetting env. episode reward total was 18.0. running mean: 9.778885813407985\n",
      "resetting env. episode reward total was 9.0. running mean: 9.771096955273904\n",
      "resetting env. episode reward total was 11.0. running mean: 9.783385985721164\n",
      "resetting env. episode reward total was 9.0. running mean: 9.775552125863952\n",
      "resetting env. episode reward total was 10.0. running mean: 9.777796604605312\n",
      "resetting env. episode reward total was 12.0. running mean: 9.800018638559258\n",
      "resetting env. episode reward total was 9.0. running mean: 9.792018452173666\n",
      "resetting env. episode reward total was 12.0. running mean: 9.814098267651929\n",
      "resetting env. episode reward total was 18.0. running mean: 9.89595728497541\n",
      "resetting env. episode reward total was 7.0. running mean: 9.866997712125656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 9.8783277350044\n",
      "resetting env. episode reward total was 6.0. running mean: 9.839544457654355\n",
      "resetting env. episode reward total was 9.0. running mean: 9.83114901307781\n",
      "resetting env. episode reward total was 8.0. running mean: 9.812837522947033\n",
      "resetting env. episode reward total was 12.0. running mean: 9.834709147717563\n",
      "resetting env. episode reward total was 13.0. running mean: 9.866362056240387\n",
      "resetting env. episode reward total was -7.0. running mean: 9.697698435677983\n",
      "resetting env. episode reward total was 18.0. running mean: 9.780721451321202\n",
      "resetting env. episode reward total was 6.0. running mean: 9.74291423680799\n",
      "resetting env. episode reward total was 10.0. running mean: 9.74548509443991\n",
      "resetting env. episode reward total was 9.0. running mean: 9.738030243495512\n",
      "resetting env. episode reward total was 12.0. running mean: 9.760649941060557\n",
      "resetting env. episode reward total was 12.0. running mean: 9.78304344164995\n",
      "resetting env. episode reward total was 20.0. running mean: 9.88521300723345\n",
      "resetting env. episode reward total was 4.0. running mean: 9.826360877161115\n",
      "resetting env. episode reward total was 8.0. running mean: 9.808097268389503\n",
      "resetting env. episode reward total was 10.0. running mean: 9.810016295705607\n",
      "resetting env. episode reward total was 6.0. running mean: 9.77191613274855\n",
      "resetting env. episode reward total was 7.0. running mean: 9.744196971421065\n",
      "resetting env. episode reward total was 4.0. running mean: 9.686755001706853\n",
      "resetting env. episode reward total was 5.0. running mean: 9.639887451689786\n",
      "resetting env. episode reward total was 5.0. running mean: 9.593488577172888\n",
      "resetting env. episode reward total was 12.0. running mean: 9.617553691401158\n",
      "resetting env. episode reward total was 8.0. running mean: 9.601378154487145\n",
      "resetting env. episode reward total was 12.0. running mean: 9.625364372942274\n",
      "resetting env. episode reward total was 15.0. running mean: 9.679110729212852\n",
      "resetting env. episode reward total was 14.0. running mean: 9.722319621920724\n",
      "resetting env. episode reward total was 15.0. running mean: 9.775096425701516\n",
      "resetting env. episode reward total was 5.0. running mean: 9.727345461444502\n",
      "resetting env. episode reward total was 5.0. running mean: 9.680072006830057\n",
      "resetting env. episode reward total was 5.0. running mean: 9.633271286761758\n",
      "resetting env. episode reward total was 18.0. running mean: 9.71693857389414\n",
      "resetting env. episode reward total was 2.0. running mean: 9.639769188155197\n",
      "resetting env. episode reward total was 2.0. running mean: 9.563371496273644\n",
      "resetting env. episode reward total was 8.0. running mean: 9.547737781310907\n",
      "resetting env. episode reward total was 12.0. running mean: 9.572260403497797\n",
      "resetting env. episode reward total was 12.0. running mean: 9.596537799462817\n",
      "resetting env. episode reward total was 14.0. running mean: 9.640572421468189\n",
      "resetting env. episode reward total was 11.0. running mean: 9.654166697253507\n",
      "resetting env. episode reward total was 8.0. running mean: 9.637625030280972\n",
      "resetting env. episode reward total was 12.0. running mean: 9.661248779978163\n",
      "resetting env. episode reward total was 12.0. running mean: 9.68463629217838\n",
      "resetting env. episode reward total was 4.0. running mean: 9.627789929256595\n",
      "resetting env. episode reward total was 12.0. running mean: 9.651512029964028\n",
      "resetting env. episode reward total was 19.0. running mean: 9.744996909664387\n",
      "resetting env. episode reward total was 12.0. running mean: 9.767546940567742\n",
      "resetting env. episode reward total was 12.0. running mean: 9.789871471162064\n",
      "resetting env. episode reward total was 9.0. running mean: 9.781972756450443\n",
      "resetting env. episode reward total was 10.0. running mean: 9.784153028885939\n",
      "resetting env. episode reward total was 14.0. running mean: 9.82631149859708\n",
      "resetting env. episode reward total was 10.0. running mean: 9.82804838361111\n",
      "resetting env. episode reward total was 10.0. running mean: 9.829767899774998\n",
      "resetting env. episode reward total was 7.0. running mean: 9.801470220777249\n",
      "resetting env. episode reward total was 5.0. running mean: 9.753455518569478\n",
      "resetting env. episode reward total was 16.0. running mean: 9.815920963383784\n",
      "resetting env. episode reward total was 8.0. running mean: 9.797761753749946\n",
      "resetting env. episode reward total was 6.0. running mean: 9.759784136212447\n",
      "resetting env. episode reward total was -4.0. running mean: 9.622186294850323\n",
      "resetting env. episode reward total was 11.0. running mean: 9.635964431901819\n",
      "resetting env. episode reward total was 2.0. running mean: 9.5596047875828\n",
      "resetting env. episode reward total was 15.0. running mean: 9.614008739706971\n",
      "resetting env. episode reward total was 16.0. running mean: 9.677868652309902\n",
      "resetting env. episode reward total was 15.0. running mean: 9.731089965786804\n",
      "resetting env. episode reward total was 1.0. running mean: 9.643779066128936\n",
      "resetting env. episode reward total was 14.0. running mean: 9.687341275467647\n",
      "resetting env. episode reward total was 10.0. running mean: 9.69046786271297\n",
      "resetting env. episode reward total was 12.0. running mean: 9.713563184085839\n",
      "resetting env. episode reward total was 2.0. running mean: 9.63642755224498\n",
      "resetting env. episode reward total was 15.0. running mean: 9.69006327672253\n",
      "resetting env. episode reward total was 16.0. running mean: 9.753162643955305\n",
      "resetting env. episode reward total was 13.0. running mean: 9.785631017515753\n",
      "resetting env. episode reward total was 8.0. running mean: 9.767774707340596\n",
      "resetting env. episode reward total was 8.0. running mean: 9.75009696026719\n",
      "resetting env. episode reward total was 3.0. running mean: 9.682595990664517\n",
      "resetting env. episode reward total was 15.0. running mean: 9.735770030757871\n",
      "resetting env. episode reward total was 6.0. running mean: 9.698412330450292\n",
      "resetting env. episode reward total was 11.0. running mean: 9.711428207145788\n",
      "resetting env. episode reward total was 17.0. running mean: 9.784313925074331\n",
      "resetting env. episode reward total was 14.0. running mean: 9.826470785823588\n",
      "resetting env. episode reward total was 13.0. running mean: 9.858206077965352\n",
      "resetting env. episode reward total was 16.0. running mean: 9.919624017185699\n",
      "resetting env. episode reward total was 9.0. running mean: 9.910427777013842\n",
      "resetting env. episode reward total was 7.0. running mean: 9.881323499243704\n",
      "resetting env. episode reward total was 1.0. running mean: 9.792510264251266\n",
      "resetting env. episode reward total was 9.0. running mean: 9.784585161608753\n",
      "resetting env. episode reward total was 5.0. running mean: 9.736739309992666\n",
      "resetting env. episode reward total was 8.0. running mean: 9.71937191689274\n",
      "resetting env. episode reward total was 10.0. running mean: 9.722178197723812\n",
      "resetting env. episode reward total was 2.0. running mean: 9.644956415746574\n",
      "resetting env. episode reward total was 10.0. running mean: 9.648506851589108\n",
      "resetting env. episode reward total was 9.0. running mean: 9.642021783073217\n",
      "resetting env. episode reward total was 9.0. running mean: 9.635601565242485\n",
      "resetting env. episode reward total was 16.0. running mean: 9.69924554959006\n",
      "resetting env. episode reward total was 13.0. running mean: 9.73225309409416\n",
      "resetting env. episode reward total was 9.0. running mean: 9.724930563153219\n",
      "resetting env. episode reward total was 15.0. running mean: 9.777681257521687\n",
      "resetting env. episode reward total was -13.0. running mean: 9.549904444946469\n",
      "resetting env. episode reward total was 8.0. running mean: 9.534405400497004\n",
      "resetting env. episode reward total was 9.0. running mean: 9.529061346492034\n",
      "resetting env. episode reward total was 5.0. running mean: 9.483770733027114\n",
      "resetting env. episode reward total was 13.0. running mean: 9.518933025696844\n",
      "resetting env. episode reward total was 16.0. running mean: 9.583743695439876\n",
      "resetting env. episode reward total was 12.0. running mean: 9.607906258485476\n",
      "resetting env. episode reward total was 7.0. running mean: 9.581827195900622\n",
      "resetting env. episode reward total was 7.0. running mean: 9.556008923941617\n",
      "resetting env. episode reward total was 5.0. running mean: 9.510448834702201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 9.515344346355178\n",
      "resetting env. episode reward total was 13.0. running mean: 9.550190902891627\n",
      "resetting env. episode reward total was 11.0. running mean: 9.56468899386271\n",
      "resetting env. episode reward total was 14.0. running mean: 9.609042103924082\n",
      "resetting env. episode reward total was 7.0. running mean: 9.582951682884842\n",
      "resetting env. episode reward total was 7.0. running mean: 9.557122166055994\n",
      "resetting env. episode reward total was 8.0. running mean: 9.541550944395434\n",
      "resetting env. episode reward total was 10.0. running mean: 9.546135434951479\n",
      "resetting env. episode reward total was 8.0. running mean: 9.530674080601964\n",
      "resetting env. episode reward total was 15.0. running mean: 9.585367339795944\n",
      "resetting env. episode reward total was 6.0. running mean: 9.549513666397985\n",
      "resetting env. episode reward total was 14.0. running mean: 9.594018529734006\n",
      "resetting env. episode reward total was 3.0. running mean: 9.528078344436665\n",
      "resetting env. episode reward total was 10.0. running mean: 9.532797560992298\n",
      "resetting env. episode reward total was 16.0. running mean: 9.597469585382376\n",
      "resetting env. episode reward total was 11.0. running mean: 9.61149488952855\n",
      "resetting env. episode reward total was 15.0. running mean: 9.665379940633265\n",
      "resetting env. episode reward total was 9.0. running mean: 9.658726141226932\n",
      "resetting env. episode reward total was 8.0. running mean: 9.642138879814663\n",
      "resetting env. episode reward total was 12.0. running mean: 9.665717491016515\n",
      "resetting env. episode reward total was 6.0. running mean: 9.62906031610635\n",
      "resetting env. episode reward total was 11.0. running mean: 9.642769712945286\n",
      "resetting env. episode reward total was 7.0. running mean: 9.616342015815833\n",
      "resetting env. episode reward total was 10.0. running mean: 9.620178595657675\n",
      "resetting env. episode reward total was 3.0. running mean: 9.553976809701098\n",
      "resetting env. episode reward total was 13.0. running mean: 9.588437041604088\n",
      "resetting env. episode reward total was 2.0. running mean: 9.512552671188047\n",
      "resetting env. episode reward total was 14.0. running mean: 9.557427144476167\n",
      "resetting env. episode reward total was 7.0. running mean: 9.531852873031406\n",
      "resetting env. episode reward total was 13.0. running mean: 9.566534344301093\n",
      "resetting env. episode reward total was 13.0. running mean: 9.600869000858083\n",
      "resetting env. episode reward total was 7.0. running mean: 9.574860310849502\n",
      "resetting env. episode reward total was 2.0. running mean: 9.499111707741006\n",
      "resetting env. episode reward total was 15.0. running mean: 9.554120590663597\n",
      "resetting env. episode reward total was 17.0. running mean: 9.62857938475696\n",
      "resetting env. episode reward total was 14.0. running mean: 9.672293590909392\n",
      "resetting env. episode reward total was 20.0. running mean: 9.775570655000298\n",
      "resetting env. episode reward total was 13.0. running mean: 9.807814948450295\n",
      "resetting env. episode reward total was 16.0. running mean: 9.869736798965793\n",
      "resetting env. episode reward total was 15.0. running mean: 9.921039430976135\n",
      "resetting env. episode reward total was 7.0. running mean: 9.891829036666374\n",
      "resetting env. episode reward total was 12.0. running mean: 9.91291074629971\n",
      "resetting env. episode reward total was 15.0. running mean: 9.963781638836714\n",
      "resetting env. episode reward total was 8.0. running mean: 9.944143822448346\n",
      "resetting env. episode reward total was 11.0. running mean: 9.954702384223863\n",
      "resetting env. episode reward total was 11.0. running mean: 9.965155360381623\n",
      "resetting env. episode reward total was 9.0. running mean: 9.955503806777806\n",
      "resetting env. episode reward total was 5.0. running mean: 9.905948768710028\n",
      "resetting env. episode reward total was 12.0. running mean: 9.926889281022927\n",
      "resetting env. episode reward total was 9.0. running mean: 9.917620388212697\n",
      "resetting env. episode reward total was 12.0. running mean: 9.938444184330569\n",
      "resetting env. episode reward total was 15.0. running mean: 9.989059742487264\n",
      "resetting env. episode reward total was 14.0. running mean: 10.029169145062392\n",
      "resetting env. episode reward total was 7.0. running mean: 9.998877453611769\n",
      "resetting env. episode reward total was 12.0. running mean: 10.01888867907565\n",
      "resetting env. episode reward total was 13.0. running mean: 10.048699792284893\n",
      "resetting env. episode reward total was 16.0. running mean: 10.108212794362045\n",
      "resetting env. episode reward total was 10.0. running mean: 10.107130666418424\n",
      "resetting env. episode reward total was 9.0. running mean: 10.09605935975424\n",
      "resetting env. episode reward total was 9.0. running mean: 10.085098766156696\n",
      "resetting env. episode reward total was 7.0. running mean: 10.05424777849513\n",
      "resetting env. episode reward total was 13.0. running mean: 10.083705300710179\n",
      "resetting env. episode reward total was 13.0. running mean: 10.112868247703078\n",
      "resetting env. episode reward total was -2.0. running mean: 9.991739565226048\n",
      "resetting env. episode reward total was 9.0. running mean: 9.981822169573787\n",
      "resetting env. episode reward total was 12.0. running mean: 10.002003947878048\n",
      "resetting env. episode reward total was 13.0. running mean: 10.031983908399269\n",
      "resetting env. episode reward total was 15.0. running mean: 10.081664069315277\n",
      "resetting env. episode reward total was 7.0. running mean: 10.050847428622124\n",
      "resetting env. episode reward total was 12.0. running mean: 10.070338954335902\n",
      "resetting env. episode reward total was 8.0. running mean: 10.049635564792544\n",
      "resetting env. episode reward total was 7.0. running mean: 10.019139209144619\n",
      "resetting env. episode reward total was 13.0. running mean: 10.048947817053174\n",
      "resetting env. episode reward total was 13.0. running mean: 10.078458338882642\n",
      "resetting env. episode reward total was 5.0. running mean: 10.027673755493817\n",
      "resetting env. episode reward total was 14.0. running mean: 10.067397017938879\n",
      "resetting env. episode reward total was 13.0. running mean: 10.09672304775949\n",
      "resetting env. episode reward total was 7.0. running mean: 10.065755817281895\n",
      "resetting env. episode reward total was 17.0. running mean: 10.135098259109077\n",
      "resetting env. episode reward total was 15.0. running mean: 10.183747276517986\n",
      "resetting env. episode reward total was -1.0. running mean: 10.071909803752806\n",
      "resetting env. episode reward total was 4.0. running mean: 10.011190705715277\n",
      "resetting env. episode reward total was 9.0. running mean: 10.001078798658124\n",
      "resetting env. episode reward total was 2.0. running mean: 9.921068010671542\n",
      "resetting env. episode reward total was 11.0. running mean: 9.931857330564826\n",
      "resetting env. episode reward total was 4.0. running mean: 9.872538757259177\n",
      "resetting env. episode reward total was 13.0. running mean: 9.903813369686585\n",
      "resetting env. episode reward total was 14.0. running mean: 9.94477523598972\n",
      "resetting env. episode reward total was 11.0. running mean: 9.955327483629823\n",
      "resetting env. episode reward total was 1.0. running mean: 9.865774208793525\n",
      "resetting env. episode reward total was 3.0. running mean: 9.797116466705589\n",
      "resetting env. episode reward total was 8.0. running mean: 9.779145302038533\n",
      "resetting env. episode reward total was 13.0. running mean: 9.811353849018149\n",
      "resetting env. episode reward total was 4.0. running mean: 9.753240310527966\n",
      "resetting env. episode reward total was 12.0. running mean: 9.775707907422685\n",
      "resetting env. episode reward total was 15.0. running mean: 9.827950828348458\n",
      "resetting env. episode reward total was -1.0. running mean: 9.719671320064974\n",
      "resetting env. episode reward total was 14.0. running mean: 9.762474606864325\n",
      "resetting env. episode reward total was 13.0. running mean: 9.794849860795683\n",
      "resetting env. episode reward total was 12.0. running mean: 9.816901362187725\n",
      "resetting env. episode reward total was 12.0. running mean: 9.838732348565847\n",
      "resetting env. episode reward total was 13.0. running mean: 9.870345025080189\n",
      "resetting env. episode reward total was 13.0. running mean: 9.901641574829387\n",
      "resetting env. episode reward total was 8.0. running mean: 9.882625159081094\n",
      "resetting env. episode reward total was 14.0. running mean: 9.923798907490283\n",
      "resetting env. episode reward total was 4.0. running mean: 9.86456091841538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 9.865915309231227\n",
      "resetting env. episode reward total was 9.0. running mean: 9.857256156138915\n",
      "resetting env. episode reward total was 12.0. running mean: 9.878683594577526\n",
      "resetting env. episode reward total was 7.0. running mean: 9.84989675863175\n",
      "resetting env. episode reward total was 17.0. running mean: 9.921397791045433\n",
      "resetting env. episode reward total was 11.0. running mean: 9.932183813134978\n",
      "resetting env. episode reward total was 12.0. running mean: 9.952861975003628\n",
      "resetting env. episode reward total was 10.0. running mean: 9.953333355253593\n",
      "resetting env. episode reward total was 11.0. running mean: 9.963800021701056\n",
      "resetting env. episode reward total was 15.0. running mean: 10.014162021484045\n",
      "resetting env. episode reward total was 3.0. running mean: 9.944020401269205\n",
      "resetting env. episode reward total was 8.0. running mean: 9.924580197256512\n",
      "resetting env. episode reward total was 8.0. running mean: 9.905334395283948\n",
      "resetting env. episode reward total was 7.0. running mean: 9.876281051331109\n",
      "resetting env. episode reward total was 5.0. running mean: 9.827518240817799\n",
      "resetting env. episode reward total was 10.0. running mean: 9.82924305840962\n",
      "resetting env. episode reward total was 12.0. running mean: 9.850950627825522\n",
      "resetting env. episode reward total was 12.0. running mean: 9.872441121547267\n",
      "resetting env. episode reward total was 8.0. running mean: 9.853716710331794\n",
      "resetting env. episode reward total was 13.0. running mean: 9.885179543228476\n",
      "resetting env. episode reward total was 7.0. running mean: 9.856327747796191\n",
      "resetting env. episode reward total was 17.0. running mean: 9.927764470318229\n",
      "resetting env. episode reward total was 7.0. running mean: 9.898486825615047\n",
      "resetting env. episode reward total was 17.0. running mean: 9.969501957358895\n",
      "resetting env. episode reward total was 5.0. running mean: 9.919806937785307\n",
      "resetting env. episode reward total was 6.0. running mean: 9.880608868407453\n",
      "resetting env. episode reward total was 9.0. running mean: 9.871802779723378\n",
      "resetting env. episode reward total was 8.0. running mean: 9.853084751926144\n",
      "resetting env. episode reward total was 10.0. running mean: 9.854553904406881\n",
      "resetting env. episode reward total was 17.0. running mean: 9.926008365362812\n",
      "resetting env. episode reward total was 5.0. running mean: 9.876748281709183\n",
      "resetting env. episode reward total was 11.0. running mean: 9.887980798892091\n",
      "resetting env. episode reward total was 12.0. running mean: 9.90910099090317\n",
      "resetting env. episode reward total was -1.0. running mean: 9.800009980994139\n",
      "resetting env. episode reward total was 16.0. running mean: 9.862009881184198\n",
      "resetting env. episode reward total was 11.0. running mean: 9.873389782372355\n",
      "resetting env. episode reward total was 11.0. running mean: 9.88465588454863\n",
      "resetting env. episode reward total was 9.0. running mean: 9.875809325703143\n",
      "resetting env. episode reward total was 10.0. running mean: 9.877051232446112\n",
      "resetting env. episode reward total was 7.0. running mean: 9.84828072012165\n",
      "resetting env. episode reward total was 14.0. running mean: 9.889797912920434\n",
      "resetting env. episode reward total was 13.0. running mean: 9.92089993379123\n",
      "resetting env. episode reward total was 16.0. running mean: 9.981690934453317\n",
      "resetting env. episode reward total was 17.0. running mean: 10.051874025108784\n",
      "resetting env. episode reward total was 3.0. running mean: 9.981355284857695\n",
      "resetting env. episode reward total was 6.0. running mean: 9.941541732009119\n",
      "resetting env. episode reward total was 9.0. running mean: 9.932126314689027\n",
      "resetting env. episode reward total was 9.0. running mean: 9.922805051542136\n",
      "resetting env. episode reward total was 15.0. running mean: 9.973577001026715\n",
      "resetting env. episode reward total was 11.0. running mean: 9.983841231016447\n",
      "resetting env. episode reward total was 9.0. running mean: 9.974002818706282\n",
      "resetting env. episode reward total was 15.0. running mean: 10.02426279051922\n",
      "resetting env. episode reward total was 14.0. running mean: 10.064020162614028\n",
      "resetting env. episode reward total was 5.0. running mean: 10.013379960987889\n",
      "resetting env. episode reward total was 6.0. running mean: 9.973246161378011\n",
      "resetting env. episode reward total was 13.0. running mean: 10.003513699764232\n",
      "resetting env. episode reward total was 8.0. running mean: 9.98347856276659\n",
      "resetting env. episode reward total was 11.0. running mean: 9.993643777138924\n",
      "resetting env. episode reward total was 8.0. running mean: 9.973707339367536\n",
      "resetting env. episode reward total was 11.0. running mean: 9.98397026597386\n",
      "resetting env. episode reward total was 3.0. running mean: 9.914130563314119\n",
      "resetting env. episode reward total was 4.0. running mean: 9.854989257680977\n",
      "resetting env. episode reward total was 8.0. running mean: 9.836439365104168\n",
      "resetting env. episode reward total was -1.0. running mean: 9.728074971453125\n",
      "resetting env. episode reward total was 10.0. running mean: 9.730794221738593\n",
      "resetting env. episode reward total was 7.0. running mean: 9.703486279521208\n",
      "resetting env. episode reward total was 13.0. running mean: 9.736451416725997\n",
      "resetting env. episode reward total was 10.0. running mean: 9.739086902558736\n",
      "resetting env. episode reward total was 6.0. running mean: 9.701696033533148\n",
      "resetting env. episode reward total was 1.0. running mean: 9.614679073197816\n",
      "resetting env. episode reward total was 9.0. running mean: 9.608532282465838\n",
      "resetting env. episode reward total was 14.0. running mean: 9.65244695964118\n",
      "resetting env. episode reward total was 10.0. running mean: 9.655922490044768\n",
      "resetting env. episode reward total was 6.0. running mean: 9.61936326514432\n",
      "resetting env. episode reward total was 12.0. running mean: 9.643169632492876\n",
      "resetting env. episode reward total was 14.0. running mean: 9.686737936167948\n",
      "resetting env. episode reward total was 9.0. running mean: 9.679870556806268\n",
      "resetting env. episode reward total was 10.0. running mean: 9.683071851238205\n",
      "resetting env. episode reward total was 5.0. running mean: 9.636241132725823\n",
      "resetting env. episode reward total was 7.0. running mean: 9.609878721398566\n",
      "resetting env. episode reward total was 9.0. running mean: 9.60377993418458\n",
      "resetting env. episode reward total was 16.0. running mean: 9.667742134842735\n",
      "resetting env. episode reward total was 9.0. running mean: 9.661064713494307\n",
      "resetting env. episode reward total was -9.0. running mean: 9.474454066359364\n",
      "resetting env. episode reward total was 15.0. running mean: 9.52970952569577\n",
      "resetting env. episode reward total was 3.0. running mean: 9.464412430438811\n",
      "resetting env. episode reward total was 9.0. running mean: 9.459768306134423\n",
      "resetting env. episode reward total was 16.0. running mean: 9.525170623073079\n",
      "resetting env. episode reward total was 13.0. running mean: 9.55991891684235\n",
      "resetting env. episode reward total was 5.0. running mean: 9.514319727673927\n",
      "resetting env. episode reward total was 14.0. running mean: 9.559176530397188\n",
      "resetting env. episode reward total was 11.0. running mean: 9.573584765093216\n",
      "resetting env. episode reward total was 12.0. running mean: 9.597848917442283\n",
      "resetting env. episode reward total was 2.0. running mean: 9.52187042826786\n",
      "resetting env. episode reward total was 8.0. running mean: 9.50665172398518\n",
      "resetting env. episode reward total was 4.0. running mean: 9.451585206745328\n",
      "resetting env. episode reward total was 10.0. running mean: 9.457069354677875\n",
      "resetting env. episode reward total was 8.0. running mean: 9.442498661131097\n",
      "resetting env. episode reward total was 9.0. running mean: 9.438073674519785\n",
      "resetting env. episode reward total was 15.0. running mean: 9.493692937774588\n",
      "resetting env. episode reward total was 7.0. running mean: 9.468756008396843\n",
      "resetting env. episode reward total was 13.0. running mean: 9.504068448312875\n",
      "resetting env. episode reward total was 3.0. running mean: 9.439027763829746\n",
      "resetting env. episode reward total was 3.0. running mean: 9.374637486191448\n",
      "resetting env. episode reward total was 6.0. running mean: 9.340891111329533\n",
      "resetting env. episode reward total was 6.0. running mean: 9.307482200216239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 9.314407378214076\n",
      "resetting env. episode reward total was 17.0. running mean: 9.391263304431936\n",
      "resetting env. episode reward total was 16.0. running mean: 9.457350671387617\n",
      "resetting env. episode reward total was 4.0. running mean: 9.40277716467374\n",
      "resetting env. episode reward total was 4.0. running mean: 9.348749393027001\n",
      "resetting env. episode reward total was 5.0. running mean: 9.305261899096731\n",
      "resetting env. episode reward total was 16.0. running mean: 9.372209280105764\n",
      "resetting env. episode reward total was 6.0. running mean: 9.338487187304708\n",
      "resetting env. episode reward total was 18.0. running mean: 9.42510231543166\n",
      "resetting env. episode reward total was 10.0. running mean: 9.430851292277342\n",
      "resetting env. episode reward total was 7.0. running mean: 9.406542779354568\n",
      "resetting env. episode reward total was 4.0. running mean: 9.352477351561022\n",
      "resetting env. episode reward total was 10.0. running mean: 9.358952578045411\n",
      "resetting env. episode reward total was 10.0. running mean: 9.365363052264957\n",
      "resetting env. episode reward total was 6.0. running mean: 9.331709421742309\n",
      "resetting env. episode reward total was 17.0. running mean: 9.408392327524885\n",
      "resetting env. episode reward total was 11.0. running mean: 9.424308404249635\n",
      "resetting env. episode reward total was 14.0. running mean: 9.470065320207139\n",
      "resetting env. episode reward total was 12.0. running mean: 9.495364667005067\n",
      "resetting env. episode reward total was 3.0. running mean: 9.430411020335015\n",
      "resetting env. episode reward total was 10.0. running mean: 9.436106910131665\n",
      "resetting env. episode reward total was 3.0. running mean: 9.371745841030348\n",
      "resetting env. episode reward total was 9.0. running mean: 9.368028382620045\n",
      "resetting env. episode reward total was 11.0. running mean: 9.384348098793843\n",
      "resetting env. episode reward total was 12.0. running mean: 9.410504617805904\n",
      "resetting env. episode reward total was -7.0. running mean: 9.246399571627844\n",
      "resetting env. episode reward total was 8.0. running mean: 9.233935575911566\n",
      "resetting env. episode reward total was 8.0. running mean: 9.22159622015245\n",
      "resetting env. episode reward total was 13.0. running mean: 9.259380257950927\n",
      "resetting env. episode reward total was 11.0. running mean: 9.276786455371417\n",
      "resetting env. episode reward total was 3.0. running mean: 9.214018590817702\n",
      "resetting env. episode reward total was 2.0. running mean: 9.141878404909525\n",
      "resetting env. episode reward total was 10.0. running mean: 9.15045962086043\n",
      "resetting env. episode reward total was 8.0. running mean: 9.138955024651825\n",
      "resetting env. episode reward total was -5.0. running mean: 8.997565474405306\n",
      "resetting env. episode reward total was 12.0. running mean: 9.027589819661252\n",
      "resetting env. episode reward total was 5.0. running mean: 8.98731392146464\n",
      "resetting env. episode reward total was 8.0. running mean: 8.977440782249994\n",
      "resetting env. episode reward total was 5.0. running mean: 8.937666374427495\n",
      "resetting env. episode reward total was 12.0. running mean: 8.96828971068322\n",
      "resetting env. episode reward total was 10.0. running mean: 8.978606813576386\n",
      "resetting env. episode reward total was 9.0. running mean: 8.978820745440622\n",
      "resetting env. episode reward total was 10.0. running mean: 8.989032537986215\n",
      "resetting env. episode reward total was 13.0. running mean: 9.029142212606354\n",
      "resetting env. episode reward total was 11.0. running mean: 9.048850790480289\n",
      "resetting env. episode reward total was 6.0. running mean: 9.018362282575486\n",
      "resetting env. episode reward total was 8.0. running mean: 9.008178659749731\n",
      "resetting env. episode reward total was 3.0. running mean: 8.948096873152233\n",
      "resetting env. episode reward total was 10.0. running mean: 8.95861590442071\n",
      "resetting env. episode reward total was 13.0. running mean: 8.999029745376504\n",
      "resetting env. episode reward total was 6.0. running mean: 8.96903944792274\n",
      "resetting env. episode reward total was -3.0. running mean: 8.849349053443513\n",
      "resetting env. episode reward total was 15.0. running mean: 8.910855562909077\n",
      "resetting env. episode reward total was 5.0. running mean: 8.871747007279987\n",
      "resetting env. episode reward total was 12.0. running mean: 8.903029537207187\n",
      "resetting env. episode reward total was 5.0. running mean: 8.863999241835115\n",
      "resetting env. episode reward total was 11.0. running mean: 8.885359249416764\n",
      "resetting env. episode reward total was 12.0. running mean: 8.916505656922595\n",
      "resetting env. episode reward total was 7.0. running mean: 8.89734060035337\n",
      "resetting env. episode reward total was 9.0. running mean: 8.898367194349836\n",
      "resetting env. episode reward total was 7.0. running mean: 8.879383522406338\n",
      "resetting env. episode reward total was 4.0. running mean: 8.830589687182274\n",
      "resetting env. episode reward total was 11.0. running mean: 8.85228379031045\n",
      "resetting env. episode reward total was 9.0. running mean: 8.853760952407345\n",
      "resetting env. episode reward total was 9.0. running mean: 8.85522334288327\n",
      "resetting env. episode reward total was 4.0. running mean: 8.806671109454436\n",
      "resetting env. episode reward total was 11.0. running mean: 8.828604398359891\n",
      "resetting env. episode reward total was 5.0. running mean: 8.790318354376293\n",
      "resetting env. episode reward total was 12.0. running mean: 8.82241517083253\n",
      "resetting env. episode reward total was 10.0. running mean: 8.834191019124203\n",
      "resetting env. episode reward total was 9.0. running mean: 8.835849108932962\n",
      "resetting env. episode reward total was 7.0. running mean: 8.817490617843632\n",
      "resetting env. episode reward total was 10.0. running mean: 8.829315711665195\n",
      "resetting env. episode reward total was 12.0. running mean: 8.861022554548542\n",
      "resetting env. episode reward total was 13.0. running mean: 8.902412329003058\n",
      "resetting env. episode reward total was 8.0. running mean: 8.893388205713027\n",
      "resetting env. episode reward total was 12.0. running mean: 8.924454323655896\n",
      "resetting env. episode reward total was 9.0. running mean: 8.925209780419337\n",
      "resetting env. episode reward total was 11.0. running mean: 8.945957682615143\n",
      "resetting env. episode reward total was 4.0. running mean: 8.896498105788991\n",
      "resetting env. episode reward total was 17.0. running mean: 8.977533124731101\n",
      "resetting env. episode reward total was 4.0. running mean: 8.927757793483789\n",
      "resetting env. episode reward total was 15.0. running mean: 8.98848021554895\n",
      "resetting env. episode reward total was 2.0. running mean: 8.91859541339346\n",
      "resetting env. episode reward total was 11.0. running mean: 8.939409459259524\n",
      "resetting env. episode reward total was 10.0. running mean: 8.950015364666928\n",
      "resetting env. episode reward total was 7.0. running mean: 8.930515211020259\n",
      "resetting env. episode reward total was 9.0. running mean: 8.931210058910056\n",
      "resetting env. episode reward total was 13.0. running mean: 8.971897958320955\n",
      "resetting env. episode reward total was 5.0. running mean: 8.932178978737745\n",
      "resetting env. episode reward total was 3.0. running mean: 8.872857188950368\n",
      "resetting env. episode reward total was 13.0. running mean: 8.914128617060864\n",
      "resetting env. episode reward total was 19.0. running mean: 9.014987330890255\n",
      "resetting env. episode reward total was -1.0. running mean: 8.914837457581353\n",
      "resetting env. episode reward total was 7.0. running mean: 8.89568908300554\n",
      "resetting env. episode reward total was 11.0. running mean: 8.916732192175484\n",
      "resetting env. episode reward total was 4.0. running mean: 8.867564870253728\n",
      "resetting env. episode reward total was 5.0. running mean: 8.828889221551192\n",
      "resetting env. episode reward total was 13.0. running mean: 8.87060032933568\n",
      "resetting env. episode reward total was -3.0. running mean: 8.751894326042324\n",
      "resetting env. episode reward total was 12.0. running mean: 8.7843753827819\n",
      "resetting env. episode reward total was 14.0. running mean: 8.83653162895408\n",
      "resetting env. episode reward total was 18.0. running mean: 8.928166312664539\n",
      "resetting env. episode reward total was 13.0. running mean: 8.968884649537895\n",
      "resetting env. episode reward total was 7.0. running mean: 8.949195803042516\n",
      "resetting env. episode reward total was 11.0. running mean: 8.96970384501209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 9.03000680656197\n",
      "resetting env. episode reward total was 7.0. running mean: 9.00970673849635\n",
      "resetting env. episode reward total was 10.0. running mean: 9.019609671111386\n",
      "resetting env. episode reward total was 9.0. running mean: 9.019413574400271\n",
      "resetting env. episode reward total was 12.0. running mean: 9.049219438656268\n",
      "resetting env. episode reward total was 12.0. running mean: 9.078727244269704\n",
      "resetting env. episode reward total was 8.0. running mean: 9.067939971827007\n",
      "resetting env. episode reward total was 15.0. running mean: 9.127260572108737\n",
      "resetting env. episode reward total was -1.0. running mean: 9.02598796638765\n",
      "resetting env. episode reward total was 7.0. running mean: 9.005728086723773\n",
      "resetting env. episode reward total was 4.0. running mean: 8.955670805856533\n",
      "resetting env. episode reward total was 9.0. running mean: 8.956114097797968\n",
      "resetting env. episode reward total was 10.0. running mean: 8.966552956819989\n",
      "resetting env. episode reward total was 12.0. running mean: 8.996887427251789\n",
      "resetting env. episode reward total was 15.0. running mean: 9.05691855297927\n",
      "resetting env. episode reward total was 5.0. running mean: 9.016349367449479\n",
      "resetting env. episode reward total was 9.0. running mean: 9.016185873774983\n",
      "resetting env. episode reward total was 17.0. running mean: 9.096024015037234\n",
      "resetting env. episode reward total was 2.0. running mean: 9.02506377488686\n",
      "resetting env. episode reward total was 4.0. running mean: 8.974813137137991\n",
      "resetting env. episode reward total was 14.0. running mean: 9.025065005766612\n",
      "resetting env. episode reward total was 11.0. running mean: 9.044814355708946\n",
      "resetting env. episode reward total was 14.0. running mean: 9.094366212151856\n",
      "resetting env. episode reward total was 8.0. running mean: 9.083422550030338\n",
      "resetting env. episode reward total was -7.0. running mean: 8.922588324530034\n",
      "resetting env. episode reward total was 12.0. running mean: 8.953362441284733\n",
      "resetting env. episode reward total was 16.0. running mean: 9.023828816871886\n",
      "resetting env. episode reward total was 17.0. running mean: 9.103590528703167\n",
      "resetting env. episode reward total was 14.0. running mean: 9.152554623416137\n",
      "resetting env. episode reward total was 11.0. running mean: 9.171029077181975\n",
      "resetting env. episode reward total was 14.0. running mean: 9.219318786410156\n",
      "resetting env. episode reward total was 7.0. running mean: 9.197125598546055\n",
      "resetting env. episode reward total was 14.0. running mean: 9.245154342560594\n",
      "resetting env. episode reward total was 13.0. running mean: 9.28270279913499\n",
      "resetting env. episode reward total was 8.0. running mean: 9.26987577114364\n",
      "resetting env. episode reward total was 7.0. running mean: 9.247177013432204\n",
      "resetting env. episode reward total was 13.0. running mean: 9.284705243297882\n",
      "resetting env. episode reward total was 12.0. running mean: 9.311858190864902\n",
      "resetting env. episode reward total was 8.0. running mean: 9.298739608956252\n",
      "resetting env. episode reward total was 7.0. running mean: 9.27575221286669\n",
      "resetting env. episode reward total was 9.0. running mean: 9.272994690738024\n",
      "resetting env. episode reward total was 7.0. running mean: 9.250264743830645\n",
      "resetting env. episode reward total was 13.0. running mean: 9.287762096392338\n",
      "resetting env. episode reward total was 12.0. running mean: 9.314884475428414\n",
      "resetting env. episode reward total was 15.0. running mean: 9.37173563067413\n",
      "resetting env. episode reward total was 13.0. running mean: 9.40801827436739\n",
      "resetting env. episode reward total was 15.0. running mean: 9.463938091623715\n",
      "resetting env. episode reward total was 10.0. running mean: 9.469298710707477\n",
      "resetting env. episode reward total was 8.0. running mean: 9.454605723600402\n",
      "resetting env. episode reward total was 16.0. running mean: 9.520059666364398\n",
      "resetting env. episode reward total was 17.0. running mean: 9.594859069700753\n",
      "resetting env. episode reward total was 15.0. running mean: 9.648910479003746\n",
      "resetting env. episode reward total was 9.0. running mean: 9.642421374213708\n",
      "resetting env. episode reward total was 16.0. running mean: 9.70599716047157\n",
      "resetting env. episode reward total was 2.0. running mean: 9.628937188866853\n",
      "resetting env. episode reward total was 9.0. running mean: 9.622647816978185\n",
      "resetting env. episode reward total was 11.0. running mean: 9.636421338808402\n",
      "resetting env. episode reward total was 14.0. running mean: 9.68005712542032\n",
      "resetting env. episode reward total was 8.0. running mean: 9.663256554166116\n",
      "resetting env. episode reward total was 4.0. running mean: 9.606623988624454\n",
      "resetting env. episode reward total was 11.0. running mean: 9.620557748738209\n",
      "resetting env. episode reward total was 7.0. running mean: 9.594352171250828\n",
      "resetting env. episode reward total was 8.0. running mean: 9.57840864953832\n",
      "resetting env. episode reward total was 14.0. running mean: 9.622624563042937\n",
      "resetting env. episode reward total was 8.0. running mean: 9.606398317412507\n",
      "resetting env. episode reward total was 10.0. running mean: 9.610334334238383\n",
      "resetting env. episode reward total was 6.0. running mean: 9.574230990896\n",
      "resetting env. episode reward total was 17.0. running mean: 9.64848868098704\n",
      "resetting env. episode reward total was 4.0. running mean: 9.592003794177169\n",
      "resetting env. episode reward total was 15.0. running mean: 9.646083756235397\n",
      "resetting env. episode reward total was 16.0. running mean: 9.709622918673043\n",
      "resetting env. episode reward total was 10.0. running mean: 9.712526689486312\n",
      "resetting env. episode reward total was 16.0. running mean: 9.775401422591449\n",
      "resetting env. episode reward total was 10.0. running mean: 9.777647408365533\n",
      "resetting env. episode reward total was 5.0. running mean: 9.729870934281879\n",
      "resetting env. episode reward total was 15.0. running mean: 9.78257222493906\n",
      "resetting env. episode reward total was 12.0. running mean: 9.804746502689667\n",
      "resetting env. episode reward total was 6.0. running mean: 9.766699037662772\n",
      "resetting env. episode reward total was -1.0. running mean: 9.659032047286145\n",
      "resetting env. episode reward total was 12.0. running mean: 9.682441726813282\n",
      "resetting env. episode reward total was 8.0. running mean: 9.66561730954515\n",
      "resetting env. episode reward total was 19.0. running mean: 9.758961136449697\n",
      "resetting env. episode reward total was 16.0. running mean: 9.8213715250852\n",
      "resetting env. episode reward total was 17.0. running mean: 9.893157809834348\n",
      "resetting env. episode reward total was 5.0. running mean: 9.844226231736005\n",
      "resetting env. episode reward total was 9.0. running mean: 9.835783969418646\n",
      "resetting env. episode reward total was 7.0. running mean: 9.80742612972446\n",
      "resetting env. episode reward total was 14.0. running mean: 9.849351868427217\n",
      "resetting env. episode reward total was 12.0. running mean: 9.870858349742944\n",
      "resetting env. episode reward total was 12.0. running mean: 9.892149766245513\n",
      "resetting env. episode reward total was 10.0. running mean: 9.893228268583057\n",
      "resetting env. episode reward total was 10.0. running mean: 9.894295985897227\n",
      "resetting env. episode reward total was 13.0. running mean: 9.925353026038255\n",
      "resetting env. episode reward total was 7.0. running mean: 9.896099495777873\n",
      "resetting env. episode reward total was 12.0. running mean: 9.917138500820094\n",
      "resetting env. episode reward total was 8.0. running mean: 9.897967115811893\n",
      "resetting env. episode reward total was 8.0. running mean: 9.878987444653774\n",
      "resetting env. episode reward total was 5.0. running mean: 9.830197570207236\n",
      "resetting env. episode reward total was 13.0. running mean: 9.861895594505164\n",
      "resetting env. episode reward total was 9.0. running mean: 9.853276638560112\n",
      "resetting env. episode reward total was 12.0. running mean: 9.87474387217451\n",
      "resetting env. episode reward total was 12.0. running mean: 9.895996433452765\n",
      "resetting env. episode reward total was 9.0. running mean: 9.887036469118238\n",
      "resetting env. episode reward total was 9.0. running mean: 9.878166104427056\n",
      "resetting env. episode reward total was 4.0. running mean: 9.819384443382784\n",
      "resetting env. episode reward total was -2.0. running mean: 9.701190598948957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 9.694178692959467\n",
      "resetting env. episode reward total was 15.0. running mean: 9.747236906029872\n",
      "resetting env. episode reward total was 16.0. running mean: 9.809764536969574\n",
      "resetting env. episode reward total was 5.0. running mean: 9.761666891599878\n",
      "resetting env. episode reward total was 11.0. running mean: 9.77405022268388\n",
      "resetting env. episode reward total was 15.0. running mean: 9.82630972045704\n",
      "resetting env. episode reward total was 15.0. running mean: 9.87804662325247\n",
      "resetting env. episode reward total was 8.0. running mean: 9.859266157019945\n",
      "resetting env. episode reward total was 5.0. running mean: 9.810673495449747\n",
      "resetting env. episode reward total was 14.0. running mean: 9.85256676049525\n",
      "resetting env. episode reward total was 5.0. running mean: 9.804041092890298\n",
      "resetting env. episode reward total was 10.0. running mean: 9.806000681961395\n",
      "resetting env. episode reward total was 10.0. running mean: 9.807940675141781\n",
      "resetting env. episode reward total was 9.0. running mean: 9.799861268390362\n",
      "resetting env. episode reward total was 11.0. running mean: 9.811862655706458\n",
      "resetting env. episode reward total was 14.0. running mean: 9.853744029149393\n",
      "resetting env. episode reward total was 7.0. running mean: 9.825206588857899\n",
      "resetting env. episode reward total was 5.0. running mean: 9.776954522969321\n",
      "resetting env. episode reward total was 3.0. running mean: 9.709184977739627\n",
      "resetting env. episode reward total was 11.0. running mean: 9.72209312796223\n",
      "resetting env. episode reward total was 4.0. running mean: 9.664872196682607\n",
      "resetting env. episode reward total was 11.0. running mean: 9.67822347471578\n",
      "resetting env. episode reward total was 12.0. running mean: 9.701441239968622\n",
      "resetting env. episode reward total was 10.0. running mean: 9.704426827568936\n",
      "resetting env. episode reward total was 3.0. running mean: 9.637382559293245\n",
      "resetting env. episode reward total was 11.0. running mean: 9.651008733700312\n",
      "resetting env. episode reward total was 15.0. running mean: 9.704498646363309\n",
      "resetting env. episode reward total was 9.0. running mean: 9.697453659899676\n",
      "resetting env. episode reward total was 9.0. running mean: 9.690479123300678\n",
      "resetting env. episode reward total was 16.0. running mean: 9.753574332067672\n",
      "resetting env. episode reward total was 16.0. running mean: 9.816038588746995\n",
      "resetting env. episode reward total was 9.0. running mean: 9.807878202859525\n",
      "resetting env. episode reward total was 16.0. running mean: 9.86979942083093\n",
      "resetting env. episode reward total was 7.0. running mean: 9.84110142662262\n",
      "resetting env. episode reward total was 13.0. running mean: 9.872690412356395\n",
      "resetting env. episode reward total was 12.0. running mean: 9.89396350823283\n",
      "resetting env. episode reward total was 5.0. running mean: 9.845023873150502\n",
      "resetting env. episode reward total was 14.0. running mean: 9.886573634418998\n",
      "resetting env. episode reward total was 15.0. running mean: 9.937707898074807\n",
      "resetting env. episode reward total was 13.0. running mean: 9.96833081909406\n",
      "resetting env. episode reward total was 14.0. running mean: 10.00864751090312\n",
      "resetting env. episode reward total was 13.0. running mean: 10.03856103579409\n",
      "resetting env. episode reward total was 6.0. running mean: 9.99817542543615\n",
      "resetting env. episode reward total was 10.0. running mean: 9.998193671181788\n",
      "resetting env. episode reward total was 19.0. running mean: 10.08821173446997\n",
      "resetting env. episode reward total was 3.0. running mean: 10.01732961712527\n",
      "resetting env. episode reward total was 17.0. running mean: 10.087156320954017\n",
      "resetting env. episode reward total was 13.0. running mean: 10.116284757744477\n",
      "resetting env. episode reward total was -2.0. running mean: 9.995121910167033\n",
      "resetting env. episode reward total was 8.0. running mean: 9.975170691065362\n",
      "resetting env. episode reward total was 10.0. running mean: 9.975418984154707\n",
      "resetting env. episode reward total was 9.0. running mean: 9.96566479431316\n",
      "resetting env. episode reward total was 8.0. running mean: 9.946008146370028\n",
      "resetting env. episode reward total was 10.0. running mean: 9.946548064906327\n",
      "resetting env. episode reward total was 13.0. running mean: 9.977082584257264\n",
      "resetting env. episode reward total was 5.0. running mean: 9.927311758414692\n",
      "resetting env. episode reward total was 16.0. running mean: 9.988038640830545\n",
      "resetting env. episode reward total was 10.0. running mean: 9.98815825442224\n",
      "resetting env. episode reward total was 17.0. running mean: 10.058276671878017\n",
      "resetting env. episode reward total was 7.0. running mean: 10.027693905159238\n",
      "resetting env. episode reward total was 10.0. running mean: 10.027416966107644\n",
      "resetting env. episode reward total was 14.0. running mean: 10.067142796446568\n",
      "resetting env. episode reward total was 16.0. running mean: 10.126471368482102\n",
      "resetting env. episode reward total was 11.0. running mean: 10.13520665479728\n",
      "resetting env. episode reward total was 9.0. running mean: 10.123854588249307\n",
      "resetting env. episode reward total was 9.0. running mean: 10.112616042366813\n",
      "resetting env. episode reward total was 3.0. running mean: 10.041489881943145\n",
      "resetting env. episode reward total was 5.0. running mean: 9.991074983123713\n",
      "resetting env. episode reward total was 14.0. running mean: 10.031164233292477\n",
      "resetting env. episode reward total was 9.0. running mean: 10.020852590959553\n",
      "resetting env. episode reward total was 12.0. running mean: 10.040644065049957\n",
      "resetting env. episode reward total was 6.0. running mean: 10.000237624399457\n",
      "resetting env. episode reward total was 11.0. running mean: 10.010235248155462\n",
      "resetting env. episode reward total was 11.0. running mean: 10.020132895673907\n",
      "resetting env. episode reward total was 16.0. running mean: 10.079931566717168\n",
      "resetting env. episode reward total was 11.0. running mean: 10.089132251049996\n",
      "resetting env. episode reward total was 1.0. running mean: 9.998240928539495\n",
      "resetting env. episode reward total was 13.0. running mean: 10.0282585192541\n",
      "resetting env. episode reward total was 16.0. running mean: 10.087975934061559\n",
      "resetting env. episode reward total was 11.0. running mean: 10.097096174720942\n",
      "resetting env. episode reward total was 8.0. running mean: 10.076125212973732\n",
      "resetting env. episode reward total was 3.0. running mean: 10.005363960843994\n",
      "resetting env. episode reward total was 11.0. running mean: 10.015310321235553\n",
      "resetting env. episode reward total was 10.0. running mean: 10.015157218023198\n",
      "resetting env. episode reward total was 4.0. running mean: 9.955005645842965\n",
      "resetting env. episode reward total was 16.0. running mean: 10.015455589384535\n",
      "resetting env. episode reward total was 12.0. running mean: 10.03530103349069\n",
      "resetting env. episode reward total was 16.0. running mean: 10.094948023155784\n",
      "resetting env. episode reward total was 15.0. running mean: 10.143998542924226\n",
      "resetting env. episode reward total was 7.0. running mean: 10.112558557494983\n",
      "resetting env. episode reward total was 11.0. running mean: 10.121432971920033\n",
      "resetting env. episode reward total was 12.0. running mean: 10.140218642200832\n",
      "resetting env. episode reward total was 10.0. running mean: 10.138816455778823\n",
      "resetting env. episode reward total was 2.0. running mean: 10.057428291221035\n",
      "resetting env. episode reward total was 11.0. running mean: 10.066854008308823\n",
      "resetting env. episode reward total was 12.0. running mean: 10.086185468225734\n",
      "resetting env. episode reward total was 13.0. running mean: 10.115323613543477\n",
      "resetting env. episode reward total was 14.0. running mean: 10.154170377408043\n",
      "resetting env. episode reward total was 12.0. running mean: 10.172628673633962\n",
      "resetting env. episode reward total was 8.0. running mean: 10.150902386897624\n",
      "resetting env. episode reward total was 14.0. running mean: 10.189393363028648\n",
      "resetting env. episode reward total was 8.0. running mean: 10.167499429398362\n",
      "resetting env. episode reward total was 12.0. running mean: 10.185824435104378\n",
      "resetting env. episode reward total was 9.0. running mean: 10.173966190753333\n",
      "resetting env. episode reward total was 11.0. running mean: 10.1822265288458\n",
      "resetting env. episode reward total was 12.0. running mean: 10.20040426355734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 10.218400220921765\n",
      "resetting env. episode reward total was 3.0. running mean: 10.146216218712548\n",
      "resetting env. episode reward total was 10.0. running mean: 10.144754056525422\n",
      "resetting env. episode reward total was 10.0. running mean: 10.143306515960166\n",
      "resetting env. episode reward total was 11.0. running mean: 10.151873450800563\n",
      "resetting env. episode reward total was 13.0. running mean: 10.180354716292559\n",
      "resetting env. episode reward total was 10.0. running mean: 10.178551169129634\n",
      "resetting env. episode reward total was 14.0. running mean: 10.216765657438337\n",
      "resetting env. episode reward total was 15.0. running mean: 10.264598000863954\n",
      "resetting env. episode reward total was 21.0. running mean: 10.371952020855314\n",
      "resetting env. episode reward total was -1.0. running mean: 10.258232500646761\n",
      "resetting env. episode reward total was 14.0. running mean: 10.295650175640294\n",
      "resetting env. episode reward total was 8.0. running mean: 10.272693673883891\n",
      "resetting env. episode reward total was 6.0. running mean: 10.229966737145054\n",
      "resetting env. episode reward total was 18.0. running mean: 10.307667069773602\n",
      "resetting env. episode reward total was 14.0. running mean: 10.344590399075868\n",
      "resetting env. episode reward total was 15.0. running mean: 10.39114449508511\n",
      "resetting env. episode reward total was 14.0. running mean: 10.427233050134259\n",
      "resetting env. episode reward total was 4.0. running mean: 10.362960719632914\n",
      "resetting env. episode reward total was 13.0. running mean: 10.389331112436587\n",
      "resetting env. episode reward total was 7.0. running mean: 10.35543780131222\n",
      "resetting env. episode reward total was 8.0. running mean: 10.331883423299098\n",
      "resetting env. episode reward total was -4.0. running mean: 10.188564589066107\n",
      "resetting env. episode reward total was 11.0. running mean: 10.196678943175446\n",
      "resetting env. episode reward total was 11.0. running mean: 10.20471215374369\n",
      "resetting env. episode reward total was 5.0. running mean: 10.152665032206254\n",
      "resetting env. episode reward total was 13.0. running mean: 10.181138381884193\n",
      "resetting env. episode reward total was 12.0. running mean: 10.19932699806535\n",
      "resetting env. episode reward total was 8.0. running mean: 10.177333728084697\n",
      "resetting env. episode reward total was 7.0. running mean: 10.145560390803851\n",
      "resetting env. episode reward total was 12.0. running mean: 10.164104786895813\n",
      "resetting env. episode reward total was 9.0. running mean: 10.152463739026855\n",
      "resetting env. episode reward total was 10.0. running mean: 10.150939101636586\n",
      "resetting env. episode reward total was 10.0. running mean: 10.14942971062022\n",
      "resetting env. episode reward total was 11.0. running mean: 10.157935413514018\n",
      "resetting env. episode reward total was 15.0. running mean: 10.206356059378878\n",
      "resetting env. episode reward total was 12.0. running mean: 10.224292498785088\n",
      "resetting env. episode reward total was 6.0. running mean: 10.182049573797238\n",
      "resetting env. episode reward total was 12.0. running mean: 10.200229078059264\n",
      "resetting env. episode reward total was 9.0. running mean: 10.188226787278671\n",
      "resetting env. episode reward total was 12.0. running mean: 10.206344519405883\n",
      "resetting env. episode reward total was 12.0. running mean: 10.224281074211824\n",
      "resetting env. episode reward total was 9.0. running mean: 10.212038263469704\n",
      "resetting env. episode reward total was 6.0. running mean: 10.169917880835008\n",
      "resetting env. episode reward total was 7.0. running mean: 10.13821870202666\n",
      "resetting env. episode reward total was 11.0. running mean: 10.146836515006392\n",
      "resetting env. episode reward total was 14.0. running mean: 10.185368149856329\n",
      "resetting env. episode reward total was 12.0. running mean: 10.203514468357765\n",
      "resetting env. episode reward total was 16.0. running mean: 10.261479323674187\n",
      "resetting env. episode reward total was 12.0. running mean: 10.278864530437446\n",
      "resetting env. episode reward total was 10.0. running mean: 10.276075885133071\n",
      "resetting env. episode reward total was -1.0. running mean: 10.163315126281741\n",
      "resetting env. episode reward total was 14.0. running mean: 10.201681975018925\n",
      "resetting env. episode reward total was -3.0. running mean: 10.069665155268737\n",
      "resetting env. episode reward total was 10.0. running mean: 10.06896850371605\n",
      "resetting env. episode reward total was 8.0. running mean: 10.04827881867889\n",
      "resetting env. episode reward total was 6.0. running mean: 10.007796030492102\n",
      "resetting env. episode reward total was 14.0. running mean: 10.047718070187182\n",
      "resetting env. episode reward total was 13.0. running mean: 10.07724088948531\n",
      "resetting env. episode reward total was 13.0. running mean: 10.106468480590458\n",
      "resetting env. episode reward total was 11.0. running mean: 10.115403795784552\n",
      "resetting env. episode reward total was 18.0. running mean: 10.194249757826706\n",
      "resetting env. episode reward total was 15.0. running mean: 10.242307260248438\n",
      "resetting env. episode reward total was 10.0. running mean: 10.239884187645954\n",
      "resetting env. episode reward total was 12.0. running mean: 10.257485345769494\n",
      "resetting env. episode reward total was 11.0. running mean: 10.264910492311799\n",
      "resetting env. episode reward total was 6.0. running mean: 10.22226138738868\n",
      "resetting env. episode reward total was 10.0. running mean: 10.220038773514794\n",
      "resetting env. episode reward total was 13.0. running mean: 10.247838385779646\n",
      "resetting env. episode reward total was 17.0. running mean: 10.31536000192185\n",
      "resetting env. episode reward total was 8.0. running mean: 10.29220640190263\n",
      "resetting env. episode reward total was 11.0. running mean: 10.299284337883604\n",
      "resetting env. episode reward total was 13.0. running mean: 10.326291494504769\n",
      "resetting env. episode reward total was 12.0. running mean: 10.34302857955972\n",
      "resetting env. episode reward total was 10.0. running mean: 10.339598293764123\n",
      "resetting env. episode reward total was 14.0. running mean: 10.376202310826482\n",
      "resetting env. episode reward total was 12.0. running mean: 10.392440287718216\n",
      "resetting env. episode reward total was 11.0. running mean: 10.398515884841034\n",
      "resetting env. episode reward total was 12.0. running mean: 10.414530725992623\n",
      "resetting env. episode reward total was 12.0. running mean: 10.430385418732696\n",
      "resetting env. episode reward total was 16.0. running mean: 10.486081564545369\n",
      "resetting env. episode reward total was 7.0. running mean: 10.451220748899916\n",
      "resetting env. episode reward total was 14.0. running mean: 10.486708541410916\n",
      "resetting env. episode reward total was 10.0. running mean: 10.481841455996806\n",
      "resetting env. episode reward total was 14.0. running mean: 10.517023041436838\n",
      "resetting env. episode reward total was 4.0. running mean: 10.45185281102247\n",
      "resetting env. episode reward total was 5.0. running mean: 10.397334282912245\n",
      "resetting env. episode reward total was 16.0. running mean: 10.453360940083122\n",
      "resetting env. episode reward total was 13.0. running mean: 10.478827330682291\n",
      "resetting env. episode reward total was 13.0. running mean: 10.504039057375469\n",
      "resetting env. episode reward total was 7.0. running mean: 10.468998666801713\n",
      "resetting env. episode reward total was 13.0. running mean: 10.494308680133697\n",
      "resetting env. episode reward total was 4.0. running mean: 10.42936559333236\n",
      "resetting env. episode reward total was 10.0. running mean: 10.425071937399036\n",
      "resetting env. episode reward total was 11.0. running mean: 10.430821218025045\n",
      "resetting env. episode reward total was 11.0. running mean: 10.436513005844795\n",
      "resetting env. episode reward total was 18.0. running mean: 10.512147875786347\n",
      "resetting env. episode reward total was 15.0. running mean: 10.557026397028483\n",
      "resetting env. episode reward total was 11.0. running mean: 10.561456133058197\n",
      "resetting env. episode reward total was 5.0. running mean: 10.505841571727617\n",
      "resetting env. episode reward total was 12.0. running mean: 10.520783156010339\n",
      "resetting env. episode reward total was 8.0. running mean: 10.495575324450236\n",
      "resetting env. episode reward total was 10.0. running mean: 10.490619571205734\n",
      "resetting env. episode reward total was 16.0. running mean: 10.545713375493676\n",
      "resetting env. episode reward total was 8.0. running mean: 10.520256241738739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 10.505053679321351\n",
      "resetting env. episode reward total was 6.0. running mean: 10.460003142528139\n",
      "resetting env. episode reward total was 12.0. running mean: 10.475403111102857\n",
      "resetting env. episode reward total was 9.0. running mean: 10.460649079991828\n",
      "resetting env. episode reward total was 10.0. running mean: 10.45604258919191\n",
      "resetting env. episode reward total was 11.0. running mean: 10.46148216329999\n",
      "resetting env. episode reward total was 8.0. running mean: 10.436867341666991\n",
      "resetting env. episode reward total was 6.0. running mean: 10.39249866825032\n",
      "resetting env. episode reward total was 5.0. running mean: 10.338573681567818\n",
      "resetting env. episode reward total was 10.0. running mean: 10.335187944752139\n",
      "resetting env. episode reward total was 2.0. running mean: 10.251836065304618\n",
      "resetting env. episode reward total was 11.0. running mean: 10.25931770465157\n",
      "resetting env. episode reward total was 12.0. running mean: 10.276724527605055\n",
      "resetting env. episode reward total was 18.0. running mean: 10.353957282329004\n",
      "resetting env. episode reward total was -3.0. running mean: 10.220417709505714\n",
      "resetting env. episode reward total was 13.0. running mean: 10.248213532410658\n",
      "resetting env. episode reward total was 13.0. running mean: 10.275731397086552\n",
      "resetting env. episode reward total was 13.0. running mean: 10.302974083115688\n",
      "resetting env. episode reward total was 13.0. running mean: 10.32994434228453\n",
      "resetting env. episode reward total was 13.0. running mean: 10.356644898861687\n",
      "resetting env. episode reward total was 11.0. running mean: 10.363078449873068\n",
      "resetting env. episode reward total was 10.0. running mean: 10.359447665374336\n",
      "resetting env. episode reward total was 10.0. running mean: 10.355853188720593\n",
      "resetting env. episode reward total was 9.0. running mean: 10.342294656833387\n",
      "resetting env. episode reward total was 11.0. running mean: 10.348871710265053\n",
      "resetting env. episode reward total was 13.0. running mean: 10.375382993162402\n",
      "resetting env. episode reward total was 16.0. running mean: 10.431629163230777\n",
      "resetting env. episode reward total was 16.0. running mean: 10.48731287159847\n",
      "resetting env. episode reward total was 11.0. running mean: 10.492439742882484\n",
      "resetting env. episode reward total was 16.0. running mean: 10.54751534545366\n",
      "resetting env. episode reward total was 12.0. running mean: 10.562040191999122\n",
      "resetting env. episode reward total was 20.0. running mean: 10.65641979007913\n",
      "resetting env. episode reward total was 6.0. running mean: 10.60985559217834\n",
      "resetting env. episode reward total was 16.0. running mean: 10.663757036256557\n",
      "resetting env. episode reward total was 6.0. running mean: 10.617119465893992\n",
      "resetting env. episode reward total was 8.0. running mean: 10.590948271235053\n",
      "resetting env. episode reward total was 9.0. running mean: 10.575038788522702\n",
      "resetting env. episode reward total was 5.0. running mean: 10.519288400637476\n",
      "resetting env. episode reward total was 10.0. running mean: 10.514095516631102\n",
      "resetting env. episode reward total was 10.0. running mean: 10.50895456146479\n",
      "resetting env. episode reward total was 8.0. running mean: 10.483865015850142\n",
      "resetting env. episode reward total was 11.0. running mean: 10.48902636569164\n",
      "resetting env. episode reward total was 7.0. running mean: 10.454136102034724\n",
      "resetting env. episode reward total was 9.0. running mean: 10.439594741014377\n",
      "resetting env. episode reward total was 9.0. running mean: 10.425198793604233\n",
      "resetting env. episode reward total was 12.0. running mean: 10.44094680566819\n",
      "resetting env. episode reward total was 13.0. running mean: 10.46653733761151\n",
      "resetting env. episode reward total was 6.0. running mean: 10.421871964235395\n",
      "resetting env. episode reward total was 16.0. running mean: 10.477653244593041\n",
      "resetting env. episode reward total was 17.0. running mean: 10.54287671214711\n",
      "resetting env. episode reward total was 13.0. running mean: 10.56744794502564\n",
      "resetting env. episode reward total was 7.0. running mean: 10.531773465575384\n",
      "resetting env. episode reward total was 8.0. running mean: 10.50645573091963\n",
      "resetting env. episode reward total was 12.0. running mean: 10.521391173610432\n",
      "resetting env. episode reward total was 12.0. running mean: 10.536177261874327\n",
      "resetting env. episode reward total was 3.0. running mean: 10.460815489255584\n",
      "resetting env. episode reward total was 12.0. running mean: 10.476207334363027\n",
      "resetting env. episode reward total was 12.0. running mean: 10.491445261019395\n",
      "resetting env. episode reward total was 8.0. running mean: 10.466530808409201\n",
      "resetting env. episode reward total was 18.0. running mean: 10.541865500325109\n",
      "resetting env. episode reward total was 9.0. running mean: 10.526446845321857\n",
      "resetting env. episode reward total was 16.0. running mean: 10.581182376868638\n",
      "resetting env. episode reward total was -3.0. running mean: 10.445370553099952\n",
      "resetting env. episode reward total was 7.0. running mean: 10.410916847568952\n",
      "resetting env. episode reward total was 15.0. running mean: 10.456807679093263\n",
      "resetting env. episode reward total was 20.0. running mean: 10.552239602302329\n",
      "resetting env. episode reward total was 14.0. running mean: 10.586717206279307\n",
      "resetting env. episode reward total was 10.0. running mean: 10.580850034216514\n",
      "resetting env. episode reward total was 12.0. running mean: 10.595041533874348\n",
      "resetting env. episode reward total was 2.0. running mean: 10.509091118535604\n",
      "resetting env. episode reward total was 8.0. running mean: 10.484000207350249\n",
      "resetting env. episode reward total was 10.0. running mean: 10.479160205276745\n",
      "resetting env. episode reward total was 14.0. running mean: 10.514368603223978\n",
      "resetting env. episode reward total was 5.0. running mean: 10.45922491719174\n",
      "resetting env. episode reward total was 7.0. running mean: 10.424632668019823\n",
      "resetting env. episode reward total was 9.0. running mean: 10.410386341339624\n",
      "resetting env. episode reward total was 12.0. running mean: 10.426282477926227\n",
      "resetting env. episode reward total was -5.0. running mean: 10.272019653146964\n",
      "resetting env. episode reward total was 2.0. running mean: 10.189299456615494\n",
      "resetting env. episode reward total was 13.0. running mean: 10.21740646204934\n",
      "resetting env. episode reward total was 14.0. running mean: 10.255232397428847\n",
      "resetting env. episode reward total was 10.0. running mean: 10.252680073454558\n",
      "resetting env. episode reward total was 8.0. running mean: 10.230153272720012\n",
      "resetting env. episode reward total was 8.0. running mean: 10.207851739992812\n",
      "resetting env. episode reward total was 9.0. running mean: 10.195773222592884\n",
      "resetting env. episode reward total was 10.0. running mean: 10.193815490366955\n",
      "resetting env. episode reward total was 17.0. running mean: 10.261877335463286\n",
      "resetting env. episode reward total was 11.0. running mean: 10.269258562108652\n",
      "resetting env. episode reward total was 11.0. running mean: 10.276565976487564\n",
      "resetting env. episode reward total was 5.0. running mean: 10.22380031672269\n",
      "resetting env. episode reward total was 13.0. running mean: 10.251562313555464\n",
      "resetting env. episode reward total was 7.0. running mean: 10.21904669041991\n",
      "resetting env. episode reward total was 9.0. running mean: 10.206856223515711\n",
      "resetting env. episode reward total was 15.0. running mean: 10.254787661280554\n",
      "resetting env. episode reward total was 5.0. running mean: 10.20223978466775\n",
      "resetting env. episode reward total was -5.0. running mean: 10.050217386821071\n",
      "resetting env. episode reward total was 10.0. running mean: 10.04971521295286\n",
      "resetting env. episode reward total was 8.0. running mean: 10.02921806082333\n",
      "resetting env. episode reward total was 14.0. running mean: 10.068925880215097\n",
      "resetting env. episode reward total was 5.0. running mean: 10.018236621412948\n",
      "resetting env. episode reward total was 11.0. running mean: 10.028054255198818\n",
      "resetting env. episode reward total was 11.0. running mean: 10.037773712646828\n",
      "resetting env. episode reward total was 17.0. running mean: 10.10739597552036\n",
      "resetting env. episode reward total was 14.0. running mean: 10.146322015765158\n",
      "resetting env. episode reward total was 13.0. running mean: 10.174858795607507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 10.193110207651431\n",
      "resetting env. episode reward total was 11.0. running mean: 10.201179105574916\n",
      "resetting env. episode reward total was 7.0. running mean: 10.169167314519166\n",
      "resetting env. episode reward total was 13.0. running mean: 10.197475641373975\n",
      "resetting env. episode reward total was 8.0. running mean: 10.175500884960236\n",
      "resetting env. episode reward total was 5.0. running mean: 10.123745876110634\n",
      "resetting env. episode reward total was 10.0. running mean: 10.122508417349527\n",
      "resetting env. episode reward total was 7.0. running mean: 10.091283333176031\n",
      "resetting env. episode reward total was 4.0. running mean: 10.03037049984427\n",
      "resetting env. episode reward total was 4.0. running mean: 9.970066794845827\n",
      "resetting env. episode reward total was -8.0. running mean: 9.79036612689737\n",
      "resetting env. episode reward total was 13.0. running mean: 9.822462465628396\n",
      "resetting env. episode reward total was 15.0. running mean: 9.874237840972112\n",
      "resetting env. episode reward total was 13.0. running mean: 9.905495462562392\n",
      "resetting env. episode reward total was 7.0. running mean: 9.876440507936769\n",
      "resetting env. episode reward total was 15.0. running mean: 9.9276761028574\n",
      "resetting env. episode reward total was 10.0. running mean: 9.928399341828825\n",
      "resetting env. episode reward total was 5.0. running mean: 9.879115348410538\n",
      "resetting env. episode reward total was 13.0. running mean: 9.910324194926433\n",
      "resetting env. episode reward total was -2.0. running mean: 9.79122095297717\n",
      "resetting env. episode reward total was 8.0. running mean: 9.773308743447398\n",
      "resetting env. episode reward total was 15.0. running mean: 9.825575656012925\n",
      "resetting env. episode reward total was 10.0. running mean: 9.827319899452794\n",
      "resetting env. episode reward total was 16.0. running mean: 9.889046700458266\n",
      "resetting env. episode reward total was 15.0. running mean: 9.940156233453683\n",
      "resetting env. episode reward total was 2.0. running mean: 9.860754671119146\n",
      "resetting env. episode reward total was 13.0. running mean: 9.892147124407956\n",
      "resetting env. episode reward total was 8.0. running mean: 9.873225653163876\n",
      "resetting env. episode reward total was 10.0. running mean: 9.874493396632237\n",
      "resetting env. episode reward total was 8.0. running mean: 9.855748462665915\n",
      "resetting env. episode reward total was 13.0. running mean: 9.887190978039257\n",
      "resetting env. episode reward total was 10.0. running mean: 9.888319068258864\n",
      "resetting env. episode reward total was 5.0. running mean: 9.839435877576276\n",
      "resetting env. episode reward total was 12.0. running mean: 9.861041518800512\n",
      "resetting env. episode reward total was 6.0. running mean: 9.822431103612507\n",
      "resetting env. episode reward total was 9.0. running mean: 9.814206792576382\n",
      "resetting env. episode reward total was 18.0. running mean: 9.896064724650618\n",
      "resetting env. episode reward total was 9.0. running mean: 9.88710407740411\n",
      "resetting env. episode reward total was 11.0. running mean: 9.898233036630069\n",
      "resetting env. episode reward total was 14.0. running mean: 9.939250706263769\n",
      "resetting env. episode reward total was 13.0. running mean: 9.969858199201132\n",
      "resetting env. episode reward total was 11.0. running mean: 9.98015961720912\n",
      "resetting env. episode reward total was 10.0. running mean: 9.980358021037029\n",
      "resetting env. episode reward total was 12.0. running mean: 10.000554440826658\n",
      "resetting env. episode reward total was 9.0. running mean: 9.99054889641839\n",
      "resetting env. episode reward total was 5.0. running mean: 9.940643407454207\n",
      "resetting env. episode reward total was 5.0. running mean: 9.891236973379666\n",
      "resetting env. episode reward total was 5.0. running mean: 9.84232460364587\n",
      "resetting env. episode reward total was 8.0. running mean: 9.823901357609412\n",
      "resetting env. episode reward total was 10.0. running mean: 9.825662344033317\n",
      "resetting env. episode reward total was 9.0. running mean: 9.817405720592983\n",
      "resetting env. episode reward total was 7.0. running mean: 9.789231663387055\n",
      "resetting env. episode reward total was 10.0. running mean: 9.791339346753183\n",
      "resetting env. episode reward total was 7.0. running mean: 9.763425953285651\n",
      "resetting env. episode reward total was 1.0. running mean: 9.675791693752794\n",
      "resetting env. episode reward total was 11.0. running mean: 9.689033776815265\n",
      "resetting env. episode reward total was 2.0. running mean: 9.612143439047111\n",
      "resetting env. episode reward total was 16.0. running mean: 9.676022004656641\n",
      "resetting env. episode reward total was 5.0. running mean: 9.629261784610074\n",
      "resetting env. episode reward total was 14.0. running mean: 9.672969166763973\n",
      "resetting env. episode reward total was 5.0. running mean: 9.626239475096334\n",
      "resetting env. episode reward total was -1.0. running mean: 9.51997708034537\n",
      "resetting env. episode reward total was 8.0. running mean: 9.504777309541916\n",
      "resetting env. episode reward total was 10.0. running mean: 9.509729536446496\n",
      "resetting env. episode reward total was 10.0. running mean: 9.514632241082031\n",
      "resetting env. episode reward total was 12.0. running mean: 9.539485918671211\n",
      "resetting env. episode reward total was 3.0. running mean: 9.474091059484499\n",
      "resetting env. episode reward total was 10.0. running mean: 9.479350148889653\n",
      "resetting env. episode reward total was 3.0. running mean: 9.414556647400756\n",
      "resetting env. episode reward total was 10.0. running mean: 9.420411080926748\n",
      "resetting env. episode reward total was 15.0. running mean: 9.476206970117481\n",
      "resetting env. episode reward total was 12.0. running mean: 9.501444900416304\n",
      "resetting env. episode reward total was 17.0. running mean: 9.576430451412142\n",
      "resetting env. episode reward total was 20.0. running mean: 9.68066614689802\n",
      "resetting env. episode reward total was 15.0. running mean: 9.73385948542904\n",
      "resetting env. episode reward total was 10.0. running mean: 9.736520890574749\n",
      "resetting env. episode reward total was 12.0. running mean: 9.759155681669\n",
      "resetting env. episode reward total was 13.0. running mean: 9.79156412485231\n",
      "resetting env. episode reward total was -5.0. running mean: 9.643648483603787\n",
      "resetting env. episode reward total was 10.0. running mean: 9.647211998767748\n",
      "resetting env. episode reward total was 11.0. running mean: 9.66073987878007\n",
      "resetting env. episode reward total was 11.0. running mean: 9.674132479992268\n",
      "resetting env. episode reward total was 13.0. running mean: 9.707391155192346\n",
      "resetting env. episode reward total was 14.0. running mean: 9.750317243640422\n",
      "resetting env. episode reward total was 13.0. running mean: 9.782814071204019\n",
      "resetting env. episode reward total was 12.0. running mean: 9.804985930491977\n",
      "resetting env. episode reward total was 14.0. running mean: 9.846936071187057\n",
      "resetting env. episode reward total was 17.0. running mean: 9.918466710475187\n",
      "resetting env. episode reward total was 8.0. running mean: 9.899282043370436\n",
      "resetting env. episode reward total was 4.0. running mean: 9.84028922293673\n",
      "resetting env. episode reward total was 6.0. running mean: 9.801886330707363\n",
      "resetting env. episode reward total was 15.0. running mean: 9.85386746740029\n",
      "resetting env. episode reward total was 8.0. running mean: 9.835328792726287\n",
      "resetting env. episode reward total was 14.0. running mean: 9.876975504799024\n",
      "resetting env. episode reward total was 13.0. running mean: 9.908205749751033\n",
      "resetting env. episode reward total was 13.0. running mean: 9.939123692253524\n",
      "resetting env. episode reward total was 17.0. running mean: 10.009732455330989\n",
      "resetting env. episode reward total was 12.0. running mean: 10.029635130777677\n",
      "resetting env. episode reward total was 10.0. running mean: 10.0293387794699\n",
      "resetting env. episode reward total was 17.0. running mean: 10.099045391675201\n",
      "resetting env. episode reward total was 11.0. running mean: 10.108054937758448\n",
      "resetting env. episode reward total was 12.0. running mean: 10.126974388380862\n",
      "resetting env. episode reward total was 10.0. running mean: 10.125704644497054\n",
      "resetting env. episode reward total was 12.0. running mean: 10.144447598052082\n",
      "resetting env. episode reward total was 13.0. running mean: 10.173003122071561\n",
      "resetting env. episode reward total was -1.0. running mean: 10.061273090850845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 10.080660359942335\n",
      "resetting env. episode reward total was 14.0. running mean: 10.119853756342913\n",
      "resetting env. episode reward total was 12.0. running mean: 10.138655218779483\n",
      "resetting env. episode reward total was 8.0. running mean: 10.117268666591688\n",
      "resetting env. episode reward total was 12.0. running mean: 10.13609597992577\n",
      "resetting env. episode reward total was 15.0. running mean: 10.184735020126512\n",
      "resetting env. episode reward total was 17.0. running mean: 10.252887669925247\n",
      "resetting env. episode reward total was 14.0. running mean: 10.290358793225995\n",
      "resetting env. episode reward total was 14.0. running mean: 10.327455205293735\n",
      "resetting env. episode reward total was 16.0. running mean: 10.384180653240797\n",
      "resetting env. episode reward total was 10.0. running mean: 10.380338846708389\n",
      "resetting env. episode reward total was 5.0. running mean: 10.326535458241306\n",
      "resetting env. episode reward total was 9.0. running mean: 10.313270103658892\n",
      "resetting env. episode reward total was 9.0. running mean: 10.300137402622303\n",
      "resetting env. episode reward total was 1.0. running mean: 10.20713602859608\n",
      "resetting env. episode reward total was 14.0. running mean: 10.24506466831012\n",
      "resetting env. episode reward total was 17.0. running mean: 10.312614021627018\n",
      "resetting env. episode reward total was 16.0. running mean: 10.369487881410748\n",
      "resetting env. episode reward total was 17.0. running mean: 10.435793002596641\n",
      "resetting env. episode reward total was 14.0. running mean: 10.471435072570676\n",
      "resetting env. episode reward total was 14.0. running mean: 10.50672072184497\n",
      "resetting env. episode reward total was 7.0. running mean: 10.471653514626519\n",
      "resetting env. episode reward total was 11.0. running mean: 10.476936979480254\n",
      "resetting env. episode reward total was -1.0. running mean: 10.362167609685452\n",
      "resetting env. episode reward total was 8.0. running mean: 10.338545933588597\n",
      "resetting env. episode reward total was 11.0. running mean: 10.34516047425271\n",
      "resetting env. episode reward total was 15.0. running mean: 10.391708869510182\n",
      "resetting env. episode reward total was 8.0. running mean: 10.36779178081508\n",
      "resetting env. episode reward total was 8.0. running mean: 10.34411386300693\n",
      "resetting env. episode reward total was 13.0. running mean: 10.370672724376861\n",
      "resetting env. episode reward total was 11.0. running mean: 10.376965997133093\n",
      "resetting env. episode reward total was 15.0. running mean: 10.423196337161762\n",
      "resetting env. episode reward total was 13.0. running mean: 10.448964373790146\n",
      "resetting env. episode reward total was 14.0. running mean: 10.484474730052245\n",
      "resetting env. episode reward total was 5.0. running mean: 10.429629982751724\n",
      "resetting env. episode reward total was 9.0. running mean: 10.415333682924206\n",
      "resetting env. episode reward total was 12.0. running mean: 10.431180346094964\n",
      "resetting env. episode reward total was 8.0. running mean: 10.406868542634014\n",
      "resetting env. episode reward total was 5.0. running mean: 10.352799857207675\n",
      "resetting env. episode reward total was 10.0. running mean: 10.349271858635598\n",
      "resetting env. episode reward total was 9.0. running mean: 10.335779140049242\n",
      "resetting env. episode reward total was 8.0. running mean: 10.31242134864875\n",
      "resetting env. episode reward total was 3.0. running mean: 10.23929713516226\n",
      "resetting env. episode reward total was 12.0. running mean: 10.256904163810637\n",
      "resetting env. episode reward total was 13.0. running mean: 10.28433512217253\n",
      "resetting env. episode reward total was 8.0. running mean: 10.261491770950805\n",
      "resetting env. episode reward total was 12.0. running mean: 10.278876853241297\n",
      "resetting env. episode reward total was 11.0. running mean: 10.286088084708883\n",
      "resetting env. episode reward total was 10.0. running mean: 10.283227203861793\n",
      "resetting env. episode reward total was 12.0. running mean: 10.300394931823174\n",
      "resetting env. episode reward total was 9.0. running mean: 10.287390982504942\n",
      "resetting env. episode reward total was 16.0. running mean: 10.344517072679892\n",
      "resetting env. episode reward total was 10.0. running mean: 10.341071901953093\n",
      "resetting env. episode reward total was 13.0. running mean: 10.367661182933563\n",
      "resetting env. episode reward total was 16.0. running mean: 10.423984571104228\n",
      "resetting env. episode reward total was 11.0. running mean: 10.429744725393185\n",
      "resetting env. episode reward total was 15.0. running mean: 10.475447278139253\n",
      "resetting env. episode reward total was 11.0. running mean: 10.48069280535786\n",
      "resetting env. episode reward total was 3.0. running mean: 10.40588587730428\n",
      "resetting env. episode reward total was 13.0. running mean: 10.431827018531239\n",
      "resetting env. episode reward total was 9.0. running mean: 10.417508748345925\n",
      "resetting env. episode reward total was 13.0. running mean: 10.443333660862466\n",
      "resetting env. episode reward total was 13.0. running mean: 10.468900324253841\n",
      "resetting env. episode reward total was 11.0. running mean: 10.474211321011301\n",
      "resetting env. episode reward total was -1.0. running mean: 10.359469207801189\n",
      "resetting env. episode reward total was 13.0. running mean: 10.385874515723177\n",
      "resetting env. episode reward total was 17.0. running mean: 10.452015770565945\n",
      "resetting env. episode reward total was 6.0. running mean: 10.407495612860286\n",
      "resetting env. episode reward total was 11.0. running mean: 10.413420656731683\n",
      "resetting env. episode reward total was 13.0. running mean: 10.439286450164367\n",
      "resetting env. episode reward total was 12.0. running mean: 10.454893585662722\n",
      "resetting env. episode reward total was 4.0. running mean: 10.390344649806094\n",
      "resetting env. episode reward total was 9.0. running mean: 10.376441203308033\n",
      "resetting env. episode reward total was 8.0. running mean: 10.352676791274954\n",
      "resetting env. episode reward total was 7.0. running mean: 10.319150023362205\n",
      "resetting env. episode reward total was 6.0. running mean: 10.275958523128583\n",
      "resetting env. episode reward total was 15.0. running mean: 10.323198937897297\n",
      "resetting env. episode reward total was 1.0. running mean: 10.229966948518324\n",
      "resetting env. episode reward total was 12.0. running mean: 10.24766727903314\n",
      "resetting env. episode reward total was 13.0. running mean: 10.275190606242809\n",
      "resetting env. episode reward total was 11.0. running mean: 10.28243870018038\n",
      "resetting env. episode reward total was 13.0. running mean: 10.309614313178578\n",
      "resetting env. episode reward total was 10.0. running mean: 10.306518170046791\n",
      "resetting env. episode reward total was 12.0. running mean: 10.323452988346322\n",
      "resetting env. episode reward total was 12.0. running mean: 10.340218458462857\n",
      "resetting env. episode reward total was 15.0. running mean: 10.386816273878228\n",
      "resetting env. episode reward total was 9.0. running mean: 10.372948111139445\n",
      "resetting env. episode reward total was 12.0. running mean: 10.38921863002805\n",
      "resetting env. episode reward total was 9.0. running mean: 10.37532644372777\n",
      "resetting env. episode reward total was 16.0. running mean: 10.431573179290492\n",
      "resetting env. episode reward total was 9.0. running mean: 10.417257447497587\n",
      "resetting env. episode reward total was 14.0. running mean: 10.453084873022611\n",
      "resetting env. episode reward total was 14.0. running mean: 10.488554024292386\n",
      "resetting env. episode reward total was 8.0. running mean: 10.463668484049462\n",
      "resetting env. episode reward total was 18.0. running mean: 10.539031799208967\n",
      "resetting env. episode reward total was 19.0. running mean: 10.623641481216877\n",
      "resetting env. episode reward total was 11.0. running mean: 10.627405066404707\n",
      "resetting env. episode reward total was 12.0. running mean: 10.641131015740658\n",
      "resetting env. episode reward total was 9.0. running mean: 10.624719705583251\n",
      "resetting env. episode reward total was 13.0. running mean: 10.64847250852742\n",
      "resetting env. episode reward total was 6.0. running mean: 10.601987783442146\n",
      "resetting env. episode reward total was 2.0. running mean: 10.515967905607724\n",
      "resetting env. episode reward total was 13.0. running mean: 10.540808226551647\n",
      "resetting env. episode reward total was 8.0. running mean: 10.515400144286131\n",
      "resetting env. episode reward total was 10.0. running mean: 10.51024614284327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 10.555143681414838\n",
      "resetting env. episode reward total was 10.0. running mean: 10.54959224460069\n",
      "resetting env. episode reward total was 12.0. running mean: 10.564096322154683\n",
      "resetting env. episode reward total was 13.0. running mean: 10.588455358933137\n",
      "resetting env. episode reward total was -1.0. running mean: 10.472570805343805\n",
      "resetting env. episode reward total was 3.0. running mean: 10.397845097290366\n",
      "resetting env. episode reward total was 4.0. running mean: 10.333866646317462\n",
      "resetting env. episode reward total was 15.0. running mean: 10.380527979854287\n",
      "resetting env. episode reward total was 2.0. running mean: 10.296722700055744\n",
      "resetting env. episode reward total was 13.0. running mean: 10.323755473055186\n",
      "resetting env. episode reward total was 3.0. running mean: 10.250517918324634\n",
      "resetting env. episode reward total was 8.0. running mean: 10.228012739141388\n",
      "resetting env. episode reward total was 16.0. running mean: 10.285732611749975\n",
      "resetting env. episode reward total was -3.0. running mean: 10.152875285632476\n",
      "resetting env. episode reward total was 10.0. running mean: 10.15134653277615\n",
      "resetting env. episode reward total was 13.0. running mean: 10.17983306744839\n",
      "resetting env. episode reward total was 7.0. running mean: 10.148034736773907\n",
      "resetting env. episode reward total was 9.0. running mean: 10.136554389406168\n",
      "resetting env. episode reward total was 10.0. running mean: 10.135188845512106\n",
      "resetting env. episode reward total was 9.0. running mean: 10.123836957056985\n",
      "resetting env. episode reward total was 10.0. running mean: 10.122598587486415\n",
      "resetting env. episode reward total was 16.0. running mean: 10.181372601611551\n",
      "resetting env. episode reward total was 12.0. running mean: 10.199558875595434\n",
      "resetting env. episode reward total was 9.0. running mean: 10.18756328683948\n",
      "resetting env. episode reward total was 7.0. running mean: 10.155687653971084\n",
      "resetting env. episode reward total was 11.0. running mean: 10.164130777431373\n",
      "resetting env. episode reward total was 11.0. running mean: 10.172489469657059\n",
      "resetting env. episode reward total was 9.0. running mean: 10.160764574960488\n",
      "resetting env. episode reward total was 10.0. running mean: 10.159156929210884\n",
      "resetting env. episode reward total was 9.0. running mean: 10.147565359918774\n",
      "resetting env. episode reward total was 11.0. running mean: 10.156089706319586\n",
      "resetting env. episode reward total was 11.0. running mean: 10.164528809256389\n",
      "resetting env. episode reward total was 6.0. running mean: 10.122883521163825\n",
      "resetting env. episode reward total was 16.0. running mean: 10.181654685952187\n",
      "resetting env. episode reward total was 5.0. running mean: 10.129838139092666\n",
      "resetting env. episode reward total was 11.0. running mean: 10.138539757701738\n",
      "resetting env. episode reward total was 10.0. running mean: 10.13715436012472\n",
      "resetting env. episode reward total was 11.0. running mean: 10.145782816523472\n",
      "resetting env. episode reward total was 9.0. running mean: 10.134324988358237\n",
      "resetting env. episode reward total was 11.0. running mean: 10.142981738474655\n",
      "resetting env. episode reward total was 12.0. running mean: 10.161551921089908\n",
      "resetting env. episode reward total was 8.0. running mean: 10.139936401879009\n",
      "resetting env. episode reward total was 12.0. running mean: 10.158537037860217\n",
      "resetting env. episode reward total was 5.0. running mean: 10.106951667481615\n",
      "resetting env. episode reward total was 13.0. running mean: 10.1358821508068\n",
      "resetting env. episode reward total was 12.0. running mean: 10.154523329298732\n",
      "resetting env. episode reward total was 7.0. running mean: 10.122978096005744\n",
      "resetting env. episode reward total was 12.0. running mean: 10.141748315045685\n",
      "resetting env. episode reward total was -1.0. running mean: 10.03033083189523\n",
      "resetting env. episode reward total was 8.0. running mean: 10.010027523576277\n",
      "resetting env. episode reward total was 4.0. running mean: 9.949927248340513\n",
      "resetting env. episode reward total was 11.0. running mean: 9.960427975857108\n",
      "resetting env. episode reward total was 18.0. running mean: 10.040823696098537\n",
      "resetting env. episode reward total was 7.0. running mean: 10.010415459137551\n",
      "resetting env. episode reward total was 13.0. running mean: 10.040311304546176\n",
      "resetting env. episode reward total was 12.0. running mean: 10.059908191500714\n",
      "resetting env. episode reward total was 11.0. running mean: 10.069309109585706\n",
      "resetting env. episode reward total was 15.0. running mean: 10.118616018489849\n",
      "resetting env. episode reward total was 4.0. running mean: 10.05742985830495\n",
      "resetting env. episode reward total was -1.0. running mean: 9.9468555597219\n",
      "resetting env. episode reward total was 9.0. running mean: 9.93738700412468\n",
      "resetting env. episode reward total was 14.0. running mean: 9.978013134083435\n",
      "resetting env. episode reward total was 11.0. running mean: 9.9882330027426\n",
      "resetting env. episode reward total was 12.0. running mean: 10.008350672715173\n",
      "resetting env. episode reward total was 12.0. running mean: 10.02826716598802\n",
      "resetting env. episode reward total was 11.0. running mean: 10.037984494328139\n",
      "resetting env. episode reward total was 13.0. running mean: 10.067604649384858\n",
      "resetting env. episode reward total was 7.0. running mean: 10.03692860289101\n",
      "resetting env. episode reward total was 13.0. running mean: 10.0665593168621\n",
      "resetting env. episode reward total was 1.0. running mean: 9.97589372369348\n",
      "resetting env. episode reward total was 11.0. running mean: 9.986134786456544\n",
      "resetting env. episode reward total was 14.0. running mean: 10.026273438591979\n",
      "resetting env. episode reward total was 17.0. running mean: 10.096010704206059\n",
      "resetting env. episode reward total was 11.0. running mean: 10.105050597163997\n",
      "resetting env. episode reward total was 12.0. running mean: 10.124000091192356\n",
      "resetting env. episode reward total was 10.0. running mean: 10.122760090280432\n",
      "resetting env. episode reward total was 14.0. running mean: 10.161532489377628\n",
      "resetting env. episode reward total was 15.0. running mean: 10.209917164483851\n",
      "resetting env. episode reward total was 10.0. running mean: 10.207817992839013\n",
      "resetting env. episode reward total was 4.0. running mean: 10.145739812910621\n",
      "resetting env. episode reward total was 1.0. running mean: 10.054282414781515\n",
      "resetting env. episode reward total was 10.0. running mean: 10.053739590633699\n",
      "resetting env. episode reward total was 11.0. running mean: 10.063202194727362\n",
      "resetting env. episode reward total was 6.0. running mean: 10.022570172780089\n",
      "resetting env. episode reward total was 10.0. running mean: 10.022344471052287\n",
      "resetting env. episode reward total was 12.0. running mean: 10.042121026341764\n",
      "resetting env. episode reward total was 5.0. running mean: 9.991699816078347\n",
      "resetting env. episode reward total was 9.0. running mean: 9.981782817917564\n",
      "resetting env. episode reward total was 2.0. running mean: 9.901964989738389\n",
      "resetting env. episode reward total was 10.0. running mean: 9.902945339841004\n",
      "resetting env. episode reward total was 9.0. running mean: 9.893915886442594\n",
      "resetting env. episode reward total was -6.0. running mean: 9.734976727578168\n",
      "resetting env. episode reward total was 17.0. running mean: 9.807626960302386\n",
      "resetting env. episode reward total was 8.0. running mean: 9.789550690699363\n",
      "resetting env. episode reward total was 6.0. running mean: 9.75165518379237\n",
      "resetting env. episode reward total was 13.0. running mean: 9.784138631954447\n",
      "resetting env. episode reward total was 15.0. running mean: 9.836297245634903\n",
      "resetting env. episode reward total was 13.0. running mean: 9.867934273178554\n",
      "resetting env. episode reward total was 6.0. running mean: 9.82925493044677\n",
      "resetting env. episode reward total was 6.0. running mean: 9.790962381142302\n",
      "resetting env. episode reward total was 12.0. running mean: 9.813052757330878\n",
      "resetting env. episode reward total was 15.0. running mean: 9.86492222975757\n",
      "resetting env. episode reward total was 17.0. running mean: 9.936273007459993\n",
      "resetting env. episode reward total was 13.0. running mean: 9.966910277385395\n",
      "resetting env. episode reward total was 12.0. running mean: 9.98724117461154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 9.997368762865424\n",
      "resetting env. episode reward total was 11.0. running mean: 10.007395075236769\n",
      "resetting env. episode reward total was 12.0. running mean: 10.0273211244844\n",
      "resetting env. episode reward total was 5.0. running mean: 9.977047913239558\n",
      "resetting env. episode reward total was 9.0. running mean: 9.967277434107162\n",
      "resetting env. episode reward total was 7.0. running mean: 9.937604659766091\n",
      "resetting env. episode reward total was 8.0. running mean: 9.91822861316843\n",
      "resetting env. episode reward total was 7.0. running mean: 9.889046327036747\n",
      "resetting env. episode reward total was 13.0. running mean: 9.92015586376638\n",
      "resetting env. episode reward total was 9.0. running mean: 9.910954305128717\n",
      "resetting env. episode reward total was 15.0. running mean: 9.96184476207743\n",
      "resetting env. episode reward total was 10.0. running mean: 9.962226314456656\n",
      "resetting env. episode reward total was 12.0. running mean: 9.982604051312089\n",
      "resetting env. episode reward total was 3.0. running mean: 9.912778010798968\n",
      "resetting env. episode reward total was 1.0. running mean: 9.823650230690978\n",
      "resetting env. episode reward total was 6.0. running mean: 9.785413728384068\n",
      "resetting env. episode reward total was 4.0. running mean: 9.727559591100226\n",
      "resetting env. episode reward total was 9.0. running mean: 9.720283995189224\n",
      "resetting env. episode reward total was 9.0. running mean: 9.713081155237331\n",
      "resetting env. episode reward total was 13.0. running mean: 9.745950343684958\n",
      "resetting env. episode reward total was 10.0. running mean: 9.748490840248108\n",
      "resetting env. episode reward total was 14.0. running mean: 9.791005931845627\n",
      "resetting env. episode reward total was 4.0. running mean: 9.73309587252717\n",
      "resetting env. episode reward total was 7.0. running mean: 9.705764913801898\n",
      "resetting env. episode reward total was 5.0. running mean: 9.65870726466388\n",
      "resetting env. episode reward total was 19.0. running mean: 9.752120192017241\n",
      "resetting env. episode reward total was 15.0. running mean: 9.80459899009707\n",
      "resetting env. episode reward total was 15.0. running mean: 9.856553000196099\n",
      "resetting env. episode reward total was 15.0. running mean: 9.907987470194138\n",
      "resetting env. episode reward total was 7.0. running mean: 9.878907595492198\n",
      "resetting env. episode reward total was 13.0. running mean: 9.910118519537276\n",
      "resetting env. episode reward total was 5.0. running mean: 9.861017334341904\n",
      "resetting env. episode reward total was 13.0. running mean: 9.892407160998486\n",
      "resetting env. episode reward total was 12.0. running mean: 9.9134830893885\n",
      "resetting env. episode reward total was 14.0. running mean: 9.954348258494615\n",
      "resetting env. episode reward total was 10.0. running mean: 9.954804775909668\n",
      "resetting env. episode reward total was 7.0. running mean: 9.925256728150572\n",
      "resetting env. episode reward total was 8.0. running mean: 9.906004160869067\n",
      "resetting env. episode reward total was 13.0. running mean: 9.936944119260376\n",
      "resetting env. episode reward total was 12.0. running mean: 9.957574678067772\n",
      "resetting env. episode reward total was 10.0. running mean: 9.957998931287094\n",
      "resetting env. episode reward total was 15.0. running mean: 10.008418941974224\n",
      "resetting env. episode reward total was 8.0. running mean: 9.988334752554481\n",
      "resetting env. episode reward total was 7.0. running mean: 9.958451405028937\n",
      "resetting env. episode reward total was 14.0. running mean: 9.998866890978649\n",
      "resetting env. episode reward total was 7.0. running mean: 9.968878222068863\n",
      "resetting env. episode reward total was 11.0. running mean: 9.979189439848174\n",
      "resetting env. episode reward total was 8.0. running mean: 9.959397545449692\n",
      "resetting env. episode reward total was 7.0. running mean: 9.929803569995196\n",
      "resetting env. episode reward total was 8.0. running mean: 9.910505534295243\n",
      "resetting env. episode reward total was 12.0. running mean: 9.93140047895229\n",
      "resetting env. episode reward total was 8.0. running mean: 9.912086474162766\n",
      "resetting env. episode reward total was 4.0. running mean: 9.852965609421137\n",
      "resetting env. episode reward total was 13.0. running mean: 9.884435953326927\n",
      "resetting env. episode reward total was 13.0. running mean: 9.915591593793659\n",
      "resetting env. episode reward total was 15.0. running mean: 9.966435677855722\n",
      "resetting env. episode reward total was 15.0. running mean: 10.016771321077165\n",
      "resetting env. episode reward total was 18.0. running mean: 10.096603607866394\n",
      "resetting env. episode reward total was 11.0. running mean: 10.10563757178773\n",
      "resetting env. episode reward total was 7.0. running mean: 10.074581196069852\n",
      "resetting env. episode reward total was 8.0. running mean: 10.053835384109153\n",
      "resetting env. episode reward total was 9.0. running mean: 10.04329703026806\n",
      "resetting env. episode reward total was 11.0. running mean: 10.05286405996538\n",
      "resetting env. episode reward total was 13.0. running mean: 10.082335419365727\n",
      "resetting env. episode reward total was 12.0. running mean: 10.101512065172068\n",
      "resetting env. episode reward total was 17.0. running mean: 10.170496944520348\n",
      "resetting env. episode reward total was 3.0. running mean: 10.098791975075144\n",
      "resetting env. episode reward total was -1.0. running mean: 9.987804055324393\n",
      "resetting env. episode reward total was 8.0. running mean: 9.967926014771148\n",
      "resetting env. episode reward total was 12.0. running mean: 9.988246754623436\n",
      "resetting env. episode reward total was -8.0. running mean: 9.808364287077202\n",
      "resetting env. episode reward total was 7.0. running mean: 9.78028064420643\n",
      "resetting env. episode reward total was 10.0. running mean: 9.782477837764365\n",
      "resetting env. episode reward total was 16.0. running mean: 9.84465305938672\n",
      "resetting env. episode reward total was 8.0. running mean: 9.826206528792854\n",
      "resetting env. episode reward total was 14.0. running mean: 9.867944463504926\n",
      "resetting env. episode reward total was 15.0. running mean: 9.919265018869877\n",
      "resetting env. episode reward total was 13.0. running mean: 9.950072368681179\n",
      "resetting env. episode reward total was 11.0. running mean: 9.960571644994365\n",
      "resetting env. episode reward total was 8.0. running mean: 9.940965928544422\n",
      "resetting env. episode reward total was 11.0. running mean: 9.951556269258978\n",
      "resetting env. episode reward total was 15.0. running mean: 10.002040706566389\n",
      "resetting env. episode reward total was 13.0. running mean: 10.032020299500726\n",
      "resetting env. episode reward total was 7.0. running mean: 10.001700096505719\n",
      "resetting env. episode reward total was 13.0. running mean: 10.031683095540663\n",
      "resetting env. episode reward total was 7.0. running mean: 10.001366264585256\n",
      "resetting env. episode reward total was 8.0. running mean: 9.981352601939403\n",
      "resetting env. episode reward total was 13.0. running mean: 10.011539075920009\n",
      "resetting env. episode reward total was 11.0. running mean: 10.021423685160809\n",
      "resetting env. episode reward total was 8.0. running mean: 10.0012094483092\n",
      "resetting env. episode reward total was 8.0. running mean: 9.981197353826108\n",
      "resetting env. episode reward total was 11.0. running mean: 9.991385380287847\n",
      "resetting env. episode reward total was 11.0. running mean: 10.001471526484968\n",
      "resetting env. episode reward total was 11.0. running mean: 10.011456811220118\n",
      "resetting env. episode reward total was 10.0. running mean: 10.011342243107917\n",
      "resetting env. episode reward total was 3.0. running mean: 9.941228820676837\n",
      "resetting env. episode reward total was 8.0. running mean: 9.92181653247007\n",
      "resetting env. episode reward total was 7.0. running mean: 9.89259836714537\n",
      "resetting env. episode reward total was 9.0. running mean: 9.883672383473916\n",
      "resetting env. episode reward total was 6.0. running mean: 9.844835659639177\n",
      "resetting env. episode reward total was 14.0. running mean: 9.886387303042785\n",
      "resetting env. episode reward total was -5.0. running mean: 9.737523430012356\n",
      "resetting env. episode reward total was 5.0. running mean: 9.690148195712233\n",
      "resetting env. episode reward total was 11.0. running mean: 9.70324671375511\n",
      "resetting env. episode reward total was 9.0. running mean: 9.69621424661756\n",
      "resetting env. episode reward total was 2.0. running mean: 9.619252104151384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 9.643059583109869\n",
      "resetting env. episode reward total was 12.0. running mean: 9.66662898727877\n",
      "resetting env. episode reward total was 11.0. running mean: 9.679962697405982\n",
      "resetting env. episode reward total was 9.0. running mean: 9.673163070431922\n",
      "resetting env. episode reward total was 6.0. running mean: 9.636431439727604\n",
      "resetting env. episode reward total was 3.0. running mean: 9.570067125330327\n",
      "resetting env. episode reward total was 14.0. running mean: 9.614366454077025\n",
      "resetting env. episode reward total was 10.0. running mean: 9.618222789536254\n",
      "resetting env. episode reward total was 12.0. running mean: 9.642040561640892\n",
      "resetting env. episode reward total was 11.0. running mean: 9.655620156024483\n",
      "resetting env. episode reward total was 9.0. running mean: 9.649063954464237\n",
      "resetting env. episode reward total was 13.0. running mean: 9.682573314919596\n",
      "resetting env. episode reward total was 13.0. running mean: 9.715747581770401\n",
      "resetting env. episode reward total was 12.0. running mean: 9.738590105952696\n",
      "resetting env. episode reward total was 14.0. running mean: 9.78120420489317\n",
      "resetting env. episode reward total was 6.0. running mean: 9.743392162844238\n",
      "resetting env. episode reward total was 12.0. running mean: 9.765958241215795\n",
      "resetting env. episode reward total was 9.0. running mean: 9.758298658803637\n",
      "resetting env. episode reward total was 6.0. running mean: 9.7207156722156\n",
      "resetting env. episode reward total was 8.0. running mean: 9.703508515493445\n",
      "resetting env. episode reward total was 15.0. running mean: 9.756473430338511\n",
      "resetting env. episode reward total was 18.0. running mean: 9.838908696035126\n",
      "resetting env. episode reward total was 12.0. running mean: 9.860519609074775\n",
      "resetting env. episode reward total was 10.0. running mean: 9.861914412984026\n",
      "resetting env. episode reward total was 4.0. running mean: 9.803295268854185\n",
      "resetting env. episode reward total was 15.0. running mean: 9.855262316165645\n",
      "resetting env. episode reward total was 12.0. running mean: 9.876709693003987\n",
      "resetting env. episode reward total was 5.0. running mean: 9.827942596073948\n",
      "resetting env. episode reward total was 5.0. running mean: 9.779663170113208\n",
      "resetting env. episode reward total was 7.0. running mean: 9.751866538412076\n",
      "resetting env. episode reward total was 17.0. running mean: 9.824347873027955\n",
      "resetting env. episode reward total was 12.0. running mean: 9.846104394297674\n",
      "resetting env. episode reward total was 11.0. running mean: 9.857643350354696\n",
      "resetting env. episode reward total was -1.0. running mean: 9.749066916851149\n",
      "resetting env. episode reward total was 9.0. running mean: 9.741576247682637\n",
      "resetting env. episode reward total was 8.0. running mean: 9.724160485205811\n",
      "resetting env. episode reward total was 7.0. running mean: 9.696918880353753\n",
      "resetting env. episode reward total was 6.0. running mean: 9.659949691550215\n",
      "resetting env. episode reward total was 11.0. running mean: 9.673350194634713\n",
      "resetting env. episode reward total was 15.0. running mean: 9.726616692688365\n",
      "resetting env. episode reward total was 17.0. running mean: 9.799350525761481\n",
      "resetting env. episode reward total was 12.0. running mean: 9.821357020503866\n",
      "resetting env. episode reward total was 6.0. running mean: 9.783143450298828\n",
      "resetting env. episode reward total was 7.0. running mean: 9.755312015795841\n",
      "resetting env. episode reward total was 11.0. running mean: 9.767758895637883\n",
      "resetting env. episode reward total was 3.0. running mean: 9.700081306681502\n",
      "resetting env. episode reward total was 14.0. running mean: 9.743080493614688\n",
      "resetting env. episode reward total was 7.0. running mean: 9.71564968867854\n",
      "resetting env. episode reward total was 1.0. running mean: 9.628493191791755\n",
      "resetting env. episode reward total was 5.0. running mean: 9.582208259873838\n",
      "resetting env. episode reward total was 8.0. running mean: 9.566386177275099\n",
      "resetting env. episode reward total was 7.0. running mean: 9.540722315502348\n",
      "resetting env. episode reward total was 13.0. running mean: 9.575315092347326\n",
      "resetting env. episode reward total was 12.0. running mean: 9.599561941423852\n",
      "resetting env. episode reward total was 10.0. running mean: 9.603566322009613\n",
      "resetting env. episode reward total was 8.0. running mean: 9.587530658789516\n",
      "resetting env. episode reward total was 13.0. running mean: 9.621655352201621\n",
      "resetting env. episode reward total was 9.0. running mean: 9.615438798679605\n",
      "resetting env. episode reward total was 18.0. running mean: 9.699284410692808\n",
      "resetting env. episode reward total was 7.0. running mean: 9.67229156658588\n",
      "resetting env. episode reward total was 4.0. running mean: 9.61556865092002\n",
      "resetting env. episode reward total was 14.0. running mean: 9.65941296441082\n",
      "resetting env. episode reward total was 4.0. running mean: 9.60281883476671\n",
      "resetting env. episode reward total was 10.0. running mean: 9.606790646419043\n",
      "resetting env. episode reward total was 14.0. running mean: 9.650722739954853\n",
      "resetting env. episode reward total was 9.0. running mean: 9.644215512555304\n",
      "resetting env. episode reward total was -7.0. running mean: 9.47777335742975\n",
      "resetting env. episode reward total was 5.0. running mean: 9.432995623855454\n",
      "resetting env. episode reward total was 14.0. running mean: 9.4786656676169\n",
      "resetting env. episode reward total was 7.0. running mean: 9.453879010940732\n",
      "resetting env. episode reward total was 6.0. running mean: 9.419340220831325\n",
      "resetting env. episode reward total was 10.0. running mean: 9.425146818623011\n",
      "resetting env. episode reward total was 12.0. running mean: 9.45089535043678\n",
      "resetting env. episode reward total was 1.0. running mean: 9.36638639693241\n",
      "resetting env. episode reward total was 7.0. running mean: 9.342722532963087\n",
      "resetting env. episode reward total was 15.0. running mean: 9.399295307633457\n",
      "resetting env. episode reward total was 10.0. running mean: 9.405302354557122\n",
      "resetting env. episode reward total was 3.0. running mean: 9.34124933101155\n",
      "resetting env. episode reward total was 13.0. running mean: 9.377836837701436\n",
      "resetting env. episode reward total was 8.0. running mean: 9.364058469324421\n",
      "resetting env. episode reward total was 12.0. running mean: 9.390417884631177\n",
      "resetting env. episode reward total was 12.0. running mean: 9.416513705784864\n",
      "resetting env. episode reward total was 12.0. running mean: 9.442348568727015\n",
      "resetting env. episode reward total was 7.0. running mean: 9.417925083039744\n",
      "resetting env. episode reward total was 17.0. running mean: 9.493745832209347\n",
      "resetting env. episode reward total was 18.0. running mean: 9.578808373887254\n",
      "resetting env. episode reward total was 14.0. running mean: 9.623020290148382\n",
      "resetting env. episode reward total was 14.0. running mean: 9.666790087246898\n",
      "resetting env. episode reward total was 6.0. running mean: 9.63012218637443\n",
      "resetting env. episode reward total was 1.0. running mean: 9.543820964510687\n",
      "resetting env. episode reward total was 11.0. running mean: 9.55838275486558\n",
      "resetting env. episode reward total was 11.0. running mean: 9.572798927316923\n",
      "resetting env. episode reward total was 19.0. running mean: 9.667070938043752\n",
      "resetting env. episode reward total was 13.0. running mean: 9.700400228663314\n",
      "resetting env. episode reward total was 6.0. running mean: 9.663396226376681\n",
      "resetting env. episode reward total was 11.0. running mean: 9.676762264112915\n",
      "resetting env. episode reward total was 10.0. running mean: 9.679994641471785\n",
      "resetting env. episode reward total was 8.0. running mean: 9.663194695057067\n",
      "resetting env. episode reward total was 15.0. running mean: 9.716562748106497\n",
      "resetting env. episode reward total was 4.0. running mean: 9.659397120625432\n",
      "resetting env. episode reward total was 12.0. running mean: 9.682803149419177\n",
      "resetting env. episode reward total was 3.0. running mean: 9.615975117924984\n",
      "resetting env. episode reward total was 17.0. running mean: 9.689815366745734\n",
      "resetting env. episode reward total was 10.0. running mean: 9.692917213078276\n",
      "resetting env. episode reward total was 14.0. running mean: 9.735988040947493\n",
      "resetting env. episode reward total was 11.0. running mean: 9.748628160538019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 9.791141878932638\n",
      "resetting env. episode reward total was 9.0. running mean: 9.783230460143312\n",
      "resetting env. episode reward total was 8.0. running mean: 9.76539815554188\n",
      "resetting env. episode reward total was 9.0. running mean: 9.75774417398646\n",
      "resetting env. episode reward total was 12.0. running mean: 9.780166732246593\n",
      "resetting env. episode reward total was 11.0. running mean: 9.792365064924127\n",
      "resetting env. episode reward total was 14.0. running mean: 9.834441414274886\n",
      "resetting env. episode reward total was 14.0. running mean: 9.876097000132138\n",
      "resetting env. episode reward total was 10.0. running mean: 9.877336030130815\n",
      "resetting env. episode reward total was 7.0. running mean: 9.848562669829507\n",
      "resetting env. episode reward total was 13.0. running mean: 9.880077043131212\n",
      "resetting env. episode reward total was 13.0. running mean: 9.9112762726999\n",
      "resetting env. episode reward total was 13.0. running mean: 9.942163509972902\n",
      "resetting env. episode reward total was 11.0. running mean: 9.952741874873173\n",
      "resetting env. episode reward total was 7.0. running mean: 9.923214456124441\n",
      "resetting env. episode reward total was 5.0. running mean: 9.873982311563198\n",
      "resetting env. episode reward total was 3.0. running mean: 9.805242488447565\n",
      "resetting env. episode reward total was 16.0. running mean: 9.86719006356309\n",
      "resetting env. episode reward total was 16.0. running mean: 9.928518162927459\n",
      "resetting env. episode reward total was 14.0. running mean: 9.969232981298184\n",
      "resetting env. episode reward total was 13.0. running mean: 9.999540651485203\n",
      "resetting env. episode reward total was 3.0. running mean: 9.92954524497035\n",
      "resetting env. episode reward total was 6.0. running mean: 9.890249792520647\n",
      "resetting env. episode reward total was 16.0. running mean: 9.951347294595442\n",
      "resetting env. episode reward total was 11.0. running mean: 9.961833821649487\n",
      "resetting env. episode reward total was 10.0. running mean: 9.962215483432992\n",
      "resetting env. episode reward total was 10.0. running mean: 9.962593328598661\n",
      "resetting env. episode reward total was 12.0. running mean: 9.982967395312674\n",
      "resetting env. episode reward total was -2.0. running mean: 9.863137721359546\n",
      "resetting env. episode reward total was 8.0. running mean: 9.844506344145952\n",
      "resetting env. episode reward total was 8.0. running mean: 9.826061280704492\n",
      "resetting env. episode reward total was 14.0. running mean: 9.867800667897447\n",
      "resetting env. episode reward total was 8.0. running mean: 9.849122661218471\n",
      "resetting env. episode reward total was 13.0. running mean: 9.880631434606288\n",
      "resetting env. episode reward total was 13.0. running mean: 9.911825120260225\n",
      "resetting env. episode reward total was 14.0. running mean: 9.952706869057623\n",
      "resetting env. episode reward total was 13.0. running mean: 9.983179800367047\n",
      "resetting env. episode reward total was 15.0. running mean: 10.033348002363377\n",
      "resetting env. episode reward total was 11.0. running mean: 10.043014522339742\n",
      "resetting env. episode reward total was 16.0. running mean: 10.102584377116345\n",
      "resetting env. episode reward total was 18.0. running mean: 10.181558533345182\n",
      "resetting env. episode reward total was 18.0. running mean: 10.25974294801173\n",
      "resetting env. episode reward total was 11.0. running mean: 10.267145518531613\n",
      "resetting env. episode reward total was -1.0. running mean: 10.154474063346298\n",
      "resetting env. episode reward total was 7.0. running mean: 10.122929322712835\n",
      "resetting env. episode reward total was 1.0. running mean: 10.031700029485707\n",
      "resetting env. episode reward total was 10.0. running mean: 10.031383029190849\n",
      "resetting env. episode reward total was 6.0. running mean: 9.991069198898941\n",
      "resetting env. episode reward total was 8.0. running mean: 9.971158506909951\n",
      "resetting env. episode reward total was 11.0. running mean: 9.98144692184085\n",
      "resetting env. episode reward total was 16.0. running mean: 10.041632452622443\n",
      "resetting env. episode reward total was 8.0. running mean: 10.021216128096219\n",
      "resetting env. episode reward total was 9.0. running mean: 10.011003966815256\n",
      "resetting env. episode reward total was 5.0. running mean: 9.960893927147104\n",
      "resetting env. episode reward total was 18.0. running mean: 10.041284987875633\n",
      "resetting env. episode reward total was 11.0. running mean: 10.050872137996876\n",
      "resetting env. episode reward total was 15.0. running mean: 10.100363416616908\n",
      "resetting env. episode reward total was 8.0. running mean: 10.079359782450739\n",
      "resetting env. episode reward total was 10.0. running mean: 10.078566184626231\n",
      "resetting env. episode reward total was 12.0. running mean: 10.097780522779967\n",
      "resetting env. episode reward total was 3.0. running mean: 10.026802717552167\n",
      "resetting env. episode reward total was 10.0. running mean: 10.026534690376645\n",
      "resetting env. episode reward total was 7.0. running mean: 9.996269343472878\n",
      "resetting env. episode reward total was 14.0. running mean: 10.03630665003815\n",
      "resetting env. episode reward total was 9.0. running mean: 10.025943583537767\n",
      "resetting env. episode reward total was 13.0. running mean: 10.05568414770239\n",
      "resetting env. episode reward total was 9.0. running mean: 10.045127306225366\n",
      "resetting env. episode reward total was 11.0. running mean: 10.054676033163112\n",
      "resetting env. episode reward total was 13.0. running mean: 10.08412927283148\n",
      "resetting env. episode reward total was 11.0. running mean: 10.093287980103165\n",
      "resetting env. episode reward total was 9.0. running mean: 10.082355100302133\n",
      "resetting env. episode reward total was 13.0. running mean: 10.111531549299112\n",
      "resetting env. episode reward total was 10.0. running mean: 10.11041623380612\n",
      "resetting env. episode reward total was -2.0. running mean: 9.98931207146806\n",
      "resetting env. episode reward total was 12.0. running mean: 10.009418950753378\n",
      "resetting env. episode reward total was 15.0. running mean: 10.059324761245845\n",
      "resetting env. episode reward total was 9.0. running mean: 10.048731513633387\n",
      "resetting env. episode reward total was 13.0. running mean: 10.078244198497053\n",
      "resetting env. episode reward total was 1.0. running mean: 9.987461756512083\n",
      "resetting env. episode reward total was 8.0. running mean: 9.967587138946962\n",
      "resetting env. episode reward total was 16.0. running mean: 10.027911267557492\n",
      "resetting env. episode reward total was 14.0. running mean: 10.067632154881919\n",
      "resetting env. episode reward total was 15.0. running mean: 10.1169558333331\n",
      "resetting env. episode reward total was 15.0. running mean: 10.16578627499977\n",
      "resetting env. episode reward total was 12.0. running mean: 10.184128412249772\n",
      "resetting env. episode reward total was 11.0. running mean: 10.192287128127273\n",
      "resetting env. episode reward total was 10.0. running mean: 10.190364256846\n",
      "resetting env. episode reward total was 14.0. running mean: 10.22846061427754\n",
      "resetting env. episode reward total was 7.0. running mean: 10.196176008134763\n",
      "resetting env. episode reward total was 14.0. running mean: 10.234214248053416\n",
      "resetting env. episode reward total was 13.0. running mean: 10.261872105572882\n",
      "resetting env. episode reward total was 17.0. running mean: 10.329253384517154\n",
      "resetting env. episode reward total was 14.0. running mean: 10.365960850671982\n",
      "resetting env. episode reward total was 8.0. running mean: 10.342301242165263\n",
      "resetting env. episode reward total was 19.0. running mean: 10.42887822974361\n",
      "resetting env. episode reward total was 6.0. running mean: 10.384589447446174\n",
      "resetting env. episode reward total was 5.0. running mean: 10.330743552971713\n",
      "resetting env. episode reward total was 2.0. running mean: 10.247436117441994\n",
      "resetting env. episode reward total was 14.0. running mean: 10.284961756267576\n",
      "resetting env. episode reward total was 3.0. running mean: 10.2121121387049\n",
      "resetting env. episode reward total was 12.0. running mean: 10.22999101731785\n",
      "resetting env. episode reward total was 8.0. running mean: 10.207691107144672\n",
      "resetting env. episode reward total was 12.0. running mean: 10.225614196073225\n",
      "resetting env. episode reward total was 4.0. running mean: 10.163358054112493\n",
      "resetting env. episode reward total was 11.0. running mean: 10.171724473571368\n",
      "resetting env. episode reward total was 9.0. running mean: 10.160007228835655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 10.1984071565473\n",
      "resetting env. episode reward total was 13.0. running mean: 10.226423084981827\n",
      "resetting env. episode reward total was 7.0. running mean: 10.194158854132008\n",
      "resetting env. episode reward total was 7.0. running mean: 10.162217265590687\n",
      "resetting env. episode reward total was 10.0. running mean: 10.16059509293478\n",
      "resetting env. episode reward total was -4.0. running mean: 10.018989142005433\n",
      "resetting env. episode reward total was 9.0. running mean: 10.008799250585378\n",
      "resetting env. episode reward total was 13.0. running mean: 10.038711258079525\n",
      "resetting env. episode reward total was 15.0. running mean: 10.08832414549873\n",
      "resetting env. episode reward total was 5.0. running mean: 10.037440904043743\n",
      "resetting env. episode reward total was 5.0. running mean: 9.987066495003306\n",
      "resetting env. episode reward total was 10.0. running mean: 9.987195830053272\n",
      "resetting env. episode reward total was 10.0. running mean: 9.98732387175274\n",
      "resetting env. episode reward total was 13.0. running mean: 10.017450633035212\n",
      "resetting env. episode reward total was 4.0. running mean: 9.957276126704858\n",
      "resetting env. episode reward total was 3.0. running mean: 9.88770336543781\n",
      "resetting env. episode reward total was 14.0. running mean: 9.928826331783432\n",
      "resetting env. episode reward total was 12.0. running mean: 9.949538068465596\n",
      "resetting env. episode reward total was 6.0. running mean: 9.91004268778094\n",
      "resetting env. episode reward total was 4.0. running mean: 9.85094226090313\n",
      "resetting env. episode reward total was 3.0. running mean: 9.782432838294097\n",
      "resetting env. episode reward total was 11.0. running mean: 9.794608509911155\n",
      "resetting env. episode reward total was 8.0. running mean: 9.776662424812043\n",
      "resetting env. episode reward total was 13.0. running mean: 9.808895800563924\n",
      "resetting env. episode reward total was 8.0. running mean: 9.790806842558284\n",
      "resetting env. episode reward total was 11.0. running mean: 9.8028987741327\n",
      "resetting env. episode reward total was 13.0. running mean: 9.834869786391375\n",
      "resetting env. episode reward total was 11.0. running mean: 9.84652108852746\n",
      "resetting env. episode reward total was 4.0. running mean: 9.788055877642185\n",
      "resetting env. episode reward total was 10.0. running mean: 9.790175318865762\n",
      "resetting env. episode reward total was 13.0. running mean: 9.822273565677104\n",
      "resetting env. episode reward total was 13.0. running mean: 9.854050830020334\n",
      "resetting env. episode reward total was 12.0. running mean: 9.87551032172013\n",
      "resetting env. episode reward total was 12.0. running mean: 9.896755218502928\n",
      "resetting env. episode reward total was 11.0. running mean: 9.907787666317898\n",
      "resetting env. episode reward total was 12.0. running mean: 9.928709789654718\n",
      "resetting env. episode reward total was 8.0. running mean: 9.90942269175817\n",
      "resetting env. episode reward total was 17.0. running mean: 9.980328464840587\n",
      "resetting env. episode reward total was 14.0. running mean: 10.020525180192182\n",
      "resetting env. episode reward total was 11.0. running mean: 10.03031992839026\n",
      "resetting env. episode reward total was 6.0. running mean: 9.990016729106356\n",
      "resetting env. episode reward total was 11.0. running mean: 10.000116561815291\n",
      "resetting env. episode reward total was 13.0. running mean: 10.03011539619714\n",
      "resetting env. episode reward total was 8.0. running mean: 10.009814242235167\n",
      "resetting env. episode reward total was 12.0. running mean: 10.029716099812815\n",
      "resetting env. episode reward total was 6.0. running mean: 9.989418938814687\n",
      "resetting env. episode reward total was 8.0. running mean: 9.96952474942654\n",
      "resetting env. episode reward total was 11.0. running mean: 9.979829501932274\n",
      "resetting env. episode reward total was 5.0. running mean: 9.930031206912952\n",
      "resetting env. episode reward total was 10.0. running mean: 9.930730894843823\n",
      "resetting env. episode reward total was 14.0. running mean: 9.971423585895385\n",
      "resetting env. episode reward total was 7.0. running mean: 9.941709350036431\n",
      "resetting env. episode reward total was 12.0. running mean: 9.962292256536067\n",
      "resetting env. episode reward total was 11.0. running mean: 9.972669333970705\n",
      "resetting env. episode reward total was 12.0. running mean: 9.992942640630996\n",
      "resetting env. episode reward total was 2.0. running mean: 9.913013214224685\n",
      "resetting env. episode reward total was 10.0. running mean: 9.913883082082439\n",
      "resetting env. episode reward total was 5.0. running mean: 9.864744251261616\n",
      "resetting env. episode reward total was 18.0. running mean: 9.946096808749\n",
      "resetting env. episode reward total was 11.0. running mean: 9.956635840661509\n",
      "resetting env. episode reward total was 14.0. running mean: 9.997069482254894\n",
      "resetting env. episode reward total was 18.0. running mean: 10.077098787432345\n",
      "resetting env. episode reward total was 7.0. running mean: 10.046327799558021\n",
      "resetting env. episode reward total was 18.0. running mean: 10.125864521562441\n",
      "resetting env. episode reward total was 13.0. running mean: 10.154605876346817\n",
      "resetting env. episode reward total was 12.0. running mean: 10.173059817583349\n",
      "resetting env. episode reward total was 8.0. running mean: 10.151329219407515\n",
      "resetting env. episode reward total was 10.0. running mean: 10.149815927213439\n",
      "resetting env. episode reward total was 17.0. running mean: 10.218317767941304\n",
      "resetting env. episode reward total was 4.0. running mean: 10.15613459026189\n",
      "resetting env. episode reward total was 10.0. running mean: 10.154573244359272\n",
      "resetting env. episode reward total was 10.0. running mean: 10.153027511915678\n",
      "resetting env. episode reward total was 11.0. running mean: 10.16149723679652\n",
      "resetting env. episode reward total was 16.0. running mean: 10.219882264428556\n",
      "resetting env. episode reward total was 12.0. running mean: 10.237683441784268\n",
      "resetting env. episode reward total was 9.0. running mean: 10.225306607366425\n",
      "resetting env. episode reward total was 7.0. running mean: 10.19305354129276\n",
      "resetting env. episode reward total was 13.0. running mean: 10.221123005879834\n",
      "resetting env. episode reward total was 15.0. running mean: 10.268911775821035\n",
      "resetting env. episode reward total was 18.0. running mean: 10.346222658062825\n",
      "resetting env. episode reward total was 7.0. running mean: 10.312760431482197\n",
      "resetting env. episode reward total was 14.0. running mean: 10.349632827167374\n",
      "resetting env. episode reward total was 15.0. running mean: 10.3961364988957\n",
      "resetting env. episode reward total was -3.0. running mean: 10.262175133906744\n",
      "resetting env. episode reward total was 9.0. running mean: 10.249553382567676\n",
      "resetting env. episode reward total was 12.0. running mean: 10.267057848741999\n",
      "resetting env. episode reward total was 13.0. running mean: 10.29438727025458\n",
      "resetting env. episode reward total was 14.0. running mean: 10.331443397552034\n",
      "resetting env. episode reward total was 10.0. running mean: 10.328128963576514\n",
      "resetting env. episode reward total was 5.0. running mean: 10.27484767394075\n",
      "resetting env. episode reward total was 7.0. running mean: 10.242099197201343\n",
      "resetting env. episode reward total was 5.0. running mean: 10.18967820522933\n",
      "resetting env. episode reward total was 13.0. running mean: 10.217781423177037\n",
      "resetting env. episode reward total was 14.0. running mean: 10.255603608945266\n",
      "resetting env. episode reward total was 3.0. running mean: 10.183047572855813\n",
      "resetting env. episode reward total was 10.0. running mean: 10.181217097127254\n",
      "resetting env. episode reward total was 6.0. running mean: 10.139404926155981\n",
      "resetting env. episode reward total was 7.0. running mean: 10.108010876894422\n",
      "resetting env. episode reward total was -2.0. running mean: 9.986930768125479\n",
      "resetting env. episode reward total was 10.0. running mean: 9.987061460444224\n",
      "resetting env. episode reward total was 7.0. running mean: 9.957190845839781\n",
      "resetting env. episode reward total was 12.0. running mean: 9.977618937381383\n",
      "resetting env. episode reward total was 12.0. running mean: 9.997842748007567\n",
      "resetting env. episode reward total was 6.0. running mean: 9.957864320527491\n",
      "resetting env. episode reward total was 9.0. running mean: 9.948285677322216\n",
      "resetting env. episode reward total was 12.0. running mean: 9.968802820548992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 17.0. running mean: 10.039114792343502\n",
      "resetting env. episode reward total was 14.0. running mean: 10.078723644420068\n",
      "resetting env. episode reward total was 20.0. running mean: 10.177936407975865\n",
      "resetting env. episode reward total was 10.0. running mean: 10.176157043896106\n",
      "resetting env. episode reward total was 15.0. running mean: 10.224395473457145\n",
      "resetting env. episode reward total was 10.0. running mean: 10.222151518722573\n",
      "resetting env. episode reward total was 18.0. running mean: 10.299930003535346\n",
      "resetting env. episode reward total was 13.0. running mean: 10.326930703499993\n",
      "resetting env. episode reward total was 3.0. running mean: 10.253661396464993\n",
      "resetting env. episode reward total was 15.0. running mean: 10.301124782500343\n",
      "resetting env. episode reward total was 6.0. running mean: 10.25811353467534\n",
      "resetting env. episode reward total was 4.0. running mean: 10.195532399328586\n",
      "resetting env. episode reward total was 11.0. running mean: 10.2035770753353\n",
      "resetting env. episode reward total was 13.0. running mean: 10.231541304581947\n",
      "resetting env. episode reward total was 14.0. running mean: 10.269225891536129\n",
      "resetting env. episode reward total was 10.0. running mean: 10.266533632620767\n",
      "resetting env. episode reward total was 11.0. running mean: 10.273868296294559\n",
      "resetting env. episode reward total was 9.0. running mean: 10.261129613331613\n",
      "resetting env. episode reward total was 11.0. running mean: 10.268518317198296\n",
      "resetting env. episode reward total was 10.0. running mean: 10.265833134026312\n",
      "resetting env. episode reward total was 4.0. running mean: 10.203174802686048\n",
      "resetting env. episode reward total was 11.0. running mean: 10.211143054659187\n",
      "resetting env. episode reward total was 12.0. running mean: 10.229031624112595\n",
      "resetting env. episode reward total was 14.0. running mean: 10.26674130787147\n",
      "resetting env. episode reward total was 11.0. running mean: 10.274073894792755\n",
      "resetting env. episode reward total was 3.0. running mean: 10.201333155844827\n",
      "resetting env. episode reward total was 6.0. running mean: 10.15931982428638\n",
      "resetting env. episode reward total was 16.0. running mean: 10.217726626043516\n",
      "resetting env. episode reward total was 15.0. running mean: 10.265549359783082\n",
      "resetting env. episode reward total was 11.0. running mean: 10.27289386618525\n",
      "resetting env. episode reward total was 6.0. running mean: 10.230164927523397\n",
      "resetting env. episode reward total was 13.0. running mean: 10.257863278248164\n",
      "resetting env. episode reward total was 9.0. running mean: 10.245284645465683\n",
      "resetting env. episode reward total was 15.0. running mean: 10.292831799011026\n",
      "resetting env. episode reward total was 12.0. running mean: 10.309903481020914\n",
      "resetting env. episode reward total was 5.0. running mean: 10.256804446210705\n",
      "resetting env. episode reward total was 10.0. running mean: 10.254236401748598\n",
      "resetting env. episode reward total was 16.0. running mean: 10.311694037731112\n",
      "resetting env. episode reward total was 9.0. running mean: 10.2985770973538\n",
      "resetting env. episode reward total was 4.0. running mean: 10.235591326380261\n",
      "resetting env. episode reward total was 8.0. running mean: 10.213235413116458\n",
      "resetting env. episode reward total was 4.0. running mean: 10.151103058985292\n",
      "resetting env. episode reward total was 8.0. running mean: 10.12959202839544\n",
      "resetting env. episode reward total was 13.0. running mean: 10.158296108111486\n",
      "resetting env. episode reward total was 15.0. running mean: 10.20671314703037\n",
      "resetting env. episode reward total was 4.0. running mean: 10.144646015560067\n",
      "resetting env. episode reward total was 5.0. running mean: 10.093199555404468\n",
      "resetting env. episode reward total was 15.0. running mean: 10.142267559850422\n",
      "resetting env. episode reward total was 13.0. running mean: 10.170844884251919\n",
      "resetting env. episode reward total was 1.0. running mean: 10.0791364354094\n",
      "resetting env. episode reward total was 17.0. running mean: 10.148345071055305\n",
      "resetting env. episode reward total was 8.0. running mean: 10.126861620344751\n",
      "resetting env. episode reward total was 17.0. running mean: 10.195593004141303\n",
      "resetting env. episode reward total was 2.0. running mean: 10.11363707409989\n",
      "resetting env. episode reward total was -9.0. running mean: 9.92250070335889\n",
      "resetting env. episode reward total was -4.0. running mean: 9.783275696325303\n",
      "resetting env. episode reward total was 15.0. running mean: 9.83544293936205\n",
      "resetting env. episode reward total was 16.0. running mean: 9.89708850996843\n",
      "resetting env. episode reward total was 6.0. running mean: 9.858117624868747\n",
      "resetting env. episode reward total was 11.0. running mean: 9.869536448620059\n",
      "resetting env. episode reward total was 11.0. running mean: 9.880841084133857\n",
      "resetting env. episode reward total was 1.0. running mean: 9.79203267329252\n",
      "resetting env. episode reward total was 1.0. running mean: 9.704112346559594\n",
      "resetting env. episode reward total was 10.0. running mean: 9.707071223093998\n",
      "resetting env. episode reward total was 7.0. running mean: 9.680000510863058\n",
      "resetting env. episode reward total was 12.0. running mean: 9.703200505754427\n",
      "resetting env. episode reward total was 12.0. running mean: 9.726168500696883\n",
      "resetting env. episode reward total was 9.0. running mean: 9.718906815689914\n",
      "resetting env. episode reward total was 13.0. running mean: 9.751717747533016\n",
      "resetting env. episode reward total was 14.0. running mean: 9.794200570057686\n",
      "resetting env. episode reward total was 9.0. running mean: 9.786258564357109\n",
      "resetting env. episode reward total was 8.0. running mean: 9.768395978713537\n",
      "resetting env. episode reward total was 18.0. running mean: 9.850712018926401\n",
      "resetting env. episode reward total was 13.0. running mean: 9.882204898737138\n",
      "resetting env. episode reward total was 14.0. running mean: 9.923382849749768\n",
      "resetting env. episode reward total was 16.0. running mean: 9.98414902125227\n",
      "resetting env. episode reward total was 6.0. running mean: 9.944307531039748\n",
      "resetting env. episode reward total was 6.0. running mean: 9.904864455729351\n",
      "resetting env. episode reward total was 8.0. running mean: 9.885815811172057\n",
      "resetting env. episode reward total was 10.0. running mean: 9.886957653060335\n",
      "resetting env. episode reward total was 13.0. running mean: 9.918088076529733\n",
      "resetting env. episode reward total was 9.0. running mean: 9.908907195764435\n",
      "resetting env. episode reward total was 14.0. running mean: 9.949818123806791\n",
      "resetting env. episode reward total was 15.0. running mean: 10.000319942568723\n",
      "resetting env. episode reward total was 11.0. running mean: 10.010316743143035\n",
      "resetting env. episode reward total was 11.0. running mean: 10.020213575711603\n",
      "resetting env. episode reward total was 15.0. running mean: 10.070011439954486\n",
      "resetting env. episode reward total was 15.0. running mean: 10.119311325554941\n",
      "resetting env. episode reward total was 9.0. running mean: 10.108118212299392\n",
      "resetting env. episode reward total was 12.0. running mean: 10.127037030176396\n",
      "resetting env. episode reward total was 4.0. running mean: 10.065766659874631\n",
      "resetting env. episode reward total was 8.0. running mean: 10.045108993275885\n",
      "resetting env. episode reward total was 9.0. running mean: 10.034657903343126\n",
      "resetting env. episode reward total was 5.0. running mean: 9.984311324309695\n",
      "resetting env. episode reward total was 9.0. running mean: 9.974468211066599\n",
      "resetting env. episode reward total was 11.0. running mean: 9.984723528955932\n",
      "resetting env. episode reward total was 7.0. running mean: 9.954876293666373\n",
      "resetting env. episode reward total was 15.0. running mean: 10.00532753072971\n",
      "resetting env. episode reward total was 9.0. running mean: 9.995274255422412\n",
      "resetting env. episode reward total was 13.0. running mean: 10.025321512868189\n",
      "resetting env. episode reward total was 12.0. running mean: 10.045068297739506\n",
      "resetting env. episode reward total was 7.0. running mean: 10.01461761476211\n",
      "resetting env. episode reward total was 4.0. running mean: 9.954471438614489\n",
      "resetting env. episode reward total was 11.0. running mean: 9.964926724228343\n",
      "resetting env. episode reward total was 3.0. running mean: 9.89527745698606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 9.886324682416198\n",
      "resetting env. episode reward total was 15.0. running mean: 9.937461435592036\n",
      "resetting env. episode reward total was 14.0. running mean: 9.978086821236117\n",
      "resetting env. episode reward total was 13.0. running mean: 10.008305953023756\n",
      "resetting env. episode reward total was 15.0. running mean: 10.058222893493518\n",
      "resetting env. episode reward total was 9.0. running mean: 10.047640664558582\n",
      "resetting env. episode reward total was 10.0. running mean: 10.047164257912996\n",
      "resetting env. episode reward total was 14.0. running mean: 10.086692615333867\n",
      "resetting env. episode reward total was 12.0. running mean: 10.105825689180527\n",
      "resetting env. episode reward total was 12.0. running mean: 10.12476743228872\n",
      "resetting env. episode reward total was 15.0. running mean: 10.173519757965833\n",
      "resetting env. episode reward total was 9.0. running mean: 10.161784560386174\n",
      "resetting env. episode reward total was 5.0. running mean: 10.110166714782313\n",
      "resetting env. episode reward total was 16.0. running mean: 10.16906504763449\n",
      "resetting env. episode reward total was 7.0. running mean: 10.137374397158146\n",
      "resetting env. episode reward total was 10.0. running mean: 10.136000653186564\n",
      "resetting env. episode reward total was 13.0. running mean: 10.164640646654698\n",
      "resetting env. episode reward total was 17.0. running mean: 10.232994240188152\n",
      "resetting env. episode reward total was 3.0. running mean: 10.16066429778627\n",
      "resetting env. episode reward total was 16.0. running mean: 10.219057654808406\n",
      "resetting env. episode reward total was 12.0. running mean: 10.236867078260321\n",
      "resetting env. episode reward total was 11.0. running mean: 10.244498407477717\n",
      "resetting env. episode reward total was 11.0. running mean: 10.25205342340294\n",
      "resetting env. episode reward total was 11.0. running mean: 10.25953288916891\n",
      "resetting env. episode reward total was 1.0. running mean: 10.16693756027722\n",
      "resetting env. episode reward total was 14.0. running mean: 10.205268184674447\n",
      "resetting env. episode reward total was 10.0. running mean: 10.203215502827701\n",
      "resetting env. episode reward total was 12.0. running mean: 10.221183347799423\n",
      "resetting env. episode reward total was 10.0. running mean: 10.218971514321428\n",
      "resetting env. episode reward total was 8.0. running mean: 10.196781799178213\n",
      "resetting env. episode reward total was 7.0. running mean: 10.16481398118643\n",
      "resetting env. episode reward total was 12.0. running mean: 10.183165841374565\n",
      "resetting env. episode reward total was 13.0. running mean: 10.21133418296082\n",
      "resetting env. episode reward total was 10.0. running mean: 10.209220841131211\n",
      "resetting env. episode reward total was 12.0. running mean: 10.227128632719898\n",
      "resetting env. episode reward total was 7.0. running mean: 10.1948573463927\n",
      "resetting env. episode reward total was 9.0. running mean: 10.182908772928773\n",
      "resetting env. episode reward total was 12.0. running mean: 10.201079685199485\n",
      "resetting env. episode reward total was 14.0. running mean: 10.239068888347491\n",
      "resetting env. episode reward total was 11.0. running mean: 10.246678199464016\n",
      "resetting env. episode reward total was 14.0. running mean: 10.284211417469377\n",
      "resetting env. episode reward total was 16.0. running mean: 10.341369303294684\n",
      "resetting env. episode reward total was 15.0. running mean: 10.387955610261738\n",
      "resetting env. episode reward total was 6.0. running mean: 10.344076054159121\n",
      "resetting env. episode reward total was 3.0. running mean: 10.270635293617529\n",
      "resetting env. episode reward total was 18.0. running mean: 10.347928940681353\n",
      "resetting env. episode reward total was 8.0. running mean: 10.32444965127454\n",
      "resetting env. episode reward total was 14.0. running mean: 10.361205154761794\n",
      "resetting env. episode reward total was 4.0. running mean: 10.297593103214176\n",
      "resetting env. episode reward total was 10.0. running mean: 10.294617172182035\n",
      "resetting env. episode reward total was -3.0. running mean: 10.161671000460215\n",
      "resetting env. episode reward total was 7.0. running mean: 10.130054290455613\n",
      "resetting env. episode reward total was 10.0. running mean: 10.128753747551055\n",
      "resetting env. episode reward total was 11.0. running mean: 10.137466210075544\n",
      "resetting env. episode reward total was 9.0. running mean: 10.126091547974788\n",
      "resetting env. episode reward total was 8.0. running mean: 10.10483063249504\n",
      "resetting env. episode reward total was 6.0. running mean: 10.06378232617009\n",
      "resetting env. episode reward total was 11.0. running mean: 10.073144502908388\n",
      "resetting env. episode reward total was 13.0. running mean: 10.102413057879305\n",
      "resetting env. episode reward total was 15.0. running mean: 10.151388927300513\n",
      "resetting env. episode reward total was 15.0. running mean: 10.199875038027507\n",
      "resetting env. episode reward total was 10.0. running mean: 10.197876287647231\n",
      "resetting env. episode reward total was 15.0. running mean: 10.24589752477076\n",
      "resetting env. episode reward total was 14.0. running mean: 10.283438549523053\n",
      "resetting env. episode reward total was 6.0. running mean: 10.240604164027824\n",
      "resetting env. episode reward total was 18.0. running mean: 10.318198122387544\n",
      "resetting env. episode reward total was 13.0. running mean: 10.34501614116367\n",
      "resetting env. episode reward total was 6.0. running mean: 10.301565979752034\n",
      "resetting env. episode reward total was 13.0. running mean: 10.328550319954514\n",
      "resetting env. episode reward total was 12.0. running mean: 10.345264816754968\n",
      "resetting env. episode reward total was 14.0. running mean: 10.381812168587418\n",
      "resetting env. episode reward total was 15.0. running mean: 10.427994046901544\n",
      "resetting env. episode reward total was 12.0. running mean: 10.443714106432529\n",
      "resetting env. episode reward total was 13.0. running mean: 10.469276965368204\n",
      "resetting env. episode reward total was 11.0. running mean: 10.47458419571452\n",
      "resetting env. episode reward total was 7.0. running mean: 10.439838353757375\n",
      "resetting env. episode reward total was 7.0. running mean: 10.405439970219803\n",
      "resetting env. episode reward total was 10.0. running mean: 10.401385570517604\n",
      "resetting env. episode reward total was 8.0. running mean: 10.377371714812428\n",
      "resetting env. episode reward total was 12.0. running mean: 10.393597997664303\n",
      "resetting env. episode reward total was 9.0. running mean: 10.379662017687659\n",
      "resetting env. episode reward total was 13.0. running mean: 10.405865397510784\n",
      "resetting env. episode reward total was 10.0. running mean: 10.401806743535676\n",
      "resetting env. episode reward total was 11.0. running mean: 10.407788676100319\n",
      "resetting env. episode reward total was 10.0. running mean: 10.403710789339316\n",
      "resetting env. episode reward total was 14.0. running mean: 10.439673681445923\n",
      "resetting env. episode reward total was 11.0. running mean: 10.445276944631463\n",
      "resetting env. episode reward total was 12.0. running mean: 10.460824175185147\n",
      "resetting env. episode reward total was 13.0. running mean: 10.486215933433296\n",
      "resetting env. episode reward total was 12.0. running mean: 10.501353774098963\n",
      "resetting env. episode reward total was 14.0. running mean: 10.536340236357974\n",
      "resetting env. episode reward total was 5.0. running mean: 10.480976833994395\n",
      "resetting env. episode reward total was 11.0. running mean: 10.48616706565445\n",
      "resetting env. episode reward total was 8.0. running mean: 10.461305394997906\n",
      "resetting env. episode reward total was 14.0. running mean: 10.496692341047927\n",
      "resetting env. episode reward total was 13.0. running mean: 10.521725417637448\n",
      "resetting env. episode reward total was 19.0. running mean: 10.606508163461074\n",
      "resetting env. episode reward total was 3.0. running mean: 10.530443081826462\n",
      "resetting env. episode reward total was 11.0. running mean: 10.535138651008197\n",
      "resetting env. episode reward total was 7.0. running mean: 10.499787264498115\n",
      "resetting env. episode reward total was 14.0. running mean: 10.534789391853135\n",
      "resetting env. episode reward total was 8.0. running mean: 10.509441497934603\n",
      "resetting env. episode reward total was 9.0. running mean: 10.494347082955256\n",
      "resetting env. episode reward total was 5.0. running mean: 10.439403612125705\n",
      "resetting env. episode reward total was 17.0. running mean: 10.505009576004449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 10.539959480244406\n",
      "resetting env. episode reward total was 11.0. running mean: 10.544559885441961\n",
      "resetting env. episode reward total was 9.0. running mean: 10.529114286587541\n",
      "resetting env. episode reward total was 15.0. running mean: 10.573823143721667\n",
      "resetting env. episode reward total was 7.0. running mean: 10.53808491228445\n",
      "resetting env. episode reward total was 14.0. running mean: 10.572704063161606\n",
      "resetting env. episode reward total was 13.0. running mean: 10.596977022529991\n",
      "resetting env. episode reward total was 15.0. running mean: 10.641007252304691\n",
      "resetting env. episode reward total was 9.0. running mean: 10.624597179781643\n",
      "resetting env. episode reward total was 5.0. running mean: 10.568351207983827\n",
      "resetting env. episode reward total was 8.0. running mean: 10.542667695903988\n",
      "resetting env. episode reward total was 5.0. running mean: 10.48724101894495\n",
      "resetting env. episode reward total was 11.0. running mean: 10.4923686087555\n",
      "resetting env. episode reward total was 11.0. running mean: 10.497444922667944\n",
      "resetting env. episode reward total was 12.0. running mean: 10.512470473441264\n",
      "resetting env. episode reward total was 12.0. running mean: 10.52734576870685\n",
      "resetting env. episode reward total was 11.0. running mean: 10.53207231101978\n",
      "resetting env. episode reward total was 11.0. running mean: 10.536751587909581\n",
      "resetting env. episode reward total was 7.0. running mean: 10.501384072030486\n",
      "resetting env. episode reward total was 9.0. running mean: 10.48637023131018\n",
      "resetting env. episode reward total was 2.0. running mean: 10.401506528997079\n",
      "resetting env. episode reward total was 8.0. running mean: 10.377491463707107\n",
      "resetting env. episode reward total was 8.0. running mean: 10.353716549070036\n",
      "resetting env. episode reward total was 14.0. running mean: 10.390179383579337\n",
      "resetting env. episode reward total was 14.0. running mean: 10.426277589743544\n",
      "resetting env. episode reward total was 15.0. running mean: 10.472014813846108\n",
      "resetting env. episode reward total was 11.0. running mean: 10.477294665707646\n",
      "resetting env. episode reward total was 5.0. running mean: 10.42252171905057\n",
      "resetting env. episode reward total was 10.0. running mean: 10.418296501860064\n",
      "resetting env. episode reward total was 7.0. running mean: 10.384113536841465\n",
      "resetting env. episode reward total was 11.0. running mean: 10.39027240147305\n",
      "resetting env. episode reward total was 12.0. running mean: 10.406369677458319\n",
      "resetting env. episode reward total was 14.0. running mean: 10.442305980683736\n",
      "resetting env. episode reward total was -1.0. running mean: 10.327882920876899\n",
      "resetting env. episode reward total was 5.0. running mean: 10.274604091668131\n",
      "resetting env. episode reward total was 9.0. running mean: 10.26185805075145\n",
      "resetting env. episode reward total was 11.0. running mean: 10.269239470243935\n",
      "resetting env. episode reward total was 10.0. running mean: 10.266547075541496\n",
      "resetting env. episode reward total was 9.0. running mean: 10.25388160478608\n",
      "resetting env. episode reward total was 12.0. running mean: 10.271342788738218\n",
      "resetting env. episode reward total was 19.0. running mean: 10.358629360850836\n",
      "resetting env. episode reward total was 5.0. running mean: 10.305043067242329\n",
      "resetting env. episode reward total was 5.0. running mean: 10.251992636569906\n",
      "resetting env. episode reward total was 10.0. running mean: 10.249472710204206\n",
      "resetting env. episode reward total was 5.0. running mean: 10.196977983102164\n",
      "resetting env. episode reward total was 7.0. running mean: 10.165008203271142\n",
      "resetting env. episode reward total was 3.0. running mean: 10.093358121238431\n",
      "resetting env. episode reward total was 13.0. running mean: 10.122424540026048\n",
      "resetting env. episode reward total was 10.0. running mean: 10.121200294625787\n",
      "resetting env. episode reward total was 11.0. running mean: 10.129988291679528\n",
      "resetting env. episode reward total was 12.0. running mean: 10.148688408762732\n",
      "resetting env. episode reward total was 14.0. running mean: 10.187201524675105\n",
      "resetting env. episode reward total was 1.0. running mean: 10.095329509428353\n",
      "resetting env. episode reward total was 4.0. running mean: 10.034376214334069\n",
      "resetting env. episode reward total was 11.0. running mean: 10.044032452190727\n",
      "resetting env. episode reward total was 9.0. running mean: 10.03359212766882\n",
      "resetting env. episode reward total was 9.0. running mean: 10.023256206392132\n",
      "resetting env. episode reward total was 9.0. running mean: 10.01302364432821\n",
      "resetting env. episode reward total was 15.0. running mean: 10.062893407884928\n",
      "resetting env. episode reward total was 9.0. running mean: 10.052264473806078\n",
      "resetting env. episode reward total was 11.0. running mean: 10.061741829068017\n",
      "resetting env. episode reward total was 8.0. running mean: 10.041124410777337\n",
      "resetting env. episode reward total was 11.0. running mean: 10.050713166669563\n",
      "resetting env. episode reward total was 13.0. running mean: 10.080206035002869\n",
      "resetting env. episode reward total was 11.0. running mean: 10.08940397465284\n",
      "resetting env. episode reward total was 12.0. running mean: 10.10850993490631\n",
      "resetting env. episode reward total was 2.0. running mean: 10.027424835557246\n",
      "resetting env. episode reward total was 10.0. running mean: 10.027150587201673\n",
      "resetting env. episode reward total was 12.0. running mean: 10.046879081329655\n",
      "resetting env. episode reward total was 9.0. running mean: 10.036410290516358\n",
      "resetting env. episode reward total was 15.0. running mean: 10.086046187611194\n",
      "resetting env. episode reward total was 16.0. running mean: 10.145185725735082\n",
      "resetting env. episode reward total was 2.0. running mean: 10.063733868477732\n",
      "resetting env. episode reward total was 16.0. running mean: 10.123096529792955\n",
      "resetting env. episode reward total was 13.0. running mean: 10.151865564495026\n",
      "resetting env. episode reward total was 16.0. running mean: 10.210346908850076\n",
      "resetting env. episode reward total was 7.0. running mean: 10.178243439761575\n",
      "resetting env. episode reward total was 11.0. running mean: 10.186461005363958\n",
      "resetting env. episode reward total was 10.0. running mean: 10.184596395310317\n",
      "resetting env. episode reward total was 4.0. running mean: 10.122750431357213\n",
      "resetting env. episode reward total was -2.0. running mean: 10.001522927043641\n",
      "resetting env. episode reward total was 4.0. running mean: 9.941507697773204\n",
      "resetting env. episode reward total was 9.0. running mean: 9.932092620795473\n",
      "resetting env. episode reward total was 11.0. running mean: 9.942771694587517\n",
      "resetting env. episode reward total was 14.0. running mean: 9.983343977641642\n",
      "resetting env. episode reward total was 2.0. running mean: 9.903510537865225\n",
      "resetting env. episode reward total was -1.0. running mean: 9.794475432486573\n",
      "resetting env. episode reward total was 7.0. running mean: 9.766530678161708\n",
      "resetting env. episode reward total was 14.0. running mean: 9.80886537138009\n",
      "resetting env. episode reward total was 1.0. running mean: 9.72077671766629\n",
      "resetting env. episode reward total was 11.0. running mean: 9.733568950489627\n",
      "resetting env. episode reward total was 11.0. running mean: 9.746233260984729\n",
      "resetting env. episode reward total was 12.0. running mean: 9.768770928374881\n",
      "resetting env. episode reward total was 8.0. running mean: 9.751083219091132\n",
      "resetting env. episode reward total was 15.0. running mean: 9.803572386900221\n",
      "resetting env. episode reward total was 4.0. running mean: 9.745536663031219\n",
      "resetting env. episode reward total was 10.0. running mean: 9.748081296400906\n",
      "resetting env. episode reward total was 10.0. running mean: 9.750600483436896\n",
      "resetting env. episode reward total was 15.0. running mean: 9.803094478602528\n",
      "resetting env. episode reward total was 12.0. running mean: 9.825063533816502\n",
      "resetting env. episode reward total was 15.0. running mean: 9.876812898478338\n",
      "resetting env. episode reward total was 8.0. running mean: 9.858044769493555\n",
      "resetting env. episode reward total was 17.0. running mean: 9.92946432179862\n",
      "resetting env. episode reward total was 11.0. running mean: 9.940169678580633\n",
      "resetting env. episode reward total was 16.0. running mean: 10.000767981794827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 10.010760301976877\n",
      "resetting env. episode reward total was 5.0. running mean: 9.960652698957109\n",
      "resetting env. episode reward total was 11.0. running mean: 9.971046171967537\n",
      "resetting env. episode reward total was 7.0. running mean: 9.941335710247861\n",
      "resetting env. episode reward total was 13.0. running mean: 9.971922353145382\n",
      "resetting env. episode reward total was 8.0. running mean: 9.95220312961393\n",
      "resetting env. episode reward total was 12.0. running mean: 9.97268109831779\n",
      "resetting env. episode reward total was 8.0. running mean: 9.952954287334611\n",
      "resetting env. episode reward total was 7.0. running mean: 9.923424744461265\n",
      "resetting env. episode reward total was 15.0. running mean: 9.974190497016652\n",
      "resetting env. episode reward total was 4.0. running mean: 9.914448592046485\n",
      "resetting env. episode reward total was -7.0. running mean: 9.745304106126019\n",
      "resetting env. episode reward total was 8.0. running mean: 9.727851065064758\n",
      "resetting env. episode reward total was 11.0. running mean: 9.74057255441411\n",
      "resetting env. episode reward total was 4.0. running mean: 9.683166828869968\n",
      "resetting env. episode reward total was 14.0. running mean: 9.72633516058127\n",
      "resetting env. episode reward total was 6.0. running mean: 9.689071808975458\n",
      "resetting env. episode reward total was 3.0. running mean: 9.622181090885702\n",
      "resetting env. episode reward total was 8.0. running mean: 9.605959279976846\n",
      "resetting env. episode reward total was 16.0. running mean: 9.669899687177077\n",
      "resetting env. episode reward total was 12.0. running mean: 9.693200690305305\n",
      "resetting env. episode reward total was 6.0. running mean: 9.656268683402253\n",
      "resetting env. episode reward total was 12.0. running mean: 9.679705996568229\n",
      "resetting env. episode reward total was 9.0. running mean: 9.672908936602546\n",
      "resetting env. episode reward total was 8.0. running mean: 9.65617984723652\n",
      "resetting env. episode reward total was 2.0. running mean: 9.579618048764155\n",
      "resetting env. episode reward total was 6.0. running mean: 9.543821868276515\n",
      "resetting env. episode reward total was 16.0. running mean: 9.60838364959375\n",
      "resetting env. episode reward total was 1.0. running mean: 9.522299813097812\n",
      "resetting env. episode reward total was 18.0. running mean: 9.607076814966833\n",
      "resetting env. episode reward total was 13.0. running mean: 9.641006046817166\n",
      "resetting env. episode reward total was 9.0. running mean: 9.634595986348995\n",
      "resetting env. episode reward total was 4.0. running mean: 9.578250026485504\n",
      "resetting env. episode reward total was 9.0. running mean: 9.572467526220649\n",
      "resetting env. episode reward total was 14.0. running mean: 9.616742850958444\n",
      "resetting env. episode reward total was 13.0. running mean: 9.65057542244886\n",
      "resetting env. episode reward total was 10.0. running mean: 9.654069668224372\n",
      "resetting env. episode reward total was 13.0. running mean: 9.687528971542129\n",
      "resetting env. episode reward total was 11.0. running mean: 9.700653681826706\n",
      "resetting env. episode reward total was 11.0. running mean: 9.713647145008439\n",
      "resetting env. episode reward total was 7.0. running mean: 9.686510673558354\n",
      "resetting env. episode reward total was 16.0. running mean: 9.749645566822771\n",
      "resetting env. episode reward total was 7.0. running mean: 9.722149111154543\n",
      "resetting env. episode reward total was 7.0. running mean: 9.694927620042998\n",
      "resetting env. episode reward total was 3.0. running mean: 9.627978343842567\n",
      "resetting env. episode reward total was 10.0. running mean: 9.631698560404141\n",
      "resetting env. episode reward total was 9.0. running mean: 9.6253815748001\n",
      "resetting env. episode reward total was 2.0. running mean: 9.549127759052098\n",
      "resetting env. episode reward total was 15.0. running mean: 9.603636481461578\n",
      "resetting env. episode reward total was 6.0. running mean: 9.567600116646963\n",
      "resetting env. episode reward total was 5.0. running mean: 9.521924115480493\n",
      "resetting env. episode reward total was 9.0. running mean: 9.516704874325688\n",
      "resetting env. episode reward total was 12.0. running mean: 9.54153782558243\n",
      "resetting env. episode reward total was 11.0. running mean: 9.556122447326606\n",
      "resetting env. episode reward total was 11.0. running mean: 9.570561222853339\n",
      "resetting env. episode reward total was 9.0. running mean: 9.564855610624805\n",
      "resetting env. episode reward total was 4.0. running mean: 9.509207054518557\n",
      "resetting env. episode reward total was 14.0. running mean: 9.554114983973372\n",
      "resetting env. episode reward total was 10.0. running mean: 9.558573834133638\n",
      "resetting env. episode reward total was 11.0. running mean: 9.5729880957923\n",
      "resetting env. episode reward total was 13.0. running mean: 9.607258214834378\n",
      "resetting env. episode reward total was 9.0. running mean: 9.601185632686034\n",
      "resetting env. episode reward total was 9.0. running mean: 9.595173776359173\n",
      "resetting env. episode reward total was 18.0. running mean: 9.679222038595581\n",
      "resetting env. episode reward total was 13.0. running mean: 9.712429818209626\n",
      "resetting env. episode reward total was 11.0. running mean: 9.72530552002753\n",
      "resetting env. episode reward total was 12.0. running mean: 9.748052464827254\n",
      "resetting env. episode reward total was 12.0. running mean: 9.77057194017898\n",
      "resetting env. episode reward total was 7.0. running mean: 9.742866220777191\n",
      "resetting env. episode reward total was 12.0. running mean: 9.765437558569419\n",
      "resetting env. episode reward total was 8.0. running mean: 9.747783182983724\n",
      "resetting env. episode reward total was 3.0. running mean: 9.680305351153887\n",
      "resetting env. episode reward total was 9.0. running mean: 9.673502297642347\n",
      "resetting env. episode reward total was 15.0. running mean: 9.726767274665924\n",
      "resetting env. episode reward total was 15.0. running mean: 9.779499601919266\n",
      "resetting env. episode reward total was 13.0. running mean: 9.811704605900074\n",
      "resetting env. episode reward total was 3.0. running mean: 9.743587559841073\n",
      "resetting env. episode reward total was 9.0. running mean: 9.736151684242662\n",
      "resetting env. episode reward total was 15.0. running mean: 9.788790167400236\n",
      "resetting env. episode reward total was 12.0. running mean: 9.810902265726233\n",
      "resetting env. episode reward total was 11.0. running mean: 9.82279324306897\n",
      "resetting env. episode reward total was 4.0. running mean: 9.764565310638279\n",
      "resetting env. episode reward total was 6.0. running mean: 9.726919657531896\n",
      "resetting env. episode reward total was 16.0. running mean: 9.789650460956578\n",
      "resetting env. episode reward total was 11.0. running mean: 9.801753956347012\n",
      "resetting env. episode reward total was -1.0. running mean: 9.693736416783542\n",
      "resetting env. episode reward total was 14.0. running mean: 9.736799052615707\n",
      "resetting env. episode reward total was 12.0. running mean: 9.759431062089549\n",
      "resetting env. episode reward total was 18.0. running mean: 9.841836751468653\n",
      "resetting env. episode reward total was 12.0. running mean: 9.863418383953967\n",
      "resetting env. episode reward total was 11.0. running mean: 9.874784200114426\n",
      "resetting env. episode reward total was 9.0. running mean: 9.866036358113282\n",
      "resetting env. episode reward total was 8.0. running mean: 9.84737599453215\n",
      "resetting env. episode reward total was 8.0. running mean: 9.82890223458683\n",
      "resetting env. episode reward total was 12.0. running mean: 9.85061321224096\n",
      "resetting env. episode reward total was 14.0. running mean: 9.892107080118551\n",
      "resetting env. episode reward total was 16.0. running mean: 9.953186009317365\n",
      "resetting env. episode reward total was 16.0. running mean: 10.013654149224191\n",
      "resetting env. episode reward total was 9.0. running mean: 10.003517607731949\n",
      "resetting env. episode reward total was 15.0. running mean: 10.05348243165463\n",
      "resetting env. episode reward total was 16.0. running mean: 10.112947607338082\n",
      "resetting env. episode reward total was 10.0. running mean: 10.111818131264702\n",
      "resetting env. episode reward total was 6.0. running mean: 10.070699949952056\n",
      "resetting env. episode reward total was 11.0. running mean: 10.079992950452535\n",
      "resetting env. episode reward total was 6.0. running mean: 10.03919302094801\n",
      "resetting env. episode reward total was 10.0. running mean: 10.03880109073853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 10.068413079831146\n",
      "resetting env. episode reward total was 3.0. running mean: 9.997728949032833\n",
      "resetting env. episode reward total was 7.0. running mean: 9.967751659542506\n",
      "resetting env. episode reward total was 13.0. running mean: 9.99807414294708\n",
      "resetting env. episode reward total was 11.0. running mean: 10.008093401517609\n",
      "resetting env. episode reward total was 4.0. running mean: 9.948012467502432\n",
      "resetting env. episode reward total was -3.0. running mean: 9.818532342827408\n",
      "resetting env. episode reward total was 13.0. running mean: 9.850347019399136\n",
      "resetting env. episode reward total was 10.0. running mean: 9.851843549205144\n",
      "resetting env. episode reward total was 12.0. running mean: 9.873325113713092\n",
      "resetting env. episode reward total was 14.0. running mean: 9.91459186257596\n",
      "resetting env. episode reward total was 18.0. running mean: 9.9954459439502\n",
      "resetting env. episode reward total was 8.0. running mean: 9.975491484510698\n",
      "resetting env. episode reward total was 10.0. running mean: 9.97573656966559\n",
      "resetting env. episode reward total was 6.0. running mean: 9.935979203968936\n",
      "resetting env. episode reward total was 5.0. running mean: 9.886619411929248\n",
      "resetting env. episode reward total was 7.0. running mean: 9.857753217809956\n",
      "resetting env. episode reward total was 11.0. running mean: 9.869175685631856\n",
      "resetting env. episode reward total was 10.0. running mean: 9.870483928775537\n",
      "resetting env. episode reward total was 12.0. running mean: 9.89177908948778\n",
      "resetting env. episode reward total was 9.0. running mean: 9.882861298592902\n",
      "resetting env. episode reward total was 16.0. running mean: 9.944032685606972\n",
      "resetting env. episode reward total was 5.0. running mean: 9.894592358750902\n",
      "resetting env. episode reward total was 4.0. running mean: 9.835646435163392\n",
      "resetting env. episode reward total was 9.0. running mean: 9.827289970811758\n",
      "resetting env. episode reward total was 8.0. running mean: 9.809017071103641\n",
      "resetting env. episode reward total was 13.0. running mean: 9.840926900392605\n",
      "resetting env. episode reward total was 12.0. running mean: 9.862517631388677\n",
      "resetting env. episode reward total was 10.0. running mean: 9.86389245507479\n",
      "resetting env. episode reward total was 16.0. running mean: 9.925253530524042\n",
      "resetting env. episode reward total was 12.0. running mean: 9.946000995218801\n",
      "resetting env. episode reward total was 8.0. running mean: 9.926540985266612\n",
      "resetting env. episode reward total was 8.0. running mean: 9.907275575413946\n",
      "resetting env. episode reward total was 6.0. running mean: 9.868202819659807\n",
      "resetting env. episode reward total was 11.0. running mean: 9.879520791463207\n",
      "resetting env. episode reward total was 9.0. running mean: 9.870725583548575\n",
      "resetting env. episode reward total was 11.0. running mean: 9.882018327713089\n",
      "resetting env. episode reward total was 13.0. running mean: 9.91319814443596\n",
      "resetting env. episode reward total was 12.0. running mean: 9.934066162991599\n",
      "resetting env. episode reward total was 10.0. running mean: 9.934725501361681\n",
      "resetting env. episode reward total was 11.0. running mean: 9.945378246348064\n",
      "resetting env. episode reward total was 4.0. running mean: 9.885924463884582\n",
      "resetting env. episode reward total was 10.0. running mean: 9.887065219245736\n",
      "resetting env. episode reward total was 11.0. running mean: 9.898194567053277\n",
      "resetting env. episode reward total was 15.0. running mean: 9.949212621382745\n",
      "resetting env. episode reward total was 8.0. running mean: 9.929720495168917\n",
      "resetting env. episode reward total was 14.0. running mean: 9.970423290217228\n",
      "resetting env. episode reward total was 10.0. running mean: 9.970719057315055\n",
      "resetting env. episode reward total was 14.0. running mean: 10.011011866741905\n",
      "resetting env. episode reward total was 13.0. running mean: 10.040901748074486\n",
      "resetting env. episode reward total was 11.0. running mean: 10.05049273059374\n",
      "resetting env. episode reward total was 9.0. running mean: 10.039987803287802\n",
      "resetting env. episode reward total was 14.0. running mean: 10.079587925254925\n",
      "resetting env. episode reward total was 12.0. running mean: 10.098792046002375\n",
      "resetting env. episode reward total was 12.0. running mean: 10.11780412554235\n",
      "resetting env. episode reward total was 9.0. running mean: 10.106626084286926\n",
      "resetting env. episode reward total was 7.0. running mean: 10.075559823444058\n",
      "resetting env. episode reward total was 11.0. running mean: 10.084804225209616\n",
      "resetting env. episode reward total was 8.0. running mean: 10.06395618295752\n",
      "resetting env. episode reward total was 8.0. running mean: 10.043316621127945\n",
      "resetting env. episode reward total was 20.0. running mean: 10.142883454916664\n",
      "resetting env. episode reward total was 1.0. running mean: 10.051454620367497\n",
      "resetting env. episode reward total was 5.0. running mean: 10.000940074163823\n",
      "resetting env. episode reward total was 14.0. running mean: 10.040930673422185\n",
      "resetting env. episode reward total was 11.0. running mean: 10.050521366687963\n",
      "resetting env. episode reward total was -1.0. running mean: 9.940016153021084\n",
      "resetting env. episode reward total was 13.0. running mean: 9.970615991490874\n",
      "resetting env. episode reward total was 13.0. running mean: 10.000909831575965\n",
      "resetting env. episode reward total was 13.0. running mean: 10.030900733260207\n",
      "resetting env. episode reward total was 12.0. running mean: 10.050591725927605\n",
      "resetting env. episode reward total was 12.0. running mean: 10.070085808668328\n",
      "resetting env. episode reward total was 10.0. running mean: 10.069384950581643\n",
      "resetting env. episode reward total was 13.0. running mean: 10.098691101075827\n",
      "resetting env. episode reward total was 12.0. running mean: 10.117704190065067\n",
      "resetting env. episode reward total was 13.0. running mean: 10.146527148164418\n",
      "resetting env. episode reward total was 9.0. running mean: 10.135061876682775\n",
      "resetting env. episode reward total was 15.0. running mean: 10.183711257915947\n",
      "resetting env. episode reward total was 13.0. running mean: 10.211874145336788\n",
      "resetting env. episode reward total was 9.0. running mean: 10.199755403883419\n",
      "resetting env. episode reward total was 2.0. running mean: 10.117757849844583\n",
      "resetting env. episode reward total was 11.0. running mean: 10.126580271346137\n",
      "resetting env. episode reward total was 5.0. running mean: 10.075314468632676\n",
      "resetting env. episode reward total was 14.0. running mean: 10.11456132394635\n",
      "resetting env. episode reward total was 11.0. running mean: 10.123415710706887\n",
      "resetting env. episode reward total was 12.0. running mean: 10.142181553599817\n",
      "resetting env. episode reward total was 5.0. running mean: 10.09075973806382\n",
      "resetting env. episode reward total was 18.0. running mean: 10.169852140683181\n",
      "resetting env. episode reward total was 8.0. running mean: 10.14815361927635\n",
      "resetting env. episode reward total was 1.0. running mean: 10.056672083083587\n",
      "resetting env. episode reward total was 12.0. running mean: 10.07610536225275\n",
      "resetting env. episode reward total was 11.0. running mean: 10.085344308630223\n",
      "resetting env. episode reward total was 11.0. running mean: 10.09449086554392\n",
      "resetting env. episode reward total was 12.0. running mean: 10.11354595688848\n",
      "resetting env. episode reward total was 14.0. running mean: 10.152410497319595\n",
      "resetting env. episode reward total was -3.0. running mean: 10.0208863923464\n",
      "resetting env. episode reward total was 7.0. running mean: 9.990677528422935\n",
      "resetting env. episode reward total was 6.0. running mean: 9.950770753138707\n",
      "resetting env. episode reward total was 8.0. running mean: 9.93126304560732\n",
      "resetting env. episode reward total was 10.0. running mean: 9.931950415151247\n",
      "resetting env. episode reward total was 6.0. running mean: 9.892630910999735\n",
      "resetting env. episode reward total was 13.0. running mean: 9.923704601889739\n",
      "resetting env. episode reward total was 11.0. running mean: 9.93446755587084\n",
      "resetting env. episode reward total was 15.0. running mean: 9.985122880312133\n",
      "resetting env. episode reward total was 5.0. running mean: 9.935271651509012\n",
      "resetting env. episode reward total was 4.0. running mean: 9.875918934993921\n",
      "resetting env. episode reward total was 10.0. running mean: 9.877159745643981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 9.918388148187542\n",
      "resetting env. episode reward total was 13.0. running mean: 9.949204266705667\n",
      "resetting env. episode reward total was 14.0. running mean: 9.98971222403861\n",
      "resetting env. episode reward total was 9.0. running mean: 9.979815101798224\n",
      "resetting env. episode reward total was 10.0. running mean: 9.980016950780241\n",
      "resetting env. episode reward total was 15.0. running mean: 10.03021678127244\n",
      "resetting env. episode reward total was 11.0. running mean: 10.039914613459715\n",
      "resetting env. episode reward total was 15.0. running mean: 10.089515467325118\n",
      "resetting env. episode reward total was 13.0. running mean: 10.118620312651867\n",
      "resetting env. episode reward total was 20.0. running mean: 10.217434109525348\n",
      "resetting env. episode reward total was -1.0. running mean: 10.105259768430095\n",
      "resetting env. episode reward total was 13.0. running mean: 10.134207170745794\n",
      "resetting env. episode reward total was 11.0. running mean: 10.142865099038335\n",
      "resetting env. episode reward total was 17.0. running mean: 10.211436448047952\n",
      "resetting env. episode reward total was 10.0. running mean: 10.209322083567471\n",
      "resetting env. episode reward total was 7.0. running mean: 10.177228862731797\n",
      "resetting env. episode reward total was 14.0. running mean: 10.21545657410448\n",
      "resetting env. episode reward total was 4.0. running mean: 10.153302008363433\n",
      "resetting env. episode reward total was 10.0. running mean: 10.151768988279798\n",
      "resetting env. episode reward total was 4.0. running mean: 10.090251298397\n",
      "resetting env. episode reward total was 12.0. running mean: 10.10934878541303\n",
      "resetting env. episode reward total was 3.0. running mean: 10.038255297558898\n",
      "resetting env. episode reward total was -5.0. running mean: 9.887872744583309\n",
      "resetting env. episode reward total was 7.0. running mean: 9.858994017137476\n",
      "resetting env. episode reward total was 8.0. running mean: 9.840404076966102\n",
      "resetting env. episode reward total was 8.0. running mean: 9.82200003619644\n",
      "resetting env. episode reward total was 14.0. running mean: 9.863780035834477\n",
      "resetting env. episode reward total was 10.0. running mean: 9.865142235476132\n",
      "resetting env. episode reward total was 14.0. running mean: 9.906490813121371\n",
      "resetting env. episode reward total was 2.0. running mean: 9.827425904990157\n",
      "resetting env. episode reward total was 4.0. running mean: 9.769151645940255\n",
      "resetting env. episode reward total was 1.0. running mean: 9.681460129480852\n",
      "resetting env. episode reward total was 8.0. running mean: 9.664645528186044\n",
      "resetting env. episode reward total was 10.0. running mean: 9.667999072904184\n",
      "resetting env. episode reward total was 11.0. running mean: 9.681319082175142\n",
      "resetting env. episode reward total was 9.0. running mean: 9.67450589135339\n",
      "resetting env. episode reward total was 8.0. running mean: 9.657760832439855\n",
      "resetting env. episode reward total was 16.0. running mean: 9.721183224115457\n",
      "resetting env. episode reward total was 11.0. running mean: 9.733971391874302\n",
      "resetting env. episode reward total was 14.0. running mean: 9.77663167795556\n",
      "resetting env. episode reward total was 10.0. running mean: 9.778865361176004\n",
      "resetting env. episode reward total was 9.0. running mean: 9.771076707564244\n",
      "resetting env. episode reward total was 10.0. running mean: 9.7733659404886\n",
      "resetting env. episode reward total was 11.0. running mean: 9.785632281083714\n",
      "resetting env. episode reward total was 5.0. running mean: 9.737775958272877\n",
      "resetting env. episode reward total was 7.0. running mean: 9.710398198690148\n",
      "resetting env. episode reward total was 16.0. running mean: 9.773294216703247\n",
      "resetting env. episode reward total was 11.0. running mean: 9.785561274536214\n",
      "resetting env. episode reward total was 7.0. running mean: 9.757705661790851\n",
      "resetting env. episode reward total was 14.0. running mean: 9.800128605172944\n",
      "resetting env. episode reward total was 13.0. running mean: 9.832127319121215\n",
      "resetting env. episode reward total was 5.0. running mean: 9.783806045930003\n",
      "resetting env. episode reward total was 16.0. running mean: 9.845967985470702\n",
      "resetting env. episode reward total was 15.0. running mean: 9.897508305615995\n",
      "resetting env. episode reward total was 8.0. running mean: 9.878533222559835\n",
      "resetting env. episode reward total was 1.0. running mean: 9.789747890334237\n",
      "resetting env. episode reward total was 11.0. running mean: 9.801850411430893\n",
      "resetting env. episode reward total was 12.0. running mean: 9.823831907316583\n",
      "resetting env. episode reward total was 10.0. running mean: 9.825593588243416\n",
      "resetting env. episode reward total was 10.0. running mean: 9.827337652360981\n",
      "resetting env. episode reward total was 4.0. running mean: 9.769064275837371\n",
      "resetting env. episode reward total was 14.0. running mean: 9.811373633078997\n",
      "resetting env. episode reward total was 9.0. running mean: 9.803259896748207\n",
      "resetting env. episode reward total was 4.0. running mean: 9.745227297780724\n",
      "resetting env. episode reward total was 6.0. running mean: 9.707775024802917\n",
      "resetting env. episode reward total was 10.0. running mean: 9.710697274554887\n",
      "resetting env. episode reward total was 15.0. running mean: 9.763590301809339\n",
      "resetting env. episode reward total was 13.0. running mean: 9.795954398791247\n",
      "resetting env. episode reward total was 13.0. running mean: 9.827994854803336\n",
      "resetting env. episode reward total was 14.0. running mean: 9.869714906255304\n",
      "resetting env. episode reward total was 7.0. running mean: 9.84101775719275\n",
      "resetting env. episode reward total was 14.0. running mean: 9.882607579620823\n",
      "resetting env. episode reward total was 16.0. running mean: 9.943781503824614\n",
      "resetting env. episode reward total was 7.0. running mean: 9.914343688786367\n",
      "resetting env. episode reward total was 10.0. running mean: 9.915200251898503\n",
      "resetting env. episode reward total was 8.0. running mean: 9.896048249379518\n",
      "resetting env. episode reward total was 9.0. running mean: 9.887087766885722\n",
      "resetting env. episode reward total was 2.0. running mean: 9.808216889216865\n",
      "resetting env. episode reward total was 14.0. running mean: 9.850134720324697\n",
      "resetting env. episode reward total was 16.0. running mean: 9.91163337312145\n",
      "resetting env. episode reward total was 13.0. running mean: 9.942517039390237\n",
      "resetting env. episode reward total was 14.0. running mean: 9.983091868996336\n",
      "resetting env. episode reward total was 12.0. running mean: 10.003260950306371\n",
      "resetting env. episode reward total was 6.0. running mean: 9.963228340803308\n",
      "resetting env. episode reward total was 13.0. running mean: 9.993596057395276\n",
      "resetting env. episode reward total was 9.0. running mean: 9.983660096821323\n",
      "resetting env. episode reward total was 15.0. running mean: 10.03382349585311\n",
      "resetting env. episode reward total was 17.0. running mean: 10.103485260894578\n",
      "resetting env. episode reward total was 11.0. running mean: 10.112450408285632\n",
      "resetting env. episode reward total was 2.0. running mean: 10.031325904202776\n",
      "resetting env. episode reward total was 3.0. running mean: 9.961012645160746\n",
      "resetting env. episode reward total was 6.0. running mean: 9.92140251870914\n",
      "resetting env. episode reward total was 2.0. running mean: 9.842188493522048\n",
      "resetting env. episode reward total was 18.0. running mean: 9.923766608586828\n",
      "resetting env. episode reward total was 9.0. running mean: 9.91452894250096\n",
      "resetting env. episode reward total was 12.0. running mean: 9.935383653075949\n",
      "resetting env. episode reward total was 14.0. running mean: 9.97602981654519\n",
      "resetting env. episode reward total was 10.0. running mean: 9.976269518379738\n",
      "resetting env. episode reward total was 13.0. running mean: 10.006506823195942\n",
      "resetting env. episode reward total was 8.0. running mean: 9.986441754963982\n",
      "resetting env. episode reward total was 8.0. running mean: 9.966577337414343\n",
      "resetting env. episode reward total was 17.0. running mean: 10.0369115640402\n",
      "resetting env. episode reward total was 14.0. running mean: 10.076542448399797\n",
      "resetting env. episode reward total was 15.0. running mean: 10.1257770239158\n",
      "resetting env. episode reward total was 12.0. running mean: 10.144519253676641\n",
      "resetting env. episode reward total was 15.0. running mean: 10.193074061139875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 10.231143320528476\n",
      "resetting env. episode reward total was 12.0. running mean: 10.24883188732319\n",
      "resetting env. episode reward total was 3.0. running mean: 10.176343568449957\n",
      "resetting env. episode reward total was 10.0. running mean: 10.174580132765456\n",
      "resetting env. episode reward total was 3.0. running mean: 10.102834331437801\n",
      "resetting env. episode reward total was 6.0. running mean: 10.061805988123425\n",
      "resetting env. episode reward total was 14.0. running mean: 10.10118792824219\n",
      "resetting env. episode reward total was 10.0. running mean: 10.100176048959767\n",
      "resetting env. episode reward total was 14.0. running mean: 10.13917428847017\n",
      "resetting env. episode reward total was 8.0. running mean: 10.117782545585467\n",
      "resetting env. episode reward total was 17.0. running mean: 10.186604720129612\n",
      "resetting env. episode reward total was 18.0. running mean: 10.264738672928315\n",
      "resetting env. episode reward total was 6.0. running mean: 10.222091286199033\n",
      "resetting env. episode reward total was 10.0. running mean: 10.219870373337042\n",
      "resetting env. episode reward total was 10.0. running mean: 10.217671669603671\n",
      "resetting env. episode reward total was 5.0. running mean: 10.165494952907634\n",
      "resetting env. episode reward total was 6.0. running mean: 10.12384000337856\n",
      "resetting env. episode reward total was 13.0. running mean: 10.152601603344774\n",
      "resetting env. episode reward total was 13.0. running mean: 10.181075587311327\n",
      "resetting env. episode reward total was 11.0. running mean: 10.189264831438212\n",
      "resetting env. episode reward total was 15.0. running mean: 10.23737218312383\n",
      "resetting env. episode reward total was 5.0. running mean: 10.184998461292592\n",
      "resetting env. episode reward total was 6.0. running mean: 10.143148476679666\n",
      "resetting env. episode reward total was 12.0. running mean: 10.161716991912868\n",
      "resetting env. episode reward total was 20.0. running mean: 10.26009982199374\n",
      "resetting env. episode reward total was 7.0. running mean: 10.227498823773802\n",
      "resetting env. episode reward total was 12.0. running mean: 10.245223835536063\n",
      "resetting env. episode reward total was 10.0. running mean: 10.242771597180703\n",
      "resetting env. episode reward total was 12.0. running mean: 10.260343881208895\n",
      "resetting env. episode reward total was 13.0. running mean: 10.287740442396807\n",
      "resetting env. episode reward total was 5.0. running mean: 10.23486303797284\n",
      "resetting env. episode reward total was 9.0. running mean: 10.222514407593112\n",
      "resetting env. episode reward total was 12.0. running mean: 10.24028926351718\n",
      "resetting env. episode reward total was 8.0. running mean: 10.217886370882008\n",
      "resetting env. episode reward total was 2.0. running mean: 10.135707507173187\n",
      "resetting env. episode reward total was 17.0. running mean: 10.204350432101455\n",
      "resetting env. episode reward total was 12.0. running mean: 10.222306927780439\n",
      "resetting env. episode reward total was 12.0. running mean: 10.240083858502633\n",
      "resetting env. episode reward total was 10.0. running mean: 10.237683019917606\n",
      "resetting env. episode reward total was 10.0. running mean: 10.235306189718429\n",
      "resetting env. episode reward total was 6.0. running mean: 10.192953127821244\n",
      "resetting env. episode reward total was 17.0. running mean: 10.261023596543032\n",
      "resetting env. episode reward total was 8.0. running mean: 10.238413360577601\n",
      "resetting env. episode reward total was 8.0. running mean: 10.216029226971825\n",
      "resetting env. episode reward total was 13.0. running mean: 10.243868934702107\n",
      "resetting env. episode reward total was 16.0. running mean: 10.301430245355085\n",
      "resetting env. episode reward total was 14.0. running mean: 10.338415942901536\n",
      "resetting env. episode reward total was 15.0. running mean: 10.38503178347252\n",
      "resetting env. episode reward total was 15.0. running mean: 10.431181465637795\n",
      "resetting env. episode reward total was 11.0. running mean: 10.436869650981416\n",
      "resetting env. episode reward total was 15.0. running mean: 10.482500954471602\n",
      "resetting env. episode reward total was 1.0. running mean: 10.387675944926885\n",
      "resetting env. episode reward total was 10.0. running mean: 10.383799185477615\n",
      "resetting env. episode reward total was 14.0. running mean: 10.41996119362284\n",
      "resetting env. episode reward total was 10.0. running mean: 10.41576158168661\n",
      "resetting env. episode reward total was 8.0. running mean: 10.391603965869743\n",
      "resetting env. episode reward total was 12.0. running mean: 10.407687926211045\n",
      "resetting env. episode reward total was 14.0. running mean: 10.443611046948934\n",
      "resetting env. episode reward total was 11.0. running mean: 10.449174936479444\n",
      "resetting env. episode reward total was 15.0. running mean: 10.494683187114651\n",
      "resetting env. episode reward total was 16.0. running mean: 10.549736355243505\n",
      "resetting env. episode reward total was -5.0. running mean: 10.394238991691068\n",
      "resetting env. episode reward total was 12.0. running mean: 10.410296601774156\n",
      "resetting env. episode reward total was 4.0. running mean: 10.346193635756414\n",
      "resetting env. episode reward total was 10.0. running mean: 10.342731699398849\n",
      "resetting env. episode reward total was 11.0. running mean: 10.34930438240486\n",
      "resetting env. episode reward total was 12.0. running mean: 10.36581133858081\n",
      "resetting env. episode reward total was 7.0. running mean: 10.332153225195002\n",
      "resetting env. episode reward total was 5.0. running mean: 10.278831692943053\n",
      "resetting env. episode reward total was 18.0. running mean: 10.356043376013622\n",
      "resetting env. episode reward total was 7.0. running mean: 10.322482942253485\n",
      "resetting env. episode reward total was 16.0. running mean: 10.37925811283095\n",
      "resetting env. episode reward total was 4.0. running mean: 10.315465531702639\n",
      "resetting env. episode reward total was 15.0. running mean: 10.362310876385612\n",
      "resetting env. episode reward total was 14.0. running mean: 10.398687767621757\n",
      "resetting env. episode reward total was 7.0. running mean: 10.36470088994554\n",
      "resetting env. episode reward total was 13.0. running mean: 10.391053881046085\n",
      "resetting env. episode reward total was 14.0. running mean: 10.427143342235626\n",
      "resetting env. episode reward total was 12.0. running mean: 10.442871908813268\n",
      "resetting env. episode reward total was 13.0. running mean: 10.468443189725136\n",
      "resetting env. episode reward total was 9.0. running mean: 10.453758757827885\n",
      "resetting env. episode reward total was 3.0. running mean: 10.379221170249606\n",
      "resetting env. episode reward total was 8.0. running mean: 10.35542895854711\n",
      "resetting env. episode reward total was 3.0. running mean: 10.281874668961638\n",
      "resetting env. episode reward total was 11.0. running mean: 10.289055922272022\n",
      "resetting env. episode reward total was 1.0. running mean: 10.196165363049301\n",
      "resetting env. episode reward total was 18.0. running mean: 10.274203709418808\n",
      "resetting env. episode reward total was 14.0. running mean: 10.31146167232462\n",
      "resetting env. episode reward total was 8.0. running mean: 10.288347055601374\n",
      "resetting env. episode reward total was 16.0. running mean: 10.34546358504536\n",
      "resetting env. episode reward total was 16.0. running mean: 10.402008949194906\n",
      "resetting env. episode reward total was 8.0. running mean: 10.377988859702958\n",
      "resetting env. episode reward total was 9.0. running mean: 10.364208971105928\n",
      "resetting env. episode reward total was 10.0. running mean: 10.360566881394869\n",
      "resetting env. episode reward total was 9.0. running mean: 10.34696121258092\n",
      "resetting env. episode reward total was 16.0. running mean: 10.40349160045511\n",
      "resetting env. episode reward total was 17.0. running mean: 10.46945668445056\n",
      "resetting env. episode reward total was 8.0. running mean: 10.444762117606054\n",
      "resetting env. episode reward total was 2.0. running mean: 10.360314496429993\n",
      "resetting env. episode reward total was 9.0. running mean: 10.346711351465693\n",
      "resetting env. episode reward total was 13.0. running mean: 10.373244237951036\n",
      "resetting env. episode reward total was 6.0. running mean: 10.329511795571527\n",
      "resetting env. episode reward total was 12.0. running mean: 10.34621667761581\n",
      "resetting env. episode reward total was 7.0. running mean: 10.312754510839653\n",
      "resetting env. episode reward total was 10.0. running mean: 10.309626965731256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 10.346530696073945\n",
      "resetting env. episode reward total was 14.0. running mean: 10.383065389113206\n",
      "resetting env. episode reward total was 6.0. running mean: 10.339234735222075\n",
      "resetting env. episode reward total was 13.0. running mean: 10.365842387869854\n",
      "resetting env. episode reward total was 11.0. running mean: 10.372183963991155\n",
      "resetting env. episode reward total was 7.0. running mean: 10.338462124351244\n",
      "resetting env. episode reward total was 12.0. running mean: 10.355077503107731\n",
      "resetting env. episode reward total was 15.0. running mean: 10.401526728076654\n",
      "resetting env. episode reward total was 6.0. running mean: 10.357511460795887\n",
      "resetting env. episode reward total was 13.0. running mean: 10.383936346187928\n",
      "resetting env. episode reward total was 9.0. running mean: 10.370096982726048\n",
      "resetting env. episode reward total was 6.0. running mean: 10.326396012898789\n",
      "resetting env. episode reward total was 16.0. running mean: 10.3831320527698\n",
      "resetting env. episode reward total was 15.0. running mean: 10.429300732242103\n",
      "resetting env. episode reward total was 12.0. running mean: 10.44500772491968\n",
      "resetting env. episode reward total was 11.0. running mean: 10.450557647670482\n",
      "resetting env. episode reward total was 11.0. running mean: 10.456052071193778\n",
      "resetting env. episode reward total was 10.0. running mean: 10.451491550481839\n",
      "resetting env. episode reward total was 2.0. running mean: 10.36697663497702\n",
      "resetting env. episode reward total was 11.0. running mean: 10.37330686862725\n",
      "resetting env. episode reward total was 9.0. running mean: 10.359573799940977\n",
      "resetting env. episode reward total was 7.0. running mean: 10.325978061941568\n",
      "resetting env. episode reward total was 4.0. running mean: 10.262718281322151\n",
      "resetting env. episode reward total was 9.0. running mean: 10.250091098508928\n",
      "resetting env. episode reward total was 15.0. running mean: 10.29759018752384\n",
      "resetting env. episode reward total was 18.0. running mean: 10.374614285648601\n",
      "resetting env. episode reward total was 10.0. running mean: 10.370868142792114\n",
      "resetting env. episode reward total was 12.0. running mean: 10.387159461364192\n",
      "resetting env. episode reward total was 9.0. running mean: 10.37328786675055\n",
      "resetting env. episode reward total was 5.0. running mean: 10.319554988083045\n",
      "resetting env. episode reward total was 11.0. running mean: 10.326359438202214\n",
      "resetting env. episode reward total was 8.0. running mean: 10.303095843820191\n",
      "resetting env. episode reward total was 18.0. running mean: 10.380064885381989\n",
      "resetting env. episode reward total was 12.0. running mean: 10.396264236528168\n",
      "resetting env. episode reward total was 6.0. running mean: 10.352301594162887\n",
      "resetting env. episode reward total was 12.0. running mean: 10.368778578221256\n",
      "resetting env. episode reward total was 8.0. running mean: 10.345090792439043\n",
      "resetting env. episode reward total was 8.0. running mean: 10.321639884514653\n",
      "resetting env. episode reward total was 7.0. running mean: 10.288423485669506\n",
      "resetting env. episode reward total was 5.0. running mean: 10.235539250812812\n",
      "resetting env. episode reward total was 13.0. running mean: 10.263183858304684\n",
      "resetting env. episode reward total was 14.0. running mean: 10.300552019721637\n",
      "resetting env. episode reward total was 8.0. running mean: 10.277546499524421\n",
      "resetting env. episode reward total was 14.0. running mean: 10.314771034529178\n",
      "resetting env. episode reward total was 8.0. running mean: 10.291623324183886\n",
      "resetting env. episode reward total was 8.0. running mean: 10.268707090942048\n",
      "resetting env. episode reward total was 10.0. running mean: 10.266020020032627\n",
      "resetting env. episode reward total was 1.0. running mean: 10.173359819832301\n",
      "resetting env. episode reward total was 10.0. running mean: 10.171626221633979\n",
      "resetting env. episode reward total was -4.0. running mean: 10.02990995941764\n",
      "resetting env. episode reward total was 6.0. running mean: 9.989610859823465\n",
      "resetting env. episode reward total was 4.0. running mean: 9.929714751225228\n",
      "resetting env. episode reward total was 11.0. running mean: 9.940417603712975\n",
      "resetting env. episode reward total was 1.0. running mean: 9.851013427675845\n",
      "resetting env. episode reward total was 11.0. running mean: 9.862503293399087\n",
      "resetting env. episode reward total was 13.0. running mean: 9.893878260465096\n",
      "resetting env. episode reward total was 13.0. running mean: 9.924939477860445\n",
      "resetting env. episode reward total was 11.0. running mean: 9.93569008308184\n",
      "resetting env. episode reward total was 8.0. running mean: 9.916333182251021\n",
      "resetting env. episode reward total was 17.0. running mean: 9.987169850428511\n",
      "resetting env. episode reward total was 11.0. running mean: 9.997298151924225\n",
      "resetting env. episode reward total was 12.0. running mean: 10.017325170404982\n",
      "resetting env. episode reward total was 6.0. running mean: 9.977151918700933\n",
      "resetting env. episode reward total was 9.0. running mean: 9.967380399513925\n",
      "resetting env. episode reward total was 10.0. running mean: 9.967706595518784\n",
      "resetting env. episode reward total was 17.0. running mean: 10.038029529563596\n",
      "resetting env. episode reward total was -2.0. running mean: 9.91764923426796\n",
      "resetting env. episode reward total was 13.0. running mean: 9.948472741925281\n",
      "resetting env. episode reward total was 11.0. running mean: 9.958988014506028\n",
      "resetting env. episode reward total was 8.0. running mean: 9.939398134360967\n",
      "resetting env. episode reward total was 14.0. running mean: 9.980004153017358\n",
      "resetting env. episode reward total was 13.0. running mean: 10.010204111487186\n",
      "resetting env. episode reward total was 12.0. running mean: 10.030102070372314\n",
      "resetting env. episode reward total was 12.0. running mean: 10.04980104966859\n",
      "resetting env. episode reward total was 11.0. running mean: 10.059303039171903\n",
      "resetting env. episode reward total was 13.0. running mean: 10.088710008780184\n",
      "resetting env. episode reward total was 11.0. running mean: 10.097822908692383\n",
      "resetting env. episode reward total was 13.0. running mean: 10.12684467960546\n",
      "resetting env. episode reward total was 10.0. running mean: 10.125576232809404\n",
      "resetting env. episode reward total was 12.0. running mean: 10.14432047048131\n",
      "resetting env. episode reward total was 8.0. running mean: 10.122877265776497\n",
      "resetting env. episode reward total was 11.0. running mean: 10.131648493118732\n",
      "resetting env. episode reward total was 14.0. running mean: 10.170332008187545\n",
      "resetting env. episode reward total was 9.0. running mean: 10.158628688105669\n",
      "resetting env. episode reward total was 11.0. running mean: 10.167042401224611\n",
      "resetting env. episode reward total was 11.0. running mean: 10.175371977212365\n",
      "resetting env. episode reward total was 12.0. running mean: 10.19361825744024\n",
      "resetting env. episode reward total was 7.0. running mean: 10.161682074865839\n",
      "resetting env. episode reward total was 13.0. running mean: 10.190065254117181\n",
      "resetting env. episode reward total was 16.0. running mean: 10.24816460157601\n",
      "resetting env. episode reward total was 4.0. running mean: 10.185682955560248\n",
      "resetting env. episode reward total was 8.0. running mean: 10.163826126004645\n",
      "resetting env. episode reward total was 11.0. running mean: 10.172187864744599\n",
      "resetting env. episode reward total was 17.0. running mean: 10.240465986097153\n",
      "resetting env. episode reward total was 9.0. running mean: 10.228061326236181\n",
      "resetting env. episode reward total was 12.0. running mean: 10.245780712973819\n",
      "resetting env. episode reward total was 6.0. running mean: 10.20332290584408\n",
      "resetting env. episode reward total was 15.0. running mean: 10.25128967678564\n",
      "resetting env. episode reward total was 5.0. running mean: 10.198776780017784\n",
      "resetting env. episode reward total was 4.0. running mean: 10.136789012217605\n",
      "resetting env. episode reward total was 8.0. running mean: 10.115421122095428\n",
      "resetting env. episode reward total was 6.0. running mean: 10.074266910874474\n",
      "resetting env. episode reward total was 11.0. running mean: 10.083524241765728\n",
      "resetting env. episode reward total was 14.0. running mean: 10.122688999348071\n",
      "resetting env. episode reward total was 8.0. running mean: 10.10146210935459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 16.0. running mean: 10.160447488261045\n",
      "resetting env. episode reward total was -2.0. running mean: 10.038843013378436\n",
      "resetting env. episode reward total was 9.0. running mean: 10.02845458324465\n",
      "resetting env. episode reward total was 8.0. running mean: 10.008170037412205\n",
      "resetting env. episode reward total was 15.0. running mean: 10.058088337038082\n",
      "resetting env. episode reward total was 13.0. running mean: 10.087507453667703\n",
      "resetting env. episode reward total was 15.0. running mean: 10.136632379131026\n",
      "resetting env. episode reward total was 18.0. running mean: 10.215266055339715\n",
      "resetting env. episode reward total was 8.0. running mean: 10.193113394786318\n",
      "resetting env. episode reward total was -3.0. running mean: 10.061182260838455\n",
      "resetting env. episode reward total was 8.0. running mean: 10.040570438230072\n",
      "resetting env. episode reward total was 12.0. running mean: 10.06016473384777\n",
      "resetting env. episode reward total was 6.0. running mean: 10.019563086509294\n",
      "resetting env. episode reward total was 5.0. running mean: 9.969367455644202\n",
      "resetting env. episode reward total was 8.0. running mean: 9.949673781087759\n",
      "resetting env. episode reward total was 7.0. running mean: 9.920177043276881\n",
      "resetting env. episode reward total was 11.0. running mean: 9.930975272844112\n",
      "resetting env. episode reward total was 3.0. running mean: 9.86166552011567\n",
      "resetting env. episode reward total was 2.0. running mean: 9.783048864914512\n",
      "resetting env. episode reward total was 12.0. running mean: 9.805218376265367\n",
      "resetting env. episode reward total was 16.0. running mean: 9.867166192502713\n",
      "resetting env. episode reward total was 16.0. running mean: 9.928494530577685\n",
      "resetting env. episode reward total was 7.0. running mean: 9.899209585271908\n",
      "resetting env. episode reward total was 13.0. running mean: 9.93021748941919\n",
      "resetting env. episode reward total was 16.0. running mean: 9.990915314525\n",
      "resetting env. episode reward total was 13.0. running mean: 10.02100616137975\n",
      "resetting env. episode reward total was 9.0. running mean: 10.010796099765953\n",
      "resetting env. episode reward total was 7.0. running mean: 9.980688138768294\n",
      "resetting env. episode reward total was 6.0. running mean: 9.94088125738061\n",
      "resetting env. episode reward total was 3.0. running mean: 9.871472444806804\n",
      "resetting env. episode reward total was 15.0. running mean: 9.922757720358735\n",
      "resetting env. episode reward total was 6.0. running mean: 9.883530143155149\n",
      "resetting env. episode reward total was 9.0. running mean: 9.874694841723597\n",
      "resetting env. episode reward total was 6.0. running mean: 9.835947893306361\n",
      "resetting env. episode reward total was 12.0. running mean: 9.857588414373296\n",
      "resetting env. episode reward total was 11.0. running mean: 9.869012530229563\n",
      "resetting env. episode reward total was 12.0. running mean: 9.890322404927266\n",
      "resetting env. episode reward total was 12.0. running mean: 9.911419180877992\n",
      "resetting env. episode reward total was 7.0. running mean: 9.882304989069212\n",
      "resetting env. episode reward total was 15.0. running mean: 9.93348193917852\n",
      "resetting env. episode reward total was 7.0. running mean: 9.904147119786735\n",
      "resetting env. episode reward total was 15.0. running mean: 9.955105648588868\n",
      "resetting env. episode reward total was 8.0. running mean: 9.93555459210298\n",
      "resetting env. episode reward total was 17.0. running mean: 10.00619904618195\n",
      "resetting env. episode reward total was 13.0. running mean: 10.03613705572013\n",
      "resetting env. episode reward total was 15.0. running mean: 10.085775685162929\n",
      "resetting env. episode reward total was 15.0. running mean: 10.1349179283113\n",
      "resetting env. episode reward total was 14.0. running mean: 10.173568749028187\n",
      "resetting env. episode reward total was 11.0. running mean: 10.181833061537905\n",
      "resetting env. episode reward total was 8.0. running mean: 10.160014730922526\n",
      "resetting env. episode reward total was 9.0. running mean: 10.1484145836133\n",
      "resetting env. episode reward total was 18.0. running mean: 10.226930437777167\n",
      "resetting env. episode reward total was 13.0. running mean: 10.254661133399395\n",
      "resetting env. episode reward total was 13.0. running mean: 10.282114522065402\n",
      "resetting env. episode reward total was 10.0. running mean: 10.279293376844748\n",
      "resetting env. episode reward total was 12.0. running mean: 10.2965004430763\n",
      "resetting env. episode reward total was 10.0. running mean: 10.293535438645536\n",
      "resetting env. episode reward total was 14.0. running mean: 10.330600084259082\n",
      "resetting env. episode reward total was 13.0. running mean: 10.357294083416491\n",
      "resetting env. episode reward total was 11.0. running mean: 10.363721142582326\n",
      "resetting env. episode reward total was 14.0. running mean: 10.400083931156503\n",
      "resetting env. episode reward total was 10.0. running mean: 10.396083091844938\n",
      "resetting env. episode reward total was 18.0. running mean: 10.472122260926488\n",
      "resetting env. episode reward total was 17.0. running mean: 10.537401038317222\n",
      "resetting env. episode reward total was 12.0. running mean: 10.552027027934049\n",
      "resetting env. episode reward total was 9.0. running mean: 10.536506757654708\n",
      "resetting env. episode reward total was 14.0. running mean: 10.57114169007816\n",
      "resetting env. episode reward total was 13.0. running mean: 10.59543027317738\n",
      "resetting env. episode reward total was 6.0. running mean: 10.549475970445606\n",
      "resetting env. episode reward total was 4.0. running mean: 10.483981210741149\n",
      "resetting env. episode reward total was 12.0. running mean: 10.499141398633737\n",
      "resetting env. episode reward total was 16.0. running mean: 10.5541499846474\n",
      "resetting env. episode reward total was 8.0. running mean: 10.528608484800927\n",
      "resetting env. episode reward total was 9.0. running mean: 10.513322399952918\n",
      "resetting env. episode reward total was 7.0. running mean: 10.47818917595339\n",
      "resetting env. episode reward total was 11.0. running mean: 10.483407284193854\n",
      "resetting env. episode reward total was 11.0. running mean: 10.488573211351914\n",
      "resetting env. episode reward total was 18.0. running mean: 10.563687479238395\n",
      "resetting env. episode reward total was 9.0. running mean: 10.54805060444601\n",
      "resetting env. episode reward total was 8.0. running mean: 10.52257009840155\n",
      "resetting env. episode reward total was 5.0. running mean: 10.467344397417536\n",
      "resetting env. episode reward total was 13.0. running mean: 10.492670953443362\n",
      "resetting env. episode reward total was 8.0. running mean: 10.467744243908928\n",
      "resetting env. episode reward total was 13.0. running mean: 10.49306680146984\n",
      "resetting env. episode reward total was 14.0. running mean: 10.528136133455142\n",
      "resetting env. episode reward total was 13.0. running mean: 10.552854772120591\n",
      "resetting env. episode reward total was 15.0. running mean: 10.597326224399385\n",
      "resetting env. episode reward total was 14.0. running mean: 10.631352962155391\n",
      "resetting env. episode reward total was 15.0. running mean: 10.675039432533838\n",
      "resetting env. episode reward total was 3.0. running mean: 10.598289038208499\n",
      "resetting env. episode reward total was 10.0. running mean: 10.592306147826413\n",
      "resetting env. episode reward total was 9.0. running mean: 10.576383086348148\n",
      "resetting env. episode reward total was 11.0. running mean: 10.580619255484667\n",
      "resetting env. episode reward total was 12.0. running mean: 10.59481306292982\n",
      "resetting env. episode reward total was 11.0. running mean: 10.59886493230052\n",
      "resetting env. episode reward total was 11.0. running mean: 10.602876282977514\n",
      "resetting env. episode reward total was 7.0. running mean: 10.56684752014774\n",
      "resetting env. episode reward total was 9.0. running mean: 10.551179044946261\n",
      "resetting env. episode reward total was 11.0. running mean: 10.555667254496798\n",
      "resetting env. episode reward total was 10.0. running mean: 10.55011058195183\n",
      "resetting env. episode reward total was 12.0. running mean: 10.564609476132311\n",
      "resetting env. episode reward total was 7.0. running mean: 10.528963381370989\n",
      "resetting env. episode reward total was 15.0. running mean: 10.57367374755728\n",
      "resetting env. episode reward total was 5.0. running mean: 10.517937010081708\n",
      "resetting env. episode reward total was 11.0. running mean: 10.52275763998089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 10.567530063581081\n",
      "resetting env. episode reward total was 11.0. running mean: 10.57185476294527\n",
      "resetting env. episode reward total was 12.0. running mean: 10.586136215315817\n",
      "resetting env. episode reward total was 14.0. running mean: 10.620274853162659\n",
      "resetting env. episode reward total was 9.0. running mean: 10.604072104631031\n",
      "resetting env. episode reward total was 10.0. running mean: 10.59803138358472\n",
      "resetting env. episode reward total was 9.0. running mean: 10.582051069748873\n",
      "resetting env. episode reward total was 12.0. running mean: 10.596230559051383\n",
      "resetting env. episode reward total was 4.0. running mean: 10.530268253460868\n",
      "resetting env. episode reward total was 7.0. running mean: 10.49496557092626\n",
      "resetting env. episode reward total was 16.0. running mean: 10.550015915216997\n",
      "resetting env. episode reward total was 8.0. running mean: 10.524515756064828\n",
      "resetting env. episode reward total was 1.0. running mean: 10.429270598504178\n",
      "resetting env. episode reward total was 11.0. running mean: 10.434977892519136\n",
      "resetting env. episode reward total was 8.0. running mean: 10.410628113593944\n",
      "resetting env. episode reward total was 12.0. running mean: 10.426521832458004\n",
      "resetting env. episode reward total was 5.0. running mean: 10.372256614133425\n",
      "resetting env. episode reward total was 18.0. running mean: 10.44853404799209\n",
      "resetting env. episode reward total was 9.0. running mean: 10.43404870751217\n",
      "resetting env. episode reward total was 4.0. running mean: 10.369708220437047\n",
      "resetting env. episode reward total was 14.0. running mean: 10.406011138232678\n",
      "resetting env. episode reward total was 12.0. running mean: 10.421951026850351\n",
      "resetting env. episode reward total was 12.0. running mean: 10.437731516581847\n",
      "resetting env. episode reward total was 4.0. running mean: 10.373354201416028\n",
      "resetting env. episode reward total was 13.0. running mean: 10.399620659401869\n",
      "resetting env. episode reward total was 9.0. running mean: 10.38562445280785\n",
      "resetting env. episode reward total was 9.0. running mean: 10.371768208279772\n",
      "resetting env. episode reward total was 18.0. running mean: 10.448050526196974\n",
      "resetting env. episode reward total was 8.0. running mean: 10.423570020935005\n",
      "resetting env. episode reward total was 9.0. running mean: 10.409334320725653\n",
      "resetting env. episode reward total was 1.0. running mean: 10.315240977518396\n",
      "resetting env. episode reward total was 12.0. running mean: 10.332088567743211\n",
      "resetting env. episode reward total was 14.0. running mean: 10.36876768206578\n",
      "resetting env. episode reward total was 13.0. running mean: 10.395080005245124\n",
      "resetting env. episode reward total was 11.0. running mean: 10.401129205192671\n",
      "resetting env. episode reward total was 13.0. running mean: 10.427117913140744\n",
      "resetting env. episode reward total was 3.0. running mean: 10.352846734009336\n",
      "resetting env. episode reward total was 9.0. running mean: 10.339318266669244\n",
      "resetting env. episode reward total was 2.0. running mean: 10.25592508400255\n",
      "resetting env. episode reward total was -3.0. running mean: 10.123365833162525\n",
      "resetting env. episode reward total was 9.0. running mean: 10.112132174830899\n",
      "resetting env. episode reward total was 10.0. running mean: 10.11101085308259\n",
      "resetting env. episode reward total was 14.0. running mean: 10.149900744551765\n",
      "resetting env. episode reward total was 6.0. running mean: 10.108401737106247\n",
      "resetting env. episode reward total was 8.0. running mean: 10.087317719735184\n",
      "resetting env. episode reward total was 11.0. running mean: 10.096444542537832\n",
      "resetting env. episode reward total was 8.0. running mean: 10.075480097112454\n",
      "resetting env. episode reward total was 6.0. running mean: 10.03472529614133\n",
      "resetting env. episode reward total was 18.0. running mean: 10.114378043179917\n",
      "resetting env. episode reward total was 2.0. running mean: 10.033234262748117\n",
      "resetting env. episode reward total was 12.0. running mean: 10.052901920120634\n",
      "resetting env. episode reward total was 15.0. running mean: 10.102372900919429\n",
      "resetting env. episode reward total was 13.0. running mean: 10.131349171910236\n",
      "resetting env. episode reward total was 14.0. running mean: 10.170035680191134\n",
      "resetting env. episode reward total was 15.0. running mean: 10.218335323389223\n",
      "resetting env. episode reward total was 10.0. running mean: 10.21615197015533\n",
      "resetting env. episode reward total was 6.0. running mean: 10.173990450453777\n",
      "resetting env. episode reward total was 6.0. running mean: 10.13225054594924\n",
      "resetting env. episode reward total was 19.0. running mean: 10.220928040489747\n",
      "resetting env. episode reward total was 15.0. running mean: 10.26871876008485\n",
      "resetting env. episode reward total was 8.0. running mean: 10.246031572484002\n",
      "resetting env. episode reward total was 8.0. running mean: 10.223571256759161\n",
      "resetting env. episode reward total was 10.0. running mean: 10.22133554419157\n",
      "resetting env. episode reward total was 10.0. running mean: 10.219122188749653\n",
      "resetting env. episode reward total was 14.0. running mean: 10.256930966862157\n",
      "resetting env. episode reward total was 12.0. running mean: 10.274361657193534\n",
      "resetting env. episode reward total was 10.0. running mean: 10.271618040621599\n",
      "resetting env. episode reward total was 14.0. running mean: 10.308901860215384\n",
      "resetting env. episode reward total was 16.0. running mean: 10.36581284161323\n",
      "resetting env. episode reward total was 3.0. running mean: 10.292154713197098\n",
      "resetting env. episode reward total was 5.0. running mean: 10.239233166065128\n",
      "resetting env. episode reward total was 16.0. running mean: 10.296840834404478\n",
      "resetting env. episode reward total was 13.0. running mean: 10.323872426060433\n",
      "resetting env. episode reward total was 12.0. running mean: 10.340633701799828\n",
      "resetting env. episode reward total was 9.0. running mean: 10.327227364781828\n",
      "resetting env. episode reward total was 7.0. running mean: 10.293955091134011\n",
      "resetting env. episode reward total was 19.0. running mean: 10.38101554022267\n",
      "resetting env. episode reward total was 13.0. running mean: 10.407205384820443\n",
      "resetting env. episode reward total was 6.0. running mean: 10.36313333097224\n",
      "resetting env. episode reward total was 17.0. running mean: 10.429501997662516\n",
      "resetting env. episode reward total was 12.0. running mean: 10.44520697768589\n",
      "resetting env. episode reward total was 14.0. running mean: 10.480754907909033\n",
      "resetting env. episode reward total was 14.0. running mean: 10.515947358829942\n",
      "resetting env. episode reward total was 9.0. running mean: 10.500787885241643\n",
      "resetting env. episode reward total was 16.0. running mean: 10.555780006389226\n",
      "resetting env. episode reward total was 12.0. running mean: 10.570222206325333\n",
      "resetting env. episode reward total was 12.0. running mean: 10.584519984262078\n",
      "resetting env. episode reward total was 14.0. running mean: 10.618674784419458\n",
      "resetting env. episode reward total was 11.0. running mean: 10.622488036575263\n",
      "resetting env. episode reward total was 8.0. running mean: 10.59626315620951\n",
      "resetting env. episode reward total was 12.0. running mean: 10.610300524647414\n",
      "resetting env. episode reward total was 10.0. running mean: 10.60419751940094\n",
      "resetting env. episode reward total was 1.0. running mean: 10.508155544206929\n",
      "resetting env. episode reward total was 10.0. running mean: 10.503073988764859\n",
      "resetting env. episode reward total was 1.0. running mean: 10.40804324887721\n",
      "resetting env. episode reward total was 8.0. running mean: 10.383962816388438\n",
      "resetting env. episode reward total was 17.0. running mean: 10.450123188224554\n",
      "resetting env. episode reward total was 12.0. running mean: 10.465621956342307\n",
      "resetting env. episode reward total was 12.0. running mean: 10.480965736778883\n",
      "resetting env. episode reward total was 9.0. running mean: 10.466156079411094\n",
      "resetting env. episode reward total was 12.0. running mean: 10.481494518616982\n",
      "resetting env. episode reward total was 14.0. running mean: 10.516679573430812\n",
      "resetting env. episode reward total was 10.0. running mean: 10.511512777696504\n",
      "resetting env. episode reward total was 10.0. running mean: 10.506397649919538\n",
      "resetting env. episode reward total was 10.0. running mean: 10.501333673420342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 10.49632033668614\n",
      "resetting env. episode reward total was 12.0. running mean: 10.511357133319278\n",
      "resetting env. episode reward total was 18.0. running mean: 10.586243561986084\n",
      "resetting env. episode reward total was 8.0. running mean: 10.560381126366224\n",
      "resetting env. episode reward total was 7.0. running mean: 10.524777315102561\n",
      "resetting env. episode reward total was 8.0. running mean: 10.499529541951535\n",
      "resetting env. episode reward total was 15.0. running mean: 10.54453424653202\n",
      "resetting env. episode reward total was 7.0. running mean: 10.5090889040667\n",
      "resetting env. episode reward total was 13.0. running mean: 10.533998015026034\n",
      "resetting env. episode reward total was 14.0. running mean: 10.568658034875774\n",
      "resetting env. episode reward total was 16.0. running mean: 10.622971454527017\n",
      "resetting env. episode reward total was 7.0. running mean: 10.586741739981747\n",
      "resetting env. episode reward total was 7.0. running mean: 10.55087432258193\n",
      "resetting env. episode reward total was 6.0. running mean: 10.505365579356111\n",
      "resetting env. episode reward total was 16.0. running mean: 10.56031192356255\n",
      "resetting env. episode reward total was 9.0. running mean: 10.544708804326923\n",
      "resetting env. episode reward total was 10.0. running mean: 10.539261716283654\n",
      "resetting env. episode reward total was 11.0. running mean: 10.543869099120817\n",
      "resetting env. episode reward total was 3.0. running mean: 10.468430408129608\n",
      "resetting env. episode reward total was 11.0. running mean: 10.473746104048312\n",
      "resetting env. episode reward total was 10.0. running mean: 10.469008643007827\n",
      "resetting env. episode reward total was 11.0. running mean: 10.474318556577748\n",
      "resetting env. episode reward total was 5.0. running mean: 10.419575371011971\n",
      "resetting env. episode reward total was 16.0. running mean: 10.475379617301853\n",
      "resetting env. episode reward total was 12.0. running mean: 10.490625821128834\n",
      "resetting env. episode reward total was 15.0. running mean: 10.535719562917546\n",
      "resetting env. episode reward total was 1.0. running mean: 10.44036236728837\n",
      "resetting env. episode reward total was 9.0. running mean: 10.425958743615487\n",
      "resetting env. episode reward total was 17.0. running mean: 10.491699156179331\n",
      "resetting env. episode reward total was 7.0. running mean: 10.456782164617538\n",
      "resetting env. episode reward total was 10.0. running mean: 10.452214342971361\n",
      "resetting env. episode reward total was 15.0. running mean: 10.497692199541648\n",
      "resetting env. episode reward total was 16.0. running mean: 10.552715277546232\n",
      "resetting env. episode reward total was 14.0. running mean: 10.58718812477077\n",
      "resetting env. episode reward total was 2.0. running mean: 10.501316243523062\n",
      "resetting env. episode reward total was 12.0. running mean: 10.51630308108783\n",
      "resetting env. episode reward total was 10.0. running mean: 10.511140050276952\n",
      "resetting env. episode reward total was 15.0. running mean: 10.556028649774182\n",
      "resetting env. episode reward total was 11.0. running mean: 10.56046836327644\n",
      "resetting env. episode reward total was 3.0. running mean: 10.484863679643675\n",
      "resetting env. episode reward total was 13.0. running mean: 10.51001504284724\n",
      "resetting env. episode reward total was 17.0. running mean: 10.574914892418768\n",
      "resetting env. episode reward total was 14.0. running mean: 10.60916574349458\n",
      "resetting env. episode reward total was 15.0. running mean: 10.653074086059634\n",
      "resetting env. episode reward total was 10.0. running mean: 10.646543345199037\n",
      "resetting env. episode reward total was -4.0. running mean: 10.500077911747047\n",
      "resetting env. episode reward total was 7.0. running mean: 10.465077132629576\n",
      "resetting env. episode reward total was 13.0. running mean: 10.49042636130328\n",
      "resetting env. episode reward total was 14.0. running mean: 10.525522097690247\n",
      "resetting env. episode reward total was 15.0. running mean: 10.570266876713346\n",
      "resetting env. episode reward total was 16.0. running mean: 10.624564207946213\n",
      "resetting env. episode reward total was 14.0. running mean: 10.65831856586675\n",
      "resetting env. episode reward total was 15.0. running mean: 10.701735380208083\n",
      "resetting env. episode reward total was 16.0. running mean: 10.754718026406001\n",
      "resetting env. episode reward total was 9.0. running mean: 10.737170846141941\n",
      "resetting env. episode reward total was 8.0. running mean: 10.709799137680521\n",
      "resetting env. episode reward total was 11.0. running mean: 10.712701146303715\n",
      "resetting env. episode reward total was 11.0. running mean: 10.715574134840677\n",
      "resetting env. episode reward total was 12.0. running mean: 10.72841839349227\n",
      "resetting env. episode reward total was 1.0. running mean: 10.631134209557347\n",
      "resetting env. episode reward total was 9.0. running mean: 10.614822867461774\n",
      "resetting env. episode reward total was 9.0. running mean: 10.598674638787156\n",
      "resetting env. episode reward total was 10.0. running mean: 10.592687892399283\n",
      "resetting env. episode reward total was 14.0. running mean: 10.62676101347529\n",
      "resetting env. episode reward total was 16.0. running mean: 10.680493403340538\n",
      "resetting env. episode reward total was 16.0. running mean: 10.733688469307133\n",
      "resetting env. episode reward total was 11.0. running mean: 10.736351584614061\n",
      "resetting env. episode reward total was 13.0. running mean: 10.758988068767922\n",
      "resetting env. episode reward total was 12.0. running mean: 10.77139818808024\n",
      "resetting env. episode reward total was 12.0. running mean: 10.783684206199437\n",
      "resetting env. episode reward total was 8.0. running mean: 10.755847364137443\n",
      "resetting env. episode reward total was 7.0. running mean: 10.71828889049607\n",
      "resetting env. episode reward total was 15.0. running mean: 10.76110600159111\n",
      "resetting env. episode reward total was 12.0. running mean: 10.773494941575198\n",
      "resetting env. episode reward total was 13.0. running mean: 10.795759992159446\n",
      "resetting env. episode reward total was 10.0. running mean: 10.787802392237852\n",
      "resetting env. episode reward total was 14.0. running mean: 10.819924368315474\n",
      "resetting env. episode reward total was 15.0. running mean: 10.86172512463232\n",
      "resetting env. episode reward total was 9.0. running mean: 10.843107873385996\n",
      "resetting env. episode reward total was 13.0. running mean: 10.864676794652137\n",
      "resetting env. episode reward total was 14.0. running mean: 10.896030026705617\n",
      "resetting env. episode reward total was 9.0. running mean: 10.877069726438561\n",
      "resetting env. episode reward total was 13.0. running mean: 10.898299029174176\n",
      "resetting env. episode reward total was 11.0. running mean: 10.899316038882434\n",
      "resetting env. episode reward total was 8.0. running mean: 10.87032287849361\n",
      "resetting env. episode reward total was 17.0. running mean: 10.931619649708674\n",
      "resetting env. episode reward total was 10.0. running mean: 10.922303453211587\n",
      "resetting env. episode reward total was 12.0. running mean: 10.93308041867947\n",
      "resetting env. episode reward total was 18.0. running mean: 11.003749614492675\n",
      "resetting env. episode reward total was 12.0. running mean: 11.013712118347748\n",
      "resetting env. episode reward total was 14.0. running mean: 11.04357499716427\n",
      "resetting env. episode reward total was 11.0. running mean: 11.043139247192627\n",
      "resetting env. episode reward total was 12.0. running mean: 11.0527078547207\n",
      "resetting env. episode reward total was 7.0. running mean: 11.012180776173492\n",
      "resetting env. episode reward total was 9.0. running mean: 10.992058968411758\n",
      "resetting env. episode reward total was 12.0. running mean: 11.00213837872764\n",
      "resetting env. episode reward total was 10.0. running mean: 10.992116994940362\n",
      "resetting env. episode reward total was 5.0. running mean: 10.93219582499096\n",
      "resetting env. episode reward total was 7.0. running mean: 10.89287386674105\n",
      "resetting env. episode reward total was 4.0. running mean: 10.823945128073639\n",
      "resetting env. episode reward total was 8.0. running mean: 10.795705676792902\n",
      "resetting env. episode reward total was -8.0. running mean: 10.607748620024973\n",
      "resetting env. episode reward total was 2.0. running mean: 10.521671133824722\n",
      "resetting env. episode reward total was 9.0. running mean: 10.506454422486474\n",
      "resetting env. episode reward total was 12.0. running mean: 10.521389878261608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 10.496175979478993\n",
      "resetting env. episode reward total was 17.0. running mean: 10.561214219684203\n",
      "resetting env. episode reward total was 10.0. running mean: 10.555602077487361\n",
      "resetting env. episode reward total was 7.0. running mean: 10.520046056712488\n",
      "resetting env. episode reward total was 7.0. running mean: 10.484845596145362\n",
      "resetting env. episode reward total was 13.0. running mean: 10.50999714018391\n",
      "resetting env. episode reward total was 12.0. running mean: 10.524897168782068\n",
      "resetting env. episode reward total was 8.0. running mean: 10.499648197094247\n",
      "resetting env. episode reward total was 10.0. running mean: 10.494651715123304\n",
      "resetting env. episode reward total was 9.0. running mean: 10.47970519797207\n",
      "resetting env. episode reward total was 9.0. running mean: 10.464908145992348\n",
      "resetting env. episode reward total was 12.0. running mean: 10.480259064532424\n",
      "resetting env. episode reward total was 7.0. running mean: 10.4454564738871\n",
      "resetting env. episode reward total was 12.0. running mean: 10.461001909148228\n",
      "resetting env. episode reward total was 11.0. running mean: 10.466391890056745\n",
      "resetting env. episode reward total was 5.0. running mean: 10.411727971156179\n",
      "resetting env. episode reward total was 13.0. running mean: 10.437610691444618\n",
      "resetting env. episode reward total was 15.0. running mean: 10.483234584530173\n",
      "resetting env. episode reward total was 16.0. running mean: 10.53840223868487\n",
      "resetting env. episode reward total was 11.0. running mean: 10.543018216298021\n",
      "resetting env. episode reward total was 15.0. running mean: 10.587588034135042\n",
      "resetting env. episode reward total was -5.0. running mean: 10.43171215379369\n",
      "resetting env. episode reward total was 8.0. running mean: 10.407395032255753\n",
      "resetting env. episode reward total was 17.0. running mean: 10.473321081933195\n",
      "resetting env. episode reward total was 11.0. running mean: 10.478587871113863\n",
      "resetting env. episode reward total was 6.0. running mean: 10.433801992402724\n",
      "resetting env. episode reward total was 18.0. running mean: 10.509463972478697\n",
      "resetting env. episode reward total was 7.0. running mean: 10.474369332753911\n",
      "resetting env. episode reward total was 13.0. running mean: 10.499625639426373\n",
      "resetting env. episode reward total was 11.0. running mean: 10.504629383032109\n",
      "resetting env. episode reward total was 12.0. running mean: 10.519583089201786\n",
      "resetting env. episode reward total was 10.0. running mean: 10.514387258309768\n",
      "resetting env. episode reward total was 17.0. running mean: 10.57924338572667\n",
      "resetting env. episode reward total was 1.0. running mean: 10.483450951869402\n",
      "resetting env. episode reward total was 6.0. running mean: 10.438616442350709\n",
      "resetting env. episode reward total was 10.0. running mean: 10.4342302779272\n",
      "resetting env. episode reward total was 11.0. running mean: 10.439887975147927\n",
      "resetting env. episode reward total was 11.0. running mean: 10.445489095396448\n",
      "resetting env. episode reward total was 6.0. running mean: 10.401034204442483\n",
      "resetting env. episode reward total was 3.0. running mean: 10.327023862398057\n",
      "resetting env. episode reward total was 8.0. running mean: 10.303753623774076\n",
      "resetting env. episode reward total was -3.0. running mean: 10.170716087536336\n",
      "resetting env. episode reward total was 1.0. running mean: 10.079008926660972\n",
      "resetting env. episode reward total was 12.0. running mean: 10.098218837394361\n",
      "resetting env. episode reward total was 10.0. running mean: 10.097236649020417\n",
      "resetting env. episode reward total was 10.0. running mean: 10.096264282530212\n",
      "resetting env. episode reward total was 12.0. running mean: 10.11530163970491\n",
      "resetting env. episode reward total was 14.0. running mean: 10.154148623307861\n",
      "resetting env. episode reward total was 17.0. running mean: 10.222607137074784\n",
      "resetting env. episode reward total was 11.0. running mean: 10.230381065704035\n",
      "resetting env. episode reward total was 7.0. running mean: 10.198077255046995\n",
      "resetting env. episode reward total was 5.0. running mean: 10.146096482496525\n",
      "resetting env. episode reward total was 13.0. running mean: 10.17463551767156\n",
      "resetting env. episode reward total was 18.0. running mean: 10.252889162494844\n",
      "resetting env. episode reward total was 12.0. running mean: 10.270360270869894\n",
      "resetting env. episode reward total was 5.0. running mean: 10.217656668161196\n",
      "resetting env. episode reward total was 7.0. running mean: 10.185480101479584\n",
      "resetting env. episode reward total was 17.0. running mean: 10.253625300464789\n",
      "resetting env. episode reward total was 8.0. running mean: 10.231089047460141\n",
      "resetting env. episode reward total was 11.0. running mean: 10.23877815698554\n",
      "resetting env. episode reward total was 14.0. running mean: 10.276390375415684\n",
      "resetting env. episode reward total was 8.0. running mean: 10.253626471661526\n",
      "resetting env. episode reward total was 17.0. running mean: 10.32109020694491\n",
      "resetting env. episode reward total was 5.0. running mean: 10.267879304875462\n",
      "resetting env. episode reward total was 2.0. running mean: 10.185200511826707\n",
      "resetting env. episode reward total was 11.0. running mean: 10.193348506708439\n",
      "resetting env. episode reward total was 7.0. running mean: 10.161415021641355\n",
      "resetting env. episode reward total was 12.0. running mean: 10.179800871424941\n",
      "resetting env. episode reward total was 3.0. running mean: 10.108002862710691\n",
      "resetting env. episode reward total was 16.0. running mean: 10.166922834083584\n",
      "resetting env. episode reward total was 2.0. running mean: 10.085253605742748\n",
      "resetting env. episode reward total was 16.0. running mean: 10.14440106968532\n",
      "resetting env. episode reward total was 13.0. running mean: 10.172957058988468\n",
      "resetting env. episode reward total was -3.0. running mean: 10.041227488398583\n",
      "resetting env. episode reward total was 11.0. running mean: 10.050815213514596\n",
      "resetting env. episode reward total was 10.0. running mean: 10.05030706137945\n",
      "resetting env. episode reward total was 13.0. running mean: 10.079803990765656\n",
      "resetting env. episode reward total was 14.0. running mean: 10.119005950858\n",
      "resetting env. episode reward total was 11.0. running mean: 10.12781589134942\n",
      "resetting env. episode reward total was 13.0. running mean: 10.156537732435925\n",
      "resetting env. episode reward total was 15.0. running mean: 10.204972355111567\n",
      "resetting env. episode reward total was 16.0. running mean: 10.262922631560452\n",
      "resetting env. episode reward total was 15.0. running mean: 10.310293405244847\n",
      "resetting env. episode reward total was 10.0. running mean: 10.307190471192397\n",
      "resetting env. episode reward total was 10.0. running mean: 10.304118566480472\n",
      "resetting env. episode reward total was 12.0. running mean: 10.321077380815666\n",
      "resetting env. episode reward total was 9.0. running mean: 10.30786660700751\n",
      "resetting env. episode reward total was 15.0. running mean: 10.354787940937435\n",
      "resetting env. episode reward total was 11.0. running mean: 10.36124006152806\n",
      "resetting env. episode reward total was 8.0. running mean: 10.337627660912778\n",
      "resetting env. episode reward total was 8.0. running mean: 10.31425138430365\n",
      "resetting env. episode reward total was 16.0. running mean: 10.371108870460615\n",
      "resetting env. episode reward total was 10.0. running mean: 10.367397781756008\n",
      "resetting env. episode reward total was 9.0. running mean: 10.353723803938447\n",
      "resetting env. episode reward total was 13.0. running mean: 10.380186565899063\n",
      "resetting env. episode reward total was 12.0. running mean: 10.396384700240072\n",
      "resetting env. episode reward total was 6.0. running mean: 10.352420853237671\n",
      "resetting env. episode reward total was 13.0. running mean: 10.378896644705295\n",
      "resetting env. episode reward total was 1.0. running mean: 10.28510767825824\n",
      "resetting env. episode reward total was 7.0. running mean: 10.252256601475658\n",
      "resetting env. episode reward total was 17.0. running mean: 10.3197340354609\n",
      "resetting env. episode reward total was 13.0. running mean: 10.346536695106293\n",
      "resetting env. episode reward total was 11.0. running mean: 10.35307132815523\n",
      "resetting env. episode reward total was 11.0. running mean: 10.359540614873676\n",
      "resetting env. episode reward total was 8.0. running mean: 10.33594520872494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 10.332585756637691\n",
      "resetting env. episode reward total was 9.0. running mean: 10.319259899071314\n",
      "resetting env. episode reward total was 10.0. running mean: 10.3160673000806\n",
      "resetting env. episode reward total was 9.0. running mean: 10.302906627079794\n",
      "resetting env. episode reward total was 15.0. running mean: 10.349877560808997\n",
      "resetting env. episode reward total was 16.0. running mean: 10.406378785200907\n",
      "resetting env. episode reward total was 12.0. running mean: 10.422314997348897\n",
      "resetting env. episode reward total was 14.0. running mean: 10.458091847375409\n",
      "resetting env. episode reward total was 17.0. running mean: 10.523510928901654\n",
      "resetting env. episode reward total was 7.0. running mean: 10.488275819612637\n",
      "resetting env. episode reward total was 11.0. running mean: 10.49339306141651\n",
      "resetting env. episode reward total was 1.0. running mean: 10.398459130802346\n",
      "resetting env. episode reward total was 11.0. running mean: 10.404474539494322\n",
      "resetting env. episode reward total was 8.0. running mean: 10.380429794099378\n",
      "resetting env. episode reward total was 14.0. running mean: 10.416625496158385\n",
      "resetting env. episode reward total was 8.0. running mean: 10.392459241196802\n",
      "resetting env. episode reward total was 13.0. running mean: 10.418534648784835\n",
      "resetting env. episode reward total was 8.0. running mean: 10.394349302296986\n",
      "resetting env. episode reward total was 7.0. running mean: 10.360405809274017\n",
      "resetting env. episode reward total was 17.0. running mean: 10.426801751181277\n",
      "resetting env. episode reward total was 18.0. running mean: 10.502533733669463\n",
      "resetting env. episode reward total was 10.0. running mean: 10.497508396332767\n",
      "resetting env. episode reward total was 8.0. running mean: 10.472533312369439\n",
      "resetting env. episode reward total was 3.0. running mean: 10.397807979245744\n",
      "resetting env. episode reward total was 6.0. running mean: 10.353829899453288\n",
      "resetting env. episode reward total was 14.0. running mean: 10.390291600458756\n",
      "resetting env. episode reward total was 15.0. running mean: 10.436388684454169\n",
      "resetting env. episode reward total was 14.0. running mean: 10.472024797609627\n",
      "resetting env. episode reward total was 10.0. running mean: 10.46730454963353\n",
      "resetting env. episode reward total was 11.0. running mean: 10.472631504137194\n",
      "resetting env. episode reward total was 10.0. running mean: 10.467905189095822\n",
      "resetting env. episode reward total was 10.0. running mean: 10.463226137204863\n",
      "resetting env. episode reward total was 8.0. running mean: 10.438593875832815\n",
      "resetting env. episode reward total was 12.0. running mean: 10.454207937074486\n",
      "resetting env. episode reward total was 16.0. running mean: 10.509665857703741\n",
      "resetting env. episode reward total was 12.0. running mean: 10.524569199126702\n",
      "resetting env. episode reward total was -9.0. running mean: 10.329323507135435\n",
      "resetting env. episode reward total was 6.0. running mean: 10.28603027206408\n",
      "resetting env. episode reward total was 11.0. running mean: 10.293169969343438\n",
      "resetting env. episode reward total was 10.0. running mean: 10.290238269650004\n",
      "resetting env. episode reward total was 15.0. running mean: 10.337335886953504\n",
      "resetting env. episode reward total was 4.0. running mean: 10.273962528083969\n",
      "resetting env. episode reward total was 14.0. running mean: 10.311222902803129\n",
      "resetting env. episode reward total was 7.0. running mean: 10.278110673775098\n",
      "resetting env. episode reward total was 14.0. running mean: 10.315329567037347\n",
      "resetting env. episode reward total was 15.0. running mean: 10.362176271366973\n",
      "resetting env. episode reward total was 11.0. running mean: 10.368554508653302\n",
      "resetting env. episode reward total was 13.0. running mean: 10.39486896356677\n",
      "resetting env. episode reward total was 5.0. running mean: 10.340920273931102\n",
      "resetting env. episode reward total was 7.0. running mean: 10.307511071191792\n",
      "resetting env. episode reward total was 15.0. running mean: 10.354435960479874\n",
      "resetting env. episode reward total was 9.0. running mean: 10.340891600875075\n",
      "resetting env. episode reward total was 19.0. running mean: 10.427482684866323\n",
      "resetting env. episode reward total was 11.0. running mean: 10.43320785801766\n",
      "resetting env. episode reward total was 17.0. running mean: 10.498875779437483\n",
      "resetting env. episode reward total was 12.0. running mean: 10.513887021643107\n",
      "resetting env. episode reward total was 1.0. running mean: 10.418748151426676\n",
      "resetting env. episode reward total was 13.0. running mean: 10.444560669912411\n",
      "resetting env. episode reward total was 17.0. running mean: 10.510115063213286\n",
      "resetting env. episode reward total was 11.0. running mean: 10.515013912581152\n",
      "resetting env. episode reward total was 16.0. running mean: 10.56986377345534\n",
      "resetting env. episode reward total was 4.0. running mean: 10.504165135720786\n",
      "resetting env. episode reward total was 14.0. running mean: 10.539123484363579\n",
      "resetting env. episode reward total was 12.0. running mean: 10.553732249519943\n",
      "resetting env. episode reward total was 11.0. running mean: 10.558194927024742\n",
      "resetting env. episode reward total was 2.0. running mean: 10.472612977754494\n",
      "resetting env. episode reward total was 7.0. running mean: 10.43788684797695\n",
      "resetting env. episode reward total was 6.0. running mean: 10.39350797949718\n",
      "resetting env. episode reward total was 15.0. running mean: 10.439572899702208\n",
      "resetting env. episode reward total was 15.0. running mean: 10.485177170705185\n",
      "resetting env. episode reward total was 10.0. running mean: 10.480325398998133\n",
      "resetting env. episode reward total was 15.0. running mean: 10.525522145008152\n",
      "resetting env. episode reward total was 1.0. running mean: 10.43026692355807\n",
      "resetting env. episode reward total was 17.0. running mean: 10.49596425432249\n",
      "resetting env. episode reward total was 12.0. running mean: 10.511004611779263\n",
      "resetting env. episode reward total was 10.0. running mean: 10.505894565661471\n",
      "resetting env. episode reward total was 10.0. running mean: 10.500835620004857\n",
      "resetting env. episode reward total was 5.0. running mean: 10.445827263804809\n",
      "resetting env. episode reward total was 6.0. running mean: 10.40136899116676\n",
      "resetting env. episode reward total was 9.0. running mean: 10.387355301255093\n",
      "resetting env. episode reward total was 11.0. running mean: 10.393481748242541\n",
      "resetting env. episode reward total was 10.0. running mean: 10.389546930760115\n",
      "resetting env. episode reward total was 11.0. running mean: 10.395651461452514\n",
      "resetting env. episode reward total was 19.0. running mean: 10.481694946837989\n",
      "resetting env. episode reward total was 9.0. running mean: 10.466877997369608\n",
      "resetting env. episode reward total was 11.0. running mean: 10.47220921739591\n",
      "resetting env. episode reward total was 13.0. running mean: 10.497487125221951\n",
      "resetting env. episode reward total was 10.0. running mean: 10.492512253969732\n",
      "resetting env. episode reward total was 9.0. running mean: 10.477587131430035\n",
      "resetting env. episode reward total was 6.0. running mean: 10.432811260115734\n",
      "resetting env. episode reward total was 13.0. running mean: 10.458483147514578\n",
      "resetting env. episode reward total was 9.0. running mean: 10.443898316039432\n",
      "resetting env. episode reward total was 7.0. running mean: 10.409459332879038\n",
      "resetting env. episode reward total was 9.0. running mean: 10.395364739550248\n",
      "resetting env. episode reward total was 7.0. running mean: 10.361411092154745\n",
      "resetting env. episode reward total was 11.0. running mean: 10.367796981233196\n",
      "resetting env. episode reward total was 7.0. running mean: 10.334119011420864\n",
      "resetting env. episode reward total was 17.0. running mean: 10.400777821306654\n",
      "resetting env. episode reward total was 16.0. running mean: 10.456770043093588\n",
      "resetting env. episode reward total was 17.0. running mean: 10.522202342662652\n",
      "resetting env. episode reward total was 17.0. running mean: 10.586980319236025\n",
      "resetting env. episode reward total was 10.0. running mean: 10.581110516043664\n",
      "resetting env. episode reward total was 13.0. running mean: 10.605299410883228\n",
      "resetting env. episode reward total was 11.0. running mean: 10.609246416774395\n",
      "resetting env. episode reward total was 9.0. running mean: 10.59315395260665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 10.607222413080583\n",
      "resetting env. episode reward total was 8.0. running mean: 10.581150188949778\n",
      "resetting env. episode reward total was 9.0. running mean: 10.56533868706028\n",
      "resetting env. episode reward total was 16.0. running mean: 10.619685300189676\n",
      "resetting env. episode reward total was 9.0. running mean: 10.603488447187779\n",
      "resetting env. episode reward total was 5.0. running mean: 10.547453562715901\n",
      "resetting env. episode reward total was 18.0. running mean: 10.621979027088742\n",
      "resetting env. episode reward total was 15.0. running mean: 10.665759236817854\n",
      "resetting env. episode reward total was 7.0. running mean: 10.629101644449676\n",
      "resetting env. episode reward total was 17.0. running mean: 10.69281062800518\n",
      "resetting env. episode reward total was 2.0. running mean: 10.605882521725128\n",
      "resetting env. episode reward total was 12.0. running mean: 10.619823696507876\n",
      "resetting env. episode reward total was 9.0. running mean: 10.603625459542796\n",
      "resetting env. episode reward total was 14.0. running mean: 10.637589204947368\n",
      "resetting env. episode reward total was 11.0. running mean: 10.641213312897893\n",
      "resetting env. episode reward total was 19.0. running mean: 10.724801179768914\n",
      "resetting env. episode reward total was 13.0. running mean: 10.747553167971226\n",
      "resetting env. episode reward total was 13.0. running mean: 10.770077636291514\n",
      "resetting env. episode reward total was 15.0. running mean: 10.8123768599286\n",
      "resetting env. episode reward total was 15.0. running mean: 10.854253091329314\n",
      "resetting env. episode reward total was 5.0. running mean: 10.79571056041602\n",
      "resetting env. episode reward total was 5.0. running mean: 10.73775345481186\n",
      "resetting env. episode reward total was 14.0. running mean: 10.770375920263742\n",
      "resetting env. episode reward total was 6.0. running mean: 10.722672161061105\n",
      "resetting env. episode reward total was 10.0. running mean: 10.715445439450493\n",
      "resetting env. episode reward total was 16.0. running mean: 10.768290985055987\n",
      "resetting env. episode reward total was 6.0. running mean: 10.720608075205428\n",
      "resetting env. episode reward total was 8.0. running mean: 10.693401994453374\n",
      "resetting env. episode reward total was 10.0. running mean: 10.68646797450884\n",
      "resetting env. episode reward total was 11.0. running mean: 10.689603294763751\n",
      "resetting env. episode reward total was 14.0. running mean: 10.722707261816113\n",
      "resetting env. episode reward total was 4.0. running mean: 10.65548018919795\n",
      "resetting env. episode reward total was 16.0. running mean: 10.708925387305971\n",
      "resetting env. episode reward total was 8.0. running mean: 10.681836133432911\n",
      "resetting env. episode reward total was 10.0. running mean: 10.675017772098581\n",
      "resetting env. episode reward total was 4.0. running mean: 10.608267594377594\n",
      "resetting env. episode reward total was 11.0. running mean: 10.612184918433817\n",
      "resetting env. episode reward total was 7.0. running mean: 10.576063069249479\n",
      "resetting env. episode reward total was 13.0. running mean: 10.600302438556984\n",
      "resetting env. episode reward total was 12.0. running mean: 10.614299414171413\n",
      "resetting env. episode reward total was 8.0. running mean: 10.588156420029698\n",
      "resetting env. episode reward total was 8.0. running mean: 10.5622748558294\n",
      "resetting env. episode reward total was 16.0. running mean: 10.616652107271106\n",
      "resetting env. episode reward total was 16.0. running mean: 10.670485586198396\n",
      "resetting env. episode reward total was 3.0. running mean: 10.59378073033641\n",
      "resetting env. episode reward total was 6.0. running mean: 10.547842923033047\n",
      "resetting env. episode reward total was 11.0. running mean: 10.552364493802715\n",
      "resetting env. episode reward total was 13.0. running mean: 10.576840848864688\n",
      "resetting env. episode reward total was 14.0. running mean: 10.611072440376041\n",
      "resetting env. episode reward total was 8.0. running mean: 10.58496171597228\n",
      "resetting env. episode reward total was 14.0. running mean: 10.619112098812558\n",
      "resetting env. episode reward total was 16.0. running mean: 10.672920977824432\n",
      "resetting env. episode reward total was 14.0. running mean: 10.706191768046189\n",
      "resetting env. episode reward total was 12.0. running mean: 10.719129850365727\n",
      "resetting env. episode reward total was 6.0. running mean: 10.67193855186207\n",
      "resetting env. episode reward total was 7.0. running mean: 10.635219166343449\n",
      "resetting env. episode reward total was 12.0. running mean: 10.648866974680013\n",
      "resetting env. episode reward total was 16.0. running mean: 10.702378304933212\n",
      "resetting env. episode reward total was 8.0. running mean: 10.67535452188388\n",
      "resetting env. episode reward total was 5.0. running mean: 10.618600976665043\n",
      "resetting env. episode reward total was 10.0. running mean: 10.612414966898392\n",
      "resetting env. episode reward total was 9.0. running mean: 10.596290817229407\n",
      "resetting env. episode reward total was 12.0. running mean: 10.610327909057112\n",
      "resetting env. episode reward total was 9.0. running mean: 10.59422462996654\n",
      "resetting env. episode reward total was 11.0. running mean: 10.598282383666874\n",
      "resetting env. episode reward total was 10.0. running mean: 10.592299559830204\n",
      "resetting env. episode reward total was 9.0. running mean: 10.576376564231902\n",
      "resetting env. episode reward total was 15.0. running mean: 10.620612798589583\n",
      "resetting env. episode reward total was 7.0. running mean: 10.584406670603688\n",
      "resetting env. episode reward total was 17.0. running mean: 10.64856260389765\n",
      "resetting env. episode reward total was 7.0. running mean: 10.612076977858674\n",
      "resetting env. episode reward total was 10.0. running mean: 10.605956208080087\n",
      "resetting env. episode reward total was 16.0. running mean: 10.659896645999286\n",
      "resetting env. episode reward total was 15.0. running mean: 10.703297679539293\n",
      "resetting env. episode reward total was 10.0. running mean: 10.6962647027439\n",
      "resetting env. episode reward total was 14.0. running mean: 10.729302055716461\n",
      "resetting env. episode reward total was 10.0. running mean: 10.722009035159296\n",
      "resetting env. episode reward total was 6.0. running mean: 10.674788944807704\n",
      "resetting env. episode reward total was 15.0. running mean: 10.718041055359627\n",
      "resetting env. episode reward total was 11.0. running mean: 10.72086064480603\n",
      "resetting env. episode reward total was 13.0. running mean: 10.743652038357972\n",
      "resetting env. episode reward total was 7.0. running mean: 10.706215517974393\n",
      "resetting env. episode reward total was 14.0. running mean: 10.73915336279465\n",
      "resetting env. episode reward total was 15.0. running mean: 10.781761829166703\n",
      "resetting env. episode reward total was 11.0. running mean: 10.783944210875035\n",
      "resetting env. episode reward total was 17.0. running mean: 10.846104768766285\n",
      "resetting env. episode reward total was 15.0. running mean: 10.887643721078621\n",
      "resetting env. episode reward total was 9.0. running mean: 10.868767283867834\n",
      "resetting env. episode reward total was 12.0. running mean: 10.880079611029155\n",
      "resetting env. episode reward total was -2.0. running mean: 10.751278814918864\n",
      "resetting env. episode reward total was 13.0. running mean: 10.773766026769676\n",
      "resetting env. episode reward total was 13.0. running mean: 10.79602836650198\n",
      "resetting env. episode reward total was 10.0. running mean: 10.78806808283696\n",
      "resetting env. episode reward total was 16.0. running mean: 10.84018740200859\n",
      "resetting env. episode reward total was 9.0. running mean: 10.821785527988505\n",
      "resetting env. episode reward total was 10.0. running mean: 10.813567672708619\n",
      "resetting env. episode reward total was 8.0. running mean: 10.785431995981533\n",
      "resetting env. episode reward total was 17.0. running mean: 10.847577676021718\n",
      "resetting env. episode reward total was 10.0. running mean: 10.8391018992615\n",
      "resetting env. episode reward total was 10.0. running mean: 10.830710880268885\n",
      "resetting env. episode reward total was 12.0. running mean: 10.842403771466195\n",
      "resetting env. episode reward total was 11.0. running mean: 10.843979733751532\n",
      "resetting env. episode reward total was 10.0. running mean: 10.835539936414015\n",
      "resetting env. episode reward total was -5.0. running mean: 10.677184537049875\n",
      "resetting env. episode reward total was 6.0. running mean: 10.630412691679377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 10.624108564762583\n",
      "resetting env. episode reward total was 12.0. running mean: 10.637867479114956\n",
      "resetting env. episode reward total was 18.0. running mean: 10.711488804323805\n",
      "resetting env. episode reward total was 11.0. running mean: 10.714373916280566\n",
      "resetting env. episode reward total was 7.0. running mean: 10.67723017711776\n",
      "resetting env. episode reward total was 13.0. running mean: 10.700457875346583\n",
      "resetting env. episode reward total was 17.0. running mean: 10.763453296593116\n",
      "resetting env. episode reward total was 12.0. running mean: 10.775818763627184\n",
      "resetting env. episode reward total was 7.0. running mean: 10.738060575990913\n",
      "resetting env. episode reward total was 15.0. running mean: 10.780679970231004\n",
      "resetting env. episode reward total was 12.0. running mean: 10.792873170528694\n",
      "resetting env. episode reward total was 9.0. running mean: 10.774944438823406\n",
      "resetting env. episode reward total was 10.0. running mean: 10.76719499443517\n",
      "resetting env. episode reward total was 15.0. running mean: 10.809523044490819\n",
      "resetting env. episode reward total was 12.0. running mean: 10.82142781404591\n",
      "resetting env. episode reward total was 9.0. running mean: 10.803213535905451\n",
      "resetting env. episode reward total was 12.0. running mean: 10.815181400546395\n",
      "resetting env. episode reward total was -2.0. running mean: 10.687029586540932\n",
      "resetting env. episode reward total was 15.0. running mean: 10.730159290675523\n",
      "resetting env. episode reward total was 10.0. running mean: 10.722857697768768\n",
      "resetting env. episode reward total was 14.0. running mean: 10.755629120791081\n",
      "resetting env. episode reward total was 18.0. running mean: 10.828072829583169\n",
      "resetting env. episode reward total was 15.0. running mean: 10.869792101287338\n",
      "resetting env. episode reward total was 4.0. running mean: 10.801094180274463\n",
      "resetting env. episode reward total was 12.0. running mean: 10.813083238471718\n",
      "resetting env. episode reward total was 17.0. running mean: 10.874952406087\n",
      "resetting env. episode reward total was 17.0. running mean: 10.93620288202613\n",
      "resetting env. episode reward total was 14.0. running mean: 10.96684085320587\n",
      "resetting env. episode reward total was 7.0. running mean: 10.927172444673811\n",
      "resetting env. episode reward total was 13.0. running mean: 10.947900720227073\n",
      "resetting env. episode reward total was 7.0. running mean: 10.908421713024802\n",
      "resetting env. episode reward total was 16.0. running mean: 10.959337495894555\n",
      "resetting env. episode reward total was 3.0. running mean: 10.879744120935609\n",
      "resetting env. episode reward total was 11.0. running mean: 10.880946679726252\n",
      "resetting env. episode reward total was 13.0. running mean: 10.90213721292899\n",
      "resetting env. episode reward total was 9.0. running mean: 10.8831158407997\n",
      "resetting env. episode reward total was 11.0. running mean: 10.884284682391703\n",
      "resetting env. episode reward total was 13.0. running mean: 10.905441835567787\n",
      "resetting env. episode reward total was 15.0. running mean: 10.94638741721211\n",
      "resetting env. episode reward total was 9.0. running mean: 10.926923543039988\n",
      "resetting env. episode reward total was 11.0. running mean: 10.927654307609588\n",
      "resetting env. episode reward total was 8.0. running mean: 10.898377764533492\n",
      "resetting env. episode reward total was 20.0. running mean: 10.989393986888157\n",
      "resetting env. episode reward total was 14.0. running mean: 11.019500047019276\n",
      "resetting env. episode reward total was 9.0. running mean: 10.999305046549082\n",
      "resetting env. episode reward total was 4.0. running mean: 10.929311996083591\n",
      "resetting env. episode reward total was 8.0. running mean: 10.900018876122756\n",
      "resetting env. episode reward total was 20.0. running mean: 10.991018687361528\n",
      "resetting env. episode reward total was 15.0. running mean: 11.031108500487914\n",
      "resetting env. episode reward total was 19.0. running mean: 11.110797415483034\n",
      "resetting env. episode reward total was 13.0. running mean: 11.129689441328205\n",
      "resetting env. episode reward total was 1.0. running mean: 11.028392546914922\n",
      "resetting env. episode reward total was 11.0. running mean: 11.028108621445773\n",
      "resetting env. episode reward total was 11.0. running mean: 11.027827535231314\n",
      "resetting env. episode reward total was 11.0. running mean: 11.027549259879\n",
      "resetting env. episode reward total was 10.0. running mean: 11.01727376728021\n",
      "resetting env. episode reward total was 17.0. running mean: 11.077101029607409\n",
      "resetting env. episode reward total was 12.0. running mean: 11.086330019311333\n",
      "resetting env. episode reward total was 12.0. running mean: 11.09546671911822\n",
      "resetting env. episode reward total was 14.0. running mean: 11.124512051927038\n",
      "resetting env. episode reward total was 11.0. running mean: 11.123266931407766\n",
      "resetting env. episode reward total was 12.0. running mean: 11.132034262093688\n",
      "resetting env. episode reward total was 9.0. running mean: 11.11071391947275\n",
      "resetting env. episode reward total was 15.0. running mean: 11.149606780278024\n",
      "resetting env. episode reward total was 15.0. running mean: 11.188110712475243\n",
      "resetting env. episode reward total was 9.0. running mean: 11.166229605350491\n",
      "resetting env. episode reward total was 5.0. running mean: 11.104567309296987\n",
      "resetting env. episode reward total was 11.0. running mean: 11.103521636204016\n",
      "resetting env. episode reward total was 4.0. running mean: 11.032486419841975\n",
      "resetting env. episode reward total was 15.0. running mean: 11.072161555643556\n",
      "resetting env. episode reward total was 3.0. running mean: 10.991439940087119\n",
      "resetting env. episode reward total was 15.0. running mean: 11.031525540686248\n",
      "resetting env. episode reward total was 8.0. running mean: 11.001210285279386\n",
      "resetting env. episode reward total was 13.0. running mean: 11.021198182426593\n",
      "resetting env. episode reward total was 13.0. running mean: 11.040986200602328\n",
      "resetting env. episode reward total was 14.0. running mean: 11.070576338596306\n",
      "resetting env. episode reward total was 16.0. running mean: 11.119870575210342\n",
      "resetting env. episode reward total was 12.0. running mean: 11.128671869458238\n",
      "resetting env. episode reward total was 12.0. running mean: 11.137385150763654\n",
      "resetting env. episode reward total was 16.0. running mean: 11.186011299256018\n",
      "resetting env. episode reward total was 11.0. running mean: 11.184151186263456\n",
      "resetting env. episode reward total was 4.0. running mean: 11.112309674400821\n",
      "resetting env. episode reward total was 15.0. running mean: 11.151186577656814\n",
      "resetting env. episode reward total was 5.0. running mean: 11.089674711880246\n",
      "resetting env. episode reward total was 14.0. running mean: 11.118777964761444\n",
      "resetting env. episode reward total was 17.0. running mean: 11.177590185113829\n",
      "resetting env. episode reward total was 16.0. running mean: 11.225814283262691\n",
      "resetting env. episode reward total was 14.0. running mean: 11.253556140430065\n",
      "resetting env. episode reward total was 15.0. running mean: 11.291020579025766\n",
      "resetting env. episode reward total was 13.0. running mean: 11.30811037323551\n",
      "resetting env. episode reward total was 15.0. running mean: 11.345029269503154\n",
      "resetting env. episode reward total was 10.0. running mean: 11.331578976808123\n",
      "resetting env. episode reward total was 12.0. running mean: 11.33826318704004\n",
      "resetting env. episode reward total was 18.0. running mean: 11.404880555169639\n",
      "resetting env. episode reward total was 15.0. running mean: 11.440831749617942\n",
      "resetting env. episode reward total was 12.0. running mean: 11.446423432121762\n",
      "resetting env. episode reward total was 5.0. running mean: 11.381959197800544\n",
      "resetting env. episode reward total was 10.0. running mean: 11.368139605822538\n",
      "resetting env. episode reward total was 10.0. running mean: 11.354458209764312\n",
      "resetting env. episode reward total was 16.0. running mean: 11.400913627666668\n",
      "resetting env. episode reward total was 15.0. running mean: 11.43690449139\n",
      "resetting env. episode reward total was 11.0. running mean: 11.4325354464761\n",
      "resetting env. episode reward total was 12.0. running mean: 11.438210092011339\n",
      "resetting env. episode reward total was 14.0. running mean: 11.463827991091225\n",
      "resetting env. episode reward total was 9.0. running mean: 11.439189711180314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 11.44479781406851\n",
      "resetting env. episode reward total was 7.0. running mean: 11.400349835927825\n",
      "resetting env. episode reward total was -2.0. running mean: 11.266346337568548\n",
      "resetting env. episode reward total was 17.0. running mean: 11.323682874192862\n",
      "resetting env. episode reward total was 7.0. running mean: 11.280446045450933\n",
      "resetting env. episode reward total was 10.0. running mean: 11.267641584996424\n",
      "resetting env. episode reward total was 13.0. running mean: 11.28496516914646\n",
      "resetting env. episode reward total was 16.0. running mean: 11.332115517454996\n",
      "resetting env. episode reward total was 14.0. running mean: 11.358794362280447\n",
      "resetting env. episode reward total was 17.0. running mean: 11.415206418657643\n",
      "resetting env. episode reward total was 20.0. running mean: 11.501054354471066\n",
      "resetting env. episode reward total was 15.0. running mean: 11.536043810926355\n",
      "resetting env. episode reward total was 9.0. running mean: 11.510683372817091\n",
      "resetting env. episode reward total was 10.0. running mean: 11.495576539088919\n",
      "resetting env. episode reward total was 5.0. running mean: 11.430620773698031\n",
      "resetting env. episode reward total was 11.0. running mean: 11.42631456596105\n",
      "resetting env. episode reward total was 7.0. running mean: 11.38205142030144\n",
      "resetting env. episode reward total was 11.0. running mean: 11.378230906098425\n",
      "resetting env. episode reward total was 8.0. running mean: 11.344448597037442\n",
      "resetting env. episode reward total was 9.0. running mean: 11.321004111067067\n",
      "resetting env. episode reward total was 12.0. running mean: 11.327794069956395\n",
      "resetting env. episode reward total was 15.0. running mean: 11.364516129256831\n",
      "resetting env. episode reward total was 16.0. running mean: 11.410870967964263\n",
      "resetting env. episode reward total was 15.0. running mean: 11.44676225828462\n",
      "resetting env. episode reward total was -2.0. running mean: 11.312294635701774\n",
      "resetting env. episode reward total was 14.0. running mean: 11.339171689344756\n",
      "resetting env. episode reward total was 13.0. running mean: 11.355779972451309\n",
      "resetting env. episode reward total was 19.0. running mean: 11.432222172726796\n",
      "resetting env. episode reward total was 19.0. running mean: 11.507899950999528\n",
      "resetting env. episode reward total was 10.0. running mean: 11.492820951489533\n",
      "resetting env. episode reward total was 13.0. running mean: 11.507892741974638\n",
      "resetting env. episode reward total was 16.0. running mean: 11.552813814554892\n",
      "resetting env. episode reward total was 7.0. running mean: 11.507285676409342\n",
      "resetting env. episode reward total was 18.0. running mean: 11.572212819645248\n",
      "resetting env. episode reward total was 9.0. running mean: 11.546490691448795\n",
      "resetting env. episode reward total was 4.0. running mean: 11.471025784534307\n",
      "resetting env. episode reward total was 11.0. running mean: 11.466315526688962\n",
      "resetting env. episode reward total was 11.0. running mean: 11.461652371422073\n",
      "resetting env. episode reward total was 5.0. running mean: 11.397035847707853\n",
      "resetting env. episode reward total was 12.0. running mean: 11.403065489230773\n",
      "resetting env. episode reward total was 15.0. running mean: 11.439034834338466\n",
      "resetting env. episode reward total was -1.0. running mean: 11.314644485995082\n",
      "resetting env. episode reward total was 15.0. running mean: 11.351498041135132\n",
      "resetting env. episode reward total was 8.0. running mean: 11.317983060723781\n",
      "resetting env. episode reward total was 11.0. running mean: 11.314803230116542\n",
      "resetting env. episode reward total was 16.0. running mean: 11.361655197815377\n",
      "resetting env. episode reward total was 14.0. running mean: 11.388038645837224\n",
      "resetting env. episode reward total was 12.0. running mean: 11.39415825937885\n",
      "resetting env. episode reward total was 8.0. running mean: 11.360216676785061\n",
      "resetting env. episode reward total was 16.0. running mean: 11.40661451001721\n",
      "resetting env. episode reward total was 9.0. running mean: 11.382548364917037\n",
      "resetting env. episode reward total was 9.0. running mean: 11.358722881267866\n",
      "resetting env. episode reward total was 15.0. running mean: 11.395135652455188\n",
      "resetting env. episode reward total was 10.0. running mean: 11.381184295930636\n",
      "resetting env. episode reward total was 16.0. running mean: 11.42737245297133\n",
      "resetting env. episode reward total was 7.0. running mean: 11.383098728441617\n",
      "resetting env. episode reward total was -7.0. running mean: 11.1992677411572\n",
      "resetting env. episode reward total was 10.0. running mean: 11.187275063745627\n",
      "resetting env. episode reward total was 8.0. running mean: 11.155402313108171\n",
      "resetting env. episode reward total was 15.0. running mean: 11.19384828997709\n",
      "resetting env. episode reward total was 5.0. running mean: 11.13190980707732\n",
      "resetting env. episode reward total was 19.0. running mean: 11.210590709006548\n",
      "resetting env. episode reward total was 10.0. running mean: 11.198484801916482\n",
      "resetting env. episode reward total was 13.0. running mean: 11.216499953897317\n",
      "resetting env. episode reward total was 10.0. running mean: 11.204334954358345\n",
      "resetting env. episode reward total was 14.0. running mean: 11.232291604814762\n",
      "resetting env. episode reward total was 9.0. running mean: 11.209968688766613\n",
      "resetting env. episode reward total was 7.0. running mean: 11.167869001878948\n",
      "resetting env. episode reward total was 11.0. running mean: 11.166190311860158\n",
      "resetting env. episode reward total was 16.0. running mean: 11.214528408741556\n",
      "resetting env. episode reward total was 12.0. running mean: 11.22238312465414\n",
      "resetting env. episode reward total was 12.0. running mean: 11.230159293407597\n",
      "resetting env. episode reward total was 14.0. running mean: 11.257857700473522\n",
      "resetting env. episode reward total was 10.0. running mean: 11.245279123468787\n",
      "resetting env. episode reward total was 17.0. running mean: 11.3028263322341\n",
      "resetting env. episode reward total was 13.0. running mean: 11.319798068911759\n",
      "resetting env. episode reward total was 11.0. running mean: 11.316600088222641\n",
      "resetting env. episode reward total was 15.0. running mean: 11.353434087340414\n",
      "resetting env. episode reward total was 12.0. running mean: 11.35989974646701\n",
      "resetting env. episode reward total was 10.0. running mean: 11.346300749002339\n",
      "resetting env. episode reward total was 11.0. running mean: 11.342837741512314\n",
      "resetting env. episode reward total was 7.0. running mean: 11.29940936409719\n",
      "resetting env. episode reward total was 17.0. running mean: 11.356415270456218\n",
      "resetting env. episode reward total was 9.0. running mean: 11.332851117751655\n",
      "resetting env. episode reward total was 14.0. running mean: 11.359522606574139\n",
      "resetting env. episode reward total was 12.0. running mean: 11.365927380508396\n",
      "resetting env. episode reward total was 12.0. running mean: 11.372268106703311\n",
      "resetting env. episode reward total was 12.0. running mean: 11.378545425636277\n",
      "resetting env. episode reward total was 10.0. running mean: 11.364759971379915\n",
      "resetting env. episode reward total was 14.0. running mean: 11.391112371666116\n",
      "resetting env. episode reward total was 1.0. running mean: 11.287201247949454\n",
      "resetting env. episode reward total was 14.0. running mean: 11.31432923546996\n",
      "resetting env. episode reward total was 7.0. running mean: 11.271185943115261\n",
      "resetting env. episode reward total was 13.0. running mean: 11.28847408368411\n",
      "resetting env. episode reward total was 5.0. running mean: 11.225589342847268\n",
      "resetting env. episode reward total was 10.0. running mean: 11.213333449418794\n",
      "resetting env. episode reward total was 12.0. running mean: 11.221200114924605\n",
      "resetting env. episode reward total was 9.0. running mean: 11.198988113775359\n",
      "resetting env. episode reward total was 16.0. running mean: 11.246998232637605\n",
      "resetting env. episode reward total was 4.0. running mean: 11.174528250311228\n",
      "resetting env. episode reward total was 10.0. running mean: 11.162782967808116\n",
      "resetting env. episode reward total was 12.0. running mean: 11.171155138130034\n",
      "resetting env. episode reward total was 11.0. running mean: 11.169443586748732\n",
      "resetting env. episode reward total was 8.0. running mean: 11.137749150881245\n",
      "resetting env. episode reward total was 10.0. running mean: 11.126371659372431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 11.165107942778707\n",
      "resetting env. episode reward total was 10.0. running mean: 11.15345686335092\n",
      "resetting env. episode reward total was 10.0. running mean: 11.14192229471741\n",
      "resetting env. episode reward total was 9.0. running mean: 11.120503071770237\n",
      "resetting env. episode reward total was 11.0. running mean: 11.119298041052534\n",
      "resetting env. episode reward total was 11.0. running mean: 11.118105060642009\n",
      "resetting env. episode reward total was 10.0. running mean: 11.106924010035588\n",
      "resetting env. episode reward total was 11.0. running mean: 11.105854769935231\n",
      "resetting env. episode reward total was 10.0. running mean: 11.094796222235878\n",
      "resetting env. episode reward total was 8.0. running mean: 11.06384826001352\n",
      "resetting env. episode reward total was 14.0. running mean: 11.093209777413385\n",
      "resetting env. episode reward total was 16.0. running mean: 11.142277679639252\n",
      "resetting env. episode reward total was 7.0. running mean: 11.10085490284286\n",
      "resetting env. episode reward total was 11.0. running mean: 11.099846353814431\n",
      "resetting env. episode reward total was 7.0. running mean: 11.058847890276287\n",
      "resetting env. episode reward total was -3.0. running mean: 10.918259411373525\n",
      "resetting env. episode reward total was 19.0. running mean: 10.99907681725979\n",
      "resetting env. episode reward total was 13.0. running mean: 11.019086049087193\n",
      "resetting env. episode reward total was 11.0. running mean: 11.01889518859632\n",
      "resetting env. episode reward total was 16.0. running mean: 11.068706236710357\n",
      "resetting env. episode reward total was 12.0. running mean: 11.078019174343252\n",
      "resetting env. episode reward total was 12.0. running mean: 11.08723898259982\n",
      "resetting env. episode reward total was 14.0. running mean: 11.116366592773822\n",
      "resetting env. episode reward total was 15.0. running mean: 11.155202926846083\n",
      "resetting env. episode reward total was 8.0. running mean: 11.123650897577622\n",
      "resetting env. episode reward total was 7.0. running mean: 11.082414388601846\n",
      "resetting env. episode reward total was 11.0. running mean: 11.081590244715827\n",
      "resetting env. episode reward total was 19.0. running mean: 11.160774342268668\n",
      "resetting env. episode reward total was 9.0. running mean: 11.139166598845982\n",
      "resetting env. episode reward total was 14.0. running mean: 11.167774932857522\n",
      "resetting env. episode reward total was 13.0. running mean: 11.186097183528949\n",
      "resetting env. episode reward total was 6.0. running mean: 11.13423621169366\n",
      "resetting env. episode reward total was 6.0. running mean: 11.082893849576724\n",
      "resetting env. episode reward total was 15.0. running mean: 11.122064911080956\n",
      "resetting env. episode reward total was 7.0. running mean: 11.080844261970148\n",
      "resetting env. episode reward total was 17.0. running mean: 11.140035819350446\n",
      "resetting env. episode reward total was 10.0. running mean: 11.128635461156941\n",
      "resetting env. episode reward total was 14.0. running mean: 11.157349106545372\n",
      "resetting env. episode reward total was 17.0. running mean: 11.215775615479918\n",
      "resetting env. episode reward total was 14.0. running mean: 11.24361785932512\n",
      "resetting env. episode reward total was 8.0. running mean: 11.211181680731869\n",
      "resetting env. episode reward total was 12.0. running mean: 11.219069863924549\n",
      "resetting env. episode reward total was 12.0. running mean: 11.226879165285302\n",
      "resetting env. episode reward total was 12.0. running mean: 11.234610373632448\n",
      "resetting env. episode reward total was 13.0. running mean: 11.252264269896123\n",
      "resetting env. episode reward total was 6.0. running mean: 11.199741627197163\n",
      "resetting env. episode reward total was 14.0. running mean: 11.227744210925191\n",
      "resetting env. episode reward total was 11.0. running mean: 11.22546676881594\n",
      "resetting env. episode reward total was 11.0. running mean: 11.22321210112778\n",
      "resetting env. episode reward total was 10.0. running mean: 11.210979980116502\n",
      "resetting env. episode reward total was 15.0. running mean: 11.248870180315336\n",
      "resetting env. episode reward total was 10.0. running mean: 11.236381478512182\n",
      "resetting env. episode reward total was 9.0. running mean: 11.214017663727061\n",
      "resetting env. episode reward total was 16.0. running mean: 11.26187748708979\n",
      "resetting env. episode reward total was 11.0. running mean: 11.259258712218893\n",
      "resetting env. episode reward total was 3.0. running mean: 11.176666125096704\n",
      "resetting env. episode reward total was 16.0. running mean: 11.224899463845736\n",
      "resetting env. episode reward total was 10.0. running mean: 11.212650469207277\n",
      "resetting env. episode reward total was 14.0. running mean: 11.240523964515205\n",
      "resetting env. episode reward total was 2.0. running mean: 11.148118724870052\n",
      "resetting env. episode reward total was 8.0. running mean: 11.11663753762135\n",
      "resetting env. episode reward total was 14.0. running mean: 11.145471162245137\n",
      "resetting env. episode reward total was -3.0. running mean: 11.004016450622686\n",
      "resetting env. episode reward total was 10.0. running mean: 10.993976286116458\n",
      "resetting env. episode reward total was 15.0. running mean: 11.034036523255294\n",
      "resetting env. episode reward total was 11.0. running mean: 11.03369615802274\n",
      "resetting env. episode reward total was 19.0. running mean: 11.113359196442513\n",
      "resetting env. episode reward total was 15.0. running mean: 11.152225604478089\n",
      "resetting env. episode reward total was 10.0. running mean: 11.140703348433307\n",
      "resetting env. episode reward total was 14.0. running mean: 11.169296314948975\n",
      "resetting env. episode reward total was 16.0. running mean: 11.217603351799484\n",
      "resetting env. episode reward total was 8.0. running mean: 11.185427318281489\n",
      "resetting env. episode reward total was 17.0. running mean: 11.243573045098675\n",
      "resetting env. episode reward total was 17.0. running mean: 11.301137314647688\n",
      "resetting env. episode reward total was 11.0. running mean: 11.29812594150121\n",
      "resetting env. episode reward total was 12.0. running mean: 11.305144682086198\n",
      "resetting env. episode reward total was 12.0. running mean: 11.312093235265335\n",
      "resetting env. episode reward total was 15.0. running mean: 11.348972302912681\n",
      "resetting env. episode reward total was 15.0. running mean: 11.385482579883554\n",
      "resetting env. episode reward total was 12.0. running mean: 11.391627754084718\n",
      "resetting env. episode reward total was 8.0. running mean: 11.357711476543871\n",
      "resetting env. episode reward total was 13.0. running mean: 11.374134361778433\n",
      "resetting env. episode reward total was 11.0. running mean: 11.370393018160648\n",
      "resetting env. episode reward total was 11.0. running mean: 11.36668908797904\n",
      "resetting env. episode reward total was 6.0. running mean: 11.31302219709925\n",
      "resetting env. episode reward total was 8.0. running mean: 11.279891975128258\n",
      "resetting env. episode reward total was 15.0. running mean: 11.317093055376976\n",
      "resetting env. episode reward total was 5.0. running mean: 11.253922124823207\n",
      "resetting env. episode reward total was 19.0. running mean: 11.331382903574974\n",
      "resetting env. episode reward total was 11.0. running mean: 11.328069074539224\n",
      "resetting env. episode reward total was 9.0. running mean: 11.30478838379383\n",
      "resetting env. episode reward total was 11.0. running mean: 11.301740499955892\n",
      "resetting env. episode reward total was 15.0. running mean: 11.338723094956334\n",
      "resetting env. episode reward total was 13.0. running mean: 11.355335864006772\n",
      "resetting env. episode reward total was 5.0. running mean: 11.291782505366704\n",
      "resetting env. episode reward total was 11.0. running mean: 11.288864680313036\n",
      "resetting env. episode reward total was 16.0. running mean: 11.335976033509906\n",
      "resetting env. episode reward total was 5.0. running mean: 11.272616273174808\n",
      "resetting env. episode reward total was 12.0. running mean: 11.27989011044306\n",
      "resetting env. episode reward total was 19.0. running mean: 11.357091209338629\n",
      "resetting env. episode reward total was 15.0. running mean: 11.393520297245242\n",
      "resetting env. episode reward total was 12.0. running mean: 11.399585094272789\n",
      "resetting env. episode reward total was 13.0. running mean: 11.41558924333006\n",
      "resetting env. episode reward total was 8.0. running mean: 11.38143335089676\n",
      "resetting env. episode reward total was 11.0. running mean: 11.377619017387792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 11.353842827213914\n",
      "resetting env. episode reward total was 10.0. running mean: 11.340304398941774\n",
      "resetting env. episode reward total was 9.0. running mean: 11.316901354952355\n",
      "resetting env. episode reward total was 10.0. running mean: 11.303732341402831\n",
      "resetting env. episode reward total was 8.0. running mean: 11.270695017988803\n",
      "resetting env. episode reward total was 2.0. running mean: 11.177988067808915\n",
      "resetting env. episode reward total was 7.0. running mean: 11.136208187130826\n",
      "resetting env. episode reward total was 15.0. running mean: 11.174846105259519\n",
      "resetting env. episode reward total was 14.0. running mean: 11.203097644206924\n",
      "resetting env. episode reward total was 6.0. running mean: 11.151066667764855\n",
      "resetting env. episode reward total was 2.0. running mean: 11.059556001087206\n",
      "resetting env. episode reward total was 8.0. running mean: 11.028960441076334\n",
      "resetting env. episode reward total was 11.0. running mean: 11.02867083666557\n",
      "resetting env. episode reward total was 10.0. running mean: 11.018384128298914\n",
      "resetting env. episode reward total was 3.0. running mean: 10.938200287015924\n",
      "resetting env. episode reward total was 6.0. running mean: 10.888818284145765\n",
      "resetting env. episode reward total was 8.0. running mean: 10.859930101304307\n",
      "resetting env. episode reward total was 15.0. running mean: 10.901330800291264\n",
      "resetting env. episode reward total was 16.0. running mean: 10.952317492288351\n",
      "resetting env. episode reward total was 14.0. running mean: 10.982794317365467\n",
      "resetting env. episode reward total was 3.0. running mean: 10.902966374191813\n",
      "resetting env. episode reward total was 17.0. running mean: 10.963936710449895\n",
      "resetting env. episode reward total was 11.0. running mean: 10.964297343345395\n",
      "resetting env. episode reward total was 19.0. running mean: 11.04465436991194\n",
      "resetting env. episode reward total was 9.0. running mean: 11.024207826212821\n",
      "resetting env. episode reward total was 12.0. running mean: 11.033965747950692\n",
      "resetting env. episode reward total was 15.0. running mean: 11.073626090471185\n",
      "resetting env. episode reward total was 13.0. running mean: 11.092889829566474\n",
      "resetting env. episode reward total was 13.0. running mean: 11.11196093127081\n",
      "resetting env. episode reward total was 13.0. running mean: 11.130841321958103\n",
      "resetting env. episode reward total was 13.0. running mean: 11.149532908738523\n",
      "resetting env. episode reward total was 11.0. running mean: 11.148037579651138\n",
      "resetting env. episode reward total was 13.0. running mean: 11.166557203854628\n",
      "resetting env. episode reward total was 14.0. running mean: 11.194891631816082\n",
      "resetting env. episode reward total was 11.0. running mean: 11.19294271549792\n",
      "resetting env. episode reward total was 12.0. running mean: 11.20101328834294\n",
      "resetting env. episode reward total was 12.0. running mean: 11.20900315545951\n",
      "resetting env. episode reward total was 2.0. running mean: 11.116913123904913\n",
      "resetting env. episode reward total was 6.0. running mean: 11.065743992665865\n",
      "resetting env. episode reward total was 9.0. running mean: 11.045086552739207\n",
      "resetting env. episode reward total was 11.0. running mean: 11.044635687211814\n",
      "resetting env. episode reward total was 9.0. running mean: 11.024189330339695\n",
      "resetting env. episode reward total was 8.0. running mean: 10.993947437036297\n",
      "resetting env. episode reward total was 14.0. running mean: 11.024007962665936\n",
      "resetting env. episode reward total was 15.0. running mean: 11.063767883039276\n",
      "resetting env. episode reward total was 12.0. running mean: 11.073130204208882\n",
      "resetting env. episode reward total was 12.0. running mean: 11.082398902166792\n",
      "resetting env. episode reward total was 12.0. running mean: 11.091574913145124\n",
      "resetting env. episode reward total was 8.0. running mean: 11.060659164013673\n",
      "resetting env. episode reward total was 16.0. running mean: 11.110052572373537\n",
      "resetting env. episode reward total was 13.0. running mean: 11.128952046649802\n",
      "resetting env. episode reward total was 13.0. running mean: 11.147662526183305\n",
      "resetting env. episode reward total was 6.0. running mean: 11.096185900921473\n",
      "resetting env. episode reward total was 18.0. running mean: 11.165224041912257\n",
      "resetting env. episode reward total was 13.0. running mean: 11.183571801493136\n",
      "resetting env. episode reward total was 11.0. running mean: 11.181736083478203\n",
      "resetting env. episode reward total was 7.0. running mean: 11.13991872264342\n",
      "resetting env. episode reward total was 12.0. running mean: 11.148519535416986\n",
      "resetting env. episode reward total was 11.0. running mean: 11.147034340062815\n",
      "resetting env. episode reward total was 13.0. running mean: 11.165563996662188\n",
      "resetting env. episode reward total was 5.0. running mean: 11.103908356695566\n",
      "resetting env. episode reward total was 16.0. running mean: 11.15286927312861\n",
      "resetting env. episode reward total was 9.0. running mean: 11.131340580397325\n",
      "resetting env. episode reward total was 6.0. running mean: 11.080027174593353\n",
      "resetting env. episode reward total was 9.0. running mean: 11.059226902847419\n",
      "resetting env. episode reward total was 1.0. running mean: 10.958634633818944\n",
      "resetting env. episode reward total was 10.0. running mean: 10.949048287480753\n",
      "resetting env. episode reward total was 10.0. running mean: 10.939557804605945\n",
      "resetting env. episode reward total was 15.0. running mean: 10.980162226559885\n",
      "resetting env. episode reward total was 14.0. running mean: 11.010360604294288\n",
      "resetting env. episode reward total was 6.0. running mean: 10.960256998251346\n",
      "resetting env. episode reward total was 8.0. running mean: 10.930654428268832\n",
      "resetting env. episode reward total was 9.0. running mean: 10.911347883986144\n",
      "resetting env. episode reward total was 7.0. running mean: 10.872234405146283\n",
      "resetting env. episode reward total was 7.0. running mean: 10.83351206109482\n",
      "resetting env. episode reward total was 9.0. running mean: 10.815176940483871\n",
      "resetting env. episode reward total was 14.0. running mean: 10.847025171079034\n",
      "resetting env. episode reward total was 5.0. running mean: 10.788554919368245\n",
      "resetting env. episode reward total was 12.0. running mean: 10.800669370174562\n",
      "resetting env. episode reward total was 12.0. running mean: 10.812662676472815\n",
      "resetting env. episode reward total was 9.0. running mean: 10.794536049708087\n",
      "resetting env. episode reward total was 11.0. running mean: 10.796590689211007\n",
      "resetting env. episode reward total was 9.0. running mean: 10.778624782318897\n",
      "resetting env. episode reward total was 12.0. running mean: 10.790838534495707\n",
      "resetting env. episode reward total was 13.0. running mean: 10.81293014915075\n",
      "resetting env. episode reward total was 6.0. running mean: 10.764800847659243\n",
      "resetting env. episode reward total was 6.0. running mean: 10.717152839182651\n",
      "resetting env. episode reward total was 11.0. running mean: 10.719981310790823\n",
      "resetting env. episode reward total was 14.0. running mean: 10.752781497682916\n",
      "resetting env. episode reward total was 9.0. running mean: 10.735253682706087\n",
      "resetting env. episode reward total was 16.0. running mean: 10.787901145879026\n",
      "resetting env. episode reward total was 13.0. running mean: 10.810022134420237\n",
      "resetting env. episode reward total was 9.0. running mean: 10.791921913076035\n",
      "resetting env. episode reward total was 17.0. running mean: 10.854002693945274\n",
      "resetting env. episode reward total was 8.0. running mean: 10.825462667005821\n",
      "resetting env. episode reward total was 8.0. running mean: 10.797208040335763\n",
      "resetting env. episode reward total was 14.0. running mean: 10.829235959932406\n",
      "resetting env. episode reward total was 6.0. running mean: 10.780943600333082\n",
      "resetting env. episode reward total was 9.0. running mean: 10.76313416432975\n",
      "resetting env. episode reward total was 11.0. running mean: 10.765502822686452\n",
      "resetting env. episode reward total was 17.0. running mean: 10.827847794459588\n",
      "resetting env. episode reward total was 10.0. running mean: 10.819569316514992\n",
      "resetting env. episode reward total was 8.0. running mean: 10.791373623349841\n",
      "resetting env. episode reward total was 17.0. running mean: 10.853459887116342\n",
      "resetting env. episode reward total was 18.0. running mean: 10.924925288245179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 17.0. running mean: 10.985676035362728\n",
      "resetting env. episode reward total was 18.0. running mean: 11.0558192750091\n",
      "resetting env. episode reward total was 10.0. running mean: 11.045261082259008\n",
      "resetting env. episode reward total was 10.0. running mean: 11.034808471436419\n",
      "resetting env. episode reward total was 12.0. running mean: 11.044460386722054\n",
      "resetting env. episode reward total was 13.0. running mean: 11.064015782854835\n",
      "resetting env. episode reward total was 19.0. running mean: 11.143375625026286\n",
      "resetting env. episode reward total was 9.0. running mean: 11.121941868776023\n",
      "resetting env. episode reward total was 13.0. running mean: 11.140722450088264\n",
      "resetting env. episode reward total was 10.0. running mean: 11.12931522558738\n",
      "resetting env. episode reward total was 11.0. running mean: 11.128022073331506\n",
      "resetting env. episode reward total was 8.0. running mean: 11.096741852598191\n",
      "resetting env. episode reward total was 9.0. running mean: 11.075774434072208\n",
      "resetting env. episode reward total was 7.0. running mean: 11.035016689731487\n",
      "resetting env. episode reward total was 5.0. running mean: 10.974666522834173\n",
      "resetting env. episode reward total was 17.0. running mean: 11.034919857605832\n",
      "resetting env. episode reward total was 14.0. running mean: 11.064570659029775\n",
      "resetting env. episode reward total was 12.0. running mean: 11.073924952439476\n",
      "resetting env. episode reward total was -1.0. running mean: 10.953185702915082\n",
      "resetting env. episode reward total was 14.0. running mean: 10.983653845885932\n",
      "resetting env. episode reward total was 8.0. running mean: 10.953817307427073\n",
      "resetting env. episode reward total was 5.0. running mean: 10.894279134352804\n",
      "resetting env. episode reward total was 12.0. running mean: 10.905336343009274\n",
      "resetting env. episode reward total was 16.0. running mean: 10.956282979579182\n",
      "resetting env. episode reward total was 6.0. running mean: 10.906720149783391\n",
      "resetting env. episode reward total was 16.0. running mean: 10.957652948285556\n",
      "resetting env. episode reward total was 9.0. running mean: 10.9380764188027\n",
      "resetting env. episode reward total was 7.0. running mean: 10.898695654614674\n",
      "resetting env. episode reward total was 7.0. running mean: 10.859708698068527\n",
      "resetting env. episode reward total was 18.0. running mean: 10.931111611087841\n",
      "resetting env. episode reward total was 14.0. running mean: 10.961800494976963\n",
      "resetting env. episode reward total was 9.0. running mean: 10.942182490027193\n",
      "resetting env. episode reward total was 16.0. running mean: 10.992760665126921\n",
      "resetting env. episode reward total was 12.0. running mean: 11.002833058475652\n",
      "resetting env. episode reward total was 8.0. running mean: 10.972804727890896\n",
      "resetting env. episode reward total was 7.0. running mean: 10.933076680611988\n",
      "resetting env. episode reward total was 12.0. running mean: 10.943745913805866\n",
      "resetting env. episode reward total was 10.0. running mean: 10.934308454667807\n",
      "resetting env. episode reward total was 13.0. running mean: 10.95496537012113\n",
      "resetting env. episode reward total was 17.0. running mean: 11.015415716419918\n",
      "resetting env. episode reward total was 3.0. running mean: 10.935261559255718\n",
      "resetting env. episode reward total was 3.0. running mean: 10.85590894366316\n",
      "resetting env. episode reward total was 15.0. running mean: 10.897349854226528\n",
      "resetting env. episode reward total was 13.0. running mean: 10.918376355684263\n",
      "resetting env. episode reward total was 12.0. running mean: 10.92919259212742\n",
      "resetting env. episode reward total was 10.0. running mean: 10.919900666206145\n",
      "resetting env. episode reward total was 12.0. running mean: 10.930701659544082\n",
      "resetting env. episode reward total was 11.0. running mean: 10.931394642948641\n",
      "resetting env. episode reward total was 9.0. running mean: 10.912080696519155\n",
      "resetting env. episode reward total was 3.0. running mean: 10.832959889553962\n",
      "resetting env. episode reward total was 16.0. running mean: 10.884630290658423\n",
      "resetting env. episode reward total was 18.0. running mean: 10.955783987751838\n",
      "resetting env. episode reward total was 9.0. running mean: 10.936226147874319\n",
      "resetting env. episode reward total was 9.0. running mean: 10.916863886395575\n",
      "resetting env. episode reward total was 6.0. running mean: 10.86769524753162\n",
      "resetting env. episode reward total was 8.0. running mean: 10.839018295056304\n",
      "resetting env. episode reward total was 13.0. running mean: 10.860628112105742\n",
      "resetting env. episode reward total was 3.0. running mean: 10.782021830984684\n",
      "resetting env. episode reward total was 12.0. running mean: 10.794201612674836\n",
      "resetting env. episode reward total was 15.0. running mean: 10.836259596548087\n",
      "resetting env. episode reward total was 8.0. running mean: 10.807897000582606\n",
      "resetting env. episode reward total was 11.0. running mean: 10.80981803057678\n",
      "resetting env. episode reward total was 10.0. running mean: 10.801719850271011\n",
      "resetting env. episode reward total was 5.0. running mean: 10.743702651768302\n",
      "resetting env. episode reward total was 15.0. running mean: 10.78626562525062\n",
      "resetting env. episode reward total was 11.0. running mean: 10.788402968998113\n",
      "resetting env. episode reward total was 12.0. running mean: 10.800518939308132\n",
      "resetting env. episode reward total was 11.0. running mean: 10.80251374991505\n",
      "resetting env. episode reward total was 15.0. running mean: 10.8444886124159\n",
      "resetting env. episode reward total was 9.0. running mean: 10.82604372629174\n",
      "resetting env. episode reward total was 16.0. running mean: 10.877783289028823\n",
      "resetting env. episode reward total was 9.0. running mean: 10.859005456138535\n",
      "resetting env. episode reward total was 13.0. running mean: 10.88041540157715\n",
      "resetting env. episode reward total was 8.0. running mean: 10.851611247561378\n",
      "resetting env. episode reward total was 13.0. running mean: 10.873095135085764\n",
      "resetting env. episode reward total was 7.0. running mean: 10.834364183734907\n",
      "resetting env. episode reward total was 14.0. running mean: 10.866020541897559\n",
      "resetting env. episode reward total was 11.0. running mean: 10.867360336478582\n",
      "resetting env. episode reward total was 12.0. running mean: 10.878686733113796\n",
      "resetting env. episode reward total was 15.0. running mean: 10.919899865782657\n",
      "resetting env. episode reward total was 18.0. running mean: 10.990700867124831\n",
      "resetting env. episode reward total was 17.0. running mean: 11.050793858453583\n",
      "resetting env. episode reward total was 10.0. running mean: 11.040285919869046\n",
      "resetting env. episode reward total was 10.0. running mean: 11.029883060670354\n",
      "resetting env. episode reward total was 12.0. running mean: 11.03958423006365\n",
      "resetting env. episode reward total was 9.0. running mean: 11.019188387763013\n",
      "resetting env. episode reward total was 6.0. running mean: 10.968996503885382\n",
      "resetting env. episode reward total was 17.0. running mean: 11.029306538846528\n",
      "resetting env. episode reward total was 9.0. running mean: 11.009013473458063\n",
      "resetting env. episode reward total was 10.0. running mean: 10.998923338723483\n",
      "resetting env. episode reward total was 15.0. running mean: 11.038934105336248\n",
      "resetting env. episode reward total was 12.0. running mean: 11.048544764282884\n",
      "resetting env. episode reward total was 13.0. running mean: 11.068059316640056\n",
      "resetting env. episode reward total was 9.0. running mean: 11.047378723473656\n",
      "resetting env. episode reward total was 17.0. running mean: 11.10690493623892\n",
      "resetting env. episode reward total was 12.0. running mean: 11.11583588687653\n",
      "resetting env. episode reward total was 10.0. running mean: 11.104677528007764\n",
      "resetting env. episode reward total was 11.0. running mean: 11.103630752727685\n",
      "resetting env. episode reward total was 8.0. running mean: 11.072594445200409\n",
      "resetting env. episode reward total was 9.0. running mean: 11.051868500748403\n",
      "resetting env. episode reward total was 11.0. running mean: 11.051349815740918\n",
      "resetting env. episode reward total was 9.0. running mean: 11.030836317583509\n",
      "resetting env. episode reward total was 13.0. running mean: 11.050527954407674\n",
      "resetting env. episode reward total was 14.0. running mean: 11.080022674863597\n",
      "resetting env. episode reward total was 7.0. running mean: 11.039222448114963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 11.028830223633813\n",
      "resetting env. episode reward total was 11.0. running mean: 11.028541921397474\n",
      "resetting env. episode reward total was 12.0. running mean: 11.038256502183499\n",
      "resetting env. episode reward total was 11.0. running mean: 11.037873937161663\n",
      "resetting env. episode reward total was 19.0. running mean: 11.117495197790046\n",
      "resetting env. episode reward total was 16.0. running mean: 11.166320245812145\n",
      "resetting env. episode reward total was 13.0. running mean: 11.184657043354024\n",
      "resetting env. episode reward total was 18.0. running mean: 11.252810472920483\n",
      "resetting env. episode reward total was 13.0. running mean: 11.27028236819128\n",
      "resetting env. episode reward total was 12.0. running mean: 11.277579544509367\n",
      "resetting env. episode reward total was 4.0. running mean: 11.204803749064272\n",
      "resetting env. episode reward total was 17.0. running mean: 11.262755711573629\n",
      "resetting env. episode reward total was 16.0. running mean: 11.310128154457892\n",
      "resetting env. episode reward total was 16.0. running mean: 11.357026872913314\n",
      "resetting env. episode reward total was 4.0. running mean: 11.283456604184181\n",
      "resetting env. episode reward total was 4.0. running mean: 11.210622038142338\n",
      "resetting env. episode reward total was 15.0. running mean: 11.248515817760914\n",
      "resetting env. episode reward total was 8.0. running mean: 11.216030659583305\n",
      "resetting env. episode reward total was 10.0. running mean: 11.203870352987472\n",
      "resetting env. episode reward total was 13.0. running mean: 11.221831649457599\n",
      "resetting env. episode reward total was 19.0. running mean: 11.299613332963022\n",
      "resetting env. episode reward total was 9.0. running mean: 11.27661719963339\n",
      "resetting env. episode reward total was 12.0. running mean: 11.283851027637056\n",
      "resetting env. episode reward total was 9.0. running mean: 11.261012517360685\n",
      "resetting env. episode reward total was 15.0. running mean: 11.298402392187079\n",
      "resetting env. episode reward total was 16.0. running mean: 11.345418368265207\n",
      "resetting env. episode reward total was 18.0. running mean: 11.411964184582555\n",
      "resetting env. episode reward total was 9.0. running mean: 11.38784454273673\n",
      "resetting env. episode reward total was 5.0. running mean: 11.323966097309363\n",
      "resetting env. episode reward total was 13.0. running mean: 11.34072643633627\n",
      "resetting env. episode reward total was -3.0. running mean: 11.197319171972907\n",
      "resetting env. episode reward total was 16.0. running mean: 11.245345980253179\n",
      "resetting env. episode reward total was 18.0. running mean: 11.312892520450646\n",
      "resetting env. episode reward total was 4.0. running mean: 11.239763595246139\n",
      "resetting env. episode reward total was 8.0. running mean: 11.207365959293677\n",
      "resetting env. episode reward total was 11.0. running mean: 11.205292299700739\n",
      "resetting env. episode reward total was 16.0. running mean: 11.253239376703732\n",
      "resetting env. episode reward total was 9.0. running mean: 11.230706982936695\n",
      "resetting env. episode reward total was 14.0. running mean: 11.25839991310733\n",
      "resetting env. episode reward total was 6.0. running mean: 11.205815913976256\n",
      "resetting env. episode reward total was 12.0. running mean: 11.213757754836493\n",
      "resetting env. episode reward total was 16.0. running mean: 11.261620177288128\n",
      "resetting env. episode reward total was 13.0. running mean: 11.279003975515247\n",
      "resetting env. episode reward total was 12.0. running mean: 11.286213935760093\n",
      "resetting env. episode reward total was 11.0. running mean: 11.283351796402492\n",
      "resetting env. episode reward total was 18.0. running mean: 11.350518278438466\n",
      "resetting env. episode reward total was 12.0. running mean: 11.35701309565408\n",
      "resetting env. episode reward total was 2.0. running mean: 11.26344296469754\n",
      "resetting env. episode reward total was 15.0. running mean: 11.300808535050564\n",
      "resetting env. episode reward total was 17.0. running mean: 11.357800449700058\n",
      "resetting env. episode reward total was 4.0. running mean: 11.284222445203056\n",
      "resetting env. episode reward total was 5.0. running mean: 11.221380220751026\n",
      "resetting env. episode reward total was 7.0. running mean: 11.179166418543517\n",
      "resetting env. episode reward total was 18.0. running mean: 11.24737475435808\n",
      "resetting env. episode reward total was 14.0. running mean: 11.2749010068145\n",
      "resetting env. episode reward total was 17.0. running mean: 11.332151996746356\n",
      "resetting env. episode reward total was 14.0. running mean: 11.358830476778893\n",
      "resetting env. episode reward total was 17.0. running mean: 11.415242172011103\n",
      "resetting env. episode reward total was 12.0. running mean: 11.42108975029099\n",
      "resetting env. episode reward total was 16.0. running mean: 11.466878852788081\n",
      "resetting env. episode reward total was 11.0. running mean: 11.4622100642602\n",
      "resetting env. episode reward total was 4.0. running mean: 11.387587963617596\n",
      "resetting env. episode reward total was 11.0. running mean: 11.38371208398142\n",
      "resetting env. episode reward total was 11.0. running mean: 11.379874963141605\n",
      "resetting env. episode reward total was 16.0. running mean: 11.42607621351019\n",
      "resetting env. episode reward total was 15.0. running mean: 11.461815451375088\n",
      "resetting env. episode reward total was 5.0. running mean: 11.397197296861338\n",
      "resetting env. episode reward total was 1.0. running mean: 11.293225323892724\n",
      "resetting env. episode reward total was 8.0. running mean: 11.260293070653796\n",
      "resetting env. episode reward total was 11.0. running mean: 11.257690139947258\n",
      "resetting env. episode reward total was 10.0. running mean: 11.245113238547784\n",
      "resetting env. episode reward total was 15.0. running mean: 11.282662106162306\n",
      "resetting env. episode reward total was 15.0. running mean: 11.319835485100683\n",
      "resetting env. episode reward total was 13.0. running mean: 11.336637130249677\n",
      "resetting env. episode reward total was 14.0. running mean: 11.36327075894718\n",
      "resetting env. episode reward total was 20.0. running mean: 11.449638051357708\n",
      "resetting env. episode reward total was 4.0. running mean: 11.37514167084413\n",
      "resetting env. episode reward total was 7.0. running mean: 11.33139025413569\n",
      "resetting env. episode reward total was 16.0. running mean: 11.378076351594332\n",
      "resetting env. episode reward total was 7.0. running mean: 11.334295588078389\n",
      "resetting env. episode reward total was 18.0. running mean: 11.400952632197605\n",
      "resetting env. episode reward total was 7.0. running mean: 11.35694310587563\n",
      "resetting env. episode reward total was 14.0. running mean: 11.383373674816873\n",
      "resetting env. episode reward total was 12.0. running mean: 11.389539938068703\n",
      "resetting env. episode reward total was 5.0. running mean: 11.325644538688016\n",
      "resetting env. episode reward total was 12.0. running mean: 11.332388093301134\n",
      "resetting env. episode reward total was 9.0. running mean: 11.309064212368122\n",
      "resetting env. episode reward total was 12.0. running mean: 11.31597357024444\n",
      "resetting env. episode reward total was 12.0. running mean: 11.322813834541995\n",
      "resetting env. episode reward total was 16.0. running mean: 11.369585696196575\n",
      "resetting env. episode reward total was 18.0. running mean: 11.435889839234608\n",
      "resetting env. episode reward total was 9.0. running mean: 11.411530940842262\n",
      "resetting env. episode reward total was 14.0. running mean: 11.43741563143384\n",
      "resetting env. episode reward total was 3.0. running mean: 11.3530414751195\n",
      "resetting env. episode reward total was 7.0. running mean: 11.309511060368305\n",
      "resetting env. episode reward total was 10.0. running mean: 11.29641594976462\n",
      "resetting env. episode reward total was 10.0. running mean: 11.283451790266973\n",
      "resetting env. episode reward total was 5.0. running mean: 11.220617272364304\n",
      "resetting env. episode reward total was 16.0. running mean: 11.26841109964066\n",
      "resetting env. episode reward total was 14.0. running mean: 11.295726988644255\n",
      "resetting env. episode reward total was 4.0. running mean: 11.222769718757812\n",
      "resetting env. episode reward total was 13.0. running mean: 11.240542021570235\n",
      "resetting env. episode reward total was 14.0. running mean: 11.268136601354533\n",
      "resetting env. episode reward total was 11.0. running mean: 11.265455235340987\n",
      "resetting env. episode reward total was 10.0. running mean: 11.252800682987576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 11.2102726761577\n",
      "resetting env. episode reward total was 11.0. running mean: 11.208169949396122\n",
      "resetting env. episode reward total was 9.0. running mean: 11.186088249902161\n",
      "resetting env. episode reward total was 9.0. running mean: 11.16422736740314\n",
      "resetting env. episode reward total was 7.0. running mean: 11.122585093729109\n",
      "resetting env. episode reward total was 10.0. running mean: 11.111359242791817\n",
      "resetting env. episode reward total was 10.0. running mean: 11.100245650363899\n",
      "resetting env. episode reward total was 7.0. running mean: 11.05924319386026\n",
      "resetting env. episode reward total was 8.0. running mean: 11.028650761921657\n",
      "resetting env. episode reward total was 7.0. running mean: 10.988364254302441\n",
      "resetting env. episode reward total was 14.0. running mean: 11.018480611759417\n",
      "resetting env. episode reward total was 6.0. running mean: 10.968295805641823\n",
      "resetting env. episode reward total was 15.0. running mean: 11.008612847585406\n",
      "resetting env. episode reward total was 13.0. running mean: 11.028526719109552\n",
      "resetting env. episode reward total was 12.0. running mean: 11.038241451918456\n",
      "resetting env. episode reward total was 17.0. running mean: 11.097859037399271\n",
      "resetting env. episode reward total was 12.0. running mean: 11.106880447025278\n",
      "resetting env. episode reward total was 12.0. running mean: 11.115811642555023\n",
      "resetting env. episode reward total was 14.0. running mean: 11.144653526129474\n",
      "resetting env. episode reward total was -7.0. running mean: 10.963206990868178\n",
      "resetting env. episode reward total was 13.0. running mean: 10.983574920959498\n",
      "resetting env. episode reward total was 15.0. running mean: 11.023739171749904\n",
      "resetting env. episode reward total was 9.0. running mean: 11.003501780032405\n",
      "resetting env. episode reward total was 8.0. running mean: 10.97346676223208\n",
      "resetting env. episode reward total was 6.0. running mean: 10.92373209460976\n",
      "resetting env. episode reward total was -4.0. running mean: 10.774494773663662\n",
      "resetting env. episode reward total was 10.0. running mean: 10.766749825927025\n",
      "resetting env. episode reward total was 14.0. running mean: 10.799082327667756\n",
      "resetting env. episode reward total was 8.0. running mean: 10.771091504391078\n",
      "resetting env. episode reward total was 7.0. running mean: 10.733380589347167\n",
      "resetting env. episode reward total was 13.0. running mean: 10.756046783453696\n",
      "resetting env. episode reward total was 12.0. running mean: 10.768486315619159\n",
      "resetting env. episode reward total was 13.0. running mean: 10.790801452462969\n",
      "resetting env. episode reward total was 12.0. running mean: 10.802893437938337\n",
      "resetting env. episode reward total was 10.0. running mean: 10.794864503558953\n",
      "resetting env. episode reward total was 12.0. running mean: 10.806915858523363\n",
      "resetting env. episode reward total was 13.0. running mean: 10.82884669993813\n",
      "resetting env. episode reward total was 11.0. running mean: 10.830558232938747\n",
      "resetting env. episode reward total was 10.0. running mean: 10.822252650609359\n",
      "resetting env. episode reward total was 15.0. running mean: 10.864030124103266\n",
      "resetting env. episode reward total was 13.0. running mean: 10.885389822862233\n",
      "resetting env. episode reward total was 10.0. running mean: 10.876535924633611\n",
      "resetting env. episode reward total was 12.0. running mean: 10.887770565387275\n",
      "resetting env. episode reward total was 14.0. running mean: 10.918892859733402\n",
      "resetting env. episode reward total was 11.0. running mean: 10.919703931136068\n",
      "resetting env. episode reward total was 10.0. running mean: 10.910506891824706\n",
      "resetting env. episode reward total was 15.0. running mean: 10.95140182290646\n",
      "resetting env. episode reward total was 18.0. running mean: 11.021887804677394\n",
      "resetting env. episode reward total was 12.0. running mean: 11.03166892663062\n",
      "resetting env. episode reward total was 11.0. running mean: 11.031352237364313\n",
      "resetting env. episode reward total was 12.0. running mean: 11.04103871499067\n",
      "resetting env. episode reward total was 13.0. running mean: 11.060628327840764\n",
      "resetting env. episode reward total was 10.0. running mean: 11.050022044562356\n",
      "resetting env. episode reward total was 16.0. running mean: 11.099521824116731\n",
      "resetting env. episode reward total was 15.0. running mean: 11.138526605875564\n",
      "resetting env. episode reward total was 13.0. running mean: 11.157141339816809\n",
      "resetting env. episode reward total was 15.0. running mean: 11.19556992641864\n",
      "resetting env. episode reward total was 10.0. running mean: 11.183614227154454\n",
      "resetting env. episode reward total was 8.0. running mean: 11.15177808488291\n",
      "resetting env. episode reward total was 8.0. running mean: 11.120260304034081\n",
      "resetting env. episode reward total was 9.0. running mean: 11.09905770099374\n",
      "resetting env. episode reward total was 11.0. running mean: 11.098067123983801\n",
      "resetting env. episode reward total was 11.0. running mean: 11.097086452743962\n",
      "resetting env. episode reward total was 14.0. running mean: 11.126115588216523\n",
      "resetting env. episode reward total was 12.0. running mean: 11.134854432334357\n",
      "resetting env. episode reward total was 13.0. running mean: 11.153505888011015\n",
      "resetting env. episode reward total was 11.0. running mean: 11.151970829130905\n",
      "resetting env. episode reward total was 12.0. running mean: 11.160451120839594\n",
      "resetting env. episode reward total was 5.0. running mean: 11.098846609631199\n",
      "resetting env. episode reward total was 13.0. running mean: 11.117858143534887\n",
      "resetting env. episode reward total was 7.0. running mean: 11.076679562099539\n",
      "resetting env. episode reward total was 10.0. running mean: 11.065912766478544\n",
      "resetting env. episode reward total was 13.0. running mean: 11.085253638813759\n",
      "resetting env. episode reward total was 11.0. running mean: 11.084401102425621\n",
      "resetting env. episode reward total was 5.0. running mean: 11.023557091401367\n",
      "resetting env. episode reward total was 17.0. running mean: 11.083321520487353\n",
      "resetting env. episode reward total was 4.0. running mean: 11.012488305282478\n",
      "resetting env. episode reward total was 16.0. running mean: 11.062363422229653\n",
      "resetting env. episode reward total was 13.0. running mean: 11.081739788007358\n",
      "resetting env. episode reward total was 19.0. running mean: 11.160922390127284\n",
      "resetting env. episode reward total was 5.0. running mean: 11.099313166226013\n",
      "resetting env. episode reward total was 2.0. running mean: 11.008320034563752\n",
      "resetting env. episode reward total was 4.0. running mean: 10.938236834218113\n",
      "resetting env. episode reward total was 18.0. running mean: 11.008854465875931\n",
      "resetting env. episode reward total was 8.0. running mean: 10.978765921217171\n",
      "resetting env. episode reward total was 1.0. running mean: 10.878978262004999\n",
      "resetting env. episode reward total was 13.0. running mean: 10.90018847938495\n",
      "resetting env. episode reward total was 8.0. running mean: 10.8711865945911\n",
      "resetting env. episode reward total was 15.0. running mean: 10.912474728645188\n",
      "resetting env. episode reward total was 10.0. running mean: 10.903349981358735\n",
      "resetting env. episode reward total was 19.0. running mean: 10.984316481545147\n",
      "resetting env. episode reward total was 7.0. running mean: 10.944473316729695\n",
      "resetting env. episode reward total was 10.0. running mean: 10.935028583562397\n",
      "resetting env. episode reward total was 10.0. running mean: 10.925678297726773\n",
      "resetting env. episode reward total was 11.0. running mean: 10.926421514749505\n",
      "resetting env. episode reward total was 18.0. running mean: 10.997157299602009\n",
      "resetting env. episode reward total was 17.0. running mean: 11.057185726605988\n",
      "resetting env. episode reward total was 8.0. running mean: 11.02661386933993\n",
      "resetting env. episode reward total was 9.0. running mean: 11.00634773064653\n",
      "resetting env. episode reward total was 12.0. running mean: 11.016284253340064\n",
      "resetting env. episode reward total was 13.0. running mean: 11.036121410806665\n",
      "resetting env. episode reward total was 10.0. running mean: 11.025760196698597\n",
      "resetting env. episode reward total was 11.0. running mean: 11.025502594731611\n",
      "resetting env. episode reward total was 9.0. running mean: 11.005247568784295\n",
      "resetting env. episode reward total was 15.0. running mean: 11.045195093096453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 17.0. running mean: 11.104743142165487\n",
      "resetting env. episode reward total was 15.0. running mean: 11.143695710743833\n",
      "resetting env. episode reward total was 18.0. running mean: 11.212258753636394\n",
      "resetting env. episode reward total was 14.0. running mean: 11.240136166100031\n",
      "resetting env. episode reward total was 19.0. running mean: 11.31773480443903\n",
      "resetting env. episode reward total was 10.0. running mean: 11.30455745639464\n",
      "resetting env. episode reward total was 9.0. running mean: 11.281511881830694\n",
      "resetting env. episode reward total was 15.0. running mean: 11.318696763012387\n",
      "resetting env. episode reward total was 14.0. running mean: 11.345509795382263\n",
      "resetting env. episode reward total was 13.0. running mean: 11.36205469742844\n",
      "resetting env. episode reward total was 17.0. running mean: 11.418434150454157\n",
      "resetting env. episode reward total was 12.0. running mean: 11.424249808949615\n",
      "resetting env. episode reward total was 12.0. running mean: 11.430007310860118\n",
      "resetting env. episode reward total was 12.0. running mean: 11.435707237751515\n",
      "resetting env. episode reward total was 11.0. running mean: 11.431350165373999\n",
      "resetting env. episode reward total was 11.0. running mean: 11.427036663720259\n",
      "resetting env. episode reward total was 9.0. running mean: 11.402766297083057\n",
      "resetting env. episode reward total was 10.0. running mean: 11.388738634112226\n",
      "resetting env. episode reward total was 6.0. running mean: 11.334851247771104\n",
      "resetting env. episode reward total was 10.0. running mean: 11.321502735293393\n",
      "resetting env. episode reward total was 5.0. running mean: 11.25828770794046\n",
      "resetting env. episode reward total was 6.0. running mean: 11.205704830861055\n",
      "resetting env. episode reward total was 2.0. running mean: 11.113647782552444\n",
      "resetting env. episode reward total was 11.0. running mean: 11.112511304726919\n",
      "resetting env. episode reward total was 13.0. running mean: 11.13138619167965\n",
      "resetting env. episode reward total was 10.0. running mean: 11.120072329762854\n",
      "resetting env. episode reward total was 11.0. running mean: 11.118871606465225\n",
      "resetting env. episode reward total was 15.0. running mean: 11.157682890400572\n",
      "resetting env. episode reward total was 6.0. running mean: 11.106106061496567\n",
      "resetting env. episode reward total was 15.0. running mean: 11.145045000881602\n",
      "resetting env. episode reward total was 14.0. running mean: 11.173594550872787\n",
      "resetting env. episode reward total was 14.0. running mean: 11.201858605364059\n",
      "resetting env. episode reward total was 3.0. running mean: 11.119840019310418\n",
      "resetting env. episode reward total was 10.0. running mean: 11.108641619117314\n",
      "resetting env. episode reward total was 14.0. running mean: 11.137555202926142\n",
      "resetting env. episode reward total was 9.0. running mean: 11.11617965089688\n",
      "resetting env. episode reward total was 13.0. running mean: 11.135017854387913\n",
      "resetting env. episode reward total was 11.0. running mean: 11.133667675844032\n",
      "resetting env. episode reward total was 10.0. running mean: 11.122330999085591\n",
      "resetting env. episode reward total was 16.0. running mean: 11.171107689094734\n",
      "resetting env. episode reward total was 9.0. running mean: 11.149396612203788\n",
      "resetting env. episode reward total was 5.0. running mean: 11.08790264608175\n",
      "resetting env. episode reward total was 9.0. running mean: 11.067023619620931\n",
      "resetting env. episode reward total was 14.0. running mean: 11.096353383424722\n",
      "resetting env. episode reward total was 11.0. running mean: 11.095389849590473\n",
      "resetting env. episode reward total was 12.0. running mean: 11.104435951094567\n",
      "resetting env. episode reward total was 16.0. running mean: 11.153391591583622\n",
      "resetting env. episode reward total was 13.0. running mean: 11.171857675667786\n",
      "resetting env. episode reward total was 12.0. running mean: 11.180139098911107\n",
      "resetting env. episode reward total was 7.0. running mean: 11.138337707921997\n",
      "resetting env. episode reward total was 9.0. running mean: 11.116954330842777\n",
      "resetting env. episode reward total was 10.0. running mean: 11.105784787534349\n",
      "resetting env. episode reward total was 14.0. running mean: 11.134726939659005\n",
      "resetting env. episode reward total was 6.0. running mean: 11.083379670262415\n",
      "resetting env. episode reward total was 10.0. running mean: 11.072545873559791\n",
      "resetting env. episode reward total was 15.0. running mean: 11.111820414824194\n",
      "resetting env. episode reward total was 9.0. running mean: 11.090702210675952\n",
      "resetting env. episode reward total was 5.0. running mean: 11.029795188569192\n",
      "resetting env. episode reward total was 13.0. running mean: 11.049497236683502\n",
      "resetting env. episode reward total was 10.0. running mean: 11.039002264316666\n",
      "resetting env. episode reward total was 13.0. running mean: 11.0586122416735\n",
      "resetting env. episode reward total was 12.0. running mean: 11.068026119256764\n",
      "resetting env. episode reward total was 9.0. running mean: 11.047345858064196\n",
      "resetting env. episode reward total was 9.0. running mean: 11.026872399483553\n",
      "resetting env. episode reward total was 10.0. running mean: 11.016603675488717\n",
      "resetting env. episode reward total was 9.0. running mean: 10.99643763873383\n",
      "resetting env. episode reward total was 11.0. running mean: 10.996473262346491\n",
      "resetting env. episode reward total was 15.0. running mean: 11.036508529723026\n",
      "resetting env. episode reward total was 18.0. running mean: 11.106143444425795\n",
      "resetting env. episode reward total was 11.0. running mean: 11.105082009981537\n",
      "resetting env. episode reward total was 5.0. running mean: 11.044031189881721\n",
      "resetting env. episode reward total was 4.0. running mean: 10.973590877982904\n",
      "resetting env. episode reward total was 16.0. running mean: 11.023854969203075\n",
      "resetting env. episode reward total was 8.0. running mean: 10.993616419511044\n",
      "resetting env. episode reward total was 8.0. running mean: 10.963680255315934\n",
      "resetting env. episode reward total was 14.0. running mean: 10.994043452762774\n",
      "resetting env. episode reward total was 10.0. running mean: 10.984103018235146\n",
      "resetting env. episode reward total was 14.0. running mean: 11.014261988052795\n",
      "resetting env. episode reward total was 10.0. running mean: 11.004119368172265\n",
      "resetting env. episode reward total was 15.0. running mean: 11.044078174490544\n",
      "resetting env. episode reward total was 11.0. running mean: 11.043637392745637\n",
      "resetting env. episode reward total was 11.0. running mean: 11.04320101881818\n",
      "resetting env. episode reward total was 9.0. running mean: 11.022769008629998\n",
      "resetting env. episode reward total was 10.0. running mean: 11.012541318543699\n",
      "resetting env. episode reward total was 18.0. running mean: 11.08241590535826\n",
      "resetting env. episode reward total was 14.0. running mean: 11.11159174630468\n",
      "resetting env. episode reward total was 4.0. running mean: 11.04047582884163\n",
      "resetting env. episode reward total was 10.0. running mean: 11.030071070553214\n",
      "resetting env. episode reward total was 13.0. running mean: 11.049770359847683\n",
      "resetting env. episode reward total was 10.0. running mean: 11.039272656249205\n",
      "resetting env. episode reward total was 11.0. running mean: 11.038879929686711\n",
      "resetting env. episode reward total was 16.0. running mean: 11.088491130389844\n",
      "resetting env. episode reward total was 13.0. running mean: 11.107606219085946\n",
      "resetting env. episode reward total was 20.0. running mean: 11.196530156895086\n",
      "resetting env. episode reward total was 11.0. running mean: 11.194564855326135\n",
      "resetting env. episode reward total was 11.0. running mean: 11.192619206772873\n",
      "resetting env. episode reward total was 14.0. running mean: 11.220693014705144\n",
      "resetting env. episode reward total was 10.0. running mean: 11.208486084558093\n",
      "resetting env. episode reward total was 10.0. running mean: 11.196401223712511\n",
      "resetting env. episode reward total was 10.0. running mean: 11.184437211475386\n",
      "resetting env. episode reward total was 18.0. running mean: 11.25259283936063\n",
      "resetting env. episode reward total was 15.0. running mean: 11.290066910967024\n",
      "resetting env. episode reward total was 11.0. running mean: 11.287166241857353\n",
      "resetting env. episode reward total was 14.0. running mean: 11.31429457943878\n",
      "resetting env. episode reward total was 14.0. running mean: 11.341151633644392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 11.307740117307947\n",
      "resetting env. episode reward total was 15.0. running mean: 11.344662716134868\n",
      "resetting env. episode reward total was 13.0. running mean: 11.36121608897352\n",
      "resetting env. episode reward total was 9.0. running mean: 11.337603928083785\n",
      "resetting env. episode reward total was 9.0. running mean: 11.314227888802947\n",
      "resetting env. episode reward total was 15.0. running mean: 11.351085609914918\n",
      "resetting env. episode reward total was 16.0. running mean: 11.39757475381577\n",
      "resetting env. episode reward total was -11.0. running mean: 11.173599006277612\n",
      "resetting env. episode reward total was 5.0. running mean: 11.111863016214837\n",
      "resetting env. episode reward total was 16.0. running mean: 11.16074438605269\n",
      "resetting env. episode reward total was 15.0. running mean: 11.199136942192164\n",
      "resetting env. episode reward total was 16.0. running mean: 11.247145572770242\n",
      "resetting env. episode reward total was 15.0. running mean: 11.28467411704254\n",
      "resetting env. episode reward total was 18.0. running mean: 11.351827375872114\n",
      "resetting env. episode reward total was 17.0. running mean: 11.408309102113392\n",
      "resetting env. episode reward total was 14.0. running mean: 11.434226011092258\n",
      "resetting env. episode reward total was 16.0. running mean: 11.479883750981337\n",
      "resetting env. episode reward total was 9.0. running mean: 11.455084913471524\n",
      "resetting env. episode reward total was 10.0. running mean: 11.440534064336807\n",
      "resetting env. episode reward total was 10.0. running mean: 11.42612872369344\n",
      "resetting env. episode reward total was 16.0. running mean: 11.471867436456506\n",
      "resetting env. episode reward total was 11.0. running mean: 11.46714876209194\n",
      "resetting env. episode reward total was 8.0. running mean: 11.43247727447102\n",
      "resetting env. episode reward total was 16.0. running mean: 11.47815250172631\n",
      "resetting env. episode reward total was 15.0. running mean: 11.513370976709048\n",
      "resetting env. episode reward total was 12.0. running mean: 11.518237266941957\n",
      "resetting env. episode reward total was 13.0. running mean: 11.533054894272539\n",
      "resetting env. episode reward total was -4.0. running mean: 11.377724345329813\n",
      "resetting env. episode reward total was 13.0. running mean: 11.393947101876515\n",
      "resetting env. episode reward total was 16.0. running mean: 11.44000763085775\n",
      "resetting env. episode reward total was 9.0. running mean: 11.415607554549172\n",
      "resetting env. episode reward total was 14.0. running mean: 11.441451479003682\n",
      "resetting env. episode reward total was 15.0. running mean: 11.477036964213646\n",
      "resetting env. episode reward total was 14.0. running mean: 11.502266594571509\n",
      "resetting env. episode reward total was 14.0. running mean: 11.527243928625795\n",
      "resetting env. episode reward total was 11.0. running mean: 11.521971489339537\n",
      "resetting env. episode reward total was 15.0. running mean: 11.556751774446141\n",
      "resetting env. episode reward total was 14.0. running mean: 11.58118425670168\n",
      "resetting env. episode reward total was 4.0. running mean: 11.505372414134664\n",
      "resetting env. episode reward total was 12.0. running mean: 11.510318689993316\n",
      "resetting env. episode reward total was 14.0. running mean: 11.535215503093383\n",
      "resetting env. episode reward total was 11.0. running mean: 11.529863348062449\n",
      "resetting env. episode reward total was 4.0. running mean: 11.454564714581823\n",
      "resetting env. episode reward total was 7.0. running mean: 11.410019067436005\n",
      "resetting env. episode reward total was 16.0. running mean: 11.455918876761645\n",
      "resetting env. episode reward total was 16.0. running mean: 11.501359687994029\n",
      "resetting env. episode reward total was 16.0. running mean: 11.546346091114088\n",
      "resetting env. episode reward total was 15.0. running mean: 11.580882630202948\n",
      "resetting env. episode reward total was 13.0. running mean: 11.59507380390092\n",
      "resetting env. episode reward total was 16.0. running mean: 11.639123065861911\n",
      "resetting env. episode reward total was 14.0. running mean: 11.662731835203292\n",
      "resetting env. episode reward total was 12.0. running mean: 11.666104516851258\n",
      "resetting env. episode reward total was 9.0. running mean: 11.639443471682744\n",
      "resetting env. episode reward total was 11.0. running mean: 11.633049036965916\n",
      "resetting env. episode reward total was 13.0. running mean: 11.646718546596258\n",
      "resetting env. episode reward total was 2.0. running mean: 11.550251361130295\n",
      "resetting env. episode reward total was 9.0. running mean: 11.52474884751899\n",
      "resetting env. episode reward total was 13.0. running mean: 11.539501359043802\n",
      "resetting env. episode reward total was 14.0. running mean: 11.564106345453364\n",
      "resetting env. episode reward total was 10.0. running mean: 11.54846528199883\n",
      "resetting env. episode reward total was 14.0. running mean: 11.572980629178842\n",
      "resetting env. episode reward total was 10.0. running mean: 11.557250822887053\n",
      "resetting env. episode reward total was 15.0. running mean: 11.591678314658182\n",
      "resetting env. episode reward total was 16.0. running mean: 11.6357615315116\n",
      "resetting env. episode reward total was 12.0. running mean: 11.639403916196482\n",
      "resetting env. episode reward total was 15.0. running mean: 11.673009877034517\n",
      "resetting env. episode reward total was 17.0. running mean: 11.726279778264171\n",
      "resetting env. episode reward total was 8.0. running mean: 11.68901698048153\n",
      "resetting env. episode reward total was 9.0. running mean: 11.662126810676714\n",
      "resetting env. episode reward total was 3.0. running mean: 11.575505542569946\n",
      "resetting env. episode reward total was 5.0. running mean: 11.509750487144247\n",
      "resetting env. episode reward total was 13.0. running mean: 11.524652982272805\n",
      "resetting env. episode reward total was 7.0. running mean: 11.479406452450077\n",
      "resetting env. episode reward total was 9.0. running mean: 11.454612387925575\n",
      "resetting env. episode reward total was 18.0. running mean: 11.520066264046319\n",
      "resetting env. episode reward total was 8.0. running mean: 11.484865601405856\n",
      "resetting env. episode reward total was 10.0. running mean: 11.470016945391796\n",
      "resetting env. episode reward total was 4.0. running mean: 11.395316775937877\n",
      "resetting env. episode reward total was 15.0. running mean: 11.431363608178499\n",
      "resetting env. episode reward total was 12.0. running mean: 11.437049972096712\n",
      "resetting env. episode reward total was 2.0. running mean: 11.342679472375744\n",
      "resetting env. episode reward total was 8.0. running mean: 11.309252677651987\n",
      "resetting env. episode reward total was 6.0. running mean: 11.256160150875468\n",
      "resetting env. episode reward total was 15.0. running mean: 11.293598549366713\n",
      "resetting env. episode reward total was 9.0. running mean: 11.270662563873046\n",
      "resetting env. episode reward total was 9.0. running mean: 11.247955938234314\n",
      "resetting env. episode reward total was 16.0. running mean: 11.295476378851971\n",
      "resetting env. episode reward total was 12.0. running mean: 11.30252161506345\n",
      "resetting env. episode reward total was 12.0. running mean: 11.309496398912815\n",
      "resetting env. episode reward total was 16.0. running mean: 11.356401434923686\n",
      "resetting env. episode reward total was 7.0. running mean: 11.31283742057445\n",
      "resetting env. episode reward total was 4.0. running mean: 11.239709046368704\n",
      "resetting env. episode reward total was 13.0. running mean: 11.257311955905017\n",
      "resetting env. episode reward total was 8.0. running mean: 11.224738836345967\n",
      "resetting env. episode reward total was 15.0. running mean: 11.262491447982507\n",
      "resetting env. episode reward total was 10.0. running mean: 11.249866533502681\n",
      "resetting env. episode reward total was 11.0. running mean: 11.247367868167654\n",
      "resetting env. episode reward total was 12.0. running mean: 11.254894189485977\n",
      "resetting env. episode reward total was 14.0. running mean: 11.282345247591119\n",
      "resetting env. episode reward total was 15.0. running mean: 11.319521795115207\n",
      "resetting env. episode reward total was 13.0. running mean: 11.336326577164057\n",
      "resetting env. episode reward total was 7.0. running mean: 11.292963311392416\n",
      "resetting env. episode reward total was 8.0. running mean: 11.260033678278491\n",
      "resetting env. episode reward total was 12.0. running mean: 11.267433341495705\n",
      "resetting env. episode reward total was 7.0. running mean: 11.224759008080747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 16.0. running mean: 11.27251141799994\n",
      "resetting env. episode reward total was 13.0. running mean: 11.289786303819941\n",
      "resetting env. episode reward total was 14.0. running mean: 11.316888440781742\n",
      "resetting env. episode reward total was 15.0. running mean: 11.353719556373925\n",
      "resetting env. episode reward total was 19.0. running mean: 11.430182360810186\n",
      "resetting env. episode reward total was 6.0. running mean: 11.375880537202084\n",
      "resetting env. episode reward total was 17.0. running mean: 11.432121731830064\n",
      "resetting env. episode reward total was 8.0. running mean: 11.397800514511763\n",
      "resetting env. episode reward total was 14.0. running mean: 11.423822509366646\n",
      "resetting env. episode reward total was 12.0. running mean: 11.429584284272979\n",
      "resetting env. episode reward total was 15.0. running mean: 11.46528844143025\n",
      "resetting env. episode reward total was 15.0. running mean: 11.500635557015947\n",
      "resetting env. episode reward total was 19.0. running mean: 11.575629201445787\n",
      "resetting env. episode reward total was 4.0. running mean: 11.499872909431328\n",
      "resetting env. episode reward total was 15.0. running mean: 11.534874180337015\n",
      "resetting env. episode reward total was 17.0. running mean: 11.589525438533645\n",
      "resetting env. episode reward total was 9.0. running mean: 11.563630184148309\n",
      "resetting env. episode reward total was 14.0. running mean: 11.587993882306826\n",
      "resetting env. episode reward total was 16.0. running mean: 11.632113943483757\n",
      "resetting env. episode reward total was 8.0. running mean: 11.59579280404892\n",
      "resetting env. episode reward total was 15.0. running mean: 11.629834876008431\n",
      "resetting env. episode reward total was 18.0. running mean: 11.693536527248346\n",
      "resetting env. episode reward total was 12.0. running mean: 11.696601161975861\n",
      "resetting env. episode reward total was 11.0. running mean: 11.689635150356102\n",
      "resetting env. episode reward total was 13.0. running mean: 11.702738798852542\n",
      "resetting env. episode reward total was 4.0. running mean: 11.625711410864016\n",
      "resetting env. episode reward total was 14.0. running mean: 11.649454296755376\n",
      "resetting env. episode reward total was 16.0. running mean: 11.692959753787823\n",
      "resetting env. episode reward total was 16.0. running mean: 11.736030156249946\n",
      "resetting env. episode reward total was 8.0. running mean: 11.698669854687447\n",
      "resetting env. episode reward total was 6.0. running mean: 11.641683156140573\n",
      "resetting env. episode reward total was 11.0. running mean: 11.635266324579167\n",
      "resetting env. episode reward total was 4.0. running mean: 11.558913661333374\n",
      "resetting env. episode reward total was 8.0. running mean: 11.52332452472004\n",
      "resetting env. episode reward total was 10.0. running mean: 11.50809127947284\n",
      "resetting env. episode reward total was 19.0. running mean: 11.583010366678112\n",
      "resetting env. episode reward total was 12.0. running mean: 11.58718026301133\n",
      "resetting env. episode reward total was 11.0. running mean: 11.581308460381216\n",
      "resetting env. episode reward total was 19.0. running mean: 11.655495375777402\n",
      "resetting env. episode reward total was 8.0. running mean: 11.618940422019628\n",
      "resetting env. episode reward total was 19.0. running mean: 11.69275101779943\n",
      "resetting env. episode reward total was 17.0. running mean: 11.745823507621436\n",
      "resetting env. episode reward total was 13.0. running mean: 11.758365272545223\n",
      "resetting env. episode reward total was 13.0. running mean: 11.770781619819772\n",
      "resetting env. episode reward total was 16.0. running mean: 11.813073803621574\n",
      "resetting env. episode reward total was 11.0. running mean: 11.804943065585357\n",
      "resetting env. episode reward total was 7.0. running mean: 11.756893634929504\n",
      "resetting env. episode reward total was 10.0. running mean: 11.739324698580209\n",
      "resetting env. episode reward total was 10.0. running mean: 11.721931451594406\n",
      "resetting env. episode reward total was 12.0. running mean: 11.72471213707846\n",
      "resetting env. episode reward total was 8.0. running mean: 11.687465015707676\n",
      "resetting env. episode reward total was 12.0. running mean: 11.690590365550598\n",
      "resetting env. episode reward total was 19.0. running mean: 11.76368446189509\n",
      "resetting env. episode reward total was 10.0. running mean: 11.746047617276139\n",
      "resetting env. episode reward total was 15.0. running mean: 11.778587141103378\n",
      "resetting env. episode reward total was 15.0. running mean: 11.810801269692345\n",
      "resetting env. episode reward total was 13.0. running mean: 11.822693256995422\n",
      "resetting env. episode reward total was 5.0. running mean: 11.754466324425469\n",
      "resetting env. episode reward total was 10.0. running mean: 11.736921661181213\n",
      "resetting env. episode reward total was 14.0. running mean: 11.759552444569401\n",
      "resetting env. episode reward total was 11.0. running mean: 11.751956920123707\n",
      "resetting env. episode reward total was 8.0. running mean: 11.71443735092247\n",
      "resetting env. episode reward total was 15.0. running mean: 11.747292977413245\n",
      "resetting env. episode reward total was 11.0. running mean: 11.739820047639112\n",
      "resetting env. episode reward total was 17.0. running mean: 11.792421847162721\n",
      "resetting env. episode reward total was 9.0. running mean: 11.764497628691094\n",
      "resetting env. episode reward total was 9.0. running mean: 11.736852652404183\n",
      "resetting env. episode reward total was 11.0. running mean: 11.729484125880141\n",
      "resetting env. episode reward total was 14.0. running mean: 11.752189284621341\n",
      "resetting env. episode reward total was 11.0. running mean: 11.744667391775128\n",
      "resetting env. episode reward total was 9.0. running mean: 11.717220717857376\n",
      "resetting env. episode reward total was 14.0. running mean: 11.740048510678804\n",
      "resetting env. episode reward total was 12.0. running mean: 11.742648025572015\n",
      "resetting env. episode reward total was 13.0. running mean: 11.755221545316296\n",
      "resetting env. episode reward total was 14.0. running mean: 11.777669329863134\n",
      "resetting env. episode reward total was 11.0. running mean: 11.769892636564501\n",
      "resetting env. episode reward total was 15.0. running mean: 11.802193710198857\n",
      "resetting env. episode reward total was 8.0. running mean: 11.764171773096868\n",
      "resetting env. episode reward total was 17.0. running mean: 11.816530055365899\n",
      "resetting env. episode reward total was 12.0. running mean: 11.818364754812238\n",
      "resetting env. episode reward total was 16.0. running mean: 11.860181107264117\n",
      "resetting env. episode reward total was 12.0. running mean: 11.861579296191474\n",
      "resetting env. episode reward total was 12.0. running mean: 11.862963503229558\n",
      "resetting env. episode reward total was 10.0. running mean: 11.844333868197262\n",
      "resetting env. episode reward total was 13.0. running mean: 11.85589052951529\n",
      "resetting env. episode reward total was 12.0. running mean: 11.857331624220137\n",
      "resetting env. episode reward total was 10.0. running mean: 11.838758307977935\n",
      "resetting env. episode reward total was 8.0. running mean: 11.800370724898155\n",
      "resetting env. episode reward total was 4.0. running mean: 11.722367017649173\n",
      "resetting env. episode reward total was 6.0. running mean: 11.665143347472682\n",
      "resetting env. episode reward total was 14.0. running mean: 11.688491913997956\n",
      "resetting env. episode reward total was 16.0. running mean: 11.731606994857977\n",
      "resetting env. episode reward total was 9.0. running mean: 11.704290924909397\n",
      "resetting env. episode reward total was 15.0. running mean: 11.737248015660304\n",
      "resetting env. episode reward total was 13.0. running mean: 11.749875535503701\n",
      "resetting env. episode reward total was 12.0. running mean: 11.752376780148664\n",
      "resetting env. episode reward total was 15.0. running mean: 11.784853012347178\n",
      "resetting env. episode reward total was 13.0. running mean: 11.797004482223706\n",
      "resetting env. episode reward total was 3.0. running mean: 11.709034437401469\n",
      "resetting env. episode reward total was 7.0. running mean: 11.661944093027454\n",
      "resetting env. episode reward total was 8.0. running mean: 11.625324652097179\n",
      "resetting env. episode reward total was 13.0. running mean: 11.639071405576209\n",
      "resetting env. episode reward total was 7.0. running mean: 11.592680691520446\n",
      "resetting env. episode reward total was -8.0. running mean: 11.396753884605241\n",
      "resetting env. episode reward total was 2.0. running mean: 11.302786345759188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 11.329758482301596\n",
      "resetting env. episode reward total was 11.0. running mean: 11.32646089747858\n",
      "resetting env. episode reward total was 7.0. running mean: 11.283196288503794\n",
      "resetting env. episode reward total was 7.0. running mean: 11.240364325618756\n",
      "resetting env. episode reward total was 17.0. running mean: 11.297960682362568\n",
      "resetting env. episode reward total was 16.0. running mean: 11.344981075538943\n",
      "resetting env. episode reward total was 6.0. running mean: 11.291531264783554\n",
      "resetting env. episode reward total was 14.0. running mean: 11.318615952135719\n",
      "resetting env. episode reward total was 11.0. running mean: 11.315429792614362\n",
      "resetting env. episode reward total was 7.0. running mean: 11.272275494688218\n",
      "resetting env. episode reward total was 5.0. running mean: 11.209552739741337\n",
      "resetting env. episode reward total was 12.0. running mean: 11.217457212343923\n",
      "resetting env. episode reward total was 16.0. running mean: 11.265282640220484\n",
      "resetting env. episode reward total was 12.0. running mean: 11.272629813818279\n",
      "resetting env. episode reward total was 8.0. running mean: 11.239903515680096\n",
      "resetting env. episode reward total was 9.0. running mean: 11.217504480523294\n",
      "resetting env. episode reward total was 14.0. running mean: 11.24532943571806\n",
      "resetting env. episode reward total was 16.0. running mean: 11.29287614136088\n",
      "resetting env. episode reward total was 11.0. running mean: 11.28994737994727\n",
      "resetting env. episode reward total was 14.0. running mean: 11.317047906147797\n",
      "resetting env. episode reward total was 5.0. running mean: 11.25387742708632\n",
      "resetting env. episode reward total was 11.0. running mean: 11.251338652815456\n",
      "resetting env. episode reward total was 14.0. running mean: 11.278825266287301\n",
      "resetting env. episode reward total was 13.0. running mean: 11.296037013624428\n",
      "resetting env. episode reward total was 9.0. running mean: 11.273076643488183\n",
      "resetting env. episode reward total was 11.0. running mean: 11.2703458770533\n",
      "resetting env. episode reward total was 12.0. running mean: 11.277642418282767\n",
      "resetting env. episode reward total was 15.0. running mean: 11.31486599409994\n",
      "resetting env. episode reward total was 15.0. running mean: 11.35171733415894\n",
      "resetting env. episode reward total was 12.0. running mean: 11.358200160817349\n",
      "resetting env. episode reward total was 7.0. running mean: 11.314618159209175\n",
      "resetting env. episode reward total was 12.0. running mean: 11.321471977617083\n",
      "resetting env. episode reward total was 15.0. running mean: 11.358257257840913\n",
      "resetting env. episode reward total was 11.0. running mean: 11.354674685262504\n",
      "resetting env. episode reward total was 18.0. running mean: 11.421127938409878\n",
      "resetting env. episode reward total was 11.0. running mean: 11.416916659025778\n",
      "resetting env. episode reward total was 8.0. running mean: 11.38274749243552\n",
      "resetting env. episode reward total was 11.0. running mean: 11.378920017511165\n",
      "resetting env. episode reward total was 5.0. running mean: 11.315130817336053\n",
      "resetting env. episode reward total was 17.0. running mean: 11.371979509162692\n",
      "resetting env. episode reward total was 4.0. running mean: 11.298259714071063\n",
      "resetting env. episode reward total was 12.0. running mean: 11.305277116930352\n",
      "resetting env. episode reward total was 13.0. running mean: 11.322224345761049\n",
      "resetting env. episode reward total was 12.0. running mean: 11.329002102303438\n",
      "resetting env. episode reward total was 13.0. running mean: 11.345712081280404\n",
      "resetting env. episode reward total was 7.0. running mean: 11.3022549604676\n",
      "resetting env. episode reward total was 3.0. running mean: 11.219232410862924\n",
      "resetting env. episode reward total was 10.0. running mean: 11.207040086754294\n",
      "resetting env. episode reward total was 19.0. running mean: 11.28496968588675\n",
      "resetting env. episode reward total was 15.0. running mean: 11.322119989027883\n",
      "resetting env. episode reward total was 12.0. running mean: 11.328898789137602\n",
      "resetting env. episode reward total was -3.0. running mean: 11.185609801246226\n",
      "resetting env. episode reward total was 13.0. running mean: 11.203753703233765\n",
      "resetting env. episode reward total was 13.0. running mean: 11.221716166201428\n",
      "resetting env. episode reward total was 13.0. running mean: 11.239499004539415\n",
      "resetting env. episode reward total was 15.0. running mean: 11.27710401449402\n",
      "resetting env. episode reward total was 12.0. running mean: 11.284332974349079\n",
      "resetting env. episode reward total was 7.0. running mean: 11.241489644605588\n",
      "resetting env. episode reward total was 11.0. running mean: 11.239074748159531\n",
      "resetting env. episode reward total was 14.0. running mean: 11.266684000677936\n",
      "resetting env. episode reward total was 7.0. running mean: 11.224017160671156\n",
      "resetting env. episode reward total was 14.0. running mean: 11.251776989064446\n",
      "resetting env. episode reward total was 10.0. running mean: 11.239259219173801\n",
      "resetting env. episode reward total was 14.0. running mean: 11.266866626982065\n",
      "resetting env. episode reward total was 14.0. running mean: 11.294197960712244\n",
      "resetting env. episode reward total was 14.0. running mean: 11.321255981105123\n",
      "resetting env. episode reward total was 12.0. running mean: 11.32804342129407\n",
      "resetting env. episode reward total was 8.0. running mean: 11.29476298708113\n",
      "resetting env. episode reward total was 6.0. running mean: 11.241815357210319\n",
      "resetting env. episode reward total was 14.0. running mean: 11.269397203638217\n",
      "resetting env. episode reward total was 13.0. running mean: 11.286703231601836\n",
      "resetting env. episode reward total was 9.0. running mean: 11.263836199285818\n",
      "resetting env. episode reward total was 10.0. running mean: 11.25119783729296\n",
      "resetting env. episode reward total was 7.0. running mean: 11.208685858920031\n",
      "resetting env. episode reward total was 8.0. running mean: 11.17659900033083\n",
      "resetting env. episode reward total was 15.0. running mean: 11.214833010327522\n",
      "resetting env. episode reward total was 7.0. running mean: 11.172684680224247\n",
      "resetting env. episode reward total was 2.0. running mean: 11.080957833422003\n",
      "resetting env. episode reward total was 12.0. running mean: 11.090148255087783\n",
      "resetting env. episode reward total was 9.0. running mean: 11.069246772536905\n",
      "resetting env. episode reward total was 13.0. running mean: 11.088554304811536\n",
      "resetting env. episode reward total was 13.0. running mean: 11.107668761763422\n",
      "resetting env. episode reward total was 4.0. running mean: 11.036592074145787\n",
      "resetting env. episode reward total was 12.0. running mean: 11.046226153404328\n",
      "resetting env. episode reward total was 9.0. running mean: 11.025763891870284\n",
      "resetting env. episode reward total was 6.0. running mean: 10.97550625295158\n",
      "resetting env. episode reward total was 12.0. running mean: 10.985751190422064\n",
      "resetting env. episode reward total was 8.0. running mean: 10.955893678517844\n",
      "resetting env. episode reward total was 13.0. running mean: 10.976334741732666\n",
      "resetting env. episode reward total was 10.0. running mean: 10.96657139431534\n",
      "resetting env. episode reward total was 15.0. running mean: 11.006905680372187\n",
      "resetting env. episode reward total was 8.0. running mean: 10.976836623568465\n",
      "resetting env. episode reward total was 14.0. running mean: 11.007068257332781\n",
      "resetting env. episode reward total was 12.0. running mean: 11.016997574759452\n",
      "resetting env. episode reward total was 13.0. running mean: 11.03682759901186\n",
      "resetting env. episode reward total was 9.0. running mean: 11.01645932302174\n",
      "resetting env. episode reward total was 7.0. running mean: 10.976294729791523\n",
      "resetting env. episode reward total was 12.0. running mean: 10.986531782493607\n",
      "resetting env. episode reward total was 9.0. running mean: 10.966666464668672\n",
      "resetting env. episode reward total was 12.0. running mean: 10.976999800021984\n",
      "resetting env. episode reward total was 14.0. running mean: 11.007229802021765\n",
      "resetting env. episode reward total was 14.0. running mean: 11.037157504001549\n",
      "resetting env. episode reward total was 11.0. running mean: 11.036785928961532\n",
      "resetting env. episode reward total was 9.0. running mean: 11.016418069671916\n",
      "resetting env. episode reward total was 9.0. running mean: 10.996253888975197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: 10.896291350085445\n",
      "resetting env. episode reward total was 9.0. running mean: 10.87732843658459\n",
      "resetting env. episode reward total was 15.0. running mean: 10.918555152218744\n",
      "resetting env. episode reward total was 9.0. running mean: 10.899369600696556\n",
      "resetting env. episode reward total was 8.0. running mean: 10.87037590468959\n",
      "resetting env. episode reward total was 13.0. running mean: 10.891672145642694\n",
      "resetting env. episode reward total was 14.0. running mean: 10.922755424186267\n",
      "resetting env. episode reward total was 16.0. running mean: 10.973527869944405\n",
      "resetting env. episode reward total was 13.0. running mean: 10.993792591244961\n",
      "resetting env. episode reward total was -5.0. running mean: 10.833854665332511\n",
      "resetting env. episode reward total was 12.0. running mean: 10.845516118679186\n",
      "resetting env. episode reward total was 9.0. running mean: 10.827060957492394\n",
      "resetting env. episode reward total was 9.0. running mean: 10.80879034791747\n",
      "resetting env. episode reward total was 10.0. running mean: 10.800702444438294\n",
      "resetting env. episode reward total was 15.0. running mean: 10.84269541999391\n",
      "resetting env. episode reward total was 11.0. running mean: 10.84426846579397\n",
      "resetting env. episode reward total was 12.0. running mean: 10.85582578113603\n",
      "resetting env. episode reward total was 15.0. running mean: 10.89726752332467\n",
      "resetting env. episode reward total was 14.0. running mean: 10.928294848091424\n",
      "resetting env. episode reward total was 15.0. running mean: 10.96901189961051\n",
      "resetting env. episode reward total was 13.0. running mean: 10.989321780614405\n",
      "resetting env. episode reward total was 12.0. running mean: 10.99942856280826\n",
      "resetting env. episode reward total was 11.0. running mean: 10.999434277180177\n",
      "resetting env. episode reward total was 10.0. running mean: 10.989439934408374\n",
      "resetting env. episode reward total was 3.0. running mean: 10.90954553506429\n",
      "resetting env. episode reward total was 11.0. running mean: 10.910450079713646\n",
      "resetting env. episode reward total was 16.0. running mean: 10.961345578916509\n",
      "resetting env. episode reward total was 18.0. running mean: 11.031732123127343\n",
      "resetting env. episode reward total was 10.0. running mean: 11.02141480189607\n",
      "resetting env. episode reward total was 20.0. running mean: 11.111200653877107\n",
      "resetting env. episode reward total was 11.0. running mean: 11.110088647338335\n",
      "resetting env. episode reward total was 11.0. running mean: 11.10898776086495\n",
      "resetting env. episode reward total was 21.0. running mean: 11.207897883256301\n",
      "resetting env. episode reward total was 15.0. running mean: 11.245818904423738\n",
      "resetting env. episode reward total was 17.0. running mean: 11.3033607153795\n",
      "resetting env. episode reward total was 11.0. running mean: 11.300327108225703\n",
      "resetting env. episode reward total was 14.0. running mean: 11.327323837143446\n",
      "resetting env. episode reward total was 9.0. running mean: 11.304050598772012\n",
      "resetting env. episode reward total was 8.0. running mean: 11.271010092784291\n",
      "resetting env. episode reward total was 11.0. running mean: 11.268299991856447\n",
      "resetting env. episode reward total was 11.0. running mean: 11.26561699193788\n",
      "resetting env. episode reward total was 13.0. running mean: 11.282960822018502\n",
      "resetting env. episode reward total was 9.0. running mean: 11.260131213798317\n",
      "resetting env. episode reward total was 12.0. running mean: 11.267529901660334\n",
      "resetting env. episode reward total was 14.0. running mean: 11.294854602643731\n",
      "resetting env. episode reward total was 15.0. running mean: 11.331906056617294\n",
      "resetting env. episode reward total was 12.0. running mean: 11.33858699605112\n",
      "resetting env. episode reward total was 16.0. running mean: 11.385201126090609\n",
      "resetting env. episode reward total was 13.0. running mean: 11.401349114829703\n",
      "resetting env. episode reward total was 6.0. running mean: 11.347335623681406\n",
      "resetting env. episode reward total was 15.0. running mean: 11.383862267444593\n",
      "resetting env. episode reward total was 12.0. running mean: 11.390023644770146\n",
      "resetting env. episode reward total was 19.0. running mean: 11.466123408322444\n",
      "resetting env. episode reward total was 5.0. running mean: 11.40146217423922\n",
      "resetting env. episode reward total was 12.0. running mean: 11.407447552496828\n",
      "resetting env. episode reward total was 7.0. running mean: 11.36337307697186\n",
      "resetting env. episode reward total was 14.0. running mean: 11.389739346202141\n",
      "resetting env. episode reward total was 11.0. running mean: 11.385841952740119\n",
      "resetting env. episode reward total was 5.0. running mean: 11.321983533212718\n",
      "resetting env. episode reward total was 20.0. running mean: 11.40876369788059\n",
      "resetting env. episode reward total was 17.0. running mean: 11.464676060901784\n",
      "resetting env. episode reward total was 3.0. running mean: 11.380029300292765\n",
      "resetting env. episode reward total was 2.0. running mean: 11.286229007289837\n",
      "resetting env. episode reward total was 8.0. running mean: 11.253366717216938\n",
      "resetting env. episode reward total was 11.0. running mean: 11.250833050044768\n",
      "resetting env. episode reward total was 7.0. running mean: 11.20832471954432\n",
      "resetting env. episode reward total was 7.0. running mean: 11.166241472348878\n",
      "resetting env. episode reward total was 17.0. running mean: 11.22457905762539\n",
      "resetting env. episode reward total was 13.0. running mean: 11.242333267049135\n",
      "resetting env. episode reward total was 11.0. running mean: 11.239909934378643\n",
      "resetting env. episode reward total was 18.0. running mean: 11.307510835034856\n",
      "resetting env. episode reward total was 12.0. running mean: 11.314435726684506\n",
      "resetting env. episode reward total was 12.0. running mean: 11.32129136941766\n",
      "resetting env. episode reward total was 9.0. running mean: 11.298078455723482\n",
      "resetting env. episode reward total was 9.0. running mean: 11.275097671166247\n",
      "resetting env. episode reward total was 5.0. running mean: 11.212346694454585\n",
      "resetting env. episode reward total was 15.0. running mean: 11.25022322751004\n",
      "resetting env. episode reward total was 16.0. running mean: 11.29772099523494\n",
      "resetting env. episode reward total was 8.0. running mean: 11.26474378528259\n",
      "resetting env. episode reward total was 7.0. running mean: 11.222096347429764\n",
      "resetting env. episode reward total was 14.0. running mean: 11.249875383955466\n",
      "resetting env. episode reward total was 14.0. running mean: 11.277376630115912\n",
      "resetting env. episode reward total was 19.0. running mean: 11.354602863814751\n",
      "resetting env. episode reward total was 18.0. running mean: 11.421056835176604\n",
      "resetting env. episode reward total was 13.0. running mean: 11.436846266824839\n",
      "resetting env. episode reward total was 13.0. running mean: 11.45247780415659\n",
      "resetting env. episode reward total was 17.0. running mean: 11.507953026115024\n",
      "resetting env. episode reward total was 12.0. running mean: 11.512873495853873\n",
      "resetting env. episode reward total was 10.0. running mean: 11.497744760895333\n",
      "resetting env. episode reward total was 6.0. running mean: 11.44276731328638\n",
      "resetting env. episode reward total was 15.0. running mean: 11.478339640153516\n",
      "resetting env. episode reward total was 13.0. running mean: 11.493556243751982\n",
      "resetting env. episode reward total was 10.0. running mean: 11.478620681314462\n",
      "resetting env. episode reward total was 14.0. running mean: 11.503834474501318\n",
      "resetting env. episode reward total was 10.0. running mean: 11.488796129756304\n",
      "resetting env. episode reward total was 9.0. running mean: 11.46390816845874\n",
      "resetting env. episode reward total was 14.0. running mean: 11.489269086774152\n",
      "resetting env. episode reward total was 11.0. running mean: 11.484376395906411\n",
      "resetting env. episode reward total was 13.0. running mean: 11.499532631947348\n",
      "resetting env. episode reward total was 5.0. running mean: 11.434537305627876\n",
      "resetting env. episode reward total was 16.0. running mean: 11.480191932571596\n",
      "resetting env. episode reward total was 12.0. running mean: 11.48539001324588\n",
      "resetting env. episode reward total was 13.0. running mean: 11.500536113113421\n",
      "resetting env. episode reward total was 14.0. running mean: 11.525530751982288\n",
      "resetting env. episode reward total was 11.0. running mean: 11.520275444462465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 11.52507269001784\n",
      "resetting env. episode reward total was 10.0. running mean: 11.50982196311766\n",
      "resetting env. episode reward total was 17.0. running mean: 11.564723743486484\n",
      "resetting env. episode reward total was 15.0. running mean: 11.599076506051619\n",
      "resetting env. episode reward total was 16.0. running mean: 11.643085740991102\n",
      "resetting env. episode reward total was 3.0. running mean: 11.55665488358119\n",
      "resetting env. episode reward total was 8.0. running mean: 11.521088334745379\n",
      "resetting env. episode reward total was 19.0. running mean: 11.595877451397925\n",
      "resetting env. episode reward total was 12.0. running mean: 11.599918676883945\n",
      "resetting env. episode reward total was 9.0. running mean: 11.573919490115106\n",
      "resetting env. episode reward total was 11.0. running mean: 11.568180295213955\n",
      "resetting env. episode reward total was 13.0. running mean: 11.582498492261816\n",
      "resetting env. episode reward total was 10.0. running mean: 11.566673507339198\n",
      "resetting env. episode reward total was 14.0. running mean: 11.591006772265807\n",
      "resetting env. episode reward total was 9.0. running mean: 11.565096704543148\n",
      "resetting env. episode reward total was 11.0. running mean: 11.559445737497716\n",
      "resetting env. episode reward total was 13.0. running mean: 11.57385128012274\n",
      "resetting env. episode reward total was 16.0. running mean: 11.618112767321513\n",
      "resetting env. episode reward total was 15.0. running mean: 11.651931639648298\n",
      "resetting env. episode reward total was 9.0. running mean: 11.625412323251815\n",
      "resetting env. episode reward total was 11.0. running mean: 11.619158200019296\n",
      "resetting env. episode reward total was 16.0. running mean: 11.662966618019103\n",
      "resetting env. episode reward total was 16.0. running mean: 11.706336951838912\n",
      "resetting env. episode reward total was 14.0. running mean: 11.729273582320523\n",
      "resetting env. episode reward total was 17.0. running mean: 11.781980846497317\n",
      "resetting env. episode reward total was 8.0. running mean: 11.744161038032344\n",
      "resetting env. episode reward total was 15.0. running mean: 11.77671942765202\n",
      "resetting env. episode reward total was 7.0. running mean: 11.7289522333755\n",
      "resetting env. episode reward total was 16.0. running mean: 11.771662711041746\n",
      "resetting env. episode reward total was 10.0. running mean: 11.753946083931327\n",
      "resetting env. episode reward total was 20.0. running mean: 11.836406623092012\n",
      "resetting env. episode reward total was 14.0. running mean: 11.858042556861092\n",
      "resetting env. episode reward total was 12.0. running mean: 11.85946213129248\n",
      "resetting env. episode reward total was 10.0. running mean: 11.840867509979555\n",
      "resetting env. episode reward total was 5.0. running mean: 11.77245883487976\n",
      "resetting env. episode reward total was 12.0. running mean: 11.774734246530961\n",
      "resetting env. episode reward total was 10.0. running mean: 11.756986904065652\n",
      "resetting env. episode reward total was 14.0. running mean: 11.779417035024997\n",
      "resetting env. episode reward total was 12.0. running mean: 11.781622864674747\n",
      "resetting env. episode reward total was 11.0. running mean: 11.773806636027999\n",
      "resetting env. episode reward total was 9.0. running mean: 11.746068569667719\n",
      "resetting env. episode reward total was 12.0. running mean: 11.74860788397104\n",
      "resetting env. episode reward total was 17.0. running mean: 11.801121805131329\n",
      "resetting env. episode reward total was 10.0. running mean: 11.783110587080015\n",
      "resetting env. episode reward total was 15.0. running mean: 11.815279481209215\n",
      "resetting env. episode reward total was 13.0. running mean: 11.827126686397124\n",
      "resetting env. episode reward total was 15.0. running mean: 11.858855419533153\n",
      "resetting env. episode reward total was 13.0. running mean: 11.870266865337822\n",
      "resetting env. episode reward total was 9.0. running mean: 11.841564196684443\n",
      "resetting env. episode reward total was 12.0. running mean: 11.843148554717597\n",
      "resetting env. episode reward total was 17.0. running mean: 11.89471706917042\n",
      "resetting env. episode reward total was 9.0. running mean: 11.865769898478716\n",
      "resetting env. episode reward total was 13.0. running mean: 11.87711219949393\n",
      "resetting env. episode reward total was 10.0. running mean: 11.85834107749899\n",
      "resetting env. episode reward total was 14.0. running mean: 11.879757666724\n",
      "resetting env. episode reward total was 17.0. running mean: 11.93096009005676\n",
      "resetting env. episode reward total was 14.0. running mean: 11.951650489156192\n",
      "resetting env. episode reward total was 13.0. running mean: 11.96213398426463\n",
      "resetting env. episode reward total was 15.0. running mean: 11.992512644421984\n",
      "resetting env. episode reward total was 11.0. running mean: 11.982587517977763\n",
      "resetting env. episode reward total was 13.0. running mean: 11.992761642797985\n",
      "resetting env. episode reward total was 8.0. running mean: 11.952834026370006\n",
      "resetting env. episode reward total was 7.0. running mean: 11.903305686106306\n",
      "resetting env. episode reward total was 13.0. running mean: 11.914272629245243\n",
      "resetting env. episode reward total was 17.0. running mean: 11.96512990295279\n",
      "resetting env. episode reward total was 15.0. running mean: 11.995478603923264\n",
      "resetting env. episode reward total was 6.0. running mean: 11.93552381788403\n",
      "resetting env. episode reward total was 6.0. running mean: 11.87616857970519\n",
      "resetting env. episode reward total was 12.0. running mean: 11.877406893908137\n",
      "resetting env. episode reward total was 8.0. running mean: 11.838632824969055\n",
      "resetting env. episode reward total was 15.0. running mean: 11.870246496719364\n",
      "resetting env. episode reward total was 13.0. running mean: 11.88154403175217\n",
      "resetting env. episode reward total was 12.0. running mean: 11.882728591434647\n",
      "resetting env. episode reward total was 10.0. running mean: 11.8639013055203\n",
      "resetting env. episode reward total was 15.0. running mean: 11.895262292465098\n",
      "resetting env. episode reward total was 10.0. running mean: 11.876309669540447\n",
      "resetting env. episode reward total was 7.0. running mean: 11.827546572845042\n",
      "resetting env. episode reward total was 11.0. running mean: 11.819271107116592\n",
      "resetting env. episode reward total was 14.0. running mean: 11.841078396045427\n",
      "resetting env. episode reward total was 13.0. running mean: 11.852667612084973\n",
      "resetting env. episode reward total was 8.0. running mean: 11.814140935964124\n",
      "resetting env. episode reward total was 8.0. running mean: 11.775999526604483\n",
      "resetting env. episode reward total was 12.0. running mean: 11.778239531338437\n",
      "resetting env. episode reward total was 12.0. running mean: 11.780457136025053\n",
      "resetting env. episode reward total was 16.0. running mean: 11.822652564664802\n",
      "resetting env. episode reward total was 15.0. running mean: 11.854426039018154\n",
      "resetting env. episode reward total was 16.0. running mean: 11.895881778627972\n",
      "resetting env. episode reward total was 11.0. running mean: 11.88692296084169\n",
      "resetting env. episode reward total was 10.0. running mean: 11.868053731233273\n",
      "resetting env. episode reward total was 6.0. running mean: 11.80937319392094\n",
      "resetting env. episode reward total was 18.0. running mean: 11.87127946198173\n",
      "resetting env. episode reward total was 15.0. running mean: 11.902566667361913\n",
      "resetting env. episode reward total was 16.0. running mean: 11.943541000688294\n",
      "resetting env. episode reward total was 12.0. running mean: 11.94410559068141\n",
      "resetting env. episode reward total was 10.0. running mean: 11.924664534774596\n",
      "resetting env. episode reward total was 13.0. running mean: 11.935417889426851\n",
      "resetting env. episode reward total was 11.0. running mean: 11.926063710532583\n",
      "resetting env. episode reward total was 11.0. running mean: 11.916803073427257\n",
      "resetting env. episode reward total was 15.0. running mean: 11.947635042692985\n",
      "resetting env. episode reward total was 4.0. running mean: 11.868158692266054\n",
      "resetting env. episode reward total was 4.0. running mean: 11.789477105343392\n",
      "resetting env. episode reward total was 10.0. running mean: 11.771582334289958\n",
      "resetting env. episode reward total was 1.0. running mean: 11.663866510947058\n",
      "resetting env. episode reward total was 8.0. running mean: 11.627227845837586\n",
      "resetting env. episode reward total was 7.0. running mean: 11.58095556737921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 16.0. running mean: 11.625146011705418\n",
      "resetting env. episode reward total was 17.0. running mean: 11.678894551588364\n",
      "resetting env. episode reward total was 11.0. running mean: 11.67210560607248\n",
      "resetting env. episode reward total was 15.0. running mean: 11.705384550011756\n",
      "resetting env. episode reward total was 5.0. running mean: 11.638330704511638\n",
      "resetting env. episode reward total was 10.0. running mean: 11.62194739746652\n",
      "resetting env. episode reward total was 12.0. running mean: 11.625727923491855\n",
      "resetting env. episode reward total was 9.0. running mean: 11.599470644256936\n",
      "resetting env. episode reward total was 7.0. running mean: 11.553475937814367\n",
      "resetting env. episode reward total was 13.0. running mean: 11.567941178436223\n",
      "resetting env. episode reward total was 16.0. running mean: 11.61226176665186\n",
      "resetting env. episode reward total was 19.0. running mean: 11.68613914898534\n",
      "resetting env. episode reward total was 17.0. running mean: 11.739277757495486\n",
      "resetting env. episode reward total was 11.0. running mean: 11.731884979920531\n",
      "resetting env. episode reward total was -3.0. running mean: 11.584566130121326\n",
      "resetting env. episode reward total was 4.0. running mean: 11.508720468820112\n",
      "resetting env. episode reward total was 15.0. running mean: 11.54363326413191\n",
      "resetting env. episode reward total was 11.0. running mean: 11.53819693149059\n",
      "resetting env. episode reward total was 15.0. running mean: 11.572814962175684\n",
      "resetting env. episode reward total was 9.0. running mean: 11.547086812553927\n",
      "resetting env. episode reward total was 14.0. running mean: 11.571615944428387\n",
      "resetting env. episode reward total was 13.0. running mean: 11.585899784984104\n",
      "resetting env. episode reward total was 4.0. running mean: 11.510040787134262\n",
      "resetting env. episode reward total was 14.0. running mean: 11.53494037926292\n",
      "resetting env. episode reward total was 15.0. running mean: 11.569590975470291\n",
      "resetting env. episode reward total was 18.0. running mean: 11.633895065715588\n",
      "resetting env. episode reward total was 15.0. running mean: 11.667556115058433\n",
      "resetting env. episode reward total was 13.0. running mean: 11.68088055390785\n",
      "resetting env. episode reward total was 13.0. running mean: 11.694071748368772\n",
      "resetting env. episode reward total was 15.0. running mean: 11.727131030885085\n",
      "resetting env. episode reward total was 12.0. running mean: 11.729859720576233\n",
      "resetting env. episode reward total was 10.0. running mean: 11.71256112337047\n",
      "resetting env. episode reward total was 16.0. running mean: 11.755435512136765\n",
      "resetting env. episode reward total was 10.0. running mean: 11.737881157015398\n",
      "resetting env. episode reward total was 14.0. running mean: 11.760502345445245\n",
      "resetting env. episode reward total was 12.0. running mean: 11.762897321990792\n",
      "resetting env. episode reward total was 7.0. running mean: 11.715268348770884\n",
      "resetting env. episode reward total was 5.0. running mean: 11.648115665283177\n",
      "resetting env. episode reward total was 14.0. running mean: 11.671634508630346\n",
      "resetting env. episode reward total was 8.0. running mean: 11.634918163544043\n",
      "resetting env. episode reward total was 13.0. running mean: 11.648568981908603\n",
      "resetting env. episode reward total was 11.0. running mean: 11.642083292089517\n",
      "resetting env. episode reward total was 12.0. running mean: 11.645662459168621\n",
      "resetting env. episode reward total was 15.0. running mean: 11.679205834576935\n",
      "resetting env. episode reward total was 11.0. running mean: 11.672413776231165\n",
      "resetting env. episode reward total was 8.0. running mean: 11.635689638468854\n",
      "resetting env. episode reward total was 17.0. running mean: 11.689332742084165\n",
      "resetting env. episode reward total was 13.0. running mean: 11.702439414663324\n",
      "resetting env. episode reward total was 12.0. running mean: 11.705415020516691\n",
      "resetting env. episode reward total was 15.0. running mean: 11.738360870311524\n",
      "resetting env. episode reward total was 7.0. running mean: 11.69097726160841\n",
      "resetting env. episode reward total was 6.0. running mean: 11.634067488992326\n",
      "resetting env. episode reward total was 17.0. running mean: 11.687726814102403\n",
      "resetting env. episode reward total was 12.0. running mean: 11.690849545961377\n",
      "resetting env. episode reward total was 11.0. running mean: 11.683941050501764\n",
      "resetting env. episode reward total was 12.0. running mean: 11.687101639996746\n",
      "resetting env. episode reward total was 3.0. running mean: 11.600230623596778\n",
      "resetting env. episode reward total was 13.0. running mean: 11.61422831736081\n",
      "resetting env. episode reward total was 13.0. running mean: 11.628086034187202\n",
      "resetting env. episode reward total was 9.0. running mean: 11.60180517384533\n",
      "resetting env. episode reward total was 16.0. running mean: 11.645787122106876\n",
      "resetting env. episode reward total was 17.0. running mean: 11.699329250885807\n",
      "resetting env. episode reward total was 11.0. running mean: 11.692335958376948\n",
      "resetting env. episode reward total was 19.0. running mean: 11.765412598793178\n",
      "resetting env. episode reward total was 15.0. running mean: 11.797758472805247\n",
      "resetting env. episode reward total was 9.0. running mean: 11.769780888077195\n",
      "resetting env. episode reward total was 18.0. running mean: 11.832083079196423\n",
      "resetting env. episode reward total was 14.0. running mean: 11.85376224840446\n",
      "resetting env. episode reward total was 9.0. running mean: 11.825224625920415\n",
      "resetting env. episode reward total was 14.0. running mean: 11.84697237966121\n",
      "resetting env. episode reward total was 11.0. running mean: 11.838502655864596\n",
      "resetting env. episode reward total was 10.0. running mean: 11.82011762930595\n",
      "resetting env. episode reward total was 12.0. running mean: 11.82191645301289\n",
      "resetting env. episode reward total was 10.0. running mean: 11.80369728848276\n",
      "resetting env. episode reward total was 12.0. running mean: 11.805660315597931\n",
      "resetting env. episode reward total was 9.0. running mean: 11.777603712441952\n",
      "resetting env. episode reward total was 12.0. running mean: 11.77982767531753\n",
      "resetting env. episode reward total was 12.0. running mean: 11.782029398564354\n",
      "resetting env. episode reward total was 5.0. running mean: 11.714209104578712\n",
      "resetting env. episode reward total was 12.0. running mean: 11.717067013532924\n",
      "resetting env. episode reward total was 12.0. running mean: 11.719896343397593\n",
      "resetting env. episode reward total was 13.0. running mean: 11.732697379963618\n",
      "resetting env. episode reward total was 13.0. running mean: 11.745370406163982\n",
      "resetting env. episode reward total was 9.0. running mean: 11.717916702102341\n",
      "resetting env. episode reward total was 3.0. running mean: 11.630737535081318\n",
      "resetting env. episode reward total was -3.0. running mean: 11.484430159730506\n",
      "resetting env. episode reward total was 12.0. running mean: 11.4895858581332\n",
      "resetting env. episode reward total was 15.0. running mean: 11.524689999551867\n",
      "resetting env. episode reward total was 16.0. running mean: 11.569443099556349\n",
      "resetting env. episode reward total was 5.0. running mean: 11.503748668560785\n",
      "resetting env. episode reward total was 15.0. running mean: 11.538711181875177\n",
      "resetting env. episode reward total was 6.0. running mean: 11.483324070056426\n",
      "resetting env. episode reward total was 9.0. running mean: 11.458490829355862\n",
      "resetting env. episode reward total was 8.0. running mean: 11.423905921062303\n",
      "resetting env. episode reward total was 9.0. running mean: 11.39966686185168\n",
      "resetting env. episode reward total was 18.0. running mean: 11.465670193233162\n",
      "resetting env. episode reward total was 8.0. running mean: 11.431013491300831\n",
      "resetting env. episode reward total was 7.0. running mean: 11.386703356387823\n",
      "resetting env. episode reward total was 10.0. running mean: 11.372836322823945\n",
      "resetting env. episode reward total was 15.0. running mean: 11.409107959595705\n",
      "resetting env. episode reward total was 16.0. running mean: 11.455016879999748\n",
      "resetting env. episode reward total was 16.0. running mean: 11.500466711199751\n",
      "resetting env. episode reward total was 11.0. running mean: 11.495462044087752\n",
      "resetting env. episode reward total was 14.0. running mean: 11.520507423646874\n",
      "resetting env. episode reward total was 13.0. running mean: 11.535302349410406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 11.549949325916304\n",
      "resetting env. episode reward total was 5.0. running mean: 11.484449832657141\n",
      "resetting env. episode reward total was 11.0. running mean: 11.47960533433057\n",
      "resetting env. episode reward total was 8.0. running mean: 11.444809280987265\n",
      "resetting env. episode reward total was 10.0. running mean: 11.430361188177391\n",
      "resetting env. episode reward total was 12.0. running mean: 11.436057576295617\n",
      "resetting env. episode reward total was 16.0. running mean: 11.48169700053266\n",
      "resetting env. episode reward total was 5.0. running mean: 11.416880030527334\n",
      "resetting env. episode reward total was 17.0. running mean: 11.47271123022206\n",
      "resetting env. episode reward total was 15.0. running mean: 11.50798411791984\n",
      "resetting env. episode reward total was 7.0. running mean: 11.462904276740641\n",
      "resetting env. episode reward total was 13.0. running mean: 11.478275233973235\n",
      "resetting env. episode reward total was 11.0. running mean: 11.473492481633503\n",
      "resetting env. episode reward total was 13.0. running mean: 11.488757556817168\n",
      "resetting env. episode reward total was 12.0. running mean: 11.493869981248995\n",
      "resetting env. episode reward total was 15.0. running mean: 11.528931281436506\n",
      "resetting env. episode reward total was 15.0. running mean: 11.563641968622141\n",
      "resetting env. episode reward total was 9.0. running mean: 11.538005548935919\n",
      "resetting env. episode reward total was 7.0. running mean: 11.49262549344656\n",
      "resetting env. episode reward total was 5.0. running mean: 11.427699238512096\n",
      "resetting env. episode reward total was 3.0. running mean: 11.343422246126973\n",
      "resetting env. episode reward total was 9.0. running mean: 11.319988023665703\n",
      "resetting env. episode reward total was 8.0. running mean: 11.286788143429046\n",
      "resetting env. episode reward total was 9.0. running mean: 11.263920261994755\n",
      "resetting env. episode reward total was 6.0. running mean: 11.211281059374809\n",
      "resetting env. episode reward total was 10.0. running mean: 11.19916824878106\n",
      "resetting env. episode reward total was 10.0. running mean: 11.18717656629325\n",
      "resetting env. episode reward total was 8.0. running mean: 11.155304800630317\n",
      "resetting env. episode reward total was 14.0. running mean: 11.183751752624014\n",
      "resetting env. episode reward total was 13.0. running mean: 11.201914235097775\n",
      "resetting env. episode reward total was 7.0. running mean: 11.159895092746797\n",
      "resetting env. episode reward total was 15.0. running mean: 11.19829614181933\n",
      "resetting env. episode reward total was 11.0. running mean: 11.196313180401136\n",
      "resetting env. episode reward total was 16.0. running mean: 11.244350048597125\n",
      "resetting env. episode reward total was 12.0. running mean: 11.251906548111153\n",
      "resetting env. episode reward total was 20.0. running mean: 11.339387482630041\n",
      "resetting env. episode reward total was 7.0. running mean: 11.29599360780374\n",
      "resetting env. episode reward total was 6.0. running mean: 11.243033671725703\n",
      "resetting env. episode reward total was 2.0. running mean: 11.150603335008446\n",
      "resetting env. episode reward total was 13.0. running mean: 11.169097301658363\n",
      "resetting env. episode reward total was 15.0. running mean: 11.20740632864178\n",
      "resetting env. episode reward total was 12.0. running mean: 11.21533226535536\n",
      "resetting env. episode reward total was 19.0. running mean: 11.293178942701807\n",
      "resetting env. episode reward total was 9.0. running mean: 11.27024715327479\n",
      "resetting env. episode reward total was 14.0. running mean: 11.297544681742043\n",
      "resetting env. episode reward total was 10.0. running mean: 11.284569234924621\n",
      "resetting env. episode reward total was 10.0. running mean: 11.271723542575375\n",
      "resetting env. episode reward total was 9.0. running mean: 11.249006307149621\n",
      "resetting env. episode reward total was 7.0. running mean: 11.206516244078125\n",
      "resetting env. episode reward total was 15.0. running mean: 11.244451081637344\n",
      "resetting env. episode reward total was 17.0. running mean: 11.30200657082097\n",
      "resetting env. episode reward total was 16.0. running mean: 11.34898650511276\n",
      "resetting env. episode reward total was 12.0. running mean: 11.355496640061633\n",
      "resetting env. episode reward total was 15.0. running mean: 11.391941673661016\n",
      "resetting env. episode reward total was 9.0. running mean: 11.368022256924405\n",
      "resetting env. episode reward total was 14.0. running mean: 11.394342034355162\n",
      "resetting env. episode reward total was 9.0. running mean: 11.370398614011611\n",
      "resetting env. episode reward total was 11.0. running mean: 11.366694627871494\n",
      "resetting env. episode reward total was 14.0. running mean: 11.39302768159278\n",
      "resetting env. episode reward total was 15.0. running mean: 11.429097404776853\n",
      "resetting env. episode reward total was 12.0. running mean: 11.434806430729083\n",
      "resetting env. episode reward total was 10.0. running mean: 11.42045836642179\n",
      "resetting env. episode reward total was 14.0. running mean: 11.446253782757573\n",
      "resetting env. episode reward total was 13.0. running mean: 11.461791244929998\n",
      "resetting env. episode reward total was 15.0. running mean: 11.497173332480699\n",
      "resetting env. episode reward total was 10.0. running mean: 11.482201599155891\n",
      "resetting env. episode reward total was 10.0. running mean: 11.467379583164332\n",
      "resetting env. episode reward total was 9.0. running mean: 11.442705787332688\n",
      "resetting env. episode reward total was 10.0. running mean: 11.428278729459361\n",
      "resetting env. episode reward total was 13.0. running mean: 11.443995942164769\n",
      "resetting env. episode reward total was 11.0. running mean: 11.439555982743121\n",
      "resetting env. episode reward total was 11.0. running mean: 11.43516042291569\n",
      "resetting env. episode reward total was 12.0. running mean: 11.440808818686532\n",
      "resetting env. episode reward total was 10.0. running mean: 11.426400730499667\n",
      "resetting env. episode reward total was 11.0. running mean: 11.42213672319467\n",
      "resetting env. episode reward total was 15.0. running mean: 11.457915355962724\n",
      "resetting env. episode reward total was 11.0. running mean: 11.453336202403095\n",
      "resetting env. episode reward total was 14.0. running mean: 11.478802840379064\n",
      "resetting env. episode reward total was 14.0. running mean: 11.504014811975274\n",
      "resetting env. episode reward total was 9.0. running mean: 11.47897466385552\n",
      "resetting env. episode reward total was 12.0. running mean: 11.484184917216965\n",
      "resetting env. episode reward total was 5.0. running mean: 11.419343068044796\n",
      "resetting env. episode reward total was 10.0. running mean: 11.405149637364348\n",
      "resetting env. episode reward total was 10.0. running mean: 11.391098140990703\n",
      "resetting env. episode reward total was 1.0. running mean: 11.287187159580796\n",
      "resetting env. episode reward total was 2.0. running mean: 11.194315287984988\n",
      "resetting env. episode reward total was 6.0. running mean: 11.14237213510514\n",
      "resetting env. episode reward total was 18.0. running mean: 11.210948413754087\n",
      "resetting env. episode reward total was 5.0. running mean: 11.148838929616547\n",
      "resetting env. episode reward total was 12.0. running mean: 11.15735054032038\n",
      "resetting env. episode reward total was 13.0. running mean: 11.175777034917177\n",
      "resetting env. episode reward total was 14.0. running mean: 11.204019264568005\n",
      "resetting env. episode reward total was 13.0. running mean: 11.221979071922327\n",
      "resetting env. episode reward total was 9.0. running mean: 11.199759281203104\n",
      "resetting env. episode reward total was 4.0. running mean: 11.127761688391072\n",
      "resetting env. episode reward total was 12.0. running mean: 11.13648407150716\n",
      "resetting env. episode reward total was 15.0. running mean: 11.17511923079209\n",
      "resetting env. episode reward total was 10.0. running mean: 11.163368038484169\n",
      "resetting env. episode reward total was 15.0. running mean: 11.201734358099328\n",
      "resetting env. episode reward total was 7.0. running mean: 11.159717014518336\n",
      "resetting env. episode reward total was 11.0. running mean: 11.158119844373152\n",
      "resetting env. episode reward total was 16.0. running mean: 11.20653864592942\n",
      "resetting env. episode reward total was 16.0. running mean: 11.254473259470126\n",
      "resetting env. episode reward total was 8.0. running mean: 11.221928526875425\n",
      "resetting env. episode reward total was 11.0. running mean: 11.21970924160667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 11.247512149190605\n",
      "resetting env. episode reward total was 11.0. running mean: 11.245037027698698\n",
      "resetting env. episode reward total was 7.0. running mean: 11.202586657421712\n",
      "resetting env. episode reward total was 10.0. running mean: 11.190560790847494\n",
      "resetting env. episode reward total was 6.0. running mean: 11.138655182939019\n",
      "resetting env. episode reward total was 5.0. running mean: 11.077268631109629\n",
      "resetting env. episode reward total was 11.0. running mean: 11.076495944798532\n",
      "resetting env. episode reward total was 15.0. running mean: 11.115730985350547\n",
      "resetting env. episode reward total was 14.0. running mean: 11.144573675497043\n",
      "resetting env. episode reward total was 9.0. running mean: 11.123127938742073\n",
      "resetting env. episode reward total was 12.0. running mean: 11.131896659354652\n",
      "resetting env. episode reward total was 6.0. running mean: 11.080577692761105\n",
      "resetting env. episode reward total was 14.0. running mean: 11.109771915833495\n",
      "resetting env. episode reward total was 8.0. running mean: 11.07867419667516\n",
      "resetting env. episode reward total was 9.0. running mean: 11.057887454708407\n",
      "resetting env. episode reward total was 8.0. running mean: 11.027308580161323\n",
      "resetting env. episode reward total was 13.0. running mean: 11.04703549435971\n",
      "resetting env. episode reward total was 7.0. running mean: 11.006565139416113\n",
      "resetting env. episode reward total was 10.0. running mean: 10.996499488021952\n",
      "resetting env. episode reward total was 10.0. running mean: 10.986534493141733\n",
      "resetting env. episode reward total was 9.0. running mean: 10.966669148210315\n",
      "resetting env. episode reward total was -5.0. running mean: 10.807002456728211\n",
      "resetting env. episode reward total was 12.0. running mean: 10.818932432160928\n",
      "resetting env. episode reward total was 14.0. running mean: 10.85074310783932\n",
      "resetting env. episode reward total was -3.0. running mean: 10.712235676760926\n",
      "resetting env. episode reward total was 16.0. running mean: 10.765113319993317\n",
      "resetting env. episode reward total was 17.0. running mean: 10.827462186793383\n",
      "resetting env. episode reward total was 13.0. running mean: 10.84918756492545\n",
      "resetting env. episode reward total was 13.0. running mean: 10.870695689276195\n",
      "resetting env. episode reward total was 12.0. running mean: 10.881988732383432\n",
      "resetting env. episode reward total was 11.0. running mean: 10.883168845059597\n",
      "resetting env. episode reward total was -10.0. running mean: 10.674337156609\n",
      "resetting env. episode reward total was 11.0. running mean: 10.67759378504291\n",
      "resetting env. episode reward total was 14.0. running mean: 10.710817847192482\n",
      "resetting env. episode reward total was 14.0. running mean: 10.743709668720557\n",
      "resetting env. episode reward total was 5.0. running mean: 10.686272572033353\n",
      "resetting env. episode reward total was 13.0. running mean: 10.70940984631302\n",
      "resetting env. episode reward total was 5.0. running mean: 10.65231574784989\n",
      "resetting env. episode reward total was 14.0. running mean: 10.685792590371392\n",
      "resetting env. episode reward total was 8.0. running mean: 10.658934664467678\n",
      "resetting env. episode reward total was 15.0. running mean: 10.702345317823001\n",
      "resetting env. episode reward total was 15.0. running mean: 10.74532186464477\n",
      "resetting env. episode reward total was 10.0. running mean: 10.737868645998322\n",
      "resetting env. episode reward total was 15.0. running mean: 10.78048995953834\n",
      "resetting env. episode reward total was 12.0. running mean: 10.792685059942956\n",
      "resetting env. episode reward total was 17.0. running mean: 10.854758209343526\n",
      "resetting env. episode reward total was 5.0. running mean: 10.796210627250092\n",
      "resetting env. episode reward total was 4.0. running mean: 10.72824852097759\n",
      "resetting env. episode reward total was 15.0. running mean: 10.770966035767815\n",
      "resetting env. episode reward total was 11.0. running mean: 10.773256375410137\n",
      "resetting env. episode reward total was 14.0. running mean: 10.805523811656036\n",
      "resetting env. episode reward total was 5.0. running mean: 10.747468573539477\n",
      "resetting env. episode reward total was 5.0. running mean: 10.689993887804082\n",
      "resetting env. episode reward total was 12.0. running mean: 10.70309394892604\n",
      "resetting env. episode reward total was 10.0. running mean: 10.69606300943678\n",
      "resetting env. episode reward total was 11.0. running mean: 10.699102379342412\n",
      "resetting env. episode reward total was 13.0. running mean: 10.722111355548988\n",
      "resetting env. episode reward total was 16.0. running mean: 10.774890241993498\n",
      "resetting env. episode reward total was 5.0. running mean: 10.717141339573564\n",
      "resetting env. episode reward total was 11.0. running mean: 10.719969926177827\n",
      "resetting env. episode reward total was 13.0. running mean: 10.742770226916049\n",
      "resetting env. episode reward total was 11.0. running mean: 10.745342524646887\n",
      "resetting env. episode reward total was 10.0. running mean: 10.737889099400418\n",
      "resetting env. episode reward total was 13.0. running mean: 10.760510208406414\n",
      "resetting env. episode reward total was 16.0. running mean: 10.81290510632235\n",
      "resetting env. episode reward total was 12.0. running mean: 10.824776055259127\n",
      "resetting env. episode reward total was 12.0. running mean: 10.836528294706534\n",
      "resetting env. episode reward total was 11.0. running mean: 10.838163011759468\n",
      "resetting env. episode reward total was 10.0. running mean: 10.829781381641872\n",
      "resetting env. episode reward total was 15.0. running mean: 10.871483567825454\n",
      "resetting env. episode reward total was 9.0. running mean: 10.852768732147199\n",
      "resetting env. episode reward total was 11.0. running mean: 10.854241044825727\n",
      "resetting env. episode reward total was 12.0. running mean: 10.86569863437747\n",
      "resetting env. episode reward total was 15.0. running mean: 10.907041648033696\n",
      "resetting env. episode reward total was 18.0. running mean: 10.977971231553358\n",
      "resetting env. episode reward total was 10.0. running mean: 10.968191519237823\n",
      "resetting env. episode reward total was 13.0. running mean: 10.988509604045445\n",
      "resetting env. episode reward total was 14.0. running mean: 11.018624508004992\n",
      "resetting env. episode reward total was 6.0. running mean: 10.968438262924943\n",
      "resetting env. episode reward total was 15.0. running mean: 11.008753880295695\n",
      "resetting env. episode reward total was 12.0. running mean: 11.018666341492736\n",
      "resetting env. episode reward total was 9.0. running mean: 10.998479678077809\n",
      "resetting env. episode reward total was 19.0. running mean: 11.07849488129703\n",
      "resetting env. episode reward total was 8.0. running mean: 11.047709932484059\n",
      "resetting env. episode reward total was -2.0. running mean: 10.917232833159218\n",
      "resetting env. episode reward total was 4.0. running mean: 10.848060504827625\n",
      "resetting env. episode reward total was 13.0. running mean: 10.86957989977935\n",
      "resetting env. episode reward total was 8.0. running mean: 10.840884100781556\n",
      "resetting env. episode reward total was 19.0. running mean: 10.92247525977374\n",
      "resetting env. episode reward total was 3.0. running mean: 10.843250507176002\n",
      "resetting env. episode reward total was 8.0. running mean: 10.814818002104241\n",
      "resetting env. episode reward total was 10.0. running mean: 10.806669822083197\n",
      "resetting env. episode reward total was 11.0. running mean: 10.808603123862365\n",
      "resetting env. episode reward total was 8.0. running mean: 10.780517092623741\n",
      "resetting env. episode reward total was 9.0. running mean: 10.762711921697504\n",
      "resetting env. episode reward total was 14.0. running mean: 10.79508480248053\n",
      "resetting env. episode reward total was 13.0. running mean: 10.817133954455725\n",
      "resetting env. episode reward total was 16.0. running mean: 10.868962614911169\n",
      "resetting env. episode reward total was 20.0. running mean: 10.960272988762057\n",
      "resetting env. episode reward total was 5.0. running mean: 10.900670258874436\n",
      "resetting env. episode reward total was 17.0. running mean: 10.961663556285691\n",
      "resetting env. episode reward total was 12.0. running mean: 10.972046920722834\n",
      "resetting env. episode reward total was 10.0. running mean: 10.962326451515604\n",
      "resetting env. episode reward total was 10.0. running mean: 10.952703187000449\n",
      "resetting env. episode reward total was 11.0. running mean: 10.953176155130443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 10.913644393579139\n",
      "resetting env. episode reward total was 13.0. running mean: 10.934507949643349\n",
      "resetting env. episode reward total was 3.0. running mean: 10.855162870146914\n",
      "resetting env. episode reward total was 15.0. running mean: 10.896611241445445\n",
      "resetting env. episode reward total was 15.0. running mean: 10.93764512903099\n",
      "resetting env. episode reward total was 12.0. running mean: 10.94826867774068\n",
      "resetting env. episode reward total was 7.0. running mean: 10.908785990963274\n",
      "resetting env. episode reward total was 7.0. running mean: 10.869698131053642\n",
      "resetting env. episode reward total was 17.0. running mean: 10.931001149743105\n",
      "resetting env. episode reward total was 15.0. running mean: 10.971691138245674\n",
      "resetting env. episode reward total was 11.0. running mean: 10.971974226863217\n",
      "resetting env. episode reward total was 18.0. running mean: 11.042254484594585\n",
      "resetting env. episode reward total was 12.0. running mean: 11.051831939748638\n",
      "resetting env. episode reward total was 12.0. running mean: 11.06131362035115\n",
      "resetting env. episode reward total was 10.0. running mean: 11.050700484147638\n",
      "resetting env. episode reward total was 8.0. running mean: 11.020193479306162\n",
      "resetting env. episode reward total was 16.0. running mean: 11.0699915445131\n",
      "resetting env. episode reward total was 5.0. running mean: 11.009291629067969\n",
      "resetting env. episode reward total was 17.0. running mean: 11.069198712777288\n",
      "resetting env. episode reward total was 13.0. running mean: 11.088506725649516\n",
      "resetting env. episode reward total was 10.0. running mean: 11.07762165839302\n",
      "resetting env. episode reward total was 13.0. running mean: 11.09684544180909\n",
      "resetting env. episode reward total was 15.0. running mean: 11.135876987391\n",
      "resetting env. episode reward total was 4.0. running mean: 11.06451821751709\n",
      "resetting env. episode reward total was 10.0. running mean: 11.053873035341919\n",
      "resetting env. episode reward total was 19.0. running mean: 11.1333343049885\n",
      "resetting env. episode reward total was 10.0. running mean: 11.122000961938614\n",
      "resetting env. episode reward total was 17.0. running mean: 11.180780952319228\n",
      "resetting env. episode reward total was 9.0. running mean: 11.158973142796036\n",
      "resetting env. episode reward total was 12.0. running mean: 11.167383411368075\n",
      "resetting env. episode reward total was 15.0. running mean: 11.205709577254394\n",
      "resetting env. episode reward total was 6.0. running mean: 11.153652481481851\n",
      "resetting env. episode reward total was 16.0. running mean: 11.202115956667033\n",
      "resetting env. episode reward total was 11.0. running mean: 11.200094797100363\n",
      "resetting env. episode reward total was 12.0. running mean: 11.208093849129359\n",
      "resetting env. episode reward total was 5.0. running mean: 11.146012910638065\n",
      "resetting env. episode reward total was 16.0. running mean: 11.194552781531685\n",
      "resetting env. episode reward total was 12.0. running mean: 11.202607253716367\n",
      "resetting env. episode reward total was 15.0. running mean: 11.240581181179204\n",
      "resetting env. episode reward total was 10.0. running mean: 11.228175369367412\n",
      "resetting env. episode reward total was 12.0. running mean: 11.235893615673737\n",
      "resetting env. episode reward total was 17.0. running mean: 11.293534679516998\n",
      "resetting env. episode reward total was 10.0. running mean: 11.280599332721827\n",
      "resetting env. episode reward total was 13.0. running mean: 11.29779333939461\n",
      "resetting env. episode reward total was -1.0. running mean: 11.174815406000665\n",
      "resetting env. episode reward total was 11.0. running mean: 11.173067251940658\n",
      "resetting env. episode reward total was 11.0. running mean: 11.17133657942125\n",
      "resetting env. episode reward total was 11.0. running mean: 11.169623213627037\n",
      "resetting env. episode reward total was 12.0. running mean: 11.177926981490765\n",
      "resetting env. episode reward total was 9.0. running mean: 11.156147711675857\n",
      "resetting env. episode reward total was 14.0. running mean: 11.184586234559099\n",
      "resetting env. episode reward total was 16.0. running mean: 11.232740372213508\n",
      "resetting env. episode reward total was 8.0. running mean: 11.200412968491372\n",
      "resetting env. episode reward total was 6.0. running mean: 11.148408838806459\n",
      "resetting env. episode reward total was 8.0. running mean: 11.116924750418395\n",
      "resetting env. episode reward total was 10.0. running mean: 11.10575550291421\n",
      "resetting env. episode reward total was 7.0. running mean: 11.064697947885069\n",
      "resetting env. episode reward total was 8.0. running mean: 11.034050968406218\n",
      "resetting env. episode reward total was 17.0. running mean: 11.093710458722155\n",
      "resetting env. episode reward total was 15.0. running mean: 11.132773354134933\n",
      "resetting env. episode reward total was 8.0. running mean: 11.101445620593584\n",
      "resetting env. episode reward total was 17.0. running mean: 11.160431164387647\n",
      "resetting env. episode reward total was 14.0. running mean: 11.188826852743771\n",
      "resetting env. episode reward total was 13.0. running mean: 11.206938584216335\n",
      "resetting env. episode reward total was 12.0. running mean: 11.21486919837417\n",
      "resetting env. episode reward total was 7.0. running mean: 11.172720506390428\n",
      "resetting env. episode reward total was 8.0. running mean: 11.140993301326525\n",
      "resetting env. episode reward total was 18.0. running mean: 11.20958336831326\n",
      "resetting env. episode reward total was 3.0. running mean: 11.127487534630125\n",
      "resetting env. episode reward total was 11.0. running mean: 11.126212659283823\n",
      "resetting env. episode reward total was 12.0. running mean: 11.134950532690985\n",
      "resetting env. episode reward total was 5.0. running mean: 11.073601027364075\n",
      "resetting env. episode reward total was 10.0. running mean: 11.062865017090434\n",
      "resetting env. episode reward total was 16.0. running mean: 11.11223636691953\n",
      "resetting env. episode reward total was 13.0. running mean: 11.131114003250335\n",
      "resetting env. episode reward total was 15.0. running mean: 11.169802863217832\n",
      "resetting env. episode reward total was 15.0. running mean: 11.208104834585654\n",
      "resetting env. episode reward total was 11.0. running mean: 11.206023786239797\n",
      "resetting env. episode reward total was 10.0. running mean: 11.193963548377399\n",
      "resetting env. episode reward total was 14.0. running mean: 11.222023912893626\n",
      "resetting env. episode reward total was 11.0. running mean: 11.21980367376469\n",
      "resetting env. episode reward total was 12.0. running mean: 11.227605637027041\n",
      "resetting env. episode reward total was 19.0. running mean: 11.305329580656771\n",
      "resetting env. episode reward total was 12.0. running mean: 11.312276284850203\n",
      "resetting env. episode reward total was 13.0. running mean: 11.329153522001702\n",
      "resetting env. episode reward total was 10.0. running mean: 11.315861986781684\n",
      "resetting env. episode reward total was 17.0. running mean: 11.372703366913868\n",
      "resetting env. episode reward total was 10.0. running mean: 11.358976333244728\n",
      "resetting env. episode reward total was 5.0. running mean: 11.295386569912282\n",
      "resetting env. episode reward total was 4.0. running mean: 11.222432704213158\n",
      "resetting env. episode reward total was 12.0. running mean: 11.230208377171026\n",
      "resetting env. episode reward total was 6.0. running mean: 11.177906293399316\n",
      "resetting env. episode reward total was 8.0. running mean: 11.146127230465323\n",
      "resetting env. episode reward total was 8.0. running mean: 11.11466595816067\n",
      "resetting env. episode reward total was 8.0. running mean: 11.083519298579063\n",
      "resetting env. episode reward total was 5.0. running mean: 11.022684105593273\n",
      "resetting env. episode reward total was 14.0. running mean: 11.05245726453734\n",
      "resetting env. episode reward total was 15.0. running mean: 11.091932691891968\n",
      "resetting env. episode reward total was 14.0. running mean: 11.121013364973049\n",
      "resetting env. episode reward total was 10.0. running mean: 11.109803231323317\n",
      "resetting env. episode reward total was 17.0. running mean: 11.168705199010084\n",
      "resetting env. episode reward total was 14.0. running mean: 11.197018147019984\n",
      "resetting env. episode reward total was 11.0. running mean: 11.195047965549783\n",
      "resetting env. episode reward total was 13.0. running mean: 11.213097485894286\n",
      "resetting env. episode reward total was 9.0. running mean: 11.190966511035343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 11.20905684592499\n",
      "resetting env. episode reward total was 9.0. running mean: 11.186966277465741\n",
      "resetting env. episode reward total was 16.0. running mean: 11.235096614691084\n",
      "resetting env. episode reward total was 8.0. running mean: 11.202745648544173\n",
      "resetting env. episode reward total was 12.0. running mean: 11.21071819205873\n",
      "resetting env. episode reward total was 16.0. running mean: 11.258611010138143\n",
      "resetting env. episode reward total was 11.0. running mean: 11.256024900036762\n",
      "resetting env. episode reward total was 12.0. running mean: 11.263464651036394\n",
      "resetting env. episode reward total was 16.0. running mean: 11.31083000452603\n",
      "resetting env. episode reward total was 15.0. running mean: 11.34772170448077\n",
      "resetting env. episode reward total was 11.0. running mean: 11.344244487435962\n",
      "resetting env. episode reward total was 6.0. running mean: 11.290802042561602\n",
      "resetting env. episode reward total was 14.0. running mean: 11.317894022135986\n",
      "resetting env. episode reward total was 11.0. running mean: 11.314715081914626\n",
      "resetting env. episode reward total was 7.0. running mean: 11.271567931095479\n",
      "resetting env. episode reward total was 10.0. running mean: 11.258852251784523\n",
      "resetting env. episode reward total was 3.0. running mean: 11.176263729266678\n",
      "resetting env. episode reward total was 10.0. running mean: 11.16450109197401\n",
      "resetting env. episode reward total was 10.0. running mean: 11.152856081054269\n",
      "resetting env. episode reward total was 19.0. running mean: 11.231327520243726\n",
      "resetting env. episode reward total was 16.0. running mean: 11.279014245041289\n",
      "resetting env. episode reward total was 7.0. running mean: 11.236224102590876\n",
      "resetting env. episode reward total was 10.0. running mean: 11.223861861564966\n",
      "resetting env. episode reward total was 12.0. running mean: 11.231623242949317\n",
      "resetting env. episode reward total was 7.0. running mean: 11.189307010519824\n",
      "resetting env. episode reward total was 15.0. running mean: 11.227413940414626\n",
      "resetting env. episode reward total was 16.0. running mean: 11.27513980101048\n",
      "resetting env. episode reward total was 12.0. running mean: 11.282388403000375\n",
      "resetting env. episode reward total was 14.0. running mean: 11.309564518970372\n",
      "resetting env. episode reward total was 18.0. running mean: 11.376468873780668\n",
      "resetting env. episode reward total was 18.0. running mean: 11.442704185042862\n",
      "resetting env. episode reward total was 16.0. running mean: 11.488277143192434\n",
      "resetting env. episode reward total was 12.0. running mean: 11.493394371760509\n",
      "resetting env. episode reward total was 16.0. running mean: 11.538460428042903\n",
      "resetting env. episode reward total was 11.0. running mean: 11.533075823762474\n",
      "resetting env. episode reward total was 15.0. running mean: 11.56774506552485\n",
      "resetting env. episode reward total was 13.0. running mean: 11.582067614869603\n",
      "resetting env. episode reward total was 10.0. running mean: 11.566246938720907\n",
      "resetting env. episode reward total was 8.0. running mean: 11.530584469333698\n",
      "resetting env. episode reward total was 4.0. running mean: 11.45527862464036\n",
      "resetting env. episode reward total was 15.0. running mean: 11.490725838393958\n",
      "resetting env. episode reward total was 16.0. running mean: 11.535818580010018\n",
      "resetting env. episode reward total was 12.0. running mean: 11.540460394209916\n",
      "resetting env. episode reward total was 11.0. running mean: 11.535055790267815\n",
      "resetting env. episode reward total was 9.0. running mean: 11.509705232365137\n",
      "resetting env. episode reward total was 19.0. running mean: 11.584608180041485\n",
      "resetting env. episode reward total was 12.0. running mean: 11.58876209824107\n",
      "resetting env. episode reward total was 13.0. running mean: 11.60287447725866\n",
      "resetting env. episode reward total was 9.0. running mean: 11.576845732486072\n",
      "resetting env. episode reward total was 8.0. running mean: 11.54107727516121\n",
      "resetting env. episode reward total was 13.0. running mean: 11.555666502409599\n",
      "resetting env. episode reward total was 17.0. running mean: 11.610109837385503\n",
      "resetting env. episode reward total was 10.0. running mean: 11.594008739011647\n",
      "resetting env. episode reward total was 9.0. running mean: 11.56806865162153\n",
      "resetting env. episode reward total was 14.0. running mean: 11.592387965105315\n",
      "resetting env. episode reward total was 13.0. running mean: 11.606464085454263\n",
      "resetting env. episode reward total was 13.0. running mean: 11.620399444599721\n",
      "resetting env. episode reward total was 16.0. running mean: 11.664195450153723\n",
      "resetting env. episode reward total was 16.0. running mean: 11.707553495652187\n",
      "resetting env. episode reward total was 18.0. running mean: 11.770477960695665\n",
      "resetting env. episode reward total was 8.0. running mean: 11.732773181088708\n",
      "resetting env. episode reward total was 11.0. running mean: 11.72544544927782\n",
      "resetting env. episode reward total was 5.0. running mean: 11.658190994785043\n",
      "resetting env. episode reward total was 15.0. running mean: 11.691609084837193\n",
      "resetting env. episode reward total was 10.0. running mean: 11.67469299398882\n",
      "resetting env. episode reward total was 9.0. running mean: 11.647946064048933\n",
      "resetting env. episode reward total was 14.0. running mean: 11.671466603408444\n",
      "resetting env. episode reward total was 14.0. running mean: 11.69475193737436\n",
      "resetting env. episode reward total was 14.0. running mean: 11.717804418000616\n",
      "resetting env. episode reward total was 12.0. running mean: 11.72062637382061\n",
      "resetting env. episode reward total was 8.0. running mean: 11.683420110082404\n",
      "resetting env. episode reward total was 13.0. running mean: 11.69658590898158\n",
      "resetting env. episode reward total was 8.0. running mean: 11.659620049891764\n",
      "resetting env. episode reward total was 11.0. running mean: 11.653023849392845\n",
      "resetting env. episode reward total was 12.0. running mean: 11.656493610898917\n",
      "resetting env. episode reward total was 9.0. running mean: 11.629928674789927\n",
      "resetting env. episode reward total was 6.0. running mean: 11.573629388042027\n",
      "resetting env. episode reward total was 16.0. running mean: 11.617893094161607\n",
      "resetting env. episode reward total was 14.0. running mean: 11.64171416321999\n",
      "resetting env. episode reward total was 9.0. running mean: 11.615297021587791\n",
      "resetting env. episode reward total was 17.0. running mean: 11.669144051371912\n",
      "resetting env. episode reward total was 10.0. running mean: 11.652452610858193\n",
      "resetting env. episode reward total was 15.0. running mean: 11.68592808474961\n",
      "resetting env. episode reward total was 18.0. running mean: 11.749068803902114\n",
      "resetting env. episode reward total was 18.0. running mean: 11.811578115863092\n",
      "resetting env. episode reward total was 2.0. running mean: 11.713462334704461\n",
      "resetting env. episode reward total was 11.0. running mean: 11.706327711357416\n",
      "resetting env. episode reward total was 11.0. running mean: 11.69926443424384\n",
      "resetting env. episode reward total was 19.0. running mean: 11.772271789901401\n",
      "resetting env. episode reward total was 9.0. running mean: 11.744549072002387\n",
      "resetting env. episode reward total was 13.0. running mean: 11.757103581282363\n",
      "resetting env. episode reward total was 6.0. running mean: 11.69953254546954\n",
      "resetting env. episode reward total was 9.0. running mean: 11.672537220014844\n",
      "resetting env. episode reward total was 15.0. running mean: 11.705811847814696\n",
      "resetting env. episode reward total was 9.0. running mean: 11.678753729336549\n",
      "resetting env. episode reward total was 8.0. running mean: 11.641966192043183\n",
      "resetting env. episode reward total was 10.0. running mean: 11.625546530122751\n",
      "resetting env. episode reward total was 9.0. running mean: 11.599291064821523\n",
      "resetting env. episode reward total was 13.0. running mean: 11.61329815417331\n",
      "resetting env. episode reward total was 10.0. running mean: 11.597165172631575\n",
      "resetting env. episode reward total was 11.0. running mean: 11.591193520905259\n",
      "resetting env. episode reward total was 16.0. running mean: 11.635281585696207\n",
      "resetting env. episode reward total was 13.0. running mean: 11.648928769839246\n",
      "resetting env. episode reward total was 7.0. running mean: 11.602439482140854\n",
      "resetting env. episode reward total was 6.0. running mean: 11.546415087319446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 11.55095093644625\n",
      "resetting env. episode reward total was 11.0. running mean: 11.545441427081787\n",
      "resetting env. episode reward total was 13.0. running mean: 11.55998701281097\n",
      "resetting env. episode reward total was 9.0. running mean: 11.53438714268286\n",
      "resetting env. episode reward total was 4.0. running mean: 11.45904327125603\n",
      "resetting env. episode reward total was 14.0. running mean: 11.48445283854347\n",
      "resetting env. episode reward total was 9.0. running mean: 11.459608310158035\n",
      "resetting env. episode reward total was 13.0. running mean: 11.475012227056455\n",
      "resetting env. episode reward total was 10.0. running mean: 11.46026210478589\n",
      "resetting env. episode reward total was 6.0. running mean: 11.405659483738033\n",
      "resetting env. episode reward total was 14.0. running mean: 11.431602888900652\n",
      "resetting env. episode reward total was 9.0. running mean: 11.407286860011645\n",
      "resetting env. episode reward total was 13.0. running mean: 11.42321399141153\n",
      "resetting env. episode reward total was 15.0. running mean: 11.458981851497414\n",
      "resetting env. episode reward total was 10.0. running mean: 11.44439203298244\n",
      "resetting env. episode reward total was 18.0. running mean: 11.509948112652616\n",
      "resetting env. episode reward total was 10.0. running mean: 11.49484863152609\n",
      "resetting env. episode reward total was 10.0. running mean: 11.479900145210829\n",
      "resetting env. episode reward total was 8.0. running mean: 11.44510114375872\n",
      "resetting env. episode reward total was 8.0. running mean: 11.410650132321132\n",
      "resetting env. episode reward total was 1.0. running mean: 11.30654363099792\n",
      "resetting env. episode reward total was 12.0. running mean: 11.31347819468794\n",
      "resetting env. episode reward total was 6.0. running mean: 11.260343412741062\n",
      "resetting env. episode reward total was 7.0. running mean: 11.21773997861365\n",
      "resetting env. episode reward total was 10.0. running mean: 11.205562578827514\n",
      "resetting env. episode reward total was 17.0. running mean: 11.263506953039238\n",
      "resetting env. episode reward total was 12.0. running mean: 11.270871883508844\n",
      "resetting env. episode reward total was 16.0. running mean: 11.318163164673756\n",
      "resetting env. episode reward total was 14.0. running mean: 11.344981533027019\n",
      "resetting env. episode reward total was 8.0. running mean: 11.311531717696749\n",
      "resetting env. episode reward total was 14.0. running mean: 11.338416400519781\n",
      "resetting env. episode reward total was 11.0. running mean: 11.335032236514582\n",
      "resetting env. episode reward total was 6.0. running mean: 11.281681914149436\n",
      "resetting env. episode reward total was 9.0. running mean: 11.258865095007941\n",
      "resetting env. episode reward total was 7.0. running mean: 11.216276444057861\n",
      "resetting env. episode reward total was 7.0. running mean: 11.174113679617284\n",
      "resetting env. episode reward total was 8.0. running mean: 11.14237254282111\n",
      "resetting env. episode reward total was 10.0. running mean: 11.130948817392898\n",
      "resetting env. episode reward total was 12.0. running mean: 11.13963932921897\n",
      "resetting env. episode reward total was 15.0. running mean: 11.17824293592678\n",
      "resetting env. episode reward total was 16.0. running mean: 11.226460506567513\n",
      "resetting env. episode reward total was 10.0. running mean: 11.214195901501837\n",
      "resetting env. episode reward total was 16.0. running mean: 11.26205394248682\n",
      "resetting env. episode reward total was 12.0. running mean: 11.26943340306195\n",
      "resetting env. episode reward total was 12.0. running mean: 11.27673906903133\n",
      "resetting env. episode reward total was 9.0. running mean: 11.253971678341015\n",
      "resetting env. episode reward total was 15.0. running mean: 11.291431961557606\n",
      "resetting env. episode reward total was 18.0. running mean: 11.35851764194203\n",
      "resetting env. episode reward total was 16.0. running mean: 11.40493246552261\n",
      "resetting env. episode reward total was 11.0. running mean: 11.400883140867382\n",
      "resetting env. episode reward total was 9.0. running mean: 11.376874309458708\n",
      "resetting env. episode reward total was 3.0. running mean: 11.29310556636412\n",
      "resetting env. episode reward total was 11.0. running mean: 11.29017451070048\n",
      "resetting env. episode reward total was 9.0. running mean: 11.267272765593475\n",
      "resetting env. episode reward total was 15.0. running mean: 11.30460003793754\n",
      "resetting env. episode reward total was 12.0. running mean: 11.311554037558164\n",
      "resetting env. episode reward total was 11.0. running mean: 11.308438497182582\n",
      "resetting env. episode reward total was -2.0. running mean: 11.175354112210757\n",
      "resetting env. episode reward total was 12.0. running mean: 11.183600571088649\n",
      "resetting env. episode reward total was 17.0. running mean: 11.241764565377762\n",
      "resetting env. episode reward total was 17.0. running mean: 11.299346919723984\n",
      "resetting env. episode reward total was 13.0. running mean: 11.316353450526744\n",
      "resetting env. episode reward total was 12.0. running mean: 11.323189916021477\n",
      "resetting env. episode reward total was 13.0. running mean: 11.339958016861262\n",
      "resetting env. episode reward total was 15.0. running mean: 11.37655843669265\n",
      "resetting env. episode reward total was 10.0. running mean: 11.362792852325722\n",
      "resetting env. episode reward total was 8.0. running mean: 11.329164923802464\n",
      "resetting env. episode reward total was 12.0. running mean: 11.335873274564438\n",
      "resetting env. episode reward total was 11.0. running mean: 11.332514541818792\n",
      "resetting env. episode reward total was 12.0. running mean: 11.339189396400604\n",
      "resetting env. episode reward total was 14.0. running mean: 11.365797502436598\n",
      "resetting env. episode reward total was 12.0. running mean: 11.37213952741223\n",
      "resetting env. episode reward total was 13.0. running mean: 11.388418132138108\n",
      "resetting env. episode reward total was 11.0. running mean: 11.384533950816726\n",
      "resetting env. episode reward total was 15.0. running mean: 11.42068861130856\n",
      "resetting env. episode reward total was 9.0. running mean: 11.396481725195473\n",
      "resetting env. episode reward total was 9.0. running mean: 11.372516907943519\n",
      "resetting env. episode reward total was 13.0. running mean: 11.388791738864084\n",
      "resetting env. episode reward total was 15.0. running mean: 11.424903821475443\n",
      "resetting env. episode reward total was 8.0. running mean: 11.390654783260688\n",
      "resetting env. episode reward total was -3.0. running mean: 11.24674823542808\n",
      "resetting env. episode reward total was 17.0. running mean: 11.3042807530738\n",
      "resetting env. episode reward total was 6.0. running mean: 11.251237945543062\n",
      "resetting env. episode reward total was 9.0. running mean: 11.22872556608763\n",
      "resetting env. episode reward total was 10.0. running mean: 11.216438310426755\n",
      "resetting env. episode reward total was 12.0. running mean: 11.224273927322486\n",
      "resetting env. episode reward total was 13.0. running mean: 11.242031188049262\n",
      "resetting env. episode reward total was 12.0. running mean: 11.249610876168768\n",
      "resetting env. episode reward total was 13.0. running mean: 11.267114767407081\n",
      "resetting env. episode reward total was 12.0. running mean: 11.27444361973301\n",
      "resetting env. episode reward total was 8.0. running mean: 11.24169918353568\n",
      "resetting env. episode reward total was 15.0. running mean: 11.279282191700323\n",
      "resetting env. episode reward total was 6.0. running mean: 11.226489369783321\n",
      "resetting env. episode reward total was 9.0. running mean: 11.204224476085487\n",
      "resetting env. episode reward total was 10.0. running mean: 11.192182231324631\n",
      "resetting env. episode reward total was 9.0. running mean: 11.170260409011386\n",
      "resetting env. episode reward total was 11.0. running mean: 11.16855780492127\n",
      "resetting env. episode reward total was 18.0. running mean: 11.236872226872057\n",
      "resetting env. episode reward total was 7.0. running mean: 11.194503504603336\n",
      "resetting env. episode reward total was 18.0. running mean: 11.262558469557302\n",
      "resetting env. episode reward total was 9.0. running mean: 11.239932884861728\n",
      "resetting env. episode reward total was 14.0. running mean: 11.267533556013111\n",
      "resetting env. episode reward total was 5.0. running mean: 11.20485822045298\n",
      "resetting env. episode reward total was 14.0. running mean: 11.232809638248451\n",
      "resetting env. episode reward total was 6.0. running mean: 11.180481541865968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 11.128676726447308\n",
      "resetting env. episode reward total was 17.0. running mean: 11.187389959182834\n",
      "resetting env. episode reward total was 15.0. running mean: 11.225516059591007\n",
      "resetting env. episode reward total was 15.0. running mean: 11.263260898995096\n",
      "resetting env. episode reward total was 10.0. running mean: 11.250628290005144\n",
      "resetting env. episode reward total was 16.0. running mean: 11.298122007105093\n",
      "resetting env. episode reward total was 5.0. running mean: 11.235140787034043\n",
      "resetting env. episode reward total was 8.0. running mean: 11.202789379163702\n",
      "resetting env. episode reward total was 13.0. running mean: 11.220761485372066\n",
      "resetting env. episode reward total was 10.0. running mean: 11.208553870518344\n",
      "resetting env. episode reward total was 15.0. running mean: 11.24646833181316\n",
      "resetting env. episode reward total was 14.0. running mean: 11.274003648495029\n",
      "resetting env. episode reward total was 13.0. running mean: 11.291263612010079\n",
      "resetting env. episode reward total was 6.0. running mean: 11.238350975889979\n",
      "resetting env. episode reward total was 17.0. running mean: 11.29596746613108\n",
      "resetting env. episode reward total was 11.0. running mean: 11.293007791469767\n",
      "resetting env. episode reward total was 8.0. running mean: 11.26007771355507\n",
      "resetting env. episode reward total was 8.0. running mean: 11.227476936419519\n",
      "resetting env. episode reward total was 14.0. running mean: 11.255202167055325\n",
      "resetting env. episode reward total was 13.0. running mean: 11.272650145384771\n",
      "resetting env. episode reward total was 13.0. running mean: 11.289923643930925\n",
      "resetting env. episode reward total was 15.0. running mean: 11.327024407491615\n",
      "resetting env. episode reward total was 11.0. running mean: 11.323754163416698\n",
      "resetting env. episode reward total was 11.0. running mean: 11.32051662178253\n",
      "resetting env. episode reward total was 13.0. running mean: 11.337311455564706\n",
      "resetting env. episode reward total was 7.0. running mean: 11.293938341009058\n",
      "resetting env. episode reward total was 15.0. running mean: 11.330998957598968\n",
      "resetting env. episode reward total was 12.0. running mean: 11.337688968022977\n",
      "resetting env. episode reward total was 12.0. running mean: 11.344312078342746\n",
      "resetting env. episode reward total was 13.0. running mean: 11.360868957559319\n",
      "resetting env. episode reward total was 17.0. running mean: 11.417260267983725\n",
      "resetting env. episode reward total was 13.0. running mean: 11.433087665303889\n",
      "resetting env. episode reward total was 6.0. running mean: 11.37875678865085\n",
      "resetting env. episode reward total was 15.0. running mean: 11.414969220764343\n",
      "resetting env. episode reward total was 13.0. running mean: 11.4308195285567\n",
      "resetting env. episode reward total was 12.0. running mean: 11.436511333271133\n",
      "resetting env. episode reward total was 9.0. running mean: 11.412146219938421\n",
      "resetting env. episode reward total was 15.0. running mean: 11.448024757739038\n",
      "resetting env. episode reward total was 17.0. running mean: 11.503544510161648\n",
      "resetting env. episode reward total was 15.0. running mean: 11.538509065060031\n",
      "resetting env. episode reward total was 12.0. running mean: 11.543123974409431\n",
      "resetting env. episode reward total was 17.0. running mean: 11.597692734665337\n",
      "resetting env. episode reward total was 13.0. running mean: 11.611715807318685\n",
      "resetting env. episode reward total was 13.0. running mean: 11.625598649245498\n",
      "resetting env. episode reward total was 12.0. running mean: 11.629342662753043\n",
      "resetting env. episode reward total was 14.0. running mean: 11.653049236125513\n",
      "resetting env. episode reward total was 14.0. running mean: 11.676518743764259\n",
      "resetting env. episode reward total was 10.0. running mean: 11.659753556326615\n",
      "resetting env. episode reward total was 10.0. running mean: 11.643156020763348\n",
      "resetting env. episode reward total was 18.0. running mean: 11.706724460555714\n",
      "resetting env. episode reward total was 9.0. running mean: 11.679657215950156\n",
      "resetting env. episode reward total was 16.0. running mean: 11.722860643790655\n",
      "resetting env. episode reward total was 14.0. running mean: 11.745632037352749\n",
      "resetting env. episode reward total was 6.0. running mean: 11.688175716979222\n",
      "resetting env. episode reward total was 13.0. running mean: 11.70129395980943\n",
      "resetting env. episode reward total was 12.0. running mean: 11.704281020211335\n",
      "resetting env. episode reward total was 15.0. running mean: 11.737238210009222\n",
      "resetting env. episode reward total was 14.0. running mean: 11.759865827909131\n",
      "resetting env. episode reward total was 12.0. running mean: 11.76226716963004\n",
      "resetting env. episode reward total was 1.0. running mean: 11.654644497933738\n",
      "resetting env. episode reward total was 15.0. running mean: 11.6880980529544\n",
      "resetting env. episode reward total was 14.0. running mean: 11.711217072424857\n",
      "resetting env. episode reward total was 13.0. running mean: 11.724104901700608\n",
      "resetting env. episode reward total was 5.0. running mean: 11.656863852683603\n",
      "resetting env. episode reward total was 7.0. running mean: 11.610295214156768\n",
      "resetting env. episode reward total was 4.0. running mean: 11.5341922620152\n",
      "resetting env. episode reward total was 7.0. running mean: 11.488850339395048\n",
      "resetting env. episode reward total was 6.0. running mean: 11.433961836001098\n",
      "resetting env. episode reward total was 15.0. running mean: 11.469622217641087\n",
      "resetting env. episode reward total was 17.0. running mean: 11.524925995464676\n",
      "resetting env. episode reward total was 18.0. running mean: 11.589676735510029\n",
      "resetting env. episode reward total was 2.0. running mean: 11.493779968154929\n",
      "resetting env. episode reward total was 2.0. running mean: 11.39884216847338\n",
      "resetting env. episode reward total was 9.0. running mean: 11.374853746788645\n",
      "resetting env. episode reward total was 12.0. running mean: 11.381105209320758\n",
      "resetting env. episode reward total was 17.0. running mean: 11.43729415722755\n",
      "resetting env. episode reward total was 10.0. running mean: 11.422921215655274\n",
      "resetting env. episode reward total was 12.0. running mean: 11.42869200349872\n",
      "resetting env. episode reward total was 14.0. running mean: 11.454405083463733\n",
      "resetting env. episode reward total was 11.0. running mean: 11.449861032629094\n",
      "resetting env. episode reward total was 16.0. running mean: 11.495362422302804\n",
      "resetting env. episode reward total was 2.0. running mean: 11.400408798079775\n",
      "resetting env. episode reward total was 14.0. running mean: 11.426404710098979\n",
      "resetting env. episode reward total was 14.0. running mean: 11.452140662997989\n",
      "resetting env. episode reward total was 14.0. running mean: 11.47761925636801\n",
      "resetting env. episode reward total was 13.0. running mean: 11.492843063804331\n",
      "resetting env. episode reward total was 12.0. running mean: 11.497914633166287\n",
      "resetting env. episode reward total was 12.0. running mean: 11.502935486834623\n",
      "resetting env. episode reward total was 12.0. running mean: 11.507906131966276\n",
      "resetting env. episode reward total was 8.0. running mean: 11.472827070646613\n",
      "resetting env. episode reward total was 13.0. running mean: 11.488098799940147\n",
      "resetting env. episode reward total was 12.0. running mean: 11.493217811940745\n",
      "resetting env. episode reward total was 14.0. running mean: 11.518285633821339\n",
      "resetting env. episode reward total was 14.0. running mean: 11.543102777483126\n",
      "resetting env. episode reward total was 17.0. running mean: 11.597671749708296\n",
      "resetting env. episode reward total was 11.0. running mean: 11.591695032211211\n",
      "resetting env. episode reward total was 14.0. running mean: 11.615778081889099\n",
      "resetting env. episode reward total was 13.0. running mean: 11.629620301070208\n",
      "resetting env. episode reward total was 2.0. running mean: 11.533324098059506\n",
      "resetting env. episode reward total was 8.0. running mean: 11.49799085707891\n",
      "resetting env. episode reward total was 14.0. running mean: 11.523010948508123\n",
      "resetting env. episode reward total was 2.0. running mean: 11.427780839023042\n",
      "resetting env. episode reward total was 16.0. running mean: 11.473503030632811\n",
      "resetting env. episode reward total was 11.0. running mean: 11.468768000326483\n",
      "resetting env. episode reward total was 11.0. running mean: 11.464080320323218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 11.499439517119987\n",
      "resetting env. episode reward total was 11.0. running mean: 11.494445121948786\n",
      "resetting env. episode reward total was 8.0. running mean: 11.459500670729298\n",
      "resetting env. episode reward total was 13.0. running mean: 11.474905664022005\n",
      "resetting env. episode reward total was 10.0. running mean: 11.460156607381785\n",
      "resetting env. episode reward total was 15.0. running mean: 11.495555041307968\n",
      "resetting env. episode reward total was 16.0. running mean: 11.540599490894888\n",
      "resetting env. episode reward total was 17.0. running mean: 11.595193495985939\n",
      "resetting env. episode reward total was 1.0. running mean: 11.489241561026079\n",
      "resetting env. episode reward total was -1.0. running mean: 11.364349145415819\n",
      "resetting env. episode reward total was 11.0. running mean: 11.36070565396166\n",
      "resetting env. episode reward total was 9.0. running mean: 11.337098597422042\n",
      "resetting env. episode reward total was 4.0. running mean: 11.26372761144782\n",
      "resetting env. episode reward total was 15.0. running mean: 11.301090335333342\n",
      "resetting env. episode reward total was 7.0. running mean: 11.25807943198001\n",
      "resetting env. episode reward total was 8.0. running mean: 11.225498637660209\n",
      "resetting env. episode reward total was 14.0. running mean: 11.253243651283608\n",
      "resetting env. episode reward total was 17.0. running mean: 11.310711214770771\n",
      "resetting env. episode reward total was 12.0. running mean: 11.317604102623063\n",
      "resetting env. episode reward total was 6.0. running mean: 11.264428061596833\n",
      "resetting env. episode reward total was 16.0. running mean: 11.311783780980864\n",
      "resetting env. episode reward total was 16.0. running mean: 11.358665943171056\n",
      "resetting env. episode reward total was 16.0. running mean: 11.405079283739346\n",
      "resetting env. episode reward total was 15.0. running mean: 11.441028490901953\n",
      "resetting env. episode reward total was 13.0. running mean: 11.456618205992934\n",
      "resetting env. episode reward total was 6.0. running mean: 11.402052023933004\n",
      "resetting env. episode reward total was 9.0. running mean: 11.378031503693673\n",
      "resetting env. episode reward total was 14.0. running mean: 11.404251188656737\n",
      "resetting env. episode reward total was 6.0. running mean: 11.350208676770169\n",
      "resetting env. episode reward total was 13.0. running mean: 11.366706590002469\n",
      "resetting env. episode reward total was 13.0. running mean: 11.383039524102445\n",
      "resetting env. episode reward total was 13.0. running mean: 11.399209128861422\n",
      "resetting env. episode reward total was 16.0. running mean: 11.445217037572808\n",
      "resetting env. episode reward total was 16.0. running mean: 11.49076486719708\n",
      "resetting env. episode reward total was 13.0. running mean: 11.50585721852511\n",
      "resetting env. episode reward total was 8.0. running mean: 11.470798646339858\n",
      "resetting env. episode reward total was 15.0. running mean: 11.50609065987646\n",
      "resetting env. episode reward total was 8.0. running mean: 11.471029753277694\n",
      "resetting env. episode reward total was 16.0. running mean: 11.516319455744917\n",
      "resetting env. episode reward total was 14.0. running mean: 11.541156261187467\n",
      "resetting env. episode reward total was 9.0. running mean: 11.515744698575592\n",
      "resetting env. episode reward total was 12.0. running mean: 11.520587251589834\n",
      "resetting env. episode reward total was 10.0. running mean: 11.505381379073935\n",
      "resetting env. episode reward total was 9.0. running mean: 11.480327565283195\n",
      "resetting env. episode reward total was 13.0. running mean: 11.495524289630364\n",
      "resetting env. episode reward total was 6.0. running mean: 11.44056904673406\n",
      "resetting env. episode reward total was 18.0. running mean: 11.50616335626672\n",
      "resetting env. episode reward total was 10.0. running mean: 11.491101722704052\n",
      "resetting env. episode reward total was 8.0. running mean: 11.456190705477011\n",
      "resetting env. episode reward total was 11.0. running mean: 11.45162879842224\n",
      "resetting env. episode reward total was 11.0. running mean: 11.447112510438016\n",
      "resetting env. episode reward total was 6.0. running mean: 11.392641385333636\n",
      "resetting env. episode reward total was 15.0. running mean: 11.4287149714803\n",
      "resetting env. episode reward total was 14.0. running mean: 11.454427821765497\n",
      "resetting env. episode reward total was -1.0. running mean: 11.329883543547842\n",
      "resetting env. episode reward total was 18.0. running mean: 11.396584708112362\n",
      "resetting env. episode reward total was 18.0. running mean: 11.462618861031238\n",
      "resetting env. episode reward total was 13.0. running mean: 11.477992672420926\n",
      "resetting env. episode reward total was 13.0. running mean: 11.493212745696718\n",
      "resetting env. episode reward total was 12.0. running mean: 11.49828061823975\n",
      "resetting env. episode reward total was 11.0. running mean: 11.493297812057353\n",
      "resetting env. episode reward total was 7.0. running mean: 11.448364833936779\n",
      "resetting env. episode reward total was 8.0. running mean: 11.413881185597411\n",
      "resetting env. episode reward total was 5.0. running mean: 11.349742373741437\n",
      "resetting env. episode reward total was 13.0. running mean: 11.366244950004024\n",
      "resetting env. episode reward total was 14.0. running mean: 11.392582500503984\n",
      "resetting env. episode reward total was 11.0. running mean: 11.388656675498943\n",
      "resetting env. episode reward total was 12.0. running mean: 11.394770108743954\n",
      "resetting env. episode reward total was -1.0. running mean: 11.270822407656514\n",
      "resetting env. episode reward total was 17.0. running mean: 11.328114183579949\n",
      "resetting env. episode reward total was 10.0. running mean: 11.31483304174415\n",
      "resetting env. episode reward total was 3.0. running mean: 11.231684711326707\n",
      "resetting env. episode reward total was 11.0. running mean: 11.22936786421344\n",
      "resetting env. episode reward total was 17.0. running mean: 11.287074185571306\n",
      "resetting env. episode reward total was 9.0. running mean: 11.264203443715592\n",
      "resetting env. episode reward total was 10.0. running mean: 11.251561409278436\n",
      "resetting env. episode reward total was 13.0. running mean: 11.269045795185653\n",
      "resetting env. episode reward total was 7.0. running mean: 11.226355337233796\n",
      "resetting env. episode reward total was 10.0. running mean: 11.214091783861457\n",
      "resetting env. episode reward total was 10.0. running mean: 11.201950866022843\n",
      "resetting env. episode reward total was 14.0. running mean: 11.229931357362615\n",
      "resetting env. episode reward total was 1.0. running mean: 11.127632043788989\n",
      "resetting env. episode reward total was 14.0. running mean: 11.1563557233511\n",
      "resetting env. episode reward total was 16.0. running mean: 11.204792166117588\n",
      "resetting env. episode reward total was 13.0. running mean: 11.222744244456413\n",
      "resetting env. episode reward total was 11.0. running mean: 11.220516802011849\n",
      "resetting env. episode reward total was 15.0. running mean: 11.258311633991731\n",
      "resetting env. episode reward total was 13.0. running mean: 11.275728517651814\n",
      "resetting env. episode reward total was 11.0. running mean: 11.272971232475294\n",
      "resetting env. episode reward total was 19.0. running mean: 11.35024152015054\n",
      "resetting env. episode reward total was 12.0. running mean: 11.356739104949034\n",
      "resetting env. episode reward total was 10.0. running mean: 11.343171713899542\n",
      "resetting env. episode reward total was 12.0. running mean: 11.349739996760546\n",
      "resetting env. episode reward total was 17.0. running mean: 11.40624259679294\n",
      "resetting env. episode reward total was 12.0. running mean: 11.412180170825009\n",
      "resetting env. episode reward total was 7.0. running mean: 11.368058369116758\n",
      "resetting env. episode reward total was 18.0. running mean: 11.43437778542559\n",
      "resetting env. episode reward total was 14.0. running mean: 11.460034007571336\n",
      "resetting env. episode reward total was 15.0. running mean: 11.495433667495623\n",
      "resetting env. episode reward total was 10.0. running mean: 11.480479330820668\n",
      "resetting env. episode reward total was 20.0. running mean: 11.56567453751246\n",
      "resetting env. episode reward total was 14.0. running mean: 11.590017792137337\n",
      "resetting env. episode reward total was 9.0. running mean: 11.564117614215963\n",
      "resetting env. episode reward total was 17.0. running mean: 11.618476438073802\n",
      "resetting env. episode reward total was 12.0. running mean: 11.622291673693063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 11.596068756956132\n",
      "resetting env. episode reward total was 14.0. running mean: 11.620108069386571\n",
      "resetting env. episode reward total was 11.0. running mean: 11.613906988692705\n",
      "resetting env. episode reward total was 12.0. running mean: 11.617767918805777\n",
      "resetting env. episode reward total was 16.0. running mean: 11.66159023961772\n",
      "resetting env. episode reward total was 12.0. running mean: 11.664974337221542\n",
      "resetting env. episode reward total was 12.0. running mean: 11.668324593849325\n",
      "resetting env. episode reward total was 16.0. running mean: 11.711641347910833\n",
      "resetting env. episode reward total was 15.0. running mean: 11.744524934431725\n",
      "resetting env. episode reward total was 10.0. running mean: 11.727079685087407\n",
      "resetting env. episode reward total was 7.0. running mean: 11.679808888236533\n",
      "resetting env. episode reward total was 14.0. running mean: 11.703010799354168\n",
      "resetting env. episode reward total was 14.0. running mean: 11.725980691360627\n",
      "resetting env. episode reward total was 16.0. running mean: 11.76872088444702\n",
      "resetting env. episode reward total was 8.0. running mean: 11.73103367560255\n",
      "resetting env. episode reward total was 13.0. running mean: 11.743723338846525\n",
      "resetting env. episode reward total was 20.0. running mean: 11.82628610545806\n",
      "resetting env. episode reward total was 6.0. running mean: 11.76802324440348\n",
      "resetting env. episode reward total was 4.0. running mean: 11.690343011959444\n",
      "resetting env. episode reward total was 13.0. running mean: 11.70343958183985\n",
      "resetting env. episode reward total was 12.0. running mean: 11.70640518602145\n",
      "resetting env. episode reward total was 10.0. running mean: 11.689341134161236\n",
      "resetting env. episode reward total was 20.0. running mean: 11.772447722819622\n",
      "resetting env. episode reward total was 16.0. running mean: 11.814723245591427\n",
      "resetting env. episode reward total was 17.0. running mean: 11.866576013135512\n",
      "resetting env. episode reward total was 7.0. running mean: 11.817910253004158\n",
      "resetting env. episode reward total was 13.0. running mean: 11.829731150474117\n",
      "resetting env. episode reward total was 8.0. running mean: 11.791433838969375\n",
      "resetting env. episode reward total was 21.0. running mean: 11.883519500579682\n",
      "resetting env. episode reward total was 13.0. running mean: 11.894684305573886\n",
      "resetting env. episode reward total was 18.0. running mean: 11.955737462518147\n",
      "resetting env. episode reward total was 6.0. running mean: 11.896180087892967\n",
      "resetting env. episode reward total was 2.0. running mean: 11.797218287014037\n",
      "resetting env. episode reward total was 9.0. running mean: 11.769246104143896\n",
      "resetting env. episode reward total was 16.0. running mean: 11.811553643102457\n",
      "resetting env. episode reward total was 15.0. running mean: 11.843438106671432\n",
      "resetting env. episode reward total was 17.0. running mean: 11.895003725604717\n",
      "resetting env. episode reward total was 8.0. running mean: 11.85605368834867\n",
      "resetting env. episode reward total was 6.0. running mean: 11.797493151465183\n",
      "resetting env. episode reward total was 13.0. running mean: 11.809518219950531\n",
      "resetting env. episode reward total was 16.0. running mean: 11.851423037751026\n",
      "resetting env. episode reward total was 13.0. running mean: 11.862908807373516\n",
      "resetting env. episode reward total was 19.0. running mean: 11.93427971929978\n",
      "resetting env. episode reward total was 13.0. running mean: 11.944936922106784\n",
      "resetting env. episode reward total was 14.0. running mean: 11.965487552885717\n",
      "resetting env. episode reward total was 9.0. running mean: 11.93583267735686\n",
      "resetting env. episode reward total was 7.0. running mean: 11.886474350583292\n",
      "resetting env. episode reward total was 17.0. running mean: 11.937609607077459\n",
      "resetting env. episode reward total was 9.0. running mean: 11.908233511006683\n",
      "resetting env. episode reward total was 15.0. running mean: 11.939151175896617\n",
      "resetting env. episode reward total was 13.0. running mean: 11.949759664137652\n",
      "resetting env. episode reward total was 8.0. running mean: 11.910262067496275\n",
      "resetting env. episode reward total was 12.0. running mean: 11.91115944682131\n",
      "resetting env. episode reward total was 15.0. running mean: 11.942047852353097\n",
      "resetting env. episode reward total was 10.0. running mean: 11.922627373829565\n",
      "resetting env. episode reward total was 16.0. running mean: 11.96340110009127\n",
      "resetting env. episode reward total was 13.0. running mean: 11.973767089090357\n",
      "resetting env. episode reward total was 8.0. running mean: 11.934029418199453\n",
      "resetting env. episode reward total was 15.0. running mean: 11.964689124017458\n",
      "resetting env. episode reward total was 7.0. running mean: 11.915042232777283\n",
      "resetting env. episode reward total was 15.0. running mean: 11.945891810449512\n",
      "resetting env. episode reward total was 18.0. running mean: 12.006432892345016\n",
      "resetting env. episode reward total was 15.0. running mean: 12.036368563421567\n",
      "resetting env. episode reward total was 12.0. running mean: 12.03600487778735\n",
      "resetting env. episode reward total was 11.0. running mean: 12.025644829009476\n",
      "resetting env. episode reward total was 12.0. running mean: 12.02538838071938\n",
      "resetting env. episode reward total was 7.0. running mean: 11.975134496912187\n",
      "resetting env. episode reward total was 17.0. running mean: 12.025383151943064\n",
      "resetting env. episode reward total was 11.0. running mean: 12.015129320423632\n",
      "resetting env. episode reward total was 13.0. running mean: 12.024978027219397\n",
      "resetting env. episode reward total was 11.0. running mean: 12.014728246947202\n",
      "resetting env. episode reward total was 5.0. running mean: 11.94458096447773\n",
      "resetting env. episode reward total was 13.0. running mean: 11.955135154832954\n",
      "resetting env. episode reward total was 17.0. running mean: 12.005583803284624\n",
      "resetting env. episode reward total was 13.0. running mean: 12.01552796525178\n",
      "resetting env. episode reward total was 6.0. running mean: 11.955372685599261\n",
      "resetting env. episode reward total was 15.0. running mean: 11.98581895874327\n",
      "resetting env. episode reward total was 5.0. running mean: 11.915960769155838\n",
      "resetting env. episode reward total was 20.0. running mean: 11.996801161464278\n",
      "resetting env. episode reward total was 21.0. running mean: 12.086833149849635\n",
      "resetting env. episode reward total was 3.0. running mean: 11.995964818351139\n",
      "resetting env. episode reward total was 12.0. running mean: 11.996005170167626\n",
      "resetting env. episode reward total was 9.0. running mean: 11.96604511846595\n",
      "resetting env. episode reward total was 8.0. running mean: 11.92638466728129\n",
      "resetting env. episode reward total was 12.0. running mean: 11.927120820608476\n",
      "resetting env. episode reward total was 9.0. running mean: 11.897849612402391\n",
      "resetting env. episode reward total was 13.0. running mean: 11.908871116278368\n",
      "resetting env. episode reward total was 6.0. running mean: 11.849782405115585\n",
      "resetting env. episode reward total was 15.0. running mean: 11.88128458106443\n",
      "resetting env. episode reward total was 13.0. running mean: 11.892471735253785\n",
      "resetting env. episode reward total was 15.0. running mean: 11.923547017901248\n",
      "resetting env. episode reward total was 15.0. running mean: 11.954311547722236\n",
      "resetting env. episode reward total was 13.0. running mean: 11.964768432245014\n",
      "resetting env. episode reward total was 11.0. running mean: 11.955120747922564\n",
      "resetting env. episode reward total was 14.0. running mean: 11.975569540443338\n",
      "resetting env. episode reward total was 13.0. running mean: 11.985813845038905\n",
      "resetting env. episode reward total was 4.0. running mean: 11.905955706588514\n",
      "resetting env. episode reward total was 6.0. running mean: 11.84689614952263\n",
      "resetting env. episode reward total was 15.0. running mean: 11.878427188027404\n",
      "resetting env. episode reward total was 11.0. running mean: 11.869642916147129\n",
      "resetting env. episode reward total was 16.0. running mean: 11.910946486985658\n",
      "resetting env. episode reward total was 12.0. running mean: 11.911837022115801\n",
      "resetting env. episode reward total was 14.0. running mean: 11.932718651894643\n",
      "resetting env. episode reward total was 13.0. running mean: 11.943391465375697\n",
      "resetting env. episode reward total was 13.0. running mean: 11.953957550721942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 17.0. running mean: 12.004417975214722\n",
      "resetting env. episode reward total was 13.0. running mean: 12.014373795462575\n",
      "resetting env. episode reward total was 10.0. running mean: 11.994230057507949\n",
      "resetting env. episode reward total was 9.0. running mean: 11.964287756932869\n",
      "resetting env. episode reward total was 15.0. running mean: 11.994644879363541\n",
      "resetting env. episode reward total was 18.0. running mean: 12.054698430569905\n",
      "resetting env. episode reward total was 6.0. running mean: 11.994151446264206\n",
      "resetting env. episode reward total was 6.0. running mean: 11.934209931801565\n",
      "resetting env. episode reward total was 8.0. running mean: 11.894867832483548\n",
      "resetting env. episode reward total was 12.0. running mean: 11.895919154158712\n",
      "resetting env. episode reward total was 12.0. running mean: 11.896959962617125\n",
      "resetting env. episode reward total was 14.0. running mean: 11.917990362990954\n",
      "resetting env. episode reward total was 6.0. running mean: 11.858810459361045\n",
      "resetting env. episode reward total was 14.0. running mean: 11.880222354767435\n",
      "resetting env. episode reward total was 13.0. running mean: 11.89142013121976\n",
      "resetting env. episode reward total was 10.0. running mean: 11.872505929907563\n",
      "resetting env. episode reward total was 15.0. running mean: 11.903780870608488\n",
      "resetting env. episode reward total was 19.0. running mean: 11.974743061902402\n",
      "resetting env. episode reward total was 8.0. running mean: 11.934995631283378\n",
      "resetting env. episode reward total was 6.0. running mean: 11.875645674970546\n",
      "resetting env. episode reward total was 14.0. running mean: 11.89688921822084\n",
      "resetting env. episode reward total was 16.0. running mean: 11.937920326038633\n",
      "resetting env. episode reward total was 15.0. running mean: 11.968541122778246\n",
      "resetting env. episode reward total was 13.0. running mean: 11.978855711550464\n",
      "resetting env. episode reward total was 7.0. running mean: 11.929067154434959\n",
      "resetting env. episode reward total was 15.0. running mean: 11.959776482890609\n",
      "resetting env. episode reward total was 14.0. running mean: 11.980178718061703\n",
      "resetting env. episode reward total was 4.0. running mean: 11.900376930881086\n",
      "resetting env. episode reward total was 7.0. running mean: 11.851373161572274\n",
      "resetting env. episode reward total was 18.0. running mean: 11.912859429956551\n",
      "resetting env. episode reward total was 12.0. running mean: 11.913730835656985\n",
      "resetting env. episode reward total was 13.0. running mean: 11.924593527300415\n",
      "resetting env. episode reward total was 12.0. running mean: 11.925347592027409\n",
      "resetting env. episode reward total was 16.0. running mean: 11.966094116107135\n",
      "resetting env. episode reward total was 14.0. running mean: 11.986433174946063\n",
      "resetting env. episode reward total was 13.0. running mean: 11.996568843196602\n",
      "resetting env. episode reward total was 12.0. running mean: 11.996603154764635\n",
      "resetting env. episode reward total was 15.0. running mean: 12.02663712321699\n",
      "resetting env. episode reward total was 12.0. running mean: 12.02637075198482\n",
      "resetting env. episode reward total was 10.0. running mean: 12.00610704446497\n",
      "resetting env. episode reward total was 11.0. running mean: 11.996045974020321\n",
      "resetting env. episode reward total was 3.0. running mean: 11.906085514280116\n",
      "resetting env. episode reward total was 10.0. running mean: 11.887024659137314\n",
      "resetting env. episode reward total was 6.0. running mean: 11.828154412545942\n",
      "resetting env. episode reward total was 11.0. running mean: 11.819872868420482\n",
      "resetting env. episode reward total was 11.0. running mean: 11.811674139736278\n",
      "resetting env. episode reward total was 13.0. running mean: 11.823557398338915\n",
      "resetting env. episode reward total was 14.0. running mean: 11.845321824355526\n",
      "resetting env. episode reward total was 9.0. running mean: 11.81686860611197\n",
      "resetting env. episode reward total was 16.0. running mean: 11.858699920050851\n",
      "resetting env. episode reward total was 7.0. running mean: 11.810112920850344\n",
      "resetting env. episode reward total was 10.0. running mean: 11.79201179164184\n",
      "resetting env. episode reward total was 9.0. running mean: 11.764091673725423\n",
      "resetting env. episode reward total was 4.0. running mean: 11.686450756988167\n",
      "resetting env. episode reward total was 15.0. running mean: 11.719586249418285\n",
      "resetting env. episode reward total was 16.0. running mean: 11.762390386924102\n",
      "resetting env. episode reward total was 15.0. running mean: 11.794766483054861\n",
      "resetting env. episode reward total was 9.0. running mean: 11.766818818224312\n",
      "resetting env. episode reward total was 3.0. running mean: 11.679150630042068\n",
      "resetting env. episode reward total was 8.0. running mean: 11.642359123741647\n",
      "resetting env. episode reward total was 8.0. running mean: 11.60593553250423\n",
      "resetting env. episode reward total was 8.0. running mean: 11.569876177179188\n",
      "resetting env. episode reward total was 19.0. running mean: 11.644177415407395\n",
      "resetting env. episode reward total was 10.0. running mean: 11.62773564125332\n",
      "resetting env. episode reward total was 16.0. running mean: 11.671458284840787\n",
      "resetting env. episode reward total was 12.0. running mean: 11.674743701992378\n",
      "resetting env. episode reward total was 7.0. running mean: 11.627996264972454\n",
      "resetting env. episode reward total was 10.0. running mean: 11.61171630232273\n",
      "resetting env. episode reward total was 8.0. running mean: 11.575599139299502\n",
      "resetting env. episode reward total was 12.0. running mean: 11.579843147906507\n",
      "resetting env. episode reward total was 7.0. running mean: 11.534044716427442\n",
      "resetting env. episode reward total was 19.0. running mean: 11.608704269263166\n",
      "resetting env. episode reward total was 13.0. running mean: 11.622617226570535\n",
      "resetting env. episode reward total was 15.0. running mean: 11.65639105430483\n",
      "resetting env. episode reward total was 16.0. running mean: 11.699827143761782\n",
      "resetting env. episode reward total was 17.0. running mean: 11.752828872324164\n",
      "resetting env. episode reward total was 12.0. running mean: 11.755300583600922\n",
      "resetting env. episode reward total was 12.0. running mean: 11.757747577764912\n",
      "resetting env. episode reward total was 13.0. running mean: 11.770170101987263\n",
      "resetting env. episode reward total was -2.0. running mean: 11.63246840096739\n",
      "resetting env. episode reward total was 11.0. running mean: 11.626143716957715\n",
      "resetting env. episode reward total was 16.0. running mean: 11.669882279788139\n",
      "resetting env. episode reward total was 14.0. running mean: 11.693183456990258\n",
      "resetting env. episode reward total was 11.0. running mean: 11.686251622420356\n",
      "resetting env. episode reward total was 14.0. running mean: 11.709389106196152\n",
      "resetting env. episode reward total was 14.0. running mean: 11.732295215134192\n",
      "resetting env. episode reward total was 8.0. running mean: 11.69497226298285\n",
      "resetting env. episode reward total was 8.0. running mean: 11.658022540353022\n",
      "resetting env. episode reward total was 8.0. running mean: 11.621442314949492\n",
      "resetting env. episode reward total was 9.0. running mean: 11.595227891799997\n",
      "resetting env. episode reward total was 9.0. running mean: 11.569275612881997\n",
      "resetting env. episode reward total was 10.0. running mean: 11.553582856753177\n",
      "resetting env. episode reward total was 15.0. running mean: 11.588047028185645\n",
      "resetting env. episode reward total was 17.0. running mean: 11.642166557903789\n",
      "resetting env. episode reward total was -3.0. running mean: 11.495744892324751\n",
      "resetting env. episode reward total was 4.0. running mean: 11.420787443401503\n",
      "resetting env. episode reward total was 2.0. running mean: 11.326579568967487\n",
      "resetting env. episode reward total was 12.0. running mean: 11.333313773277812\n",
      "resetting env. episode reward total was 9.0. running mean: 11.309980635545033\n",
      "resetting env. episode reward total was 12.0. running mean: 11.316880829189582\n",
      "resetting env. episode reward total was 12.0. running mean: 11.323712020897686\n",
      "resetting env. episode reward total was 5.0. running mean: 11.26047490068871\n",
      "resetting env. episode reward total was 5.0. running mean: 11.197870151681823\n",
      "resetting env. episode reward total was 3.0. running mean: 11.115891450165003\n",
      "resetting env. episode reward total was 14.0. running mean: 11.144732535663353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 11.09328521030672\n",
      "resetting env. episode reward total was 10.0. running mean: 11.082352358203652\n",
      "resetting env. episode reward total was 7.0. running mean: 11.041528834621616\n",
      "resetting env. episode reward total was 17.0. running mean: 11.1011135462754\n",
      "resetting env. episode reward total was 16.0. running mean: 11.150102410812647\n",
      "resetting env. episode reward total was 4.0. running mean: 11.07860138670452\n",
      "resetting env. episode reward total was 12.0. running mean: 11.087815372837474\n",
      "resetting env. episode reward total was 12.0. running mean: 11.096937219109098\n",
      "resetting env. episode reward total was 14.0. running mean: 11.125967846918007\n",
      "resetting env. episode reward total was 5.0. running mean: 11.064708168448828\n",
      "resetting env. episode reward total was 18.0. running mean: 11.134061086764339\n",
      "resetting env. episode reward total was 12.0. running mean: 11.142720475896695\n",
      "resetting env. episode reward total was 11.0. running mean: 11.141293271137728\n",
      "resetting env. episode reward total was 17.0. running mean: 11.19988033842635\n",
      "resetting env. episode reward total was 14.0. running mean: 11.227881535042087\n",
      "resetting env. episode reward total was 9.0. running mean: 11.205602719691665\n",
      "resetting env. episode reward total was 14.0. running mean: 11.233546692494748\n",
      "resetting env. episode reward total was 7.0. running mean: 11.1912112255698\n",
      "resetting env. episode reward total was 9.0. running mean: 11.169299113314102\n",
      "resetting env. episode reward total was 18.0. running mean: 11.23760612218096\n",
      "resetting env. episode reward total was 14.0. running mean: 11.265230060959151\n",
      "resetting env. episode reward total was 12.0. running mean: 11.27257776034956\n",
      "resetting env. episode reward total was 6.0. running mean: 11.219851982746064\n",
      "resetting env. episode reward total was 8.0. running mean: 11.187653462918604\n",
      "resetting env. episode reward total was 9.0. running mean: 11.165776928289418\n",
      "resetting env. episode reward total was 13.0. running mean: 11.184119159006524\n",
      "resetting env. episode reward total was 19.0. running mean: 11.262277967416459\n",
      "resetting env. episode reward total was 11.0. running mean: 11.259655187742293\n",
      "resetting env. episode reward total was 17.0. running mean: 11.31705863586487\n",
      "resetting env. episode reward total was 11.0. running mean: 11.31388804950622\n",
      "resetting env. episode reward total was 10.0. running mean: 11.300749169011157\n",
      "resetting env. episode reward total was 14.0. running mean: 11.327741677321045\n",
      "resetting env. episode reward total was 16.0. running mean: 11.374464260547835\n",
      "resetting env. episode reward total was 13.0. running mean: 11.390719617942358\n",
      "resetting env. episode reward total was 17.0. running mean: 11.446812421762933\n",
      "resetting env. episode reward total was 11.0. running mean: 11.442344297545304\n",
      "resetting env. episode reward total was 14.0. running mean: 11.467920854569853\n",
      "resetting env. episode reward total was 8.0. running mean: 11.433241646024154\n",
      "resetting env. episode reward total was 14.0. running mean: 11.458909229563913\n",
      "resetting env. episode reward total was 16.0. running mean: 11.504320137268273\n",
      "resetting env. episode reward total was 14.0. running mean: 11.529276935895592\n",
      "resetting env. episode reward total was 13.0. running mean: 11.543984166536637\n",
      "resetting env. episode reward total was 7.0. running mean: 11.49854432487127\n",
      "resetting env. episode reward total was 19.0. running mean: 11.573558881622557\n",
      "resetting env. episode reward total was 15.0. running mean: 11.607823292806332\n",
      "resetting env. episode reward total was 19.0. running mean: 11.681745059878267\n",
      "resetting env. episode reward total was 15.0. running mean: 11.714927609279485\n",
      "resetting env. episode reward total was 13.0. running mean: 11.727778333186691\n",
      "resetting env. episode reward total was 9.0. running mean: 11.700500549854825\n",
      "resetting env. episode reward total was 5.0. running mean: 11.633495544356277\n",
      "resetting env. episode reward total was 13.0. running mean: 11.647160588912715\n",
      "resetting env. episode reward total was 6.0. running mean: 11.590688983023588\n",
      "resetting env. episode reward total was 10.0. running mean: 11.574782093193352\n",
      "resetting env. episode reward total was 5.0. running mean: 11.50903427226142\n",
      "resetting env. episode reward total was 14.0. running mean: 11.533943929538806\n",
      "resetting env. episode reward total was 16.0. running mean: 11.578604490243418\n",
      "resetting env. episode reward total was 12.0. running mean: 11.582818445340983\n",
      "resetting env. episode reward total was 20.0. running mean: 11.666990260887573\n",
      "resetting env. episode reward total was 10.0. running mean: 11.650320358278696\n",
      "resetting env. episode reward total was 15.0. running mean: 11.683817154695909\n",
      "resetting env. episode reward total was 10.0. running mean: 11.66697898314895\n",
      "resetting env. episode reward total was 9.0. running mean: 11.64030919331746\n",
      "resetting env. episode reward total was 16.0. running mean: 11.683906101384286\n",
      "resetting env. episode reward total was 10.0. running mean: 11.667067040370442\n",
      "resetting env. episode reward total was 10.0. running mean: 11.650396369966737\n",
      "resetting env. episode reward total was 9.0. running mean: 11.62389240626707\n",
      "resetting env. episode reward total was 13.0. running mean: 11.6376534822044\n",
      "resetting env. episode reward total was 17.0. running mean: 11.691276947382356\n",
      "resetting env. episode reward total was 10.0. running mean: 11.674364177908531\n",
      "resetting env. episode reward total was 10.0. running mean: 11.657620536129446\n",
      "resetting env. episode reward total was 11.0. running mean: 11.651044330768151\n",
      "resetting env. episode reward total was 8.0. running mean: 11.61453388746047\n",
      "resetting env. episode reward total was 13.0. running mean: 11.628388548585866\n",
      "resetting env. episode reward total was -1.0. running mean: 11.502104663100008\n",
      "resetting env. episode reward total was 13.0. running mean: 11.517083616469009\n",
      "resetting env. episode reward total was 15.0. running mean: 11.551912780304319\n",
      "resetting env. episode reward total was 13.0. running mean: 11.566393652501276\n",
      "resetting env. episode reward total was 13.0. running mean: 11.580729715976263\n",
      "resetting env. episode reward total was 10.0. running mean: 11.5649224188165\n",
      "resetting env. episode reward total was 5.0. running mean: 11.499273194628337\n",
      "resetting env. episode reward total was 11.0. running mean: 11.494280462682053\n",
      "resetting env. episode reward total was 12.0. running mean: 11.49933765805523\n",
      "resetting env. episode reward total was 10.0. running mean: 11.484344281474678\n",
      "resetting env. episode reward total was 18.0. running mean: 11.549500838659931\n",
      "resetting env. episode reward total was 7.0. running mean: 11.504005830273332\n",
      "resetting env. episode reward total was 13.0. running mean: 11.5189657719706\n",
      "resetting env. episode reward total was 9.0. running mean: 11.493776114250894\n",
      "resetting env. episode reward total was 17.0. running mean: 11.548838353108385\n",
      "resetting env. episode reward total was 14.0. running mean: 11.573349969577302\n",
      "resetting env. episode reward total was 10.0. running mean: 11.557616469881529\n",
      "resetting env. episode reward total was 15.0. running mean: 11.592040305182714\n",
      "resetting env. episode reward total was 16.0. running mean: 11.636119902130886\n",
      "resetting env. episode reward total was 9.0. running mean: 11.609758703109577\n",
      "resetting env. episode reward total was 19.0. running mean: 11.683661116078481\n",
      "resetting env. episode reward total was 14.0. running mean: 11.706824504917696\n",
      "resetting env. episode reward total was 4.0. running mean: 11.629756259868518\n",
      "resetting env. episode reward total was 14.0. running mean: 11.653458697269834\n",
      "resetting env. episode reward total was 15.0. running mean: 11.686924110297136\n",
      "resetting env. episode reward total was 16.0. running mean: 11.730054869194165\n",
      "resetting env. episode reward total was 4.0. running mean: 11.652754320502222\n",
      "resetting env. episode reward total was 14.0. running mean: 11.6762267772972\n",
      "resetting env. episode reward total was 10.0. running mean: 11.659464509524229\n",
      "resetting env. episode reward total was -5.0. running mean: 11.492869864428986\n",
      "resetting env. episode reward total was 9.0. running mean: 11.467941165784696\n",
      "resetting env. episode reward total was 10.0. running mean: 11.45326175412685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 11.408729136585581\n",
      "resetting env. episode reward total was 12.0. running mean: 11.414641845219725\n",
      "resetting env. episode reward total was 13.0. running mean: 11.430495426767528\n",
      "resetting env. episode reward total was 10.0. running mean: 11.416190472499853\n",
      "resetting env. episode reward total was 15.0. running mean: 11.452028567774855\n",
      "resetting env. episode reward total was 14.0. running mean: 11.477508282097107\n",
      "resetting env. episode reward total was 14.0. running mean: 11.502733199276136\n",
      "resetting env. episode reward total was 17.0. running mean: 11.557705867283374\n",
      "resetting env. episode reward total was 7.0. running mean: 11.51212880861054\n",
      "resetting env. episode reward total was 15.0. running mean: 11.547007520524435\n",
      "resetting env. episode reward total was 3.0. running mean: 11.46153744531919\n",
      "resetting env. episode reward total was 14.0. running mean: 11.486922070865997\n",
      "resetting env. episode reward total was 14.0. running mean: 11.512052850157337\n",
      "resetting env. episode reward total was 15.0. running mean: 11.546932321655763\n",
      "resetting env. episode reward total was 4.0. running mean: 11.471462998439204\n",
      "resetting env. episode reward total was 15.0. running mean: 11.506748368454812\n",
      "resetting env. episode reward total was 13.0. running mean: 11.521680884770264\n",
      "resetting env. episode reward total was 12.0. running mean: 11.526464075922561\n",
      "resetting env. episode reward total was 17.0. running mean: 11.581199435163336\n",
      "resetting env. episode reward total was 18.0. running mean: 11.645387440811703\n",
      "resetting env. episode reward total was 13.0. running mean: 11.658933566403586\n",
      "resetting env. episode reward total was 14.0. running mean: 11.68234423073955\n",
      "resetting env. episode reward total was 10.0. running mean: 11.665520788432154\n",
      "resetting env. episode reward total was 11.0. running mean: 11.658865580547833\n",
      "resetting env. episode reward total was 17.0. running mean: 11.712276924742355\n",
      "resetting env. episode reward total was 12.0. running mean: 11.71515415549493\n",
      "resetting env. episode reward total was 15.0. running mean: 11.748002613939981\n",
      "resetting env. episode reward total was 15.0. running mean: 11.780522587800581\n",
      "resetting env. episode reward total was 9.0. running mean: 11.752717361922574\n",
      "resetting env. episode reward total was 7.0. running mean: 11.705190188303348\n",
      "resetting env. episode reward total was 8.0. running mean: 11.668138286420314\n",
      "resetting env. episode reward total was 20.0. running mean: 11.751456903556111\n",
      "resetting env. episode reward total was 14.0. running mean: 11.77394233452055\n",
      "resetting env. episode reward total was 7.0. running mean: 11.726202911175344\n",
      "resetting env. episode reward total was 6.0. running mean: 11.668940882063591\n",
      "resetting env. episode reward total was 4.0. running mean: 11.592251473242955\n",
      "resetting env. episode reward total was 14.0. running mean: 11.616328958510525\n",
      "resetting env. episode reward total was 13.0. running mean: 11.630165668925422\n",
      "resetting env. episode reward total was 18.0. running mean: 11.693864012236167\n",
      "resetting env. episode reward total was 16.0. running mean: 11.736925372113806\n",
      "resetting env. episode reward total was 5.0. running mean: 11.669556118392668\n",
      "resetting env. episode reward total was 9.0. running mean: 11.642860557208742\n",
      "resetting env. episode reward total was 12.0. running mean: 11.646431951636654\n",
      "resetting env. episode reward total was 10.0. running mean: 11.629967632120287\n",
      "resetting env. episode reward total was -2.0. running mean: 11.493667955799085\n",
      "resetting env. episode reward total was 11.0. running mean: 11.488731276241094\n",
      "resetting env. episode reward total was 3.0. running mean: 11.403843963478682\n",
      "resetting env. episode reward total was 11.0. running mean: 11.399805523843895\n",
      "resetting env. episode reward total was 16.0. running mean: 11.445807468605457\n",
      "resetting env. episode reward total was 10.0. running mean: 11.431349393919401\n",
      "resetting env. episode reward total was 6.0. running mean: 11.377035899980207\n",
      "resetting env. episode reward total was 12.0. running mean: 11.383265540980403\n",
      "resetting env. episode reward total was 12.0. running mean: 11.3894328855706\n",
      "resetting env. episode reward total was 7.0. running mean: 11.345538556714894\n",
      "resetting env. episode reward total was 6.0. running mean: 11.292083171147745\n",
      "resetting env. episode reward total was 13.0. running mean: 11.309162339436268\n",
      "resetting env. episode reward total was 10.0. running mean: 11.296070716041905\n",
      "resetting env. episode reward total was 8.0. running mean: 11.263110008881487\n",
      "resetting env. episode reward total was 16.0. running mean: 11.310478908792671\n",
      "resetting env. episode reward total was 15.0. running mean: 11.347374119704744\n",
      "resetting env. episode reward total was 10.0. running mean: 11.333900378507696\n",
      "resetting env. episode reward total was 11.0. running mean: 11.330561374722619\n",
      "resetting env. episode reward total was 7.0. running mean: 11.287255760975393\n",
      "resetting env. episode reward total was 12.0. running mean: 11.294383203365639\n",
      "resetting env. episode reward total was 13.0. running mean: 11.311439371331984\n",
      "resetting env. episode reward total was 13.0. running mean: 11.328324977618665\n",
      "resetting env. episode reward total was 14.0. running mean: 11.35504172784248\n",
      "resetting env. episode reward total was 15.0. running mean: 11.391491310564055\n",
      "resetting env. episode reward total was 12.0. running mean: 11.397576397458414\n",
      "resetting env. episode reward total was 4.0. running mean: 11.323600633483828\n",
      "resetting env. episode reward total was 12.0. running mean: 11.330364627148988\n",
      "resetting env. episode reward total was 4.0. running mean: 11.257060980877498\n",
      "resetting env. episode reward total was 12.0. running mean: 11.264490371068721\n",
      "resetting env. episode reward total was 15.0. running mean: 11.301845467358033\n",
      "resetting env. episode reward total was 9.0. running mean: 11.278827012684452\n",
      "resetting env. episode reward total was 4.0. running mean: 11.206038742557606\n",
      "resetting env. episode reward total was 15.0. running mean: 11.24397835513203\n",
      "resetting env. episode reward total was 13.0. running mean: 11.261538571580711\n",
      "resetting env. episode reward total was 10.0. running mean: 11.248923185864903\n",
      "resetting env. episode reward total was 8.0. running mean: 11.216433954006254\n",
      "resetting env. episode reward total was 8.0. running mean: 11.184269614466192\n",
      "resetting env. episode reward total was 12.0. running mean: 11.19242691832153\n",
      "resetting env. episode reward total was 14.0. running mean: 11.220502649138316\n",
      "resetting env. episode reward total was 6.0. running mean: 11.168297622646934\n",
      "resetting env. episode reward total was 17.0. running mean: 11.226614646420465\n",
      "resetting env. episode reward total was 15.0. running mean: 11.264348499956261\n",
      "resetting env. episode reward total was 11.0. running mean: 11.261705014956698\n",
      "resetting env. episode reward total was 10.0. running mean: 11.249087964807131\n",
      "resetting env. episode reward total was 10.0. running mean: 11.23659708515906\n",
      "resetting env. episode reward total was 11.0. running mean: 11.23423111430747\n",
      "resetting env. episode reward total was 13.0. running mean: 11.251888803164396\n",
      "resetting env. episode reward total was 13.0. running mean: 11.269369915132753\n",
      "resetting env. episode reward total was 15.0. running mean: 11.306676215981426\n",
      "resetting env. episode reward total was 6.0. running mean: 11.253609453821612\n",
      "resetting env. episode reward total was 14.0. running mean: 11.281073359283397\n",
      "resetting env. episode reward total was 12.0. running mean: 11.288262625690562\n",
      "resetting env. episode reward total was 2.0. running mean: 11.195379999433657\n",
      "resetting env. episode reward total was 19.0. running mean: 11.273426199439319\n",
      "resetting env. episode reward total was 15.0. running mean: 11.310691937444926\n",
      "resetting env. episode reward total was 18.0. running mean: 11.377585018070477\n",
      "resetting env. episode reward total was 9.0. running mean: 11.353809167889771\n",
      "resetting env. episode reward total was 16.0. running mean: 11.400271076210874\n",
      "resetting env. episode reward total was 17.0. running mean: 11.456268365448766\n",
      "resetting env. episode reward total was 17.0. running mean: 11.511705681794279\n",
      "resetting env. episode reward total was 16.0. running mean: 11.556588624976337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 11.551022738726573\n",
      "resetting env. episode reward total was 16.0. running mean: 11.595512511339308\n",
      "resetting env. episode reward total was 11.0. running mean: 11.589557386225914\n",
      "resetting env. episode reward total was 8.0. running mean: 11.553661812363655\n",
      "resetting env. episode reward total was 14.0. running mean: 11.57812519424002\n",
      "resetting env. episode reward total was 10.0. running mean: 11.56234394229762\n",
      "resetting env. episode reward total was 12.0. running mean: 11.566720502874643\n",
      "resetting env. episode reward total was 11.0. running mean: 11.561053297845897\n",
      "resetting env. episode reward total was 17.0. running mean: 11.615442764867437\n",
      "resetting env. episode reward total was 10.0. running mean: 11.599288337218763\n",
      "resetting env. episode reward total was 14.0. running mean: 11.623295453846575\n",
      "resetting env. episode reward total was 13.0. running mean: 11.63706249930811\n",
      "resetting env. episode reward total was 12.0. running mean: 11.640691874315028\n",
      "resetting env. episode reward total was 12.0. running mean: 11.644284955571877\n",
      "resetting env. episode reward total was 11.0. running mean: 11.637842106016157\n",
      "resetting env. episode reward total was 5.0. running mean: 11.571463684955996\n",
      "resetting env. episode reward total was 4.0. running mean: 11.495749048106434\n",
      "resetting env. episode reward total was 9.0. running mean: 11.47079155762537\n",
      "resetting env. episode reward total was 17.0. running mean: 11.526083642049116\n",
      "resetting env. episode reward total was 11.0. running mean: 11.520822805628624\n",
      "resetting env. episode reward total was 7.0. running mean: 11.475614577572339\n",
      "resetting env. episode reward total was 12.0. running mean: 11.480858431796614\n",
      "resetting env. episode reward total was 16.0. running mean: 11.526049847478648\n",
      "resetting env. episode reward total was 14.0. running mean: 11.550789349003862\n",
      "resetting env. episode reward total was 17.0. running mean: 11.605281455513824\n",
      "resetting env. episode reward total was 11.0. running mean: 11.599228640958685\n",
      "resetting env. episode reward total was 7.0. running mean: 11.5532363545491\n",
      "resetting env. episode reward total was 18.0. running mean: 11.617703991003609\n",
      "resetting env. episode reward total was 10.0. running mean: 11.601526951093572\n",
      "resetting env. episode reward total was 11.0. running mean: 11.595511681582636\n",
      "resetting env. episode reward total was 2.0. running mean: 11.49955656476681\n",
      "resetting env. episode reward total was 12.0. running mean: 11.50456099911914\n",
      "resetting env. episode reward total was 2.0. running mean: 11.409515389127948\n",
      "resetting env. episode reward total was 7.0. running mean: 11.36542023523667\n",
      "resetting env. episode reward total was 12.0. running mean: 11.371766032884302\n",
      "resetting env. episode reward total was 7.0. running mean: 11.32804837255546\n",
      "resetting env. episode reward total was 11.0. running mean: 11.324767888829903\n",
      "resetting env. episode reward total was 16.0. running mean: 11.371520209941604\n",
      "resetting env. episode reward total was 15.0. running mean: 11.407805007842189\n",
      "resetting env. episode reward total was 6.0. running mean: 11.353726957763767\n",
      "resetting env. episode reward total was 6.0. running mean: 11.30018968818613\n",
      "resetting env. episode reward total was 10.0. running mean: 11.287187791304268\n",
      "resetting env. episode reward total was 13.0. running mean: 11.304315913391227\n",
      "resetting env. episode reward total was 17.0. running mean: 11.361272754257314\n",
      "resetting env. episode reward total was 11.0. running mean: 11.35766002671474\n",
      "resetting env. episode reward total was 11.0. running mean: 11.354083426447591\n",
      "resetting env. episode reward total was 16.0. running mean: 11.400542592183115\n",
      "resetting env. episode reward total was 3.0. running mean: 11.316537166261282\n",
      "resetting env. episode reward total was 15.0. running mean: 11.35337179459867\n",
      "resetting env. episode reward total was 11.0. running mean: 11.349838076652683\n",
      "resetting env. episode reward total was 4.0. running mean: 11.276339695886154\n",
      "resetting env. episode reward total was 11.0. running mean: 11.273576298927292\n",
      "resetting env. episode reward total was 16.0. running mean: 11.32084053593802\n",
      "resetting env. episode reward total was 16.0. running mean: 11.36763213057864\n",
      "resetting env. episode reward total was 8.0. running mean: 11.333955809272853\n",
      "resetting env. episode reward total was 14.0. running mean: 11.360616251180124\n",
      "resetting env. episode reward total was 16.0. running mean: 11.407010088668322\n",
      "resetting env. episode reward total was 14.0. running mean: 11.432939987781639\n",
      "resetting env. episode reward total was 13.0. running mean: 11.448610587903824\n",
      "resetting env. episode reward total was 10.0. running mean: 11.434124482024785\n",
      "resetting env. episode reward total was 12.0. running mean: 11.439783237204537\n",
      "resetting env. episode reward total was 13.0. running mean: 11.455385404832493\n",
      "resetting env. episode reward total was 9.0. running mean: 11.430831550784168\n",
      "resetting env. episode reward total was 16.0. running mean: 11.476523235276327\n",
      "resetting env. episode reward total was 9.0. running mean: 11.451758002923563\n",
      "resetting env. episode reward total was 16.0. running mean: 11.497240422894327\n",
      "resetting env. episode reward total was 2.0. running mean: 11.402268018665383\n",
      "resetting env. episode reward total was 14.0. running mean: 11.42824533847873\n",
      "resetting env. episode reward total was 14.0. running mean: 11.453962885093944\n",
      "resetting env. episode reward total was 16.0. running mean: 11.499423256243004\n",
      "resetting env. episode reward total was 3.0. running mean: 11.414429023680572\n",
      "resetting env. episode reward total was 12.0. running mean: 11.420284733443765\n",
      "resetting env. episode reward total was 14.0. running mean: 11.446081886109328\n",
      "resetting env. episode reward total was 7.0. running mean: 11.401621067248234\n",
      "resetting env. episode reward total was 12.0. running mean: 11.407604856575752\n",
      "resetting env. episode reward total was 11.0. running mean: 11.403528808009993\n",
      "resetting env. episode reward total was 7.0. running mean: 11.359493519929893\n",
      "resetting env. episode reward total was 13.0. running mean: 11.375898584730596\n",
      "resetting env. episode reward total was 16.0. running mean: 11.42213959888329\n",
      "resetting env. episode reward total was 3.0. running mean: 11.337918202894455\n",
      "resetting env. episode reward total was 8.0. running mean: 11.30453902086551\n",
      "resetting env. episode reward total was 13.0. running mean: 11.321493630656857\n",
      "resetting env. episode reward total was 9.0. running mean: 11.298278694350287\n",
      "resetting env. episode reward total was 19.0. running mean: 11.375295907406784\n",
      "resetting env. episode reward total was 10.0. running mean: 11.361542948332715\n",
      "resetting env. episode reward total was 5.0. running mean: 11.29792751884939\n",
      "resetting env. episode reward total was 15.0. running mean: 11.334948243660897\n",
      "resetting env. episode reward total was 14.0. running mean: 11.361598761224288\n",
      "resetting env. episode reward total was 15.0. running mean: 11.397982773612044\n",
      "resetting env. episode reward total was 10.0. running mean: 11.384002945875924\n",
      "resetting env. episode reward total was 7.0. running mean: 11.340162916417166\n",
      "resetting env. episode reward total was 14.0. running mean: 11.366761287252995\n",
      "resetting env. episode reward total was 11.0. running mean: 11.363093674380464\n",
      "resetting env. episode reward total was 20.0. running mean: 11.449462737636658\n",
      "resetting env. episode reward total was 10.0. running mean: 11.434968110260291\n",
      "resetting env. episode reward total was 10.0. running mean: 11.420618429157688\n",
      "resetting env. episode reward total was 13.0. running mean: 11.436412244866112\n",
      "resetting env. episode reward total was 8.0. running mean: 11.402048122417451\n",
      "resetting env. episode reward total was 14.0. running mean: 11.428027641193276\n",
      "resetting env. episode reward total was 7.0. running mean: 11.383747364781344\n",
      "resetting env. episode reward total was 9.0. running mean: 11.359909891133531\n",
      "resetting env. episode reward total was 17.0. running mean: 11.416310792222196\n",
      "resetting env. episode reward total was 10.0. running mean: 11.402147684299974\n",
      "resetting env. episode reward total was 15.0. running mean: 11.438126207456975\n",
      "resetting env. episode reward total was 14.0. running mean: 11.463744945382405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 17.0. running mean: 11.519107495928582\n",
      "resetting env. episode reward total was 5.0. running mean: 11.453916420969296\n",
      "resetting env. episode reward total was 10.0. running mean: 11.439377256759602\n",
      "resetting env. episode reward total was 14.0. running mean: 11.464983484192008\n",
      "resetting env. episode reward total was 9.0. running mean: 11.440333649350087\n",
      "resetting env. episode reward total was 18.0. running mean: 11.505930312856586\n",
      "resetting env. episode reward total was 9.0. running mean: 11.48087100972802\n",
      "resetting env. episode reward total was 16.0. running mean: 11.52606229963074\n",
      "resetting env. episode reward total was 12.0. running mean: 11.53080167663443\n",
      "resetting env. episode reward total was 8.0. running mean: 11.495493659868087\n",
      "resetting env. episode reward total was 6.0. running mean: 11.440538723269407\n",
      "resetting env. episode reward total was 17.0. running mean: 11.496133336036714\n",
      "resetting env. episode reward total was 18.0. running mean: 11.561172002676345\n",
      "resetting env. episode reward total was 13.0. running mean: 11.575560282649583\n",
      "resetting env. episode reward total was 20.0. running mean: 11.659804679823086\n",
      "resetting env. episode reward total was 11.0. running mean: 11.653206633024855\n",
      "resetting env. episode reward total was 16.0. running mean: 11.696674566694606\n",
      "resetting env. episode reward total was 14.0. running mean: 11.71970782102766\n",
      "resetting env. episode reward total was 16.0. running mean: 11.762510742817383\n",
      "resetting env. episode reward total was 13.0. running mean: 11.77488563538921\n",
      "resetting env. episode reward total was 11.0. running mean: 11.767136779035319\n",
      "resetting env. episode reward total was 9.0. running mean: 11.739465411244966\n",
      "resetting env. episode reward total was 8.0. running mean: 11.702070757132516\n",
      "resetting env. episode reward total was 10.0. running mean: 11.68505004956119\n",
      "resetting env. episode reward total was 10.0. running mean: 11.668199549065577\n",
      "resetting env. episode reward total was 18.0. running mean: 11.731517553574921\n",
      "resetting env. episode reward total was 9.0. running mean: 11.704202378039172\n",
      "resetting env. episode reward total was 16.0. running mean: 11.74716035425878\n",
      "resetting env. episode reward total was 11.0. running mean: 11.73968875071619\n",
      "resetting env. episode reward total was 14.0. running mean: 11.762291863209029\n",
      "resetting env. episode reward total was 9.0. running mean: 11.734668944576939\n",
      "resetting env. episode reward total was 14.0. running mean: 11.75732225513117\n",
      "resetting env. episode reward total was 13.0. running mean: 11.769749032579858\n",
      "resetting env. episode reward total was 15.0. running mean: 11.802051542254059\n",
      "resetting env. episode reward total was 15.0. running mean: 11.834031026831518\n",
      "resetting env. episode reward total was 11.0. running mean: 11.825690716563201\n",
      "resetting env. episode reward total was 15.0. running mean: 11.85743380939757\n",
      "resetting env. episode reward total was 8.0. running mean: 11.818859471303593\n",
      "resetting env. episode reward total was 9.0. running mean: 11.790670876590557\n",
      "resetting env. episode reward total was 7.0. running mean: 11.742764167824651\n",
      "resetting env. episode reward total was 15.0. running mean: 11.775336526146406\n",
      "resetting env. episode reward total was 17.0. running mean: 11.827583160884942\n",
      "resetting env. episode reward total was 11.0. running mean: 11.819307329276091\n",
      "resetting env. episode reward total was 12.0. running mean: 11.821114255983328\n",
      "resetting env. episode reward total was 8.0. running mean: 11.782903113423496\n",
      "resetting env. episode reward total was 12.0. running mean: 11.78507408228926\n",
      "resetting env. episode reward total was 14.0. running mean: 11.807223341466367\n",
      "resetting env. episode reward total was 10.0. running mean: 11.789151108051703\n",
      "resetting env. episode reward total was 12.0. running mean: 11.791259596971186\n",
      "resetting env. episode reward total was 15.0. running mean: 11.823347001001475\n",
      "resetting env. episode reward total was 7.0. running mean: 11.77511353099146\n",
      "resetting env. episode reward total was 8.0. running mean: 11.737362395681545\n",
      "resetting env. episode reward total was 17.0. running mean: 11.78998877172473\n",
      "resetting env. episode reward total was 7.0. running mean: 11.742088884007483\n",
      "resetting env. episode reward total was 17.0. running mean: 11.794667995167408\n",
      "resetting env. episode reward total was 13.0. running mean: 11.806721315215736\n",
      "resetting env. episode reward total was 11.0. running mean: 11.798654102063578\n",
      "resetting env. episode reward total was 18.0. running mean: 11.860667561042941\n",
      "resetting env. episode reward total was 14.0. running mean: 11.882060885432512\n",
      "resetting env. episode reward total was 13.0. running mean: 11.893240276578188\n",
      "resetting env. episode reward total was 17.0. running mean: 11.944307873812406\n",
      "resetting env. episode reward total was 9.0. running mean: 11.914864795074282\n",
      "resetting env. episode reward total was 11.0. running mean: 11.905716147123538\n",
      "resetting env. episode reward total was 6.0. running mean: 11.846658985652303\n",
      "resetting env. episode reward total was 9.0. running mean: 11.81819239579578\n",
      "resetting env. episode reward total was 11.0. running mean: 11.810010471837822\n",
      "resetting env. episode reward total was 7.0. running mean: 11.761910367119444\n",
      "resetting env. episode reward total was 11.0. running mean: 11.75429126344825\n",
      "resetting env. episode reward total was 15.0. running mean: 11.786748350813768\n",
      "resetting env. episode reward total was 15.0. running mean: 11.818880867305632\n",
      "resetting env. episode reward total was 10.0. running mean: 11.800692058632576\n",
      "resetting env. episode reward total was 13.0. running mean: 11.81268513804625\n",
      "resetting env. episode reward total was 13.0. running mean: 11.824558286665788\n",
      "resetting env. episode reward total was 15.0. running mean: 11.85631270379913\n",
      "resetting env. episode reward total was 12.0. running mean: 11.857749576761138\n",
      "resetting env. episode reward total was 14.0. running mean: 11.879172080993527\n",
      "resetting env. episode reward total was 13.0. running mean: 11.890380360183592\n",
      "resetting env. episode reward total was 12.0. running mean: 11.891476556581756\n",
      "resetting env. episode reward total was 12.0. running mean: 11.892561791015938\n",
      "resetting env. episode reward total was 7.0. running mean: 11.843636173105779\n",
      "resetting env. episode reward total was 16.0. running mean: 11.88519981137472\n",
      "resetting env. episode reward total was 12.0. running mean: 11.886347813260972\n",
      "resetting env. episode reward total was 17.0. running mean: 11.937484335128362\n",
      "resetting env. episode reward total was 12.0. running mean: 11.938109491777077\n",
      "resetting env. episode reward total was 11.0. running mean: 11.928728396859306\n",
      "resetting env. episode reward total was 13.0. running mean: 11.939441112890714\n",
      "resetting env. episode reward total was 15.0. running mean: 11.970046701761808\n",
      "resetting env. episode reward total was 18.0. running mean: 12.03034623474419\n",
      "resetting env. episode reward total was 13.0. running mean: 12.040042772396749\n",
      "resetting env. episode reward total was 8.0. running mean: 11.99964234467278\n",
      "resetting env. episode reward total was 11.0. running mean: 11.989645921226051\n",
      "resetting env. episode reward total was 9.0. running mean: 11.959749462013791\n",
      "resetting env. episode reward total was 9.0. running mean: 11.930151967393654\n",
      "resetting env. episode reward total was 13.0. running mean: 11.940850447719718\n",
      "resetting env. episode reward total was 8.0. running mean: 11.90144194324252\n",
      "resetting env. episode reward total was 12.0. running mean: 11.902427523810095\n",
      "resetting env. episode reward total was 14.0. running mean: 11.923403248571995\n",
      "resetting env. episode reward total was 9.0. running mean: 11.894169216086276\n",
      "resetting env. episode reward total was 8.0. running mean: 11.855227523925413\n",
      "resetting env. episode reward total was 10.0. running mean: 11.836675248686158\n",
      "resetting env. episode reward total was 7.0. running mean: 11.788308496199296\n",
      "resetting env. episode reward total was 10.0. running mean: 11.770425411237301\n",
      "resetting env. episode reward total was 18.0. running mean: 11.832721157124928\n",
      "resetting env. episode reward total was 19.0. running mean: 11.904393945553677\n",
      "resetting env. episode reward total was 11.0. running mean: 11.89535000609814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 11.916396506037158\n",
      "resetting env. episode reward total was 15.0. running mean: 11.947232540976787\n",
      "resetting env. episode reward total was 13.0. running mean: 11.957760215567019\n",
      "resetting env. episode reward total was 9.0. running mean: 11.928182613411348\n",
      "resetting env. episode reward total was 8.0. running mean: 11.888900787277235\n",
      "resetting env. episode reward total was 13.0. running mean: 11.900011779404464\n",
      "resetting env. episode reward total was 10.0. running mean: 11.881011661610419\n",
      "resetting env. episode reward total was 10.0. running mean: 11.862201544994313\n",
      "resetting env. episode reward total was 5.0. running mean: 11.79357952954437\n",
      "resetting env. episode reward total was 7.0. running mean: 11.745643734248928\n",
      "resetting env. episode reward total was 9.0. running mean: 11.718187296906438\n",
      "resetting env. episode reward total was 6.0. running mean: 11.661005423937373\n",
      "resetting env. episode reward total was 12.0. running mean: 11.664395369698\n",
      "resetting env. episode reward total was 14.0. running mean: 11.687751416001019\n",
      "resetting env. episode reward total was 15.0. running mean: 11.720873901841008\n",
      "resetting env. episode reward total was 12.0. running mean: 11.723665162822597\n",
      "resetting env. episode reward total was 8.0. running mean: 11.686428511194372\n",
      "resetting env. episode reward total was 10.0. running mean: 11.669564226082427\n",
      "resetting env. episode reward total was 7.0. running mean: 11.622868583821603\n",
      "resetting env. episode reward total was 9.0. running mean: 11.596639897983387\n",
      "resetting env. episode reward total was 11.0. running mean: 11.590673499003552\n",
      "resetting env. episode reward total was 7.0. running mean: 11.544766764013517\n",
      "resetting env. episode reward total was 16.0. running mean: 11.589319096373382\n",
      "resetting env. episode reward total was 13.0. running mean: 11.60342590540965\n",
      "resetting env. episode reward total was 14.0. running mean: 11.627391646355553\n",
      "resetting env. episode reward total was 17.0. running mean: 11.681117729891998\n",
      "resetting env. episode reward total was 14.0. running mean: 11.704306552593078\n",
      "resetting env. episode reward total was 8.0. running mean: 11.667263487067148\n",
      "resetting env. episode reward total was 15.0. running mean: 11.700590852196477\n",
      "resetting env. episode reward total was 18.0. running mean: 11.763584943674513\n",
      "resetting env. episode reward total was 8.0. running mean: 11.725949094237768\n",
      "resetting env. episode reward total was 7.0. running mean: 11.67868960329539\n",
      "resetting env. episode reward total was 14.0. running mean: 11.701902707262438\n",
      "resetting env. episode reward total was 11.0. running mean: 11.694883680189813\n",
      "resetting env. episode reward total was 16.0. running mean: 11.737934843387915\n",
      "resetting env. episode reward total was 10.0. running mean: 11.720555494954036\n",
      "resetting env. episode reward total was 13.0. running mean: 11.733349940004496\n",
      "resetting env. episode reward total was 17.0. running mean: 11.78601644060445\n",
      "resetting env. episode reward total was 16.0. running mean: 11.828156276198406\n",
      "resetting env. episode reward total was 18.0. running mean: 11.889874713436422\n",
      "resetting env. episode reward total was 12.0. running mean: 11.890975966302056\n",
      "resetting env. episode reward total was 15.0. running mean: 11.922066206639036\n",
      "resetting env. episode reward total was 9.0. running mean: 11.892845544572646\n",
      "resetting env. episode reward total was 9.0. running mean: 11.86391708912692\n",
      "resetting env. episode reward total was 8.0. running mean: 11.82527791823565\n",
      "resetting env. episode reward total was 12.0. running mean: 11.827025139053294\n",
      "resetting env. episode reward total was 15.0. running mean: 11.858754887662762\n",
      "resetting env. episode reward total was 11.0. running mean: 11.850167338786134\n",
      "resetting env. episode reward total was 18.0. running mean: 11.911665665398273\n",
      "resetting env. episode reward total was 5.0. running mean: 11.84254900874429\n",
      "resetting env. episode reward total was 10.0. running mean: 11.824123518656847\n",
      "resetting env. episode reward total was 5.0. running mean: 11.75588228347028\n",
      "resetting env. episode reward total was 18.0. running mean: 11.818323460635577\n",
      "resetting env. episode reward total was 11.0. running mean: 11.81014022602922\n",
      "resetting env. episode reward total was 14.0. running mean: 11.83203882376893\n",
      "resetting env. episode reward total was 15.0. running mean: 11.86371843553124\n",
      "resetting env. episode reward total was 13.0. running mean: 11.875081251175928\n",
      "resetting env. episode reward total was 9.0. running mean: 11.846330438664168\n",
      "resetting env. episode reward total was 16.0. running mean: 11.887867134277526\n",
      "resetting env. episode reward total was 13.0. running mean: 11.898988462934751\n",
      "resetting env. episode reward total was 15.0. running mean: 11.929998578305403\n",
      "resetting env. episode reward total was 16.0. running mean: 11.970698592522348\n",
      "resetting env. episode reward total was 14.0. running mean: 11.990991606597126\n",
      "resetting env. episode reward total was 16.0. running mean: 12.031081690531154\n",
      "resetting env. episode reward total was 15.0. running mean: 12.060770873625843\n",
      "resetting env. episode reward total was 15.0. running mean: 12.090163164889585\n",
      "resetting env. episode reward total was 15.0. running mean: 12.119261533240689\n",
      "resetting env. episode reward total was 17.0. running mean: 12.16806891790828\n",
      "resetting env. episode reward total was 11.0. running mean: 12.156388228729197\n",
      "resetting env. episode reward total was 12.0. running mean: 12.154824346441904\n",
      "resetting env. episode reward total was 12.0. running mean: 12.153276102977484\n",
      "resetting env. episode reward total was 10.0. running mean: 12.13174334194771\n",
      "resetting env. episode reward total was 10.0. running mean: 12.110425908528232\n",
      "resetting env. episode reward total was 14.0. running mean: 12.12932164944295\n",
      "resetting env. episode reward total was 18.0. running mean: 12.18802843294852\n",
      "resetting env. episode reward total was 6.0. running mean: 12.126148148619036\n",
      "resetting env. episode reward total was 16.0. running mean: 12.164886667132846\n",
      "resetting env. episode reward total was 18.0. running mean: 12.223237800461517\n",
      "resetting env. episode reward total was 12.0. running mean: 12.221005422456901\n",
      "resetting env. episode reward total was 13.0. running mean: 12.228795368232333\n",
      "resetting env. episode reward total was 20.0. running mean: 12.306507414550008\n",
      "resetting env. episode reward total was 15.0. running mean: 12.333442340404508\n",
      "resetting env. episode reward total was 14.0. running mean: 12.350107917000463\n",
      "resetting env. episode reward total was 8.0. running mean: 12.306606837830458\n",
      "resetting env. episode reward total was 18.0. running mean: 12.363540769452152\n",
      "resetting env. episode reward total was 8.0. running mean: 12.31990536175763\n",
      "resetting env. episode reward total was 19.0. running mean: 12.386706308140054\n",
      "resetting env. episode reward total was 15.0. running mean: 12.412839245058654\n",
      "resetting env. episode reward total was 15.0. running mean: 12.438710852608068\n",
      "resetting env. episode reward total was 11.0. running mean: 12.424323744081986\n",
      "resetting env. episode reward total was 15.0. running mean: 12.450080506641166\n",
      "resetting env. episode reward total was 15.0. running mean: 12.475579701574755\n",
      "resetting env. episode reward total was 17.0. running mean: 12.520823904559007\n",
      "resetting env. episode reward total was 7.0. running mean: 12.465615665513418\n",
      "resetting env. episode reward total was 10.0. running mean: 12.440959508858283\n",
      "resetting env. episode reward total was 17.0. running mean: 12.4865499137697\n",
      "resetting env. episode reward total was 8.0. running mean: 12.441684414632004\n",
      "resetting env. episode reward total was 16.0. running mean: 12.477267570485683\n",
      "resetting env. episode reward total was 12.0. running mean: 12.472494894780825\n",
      "resetting env. episode reward total was 16.0. running mean: 12.507769945833017\n",
      "resetting env. episode reward total was 19.0. running mean: 12.572692246374686\n",
      "resetting env. episode reward total was 3.0. running mean: 12.476965323910939\n",
      "resetting env. episode reward total was 6.0. running mean: 12.41219567067183\n",
      "resetting env. episode reward total was 13.0. running mean: 12.418073713965113\n",
      "resetting env. episode reward total was 17.0. running mean: 12.463892976825461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 12.449254047057206\n",
      "resetting env. episode reward total was 13.0. running mean: 12.454761506586635\n",
      "resetting env. episode reward total was 12.0. running mean: 12.450213891520768\n",
      "resetting env. episode reward total was 11.0. running mean: 12.43571175260556\n",
      "resetting env. episode reward total was 16.0. running mean: 12.471354635079503\n",
      "resetting env. episode reward total was 16.0. running mean: 12.506641088728708\n",
      "resetting env. episode reward total was 17.0. running mean: 12.55157467784142\n",
      "resetting env. episode reward total was 15.0. running mean: 12.576058931063006\n",
      "resetting env. episode reward total was 15.0. running mean: 12.600298341752376\n",
      "resetting env. episode reward total was 9.0. running mean: 12.564295358334853\n",
      "resetting env. episode reward total was 12.0. running mean: 12.558652404751504\n",
      "resetting env. episode reward total was 10.0. running mean: 12.533065880703989\n",
      "resetting env. episode reward total was 13.0. running mean: 12.537735221896948\n",
      "resetting env. episode reward total was 11.0. running mean: 12.522357869677979\n",
      "resetting env. episode reward total was 13.0. running mean: 12.5271342909812\n",
      "resetting env. episode reward total was 17.0. running mean: 12.571862948071388\n",
      "resetting env. episode reward total was 11.0. running mean: 12.556144318590674\n",
      "resetting env. episode reward total was 14.0. running mean: 12.570582875404767\n",
      "resetting env. episode reward total was 6.0. running mean: 12.50487704665072\n",
      "resetting env. episode reward total was 14.0. running mean: 12.519828276184212\n",
      "resetting env. episode reward total was 8.0. running mean: 12.47462999342237\n",
      "resetting env. episode reward total was 11.0. running mean: 12.459883693488147\n",
      "resetting env. episode reward total was 13.0. running mean: 12.465284856553266\n",
      "resetting env. episode reward total was 17.0. running mean: 12.510632007987732\n",
      "resetting env. episode reward total was 12.0. running mean: 12.505525687907854\n",
      "resetting env. episode reward total was 16.0. running mean: 12.540470431028774\n",
      "resetting env. episode reward total was 8.0. running mean: 12.495065726718487\n",
      "resetting env. episode reward total was 10.0. running mean: 12.470115069451301\n",
      "resetting env. episode reward total was 11.0. running mean: 12.455413918756788\n",
      "resetting env. episode reward total was 20.0. running mean: 12.53085977956922\n",
      "resetting env. episode reward total was 10.0. running mean: 12.505551181773527\n",
      "resetting env. episode reward total was 12.0. running mean: 12.500495669955791\n",
      "resetting env. episode reward total was 12.0. running mean: 12.495490713256233\n",
      "resetting env. episode reward total was 11.0. running mean: 12.48053580612367\n",
      "resetting env. episode reward total was 4.0. running mean: 12.395730448062434\n",
      "resetting env. episode reward total was 12.0. running mean: 12.391773143581808\n",
      "resetting env. episode reward total was 17.0. running mean: 12.43785541214599\n",
      "resetting env. episode reward total was 13.0. running mean: 12.44347685802453\n",
      "resetting env. episode reward total was 9.0. running mean: 12.409042089444284\n",
      "resetting env. episode reward total was 13.0. running mean: 12.414951668549842\n",
      "resetting env. episode reward total was 13.0. running mean: 12.420802151864343\n",
      "resetting env. episode reward total was 10.0. running mean: 12.396594130345699\n",
      "resetting env. episode reward total was 12.0. running mean: 12.392628189042242\n",
      "resetting env. episode reward total was 12.0. running mean: 12.388701907151818\n",
      "resetting env. episode reward total was 18.0. running mean: 12.4448148880803\n",
      "resetting env. episode reward total was 13.0. running mean: 12.450366739199497\n",
      "resetting env. episode reward total was 12.0. running mean: 12.445863071807501\n",
      "resetting env. episode reward total was 19.0. running mean: 12.511404441089425\n",
      "resetting env. episode reward total was 2.0. running mean: 12.40629039667853\n",
      "resetting env. episode reward total was 9.0. running mean: 12.372227492711744\n",
      "resetting env. episode reward total was 12.0. running mean: 12.368505217784625\n",
      "resetting env. episode reward total was 4.0. running mean: 12.284820165606778\n",
      "resetting env. episode reward total was 14.0. running mean: 12.301971963950711\n",
      "resetting env. episode reward total was 13.0. running mean: 12.308952244311206\n",
      "resetting env. episode reward total was 10.0. running mean: 12.285862721868092\n",
      "resetting env. episode reward total was 13.0. running mean: 12.293004094649412\n",
      "resetting env. episode reward total was 12.0. running mean: 12.290074053702917\n",
      "resetting env. episode reward total was 16.0. running mean: 12.327173313165888\n",
      "resetting env. episode reward total was 11.0. running mean: 12.313901580034228\n",
      "resetting env. episode reward total was 16.0. running mean: 12.350762564233886\n",
      "resetting env. episode reward total was 13.0. running mean: 12.357254938591547\n",
      "resetting env. episode reward total was -7.0. running mean: 12.163682389205631\n",
      "resetting env. episode reward total was 12.0. running mean: 12.162045565313575\n",
      "resetting env. episode reward total was 4.0. running mean: 12.080425109660437\n",
      "resetting env. episode reward total was 15.0. running mean: 12.109620858563833\n",
      "resetting env. episode reward total was 15.0. running mean: 12.138524649978194\n",
      "resetting env. episode reward total was 13.0. running mean: 12.147139403478413\n",
      "resetting env. episode reward total was 18.0. running mean: 12.205668009443627\n",
      "resetting env. episode reward total was 9.0. running mean: 12.17361132934919\n",
      "resetting env. episode reward total was 9.0. running mean: 12.141875216055698\n",
      "resetting env. episode reward total was 11.0. running mean: 12.130456463895142\n",
      "resetting env. episode reward total was 10.0. running mean: 12.10915189925619\n",
      "resetting env. episode reward total was 14.0. running mean: 12.128060380263628\n",
      "resetting env. episode reward total was 10.0. running mean: 12.106779776460991\n",
      "resetting env. episode reward total was 12.0. running mean: 12.10571197869638\n",
      "resetting env. episode reward total was 9.0. running mean: 12.074654858909415\n",
      "resetting env. episode reward total was 7.0. running mean: 12.023908310320321\n",
      "resetting env. episode reward total was 13.0. running mean: 12.033669227217118\n",
      "resetting env. episode reward total was 11.0. running mean: 12.023332534944945\n",
      "resetting env. episode reward total was 16.0. running mean: 12.063099209595496\n",
      "resetting env. episode reward total was 16.0. running mean: 12.10246821749954\n",
      "resetting env. episode reward total was 16.0. running mean: 12.141443535324544\n",
      "resetting env. episode reward total was 17.0. running mean: 12.1900290999713\n",
      "resetting env. episode reward total was 14.0. running mean: 12.208128808971587\n",
      "resetting env. episode reward total was 9.0. running mean: 12.176047520881871\n",
      "resetting env. episode reward total was 18.0. running mean: 12.234287045673053\n",
      "resetting env. episode reward total was 15.0. running mean: 12.261944175216323\n",
      "resetting env. episode reward total was 11.0. running mean: 12.249324733464158\n",
      "resetting env. episode reward total was 16.0. running mean: 12.286831486129516\n",
      "resetting env. episode reward total was 14.0. running mean: 12.303963171268222\n",
      "resetting env. episode reward total was 11.0. running mean: 12.29092353955554\n",
      "resetting env. episode reward total was 14.0. running mean: 12.308014304159984\n",
      "resetting env. episode reward total was 14.0. running mean: 12.324934161118385\n",
      "resetting env. episode reward total was 8.0. running mean: 12.281684819507202\n",
      "resetting env. episode reward total was 10.0. running mean: 12.25886797131213\n",
      "resetting env. episode reward total was 12.0. running mean: 12.256279291599007\n",
      "resetting env. episode reward total was 11.0. running mean: 12.243716498683016\n",
      "resetting env. episode reward total was 19.0. running mean: 12.311279333696184\n",
      "resetting env. episode reward total was 10.0. running mean: 12.288166540359223\n",
      "resetting env. episode reward total was 16.0. running mean: 12.32528487495563\n",
      "resetting env. episode reward total was 14.0. running mean: 12.342032026206073\n",
      "resetting env. episode reward total was 17.0. running mean: 12.388611705944012\n",
      "resetting env. episode reward total was 16.0. running mean: 12.424725588884572\n",
      "resetting env. episode reward total was 1.0. running mean: 12.310478332995725\n",
      "resetting env. episode reward total was 12.0. running mean: 12.307373549665767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 12.314299814169111\n",
      "resetting env. episode reward total was 14.0. running mean: 12.33115681602742\n",
      "resetting env. episode reward total was 15.0. running mean: 12.357845247867147\n",
      "resetting env. episode reward total was 10.0. running mean: 12.334266795388475\n",
      "resetting env. episode reward total was 11.0. running mean: 12.320924127434589\n",
      "resetting env. episode reward total was 14.0. running mean: 12.337714886160244\n",
      "resetting env. episode reward total was 15.0. running mean: 12.364337737298642\n",
      "resetting env. episode reward total was 11.0. running mean: 12.350694359925656\n",
      "resetting env. episode reward total was 12.0. running mean: 12.347187416326399\n",
      "resetting env. episode reward total was 14.0. running mean: 12.363715542163135\n",
      "resetting env. episode reward total was 6.0. running mean: 12.300078386741504\n",
      "resetting env. episode reward total was 16.0. running mean: 12.33707760287409\n",
      "resetting env. episode reward total was 9.0. running mean: 12.303706826845348\n",
      "resetting env. episode reward total was 14.0. running mean: 12.320669758576894\n",
      "resetting env. episode reward total was 8.0. running mean: 12.277463060991126\n",
      "resetting env. episode reward total was 15.0. running mean: 12.304688430381216\n",
      "resetting env. episode reward total was 13.0. running mean: 12.311641546077404\n",
      "resetting env. episode reward total was 8.0. running mean: 12.268525130616629\n",
      "resetting env. episode reward total was 13.0. running mean: 12.275839879310464\n",
      "resetting env. episode reward total was 16.0. running mean: 12.31308148051736\n",
      "resetting env. episode reward total was 5.0. running mean: 12.239950665712186\n",
      "resetting env. episode reward total was 13.0. running mean: 12.247551159055066\n",
      "resetting env. episode reward total was 9.0. running mean: 12.215075647464515\n",
      "resetting env. episode reward total was 16.0. running mean: 12.252924890989869\n",
      "resetting env. episode reward total was 16.0. running mean: 12.29039564207997\n",
      "resetting env. episode reward total was 13.0. running mean: 12.297491685659171\n",
      "resetting env. episode reward total was 9.0. running mean: 12.26451676880258\n",
      "resetting env. episode reward total was 18.0. running mean: 12.321871601114553\n",
      "resetting env. episode reward total was 13.0. running mean: 12.32865288510341\n",
      "resetting env. episode reward total was 16.0. running mean: 12.365366356252375\n",
      "resetting env. episode reward total was 9.0. running mean: 12.331712692689852\n",
      "resetting env. episode reward total was 11.0. running mean: 12.318395565762952\n",
      "resetting env. episode reward total was 13.0. running mean: 12.325211610105322\n",
      "resetting env. episode reward total was 6.0. running mean: 12.26195949400427\n",
      "resetting env. episode reward total was 17.0. running mean: 12.309339899064227\n",
      "resetting env. episode reward total was 9.0. running mean: 12.276246500073585\n",
      "resetting env. episode reward total was 12.0. running mean: 12.273484035072848\n",
      "resetting env. episode reward total was 16.0. running mean: 12.310749194722119\n",
      "resetting env. episode reward total was 12.0. running mean: 12.307641702774896\n",
      "resetting env. episode reward total was 10.0. running mean: 12.284565285747147\n",
      "resetting env. episode reward total was 13.0. running mean: 12.291719632889677\n",
      "resetting env. episode reward total was 18.0. running mean: 12.34880243656078\n",
      "resetting env. episode reward total was 14.0. running mean: 12.365314412195172\n",
      "resetting env. episode reward total was 12.0. running mean: 12.361661268073219\n",
      "resetting env. episode reward total was 12.0. running mean: 12.358044655392485\n",
      "resetting env. episode reward total was 16.0. running mean: 12.39446420883856\n",
      "resetting env. episode reward total was 10.0. running mean: 12.370519566750174\n",
      "resetting env. episode reward total was 15.0. running mean: 12.396814371082673\n",
      "resetting env. episode reward total was 12.0. running mean: 12.392846227371846\n",
      "resetting env. episode reward total was 13.0. running mean: 12.398917765098128\n",
      "resetting env. episode reward total was 12.0. running mean: 12.394928587447145\n",
      "resetting env. episode reward total was 11.0. running mean: 12.380979301572673\n",
      "resetting env. episode reward total was 12.0. running mean: 12.377169508556944\n",
      "resetting env. episode reward total was 9.0. running mean: 12.343397813471375\n",
      "resetting env. episode reward total was 7.0. running mean: 12.289963835336662\n",
      "resetting env. episode reward total was 17.0. running mean: 12.337064196983295\n",
      "resetting env. episode reward total was 10.0. running mean: 12.313693555013462\n",
      "resetting env. episode reward total was 10.0. running mean: 12.290556619463327\n",
      "resetting env. episode reward total was 8.0. running mean: 12.247651053268694\n",
      "resetting env. episode reward total was 9.0. running mean: 12.215174542736007\n",
      "resetting env. episode reward total was 8.0. running mean: 12.173022797308647\n",
      "resetting env. episode reward total was 11.0. running mean: 12.16129256933556\n",
      "resetting env. episode reward total was 19.0. running mean: 12.229679643642204\n",
      "resetting env. episode reward total was 10.0. running mean: 12.20738284720578\n",
      "resetting env. episode reward total was 16.0. running mean: 12.245309018733723\n",
      "resetting env. episode reward total was 8.0. running mean: 12.202855928546386\n",
      "resetting env. episode reward total was 14.0. running mean: 12.220827369260922\n",
      "resetting env. episode reward total was 19.0. running mean: 12.288619095568313\n",
      "resetting env. episode reward total was 18.0. running mean: 12.34573290461263\n",
      "resetting env. episode reward total was 11.0. running mean: 12.332275575566504\n",
      "resetting env. episode reward total was 11.0. running mean: 12.318952819810837\n",
      "resetting env. episode reward total was 17.0. running mean: 12.365763291612728\n",
      "resetting env. episode reward total was 12.0. running mean: 12.3621056586966\n",
      "resetting env. episode reward total was 16.0. running mean: 12.398484602109633\n",
      "resetting env. episode reward total was 12.0. running mean: 12.394499756088535\n",
      "resetting env. episode reward total was 12.0. running mean: 12.39055475852765\n",
      "resetting env. episode reward total was 10.0. running mean: 12.366649210942372\n",
      "resetting env. episode reward total was 18.0. running mean: 12.422982718832948\n",
      "resetting env. episode reward total was 17.0. running mean: 12.468752891644618\n",
      "resetting env. episode reward total was 9.0. running mean: 12.434065362728171\n",
      "resetting env. episode reward total was 9.0. running mean: 12.399724709100889\n",
      "resetting env. episode reward total was 14.0. running mean: 12.415727462009881\n",
      "resetting env. episode reward total was 6.0. running mean: 12.351570187389783\n",
      "resetting env. episode reward total was 5.0. running mean: 12.278054485515884\n",
      "resetting env. episode reward total was 19.0. running mean: 12.345273940660725\n",
      "resetting env. episode reward total was 9.0. running mean: 12.311821201254117\n",
      "resetting env. episode reward total was 10.0. running mean: 12.288702989241576\n",
      "resetting env. episode reward total was 13.0. running mean: 12.295815959349161\n",
      "resetting env. episode reward total was 8.0. running mean: 12.25285779975567\n",
      "resetting env. episode reward total was 14.0. running mean: 12.270329221758114\n",
      "resetting env. episode reward total was 14.0. running mean: 12.287625929540534\n",
      "resetting env. episode reward total was 15.0. running mean: 12.314749670245128\n",
      "resetting env. episode reward total was 8.0. running mean: 12.271602173542677\n",
      "resetting env. episode reward total was 9.0. running mean: 12.23888615180725\n",
      "resetting env. episode reward total was 10.0. running mean: 12.216497290289178\n",
      "resetting env. episode reward total was 18.0. running mean: 12.274332317386285\n",
      "resetting env. episode reward total was 14.0. running mean: 12.291588994212423\n",
      "resetting env. episode reward total was 9.0. running mean: 12.258673104270299\n",
      "resetting env. episode reward total was 13.0. running mean: 12.266086373227596\n",
      "resetting env. episode reward total was 6.0. running mean: 12.20342550949532\n",
      "resetting env. episode reward total was 18.0. running mean: 12.261391254400367\n",
      "resetting env. episode reward total was 12.0. running mean: 12.258777341856362\n",
      "resetting env. episode reward total was 12.0. running mean: 12.256189568437797\n",
      "resetting env. episode reward total was 18.0. running mean: 12.31362767275342\n",
      "resetting env. episode reward total was 13.0. running mean: 12.320491396025886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 12.317286482065626\n",
      "resetting env. episode reward total was 14.0. running mean: 12.33411361724497\n",
      "resetting env. episode reward total was 15.0. running mean: 12.360772481072521\n",
      "resetting env. episode reward total was 13.0. running mean: 12.367164756261797\n",
      "resetting env. episode reward total was 12.0. running mean: 12.363493108699178\n",
      "resetting env. episode reward total was 14.0. running mean: 12.379858177612187\n",
      "resetting env. episode reward total was 14.0. running mean: 12.396059595836066\n",
      "resetting env. episode reward total was 9.0. running mean: 12.362098999877706\n",
      "resetting env. episode reward total was 13.0. running mean: 12.36847800987893\n",
      "resetting env. episode reward total was 11.0. running mean: 12.354793229780139\n",
      "resetting env. episode reward total was 9.0. running mean: 12.321245297482337\n",
      "resetting env. episode reward total was 18.0. running mean: 12.378032844507514\n",
      "resetting env. episode reward total was 13.0. running mean: 12.384252516062439\n",
      "resetting env. episode reward total was 13.0. running mean: 12.390409990901816\n",
      "resetting env. episode reward total was 15.0. running mean: 12.416505890992799\n",
      "resetting env. episode reward total was 16.0. running mean: 12.452340832082871\n",
      "resetting env. episode reward total was 16.0. running mean: 12.487817423762042\n",
      "resetting env. episode reward total was 8.0. running mean: 12.442939249524422\n",
      "resetting env. episode reward total was 17.0. running mean: 12.488509857029177\n",
      "resetting env. episode reward total was 14.0. running mean: 12.503624758458885\n",
      "resetting env. episode reward total was 15.0. running mean: 12.528588510874297\n",
      "resetting env. episode reward total was 12.0. running mean: 12.523302625765552\n",
      "resetting env. episode reward total was 13.0. running mean: 12.528069599507898\n",
      "resetting env. episode reward total was 6.0. running mean: 12.46278890351282\n",
      "resetting env. episode reward total was 16.0. running mean: 12.498161014477692\n",
      "resetting env. episode reward total was 11.0. running mean: 12.483179404332914\n",
      "resetting env. episode reward total was 15.0. running mean: 12.508347610289585\n",
      "resetting env. episode reward total was 14.0. running mean: 12.52326413418669\n",
      "resetting env. episode reward total was 15.0. running mean: 12.548031492844823\n",
      "resetting env. episode reward total was 6.0. running mean: 12.482551177916374\n",
      "resetting env. episode reward total was 10.0. running mean: 12.45772566613721\n",
      "resetting env. episode reward total was 2.0. running mean: 12.353148409475837\n",
      "resetting env. episode reward total was 17.0. running mean: 12.399616925381078\n",
      "resetting env. episode reward total was 13.0. running mean: 12.405620756127268\n",
      "resetting env. episode reward total was 14.0. running mean: 12.421564548565996\n",
      "resetting env. episode reward total was 11.0. running mean: 12.407348903080335\n",
      "resetting env. episode reward total was 19.0. running mean: 12.473275414049532\n",
      "resetting env. episode reward total was 3.0. running mean: 12.378542659909035\n",
      "resetting env. episode reward total was 14.0. running mean: 12.394757233309946\n",
      "resetting env. episode reward total was 7.0. running mean: 12.340809660976847\n",
      "resetting env. episode reward total was 17.0. running mean: 12.387401564367078\n",
      "resetting env. episode reward total was 2.0. running mean: 12.283527548723407\n",
      "resetting env. episode reward total was 7.0. running mean: 12.230692273236173\n",
      "resetting env. episode reward total was 16.0. running mean: 12.268385350503811\n",
      "resetting env. episode reward total was 10.0. running mean: 12.245701496998773\n",
      "resetting env. episode reward total was 7.0. running mean: 12.193244482028785\n",
      "resetting env. episode reward total was 15.0. running mean: 12.221312037208497\n",
      "resetting env. episode reward total was 12.0. running mean: 12.219098916836412\n",
      "resetting env. episode reward total was 18.0. running mean: 12.276907927668047\n",
      "resetting env. episode reward total was 10.0. running mean: 12.254138848391365\n",
      "resetting env. episode reward total was 14.0. running mean: 12.271597459907452\n",
      "resetting env. episode reward total was 12.0. running mean: 12.268881485308377\n",
      "resetting env. episode reward total was 11.0. running mean: 12.256192670455292\n",
      "resetting env. episode reward total was 6.0. running mean: 12.19363074375074\n",
      "resetting env. episode reward total was 8.0. running mean: 12.151694436313232\n",
      "resetting env. episode reward total was 19.0. running mean: 12.220177491950098\n",
      "resetting env. episode reward total was 5.0. running mean: 12.147975717030597\n",
      "resetting env. episode reward total was 9.0. running mean: 12.116495959860291\n",
      "resetting env. episode reward total was 12.0. running mean: 12.115331000261687\n",
      "resetting env. episode reward total was 7.0. running mean: 12.06417769025907\n",
      "resetting env. episode reward total was 6.0. running mean: 12.00353591335648\n",
      "resetting env. episode reward total was 10.0. running mean: 11.983500554222914\n",
      "resetting env. episode reward total was 16.0. running mean: 12.023665548680684\n",
      "resetting env. episode reward total was 11.0. running mean: 12.013428893193877\n",
      "resetting env. episode reward total was 9.0. running mean: 11.983294604261939\n",
      "resetting env. episode reward total was 15.0. running mean: 12.01346165821932\n",
      "resetting env. episode reward total was 17.0. running mean: 12.063327041637127\n",
      "resetting env. episode reward total was 15.0. running mean: 12.092693771220755\n",
      "resetting env. episode reward total was 13.0. running mean: 12.101766833508549\n",
      "resetting env. episode reward total was 15.0. running mean: 12.130749165173464\n",
      "resetting env. episode reward total was 13.0. running mean: 12.13944167352173\n",
      "resetting env. episode reward total was 19.0. running mean: 12.208047256786513\n",
      "resetting env. episode reward total was 1.0. running mean: 12.095966784218648\n",
      "resetting env. episode reward total was 12.0. running mean: 12.095007116376461\n",
      "resetting env. episode reward total was 15.0. running mean: 12.124057045212696\n",
      "resetting env. episode reward total was 13.0. running mean: 12.13281647476057\n",
      "resetting env. episode reward total was 8.0. running mean: 12.091488310012965\n",
      "resetting env. episode reward total was 19.0. running mean: 12.160573426912835\n",
      "resetting env. episode reward total was 15.0. running mean: 12.188967692643708\n",
      "resetting env. episode reward total was 16.0. running mean: 12.22707801571727\n",
      "resetting env. episode reward total was 17.0. running mean: 12.274807235560097\n",
      "resetting env. episode reward total was 15.0. running mean: 12.302059163204497\n",
      "resetting env. episode reward total was 14.0. running mean: 12.319038571572452\n",
      "resetting env. episode reward total was 13.0. running mean: 12.325848185856728\n",
      "resetting env. episode reward total was 7.0. running mean: 12.272589703998161\n",
      "resetting env. episode reward total was 8.0. running mean: 12.22986380695818\n",
      "resetting env. episode reward total was 19.0. running mean: 12.297565168888598\n",
      "resetting env. episode reward total was 16.0. running mean: 12.334589517199712\n",
      "resetting env. episode reward total was 14.0. running mean: 12.351243622027715\n",
      "resetting env. episode reward total was 11.0. running mean: 12.337731185807437\n",
      "resetting env. episode reward total was 11.0. running mean: 12.324353873949361\n",
      "resetting env. episode reward total was 12.0. running mean: 12.321110335209866\n",
      "resetting env. episode reward total was 14.0. running mean: 12.337899231857769\n",
      "resetting env. episode reward total was 16.0. running mean: 12.37452023953919\n",
      "resetting env. episode reward total was 13.0. running mean: 12.380775037143799\n",
      "resetting env. episode reward total was 17.0. running mean: 12.42696728677236\n",
      "resetting env. episode reward total was 2.0. running mean: 12.322697613904635\n",
      "resetting env. episode reward total was 12.0. running mean: 12.319470637765589\n",
      "resetting env. episode reward total was 13.0. running mean: 12.326275931387933\n",
      "resetting env. episode reward total was 15.0. running mean: 12.353013172074053\n",
      "resetting env. episode reward total was 18.0. running mean: 12.409483040353313\n",
      "resetting env. episode reward total was 19.0. running mean: 12.475388209949779\n",
      "resetting env. episode reward total was 12.0. running mean: 12.47063432785028\n",
      "resetting env. episode reward total was 11.0. running mean: 12.455927984571778\n",
      "resetting env. episode reward total was 13.0. running mean: 12.46136870472606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 12.3567550176788\n",
      "resetting env. episode reward total was 15.0. running mean: 12.383187467502012\n",
      "resetting env. episode reward total was 15.0. running mean: 12.409355592826993\n",
      "resetting env. episode reward total was 2.0. running mean: 12.305262036898721\n",
      "resetting env. episode reward total was 9.0. running mean: 12.272209416529734\n",
      "resetting env. episode reward total was 16.0. running mean: 12.309487322364436\n",
      "resetting env. episode reward total was 13.0. running mean: 12.316392449140793\n",
      "resetting env. episode reward total was 5.0. running mean: 12.243228524649385\n",
      "resetting env. episode reward total was 9.0. running mean: 12.21079623940289\n",
      "resetting env. episode reward total was 15.0. running mean: 12.238688277008862\n",
      "resetting env. episode reward total was 13.0. running mean: 12.246301394238774\n",
      "resetting env. episode reward total was 17.0. running mean: 12.293838380296386\n",
      "resetting env. episode reward total was 13.0. running mean: 12.300899996493422\n",
      "resetting env. episode reward total was 15.0. running mean: 12.327890996528488\n",
      "resetting env. episode reward total was 13.0. running mean: 12.334612086563205\n",
      "resetting env. episode reward total was 21.0. running mean: 12.421265965697573\n",
      "resetting env. episode reward total was 11.0. running mean: 12.407053306040597\n",
      "resetting env. episode reward total was 8.0. running mean: 12.36298277298019\n",
      "resetting env. episode reward total was 10.0. running mean: 12.339352945250388\n",
      "resetting env. episode reward total was 18.0. running mean: 12.395959415797885\n",
      "resetting env. episode reward total was 12.0. running mean: 12.391999821639905\n",
      "resetting env. episode reward total was 6.0. running mean: 12.328079823423506\n",
      "resetting env. episode reward total was 14.0. running mean: 12.344799025189271\n",
      "resetting env. episode reward total was 16.0. running mean: 12.381351034937378\n",
      "resetting env. episode reward total was 16.0. running mean: 12.417537524588004\n",
      "resetting env. episode reward total was 14.0. running mean: 12.433362149342125\n",
      "resetting env. episode reward total was 17.0. running mean: 12.479028527848703\n",
      "resetting env. episode reward total was 6.0. running mean: 12.414238242570216\n",
      "resetting env. episode reward total was 3.0. running mean: 12.320095860144512\n",
      "resetting env. episode reward total was 15.0. running mean: 12.346894901543067\n",
      "resetting env. episode reward total was 15.0. running mean: 12.373425952527636\n",
      "resetting env. episode reward total was 14.0. running mean: 12.38969169300236\n",
      "resetting env. episode reward total was 13.0. running mean: 12.395794776072337\n",
      "resetting env. episode reward total was 12.0. running mean: 12.391836828311613\n",
      "resetting env. episode reward total was 14.0. running mean: 12.407918460028498\n",
      "resetting env. episode reward total was 15.0. running mean: 12.433839275428213\n",
      "resetting env. episode reward total was 10.0. running mean: 12.40950088267393\n",
      "resetting env. episode reward total was 16.0. running mean: 12.445405873847191\n",
      "resetting env. episode reward total was 4.0. running mean: 12.360951815108718\n",
      "resetting env. episode reward total was 13.0. running mean: 12.367342296957633\n",
      "resetting env. episode reward total was 13.0. running mean: 12.373668873988057\n",
      "resetting env. episode reward total was 13.0. running mean: 12.379932185248178\n",
      "resetting env. episode reward total was 11.0. running mean: 12.366132863395695\n",
      "resetting env. episode reward total was 12.0. running mean: 12.362471534761736\n",
      "resetting env. episode reward total was 16.0. running mean: 12.39884681941412\n",
      "resetting env. episode reward total was 8.0. running mean: 12.354858351219978\n",
      "resetting env. episode reward total was 11.0. running mean: 12.341309767707777\n",
      "resetting env. episode reward total was 11.0. running mean: 12.327896670030698\n",
      "resetting env. episode reward total was 14.0. running mean: 12.344617703330393\n",
      "resetting env. episode reward total was 8.0. running mean: 12.301171526297088\n",
      "resetting env. episode reward total was 15.0. running mean: 12.328159811034118\n",
      "resetting env. episode reward total was 14.0. running mean: 12.344878212923776\n",
      "resetting env. episode reward total was 17.0. running mean: 12.391429430794538\n",
      "resetting env. episode reward total was 18.0. running mean: 12.447515136486592\n",
      "resetting env. episode reward total was 17.0. running mean: 12.493039985121726\n",
      "resetting env. episode reward total was 13.0. running mean: 12.498109585270509\n",
      "resetting env. episode reward total was 4.0. running mean: 12.413128489417803\n",
      "resetting env. episode reward total was 9.0. running mean: 12.378997204523625\n",
      "resetting env. episode reward total was 5.0. running mean: 12.30520723247839\n",
      "resetting env. episode reward total was 8.0. running mean: 12.262155160153606\n",
      "resetting env. episode reward total was 8.0. running mean: 12.21953360855207\n",
      "resetting env. episode reward total was 8.0. running mean: 12.177338272466548\n",
      "resetting env. episode reward total was 15.0. running mean: 12.205564889741883\n",
      "resetting env. episode reward total was 16.0. running mean: 12.243509240844464\n",
      "resetting env. episode reward total was 10.0. running mean: 12.221074148436019\n",
      "resetting env. episode reward total was 14.0. running mean: 12.238863406951658\n",
      "resetting env. episode reward total was 10.0. running mean: 12.216474772882142\n",
      "resetting env. episode reward total was 10.0. running mean: 12.194310025153321\n",
      "resetting env. episode reward total was 16.0. running mean: 12.232366924901788\n",
      "resetting env. episode reward total was 16.0. running mean: 12.27004325565277\n",
      "resetting env. episode reward total was 13.0. running mean: 12.277342823096243\n",
      "resetting env. episode reward total was 18.0. running mean: 12.33456939486528\n",
      "resetting env. episode reward total was 16.0. running mean: 12.371223700916627\n",
      "resetting env. episode reward total was 6.0. running mean: 12.30751146390746\n",
      "resetting env. episode reward total was 14.0. running mean: 12.324436349268385\n",
      "resetting env. episode reward total was 17.0. running mean: 12.3711919857757\n",
      "resetting env. episode reward total was 12.0. running mean: 12.367480065917944\n",
      "resetting env. episode reward total was 9.0. running mean: 12.333805265258764\n",
      "resetting env. episode reward total was 16.0. running mean: 12.370467212606176\n",
      "resetting env. episode reward total was 17.0. running mean: 12.416762540480114\n",
      "resetting env. episode reward total was 17.0. running mean: 12.462594915075313\n",
      "resetting env. episode reward total was 13.0. running mean: 12.46796896592456\n",
      "resetting env. episode reward total was 13.0. running mean: 12.473289276265316\n",
      "resetting env. episode reward total was 12.0. running mean: 12.468556383502662\n",
      "resetting env. episode reward total was 14.0. running mean: 12.483870819667636\n",
      "resetting env. episode reward total was 11.0. running mean: 12.469032111470959\n",
      "resetting env. episode reward total was 14.0. running mean: 12.48434179035625\n",
      "resetting env. episode reward total was 12.0. running mean: 12.479498372452687\n",
      "resetting env. episode reward total was 16.0. running mean: 12.51470338872816\n",
      "resetting env. episode reward total was 8.0. running mean: 12.469556354840877\n",
      "resetting env. episode reward total was 13.0. running mean: 12.47486079129247\n",
      "resetting env. episode reward total was 13.0. running mean: 12.480112183379545\n",
      "resetting env. episode reward total was 7.0. running mean: 12.425311061545749\n",
      "resetting env. episode reward total was 5.0. running mean: 12.351057950930292\n",
      "resetting env. episode reward total was 16.0. running mean: 12.38754737142099\n",
      "resetting env. episode reward total was 12.0. running mean: 12.38367189770678\n",
      "resetting env. episode reward total was 14.0. running mean: 12.399835178729713\n",
      "resetting env. episode reward total was 15.0. running mean: 12.425836826942417\n",
      "resetting env. episode reward total was 19.0. running mean: 12.491578458672992\n",
      "resetting env. episode reward total was 13.0. running mean: 12.496662674086263\n",
      "resetting env. episode reward total was 15.0. running mean: 12.5216960473454\n",
      "resetting env. episode reward total was 15.0. running mean: 12.546479086871948\n",
      "resetting env. episode reward total was 13.0. running mean: 12.55101429600323\n",
      "resetting env. episode reward total was 14.0. running mean: 12.565504153043198\n",
      "resetting env. episode reward total was 14.0. running mean: 12.579849111512766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 12.564050620397637\n",
      "resetting env. episode reward total was 10.0. running mean: 12.53841011419366\n",
      "resetting env. episode reward total was 11.0. running mean: 12.523026013051723\n",
      "resetting env. episode reward total was 16.0. running mean: 12.557795752921205\n",
      "resetting env. episode reward total was 13.0. running mean: 12.562217795391994\n",
      "resetting env. episode reward total was 15.0. running mean: 12.586595617438075\n",
      "resetting env. episode reward total was -1.0. running mean: 12.450729661263694\n",
      "resetting env. episode reward total was 20.0. running mean: 12.526222364651055\n",
      "resetting env. episode reward total was 12.0. running mean: 12.520960141004544\n",
      "resetting env. episode reward total was 10.0. running mean: 12.495750539594498\n",
      "resetting env. episode reward total was 18.0. running mean: 12.550793034198552\n",
      "resetting env. episode reward total was 13.0. running mean: 12.555285103856567\n",
      "resetting env. episode reward total was 8.0. running mean: 12.509732252818\n",
      "resetting env. episode reward total was 15.0. running mean: 12.53463493028982\n",
      "resetting env. episode reward total was 12.0. running mean: 12.529288580986922\n",
      "resetting env. episode reward total was 11.0. running mean: 12.513995695177051\n",
      "resetting env. episode reward total was 14.0. running mean: 12.528855738225282\n",
      "resetting env. episode reward total was 12.0. running mean: 12.523567180843028\n",
      "resetting env. episode reward total was 6.0. running mean: 12.458331509034597\n",
      "resetting env. episode reward total was 15.0. running mean: 12.483748193944251\n",
      "resetting env. episode reward total was 13.0. running mean: 12.48891071200481\n",
      "resetting env. episode reward total was 16.0. running mean: 12.524021604884762\n",
      "resetting env. episode reward total was 14.0. running mean: 12.538781388835915\n",
      "resetting env. episode reward total was 7.0. running mean: 12.483393574947556\n",
      "resetting env. episode reward total was 13.0. running mean: 12.488559639198082\n",
      "resetting env. episode reward total was 13.0. running mean: 12.493674042806102\n",
      "resetting env. episode reward total was 15.0. running mean: 12.51873730237804\n",
      "resetting env. episode reward total was 14.0. running mean: 12.53354992935426\n",
      "resetting env. episode reward total was 8.0. running mean: 12.488214430060717\n",
      "resetting env. episode reward total was 8.0. running mean: 12.44333228576011\n",
      "resetting env. episode reward total was 4.0. running mean: 12.358898962902508\n",
      "resetting env. episode reward total was 16.0. running mean: 12.395309973273482\n",
      "resetting env. episode reward total was 13.0. running mean: 12.401356873540749\n",
      "resetting env. episode reward total was 14.0. running mean: 12.417343304805343\n",
      "resetting env. episode reward total was 10.0. running mean: 12.393169871757289\n",
      "resetting env. episode reward total was 16.0. running mean: 12.429238173039716\n",
      "resetting env. episode reward total was 14.0. running mean: 12.444945791309319\n",
      "resetting env. episode reward total was 18.0. running mean: 12.500496333396226\n",
      "resetting env. episode reward total was 11.0. running mean: 12.485491370062263\n",
      "resetting env. episode reward total was 8.0. running mean: 12.44063645636164\n",
      "resetting env. episode reward total was 10.0. running mean: 12.416230091798022\n",
      "resetting env. episode reward total was 3.0. running mean: 12.322067790880041\n",
      "resetting env. episode reward total was 17.0. running mean: 12.36884711297124\n",
      "resetting env. episode reward total was 10.0. running mean: 12.345158641841527\n",
      "resetting env. episode reward total was 15.0. running mean: 12.371707055423112\n",
      "resetting env. episode reward total was 9.0. running mean: 12.33798998486888\n",
      "resetting env. episode reward total was 13.0. running mean: 12.344610085020191\n",
      "resetting env. episode reward total was 12.0. running mean: 12.341163984169988\n",
      "resetting env. episode reward total was 13.0. running mean: 12.347752344328288\n",
      "resetting env. episode reward total was 11.0. running mean: 12.334274820885005\n",
      "resetting env. episode reward total was 16.0. running mean: 12.370932072676155\n",
      "resetting env. episode reward total was 12.0. running mean: 12.367222751949392\n",
      "resetting env. episode reward total was 6.0. running mean: 12.303550524429898\n",
      "resetting env. episode reward total was 10.0. running mean: 12.280515019185598\n",
      "resetting env. episode reward total was 11.0. running mean: 12.267709868993741\n",
      "resetting env. episode reward total was 15.0. running mean: 12.295032770303804\n",
      "resetting env. episode reward total was 18.0. running mean: 12.352082442600766\n",
      "resetting env. episode reward total was 12.0. running mean: 12.348561618174758\n",
      "resetting env. episode reward total was 13.0. running mean: 12.35507600199301\n",
      "resetting env. episode reward total was 16.0. running mean: 12.391525241973081\n",
      "resetting env. episode reward total was 15.0. running mean: 12.41760998955335\n",
      "resetting env. episode reward total was 17.0. running mean: 12.463433889657816\n",
      "resetting env. episode reward total was 12.0. running mean: 12.458799550761237\n",
      "resetting env. episode reward total was 16.0. running mean: 12.494211555253624\n",
      "resetting env. episode reward total was 14.0. running mean: 12.509269439701088\n",
      "resetting env. episode reward total was 16.0. running mean: 12.544176745304076\n",
      "resetting env. episode reward total was 14.0. running mean: 12.558734977851037\n",
      "resetting env. episode reward total was 10.0. running mean: 12.533147628072527\n",
      "resetting env. episode reward total was 9.0. running mean: 12.4978161517918\n",
      "resetting env. episode reward total was 16.0. running mean: 12.532837990273883\n",
      "resetting env. episode reward total was 17.0. running mean: 12.577509610371145\n",
      "resetting env. episode reward total was 15.0. running mean: 12.601734514267434\n",
      "resetting env. episode reward total was 12.0. running mean: 12.59571716912476\n",
      "resetting env. episode reward total was 11.0. running mean: 12.579759997433511\n",
      "resetting env. episode reward total was 8.0. running mean: 12.533962397459176\n",
      "resetting env. episode reward total was 17.0. running mean: 12.578622773484584\n",
      "resetting env. episode reward total was 7.0. running mean: 12.522836545749739\n",
      "resetting env. episode reward total was 13.0. running mean: 12.527608180292242\n",
      "resetting env. episode reward total was 7.0. running mean: 12.47233209848932\n",
      "resetting env. episode reward total was 14.0. running mean: 12.487608777504427\n",
      "resetting env. episode reward total was 10.0. running mean: 12.462732689729382\n",
      "resetting env. episode reward total was 18.0. running mean: 12.518105362832088\n",
      "resetting env. episode reward total was 13.0. running mean: 12.522924309203768\n",
      "resetting env. episode reward total was 16.0. running mean: 12.55769506611173\n",
      "resetting env. episode reward total was 9.0. running mean: 12.522118115450613\n",
      "resetting env. episode reward total was 16.0. running mean: 12.556896934296107\n",
      "resetting env. episode reward total was 17.0. running mean: 12.601327964953146\n",
      "resetting env. episode reward total was 13.0. running mean: 12.605314685303615\n",
      "resetting env. episode reward total was 14.0. running mean: 12.619261538450578\n",
      "resetting env. episode reward total was 13.0. running mean: 12.623068923066073\n",
      "resetting env. episode reward total was 10.0. running mean: 12.596838233835411\n",
      "resetting env. episode reward total was 14.0. running mean: 12.610869851497057\n",
      "resetting env. episode reward total was 13.0. running mean: 12.614761152982087\n",
      "resetting env. episode reward total was 15.0. running mean: 12.638613541452267\n",
      "resetting env. episode reward total was 13.0. running mean: 12.642227406037746\n",
      "resetting env. episode reward total was 16.0. running mean: 12.675805131977368\n",
      "resetting env. episode reward total was 11.0. running mean: 12.659047080657594\n",
      "resetting env. episode reward total was 15.0. running mean: 12.682456609851018\n",
      "resetting env. episode reward total was 14.0. running mean: 12.695632043752509\n",
      "resetting env. episode reward total was 17.0. running mean: 12.738675723314984\n",
      "resetting env. episode reward total was 14.0. running mean: 12.751288966081834\n",
      "resetting env. episode reward total was 17.0. running mean: 12.793776076421015\n",
      "resetting env. episode reward total was 11.0. running mean: 12.775838315656804\n",
      "resetting env. episode reward total was 15.0. running mean: 12.798079932500237\n",
      "resetting env. episode reward total was 14.0. running mean: 12.810099133175235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 12.811998141843484\n",
      "resetting env. episode reward total was 14.0. running mean: 12.82387816042505\n",
      "resetting env. episode reward total was 15.0. running mean: 12.845639378820799\n",
      "resetting env. episode reward total was 16.0. running mean: 12.877182985032592\n",
      "resetting env. episode reward total was 15.0. running mean: 12.898411155182266\n",
      "resetting env. episode reward total was 13.0. running mean: 12.899427043630444\n",
      "resetting env. episode reward total was 13.0. running mean: 12.90043277319414\n",
      "resetting env. episode reward total was 12.0. running mean: 12.891428445462198\n",
      "resetting env. episode reward total was 10.0. running mean: 12.862514161007576\n",
      "resetting env. episode reward total was 16.0. running mean: 12.8938890193975\n",
      "resetting env. episode reward total was 9.0. running mean: 12.854950129203525\n",
      "resetting env. episode reward total was 14.0. running mean: 12.86640062791149\n",
      "resetting env. episode reward total was 8.0. running mean: 12.817736621632376\n",
      "resetting env. episode reward total was 14.0. running mean: 12.829559255416052\n",
      "resetting env. episode reward total was 16.0. running mean: 12.861263662861893\n",
      "resetting env. episode reward total was 10.0. running mean: 12.832651026233274\n",
      "resetting env. episode reward total was 14.0. running mean: 12.844324515970941\n",
      "resetting env. episode reward total was 13.0. running mean: 12.845881270811232\n",
      "resetting env. episode reward total was 10.0. running mean: 12.817422458103119\n",
      "resetting env. episode reward total was 17.0. running mean: 12.859248233522088\n",
      "resetting env. episode reward total was 13.0. running mean: 12.860655751186867\n",
      "resetting env. episode reward total was 14.0. running mean: 12.872049193674998\n",
      "resetting env. episode reward total was 7.0. running mean: 12.813328701738248\n",
      "resetting env. episode reward total was 19.0. running mean: 12.875195414720865\n",
      "resetting env. episode reward total was 2.0. running mean: 12.766443460573656\n",
      "resetting env. episode reward total was 8.0. running mean: 12.718779025967919\n",
      "resetting env. episode reward total was 10.0. running mean: 12.69159123570824\n",
      "resetting env. episode reward total was -1.0. running mean: 12.554675323351157\n",
      "resetting env. episode reward total was 13.0. running mean: 12.559128570117647\n",
      "resetting env. episode reward total was 17.0. running mean: 12.60353728441647\n",
      "resetting env. episode reward total was 5.0. running mean: 12.527501911572307\n",
      "resetting env. episode reward total was 11.0. running mean: 12.512226892456583\n",
      "resetting env. episode reward total was 14.0. running mean: 12.527104623532018\n",
      "resetting env. episode reward total was 8.0. running mean: 12.481833577296698\n",
      "resetting env. episode reward total was 9.0. running mean: 12.44701524152373\n",
      "resetting env. episode reward total was 15.0. running mean: 12.472545089108491\n",
      "resetting env. episode reward total was 10.0. running mean: 12.447819638217407\n",
      "resetting env. episode reward total was 13.0. running mean: 12.453341441835233\n",
      "resetting env. episode reward total was 9.0. running mean: 12.418808027416882\n",
      "resetting env. episode reward total was 14.0. running mean: 12.434619947142712\n",
      "resetting env. episode reward total was 13.0. running mean: 12.440273747671286\n",
      "resetting env. episode reward total was 12.0. running mean: 12.435871010194573\n",
      "resetting env. episode reward total was 12.0. running mean: 12.431512300092626\n",
      "resetting env. episode reward total was 8.0. running mean: 12.3871971770917\n",
      "resetting env. episode reward total was 10.0. running mean: 12.363325205320782\n",
      "resetting env. episode reward total was 6.0. running mean: 12.299691953267574\n",
      "resetting env. episode reward total was 12.0. running mean: 12.296695033734897\n",
      "resetting env. episode reward total was 15.0. running mean: 12.32372808339755\n",
      "resetting env. episode reward total was 9.0. running mean: 12.290490802563573\n",
      "resetting env. episode reward total was 14.0. running mean: 12.307585894537938\n",
      "resetting env. episode reward total was 7.0. running mean: 12.25451003559256\n",
      "resetting env. episode reward total was 17.0. running mean: 12.301964935236635\n",
      "resetting env. episode reward total was 16.0. running mean: 12.338945285884268\n",
      "resetting env. episode reward total was 14.0. running mean: 12.355555833025425\n",
      "resetting env. episode reward total was 17.0. running mean: 12.40200027469517\n",
      "resetting env. episode reward total was 19.0. running mean: 12.467980271948218\n",
      "resetting env. episode reward total was 10.0. running mean: 12.443300469228735\n",
      "resetting env. episode reward total was 10.0. running mean: 12.418867464536447\n",
      "resetting env. episode reward total was 15.0. running mean: 12.444678789891084\n",
      "resetting env. episode reward total was 9.0. running mean: 12.410232001992172\n",
      "resetting env. episode reward total was 15.0. running mean: 12.43612968197225\n",
      "resetting env. episode reward total was 18.0. running mean: 12.491768385152527\n",
      "resetting env. episode reward total was 18.0. running mean: 12.546850701301002\n",
      "resetting env. episode reward total was 15.0. running mean: 12.571382194287992\n",
      "resetting env. episode reward total was 12.0. running mean: 12.565668372345112\n",
      "resetting env. episode reward total was 17.0. running mean: 12.610011688621661\n",
      "resetting env. episode reward total was 14.0. running mean: 12.623911571735444\n",
      "resetting env. episode reward total was 6.0. running mean: 12.557672456018091\n",
      "resetting env. episode reward total was 13.0. running mean: 12.56209573145791\n",
      "resetting env. episode reward total was 17.0. running mean: 12.606474774143331\n",
      "resetting env. episode reward total was 13.0. running mean: 12.6104100264019\n",
      "resetting env. episode reward total was 18.0. running mean: 12.66430592613788\n",
      "resetting env. episode reward total was 12.0. running mean: 12.6576628668765\n",
      "resetting env. episode reward total was 11.0. running mean: 12.641086238207734\n",
      "resetting env. episode reward total was 18.0. running mean: 12.694675375825657\n",
      "resetting env. episode reward total was 13.0. running mean: 12.697728622067402\n",
      "resetting env. episode reward total was 11.0. running mean: 12.680751335846727\n",
      "resetting env. episode reward total was 7.0. running mean: 12.62394382248826\n",
      "resetting env. episode reward total was 10.0. running mean: 12.597704384263377\n",
      "resetting env. episode reward total was 14.0. running mean: 12.611727340420744\n",
      "resetting env. episode reward total was 14.0. running mean: 12.625610067016536\n",
      "resetting env. episode reward total was 11.0. running mean: 12.60935396634637\n",
      "resetting env. episode reward total was 11.0. running mean: 12.593260426682907\n",
      "resetting env. episode reward total was 12.0. running mean: 12.587327822416077\n",
      "resetting env. episode reward total was 8.0. running mean: 12.541454544191916\n",
      "resetting env. episode reward total was 12.0. running mean: 12.536039998749997\n",
      "resetting env. episode reward total was 14.0. running mean: 12.550679598762498\n",
      "resetting env. episode reward total was 6.0. running mean: 12.485172802774873\n",
      "resetting env. episode reward total was 12.0. running mean: 12.480321074747122\n",
      "resetting env. episode reward total was 14.0. running mean: 12.495517863999652\n",
      "resetting env. episode reward total was 12.0. running mean: 12.490562685359654\n",
      "resetting env. episode reward total was 12.0. running mean: 12.485657058506057\n",
      "resetting env. episode reward total was 9.0. running mean: 12.450800487920995\n",
      "resetting env. episode reward total was 11.0. running mean: 12.436292483041784\n",
      "resetting env. episode reward total was 12.0. running mean: 12.431929558211365\n",
      "resetting env. episode reward total was 6.0. running mean: 12.367610262629253\n",
      "resetting env. episode reward total was 12.0. running mean: 12.363934160002959\n",
      "resetting env. episode reward total was 12.0. running mean: 12.360294818402929\n",
      "resetting env. episode reward total was 18.0. running mean: 12.4166918702189\n",
      "resetting env. episode reward total was 14.0. running mean: 12.432524951516712\n",
      "resetting env. episode reward total was 18.0. running mean: 12.488199702001545\n",
      "resetting env. episode reward total was 13.0. running mean: 12.49331770498153\n",
      "resetting env. episode reward total was 11.0. running mean: 12.478384527931714\n",
      "resetting env. episode reward total was 14.0. running mean: 12.493600682652398\n",
      "resetting env. episode reward total was 10.0. running mean: 12.468664675825874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 12.493978029067616\n",
      "resetting env. episode reward total was 6.0. running mean: 12.42903824877694\n",
      "resetting env. episode reward total was 6.0. running mean: 12.364747866289171\n",
      "resetting env. episode reward total was 15.0. running mean: 12.39110038762628\n",
      "resetting env. episode reward total was 16.0. running mean: 12.427189383750017\n",
      "resetting env. episode reward total was 15.0. running mean: 12.452917489912517\n",
      "resetting env. episode reward total was 8.0. running mean: 12.408388315013392\n",
      "resetting env. episode reward total was 15.0. running mean: 12.434304431863259\n",
      "resetting env. episode reward total was 12.0. running mean: 12.429961387544626\n",
      "resetting env. episode reward total was 14.0. running mean: 12.44566177366918\n",
      "resetting env. episode reward total was 15.0. running mean: 12.471205155932488\n",
      "resetting env. episode reward total was 17.0. running mean: 12.516493104373163\n",
      "resetting env. episode reward total was 12.0. running mean: 12.51132817332943\n",
      "resetting env. episode reward total was 10.0. running mean: 12.486214891596134\n",
      "resetting env. episode reward total was 9.0. running mean: 12.451352742680173\n",
      "resetting env. episode reward total was 19.0. running mean: 12.516839215253372\n",
      "resetting env. episode reward total was 12.0. running mean: 12.511670823100838\n",
      "resetting env. episode reward total was 17.0. running mean: 12.55655411486983\n",
      "resetting env. episode reward total was 11.0. running mean: 12.54098857372113\n",
      "resetting env. episode reward total was 19.0. running mean: 12.605578687983918\n",
      "resetting env. episode reward total was 14.0. running mean: 12.61952290110408\n",
      "resetting env. episode reward total was 14.0. running mean: 12.63332767209304\n",
      "resetting env. episode reward total was 15.0. running mean: 12.65699439537211\n",
      "resetting env. episode reward total was 1.0. running mean: 12.540424451418389\n",
      "resetting env. episode reward total was 14.0. running mean: 12.555020206904205\n",
      "resetting env. episode reward total was 16.0. running mean: 12.589470004835162\n",
      "resetting env. episode reward total was 12.0. running mean: 12.583575304786809\n",
      "resetting env. episode reward total was 15.0. running mean: 12.607739551738941\n",
      "resetting env. episode reward total was 11.0. running mean: 12.59166215622155\n",
      "resetting env. episode reward total was 9.0. running mean: 12.555745534659335\n",
      "resetting env. episode reward total was 9.0. running mean: 12.520188079312742\n",
      "resetting env. episode reward total was 13.0. running mean: 12.524986198519615\n",
      "resetting env. episode reward total was 16.0. running mean: 12.559736336534419\n",
      "resetting env. episode reward total was 16.0. running mean: 12.594138973169075\n",
      "resetting env. episode reward total was 14.0. running mean: 12.608197583437384\n",
      "resetting env. episode reward total was 15.0. running mean: 12.63211560760301\n",
      "resetting env. episode reward total was 7.0. running mean: 12.575794451526981\n",
      "resetting env. episode reward total was 12.0. running mean: 12.57003650701171\n",
      "resetting env. episode reward total was 12.0. running mean: 12.564336141941594\n",
      "resetting env. episode reward total was 11.0. running mean: 12.548692780522178\n",
      "resetting env. episode reward total was 10.0. running mean: 12.523205852716956\n",
      "resetting env. episode reward total was 14.0. running mean: 12.537973794189787\n",
      "resetting env. episode reward total was 9.0. running mean: 12.502594056247888\n",
      "resetting env. episode reward total was 14.0. running mean: 12.51756811568541\n",
      "resetting env. episode reward total was 10.0. running mean: 12.492392434528556\n",
      "resetting env. episode reward total was 8.0. running mean: 12.44746851018327\n",
      "resetting env. episode reward total was 12.0. running mean: 12.442993825081437\n",
      "resetting env. episode reward total was 2.0. running mean: 12.338563886830622\n",
      "resetting env. episode reward total was 11.0. running mean: 12.325178247962315\n",
      "resetting env. episode reward total was 20.0. running mean: 12.40192646548269\n",
      "resetting env. episode reward total was 10.0. running mean: 12.377907200827863\n",
      "resetting env. episode reward total was 15.0. running mean: 12.404128128819584\n",
      "resetting env. episode reward total was 12.0. running mean: 12.400086847531387\n",
      "resetting env. episode reward total was 13.0. running mean: 12.406085979056074\n",
      "resetting env. episode reward total was 8.0. running mean: 12.362025119265514\n",
      "resetting env. episode reward total was 14.0. running mean: 12.37840486807286\n",
      "resetting env. episode reward total was 9.0. running mean: 12.34462081939213\n",
      "resetting env. episode reward total was 10.0. running mean: 12.321174611198208\n",
      "resetting env. episode reward total was 13.0. running mean: 12.327962865086226\n",
      "resetting env. episode reward total was 5.0. running mean: 12.254683236435364\n",
      "resetting env. episode reward total was 17.0. running mean: 12.30213640407101\n",
      "resetting env. episode reward total was 12.0. running mean: 12.2991150400303\n",
      "resetting env. episode reward total was 17.0. running mean: 12.346123889629997\n",
      "resetting env. episode reward total was 13.0. running mean: 12.352662650733697\n",
      "resetting env. episode reward total was 16.0. running mean: 12.38913602422636\n",
      "resetting env. episode reward total was 13.0. running mean: 12.395244663984098\n",
      "resetting env. episode reward total was 17.0. running mean: 12.441292217344257\n",
      "resetting env. episode reward total was 5.0. running mean: 12.366879295170815\n",
      "resetting env. episode reward total was 10.0. running mean: 12.343210502219106\n",
      "resetting env. episode reward total was 6.0. running mean: 12.279778397196916\n",
      "resetting env. episode reward total was 13.0. running mean: 12.286980613224948\n",
      "resetting env. episode reward total was 16.0. running mean: 12.324110807092698\n",
      "resetting env. episode reward total was 15.0. running mean: 12.350869699021771\n",
      "resetting env. episode reward total was 15.0. running mean: 12.377361002031554\n",
      "resetting env. episode reward total was 18.0. running mean: 12.433587392011239\n",
      "resetting env. episode reward total was 12.0. running mean: 12.429251518091126\n",
      "resetting env. episode reward total was 14.0. running mean: 12.444959002910215\n",
      "resetting env. episode reward total was 11.0. running mean: 12.430509412881113\n",
      "resetting env. episode reward total was 9.0. running mean: 12.396204318752302\n",
      "resetting env. episode reward total was 11.0. running mean: 12.382242275564778\n",
      "resetting env. episode reward total was 15.0. running mean: 12.40841985280913\n",
      "resetting env. episode reward total was 14.0. running mean: 12.42433565428104\n",
      "resetting env. episode reward total was 13.0. running mean: 12.430092297738229\n",
      "resetting env. episode reward total was 6.0. running mean: 12.365791374760846\n",
      "resetting env. episode reward total was 12.0. running mean: 12.362133461013237\n",
      "resetting env. episode reward total was 12.0. running mean: 12.358512126403102\n",
      "resetting env. episode reward total was 10.0. running mean: 12.33492700513907\n",
      "resetting env. episode reward total was 12.0. running mean: 12.331577735087679\n",
      "resetting env. episode reward total was 15.0. running mean: 12.358261957736802\n",
      "resetting env. episode reward total was 12.0. running mean: 12.354679338159434\n",
      "resetting env. episode reward total was 15.0. running mean: 12.38113254477784\n",
      "resetting env. episode reward total was 15.0. running mean: 12.407321219330061\n",
      "resetting env. episode reward total was 10.0. running mean: 12.38324800713676\n",
      "resetting env. episode reward total was 14.0. running mean: 12.399415527065393\n",
      "resetting env. episode reward total was 8.0. running mean: 12.355421371794739\n",
      "resetting env. episode reward total was 19.0. running mean: 12.421867158076791\n",
      "resetting env. episode reward total was 14.0. running mean: 12.437648486496023\n",
      "resetting env. episode reward total was 10.0. running mean: 12.413272001631062\n",
      "resetting env. episode reward total was 11.0. running mean: 12.399139281614751\n",
      "resetting env. episode reward total was 10.0. running mean: 12.375147888798603\n",
      "resetting env. episode reward total was 17.0. running mean: 12.421396409910617\n",
      "resetting env. episode reward total was 5.0. running mean: 12.347182445811512\n",
      "resetting env. episode reward total was 15.0. running mean: 12.373710621353398\n",
      "resetting env. episode reward total was 18.0. running mean: 12.429973515139864\n",
      "resetting env. episode reward total was 12.0. running mean: 12.425673779988465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 12.38141704218858\n",
      "resetting env. episode reward total was 8.0. running mean: 12.337602871766695\n",
      "resetting env. episode reward total was 14.0. running mean: 12.354226843049029\n",
      "resetting env. episode reward total was 11.0. running mean: 12.340684574618537\n",
      "resetting env. episode reward total was 15.0. running mean: 12.367277728872352\n",
      "resetting env. episode reward total was 14.0. running mean: 12.38360495158363\n",
      "resetting env. episode reward total was 13.0. running mean: 12.389768902067795\n",
      "resetting env. episode reward total was 11.0. running mean: 12.375871213047116\n",
      "resetting env. episode reward total was 14.0. running mean: 12.392112500916646\n",
      "resetting env. episode reward total was 9.0. running mean: 12.358191375907479\n",
      "resetting env. episode reward total was 15.0. running mean: 12.384609462148404\n",
      "resetting env. episode reward total was 9.0. running mean: 12.35076336752692\n",
      "resetting env. episode reward total was 15.0. running mean: 12.377255733851651\n",
      "resetting env. episode reward total was 17.0. running mean: 12.423483176513134\n",
      "resetting env. episode reward total was 10.0. running mean: 12.399248344748003\n",
      "resetting env. episode reward total was 10.0. running mean: 12.375255861300522\n",
      "resetting env. episode reward total was 11.0. running mean: 12.361503302687515\n",
      "resetting env. episode reward total was 14.0. running mean: 12.377888269660641\n",
      "resetting env. episode reward total was 12.0. running mean: 12.374109386964033\n",
      "resetting env. episode reward total was 14.0. running mean: 12.390368293094394\n",
      "resetting env. episode reward total was 14.0. running mean: 12.40646461016345\n",
      "resetting env. episode reward total was 8.0. running mean: 12.362399964061815\n",
      "resetting env. episode reward total was -1.0. running mean: 12.228775964421198\n",
      "resetting env. episode reward total was 6.0. running mean: 12.166488204776986\n",
      "resetting env. episode reward total was 15.0. running mean: 12.194823322729215\n",
      "resetting env. episode reward total was 16.0. running mean: 12.232875089501924\n",
      "resetting env. episode reward total was 6.0. running mean: 12.170546338606906\n",
      "resetting env. episode reward total was 14.0. running mean: 12.188840875220837\n",
      "resetting env. episode reward total was 18.0. running mean: 12.246952466468628\n",
      "resetting env. episode reward total was 13.0. running mean: 12.254482941803943\n",
      "resetting env. episode reward total was 12.0. running mean: 12.251938112385902\n",
      "resetting env. episode reward total was 1.0. running mean: 12.139418731262044\n",
      "resetting env. episode reward total was 9.0. running mean: 12.108024543949423\n",
      "resetting env. episode reward total was 14.0. running mean: 12.12694429850993\n",
      "resetting env. episode reward total was 16.0. running mean: 12.16567485552483\n",
      "resetting env. episode reward total was 13.0. running mean: 12.174018106969584\n",
      "resetting env. episode reward total was 11.0. running mean: 12.162277925899888\n",
      "resetting env. episode reward total was 12.0. running mean: 12.160655146640888\n",
      "resetting env. episode reward total was 11.0. running mean: 12.149048595174479\n",
      "resetting env. episode reward total was 10.0. running mean: 12.127558109222734\n",
      "resetting env. episode reward total was 8.0. running mean: 12.086282528130507\n",
      "resetting env. episode reward total was 12.0. running mean: 12.085419702849201\n",
      "resetting env. episode reward total was 9.0. running mean: 12.054565505820708\n",
      "resetting env. episode reward total was 14.0. running mean: 12.074019850762502\n",
      "resetting env. episode reward total was 11.0. running mean: 12.063279652254876\n",
      "resetting env. episode reward total was 11.0. running mean: 12.052646855732327\n",
      "resetting env. episode reward total was 9.0. running mean: 12.022120387175004\n",
      "resetting env. episode reward total was 15.0. running mean: 12.051899183303254\n",
      "resetting env. episode reward total was 17.0. running mean: 12.101380191470222\n",
      "resetting env. episode reward total was 13.0. running mean: 12.11036638955552\n",
      "resetting env. episode reward total was 15.0. running mean: 12.139262725659965\n",
      "resetting env. episode reward total was 6.0. running mean: 12.077870098403364\n",
      "resetting env. episode reward total was 14.0. running mean: 12.097091397419332\n",
      "resetting env. episode reward total was 13.0. running mean: 12.106120483445139\n",
      "resetting env. episode reward total was 12.0. running mean: 12.105059278610687\n",
      "resetting env. episode reward total was 9.0. running mean: 12.07400868582458\n",
      "resetting env. episode reward total was 12.0. running mean: 12.073268598966333\n",
      "resetting env. episode reward total was 12.0. running mean: 12.072535912976669\n",
      "resetting env. episode reward total was 16.0. running mean: 12.111810553846903\n",
      "resetting env. episode reward total was 10.0. running mean: 12.090692448308433\n",
      "resetting env. episode reward total was 16.0. running mean: 12.12978552382535\n",
      "resetting env. episode reward total was 14.0. running mean: 12.148487668587096\n",
      "resetting env. episode reward total was 9.0. running mean: 12.117002791901225\n",
      "resetting env. episode reward total was 13.0. running mean: 12.125832763982213\n",
      "resetting env. episode reward total was 13.0. running mean: 12.134574436342392\n",
      "resetting env. episode reward total was 12.0. running mean: 12.133228691978967\n",
      "resetting env. episode reward total was 11.0. running mean: 12.121896405059177\n",
      "resetting env. episode reward total was 15.0. running mean: 12.150677441008586\n",
      "resetting env. episode reward total was 13.0. running mean: 12.1591706665985\n",
      "resetting env. episode reward total was 11.0. running mean: 12.147578959932515\n",
      "resetting env. episode reward total was 10.0. running mean: 12.12610317033319\n",
      "resetting env. episode reward total was 11.0. running mean: 12.114842138629857\n",
      "resetting env. episode reward total was 11.0. running mean: 12.103693717243559\n",
      "resetting env. episode reward total was 7.0. running mean: 12.052656780071123\n",
      "resetting env. episode reward total was 10.0. running mean: 12.032130212270411\n",
      "resetting env. episode reward total was 4.0. running mean: 11.951808910147706\n",
      "resetting env. episode reward total was 14.0. running mean: 11.97229082104623\n",
      "resetting env. episode reward total was 12.0. running mean: 11.972567912835766\n",
      "resetting env. episode reward total was 6.0. running mean: 11.912842233707408\n",
      "resetting env. episode reward total was 5.0. running mean: 11.843713811370336\n",
      "resetting env. episode reward total was 13.0. running mean: 11.855276673256633\n",
      "resetting env. episode reward total was 17.0. running mean: 11.906723906524066\n",
      "resetting env. episode reward total was 10.0. running mean: 11.887656667458824\n",
      "resetting env. episode reward total was 13.0. running mean: 11.898780100784236\n",
      "resetting env. episode reward total was 19.0. running mean: 11.969792299776394\n",
      "resetting env. episode reward total was 19.0. running mean: 12.04009437677863\n",
      "resetting env. episode reward total was 5.0. running mean: 11.969693433010844\n",
      "resetting env. episode reward total was 16.0. running mean: 12.009996498680737\n",
      "resetting env. episode reward total was 7.0. running mean: 11.95989653369393\n",
      "resetting env. episode reward total was 11.0. running mean: 11.95029756835699\n",
      "resetting env. episode reward total was 10.0. running mean: 11.93079459267342\n",
      "resetting env. episode reward total was 13.0. running mean: 11.941486646746688\n",
      "resetting env. episode reward total was 9.0. running mean: 11.91207178027922\n",
      "resetting env. episode reward total was 7.0. running mean: 11.862951062476428\n",
      "resetting env. episode reward total was 15.0. running mean: 11.894321551851665\n",
      "resetting env. episode reward total was 10.0. running mean: 11.875378336333148\n",
      "resetting env. episode reward total was 15.0. running mean: 11.906624552969816\n",
      "resetting env. episode reward total was 15.0. running mean: 11.937558307440119\n",
      "resetting env. episode reward total was 18.0. running mean: 11.998182724365718\n",
      "resetting env. episode reward total was 14.0. running mean: 12.01820089712206\n",
      "resetting env. episode reward total was 14.0. running mean: 12.038018888150841\n",
      "resetting env. episode reward total was 9.0. running mean: 12.007638699269332\n",
      "resetting env. episode reward total was 14.0. running mean: 12.02756231227664\n",
      "resetting env. episode reward total was 11.0. running mean: 12.017286689153872\n",
      "resetting env. episode reward total was 16.0. running mean: 12.057113822262334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 12.066542684039712\n",
      "resetting env. episode reward total was 16.0. running mean: 12.105877257199316\n",
      "resetting env. episode reward total was 11.0. running mean: 12.094818484627321\n",
      "resetting env. episode reward total was 9.0. running mean: 12.063870299781048\n",
      "resetting env. episode reward total was 12.0. running mean: 12.063231596783236\n",
      "resetting env. episode reward total was 18.0. running mean: 12.122599280815404\n",
      "resetting env. episode reward total was 15.0. running mean: 12.15137328800725\n",
      "resetting env. episode reward total was 16.0. running mean: 12.189859555127176\n",
      "resetting env. episode reward total was 12.0. running mean: 12.187960959575904\n",
      "resetting env. episode reward total was 17.0. running mean: 12.236081349980145\n",
      "resetting env. episode reward total was 13.0. running mean: 12.243720536480344\n",
      "resetting env. episode reward total was 8.0. running mean: 12.20128333111554\n",
      "resetting env. episode reward total was 7.0. running mean: 12.149270497804386\n",
      "resetting env. episode reward total was 14.0. running mean: 12.167777792826342\n",
      "resetting env. episode reward total was 8.0. running mean: 12.126100014898078\n",
      "resetting env. episode reward total was 12.0. running mean: 12.124839014749096\n",
      "resetting env. episode reward total was 16.0. running mean: 12.163590624601605\n",
      "resetting env. episode reward total was 13.0. running mean: 12.17195471835559\n",
      "resetting env. episode reward total was 10.0. running mean: 12.150235171172033\n",
      "resetting env. episode reward total was 14.0. running mean: 12.168732819460313\n",
      "resetting env. episode reward total was 13.0. running mean: 12.17704549126571\n",
      "resetting env. episode reward total was 15.0. running mean: 12.205275036353054\n",
      "resetting env. episode reward total was 10.0. running mean: 12.183222285989523\n",
      "resetting env. episode reward total was 6.0. running mean: 12.121390063129628\n",
      "resetting env. episode reward total was 10.0. running mean: 12.10017616249833\n",
      "resetting env. episode reward total was 4.0. running mean: 12.019174400873347\n",
      "resetting env. episode reward total was 13.0. running mean: 12.028982656864613\n",
      "resetting env. episode reward total was 13.0. running mean: 12.038692830295968\n",
      "resetting env. episode reward total was 14.0. running mean: 12.058305901993009\n",
      "resetting env. episode reward total was 17.0. running mean: 12.107722842973079\n",
      "resetting env. episode reward total was 12.0. running mean: 12.106645614543346\n",
      "resetting env. episode reward total was 9.0. running mean: 12.075579158397913\n",
      "resetting env. episode reward total was 13.0. running mean: 12.084823366813934\n",
      "resetting env. episode reward total was 14.0. running mean: 12.103975133145795\n",
      "resetting env. episode reward total was 7.0. running mean: 12.052935381814336\n",
      "resetting env. episode reward total was 13.0. running mean: 12.062406027996193\n",
      "resetting env. episode reward total was 8.0. running mean: 12.021781967716231\n",
      "resetting env. episode reward total was 15.0. running mean: 12.05156414803907\n",
      "resetting env. episode reward total was 18.0. running mean: 12.111048506558678\n",
      "resetting env. episode reward total was 10.0. running mean: 12.08993802149309\n",
      "resetting env. episode reward total was 4.0. running mean: 12.009038641278158\n",
      "resetting env. episode reward total was 12.0. running mean: 12.008948254865375\n",
      "resetting env. episode reward total was 13.0. running mean: 12.018858772316722\n",
      "resetting env. episode reward total was 11.0. running mean: 12.008670184593555\n",
      "resetting env. episode reward total was 15.0. running mean: 12.03858348274762\n",
      "resetting env. episode reward total was 11.0. running mean: 12.028197647920143\n",
      "resetting env. episode reward total was 12.0. running mean: 12.02791567144094\n",
      "resetting env. episode reward total was 13.0. running mean: 12.03763651472653\n",
      "resetting env. episode reward total was 12.0. running mean: 12.037260149579264\n",
      "resetting env. episode reward total was 12.0. running mean: 12.03688754808347\n",
      "resetting env. episode reward total was 2.0. running mean: 11.936518672602634\n",
      "resetting env. episode reward total was 12.0. running mean: 11.937153485876607\n",
      "resetting env. episode reward total was 8.0. running mean: 11.89778195101784\n",
      "resetting env. episode reward total was 17.0. running mean: 11.948804131507663\n",
      "resetting env. episode reward total was 14.0. running mean: 11.969316090192587\n",
      "resetting env. episode reward total was 14.0. running mean: 11.989622929290661\n",
      "resetting env. episode reward total was 8.0. running mean: 11.949726699997754\n",
      "resetting env. episode reward total was 18.0. running mean: 12.010229432997777\n",
      "resetting env. episode reward total was 15.0. running mean: 12.040127138667799\n",
      "resetting env. episode reward total was 11.0. running mean: 12.02972586728112\n",
      "resetting env. episode reward total was 14.0. running mean: 12.04942860860831\n",
      "resetting env. episode reward total was 18.0. running mean: 12.108934322522225\n",
      "resetting env. episode reward total was 15.0. running mean: 12.137844979297004\n",
      "resetting env. episode reward total was 13.0. running mean: 12.146466529504034\n",
      "resetting env. episode reward total was 11.0. running mean: 12.135001864208993\n",
      "resetting env. episode reward total was 12.0. running mean: 12.133651845566902\n",
      "resetting env. episode reward total was 11.0. running mean: 12.122315327111233\n",
      "resetting env. episode reward total was 10.0. running mean: 12.10109217384012\n",
      "resetting env. episode reward total was 11.0. running mean: 12.090081252101719\n",
      "resetting env. episode reward total was 18.0. running mean: 12.149180439580702\n",
      "resetting env. episode reward total was 12.0. running mean: 12.147688635184894\n",
      "resetting env. episode reward total was 17.0. running mean: 12.196211748833045\n",
      "resetting env. episode reward total was 11.0. running mean: 12.184249631344715\n",
      "resetting env. episode reward total was 14.0. running mean: 12.202407135031267\n",
      "resetting env. episode reward total was 13.0. running mean: 12.210383063680956\n",
      "resetting env. episode reward total was 12.0. running mean: 12.208279233044145\n",
      "resetting env. episode reward total was 18.0. running mean: 12.266196440713703\n",
      "resetting env. episode reward total was 11.0. running mean: 12.253534476306566\n",
      "resetting env. episode reward total was 15.0. running mean: 12.280999131543501\n",
      "resetting env. episode reward total was 1.0. running mean: 12.168189140228066\n",
      "resetting env. episode reward total was 15.0. running mean: 12.196507248825785\n",
      "resetting env. episode reward total was 15.0. running mean: 12.224542176337527\n",
      "resetting env. episode reward total was 10.0. running mean: 12.202296754574151\n",
      "resetting env. episode reward total was 11.0. running mean: 12.190273787028408\n",
      "resetting env. episode reward total was 12.0. running mean: 12.188371049158123\n",
      "resetting env. episode reward total was 12.0. running mean: 12.186487338666542\n",
      "resetting env. episode reward total was 6.0. running mean: 12.124622465279877\n",
      "resetting env. episode reward total was 9.0. running mean: 12.093376240627078\n",
      "resetting env. episode reward total was 15.0. running mean: 12.122442478220808\n",
      "resetting env. episode reward total was 9.0. running mean: 12.0912180534386\n",
      "resetting env. episode reward total was 8.0. running mean: 12.050305872904215\n",
      "resetting env. episode reward total was 15.0. running mean: 12.079802814175173\n",
      "resetting env. episode reward total was 14.0. running mean: 12.09900478603342\n",
      "resetting env. episode reward total was 1.0. running mean: 11.988014738173085\n",
      "resetting env. episode reward total was 18.0. running mean: 12.048134590791355\n",
      "resetting env. episode reward total was 16.0. running mean: 12.087653244883441\n",
      "resetting env. episode reward total was 11.0. running mean: 12.076776712434606\n",
      "resetting env. episode reward total was 11.0. running mean: 12.066008945310259\n",
      "resetting env. episode reward total was 10.0. running mean: 12.045348855857155\n",
      "resetting env. episode reward total was 16.0. running mean: 12.084895367298584\n",
      "resetting env. episode reward total was 14.0. running mean: 12.104046413625598\n",
      "resetting env. episode reward total was 11.0. running mean: 12.093005949489342\n",
      "resetting env. episode reward total was 11.0. running mean: 12.082075889994448\n",
      "resetting env. episode reward total was 11.0. running mean: 12.071255131094503\n",
      "resetting env. episode reward total was 11.0. running mean: 12.060542579783558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 12.089937153985723\n",
      "resetting env. episode reward total was 12.0. running mean: 12.089037782445864\n",
      "resetting env. episode reward total was 8.0. running mean: 12.048147404621405\n",
      "resetting env. episode reward total was 13.0. running mean: 12.057665930575192\n",
      "resetting env. episode reward total was 12.0. running mean: 12.057089271269438\n",
      "resetting env. episode reward total was 17.0. running mean: 12.106518378556745\n",
      "resetting env. episode reward total was 19.0. running mean: 12.175453194771176\n",
      "resetting env. episode reward total was 11.0. running mean: 12.163698662823464\n",
      "resetting env. episode reward total was 7.0. running mean: 12.112061676195228\n",
      "resetting env. episode reward total was 8.0. running mean: 12.070941059433276\n",
      "resetting env. episode reward total was 11.0. running mean: 12.060231648838942\n",
      "resetting env. episode reward total was 11.0. running mean: 12.049629332350552\n",
      "resetting env. episode reward total was 9.0. running mean: 12.019133039027047\n",
      "resetting env. episode reward total was 17.0. running mean: 12.068941708636777\n",
      "resetting env. episode reward total was 14.0. running mean: 12.08825229155041\n",
      "resetting env. episode reward total was 13.0. running mean: 12.097369768634906\n",
      "resetting env. episode reward total was 15.0. running mean: 12.126396070948557\n",
      "resetting env. episode reward total was 12.0. running mean: 12.12513211023907\n",
      "resetting env. episode reward total was 11.0. running mean: 12.11388078913668\n",
      "resetting env. episode reward total was 12.0. running mean: 12.112741981245312\n",
      "resetting env. episode reward total was 8.0. running mean: 12.07161456143286\n",
      "resetting env. episode reward total was 9.0. running mean: 12.04089841581853\n",
      "resetting env. episode reward total was 14.0. running mean: 12.060489431660345\n",
      "resetting env. episode reward total was 16.0. running mean: 12.099884537343742\n",
      "resetting env. episode reward total was 12.0. running mean: 12.098885691970304\n",
      "resetting env. episode reward total was 11.0. running mean: 12.0878968350506\n",
      "resetting env. episode reward total was 13.0. running mean: 12.097017866700094\n",
      "resetting env. episode reward total was 10.0. running mean: 12.076047688033093\n",
      "resetting env. episode reward total was 14.0. running mean: 12.095287211152762\n",
      "resetting env. episode reward total was 18.0. running mean: 12.154334339041235\n",
      "resetting env. episode reward total was 13.0. running mean: 12.162790995650823\n",
      "resetting env. episode reward total was 17.0. running mean: 12.211163085694315\n",
      "resetting env. episode reward total was 11.0. running mean: 12.19905145483737\n",
      "resetting env. episode reward total was 11.0. running mean: 12.187060940288996\n",
      "resetting env. episode reward total was 13.0. running mean: 12.195190330886106\n",
      "resetting env. episode reward total was 15.0. running mean: 12.223238427577245\n",
      "resetting env. episode reward total was 13.0. running mean: 12.231006043301473\n",
      "resetting env. episode reward total was 12.0. running mean: 12.228695982868457\n",
      "resetting env. episode reward total was 12.0. running mean: 12.226409023039771\n",
      "resetting env. episode reward total was 10.0. running mean: 12.204144932809372\n",
      "resetting env. episode reward total was 12.0. running mean: 12.202103483481277\n",
      "resetting env. episode reward total was 15.0. running mean: 12.230082448646465\n",
      "resetting env. episode reward total was 10.0. running mean: 12.20778162416\n",
      "resetting env. episode reward total was 10.0. running mean: 12.1857038079184\n",
      "resetting env. episode reward total was 10.0. running mean: 12.163846769839216\n",
      "resetting env. episode reward total was 12.0. running mean: 12.162208302140822\n",
      "resetting env. episode reward total was 14.0. running mean: 12.180586219119414\n",
      "resetting env. episode reward total was 4.0. running mean: 12.098780356928218\n",
      "resetting env. episode reward total was 15.0. running mean: 12.127792553358937\n",
      "resetting env. episode reward total was 14.0. running mean: 12.146514627825347\n",
      "resetting env. episode reward total was 14.0. running mean: 12.165049481547094\n",
      "resetting env. episode reward total was 14.0. running mean: 12.183398986731623\n",
      "resetting env. episode reward total was 7.0. running mean: 12.131564996864308\n",
      "resetting env. episode reward total was 7.0. running mean: 12.080249346895664\n",
      "resetting env. episode reward total was 15.0. running mean: 12.109446853426707\n",
      "resetting env. episode reward total was 14.0. running mean: 12.128352384892441\n",
      "resetting env. episode reward total was 8.0. running mean: 12.087068861043516\n",
      "resetting env. episode reward total was 18.0. running mean: 12.146198172433081\n",
      "resetting env. episode reward total was 9.0. running mean: 12.11473619070875\n",
      "resetting env. episode reward total was 12.0. running mean: 12.113588828801662\n",
      "resetting env. episode reward total was 11.0. running mean: 12.102452940513645\n",
      "resetting env. episode reward total was 16.0. running mean: 12.141428411108508\n",
      "resetting env. episode reward total was 4.0. running mean: 12.060014126997423\n",
      "resetting env. episode reward total was 3.0. running mean: 11.969413985727448\n",
      "resetting env. episode reward total was 12.0. running mean: 11.969719845870172\n",
      "resetting env. episode reward total was 14.0. running mean: 11.99002264741147\n",
      "resetting env. episode reward total was 16.0. running mean: 12.030122420937355\n",
      "resetting env. episode reward total was 17.0. running mean: 12.07982119672798\n",
      "resetting env. episode reward total was 14.0. running mean: 12.099022984760701\n",
      "resetting env. episode reward total was 15.0. running mean: 12.128032754913095\n",
      "resetting env. episode reward total was 12.0. running mean: 12.126752427363963\n",
      "resetting env. episode reward total was 12.0. running mean: 12.125484903090323\n",
      "resetting env. episode reward total was 12.0. running mean: 12.124230054059419\n",
      "resetting env. episode reward total was 13.0. running mean: 12.132987753518826\n",
      "resetting env. episode reward total was 3.0. running mean: 12.041657875983637\n",
      "resetting env. episode reward total was 15.0. running mean: 12.0712412972238\n",
      "resetting env. episode reward total was 2.0. running mean: 11.97052888425156\n",
      "resetting env. episode reward total was 11.0. running mean: 11.960823595409044\n",
      "resetting env. episode reward total was 10.0. running mean: 11.941215359454953\n",
      "resetting env. episode reward total was 15.0. running mean: 11.971803205860404\n",
      "resetting env. episode reward total was 16.0. running mean: 12.0120851738018\n",
      "resetting env. episode reward total was 14.0. running mean: 12.031964322063782\n",
      "resetting env. episode reward total was 15.0. running mean: 12.061644678843145\n",
      "resetting env. episode reward total was 9.0. running mean: 12.031028232054712\n",
      "resetting env. episode reward total was 11.0. running mean: 12.020717949734165\n",
      "resetting env. episode reward total was 9.0. running mean: 11.990510770236822\n",
      "resetting env. episode reward total was 6.0. running mean: 11.930605662534454\n",
      "resetting env. episode reward total was 15.0. running mean: 11.96129960590911\n",
      "resetting env. episode reward total was 12.0. running mean: 11.961686609850018\n",
      "resetting env. episode reward total was 11.0. running mean: 11.952069743751517\n",
      "resetting env. episode reward total was 18.0. running mean: 12.012549046314001\n",
      "resetting env. episode reward total was 5.0. running mean: 11.942423555850862\n",
      "resetting env. episode reward total was 14.0. running mean: 11.962999320292354\n",
      "resetting env. episode reward total was 14.0. running mean: 11.98336932708943\n",
      "resetting env. episode reward total was 16.0. running mean: 12.023535633818536\n",
      "resetting env. episode reward total was 13.0. running mean: 12.033300277480352\n",
      "resetting env. episode reward total was 18.0. running mean: 12.092967274705549\n",
      "resetting env. episode reward total was 8.0. running mean: 12.052037601958494\n",
      "resetting env. episode reward total was 15.0. running mean: 12.08151722593891\n",
      "resetting env. episode reward total was 12.0. running mean: 12.08070205367952\n",
      "resetting env. episode reward total was 9.0. running mean: 12.049895033142725\n",
      "resetting env. episode reward total was 13.0. running mean: 12.059396082811299\n",
      "resetting env. episode reward total was 18.0. running mean: 12.118802121983185\n",
      "resetting env. episode reward total was 15.0. running mean: 12.147614100763354\n",
      "resetting env. episode reward total was 8.0. running mean: 12.10613795975572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 12.115076580158163\n",
      "resetting env. episode reward total was 13.0. running mean: 12.123925814356582\n",
      "resetting env. episode reward total was 13.0. running mean: 12.132686556213017\n",
      "resetting env. episode reward total was 11.0. running mean: 12.121359690650886\n",
      "resetting env. episode reward total was 11.0. running mean: 12.110146093744376\n",
      "resetting env. episode reward total was 12.0. running mean: 12.109044632806931\n",
      "resetting env. episode reward total was 10.0. running mean: 12.08795418647886\n",
      "resetting env. episode reward total was 20.0. running mean: 12.167074644614072\n",
      "resetting env. episode reward total was 14.0. running mean: 12.185403898167932\n",
      "resetting env. episode reward total was 7.0. running mean: 12.133549859186253\n",
      "resetting env. episode reward total was 12.0. running mean: 12.13221436059439\n",
      "resetting env. episode reward total was 11.0. running mean: 12.120892216988445\n",
      "resetting env. episode reward total was 7.0. running mean: 12.06968329481856\n",
      "resetting env. episode reward total was 15.0. running mean: 12.098986461870375\n",
      "resetting env. episode reward total was 11.0. running mean: 12.08799659725167\n",
      "resetting env. episode reward total was 18.0. running mean: 12.147116631279154\n",
      "resetting env. episode reward total was 2.0. running mean: 12.045645464966361\n",
      "resetting env. episode reward total was 17.0. running mean: 12.095189010316696\n",
      "resetting env. episode reward total was 13.0. running mean: 12.10423712021353\n",
      "resetting env. episode reward total was 5.0. running mean: 12.033194749011395\n",
      "resetting env. episode reward total was 7.0. running mean: 11.982862801521282\n",
      "resetting env. episode reward total was 15.0. running mean: 12.01303417350607\n",
      "resetting env. episode reward total was 16.0. running mean: 12.052903831771008\n",
      "resetting env. episode reward total was 8.0. running mean: 12.012374793453299\n",
      "resetting env. episode reward total was 11.0. running mean: 12.002251045518765\n",
      "resetting env. episode reward total was 10.0. running mean: 11.982228535063577\n",
      "resetting env. episode reward total was 12.0. running mean: 11.98240624971294\n",
      "resetting env. episode reward total was 15.0. running mean: 12.012582187215811\n",
      "resetting env. episode reward total was 17.0. running mean: 12.062456365343653\n",
      "resetting env. episode reward total was 14.0. running mean: 12.081831801690218\n",
      "resetting env. episode reward total was 12.0. running mean: 12.081013483673315\n",
      "resetting env. episode reward total was 11.0. running mean: 12.070203348836582\n",
      "resetting env. episode reward total was 8.0. running mean: 12.029501315348217\n",
      "resetting env. episode reward total was 9.0. running mean: 11.999206302194734\n",
      "resetting env. episode reward total was 7.0. running mean: 11.949214239172788\n",
      "resetting env. episode reward total was 14.0. running mean: 11.96972209678106\n",
      "resetting env. episode reward total was 13.0. running mean: 11.98002487581325\n",
      "resetting env. episode reward total was 18.0. running mean: 12.040224627055117\n",
      "resetting env. episode reward total was 16.0. running mean: 12.079822380784567\n",
      "resetting env. episode reward total was 15.0. running mean: 12.109024156976721\n",
      "resetting env. episode reward total was 14.0. running mean: 12.127933915406954\n",
      "resetting env. episode reward total was 13.0. running mean: 12.136654576252885\n",
      "resetting env. episode reward total was 11.0. running mean: 12.125288030490356\n",
      "resetting env. episode reward total was 16.0. running mean: 12.164035150185454\n",
      "resetting env. episode reward total was 12.0. running mean: 12.162394798683598\n",
      "resetting env. episode reward total was 15.0. running mean: 12.190770850696763\n",
      "resetting env. episode reward total was 6.0. running mean: 12.128863142189797\n",
      "resetting env. episode reward total was 16.0. running mean: 12.1675745107679\n",
      "resetting env. episode reward total was -1.0. running mean: 12.035898765660221\n",
      "resetting env. episode reward total was 6.0. running mean: 11.975539778003618\n",
      "resetting env. episode reward total was 10.0. running mean: 11.955784380223582\n",
      "resetting env. episode reward total was 17.0. running mean: 12.006226536421346\n",
      "resetting env. episode reward total was 16.0. running mean: 12.046164271057133\n",
      "resetting env. episode reward total was 12.0. running mean: 12.045702628346561\n",
      "resetting env. episode reward total was 16.0. running mean: 12.085245602063095\n",
      "resetting env. episode reward total was 18.0. running mean: 12.144393146042464\n",
      "resetting env. episode reward total was 13.0. running mean: 12.15294921458204\n",
      "resetting env. episode reward total was 13.0. running mean: 12.161419722436221\n",
      "resetting env. episode reward total was 20.0. running mean: 12.239805525211858\n",
      "resetting env. episode reward total was 18.0. running mean: 12.29740746995974\n",
      "resetting env. episode reward total was 11.0. running mean: 12.284433395260143\n",
      "resetting env. episode reward total was 10.0. running mean: 12.261589061307541\n",
      "resetting env. episode reward total was 16.0. running mean: 12.298973170694465\n",
      "resetting env. episode reward total was 13.0. running mean: 12.305983438987521\n",
      "resetting env. episode reward total was 8.0. running mean: 12.262923604597646\n",
      "resetting env. episode reward total was 18.0. running mean: 12.320294368551668\n",
      "resetting env. episode reward total was 15.0. running mean: 12.347091424866152\n",
      "resetting env. episode reward total was 18.0. running mean: 12.40362051061749\n",
      "resetting env. episode reward total was 17.0. running mean: 12.449584305511314\n",
      "resetting env. episode reward total was 16.0. running mean: 12.4850884624562\n",
      "resetting env. episode reward total was 17.0. running mean: 12.530237577831638\n",
      "resetting env. episode reward total was 19.0. running mean: 12.594935202053321\n",
      "resetting env. episode reward total was 12.0. running mean: 12.588985850032786\n",
      "resetting env. episode reward total was 16.0. running mean: 12.623095991532459\n",
      "resetting env. episode reward total was 18.0. running mean: 12.676865031617133\n",
      "resetting env. episode reward total was 18.0. running mean: 12.730096381300962\n",
      "resetting env. episode reward total was 9.0. running mean: 12.692795417487952\n",
      "resetting env. episode reward total was 14.0. running mean: 12.705867463313073\n",
      "resetting env. episode reward total was 15.0. running mean: 12.728808788679942\n",
      "resetting env. episode reward total was 11.0. running mean: 12.711520700793141\n",
      "resetting env. episode reward total was 13.0. running mean: 12.714405493785211\n",
      "resetting env. episode reward total was 19.0. running mean: 12.777261438847358\n",
      "resetting env. episode reward total was 15.0. running mean: 12.799488824458884\n",
      "resetting env. episode reward total was 16.0. running mean: 12.831493936214295\n",
      "resetting env. episode reward total was 11.0. running mean: 12.813178996852152\n",
      "resetting env. episode reward total was 16.0. running mean: 12.84504720688363\n",
      "resetting env. episode reward total was 13.0. running mean: 12.846596734814794\n",
      "resetting env. episode reward total was 7.0. running mean: 12.788130767466646\n",
      "resetting env. episode reward total was 17.0. running mean: 12.830249459791979\n",
      "resetting env. episode reward total was 11.0. running mean: 12.811946965194059\n",
      "resetting env. episode reward total was 13.0. running mean: 12.81382749554212\n",
      "resetting env. episode reward total was 16.0. running mean: 12.845689220586697\n",
      "resetting env. episode reward total was 16.0. running mean: 12.877232328380831\n",
      "resetting env. episode reward total was 14.0. running mean: 12.888460005097023\n",
      "resetting env. episode reward total was 7.0. running mean: 12.829575405046054\n",
      "resetting env. episode reward total was 20.0. running mean: 12.901279650995592\n",
      "resetting env. episode reward total was 14.0. running mean: 12.912266854485637\n",
      "resetting env. episode reward total was 15.0. running mean: 12.933144185940781\n",
      "resetting env. episode reward total was 14.0. running mean: 12.943812744081374\n",
      "resetting env. episode reward total was 7.0. running mean: 12.88437461664056\n",
      "resetting env. episode reward total was 10.0. running mean: 12.855530870474155\n",
      "resetting env. episode reward total was 15.0. running mean: 12.876975561769413\n",
      "resetting env. episode reward total was 13.0. running mean: 12.878205806151719\n",
      "resetting env. episode reward total was 12.0. running mean: 12.8694237480902\n",
      "resetting env. episode reward total was 11.0. running mean: 12.850729510609298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 12.822222215503205\n",
      "resetting env. episode reward total was 16.0. running mean: 12.853999993348173\n",
      "resetting env. episode reward total was 13.0. running mean: 12.855459993414692\n",
      "resetting env. episode reward total was 17.0. running mean: 12.896905393480546\n",
      "resetting env. episode reward total was 14.0. running mean: 12.907936339545742\n",
      "resetting env. episode reward total was 11.0. running mean: 12.888856976150285\n",
      "resetting env. episode reward total was 15.0. running mean: 12.909968406388781\n",
      "resetting env. episode reward total was 8.0. running mean: 12.860868722324893\n",
      "resetting env. episode reward total was 7.0. running mean: 12.802260035101645\n",
      "resetting env. episode reward total was 10.0. running mean: 12.774237434750628\n",
      "resetting env. episode reward total was 9.0. running mean: 12.73649506040312\n",
      "resetting env. episode reward total was 5.0. running mean: 12.65913010979909\n",
      "resetting env. episode reward total was 17.0. running mean: 12.7025388087011\n",
      "resetting env. episode reward total was 13.0. running mean: 12.70551342061409\n",
      "resetting env. episode reward total was 13.0. running mean: 12.708458286407948\n",
      "resetting env. episode reward total was 10.0. running mean: 12.68137370354387\n",
      "resetting env. episode reward total was 10.0. running mean: 12.65455996650843\n",
      "resetting env. episode reward total was 10.0. running mean: 12.628014366843345\n",
      "resetting env. episode reward total was 7.0. running mean: 12.571734223174913\n",
      "resetting env. episode reward total was 9.0. running mean: 12.536016880943164\n",
      "resetting env. episode reward total was 19.0. running mean: 12.600656712133732\n",
      "resetting env. episode reward total was 7.0. running mean: 12.544650145012396\n",
      "resetting env. episode reward total was 7.0. running mean: 12.489203643562272\n",
      "resetting env. episode reward total was 11.0. running mean: 12.474311607126648\n",
      "resetting env. episode reward total was 15.0. running mean: 12.499568491055381\n",
      "resetting env. episode reward total was 8.0. running mean: 12.454572806144828\n",
      "resetting env. episode reward total was 14.0. running mean: 12.47002707808338\n",
      "resetting env. episode reward total was 14.0. running mean: 12.485326807302547\n",
      "resetting env. episode reward total was 11.0. running mean: 12.470473539229522\n",
      "resetting env. episode reward total was 10.0. running mean: 12.445768803837225\n",
      "resetting env. episode reward total was 16.0. running mean: 12.481311115798853\n",
      "resetting env. episode reward total was 15.0. running mean: 12.506498004640864\n",
      "resetting env. episode reward total was 15.0. running mean: 12.531433024594456\n",
      "resetting env. episode reward total was 11.0. running mean: 12.516118694348512\n",
      "resetting env. episode reward total was 7.0. running mean: 12.460957507405027\n",
      "resetting env. episode reward total was 17.0. running mean: 12.506347932330977\n",
      "resetting env. episode reward total was 8.0. running mean: 12.461284453007666\n",
      "resetting env. episode reward total was 8.0. running mean: 12.41667160847759\n",
      "resetting env. episode reward total was 16.0. running mean: 12.452504892392813\n",
      "resetting env. episode reward total was 15.0. running mean: 12.477979843468885\n",
      "resetting env. episode reward total was 9.0. running mean: 12.443200045034196\n",
      "resetting env. episode reward total was 6.0. running mean: 12.378768044583854\n",
      "resetting env. episode reward total was 12.0. running mean: 12.374980364138015\n",
      "resetting env. episode reward total was 17.0. running mean: 12.421230560496634\n",
      "resetting env. episode reward total was 11.0. running mean: 12.407018254891666\n",
      "resetting env. episode reward total was 16.0. running mean: 12.44294807234275\n",
      "resetting env. episode reward total was 9.0. running mean: 12.408518591619321\n",
      "resetting env. episode reward total was 14.0. running mean: 12.424433405703128\n",
      "resetting env. episode reward total was 9.0. running mean: 12.390189071646097\n",
      "resetting env. episode reward total was 12.0. running mean: 12.386287180929635\n",
      "resetting env. episode reward total was 10.0. running mean: 12.362424309120339\n",
      "resetting env. episode reward total was 12.0. running mean: 12.358800066029135\n",
      "resetting env. episode reward total was 9.0. running mean: 12.325212065368843\n",
      "resetting env. episode reward total was 16.0. running mean: 12.361959944715155\n",
      "resetting env. episode reward total was 6.0. running mean: 12.298340345268004\n",
      "resetting env. episode reward total was 11.0. running mean: 12.285356941815323\n",
      "resetting env. episode reward total was 16.0. running mean: 12.32250337239717\n",
      "resetting env. episode reward total was 13.0. running mean: 12.329278338673198\n",
      "resetting env. episode reward total was 14.0. running mean: 12.345985555286466\n",
      "resetting env. episode reward total was 8.0. running mean: 12.302525699733602\n",
      "resetting env. episode reward total was 5.0. running mean: 12.229500442736267\n",
      "resetting env. episode reward total was 14.0. running mean: 12.247205438308905\n",
      "resetting env. episode reward total was 17.0. running mean: 12.294733383925816\n",
      "resetting env. episode reward total was 5.0. running mean: 12.221786050086559\n",
      "resetting env. episode reward total was 9.0. running mean: 12.189568189585692\n",
      "resetting env. episode reward total was 8.0. running mean: 12.147672507689835\n",
      "resetting env. episode reward total was 12.0. running mean: 12.146195782612935\n",
      "resetting env. episode reward total was 18.0. running mean: 12.204733824786805\n",
      "resetting env. episode reward total was 2.0. running mean: 12.102686486538937\n",
      "resetting env. episode reward total was 9.0. running mean: 12.071659621673549\n",
      "resetting env. episode reward total was 10.0. running mean: 12.050943025456812\n",
      "resetting env. episode reward total was 13.0. running mean: 12.060433595202245\n",
      "resetting env. episode reward total was 8.0. running mean: 12.019829259250223\n",
      "resetting env. episode reward total was 12.0. running mean: 12.01963096665772\n",
      "resetting env. episode reward total was 5.0. running mean: 11.949434656991144\n",
      "resetting env. episode reward total was 13.0. running mean: 11.959940310421233\n",
      "resetting env. episode reward total was 3.0. running mean: 11.87034090731702\n",
      "resetting env. episode reward total was 15.0. running mean: 11.90163749824385\n",
      "resetting env. episode reward total was 15.0. running mean: 11.932621123261413\n",
      "resetting env. episode reward total was 3.0. running mean: 11.843294912028798\n",
      "resetting env. episode reward total was 11.0. running mean: 11.834861962908509\n",
      "resetting env. episode reward total was 12.0. running mean: 11.836513343279423\n",
      "resetting env. episode reward total was 21.0. running mean: 11.92814820984663\n",
      "resetting env. episode reward total was 11.0. running mean: 11.918866727748162\n",
      "resetting env. episode reward total was 2.0. running mean: 11.819678060470679\n",
      "resetting env. episode reward total was 13.0. running mean: 11.831481279865972\n",
      "resetting env. episode reward total was 13.0. running mean: 11.843166467067313\n",
      "resetting env. episode reward total was 17.0. running mean: 11.89473480239664\n",
      "resetting env. episode reward total was 14.0. running mean: 11.915787454372673\n",
      "resetting env. episode reward total was 14.0. running mean: 11.936629579828946\n",
      "resetting env. episode reward total was 10.0. running mean: 11.917263284030655\n",
      "resetting env. episode reward total was 12.0. running mean: 11.918090651190347\n",
      "resetting env. episode reward total was 14.0. running mean: 11.938909744678444\n",
      "resetting env. episode reward total was 9.0. running mean: 11.909520647231659\n",
      "resetting env. episode reward total was 9.0. running mean: 11.880425440759343\n",
      "resetting env. episode reward total was 14.0. running mean: 11.90162118635175\n",
      "resetting env. episode reward total was 8.0. running mean: 11.862604974488233\n",
      "resetting env. episode reward total was 15.0. running mean: 11.893978924743351\n",
      "resetting env. episode reward total was 14.0. running mean: 11.915039135495919\n",
      "resetting env. episode reward total was 16.0. running mean: 11.95588874414096\n",
      "resetting env. episode reward total was 14.0. running mean: 11.976329856699552\n",
      "resetting env. episode reward total was 11.0. running mean: 11.966566558132556\n",
      "resetting env. episode reward total was 15.0. running mean: 11.99690089255123\n",
      "resetting env. episode reward total was 13.0. running mean: 12.006931883625718\n",
      "resetting env. episode reward total was 16.0. running mean: 12.04686256478946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 12.056393939141566\n",
      "resetting env. episode reward total was -6.0. running mean: 11.87582999975015\n",
      "resetting env. episode reward total was 14.0. running mean: 11.897071699752649\n",
      "resetting env. episode reward total was 2.0. running mean: 11.798100982755122\n",
      "resetting env. episode reward total was 11.0. running mean: 11.79011997292757\n",
      "resetting env. episode reward total was 19.0. running mean: 11.862218773198293\n",
      "resetting env. episode reward total was 9.0. running mean: 11.83359658546631\n",
      "resetting env. episode reward total was 14.0. running mean: 11.855260619611647\n",
      "resetting env. episode reward total was 8.0. running mean: 11.81670801341553\n",
      "resetting env. episode reward total was 12.0. running mean: 11.818540933281374\n",
      "resetting env. episode reward total was 12.0. running mean: 11.82035552394856\n",
      "resetting env. episode reward total was 9.0. running mean: 11.792151968709074\n",
      "resetting env. episode reward total was 3.0. running mean: 11.704230449021983\n",
      "resetting env. episode reward total was 15.0. running mean: 11.737188144531764\n",
      "resetting env. episode reward total was 10.0. running mean: 11.719816263086447\n",
      "resetting env. episode reward total was 11.0. running mean: 11.71261810045558\n",
      "resetting env. episode reward total was 17.0. running mean: 11.765491919451025\n",
      "resetting env. episode reward total was 8.0. running mean: 11.727837000256514\n",
      "resetting env. episode reward total was 13.0. running mean: 11.74055863025395\n",
      "resetting env. episode reward total was 9.0. running mean: 11.713153043951412\n",
      "resetting env. episode reward total was 10.0. running mean: 11.696021513511896\n",
      "resetting env. episode reward total was 14.0. running mean: 11.719061298376777\n",
      "resetting env. episode reward total was 4.0. running mean: 11.641870685393009\n",
      "resetting env. episode reward total was 12.0. running mean: 11.645451978539079\n",
      "resetting env. episode reward total was 16.0. running mean: 11.688997458753688\n",
      "resetting env. episode reward total was 14.0. running mean: 11.712107484166152\n",
      "resetting env. episode reward total was 9.0. running mean: 11.684986409324491\n",
      "resetting env. episode reward total was 17.0. running mean: 11.738136545231246\n",
      "resetting env. episode reward total was 12.0. running mean: 11.740755179778933\n",
      "resetting env. episode reward total was 10.0. running mean: 11.723347627981143\n",
      "resetting env. episode reward total was 11.0. running mean: 11.716114151701332\n",
      "resetting env. episode reward total was 15.0. running mean: 11.74895301018432\n",
      "resetting env. episode reward total was 15.0. running mean: 11.781463480082476\n",
      "resetting env. episode reward total was 7.0. running mean: 11.733648845281651\n",
      "resetting env. episode reward total was 11.0. running mean: 11.726312356828835\n",
      "resetting env. episode reward total was 15.0. running mean: 11.759049233260546\n",
      "resetting env. episode reward total was 11.0. running mean: 11.75145874092794\n",
      "resetting env. episode reward total was 14.0. running mean: 11.773944153518661\n",
      "resetting env. episode reward total was 17.0. running mean: 11.826204711983474\n",
      "resetting env. episode reward total was 14.0. running mean: 11.84794266486364\n",
      "resetting env. episode reward total was 15.0. running mean: 11.879463238215003\n",
      "resetting env. episode reward total was 15.0. running mean: 11.910668605832853\n",
      "resetting env. episode reward total was 12.0. running mean: 11.911561919774524\n",
      "resetting env. episode reward total was 16.0. running mean: 11.95244630057678\n",
      "resetting env. episode reward total was 14.0. running mean: 11.972921837571013\n",
      "resetting env. episode reward total was 13.0. running mean: 11.983192619195304\n",
      "resetting env. episode reward total was 13.0. running mean: 11.993360693003352\n",
      "resetting env. episode reward total was 14.0. running mean: 12.01342708607332\n",
      "resetting env. episode reward total was 13.0. running mean: 12.023292815212587\n",
      "resetting env. episode reward total was 14.0. running mean: 12.043059887060462\n",
      "resetting env. episode reward total was 14.0. running mean: 12.062629288189857\n",
      "resetting env. episode reward total was 18.0. running mean: 12.122002995307959\n",
      "resetting env. episode reward total was 18.0. running mean: 12.18078296535488\n",
      "resetting env. episode reward total was 12.0. running mean: 12.17897513570133\n",
      "resetting env. episode reward total was 10.0. running mean: 12.157185384344317\n",
      "resetting env. episode reward total was 7.0. running mean: 12.105613530500873\n",
      "resetting env. episode reward total was 10.0. running mean: 12.084557395195864\n",
      "resetting env. episode reward total was 16.0. running mean: 12.123711821243905\n",
      "resetting env. episode reward total was 17.0. running mean: 12.172474703031465\n",
      "resetting env. episode reward total was 15.0. running mean: 12.20074995600115\n",
      "resetting env. episode reward total was 16.0. running mean: 12.23874245644114\n",
      "resetting env. episode reward total was 14.0. running mean: 12.256355031876728\n",
      "resetting env. episode reward total was 7.0. running mean: 12.20379148155796\n",
      "resetting env. episode reward total was 13.0. running mean: 12.21175356674238\n",
      "resetting env. episode reward total was 15.0. running mean: 12.239636031074957\n",
      "resetting env. episode reward total was 19.0. running mean: 12.307239670764206\n",
      "resetting env. episode reward total was 13.0. running mean: 12.314167274056565\n",
      "resetting env. episode reward total was 18.0. running mean: 12.371025601316\n",
      "resetting env. episode reward total was 19.0. running mean: 12.437315345302839\n",
      "resetting env. episode reward total was 11.0. running mean: 12.42294219184981\n",
      "resetting env. episode reward total was 9.0. running mean: 12.388712769931312\n",
      "resetting env. episode reward total was 13.0. running mean: 12.394825642231998\n",
      "resetting env. episode reward total was 10.0. running mean: 12.370877385809678\n",
      "resetting env. episode reward total was 18.0. running mean: 12.427168611951581\n",
      "resetting env. episode reward total was 17.0. running mean: 12.472896925832066\n",
      "resetting env. episode reward total was 15.0. running mean: 12.498167956573745\n",
      "resetting env. episode reward total was 9.0. running mean: 12.463186277008008\n",
      "resetting env. episode reward total was 8.0. running mean: 12.418554414237928\n",
      "resetting env. episode reward total was 15.0. running mean: 12.444368870095548\n",
      "resetting env. episode reward total was 12.0. running mean: 12.439925181394592\n",
      "resetting env. episode reward total was 16.0. running mean: 12.475525929580646\n",
      "resetting env. episode reward total was 16.0. running mean: 12.51077067028484\n",
      "resetting env. episode reward total was 18.0. running mean: 12.56566296358199\n",
      "resetting env. episode reward total was 14.0. running mean: 12.580006333946171\n",
      "resetting env. episode reward total was 18.0. running mean: 12.63420627060671\n",
      "resetting env. episode reward total was 14.0. running mean: 12.647864207900643\n",
      "resetting env. episode reward total was 10.0. running mean: 12.621385565821635\n",
      "resetting env. episode reward total was 15.0. running mean: 12.64517171016342\n",
      "resetting env. episode reward total was 11.0. running mean: 12.628719993061784\n",
      "resetting env. episode reward total was 15.0. running mean: 12.652432793131167\n",
      "resetting env. episode reward total was 13.0. running mean: 12.655908465199856\n",
      "resetting env. episode reward total was 3.0. running mean: 12.559349380547856\n",
      "resetting env. episode reward total was 16.0. running mean: 12.593755886742377\n",
      "resetting env. episode reward total was 12.0. running mean: 12.587818327874952\n",
      "resetting env. episode reward total was 14.0. running mean: 12.601940144596204\n",
      "resetting env. episode reward total was 14.0. running mean: 12.615920743150243\n",
      "resetting env. episode reward total was 16.0. running mean: 12.64976153571874\n",
      "resetting env. episode reward total was 10.0. running mean: 12.623263920361552\n",
      "resetting env. episode reward total was 15.0. running mean: 12.647031281157936\n",
      "resetting env. episode reward total was 14.0. running mean: 12.660560968346358\n",
      "resetting env. episode reward total was 8.0. running mean: 12.613955358662894\n",
      "resetting env. episode reward total was 10.0. running mean: 12.587815805076264\n",
      "resetting env. episode reward total was 17.0. running mean: 12.631937647025502\n",
      "resetting env. episode reward total was 13.0. running mean: 12.635618270555248\n",
      "resetting env. episode reward total was 13.0. running mean: 12.639262087849696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 12.6628694669712\n",
      "resetting env. episode reward total was 8.0. running mean: 12.616240772301488\n",
      "resetting env. episode reward total was 18.0. running mean: 12.670078364578472\n",
      "resetting env. episode reward total was 16.0. running mean: 12.703377580932688\n",
      "resetting env. episode reward total was 14.0. running mean: 12.716343805123362\n",
      "resetting env. episode reward total was 16.0. running mean: 12.749180367072128\n",
      "resetting env. episode reward total was 10.0. running mean: 12.721688563401406\n",
      "resetting env. episode reward total was 13.0. running mean: 12.724471677767392\n",
      "resetting env. episode reward total was 14.0. running mean: 12.737226960989718\n",
      "resetting env. episode reward total was 17.0. running mean: 12.779854691379821\n",
      "resetting env. episode reward total was 10.0. running mean: 12.752056144466023\n",
      "resetting env. episode reward total was 15.0. running mean: 12.774535583021363\n",
      "resetting env. episode reward total was 18.0. running mean: 12.826790227191148\n",
      "resetting env. episode reward total was 10.0. running mean: 12.798522324919237\n",
      "resetting env. episode reward total was 10.0. running mean: 12.770537101670044\n",
      "resetting env. episode reward total was 17.0. running mean: 12.812831730653343\n",
      "resetting env. episode reward total was 8.0. running mean: 12.76470341334681\n",
      "resetting env. episode reward total was 19.0. running mean: 12.82705637921334\n",
      "resetting env. episode reward total was 11.0. running mean: 12.808785815421206\n",
      "resetting env. episode reward total was 10.0. running mean: 12.780697957266995\n",
      "resetting env. episode reward total was 7.0. running mean: 12.722890977694325\n",
      "resetting env. episode reward total was 15.0. running mean: 12.745662067917381\n",
      "resetting env. episode reward total was 12.0. running mean: 12.738205447238206\n",
      "resetting env. episode reward total was 13.0. running mean: 12.740823392765824\n",
      "resetting env. episode reward total was 17.0. running mean: 12.783415158838165\n",
      "resetting env. episode reward total was 12.0. running mean: 12.775581007249784\n",
      "resetting env. episode reward total was 16.0. running mean: 12.807825197177285\n",
      "resetting env. episode reward total was 10.0. running mean: 12.779746945205511\n",
      "resetting env. episode reward total was 9.0. running mean: 12.741949475753456\n",
      "resetting env. episode reward total was 7.0. running mean: 12.684529980995922\n",
      "resetting env. episode reward total was 14.0. running mean: 12.697684681185963\n",
      "resetting env. episode reward total was 14.0. running mean: 12.710707834374103\n",
      "resetting env. episode reward total was 16.0. running mean: 12.743600756030363\n",
      "resetting env. episode reward total was 19.0. running mean: 12.806164748470058\n",
      "resetting env. episode reward total was 8.0. running mean: 12.758103100985357\n",
      "resetting env. episode reward total was 18.0. running mean: 12.810522069975503\n",
      "resetting env. episode reward total was 8.0. running mean: 12.762416849275748\n",
      "resetting env. episode reward total was 13.0. running mean: 12.76479268078299\n",
      "resetting env. episode reward total was 15.0. running mean: 12.787144753975161\n",
      "resetting env. episode reward total was 17.0. running mean: 12.82927330643541\n",
      "resetting env. episode reward total was 15.0. running mean: 12.850980573371055\n",
      "resetting env. episode reward total was 15.0. running mean: 12.872470767637346\n",
      "resetting env. episode reward total was 15.0. running mean: 12.893746059960971\n",
      "resetting env. episode reward total was 14.0. running mean: 12.904808599361361\n",
      "resetting env. episode reward total was 16.0. running mean: 12.935760513367748\n",
      "resetting env. episode reward total was 8.0. running mean: 12.886402908234071\n",
      "resetting env. episode reward total was 8.0. running mean: 12.837538879151731\n",
      "resetting env. episode reward total was 7.0. running mean: 12.779163490360213\n",
      "resetting env. episode reward total was 16.0. running mean: 12.811371855456612\n",
      "resetting env. episode reward total was 4.0. running mean: 12.723258136902045\n",
      "resetting env. episode reward total was 14.0. running mean: 12.736025555533026\n",
      "resetting env. episode reward total was 12.0. running mean: 12.728665299977694\n",
      "resetting env. episode reward total was 10.0. running mean: 12.701378646977917\n",
      "resetting env. episode reward total was 13.0. running mean: 12.704364860508138\n",
      "resetting env. episode reward total was 17.0. running mean: 12.747321211903056\n",
      "resetting env. episode reward total was 18.0. running mean: 12.799847999784026\n",
      "resetting env. episode reward total was 15.0. running mean: 12.821849519786186\n",
      "resetting env. episode reward total was 20.0. running mean: 12.893631024588323\n",
      "resetting env. episode reward total was 10.0. running mean: 12.86469471434244\n",
      "resetting env. episode reward total was 16.0. running mean: 12.896047767199015\n",
      "resetting env. episode reward total was 15.0. running mean: 12.917087289527025\n",
      "resetting env. episode reward total was 11.0. running mean: 12.897916416631753\n",
      "resetting env. episode reward total was 19.0. running mean: 12.958937252465436\n",
      "resetting env. episode reward total was 17.0. running mean: 12.999347879940782\n",
      "resetting env. episode reward total was 14.0. running mean: 13.009354401141374\n",
      "resetting env. episode reward total was 10.0. running mean: 12.97926085712996\n",
      "resetting env. episode reward total was 11.0. running mean: 12.95946824855866\n",
      "resetting env. episode reward total was 16.0. running mean: 12.989873566073072\n",
      "resetting env. episode reward total was 11.0. running mean: 12.96997483041234\n",
      "resetting env. episode reward total was 6.0. running mean: 12.900275082108218\n",
      "resetting env. episode reward total was 13.0. running mean: 12.901272331287137\n",
      "resetting env. episode reward total was 13.0. running mean: 12.902259607974266\n",
      "resetting env. episode reward total was 15.0. running mean: 12.923237011894523\n",
      "resetting env. episode reward total was 12.0. running mean: 12.914004641775577\n",
      "resetting env. episode reward total was 15.0. running mean: 12.934864595357821\n",
      "resetting env. episode reward total was 15.0. running mean: 12.955515949404242\n",
      "resetting env. episode reward total was 14.0. running mean: 12.9659607899102\n",
      "resetting env. episode reward total was 7.0. running mean: 12.906301182011099\n",
      "resetting env. episode reward total was 19.0. running mean: 12.967238170190987\n",
      "resetting env. episode reward total was 13.0. running mean: 12.967565788489077\n",
      "resetting env. episode reward total was 12.0. running mean: 12.957890130604186\n",
      "resetting env. episode reward total was 9.0. running mean: 12.918311229298144\n",
      "resetting env. episode reward total was 10.0. running mean: 12.889128117005162\n",
      "resetting env. episode reward total was 10.0. running mean: 12.86023683583511\n",
      "resetting env. episode reward total was 8.0. running mean: 12.81163446747676\n",
      "resetting env. episode reward total was 12.0. running mean: 12.803518122801991\n",
      "resetting env. episode reward total was 14.0. running mean: 12.815482941573972\n",
      "resetting env. episode reward total was 16.0. running mean: 12.847328112158232\n",
      "resetting env. episode reward total was 15.0. running mean: 12.86885483103665\n",
      "resetting env. episode reward total was 6.0. running mean: 12.800166282726284\n",
      "resetting env. episode reward total was 9.0. running mean: 12.762164619899021\n",
      "resetting env. episode reward total was 14.0. running mean: 12.774542973700031\n",
      "resetting env. episode reward total was 7.0. running mean: 12.71679754396303\n",
      "resetting env. episode reward total was 13.0. running mean: 12.719629568523402\n",
      "resetting env. episode reward total was 14.0. running mean: 12.732433272838168\n",
      "resetting env. episode reward total was 15.0. running mean: 12.755108940109787\n",
      "resetting env. episode reward total was 14.0. running mean: 12.76755785070869\n",
      "resetting env. episode reward total was 15.0. running mean: 12.789882272201602\n",
      "resetting env. episode reward total was 10.0. running mean: 12.761983449479585\n",
      "resetting env. episode reward total was 12.0. running mean: 12.754363614984788\n",
      "resetting env. episode reward total was 19.0. running mean: 12.816819978834939\n",
      "resetting env. episode reward total was 11.0. running mean: 12.798651779046589\n",
      "resetting env. episode reward total was 16.0. running mean: 12.830665261256122\n",
      "resetting env. episode reward total was 5.0. running mean: 12.752358608643561\n",
      "resetting env. episode reward total was 15.0. running mean: 12.774835022557125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 12.757086672331553\n",
      "resetting env. episode reward total was 8.0. running mean: 12.709515805608238\n",
      "resetting env. episode reward total was 14.0. running mean: 12.722420647552156\n",
      "resetting env. episode reward total was 12.0. running mean: 12.715196441076634\n",
      "resetting env. episode reward total was 11.0. running mean: 12.698044476665867\n",
      "resetting env. episode reward total was 12.0. running mean: 12.691064031899208\n",
      "resetting env. episode reward total was 8.0. running mean: 12.644153391580215\n",
      "resetting env. episode reward total was 16.0. running mean: 12.677711857664413\n",
      "resetting env. episode reward total was 9.0. running mean: 12.640934739087768\n",
      "resetting env. episode reward total was 7.0. running mean: 12.584525391696891\n",
      "resetting env. episode reward total was 16.0. running mean: 12.618680137779922\n",
      "resetting env. episode reward total was 15.0. running mean: 12.642493336402124\n",
      "resetting env. episode reward total was 3.0. running mean: 12.546068403038102\n",
      "resetting env. episode reward total was 15.0. running mean: 12.570607719007722\n",
      "resetting env. episode reward total was 13.0. running mean: 12.574901641817645\n",
      "resetting env. episode reward total was 15.0. running mean: 12.59915262539947\n",
      "resetting env. episode reward total was 12.0. running mean: 12.593161099145474\n",
      "resetting env. episode reward total was 14.0. running mean: 12.60722948815402\n",
      "resetting env. episode reward total was 13.0. running mean: 12.611157193272481\n",
      "resetting env. episode reward total was 17.0. running mean: 12.655045621339756\n",
      "resetting env. episode reward total was 14.0. running mean: 12.668495165126359\n",
      "resetting env. episode reward total was 8.0. running mean: 12.621810213475095\n",
      "resetting env. episode reward total was 15.0. running mean: 12.645592111340344\n",
      "resetting env. episode reward total was 12.0. running mean: 12.639136190226939\n",
      "resetting env. episode reward total was 17.0. running mean: 12.682744828324669\n",
      "resetting env. episode reward total was 8.0. running mean: 12.635917380041422\n",
      "resetting env. episode reward total was 11.0. running mean: 12.619558206241006\n",
      "resetting env. episode reward total was 16.0. running mean: 12.653362624178596\n",
      "resetting env. episode reward total was 17.0. running mean: 12.69682899793681\n",
      "resetting env. episode reward total was 11.0. running mean: 12.679860707957442\n",
      "resetting env. episode reward total was 15.0. running mean: 12.703062100877867\n",
      "resetting env. episode reward total was 8.0. running mean: 12.656031479869089\n",
      "resetting env. episode reward total was 15.0. running mean: 12.679471165070398\n",
      "resetting env. episode reward total was 15.0. running mean: 12.702676453419693\n",
      "resetting env. episode reward total was 15.0. running mean: 12.725649688885497\n",
      "resetting env. episode reward total was 15.0. running mean: 12.748393191996643\n",
      "resetting env. episode reward total was 14.0. running mean: 12.760909260076676\n",
      "resetting env. episode reward total was 10.0. running mean: 12.733300167475909\n",
      "resetting env. episode reward total was 18.0. running mean: 12.785967165801148\n",
      "resetting env. episode reward total was 15.0. running mean: 12.808107494143137\n",
      "resetting env. episode reward total was 9.0. running mean: 12.770026419201706\n",
      "resetting env. episode reward total was 11.0. running mean: 12.752326155009689\n",
      "resetting env. episode reward total was 15.0. running mean: 12.774802893459592\n",
      "resetting env. episode reward total was 12.0. running mean: 12.767054864524995\n",
      "resetting env. episode reward total was 13.0. running mean: 12.769384315879746\n",
      "resetting env. episode reward total was 20.0. running mean: 12.841690472720948\n",
      "resetting env. episode reward total was 16.0. running mean: 12.873273567993738\n",
      "resetting env. episode reward total was 12.0. running mean: 12.8645408323138\n",
      "resetting env. episode reward total was 7.0. running mean: 12.805895423990663\n",
      "resetting env. episode reward total was 12.0. running mean: 12.797836469750756\n",
      "resetting env. episode reward total was 7.0. running mean: 12.739858105053248\n",
      "resetting env. episode reward total was 17.0. running mean: 12.782459524002714\n",
      "resetting env. episode reward total was 3.0. running mean: 12.684634928762687\n",
      "resetting env. episode reward total was 16.0. running mean: 12.71778857947506\n",
      "resetting env. episode reward total was 12.0. running mean: 12.710610693680309\n",
      "resetting env. episode reward total was 16.0. running mean: 12.743504586743505\n",
      "resetting env. episode reward total was 15.0. running mean: 12.766069540876071\n",
      "resetting env. episode reward total was 10.0. running mean: 12.73840884546731\n",
      "resetting env. episode reward total was 13.0. running mean: 12.741024757012637\n",
      "resetting env. episode reward total was 11.0. running mean: 12.723614509442509\n",
      "resetting env. episode reward total was 11.0. running mean: 12.706378364348083\n",
      "resetting env. episode reward total was 11.0. running mean: 12.689314580704602\n",
      "resetting env. episode reward total was 15.0. running mean: 12.712421434897557\n",
      "resetting env. episode reward total was 9.0. running mean: 12.67529722054858\n",
      "resetting env. episode reward total was 18.0. running mean: 12.728544248343095\n",
      "resetting env. episode reward total was 16.0. running mean: 12.761258805859663\n",
      "resetting env. episode reward total was 9.0. running mean: 12.723646217801067\n",
      "resetting env. episode reward total was 10.0. running mean: 12.696409755623055\n",
      "resetting env. episode reward total was 16.0. running mean: 12.729445658066824\n",
      "resetting env. episode reward total was 10.0. running mean: 12.702151201486156\n",
      "resetting env. episode reward total was 16.0. running mean: 12.735129689471295\n",
      "resetting env. episode reward total was 13.0. running mean: 12.737778392576583\n",
      "resetting env. episode reward total was 18.0. running mean: 12.790400608650817\n",
      "resetting env. episode reward total was 14.0. running mean: 12.80249660256431\n",
      "resetting env. episode reward total was 7.0. running mean: 12.744471636538666\n",
      "resetting env. episode reward total was 10.0. running mean: 12.717026920173279\n",
      "resetting env. episode reward total was 5.0. running mean: 12.639856650971547\n",
      "resetting env. episode reward total was 13.0. running mean: 12.643458084461832\n",
      "resetting env. episode reward total was 11.0. running mean: 12.627023503617213\n",
      "resetting env. episode reward total was 15.0. running mean: 12.650753268581042\n",
      "resetting env. episode reward total was 9.0. running mean: 12.614245735895231\n",
      "resetting env. episode reward total was 12.0. running mean: 12.608103278536278\n",
      "resetting env. episode reward total was 19.0. running mean: 12.672022245750915\n",
      "resetting env. episode reward total was 15.0. running mean: 12.695302023293406\n",
      "resetting env. episode reward total was 12.0. running mean: 12.688349003060472\n",
      "resetting env. episode reward total was 16.0. running mean: 12.721465513029868\n",
      "resetting env. episode reward total was 18.0. running mean: 12.774250857899569\n",
      "resetting env. episode reward total was 8.0. running mean: 12.726508349320573\n",
      "resetting env. episode reward total was 8.0. running mean: 12.679243265827367\n",
      "resetting env. episode reward total was 8.0. running mean: 12.632450833169093\n",
      "resetting env. episode reward total was 7.0. running mean: 12.576126324837402\n",
      "resetting env. episode reward total was 12.0. running mean: 12.570365061589026\n",
      "resetting env. episode reward total was 14.0. running mean: 12.584661410973137\n",
      "resetting env. episode reward total was 17.0. running mean: 12.628814796863406\n",
      "resetting env. episode reward total was 7.0. running mean: 12.572526648894772\n",
      "resetting env. episode reward total was 14.0. running mean: 12.586801382405826\n",
      "resetting env. episode reward total was 14.0. running mean: 12.600933368581767\n",
      "resetting env. episode reward total was 6.0. running mean: 12.53492403489595\n",
      "resetting env. episode reward total was 11.0. running mean: 12.519574794546989\n",
      "resetting env. episode reward total was 13.0. running mean: 12.524379046601519\n",
      "resetting env. episode reward total was 11.0. running mean: 12.509135256135503\n",
      "resetting env. episode reward total was 13.0. running mean: 12.514043903574148\n",
      "resetting env. episode reward total was 16.0. running mean: 12.548903464538407\n",
      "resetting env. episode reward total was 13.0. running mean: 12.553414429893024\n",
      "resetting env. episode reward total was 10.0. running mean: 12.527880285594094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 12.552601482738153\n",
      "resetting env. episode reward total was 12.0. running mean: 12.547075467910771\n",
      "resetting env. episode reward total was 13.0. running mean: 12.551604713231663\n",
      "resetting env. episode reward total was 20.0. running mean: 12.626088666099346\n",
      "resetting env. episode reward total was 9.0. running mean: 12.589827779438352\n",
      "resetting env. episode reward total was 19.0. running mean: 12.653929501643967\n",
      "resetting env. episode reward total was 15.0. running mean: 12.677390206627528\n",
      "resetting env. episode reward total was 11.0. running mean: 12.660616304561252\n",
      "resetting env. episode reward total was 15.0. running mean: 12.684010141515639\n",
      "resetting env. episode reward total was 16.0. running mean: 12.717170040100482\n",
      "resetting env. episode reward total was 10.0. running mean: 12.689998339699477\n",
      "resetting env. episode reward total was 9.0. running mean: 12.65309835630248\n",
      "resetting env. episode reward total was 15.0. running mean: 12.676567372739456\n",
      "resetting env. episode reward total was 15.0. running mean: 12.699801699012061\n",
      "resetting env. episode reward total was 11.0. running mean: 12.682803682021941\n",
      "resetting env. episode reward total was 17.0. running mean: 12.725975645201721\n",
      "resetting env. episode reward total was 12.0. running mean: 12.718715888749703\n",
      "resetting env. episode reward total was 10.0. running mean: 12.691528729862204\n",
      "resetting env. episode reward total was 11.0. running mean: 12.674613442563581\n",
      "resetting env. episode reward total was 10.0. running mean: 12.647867308137945\n",
      "resetting env. episode reward total was 14.0. running mean: 12.661388635056566\n",
      "resetting env. episode reward total was 11.0. running mean: 12.644774748706\n",
      "resetting env. episode reward total was 15.0. running mean: 12.668327001218941\n",
      "resetting env. episode reward total was 14.0. running mean: 12.681643731206751\n",
      "resetting env. episode reward total was 18.0. running mean: 12.734827293894684\n",
      "resetting env. episode reward total was 13.0. running mean: 12.737479020955737\n",
      "resetting env. episode reward total was 11.0. running mean: 12.720104230746179\n",
      "resetting env. episode reward total was 10.0. running mean: 12.692903188438716\n",
      "resetting env. episode reward total was 11.0. running mean: 12.675974156554329\n",
      "resetting env. episode reward total was 16.0. running mean: 12.709214414988786\n",
      "resetting env. episode reward total was 14.0. running mean: 12.722122270838899\n",
      "resetting env. episode reward total was 11.0. running mean: 12.704901048130509\n",
      "resetting env. episode reward total was 17.0. running mean: 12.747852037649203\n",
      "resetting env. episode reward total was 16.0. running mean: 12.78037351727271\n",
      "resetting env. episode reward total was 2.0. running mean: 12.672569782099984\n",
      "resetting env. episode reward total was 4.0. running mean: 12.585844084278984\n",
      "resetting env. episode reward total was 12.0. running mean: 12.579985643436192\n",
      "resetting env. episode reward total was 17.0. running mean: 12.62418578700183\n",
      "resetting env. episode reward total was 20.0. running mean: 12.69794392913181\n",
      "resetting env. episode reward total was 11.0. running mean: 12.680964489840491\n",
      "resetting env. episode reward total was 11.0. running mean: 12.664154844942086\n",
      "resetting env. episode reward total was 9.0. running mean: 12.627513296492666\n",
      "resetting env. episode reward total was 16.0. running mean: 12.661238163527738\n",
      "resetting env. episode reward total was 17.0. running mean: 12.70462578189246\n",
      "resetting env. episode reward total was -1.0. running mean: 12.567579524073535\n",
      "resetting env. episode reward total was 15.0. running mean: 12.5919037288328\n",
      "resetting env. episode reward total was 7.0. running mean: 12.535984691544472\n",
      "resetting env. episode reward total was 14.0. running mean: 12.550624844629029\n",
      "resetting env. episode reward total was 18.0. running mean: 12.605118596182738\n",
      "resetting env. episode reward total was 13.0. running mean: 12.609067410220911\n",
      "resetting env. episode reward total was 11.0. running mean: 12.5929767361187\n",
      "resetting env. episode reward total was 11.0. running mean: 12.577046968757513\n",
      "resetting env. episode reward total was 13.0. running mean: 12.581276499069938\n",
      "resetting env. episode reward total was 13.0. running mean: 12.585463734079239\n",
      "resetting env. episode reward total was 12.0. running mean: 12.579609096738446\n",
      "resetting env. episode reward total was 14.0. running mean: 12.593813005771063\n",
      "resetting env. episode reward total was 11.0. running mean: 12.577874875713352\n",
      "resetting env. episode reward total was 15.0. running mean: 12.60209612695622\n",
      "resetting env. episode reward total was 13.0. running mean: 12.606075165686658\n",
      "resetting env. episode reward total was 13.0. running mean: 12.610014414029791\n",
      "resetting env. episode reward total was 15.0. running mean: 12.633914269889493\n",
      "resetting env. episode reward total was 15.0. running mean: 12.657575127190599\n",
      "resetting env. episode reward total was 11.0. running mean: 12.640999375918692\n",
      "resetting env. episode reward total was 8.0. running mean: 12.594589382159505\n",
      "resetting env. episode reward total was 9.0. running mean: 12.558643488337909\n",
      "resetting env. episode reward total was 14.0. running mean: 12.57305705345453\n",
      "resetting env. episode reward total was 15.0. running mean: 12.597326482919986\n",
      "resetting env. episode reward total was 12.0. running mean: 12.591353218090784\n",
      "resetting env. episode reward total was 13.0. running mean: 12.595439685909877\n",
      "resetting env. episode reward total was 18.0. running mean: 12.649485289050778\n",
      "resetting env. episode reward total was 14.0. running mean: 12.662990436160271\n",
      "resetting env. episode reward total was 17.0. running mean: 12.706360531798667\n",
      "resetting env. episode reward total was 9.0. running mean: 12.66929692648068\n",
      "resetting env. episode reward total was 12.0. running mean: 12.662603957215872\n",
      "resetting env. episode reward total was 14.0. running mean: 12.675977917643714\n",
      "resetting env. episode reward total was 13.0. running mean: 12.679218138467277\n",
      "resetting env. episode reward total was 14.0. running mean: 12.692425957082605\n",
      "resetting env. episode reward total was 13.0. running mean: 12.69550169751178\n",
      "resetting env. episode reward total was 15.0. running mean: 12.718546680536662\n",
      "resetting env. episode reward total was 16.0. running mean: 12.751361213731295\n",
      "resetting env. episode reward total was 6.0. running mean: 12.683847601593982\n",
      "resetting env. episode reward total was 6.0. running mean: 12.617009125578042\n",
      "resetting env. episode reward total was 13.0. running mean: 12.620839034322263\n",
      "resetting env. episode reward total was 9.0. running mean: 12.58463064397904\n",
      "resetting env. episode reward total was 15.0. running mean: 12.60878433753925\n",
      "resetting env. episode reward total was 13.0. running mean: 12.612696494163858\n",
      "resetting env. episode reward total was 11.0. running mean: 12.596569529222219\n",
      "resetting env. episode reward total was 8.0. running mean: 12.550603833929996\n",
      "resetting env. episode reward total was 12.0. running mean: 12.545097795590696\n",
      "resetting env. episode reward total was 14.0. running mean: 12.559646817634789\n",
      "resetting env. episode reward total was 14.0. running mean: 12.574050349458442\n",
      "resetting env. episode reward total was 15.0. running mean: 12.598309845963858\n",
      "resetting env. episode reward total was 15.0. running mean: 12.62232674750422\n",
      "resetting env. episode reward total was 17.0. running mean: 12.666103480029177\n",
      "resetting env. episode reward total was 16.0. running mean: 12.699442445228886\n",
      "resetting env. episode reward total was 12.0. running mean: 12.692448020776597\n",
      "resetting env. episode reward total was 16.0. running mean: 12.725523540568831\n",
      "resetting env. episode reward total was 16.0. running mean: 12.758268305163144\n",
      "resetting env. episode reward total was 5.0. running mean: 12.680685622111513\n",
      "resetting env. episode reward total was 18.0. running mean: 12.733878765890397\n",
      "resetting env. episode reward total was 19.0. running mean: 12.796539978231493\n",
      "resetting env. episode reward total was 15.0. running mean: 12.818574578449178\n",
      "resetting env. episode reward total was 20.0. running mean: 12.890388832664685\n",
      "resetting env. episode reward total was 9.0. running mean: 12.851484944338038\n",
      "resetting env. episode reward total was 9.0. running mean: 12.812970094894657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 16.0. running mean: 12.844840393945711\n",
      "resetting env. episode reward total was 13.0. running mean: 12.846391990006255\n",
      "resetting env. episode reward total was 12.0. running mean: 12.837928070106193\n",
      "resetting env. episode reward total was 14.0. running mean: 12.849548789405132\n",
      "resetting env. episode reward total was 14.0. running mean: 12.861053301511081\n",
      "resetting env. episode reward total was 6.0. running mean: 12.79244276849597\n",
      "resetting env. episode reward total was 10.0. running mean: 12.76451834081101\n",
      "resetting env. episode reward total was 6.0. running mean: 12.696873157402901\n",
      "resetting env. episode reward total was 17.0. running mean: 12.739904425828872\n",
      "resetting env. episode reward total was 14.0. running mean: 12.752505381570584\n",
      "resetting env. episode reward total was 8.0. running mean: 12.704980327754878\n",
      "resetting env. episode reward total was 6.0. running mean: 12.63793052447733\n",
      "resetting env. episode reward total was 14.0. running mean: 12.651551219232557\n",
      "resetting env. episode reward total was 17.0. running mean: 12.695035707040232\n",
      "resetting env. episode reward total was 7.0. running mean: 12.63808534996983\n",
      "resetting env. episode reward total was 20.0. running mean: 12.71170449647013\n",
      "resetting env. episode reward total was 11.0. running mean: 12.694587451505429\n",
      "resetting env. episode reward total was 11.0. running mean: 12.677641576990373\n",
      "resetting env. episode reward total was 10.0. running mean: 12.65086516122047\n",
      "resetting env. episode reward total was 16.0. running mean: 12.684356509608264\n",
      "resetting env. episode reward total was 6.0. running mean: 12.617512944512182\n",
      "resetting env. episode reward total was 14.0. running mean: 12.631337815067061\n",
      "resetting env. episode reward total was 14.0. running mean: 12.64502443691639\n",
      "resetting env. episode reward total was 10.0. running mean: 12.618574192547227\n",
      "resetting env. episode reward total was 11.0. running mean: 12.602388450621755\n",
      "resetting env. episode reward total was 14.0. running mean: 12.616364566115537\n",
      "resetting env. episode reward total was 9.0. running mean: 12.580200920454383\n",
      "resetting env. episode reward total was 16.0. running mean: 12.61439891124984\n",
      "resetting env. episode reward total was 12.0. running mean: 12.60825492213734\n",
      "resetting env. episode reward total was 13.0. running mean: 12.612172372915968\n",
      "resetting env. episode reward total was 12.0. running mean: 12.606050649186807\n",
      "resetting env. episode reward total was 12.0. running mean: 12.599990142694939\n",
      "resetting env. episode reward total was 9.0. running mean: 12.56399024126799\n",
      "resetting env. episode reward total was 8.0. running mean: 12.51835033885531\n",
      "resetting env. episode reward total was 6.0. running mean: 12.453166835466757\n",
      "resetting env. episode reward total was 7.0. running mean: 12.39863516711209\n",
      "resetting env. episode reward total was 14.0. running mean: 12.41464881544097\n",
      "resetting env. episode reward total was 18.0. running mean: 12.47050232728656\n",
      "resetting env. episode reward total was 19.0. running mean: 12.535797304013695\n",
      "resetting env. episode reward total was 16.0. running mean: 12.570439330973558\n",
      "resetting env. episode reward total was 12.0. running mean: 12.564734937663822\n",
      "resetting env. episode reward total was 15.0. running mean: 12.589087588287184\n",
      "resetting env. episode reward total was 11.0. running mean: 12.573196712404311\n",
      "resetting env. episode reward total was 13.0. running mean: 12.577464745280269\n",
      "resetting env. episode reward total was 10.0. running mean: 12.551690097827466\n",
      "resetting env. episode reward total was 16.0. running mean: 12.586173196849192\n",
      "resetting env. episode reward total was 18.0. running mean: 12.6403114648807\n",
      "resetting env. episode reward total was 14.0. running mean: 12.653908350231893\n",
      "resetting env. episode reward total was 15.0. running mean: 12.677369266729574\n",
      "resetting env. episode reward total was 12.0. running mean: 12.670595574062277\n",
      "resetting env. episode reward total was 7.0. running mean: 12.613889618321656\n",
      "resetting env. episode reward total was 15.0. running mean: 12.637750722138438\n",
      "resetting env. episode reward total was 14.0. running mean: 12.651373214917054\n",
      "resetting env. episode reward total was 3.0. running mean: 12.554859482767883\n",
      "resetting env. episode reward total was 16.0. running mean: 12.589310887940204\n",
      "resetting env. episode reward total was 12.0. running mean: 12.5834177790608\n",
      "resetting env. episode reward total was 11.0. running mean: 12.567583601270192\n",
      "resetting env. episode reward total was 12.0. running mean: 12.561907765257489\n",
      "resetting env. episode reward total was 5.0. running mean: 12.486288687604915\n",
      "resetting env. episode reward total was 8.0. running mean: 12.441425800728867\n",
      "resetting env. episode reward total was 11.0. running mean: 12.427011542721578\n",
      "resetting env. episode reward total was 15.0. running mean: 12.452741427294363\n",
      "resetting env. episode reward total was 6.0. running mean: 12.38821401302142\n",
      "resetting env. episode reward total was 9.0. running mean: 12.354331872891205\n",
      "resetting env. episode reward total was 14.0. running mean: 12.370788554162294\n",
      "resetting env. episode reward total was 13.0. running mean: 12.377080668620671\n",
      "resetting env. episode reward total was 10.0. running mean: 12.353309861934465\n",
      "resetting env. episode reward total was 15.0. running mean: 12.379776763315121\n",
      "resetting env. episode reward total was 16.0. running mean: 12.41597899568197\n",
      "resetting env. episode reward total was 16.0. running mean: 12.45181920572515\n",
      "resetting env. episode reward total was 13.0. running mean: 12.457301013667898\n",
      "resetting env. episode reward total was 15.0. running mean: 12.48272800353122\n",
      "resetting env. episode reward total was 6.0. running mean: 12.417900723495908\n",
      "resetting env. episode reward total was 16.0. running mean: 12.453721716260949\n",
      "resetting env. episode reward total was 15.0. running mean: 12.47918449909834\n",
      "resetting env. episode reward total was 9.0. running mean: 12.444392654107356\n",
      "resetting env. episode reward total was 18.0. running mean: 12.49994872756628\n",
      "resetting env. episode reward total was 14.0. running mean: 12.514949240290619\n",
      "resetting env. episode reward total was 11.0. running mean: 12.499799747887712\n",
      "resetting env. episode reward total was 18.0. running mean: 12.554801750408835\n",
      "resetting env. episode reward total was 14.0. running mean: 12.569253732904746\n",
      "resetting env. episode reward total was 12.0. running mean: 12.563561195575698\n",
      "resetting env. episode reward total was 12.0. running mean: 12.55792558361994\n",
      "resetting env. episode reward total was 4.0. running mean: 12.47234632778374\n",
      "resetting env. episode reward total was 6.0. running mean: 12.407622864505903\n",
      "resetting env. episode reward total was 11.0. running mean: 12.393546635860844\n",
      "resetting env. episode reward total was 8.0. running mean: 12.349611169502236\n",
      "resetting env. episode reward total was 13.0. running mean: 12.356115057807214\n",
      "resetting env. episode reward total was 14.0. running mean: 12.372553907229143\n",
      "resetting env. episode reward total was 17.0. running mean: 12.418828368156852\n",
      "resetting env. episode reward total was 7.0. running mean: 12.364640084475283\n",
      "resetting env. episode reward total was 12.0. running mean: 12.360993683630529\n",
      "resetting env. episode reward total was 17.0. running mean: 12.407383746794224\n",
      "resetting env. episode reward total was 9.0. running mean: 12.37330990932628\n",
      "resetting env. episode reward total was 9.0. running mean: 12.339576810233018\n",
      "resetting env. episode reward total was 12.0. running mean: 12.336181042130686\n",
      "resetting env. episode reward total was 16.0. running mean: 12.37281923170938\n",
      "resetting env. episode reward total was 12.0. running mean: 12.369091039392286\n",
      "resetting env. episode reward total was 8.0. running mean: 12.325400128998362\n",
      "resetting env. episode reward total was 7.0. running mean: 12.272146127708378\n",
      "resetting env. episode reward total was 13.0. running mean: 12.279424666431295\n",
      "resetting env. episode reward total was 12.0. running mean: 12.276630419766981\n",
      "resetting env. episode reward total was 18.0. running mean: 12.33386411556931\n",
      "resetting env. episode reward total was 14.0. running mean: 12.350525474413619\n",
      "resetting env. episode reward total was 14.0. running mean: 12.367020219669483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 12.313350017472787\n",
      "resetting env. episode reward total was 11.0. running mean: 12.30021651729806\n",
      "resetting env. episode reward total was 8.0. running mean: 12.257214352125079\n",
      "resetting env. episode reward total was 10.0. running mean: 12.234642208603827\n",
      "resetting env. episode reward total was 14.0. running mean: 12.25229578651779\n",
      "resetting env. episode reward total was 13.0. running mean: 12.259772828652613\n",
      "resetting env. episode reward total was 10.0. running mean: 12.237175100366086\n",
      "resetting env. episode reward total was 12.0. running mean: 12.234803349362425\n",
      "resetting env. episode reward total was 7.0. running mean: 12.1824553158688\n",
      "resetting env. episode reward total was 9.0. running mean: 12.150630762710112\n",
      "resetting env. episode reward total was 5.0. running mean: 12.079124455083011\n",
      "resetting env. episode reward total was 10.0. running mean: 12.058333210532181\n",
      "resetting env. episode reward total was 1.0. running mean: 11.947749878426858\n",
      "resetting env. episode reward total was 12.0. running mean: 11.948272379642589\n",
      "resetting env. episode reward total was 14.0. running mean: 11.968789655846164\n",
      "resetting env. episode reward total was -1.0. running mean: 11.839101759287702\n",
      "resetting env. episode reward total was 8.0. running mean: 11.800710741694825\n",
      "resetting env. episode reward total was 13.0. running mean: 11.812703634277877\n",
      "resetting env. episode reward total was 15.0. running mean: 11.844576597935099\n",
      "resetting env. episode reward total was 19.0. running mean: 11.916130831955748\n",
      "resetting env. episode reward total was 10.0. running mean: 11.896969523636189\n",
      "resetting env. episode reward total was 8.0. running mean: 11.857999828399826\n",
      "resetting env. episode reward total was 10.0. running mean: 11.839419830115828\n",
      "resetting env. episode reward total was 16.0. running mean: 11.88102563181467\n",
      "resetting env. episode reward total was 17.0. running mean: 11.932215375496522\n",
      "resetting env. episode reward total was 13.0. running mean: 11.942893221741558\n",
      "resetting env. episode reward total was 14.0. running mean: 11.963464289524143\n",
      "resetting env. episode reward total was 15.0. running mean: 11.993829646628901\n",
      "resetting env. episode reward total was 6.0. running mean: 11.933891350162613\n",
      "resetting env. episode reward total was 12.0. running mean: 11.934552436660987\n",
      "resetting env. episode reward total was 9.0. running mean: 11.905206912294377\n",
      "resetting env. episode reward total was 1.0. running mean: 11.796154843171433\n",
      "resetting env. episode reward total was 13.0. running mean: 11.80819329473972\n",
      "resetting env. episode reward total was 13.0. running mean: 11.820111361792323\n",
      "resetting env. episode reward total was 12.0. running mean: 11.8219102481744\n",
      "resetting env. episode reward total was 6.0. running mean: 11.763691145692656\n",
      "resetting env. episode reward total was 9.0. running mean: 11.736054234235729\n",
      "resetting env. episode reward total was 14.0. running mean: 11.758693691893372\n",
      "resetting env. episode reward total was 15.0. running mean: 11.791106754974438\n",
      "resetting env. episode reward total was 11.0. running mean: 11.783195687424692\n",
      "resetting env. episode reward total was 14.0. running mean: 11.805363730550447\n",
      "resetting env. episode reward total was 6.0. running mean: 11.747310093244943\n",
      "resetting env. episode reward total was 11.0. running mean: 11.739836992312492\n",
      "resetting env. episode reward total was 16.0. running mean: 11.782438622389368\n",
      "resetting env. episode reward total was 17.0. running mean: 11.834614236165473\n",
      "resetting env. episode reward total was 12.0. running mean: 11.836268093803817\n",
      "resetting env. episode reward total was 10.0. running mean: 11.817905412865779\n",
      "resetting env. episode reward total was 13.0. running mean: 11.82972635873712\n",
      "resetting env. episode reward total was 16.0. running mean: 11.87142909514975\n",
      "resetting env. episode reward total was 9.0. running mean: 11.842714804198252\n",
      "resetting env. episode reward total was 9.0. running mean: 11.814287656156269\n",
      "resetting env. episode reward total was 10.0. running mean: 11.796144779594705\n",
      "resetting env. episode reward total was 12.0. running mean: 11.798183331798757\n",
      "resetting env. episode reward total was 16.0. running mean: 11.84020149848077\n",
      "resetting env. episode reward total was 9.0. running mean: 11.811799483495962\n",
      "resetting env. episode reward total was 12.0. running mean: 11.813681488661002\n",
      "resetting env. episode reward total was -1.0. running mean: 11.685544673774393\n",
      "resetting env. episode reward total was 5.0. running mean: 11.618689227036649\n",
      "resetting env. episode reward total was 15.0. running mean: 11.652502334766282\n",
      "resetting env. episode reward total was 14.0. running mean: 11.67597731141862\n",
      "resetting env. episode reward total was 13.0. running mean: 11.689217538304435\n",
      "resetting env. episode reward total was 10.0. running mean: 11.67232536292139\n",
      "resetting env. episode reward total was 10.0. running mean: 11.655602109292175\n",
      "resetting env. episode reward total was 3.0. running mean: 11.569046088199253\n",
      "resetting env. episode reward total was 5.0. running mean: 11.50335562731726\n",
      "resetting env. episode reward total was 7.0. running mean: 11.458322071044089\n",
      "resetting env. episode reward total was 15.0. running mean: 11.493738850333648\n",
      "resetting env. episode reward total was 10.0. running mean: 11.47880146183031\n",
      "resetting env. episode reward total was 12.0. running mean: 11.484013447212005\n",
      "resetting env. episode reward total was 13.0. running mean: 11.499173312739886\n",
      "resetting env. episode reward total was 10.0. running mean: 11.484181579612487\n",
      "resetting env. episode reward total was 12.0. running mean: 11.489339763816362\n",
      "resetting env. episode reward total was 10.0. running mean: 11.474446366178197\n",
      "resetting env. episode reward total was 15.0. running mean: 11.509701902516415\n",
      "resetting env. episode reward total was 6.0. running mean: 11.454604883491251\n",
      "resetting env. episode reward total was 7.0. running mean: 11.41005883465634\n",
      "resetting env. episode reward total was 14.0. running mean: 11.435958246309777\n",
      "resetting env. episode reward total was 5.0. running mean: 11.37159866384668\n",
      "resetting env. episode reward total was 16.0. running mean: 11.417882677208214\n",
      "resetting env. episode reward total was 16.0. running mean: 11.463703850436131\n",
      "resetting env. episode reward total was 8.0. running mean: 11.42906681193177\n",
      "resetting env. episode reward total was 8.0. running mean: 11.394776143812452\n",
      "resetting env. episode reward total was 18.0. running mean: 11.460828382374327\n",
      "resetting env. episode reward total was 11.0. running mean: 11.456220098550583\n",
      "resetting env. episode reward total was 12.0. running mean: 11.461657897565075\n",
      "resetting env. episode reward total was 11.0. running mean: 11.457041318589424\n",
      "resetting env. episode reward total was 19.0. running mean: 11.532470905403528\n",
      "resetting env. episode reward total was 12.0. running mean: 11.537146196349491\n",
      "resetting env. episode reward total was 17.0. running mean: 11.591774734385996\n",
      "resetting env. episode reward total was 1.0. running mean: 11.485856987042137\n",
      "resetting env. episode reward total was 10.0. running mean: 11.470998417171716\n",
      "resetting env. episode reward total was 14.0. running mean: 11.496288432999998\n",
      "resetting env. episode reward total was 14.0. running mean: 11.52132554867\n",
      "resetting env. episode reward total was 13.0. running mean: 11.5361122931833\n",
      "resetting env. episode reward total was 11.0. running mean: 11.530751170251465\n",
      "resetting env. episode reward total was 15.0. running mean: 11.56544365854895\n",
      "resetting env. episode reward total was 9.0. running mean: 11.539789221963462\n",
      "resetting env. episode reward total was 10.0. running mean: 11.524391329743827\n",
      "resetting env. episode reward total was 6.0. running mean: 11.469147416446388\n",
      "resetting env. episode reward total was 12.0. running mean: 11.474455942281923\n",
      "resetting env. episode reward total was 8.0. running mean: 11.439711382859103\n",
      "resetting env. episode reward total was 15.0. running mean: 11.475314269030513\n",
      "resetting env. episode reward total was 9.0. running mean: 11.450561126340208\n",
      "resetting env. episode reward total was 12.0. running mean: 11.456055515076805\n",
      "resetting env. episode reward total was 8.0. running mean: 11.421494959926036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 11.427280010326776\n",
      "resetting env. episode reward total was 17.0. running mean: 11.483007210223507\n",
      "resetting env. episode reward total was 6.0. running mean: 11.428177138121272\n",
      "resetting env. episode reward total was 10.0. running mean: 11.413895366740059\n",
      "resetting env. episode reward total was 12.0. running mean: 11.419756413072657\n",
      "resetting env. episode reward total was 13.0. running mean: 11.43555884894193\n",
      "resetting env. episode reward total was 10.0. running mean: 11.421203260452511\n",
      "resetting env. episode reward total was 11.0. running mean: 11.416991227847985\n",
      "resetting env. episode reward total was 14.0. running mean: 11.442821315569505\n",
      "resetting env. episode reward total was 12.0. running mean: 11.448393102413808\n",
      "resetting env. episode reward total was 13.0. running mean: 11.463909171389671\n",
      "resetting env. episode reward total was 14.0. running mean: 11.489270079675775\n",
      "resetting env. episode reward total was 12.0. running mean: 11.494377378879015\n",
      "resetting env. episode reward total was 15.0. running mean: 11.529433605090226\n",
      "resetting env. episode reward total was 13.0. running mean: 11.544139269039324\n",
      "resetting env. episode reward total was 15.0. running mean: 11.578697876348931\n",
      "resetting env. episode reward total was 14.0. running mean: 11.602910897585442\n",
      "resetting env. episode reward total was 6.0. running mean: 11.546881788609587\n",
      "resetting env. episode reward total was 12.0. running mean: 11.55141297072349\n",
      "resetting env. episode reward total was 15.0. running mean: 11.585898841016256\n",
      "resetting env. episode reward total was 13.0. running mean: 11.600039852606095\n",
      "resetting env. episode reward total was 15.0. running mean: 11.634039454080034\n",
      "resetting env. episode reward total was 11.0. running mean: 11.627699059539232\n",
      "resetting env. episode reward total was 8.0. running mean: 11.59142206894384\n",
      "resetting env. episode reward total was 4.0. running mean: 11.515507848254401\n",
      "resetting env. episode reward total was 7.0. running mean: 11.470352769771857\n",
      "resetting env. episode reward total was 8.0. running mean: 11.435649242074138\n",
      "resetting env. episode reward total was 4.0. running mean: 11.361292749653396\n",
      "resetting env. episode reward total was 9.0. running mean: 11.337679822156861\n",
      "resetting env. episode reward total was 5.0. running mean: 11.274303023935293\n",
      "resetting env. episode reward total was 17.0. running mean: 11.33155999369594\n",
      "resetting env. episode reward total was 19.0. running mean: 11.40824439375898\n",
      "resetting env. episode reward total was 9.0. running mean: 11.38416194982139\n",
      "resetting env. episode reward total was 3.0. running mean: 11.300320330323176\n",
      "resetting env. episode reward total was 15.0. running mean: 11.337317127019945\n",
      "resetting env. episode reward total was 12.0. running mean: 11.343943955749745\n",
      "resetting env. episode reward total was 1.0. running mean: 11.240504516192248\n",
      "resetting env. episode reward total was 11.0. running mean: 11.238099471030324\n",
      "resetting env. episode reward total was 3.0. running mean: 11.15571847632002\n",
      "resetting env. episode reward total was 12.0. running mean: 11.16416129155682\n",
      "resetting env. episode reward total was 17.0. running mean: 11.222519678641252\n",
      "resetting env. episode reward total was 11.0. running mean: 11.220294481854838\n",
      "resetting env. episode reward total was 15.0. running mean: 11.25809153703629\n",
      "resetting env. episode reward total was 11.0. running mean: 11.255510621665925\n",
      "resetting env. episode reward total was 12.0. running mean: 11.262955515449265\n",
      "resetting env. episode reward total was 18.0. running mean: 11.330325960294772\n",
      "resetting env. episode reward total was 17.0. running mean: 11.387022700691825\n",
      "resetting env. episode reward total was 4.0. running mean: 11.313152473684905\n",
      "resetting env. episode reward total was 15.0. running mean: 11.350020948948057\n",
      "resetting env. episode reward total was 14.0. running mean: 11.376520739458577\n",
      "resetting env. episode reward total was 10.0. running mean: 11.362755532063991\n",
      "resetting env. episode reward total was 10.0. running mean: 11.34912797674335\n",
      "resetting env. episode reward total was 15.0. running mean: 11.385636696975917\n",
      "resetting env. episode reward total was 17.0. running mean: 11.441780330006157\n",
      "resetting env. episode reward total was 7.0. running mean: 11.397362526706095\n",
      "resetting env. episode reward total was 9.0. running mean: 11.373388901439034\n",
      "resetting env. episode reward total was 18.0. running mean: 11.439655012424643\n",
      "resetting env. episode reward total was 12.0. running mean: 11.445258462300396\n",
      "resetting env. episode reward total was 19.0. running mean: 11.520805877677391\n",
      "resetting env. episode reward total was 12.0. running mean: 11.525597818900616\n",
      "resetting env. episode reward total was 17.0. running mean: 11.58034184071161\n",
      "resetting env. episode reward total was 11.0. running mean: 11.574538422304492\n",
      "resetting env. episode reward total was 12.0. running mean: 11.578793038081447\n",
      "resetting env. episode reward total was 9.0. running mean: 11.553005107700631\n",
      "resetting env. episode reward total was 7.0. running mean: 11.507475056623624\n",
      "resetting env. episode reward total was 13.0. running mean: 11.522400306057389\n",
      "resetting env. episode reward total was 13.0. running mean: 11.537176302996816\n",
      "resetting env. episode reward total was 19.0. running mean: 11.611804539966847\n",
      "resetting env. episode reward total was 13.0. running mean: 11.62568649456718\n",
      "resetting env. episode reward total was 13.0. running mean: 11.639429629621509\n",
      "resetting env. episode reward total was 18.0. running mean: 11.703035333325293\n",
      "resetting env. episode reward total was 9.0. running mean: 11.67600497999204\n",
      "resetting env. episode reward total was 7.0. running mean: 11.62924493019212\n",
      "resetting env. episode reward total was 17.0. running mean: 11.682952480890199\n",
      "resetting env. episode reward total was 9.0. running mean: 11.656122956081298\n",
      "resetting env. episode reward total was 13.0. running mean: 11.669561726520485\n",
      "resetting env. episode reward total was 10.0. running mean: 11.65286610925528\n",
      "resetting env. episode reward total was 16.0. running mean: 11.696337448162726\n",
      "resetting env. episode reward total was 16.0. running mean: 11.739374073681098\n",
      "resetting env. episode reward total was 16.0. running mean: 11.781980332944288\n",
      "resetting env. episode reward total was 15.0. running mean: 11.814160529614846\n",
      "resetting env. episode reward total was 16.0. running mean: 11.856018924318697\n",
      "resetting env. episode reward total was 12.0. running mean: 11.85745873507551\n",
      "resetting env. episode reward total was 15.0. running mean: 11.888884147724754\n",
      "resetting env. episode reward total was 10.0. running mean: 11.869995306247507\n",
      "resetting env. episode reward total was 7.0. running mean: 11.821295353185032\n",
      "resetting env. episode reward total was 17.0. running mean: 11.873082399653182\n",
      "resetting env. episode reward total was 18.0. running mean: 11.934351575656649\n",
      "resetting env. episode reward total was 5.0. running mean: 11.865008059900083\n",
      "resetting env. episode reward total was 12.0. running mean: 11.866357979301082\n",
      "resetting env. episode reward total was 12.0. running mean: 11.86769439950807\n",
      "resetting env. episode reward total was 7.0. running mean: 11.81901745551299\n",
      "resetting env. episode reward total was 12.0. running mean: 11.82082728095786\n",
      "resetting env. episode reward total was 16.0. running mean: 11.86261900814828\n",
      "resetting env. episode reward total was 13.0. running mean: 11.873992818066798\n",
      "resetting env. episode reward total was 17.0. running mean: 11.92525288988613\n",
      "resetting env. episode reward total was 17.0. running mean: 11.976000360987268\n",
      "resetting env. episode reward total was 12.0. running mean: 11.976240357377394\n",
      "resetting env. episode reward total was 14.0. running mean: 11.996477953803621\n",
      "resetting env. episode reward total was 11.0. running mean: 11.986513174265584\n",
      "resetting env. episode reward total was 17.0. running mean: 12.036648042522927\n",
      "resetting env. episode reward total was 13.0. running mean: 12.046281562097699\n",
      "resetting env. episode reward total was 16.0. running mean: 12.085818746476722\n",
      "resetting env. episode reward total was 14.0. running mean: 12.104960559011955\n",
      "resetting env. episode reward total was 15.0. running mean: 12.133910953421836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 17.0. running mean: 12.182571843887617\n",
      "resetting env. episode reward total was 7.0. running mean: 12.130746125448741\n",
      "resetting env. episode reward total was 14.0. running mean: 12.149438664194255\n",
      "resetting env. episode reward total was 3.0. running mean: 12.057944277552313\n",
      "resetting env. episode reward total was 8.0. running mean: 12.017364834776789\n",
      "resetting env. episode reward total was 14.0. running mean: 12.037191186429022\n",
      "resetting env. episode reward total was 12.0. running mean: 12.03681927456473\n",
      "resetting env. episode reward total was 12.0. running mean: 12.03645108181908\n",
      "resetting env. episode reward total was 16.0. running mean: 12.07608657100089\n",
      "resetting env. episode reward total was 15.0. running mean: 12.10532570529088\n",
      "resetting env. episode reward total was 12.0. running mean: 12.104272448237971\n",
      "resetting env. episode reward total was 12.0. running mean: 12.103229723755591\n",
      "resetting env. episode reward total was 7.0. running mean: 12.052197426518035\n",
      "resetting env. episode reward total was 13.0. running mean: 12.061675452252855\n",
      "resetting env. episode reward total was 10.0. running mean: 12.041058697730326\n",
      "resetting env. episode reward total was 12.0. running mean: 12.040648110753022\n",
      "resetting env. episode reward total was 12.0. running mean: 12.040241629645491\n",
      "resetting env. episode reward total was 16.0. running mean: 12.079839213349036\n",
      "resetting env. episode reward total was 17.0. running mean: 12.129040821215545\n",
      "resetting env. episode reward total was 17.0. running mean: 12.17775041300339\n",
      "resetting env. episode reward total was 7.0. running mean: 12.125972908873356\n",
      "resetting env. episode reward total was 18.0. running mean: 12.184713179784621\n",
      "resetting env. episode reward total was 12.0. running mean: 12.182866047986774\n",
      "resetting env. episode reward total was 11.0. running mean: 12.171037387506907\n",
      "resetting env. episode reward total was 13.0. running mean: 12.179327013631838\n",
      "resetting env. episode reward total was 6.0. running mean: 12.11753374349552\n",
      "resetting env. episode reward total was 14.0. running mean: 12.136358406060564\n",
      "resetting env. episode reward total was 11.0. running mean: 12.124994821999959\n",
      "resetting env. episode reward total was 16.0. running mean: 12.16374487377996\n",
      "resetting env. episode reward total was 10.0. running mean: 12.142107425042159\n",
      "resetting env. episode reward total was 13.0. running mean: 12.150686350791737\n",
      "resetting env. episode reward total was 2.0. running mean: 12.04917948728382\n",
      "resetting env. episode reward total was 14.0. running mean: 12.06868769241098\n",
      "resetting env. episode reward total was 5.0. running mean: 11.998000815486872\n",
      "resetting env. episode reward total was 13.0. running mean: 12.008020807332004\n",
      "resetting env. episode reward total was 13.0. running mean: 12.017940599258685\n",
      "resetting env. episode reward total was 13.0. running mean: 12.027761193266098\n",
      "resetting env. episode reward total was 14.0. running mean: 12.047483581333438\n",
      "resetting env. episode reward total was 14.0. running mean: 12.067008745520104\n",
      "resetting env. episode reward total was 18.0. running mean: 12.126338658064903\n",
      "resetting env. episode reward total was 14.0. running mean: 12.145075271484254\n",
      "resetting env. episode reward total was 18.0. running mean: 12.203624518769411\n",
      "resetting env. episode reward total was 12.0. running mean: 12.201588273581716\n",
      "resetting env. episode reward total was 14.0. running mean: 12.219572390845899\n",
      "resetting env. episode reward total was 14.0. running mean: 12.23737666693744\n",
      "resetting env. episode reward total was 12.0. running mean: 12.235002900268064\n",
      "resetting env. episode reward total was 17.0. running mean: 12.282652871265384\n",
      "resetting env. episode reward total was 10.0. running mean: 12.25982634255273\n",
      "resetting env. episode reward total was 14.0. running mean: 12.277228079127203\n",
      "resetting env. episode reward total was 9.0. running mean: 12.244455798335931\n",
      "resetting env. episode reward total was 15.0. running mean: 12.272011240352573\n",
      "resetting env. episode reward total was 6.0. running mean: 12.209291127949047\n",
      "resetting env. episode reward total was 12.0. running mean: 12.207198216669555\n",
      "resetting env. episode reward total was 13.0. running mean: 12.21512623450286\n",
      "resetting env. episode reward total was 12.0. running mean: 12.21297497215783\n",
      "resetting env. episode reward total was 9.0. running mean: 12.180845222436252\n",
      "resetting env. episode reward total was 8.0. running mean: 12.13903677021189\n",
      "resetting env. episode reward total was 17.0. running mean: 12.18764640250977\n",
      "resetting env. episode reward total was 6.0. running mean: 12.125769938484673\n",
      "resetting env. episode reward total was 16.0. running mean: 12.164512239099826\n",
      "resetting env. episode reward total was 11.0. running mean: 12.152867116708828\n",
      "resetting env. episode reward total was 18.0. running mean: 12.21133844554174\n",
      "resetting env. episode reward total was 16.0. running mean: 12.249225061086323\n",
      "resetting env. episode reward total was 8.0. running mean: 12.20673281047546\n",
      "resetting env. episode reward total was 20.0. running mean: 12.284665482370704\n",
      "resetting env. episode reward total was 6.0. running mean: 12.221818827546997\n",
      "resetting env. episode reward total was 15.0. running mean: 12.249600639271527\n",
      "resetting env. episode reward total was 12.0. running mean: 12.247104632878811\n",
      "resetting env. episode reward total was 15.0. running mean: 12.274633586550022\n",
      "resetting env. episode reward total was 8.0. running mean: 12.231887250684522\n",
      "resetting env. episode reward total was 9.0. running mean: 12.199568378177677\n",
      "resetting env. episode reward total was 17.0. running mean: 12.2475726943959\n",
      "resetting env. episode reward total was 18.0. running mean: 12.305096967451941\n",
      "resetting env. episode reward total was 14.0. running mean: 12.322045997777423\n",
      "resetting env. episode reward total was 14.0. running mean: 12.338825537799648\n",
      "resetting env. episode reward total was 9.0. running mean: 12.305437282421652\n",
      "resetting env. episode reward total was 14.0. running mean: 12.322382909597435\n",
      "resetting env. episode reward total was 10.0. running mean: 12.29915908050146\n",
      "resetting env. episode reward total was 8.0. running mean: 12.256167489696445\n",
      "resetting env. episode reward total was 19.0. running mean: 12.32360581479948\n",
      "resetting env. episode reward total was 11.0. running mean: 12.310369756651484\n",
      "resetting env. episode reward total was 10.0. running mean: 12.287266059084969\n",
      "resetting env. episode reward total was 5.0. running mean: 12.214393398494119\n",
      "resetting env. episode reward total was 9.0. running mean: 12.182249464509177\n",
      "resetting env. episode reward total was 14.0. running mean: 12.200426969864084\n",
      "resetting env. episode reward total was 9.0. running mean: 12.168422700165443\n",
      "resetting env. episode reward total was -1.0. running mean: 12.036738473163789\n",
      "resetting env. episode reward total was 15.0. running mean: 12.06637108843215\n",
      "resetting env. episode reward total was 5.0. running mean: 11.995707377547829\n",
      "resetting env. episode reward total was 11.0. running mean: 11.98575030377235\n",
      "resetting env. episode reward total was 11.0. running mean: 11.975892800734627\n",
      "resetting env. episode reward total was 1.0. running mean: 11.86613387272728\n",
      "resetting env. episode reward total was 16.0. running mean: 11.907472534000007\n",
      "resetting env. episode reward total was 15.0. running mean: 11.938397808660007\n",
      "resetting env. episode reward total was 10.0. running mean: 11.919013830573407\n",
      "resetting env. episode reward total was 16.0. running mean: 11.959823692267673\n",
      "resetting env. episode reward total was 12.0. running mean: 11.960225455344995\n",
      "resetting env. episode reward total was 12.0. running mean: 11.960623200791543\n",
      "resetting env. episode reward total was 7.0. running mean: 11.911016968783628\n",
      "resetting env. episode reward total was 12.0. running mean: 11.91190679909579\n",
      "resetting env. episode reward total was 12.0. running mean: 11.912787731104832\n",
      "resetting env. episode reward total was 14.0. running mean: 11.933659853793785\n",
      "resetting env. episode reward total was 10.0. running mean: 11.914323255255846\n",
      "resetting env. episode reward total was 9.0. running mean: 11.885180022703288\n",
      "resetting env. episode reward total was 17.0. running mean: 11.936328222476256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 16.0. running mean: 11.976964940251493\n",
      "resetting env. episode reward total was 14.0. running mean: 11.997195290848978\n",
      "resetting env. episode reward total was 18.0. running mean: 12.057223337940489\n",
      "resetting env. episode reward total was 15.0. running mean: 12.086651104561083\n",
      "resetting env. episode reward total was 17.0. running mean: 12.135784593515472\n",
      "resetting env. episode reward total was 12.0. running mean: 12.134426747580317\n",
      "resetting env. episode reward total was 18.0. running mean: 12.193082480104513\n",
      "resetting env. episode reward total was 10.0. running mean: 12.171151655303467\n",
      "resetting env. episode reward total was 14.0. running mean: 12.189440138750433\n",
      "resetting env. episode reward total was 15.0. running mean: 12.21754573736293\n",
      "resetting env. episode reward total was 14.0. running mean: 12.2353702799893\n",
      "resetting env. episode reward total was 16.0. running mean: 12.273016577189408\n",
      "resetting env. episode reward total was 12.0. running mean: 12.270286411417512\n",
      "resetting env. episode reward total was 12.0. running mean: 12.267583547303335\n",
      "resetting env. episode reward total was 12.0. running mean: 12.2649077118303\n",
      "resetting env. episode reward total was 20.0. running mean: 12.342258634711996\n",
      "resetting env. episode reward total was 16.0. running mean: 12.378836048364876\n",
      "resetting env. episode reward total was 16.0. running mean: 12.415047687881227\n",
      "resetting env. episode reward total was 11.0. running mean: 12.400897211002414\n",
      "resetting env. episode reward total was 12.0. running mean: 12.396888238892389\n",
      "resetting env. episode reward total was 12.0. running mean: 12.392919356503464\n",
      "resetting env. episode reward total was 14.0. running mean: 12.40899016293843\n",
      "resetting env. episode reward total was 17.0. running mean: 12.454900261309046\n",
      "resetting env. episode reward total was 13.0. running mean: 12.460351258695956\n",
      "resetting env. episode reward total was 17.0. running mean: 12.505747746108996\n",
      "resetting env. episode reward total was 11.0. running mean: 12.490690268647906\n",
      "resetting env. episode reward total was 12.0. running mean: 12.485783365961426\n",
      "resetting env. episode reward total was 18.0. running mean: 12.540925532301811\n",
      "resetting env. episode reward total was 6.0. running mean: 12.475516276978793\n",
      "resetting env. episode reward total was 10.0. running mean: 12.450761114209005\n",
      "resetting env. episode reward total was 11.0. running mean: 12.436253503066915\n",
      "resetting env. episode reward total was 14.0. running mean: 12.451890968036246\n",
      "resetting env. episode reward total was 15.0. running mean: 12.477372058355883\n",
      "resetting env. episode reward total was 14.0. running mean: 12.492598337772325\n",
      "resetting env. episode reward total was 12.0. running mean: 12.4876723543946\n",
      "resetting env. episode reward total was 13.0. running mean: 12.492795630850654\n",
      "resetting env. episode reward total was 14.0. running mean: 12.507867674542148\n",
      "resetting env. episode reward total was 18.0. running mean: 12.562788997796726\n",
      "resetting env. episode reward total was 12.0. running mean: 12.557161107818759\n",
      "resetting env. episode reward total was 12.0. running mean: 12.55158949674057\n",
      "resetting env. episode reward total was 18.0. running mean: 12.606073601773165\n",
      "resetting env. episode reward total was 13.0. running mean: 12.610012865755435\n",
      "resetting env. episode reward total was 8.0. running mean: 12.56391273709788\n",
      "resetting env. episode reward total was 9.0. running mean: 12.5282736097269\n",
      "resetting env. episode reward total was 16.0. running mean: 12.562990873629632\n",
      "resetting env. episode reward total was 8.0. running mean: 12.517360964893335\n",
      "resetting env. episode reward total was 10.0. running mean: 12.4921873552444\n",
      "resetting env. episode reward total was 15.0. running mean: 12.517265481691958\n",
      "resetting env. episode reward total was 11.0. running mean: 12.502092826875037\n",
      "resetting env. episode reward total was 5.0. running mean: 12.427071898606288\n",
      "resetting env. episode reward total was 4.0. running mean: 12.342801179620224\n",
      "resetting env. episode reward total was 10.0. running mean: 12.319373167824022\n",
      "resetting env. episode reward total was 13.0. running mean: 12.326179436145782\n",
      "resetting env. episode reward total was 11.0. running mean: 12.312917641784324\n",
      "resetting env. episode reward total was 9.0. running mean: 12.279788465366481\n",
      "resetting env. episode reward total was 13.0. running mean: 12.286990580712818\n",
      "resetting env. episode reward total was 11.0. running mean: 12.274120674905689\n",
      "resetting env. episode reward total was 10.0. running mean: 12.251379468156632\n",
      "resetting env. episode reward total was 19.0. running mean: 12.318865673475065\n",
      "resetting env. episode reward total was 15.0. running mean: 12.345677016740314\n",
      "resetting env. episode reward total was 11.0. running mean: 12.332220246572911\n",
      "resetting env. episode reward total was 9.0. running mean: 12.298898044107181\n",
      "resetting env. episode reward total was 9.0. running mean: 12.26590906366611\n",
      "resetting env. episode reward total was 8.0. running mean: 12.223249973029448\n",
      "resetting env. episode reward total was 13.0. running mean: 12.231017473299154\n",
      "resetting env. episode reward total was 14.0. running mean: 12.248707298566163\n",
      "resetting env. episode reward total was 11.0. running mean: 12.236220225580501\n",
      "resetting env. episode reward total was 14.0. running mean: 12.253858023324696\n",
      "resetting env. episode reward total was 8.0. running mean: 12.21131944309145\n",
      "resetting env. episode reward total was 9.0. running mean: 12.179206248660535\n",
      "resetting env. episode reward total was 8.0. running mean: 12.13741418617393\n",
      "resetting env. episode reward total was 12.0. running mean: 12.136040044312189\n",
      "resetting env. episode reward total was 16.0. running mean: 12.174679643869068\n",
      "resetting env. episode reward total was 13.0. running mean: 12.182932847430378\n",
      "resetting env. episode reward total was 4.0. running mean: 12.101103518956073\n",
      "resetting env. episode reward total was 4.0. running mean: 12.020092483766511\n",
      "resetting env. episode reward total was 11.0. running mean: 12.009891558928846\n",
      "resetting env. episode reward total was 7.0. running mean: 11.959792643339558\n",
      "resetting env. episode reward total was 17.0. running mean: 12.010194716906161\n",
      "resetting env. episode reward total was 15.0. running mean: 12.0400927697371\n",
      "resetting env. episode reward total was 13.0. running mean: 12.04969184203973\n",
      "resetting env. episode reward total was 13.0. running mean: 12.059194923619334\n",
      "resetting env. episode reward total was 14.0. running mean: 12.078602974383141\n",
      "resetting env. episode reward total was 14.0. running mean: 12.09781694463931\n",
      "resetting env. episode reward total was 17.0. running mean: 12.146838775192917\n",
      "resetting env. episode reward total was 13.0. running mean: 12.155370387440989\n",
      "resetting env. episode reward total was 11.0. running mean: 12.143816683566579\n",
      "resetting env. episode reward total was 11.0. running mean: 12.132378516730911\n",
      "resetting env. episode reward total was 11.0. running mean: 12.121054731563602\n",
      "resetting env. episode reward total was 11.0. running mean: 12.109844184247965\n",
      "resetting env. episode reward total was 18.0. running mean: 12.168745742405486\n",
      "resetting env. episode reward total was 10.0. running mean: 12.14705828498143\n",
      "resetting env. episode reward total was 10.0. running mean: 12.125587702131615\n",
      "resetting env. episode reward total was 8.0. running mean: 12.084331825110299\n",
      "resetting env. episode reward total was 15.0. running mean: 12.113488506859197\n",
      "resetting env. episode reward total was 13.0. running mean: 12.122353621790605\n",
      "resetting env. episode reward total was 14.0. running mean: 12.1411300855727\n",
      "resetting env. episode reward total was 10.0. running mean: 12.119718784716973\n",
      "resetting env. episode reward total was 12.0. running mean: 12.118521596869803\n",
      "resetting env. episode reward total was 11.0. running mean: 12.107336380901105\n",
      "resetting env. episode reward total was 11.0. running mean: 12.096263017092094\n",
      "resetting env. episode reward total was 19.0. running mean: 12.165300386921173\n",
      "resetting env. episode reward total was 13.0. running mean: 12.173647383051962\n",
      "resetting env. episode reward total was 15.0. running mean: 12.201910909221443\n",
      "resetting env. episode reward total was 14.0. running mean: 12.21989180012923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 12.187692882127937\n",
      "resetting env. episode reward total was 13.0. running mean: 12.195815953306658\n",
      "resetting env. episode reward total was 9.0. running mean: 12.163857793773591\n",
      "resetting env. episode reward total was 14.0. running mean: 12.182219215835856\n",
      "resetting env. episode reward total was 13.0. running mean: 12.190397023677498\n",
      "resetting env. episode reward total was 10.0. running mean: 12.168493053440722\n",
      "resetting env. episode reward total was 11.0. running mean: 12.156808122906314\n",
      "resetting env. episode reward total was 15.0. running mean: 12.185240041677252\n",
      "resetting env. episode reward total was 4.0. running mean: 12.103387641260479\n",
      "resetting env. episode reward total was 10.0. running mean: 12.082353764847873\n",
      "resetting env. episode reward total was 15.0. running mean: 12.111530227199395\n",
      "resetting env. episode reward total was 18.0. running mean: 12.170414924927401\n",
      "resetting env. episode reward total was 15.0. running mean: 12.198710775678128\n",
      "resetting env. episode reward total was 17.0. running mean: 12.246723667921346\n",
      "resetting env. episode reward total was 10.0. running mean: 12.224256431242132\n",
      "resetting env. episode reward total was 15.0. running mean: 12.252013866929712\n",
      "resetting env. episode reward total was 15.0. running mean: 12.279493728260414\n",
      "resetting env. episode reward total was 11.0. running mean: 12.26669879097781\n",
      "resetting env. episode reward total was 13.0. running mean: 12.274031803068032\n",
      "resetting env. episode reward total was 16.0. running mean: 12.311291485037351\n",
      "resetting env. episode reward total was 17.0. running mean: 12.358178570186977\n",
      "resetting env. episode reward total was 7.0. running mean: 12.304596784485108\n",
      "resetting env. episode reward total was 8.0. running mean: 12.261550816640257\n",
      "resetting env. episode reward total was 16.0. running mean: 12.298935308473855\n",
      "resetting env. episode reward total was 18.0. running mean: 12.355945955389116\n",
      "resetting env. episode reward total was 15.0. running mean: 12.382386495835224\n",
      "resetting env. episode reward total was 13.0. running mean: 12.388562630876873\n",
      "resetting env. episode reward total was 2.0. running mean: 12.284677004568104\n",
      "resetting env. episode reward total was 15.0. running mean: 12.311830234522423\n",
      "resetting env. episode reward total was -2.0. running mean: 12.1687119321772\n",
      "resetting env. episode reward total was 14.0. running mean: 12.187024812855428\n",
      "resetting env. episode reward total was 15.0. running mean: 12.215154564726875\n",
      "resetting env. episode reward total was 5.0. running mean: 12.143003019079607\n",
      "resetting env. episode reward total was 13.0. running mean: 12.151572988888812\n",
      "resetting env. episode reward total was 13.0. running mean: 12.160057258999926\n",
      "resetting env. episode reward total was 12.0. running mean: 12.158456686409925\n",
      "resetting env. episode reward total was 10.0. running mean: 12.136872119545826\n",
      "resetting env. episode reward total was 12.0. running mean: 12.135503398350368\n",
      "resetting env. episode reward total was 15.0. running mean: 12.164148364366865\n",
      "resetting env. episode reward total was 19.0. running mean: 12.232506880723195\n",
      "resetting env. episode reward total was 3.0. running mean: 12.140181811915962\n",
      "resetting env. episode reward total was 10.0. running mean: 12.118779993796801\n",
      "resetting env. episode reward total was 13.0. running mean: 12.127592193858835\n",
      "resetting env. episode reward total was 8.0. running mean: 12.086316271920246\n",
      "resetting env. episode reward total was 12.0. running mean: 12.085453109201042\n",
      "resetting env. episode reward total was 14.0. running mean: 12.104598578109032\n",
      "resetting env. episode reward total was 9.0. running mean: 12.07355259232794\n",
      "resetting env. episode reward total was 11.0. running mean: 12.06281706640466\n",
      "resetting env. episode reward total was 15.0. running mean: 12.092188895740614\n",
      "resetting env. episode reward total was 12.0. running mean: 12.091267006783207\n",
      "resetting env. episode reward total was 16.0. running mean: 12.130354336715374\n",
      "resetting env. episode reward total was 13.0. running mean: 12.139050793348222\n",
      "resetting env. episode reward total was 16.0. running mean: 12.17766028541474\n",
      "resetting env. episode reward total was 13.0. running mean: 12.185883682560593\n",
      "resetting env. episode reward total was 19.0. running mean: 12.254024845734987\n",
      "resetting env. episode reward total was 14.0. running mean: 12.271484597277638\n",
      "resetting env. episode reward total was -4.0. running mean: 12.108769751304862\n",
      "resetting env. episode reward total was 13.0. running mean: 12.117682053791814\n",
      "resetting env. episode reward total was 12.0. running mean: 12.116505233253895\n",
      "resetting env. episode reward total was 9.0. running mean: 12.085340180921355\n",
      "resetting env. episode reward total was 14.0. running mean: 12.104486779112142\n",
      "resetting env. episode reward total was 12.0. running mean: 12.103441911321019\n",
      "resetting env. episode reward total was 13.0. running mean: 12.11240749220781\n",
      "resetting env. episode reward total was 9.0. running mean: 12.081283417285732\n",
      "resetting env. episode reward total was 16.0. running mean: 12.120470583112875\n",
      "resetting env. episode reward total was 12.0. running mean: 12.119265877281745\n",
      "resetting env. episode reward total was 9.0. running mean: 12.088073218508926\n",
      "resetting env. episode reward total was 17.0. running mean: 12.137192486323837\n",
      "resetting env. episode reward total was 17.0. running mean: 12.185820561460599\n",
      "resetting env. episode reward total was 9.0. running mean: 12.153962355845993\n",
      "resetting env. episode reward total was 17.0. running mean: 12.202422732287532\n",
      "resetting env. episode reward total was 11.0. running mean: 12.190398504964657\n",
      "resetting env. episode reward total was 16.0. running mean: 12.22849451991501\n",
      "resetting env. episode reward total was 13.0. running mean: 12.236209574715861\n",
      "resetting env. episode reward total was 9.0. running mean: 12.203847478968703\n",
      "resetting env. episode reward total was 16.0. running mean: 12.241809004179016\n",
      "resetting env. episode reward total was 9.0. running mean: 12.209390914137225\n",
      "resetting env. episode reward total was 15.0. running mean: 12.237297004995854\n",
      "resetting env. episode reward total was 15.0. running mean: 12.264924034945896\n",
      "resetting env. episode reward total was 13.0. running mean: 12.272274794596438\n",
      "resetting env. episode reward total was 14.0. running mean: 12.289552046650474\n",
      "resetting env. episode reward total was 16.0. running mean: 12.32665652618397\n",
      "resetting env. episode reward total was 15.0. running mean: 12.35338996092213\n",
      "resetting env. episode reward total was 12.0. running mean: 12.349856061312908\n",
      "resetting env. episode reward total was 12.0. running mean: 12.346357500699778\n",
      "resetting env. episode reward total was 16.0. running mean: 12.38289392569278\n",
      "resetting env. episode reward total was 14.0. running mean: 12.399064986435853\n",
      "resetting env. episode reward total was 14.0. running mean: 12.415074336571495\n",
      "resetting env. episode reward total was 11.0. running mean: 12.400923593205778\n",
      "resetting env. episode reward total was 19.0. running mean: 12.46691435727372\n",
      "resetting env. episode reward total was 15.0. running mean: 12.492245213700985\n",
      "resetting env. episode reward total was 14.0. running mean: 12.507322761563975\n",
      "resetting env. episode reward total was 10.0. running mean: 12.482249533948334\n",
      "resetting env. episode reward total was 14.0. running mean: 12.497427038608851\n",
      "resetting env. episode reward total was 14.0. running mean: 12.512452768222763\n",
      "resetting env. episode reward total was 19.0. running mean: 12.577328240540535\n",
      "resetting env. episode reward total was 11.0. running mean: 12.561554958135128\n",
      "resetting env. episode reward total was 15.0. running mean: 12.585939408553777\n",
      "resetting env. episode reward total was 10.0. running mean: 12.56008001446824\n",
      "resetting env. episode reward total was 13.0. running mean: 12.564479214323557\n",
      "resetting env. episode reward total was 12.0. running mean: 12.55883442218032\n",
      "resetting env. episode reward total was 12.0. running mean: 12.553246077958516\n",
      "resetting env. episode reward total was 13.0. running mean: 12.557713617178932\n",
      "resetting env. episode reward total was 13.0. running mean: 12.562136481007142\n",
      "resetting env. episode reward total was 12.0. running mean: 12.55651511619707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 19.0. running mean: 12.6209499650351\n",
      "resetting env. episode reward total was 16.0. running mean: 12.65474046538475\n",
      "resetting env. episode reward total was 7.0. running mean: 12.598193060730903\n",
      "resetting env. episode reward total was 12.0. running mean: 12.592211130123593\n",
      "resetting env. episode reward total was 7.0. running mean: 12.536289018822357\n",
      "resetting env. episode reward total was 14.0. running mean: 12.550926128634133\n",
      "resetting env. episode reward total was 16.0. running mean: 12.585416867347792\n",
      "resetting env. episode reward total was 14.0. running mean: 12.599562698674315\n",
      "resetting env. episode reward total was 13.0. running mean: 12.603567071687573\n",
      "resetting env. episode reward total was 13.0. running mean: 12.607531400970698\n",
      "resetting env. episode reward total was 12.0. running mean: 12.60145608696099\n",
      "resetting env. episode reward total was 15.0. running mean: 12.62544152609138\n",
      "resetting env. episode reward total was 12.0. running mean: 12.619187110830467\n",
      "resetting env. episode reward total was 6.0. running mean: 12.552995239722163\n",
      "resetting env. episode reward total was 12.0. running mean: 12.547465287324941\n",
      "resetting env. episode reward total was 13.0. running mean: 12.551990634451693\n",
      "resetting env. episode reward total was 12.0. running mean: 12.546470728107176\n",
      "resetting env. episode reward total was 14.0. running mean: 12.561006020826104\n",
      "resetting env. episode reward total was 12.0. running mean: 12.555395960617842\n",
      "resetting env. episode reward total was 14.0. running mean: 12.569842001011665\n",
      "resetting env. episode reward total was 19.0. running mean: 12.634143581001547\n",
      "resetting env. episode reward total was 13.0. running mean: 12.637802145191532\n",
      "resetting env. episode reward total was 13.0. running mean: 12.641424123739618\n",
      "resetting env. episode reward total was 11.0. running mean: 12.625009882502221\n",
      "resetting env. episode reward total was 14.0. running mean: 12.6387597836772\n",
      "resetting env. episode reward total was 12.0. running mean: 12.632372185840428\n",
      "resetting env. episode reward total was 16.0. running mean: 12.666048463982023\n",
      "resetting env. episode reward total was 19.0. running mean: 12.729387979342201\n",
      "resetting env. episode reward total was 14.0. running mean: 12.74209409954878\n",
      "resetting env. episode reward total was 11.0. running mean: 12.72467315855329\n",
      "resetting env. episode reward total was 17.0. running mean: 12.767426426967758\n",
      "resetting env. episode reward total was 9.0. running mean: 12.72975216269808\n",
      "resetting env. episode reward total was 16.0. running mean: 12.7624546410711\n",
      "resetting env. episode reward total was 15.0. running mean: 12.78483009466039\n",
      "resetting env. episode reward total was 10.0. running mean: 12.756981793713784\n",
      "resetting env. episode reward total was 2.0. running mean: 12.649411975776646\n",
      "resetting env. episode reward total was 14.0. running mean: 12.662917856018879\n",
      "resetting env. episode reward total was 12.0. running mean: 12.65628867745869\n",
      "resetting env. episode reward total was 14.0. running mean: 12.669725790684103\n",
      "resetting env. episode reward total was 15.0. running mean: 12.693028532777262\n",
      "resetting env. episode reward total was 13.0. running mean: 12.69609824744949\n",
      "resetting env. episode reward total was 16.0. running mean: 12.729137264974995\n",
      "resetting env. episode reward total was 15.0. running mean: 12.751845892325244\n",
      "resetting env. episode reward total was 13.0. running mean: 12.754327433401992\n",
      "resetting env. episode reward total was 14.0. running mean: 12.766784159067972\n",
      "resetting env. episode reward total was 14.0. running mean: 12.779116317477293\n",
      "resetting env. episode reward total was 12.0. running mean: 12.771325154302518\n",
      "resetting env. episode reward total was 14.0. running mean: 12.783611902759494\n",
      "resetting env. episode reward total was 8.0. running mean: 12.7357757837319\n",
      "resetting env. episode reward total was 15.0. running mean: 12.75841802589458\n",
      "resetting env. episode reward total was 11.0. running mean: 12.740833845635633\n",
      "resetting env. episode reward total was 17.0. running mean: 12.783425507179276\n",
      "resetting env. episode reward total was 12.0. running mean: 12.775591252107482\n",
      "resetting env. episode reward total was 16.0. running mean: 12.807835339586408\n",
      "resetting env. episode reward total was 14.0. running mean: 12.819756986190544\n",
      "resetting env. episode reward total was 14.0. running mean: 12.83155941632864\n",
      "resetting env. episode reward total was 10.0. running mean: 12.803243822165353\n",
      "resetting env. episode reward total was 7.0. running mean: 12.7452113839437\n",
      "resetting env. episode reward total was 17.0. running mean: 12.787759270104262\n",
      "resetting env. episode reward total was 12.0. running mean: 12.779881677403218\n",
      "resetting env. episode reward total was 10.0. running mean: 12.752082860629185\n",
      "resetting env. episode reward total was 17.0. running mean: 12.794562032022894\n",
      "resetting env. episode reward total was 17.0. running mean: 12.836616411702664\n",
      "resetting env. episode reward total was 16.0. running mean: 12.868250247585637\n",
      "resetting env. episode reward total was 8.0. running mean: 12.819567745109781\n",
      "resetting env. episode reward total was 7.0. running mean: 12.761372067658684\n",
      "resetting env. episode reward total was 9.0. running mean: 12.723758346982097\n",
      "resetting env. episode reward total was 10.0. running mean: 12.696520763512275\n",
      "resetting env. episode reward total was 19.0. running mean: 12.759555555877151\n",
      "resetting env. episode reward total was 13.0. running mean: 12.76196000031838\n",
      "resetting env. episode reward total was 12.0. running mean: 12.754340400315195\n",
      "resetting env. episode reward total was 17.0. running mean: 12.796796996312043\n",
      "resetting env. episode reward total was 16.0. running mean: 12.828829026348922\n",
      "resetting env. episode reward total was 13.0. running mean: 12.830540736085434\n",
      "resetting env. episode reward total was 11.0. running mean: 12.81223532872458\n",
      "resetting env. episode reward total was 16.0. running mean: 12.844112975437334\n",
      "resetting env. episode reward total was 11.0. running mean: 12.82567184568296\n",
      "resetting env. episode reward total was 9.0. running mean: 12.78741512722613\n",
      "resetting env. episode reward total was 13.0. running mean: 12.78954097595387\n",
      "resetting env. episode reward total was 17.0. running mean: 12.83164556619433\n",
      "resetting env. episode reward total was 10.0. running mean: 12.803329110532387\n",
      "resetting env. episode reward total was 12.0. running mean: 12.795295819427063\n",
      "resetting env. episode reward total was 14.0. running mean: 12.807342861232792\n",
      "resetting env. episode reward total was 17.0. running mean: 12.849269432620464\n",
      "resetting env. episode reward total was 14.0. running mean: 12.860776738294259\n",
      "resetting env. episode reward total was 15.0. running mean: 12.882168970911316\n",
      "resetting env. episode reward total was 5.0. running mean: 12.803347281202203\n",
      "resetting env. episode reward total was 14.0. running mean: 12.815313808390181\n",
      "resetting env. episode reward total was 19.0. running mean: 12.877160670306278\n",
      "resetting env. episode reward total was 14.0. running mean: 12.888389063603215\n",
      "resetting env. episode reward total was 11.0. running mean: 12.869505172967182\n",
      "resetting env. episode reward total was 12.0. running mean: 12.86081012123751\n",
      "resetting env. episode reward total was 9.0. running mean: 12.822202020025134\n",
      "resetting env. episode reward total was 11.0. running mean: 12.803979999824882\n",
      "resetting env. episode reward total was 11.0. running mean: 12.785940199826634\n",
      "resetting env. episode reward total was 17.0. running mean: 12.828080797828367\n",
      "resetting env. episode reward total was 15.0. running mean: 12.849799989850084\n",
      "resetting env. episode reward total was 18.0. running mean: 12.901301989951582\n",
      "resetting env. episode reward total was 14.0. running mean: 12.912288970052067\n",
      "resetting env. episode reward total was 9.0. running mean: 12.873166080351547\n",
      "resetting env. episode reward total was 14.0. running mean: 12.884434419548032\n",
      "resetting env. episode reward total was 10.0. running mean: 12.855590075352552\n",
      "resetting env. episode reward total was 12.0. running mean: 12.847034174599026\n",
      "resetting env. episode reward total was 15.0. running mean: 12.868563832853036\n",
      "resetting env. episode reward total was 17.0. running mean: 12.909878194524506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 12.82077941257926\n",
      "resetting env. episode reward total was 14.0. running mean: 12.832571618453468\n",
      "resetting env. episode reward total was 12.0. running mean: 12.824245902268933\n",
      "resetting env. episode reward total was 14.0. running mean: 12.836003443246243\n",
      "resetting env. episode reward total was 16.0. running mean: 12.86764340881378\n",
      "resetting env. episode reward total was 13.0. running mean: 12.868966974725643\n",
      "resetting env. episode reward total was 12.0. running mean: 12.860277304978386\n",
      "resetting env. episode reward total was 12.0. running mean: 12.851674531928602\n",
      "resetting env. episode reward total was 17.0. running mean: 12.893157786609315\n",
      "resetting env. episode reward total was 12.0. running mean: 12.884226208743222\n",
      "resetting env. episode reward total was 13.0. running mean: 12.88538394665579\n",
      "resetting env. episode reward total was 9.0. running mean: 12.846530107189231\n",
      "resetting env. episode reward total was 16.0. running mean: 12.878064806117338\n",
      "resetting env. episode reward total was 14.0. running mean: 12.889284158056165\n",
      "resetting env. episode reward total was 14.0. running mean: 12.900391316475604\n",
      "resetting env. episode reward total was 13.0. running mean: 12.90138740331085\n",
      "resetting env. episode reward total was 2.0. running mean: 12.79237352927774\n",
      "resetting env. episode reward total was 17.0. running mean: 12.834449793984962\n",
      "resetting env. episode reward total was 8.0. running mean: 12.786105296045113\n",
      "resetting env. episode reward total was 14.0. running mean: 12.798244243084662\n",
      "resetting env. episode reward total was 8.0. running mean: 12.750261800653815\n",
      "resetting env. episode reward total was 13.0. running mean: 12.752759182647278\n",
      "resetting env. episode reward total was 16.0. running mean: 12.785231590820805\n",
      "resetting env. episode reward total was 13.0. running mean: 12.787379274912597\n",
      "resetting env. episode reward total was 12.0. running mean: 12.77950548216347\n",
      "resetting env. episode reward total was 13.0. running mean: 12.781710427341837\n",
      "resetting env. episode reward total was 10.0. running mean: 12.753893323068418\n",
      "resetting env. episode reward total was 17.0. running mean: 12.796354389837733\n",
      "resetting env. episode reward total was 18.0. running mean: 12.848390845939354\n",
      "resetting env. episode reward total was 4.0. running mean: 12.75990693747996\n",
      "resetting env. episode reward total was 12.0. running mean: 12.75230786810516\n",
      "resetting env. episode reward total was 13.0. running mean: 12.754784789424109\n",
      "resetting env. episode reward total was 13.0. running mean: 12.757236941529868\n",
      "resetting env. episode reward total was 8.0. running mean: 12.70966457211457\n",
      "resetting env. episode reward total was 13.0. running mean: 12.712567926393424\n",
      "resetting env. episode reward total was 13.0. running mean: 12.715442247129491\n",
      "resetting env. episode reward total was 20.0. running mean: 12.788287824658196\n",
      "resetting env. episode reward total was 17.0. running mean: 12.830404946411614\n",
      "resetting env. episode reward total was 13.0. running mean: 12.832100896947498\n",
      "resetting env. episode reward total was 14.0. running mean: 12.843779887978023\n",
      "resetting env. episode reward total was 19.0. running mean: 12.905342089098243\n",
      "resetting env. episode reward total was 11.0. running mean: 12.886288668207259\n",
      "resetting env. episode reward total was 16.0. running mean: 12.917425781525186\n",
      "resetting env. episode reward total was 16.0. running mean: 12.948251523709933\n",
      "resetting env. episode reward total was 12.0. running mean: 12.938769008472834\n",
      "resetting env. episode reward total was 17.0. running mean: 12.979381318388105\n",
      "resetting env. episode reward total was 12.0. running mean: 12.969587505204224\n",
      "resetting env. episode reward total was 8.0. running mean: 12.919891630152181\n",
      "resetting env. episode reward total was 6.0. running mean: 12.850692713850659\n",
      "resetting env. episode reward total was 15.0. running mean: 12.872185786712153\n",
      "resetting env. episode reward total was 11.0. running mean: 12.85346392884503\n",
      "resetting env. episode reward total was 18.0. running mean: 12.90492928955658\n",
      "resetting env. episode reward total was 16.0. running mean: 12.935879996661015\n",
      "resetting env. episode reward total was 12.0. running mean: 12.926521196694404\n",
      "resetting env. episode reward total was 17.0. running mean: 12.96725598472746\n",
      "resetting env. episode reward total was 16.0. running mean: 12.997583424880185\n",
      "resetting env. episode reward total was 15.0. running mean: 13.017607590631384\n",
      "resetting env. episode reward total was 18.0. running mean: 13.067431514725069\n",
      "resetting env. episode reward total was 6.0. running mean: 12.996757199577818\n",
      "resetting env. episode reward total was 13.0. running mean: 12.996789627582041\n",
      "resetting env. episode reward total was 10.0. running mean: 12.96682173130622\n",
      "resetting env. episode reward total was 18.0. running mean: 13.017153513993158\n",
      "resetting env. episode reward total was 10.0. running mean: 12.986981978853226\n",
      "resetting env. episode reward total was 12.0. running mean: 12.977112159064694\n",
      "resetting env. episode reward total was 15.0. running mean: 12.997341037474047\n",
      "resetting env. episode reward total was 8.0. running mean: 12.947367627099307\n",
      "resetting env. episode reward total was 11.0. running mean: 12.927893950828313\n",
      "resetting env. episode reward total was 17.0. running mean: 12.96861501132003\n",
      "resetting env. episode reward total was 19.0. running mean: 13.028928861206829\n",
      "resetting env. episode reward total was 6.0. running mean: 12.95863957259476\n",
      "resetting env. episode reward total was 14.0. running mean: 12.969053176868814\n",
      "resetting env. episode reward total was 10.0. running mean: 12.939362645100125\n",
      "resetting env. episode reward total was 15.0. running mean: 12.959969018649124\n",
      "resetting env. episode reward total was 12.0. running mean: 12.950369328462632\n",
      "resetting env. episode reward total was 18.0. running mean: 13.000865635178005\n",
      "resetting env. episode reward total was 16.0. running mean: 13.030856978826225\n",
      "resetting env. episode reward total was 12.0. running mean: 13.020548409037962\n",
      "resetting env. episode reward total was 14.0. running mean: 13.030342924947583\n",
      "resetting env. episode reward total was 13.0. running mean: 13.030039495698107\n",
      "resetting env. episode reward total was 8.0. running mean: 12.979739100741126\n",
      "resetting env. episode reward total was 15.0. running mean: 12.999941709733715\n",
      "resetting env. episode reward total was 14.0. running mean: 13.009942292636378\n",
      "resetting env. episode reward total was 17.0. running mean: 13.049842869710014\n",
      "resetting env. episode reward total was 5.0. running mean: 12.969344441012915\n",
      "resetting env. episode reward total was 14.0. running mean: 12.979650996602786\n",
      "resetting env. episode reward total was 13.0. running mean: 12.979854486636759\n",
      "resetting env. episode reward total was 6.0. running mean: 12.910055941770391\n",
      "resetting env. episode reward total was 8.0. running mean: 12.860955382352687\n",
      "resetting env. episode reward total was 16.0. running mean: 12.89234582852916\n",
      "resetting env. episode reward total was 13.0. running mean: 12.89342237024387\n",
      "resetting env. episode reward total was 12.0. running mean: 12.88448814654143\n",
      "resetting env. episode reward total was 13.0. running mean: 12.885643265076016\n",
      "resetting env. episode reward total was 13.0. running mean: 12.886786832425257\n",
      "resetting env. episode reward total was 6.0. running mean: 12.817918964101004\n",
      "resetting env. episode reward total was 14.0. running mean: 12.829739774459995\n",
      "resetting env. episode reward total was 12.0. running mean: 12.821442376715394\n",
      "resetting env. episode reward total was 13.0. running mean: 12.82322795294824\n",
      "resetting env. episode reward total was 16.0. running mean: 12.854995673418758\n",
      "resetting env. episode reward total was 11.0. running mean: 12.836445716684569\n",
      "resetting env. episode reward total was 12.0. running mean: 12.828081259517722\n",
      "resetting env. episode reward total was 9.0. running mean: 12.789800446922545\n",
      "resetting env. episode reward total was 8.0. running mean: 12.74190244245332\n",
      "resetting env. episode reward total was 17.0. running mean: 12.784483418028787\n",
      "resetting env. episode reward total was 12.0. running mean: 12.776638583848499\n",
      "resetting env. episode reward total was 11.0. running mean: 12.758872198010012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 12.781283476029913\n",
      "resetting env. episode reward total was 15.0. running mean: 12.803470641269614\n",
      "resetting env. episode reward total was 17.0. running mean: 12.845435934856917\n",
      "resetting env. episode reward total was 9.0. running mean: 12.806981575508347\n",
      "resetting env. episode reward total was 15.0. running mean: 12.828911759753264\n",
      "resetting env. episode reward total was 20.0. running mean: 12.900622642155732\n",
      "resetting env. episode reward total was 14.0. running mean: 12.911616415734175\n",
      "resetting env. episode reward total was 18.0. running mean: 12.962500251576833\n",
      "resetting env. episode reward total was 16.0. running mean: 12.992875249061065\n",
      "resetting env. episode reward total was 16.0. running mean: 13.022946496570453\n",
      "resetting env. episode reward total was 10.0. running mean: 12.992717031604748\n",
      "resetting env. episode reward total was 13.0. running mean: 12.992789861288701\n",
      "resetting env. episode reward total was 5.0. running mean: 12.912861962675814\n",
      "resetting env. episode reward total was 9.0. running mean: 12.873733343049055\n",
      "resetting env. episode reward total was 11.0. running mean: 12.854996009618564\n",
      "resetting env. episode reward total was 11.0. running mean: 12.836446049522378\n",
      "resetting env. episode reward total was 9.0. running mean: 12.798081589027154\n",
      "resetting env. episode reward total was 4.0. running mean: 12.710100773136881\n",
      "resetting env. episode reward total was 15.0. running mean: 12.732999765405513\n",
      "resetting env. episode reward total was 8.0. running mean: 12.685669767751458\n",
      "resetting env. episode reward total was 17.0. running mean: 12.728813070073944\n",
      "resetting env. episode reward total was 14.0. running mean: 12.741524939373205\n",
      "resetting env. episode reward total was 15.0. running mean: 12.764109689979474\n",
      "resetting env. episode reward total was 17.0. running mean: 12.806468593079678\n",
      "resetting env. episode reward total was 16.0. running mean: 12.838403907148882\n",
      "resetting env. episode reward total was 13.0. running mean: 12.840019868077393\n",
      "resetting env. episode reward total was 13.0. running mean: 12.84161966939662\n",
      "resetting env. episode reward total was 18.0. running mean: 12.893203472702654\n",
      "resetting env. episode reward total was 18.0. running mean: 12.944271437975626\n",
      "resetting env. episode reward total was 6.0. running mean: 12.87482872359587\n",
      "resetting env. episode reward total was 14.0. running mean: 12.886080436359912\n",
      "resetting env. episode reward total was 16.0. running mean: 12.917219631996312\n",
      "resetting env. episode reward total was 11.0. running mean: 12.898047435676348\n",
      "resetting env. episode reward total was 8.0. running mean: 12.849066961319584\n",
      "resetting env. episode reward total was 19.0. running mean: 12.910576291706388\n",
      "resetting env. episode reward total was 8.0. running mean: 12.861470528789324\n",
      "resetting env. episode reward total was 10.0. running mean: 12.832855823501431\n",
      "resetting env. episode reward total was 13.0. running mean: 12.834527265266418\n",
      "resetting env. episode reward total was 14.0. running mean: 12.846181992613754\n",
      "resetting env. episode reward total was 16.0. running mean: 12.877720172687617\n",
      "resetting env. episode reward total was 14.0. running mean: 12.888942970960741\n",
      "resetting env. episode reward total was 13.0. running mean: 12.890053541251135\n",
      "resetting env. episode reward total was 18.0. running mean: 12.941153005838622\n",
      "resetting env. episode reward total was 7.0. running mean: 12.881741475780236\n",
      "resetting env. episode reward total was 16.0. running mean: 12.912924061022434\n",
      "resetting env. episode reward total was 15.0. running mean: 12.93379482041221\n",
      "resetting env. episode reward total was 10.0. running mean: 12.904456872208087\n",
      "resetting env. episode reward total was 10.0. running mean: 12.875412303486005\n",
      "resetting env. episode reward total was 1.0. running mean: 12.756658180451145\n",
      "resetting env. episode reward total was 12.0. running mean: 12.749091598646633\n",
      "resetting env. episode reward total was 16.0. running mean: 12.781600682660166\n",
      "resetting env. episode reward total was 7.0. running mean: 12.723784675833564\n",
      "resetting env. episode reward total was 11.0. running mean: 12.706546829075227\n",
      "resetting env. episode reward total was 11.0. running mean: 12.689481360784475\n",
      "resetting env. episode reward total was 16.0. running mean: 12.72258654717663\n",
      "resetting env. episode reward total was 16.0. running mean: 12.755360681704865\n",
      "resetting env. episode reward total was 9.0. running mean: 12.717807074887816\n",
      "resetting env. episode reward total was 14.0. running mean: 12.730629004138938\n",
      "resetting env. episode reward total was 13.0. running mean: 12.73332271409755\n",
      "resetting env. episode reward total was 8.0. running mean: 12.685989486956574\n",
      "resetting env. episode reward total was 16.0. running mean: 12.719129592087008\n",
      "resetting env. episode reward total was 17.0. running mean: 12.761938296166138\n",
      "resetting env. episode reward total was 10.0. running mean: 12.734318913204476\n",
      "resetting env. episode reward total was 10.0. running mean: 12.70697572407243\n",
      "resetting env. episode reward total was 8.0. running mean: 12.659905966831706\n",
      "resetting env. episode reward total was 16.0. running mean: 12.69330690716339\n",
      "resetting env. episode reward total was 17.0. running mean: 12.736373838091755\n",
      "resetting env. episode reward total was 14.0. running mean: 12.749010099710837\n",
      "resetting env. episode reward total was 18.0. running mean: 12.801519998713728\n",
      "resetting env. episode reward total was 16.0. running mean: 12.83350479872659\n",
      "resetting env. episode reward total was 18.0. running mean: 12.885169750739324\n",
      "resetting env. episode reward total was 20.0. running mean: 12.95631805323193\n",
      "resetting env. episode reward total was 10.0. running mean: 12.926754872699611\n",
      "resetting env. episode reward total was 12.0. running mean: 12.917487323972614\n",
      "resetting env. episode reward total was 4.0. running mean: 12.828312450732886\n",
      "resetting env. episode reward total was 13.0. running mean: 12.830029326225558\n",
      "resetting env. episode reward total was 15.0. running mean: 12.851729032963302\n",
      "resetting env. episode reward total was 18.0. running mean: 12.903211742633669\n",
      "resetting env. episode reward total was 11.0. running mean: 12.88417962520733\n",
      "resetting env. episode reward total was 7.0. running mean: 12.825337828955258\n",
      "resetting env. episode reward total was 7.0. running mean: 12.767084450665704\n",
      "resetting env. episode reward total was 17.0. running mean: 12.809413606159048\n",
      "resetting env. episode reward total was 13.0. running mean: 12.811319470097457\n",
      "resetting env. episode reward total was 11.0. running mean: 12.793206275396482\n",
      "resetting env. episode reward total was 14.0. running mean: 12.805274212642518\n",
      "resetting env. episode reward total was 17.0. running mean: 12.847221470516093\n",
      "resetting env. episode reward total was 19.0. running mean: 12.908749255810932\n",
      "resetting env. episode reward total was 16.0. running mean: 12.939661763252822\n",
      "resetting env. episode reward total was 12.0. running mean: 12.930265145620293\n",
      "resetting env. episode reward total was 15.0. running mean: 12.95096249416409\n",
      "resetting env. episode reward total was 15.0. running mean: 12.97145286922245\n",
      "resetting env. episode reward total was 9.0. running mean: 12.931738340530226\n",
      "resetting env. episode reward total was 9.0. running mean: 12.892420957124923\n",
      "resetting env. episode reward total was 9.0. running mean: 12.853496747553674\n",
      "resetting env. episode reward total was 13.0. running mean: 12.854961780078138\n",
      "resetting env. episode reward total was 11.0. running mean: 12.836412162277357\n",
      "resetting env. episode reward total was 6.0. running mean: 12.768048040654584\n",
      "resetting env. episode reward total was 13.0. running mean: 12.770367560248038\n",
      "resetting env. episode reward total was 14.0. running mean: 12.782663884645558\n",
      "resetting env. episode reward total was 2.0. running mean: 12.674837245799102\n",
      "resetting env. episode reward total was 16.0. running mean: 12.708088873341111\n",
      "resetting env. episode reward total was 11.0. running mean: 12.6910079846077\n",
      "resetting env. episode reward total was 12.0. running mean: 12.684097904761622\n",
      "resetting env. episode reward total was 18.0. running mean: 12.737256925714005\n",
      "resetting env. episode reward total was 13.0. running mean: 12.739884356456866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 12.752485512892298\n",
      "resetting env. episode reward total was 12.0. running mean: 12.744960657763373\n",
      "resetting env. episode reward total was 14.0. running mean: 12.75751105118574\n",
      "resetting env. episode reward total was 8.0. running mean: 12.709935940673882\n",
      "resetting env. episode reward total was -3.0. running mean: 12.552836581267144\n",
      "resetting env. episode reward total was 15.0. running mean: 12.577308215454472\n",
      "resetting env. episode reward total was 15.0. running mean: 12.601535133299928\n",
      "resetting env. episode reward total was 5.0. running mean: 12.52551978196693\n",
      "resetting env. episode reward total was 14.0. running mean: 12.54026458414726\n",
      "resetting env. episode reward total was 10.0. running mean: 12.514861938305788\n",
      "resetting env. episode reward total was 16.0. running mean: 12.54971331892273\n",
      "resetting env. episode reward total was 11.0. running mean: 12.534216185733502\n",
      "resetting env. episode reward total was 16.0. running mean: 12.568874023876168\n",
      "resetting env. episode reward total was 16.0. running mean: 12.603185283637407\n",
      "resetting env. episode reward total was 7.0. running mean: 12.547153430801034\n",
      "resetting env. episode reward total was 13.0. running mean: 12.551681896493024\n",
      "resetting env. episode reward total was 12.0. running mean: 12.546165077528093\n",
      "resetting env. episode reward total was 8.0. running mean: 12.500703426752812\n",
      "resetting env. episode reward total was 18.0. running mean: 12.555696392485284\n",
      "resetting env. episode reward total was 15.0. running mean: 12.580139428560432\n",
      "resetting env. episode reward total was 17.0. running mean: 12.624338034274828\n",
      "resetting env. episode reward total was 13.0. running mean: 12.62809465393208\n",
      "resetting env. episode reward total was 16.0. running mean: 12.66181370739276\n",
      "resetting env. episode reward total was 12.0. running mean: 12.655195570318831\n",
      "resetting env. episode reward total was 16.0. running mean: 12.688643614615643\n",
      "resetting env. episode reward total was 15.0. running mean: 12.711757178469487\n",
      "resetting env. episode reward total was 6.0. running mean: 12.644639606684793\n",
      "resetting env. episode reward total was 19.0. running mean: 12.708193210617944\n",
      "resetting env. episode reward total was 10.0. running mean: 12.681111278511764\n",
      "resetting env. episode reward total was 9.0. running mean: 12.644300165726646\n",
      "resetting env. episode reward total was 10.0. running mean: 12.61785716406938\n",
      "resetting env. episode reward total was 12.0. running mean: 12.611678592428685\n",
      "resetting env. episode reward total was 11.0. running mean: 12.595561806504397\n",
      "resetting env. episode reward total was 7.0. running mean: 12.539606188439354\n",
      "resetting env. episode reward total was 14.0. running mean: 12.554210126554961\n",
      "resetting env. episode reward total was 16.0. running mean: 12.588668025289412\n",
      "resetting env. episode reward total was 10.0. running mean: 12.562781345036518\n",
      "resetting env. episode reward total was 14.0. running mean: 12.577153531586154\n",
      "resetting env. episode reward total was 17.0. running mean: 12.621381996270292\n",
      "resetting env. episode reward total was 12.0. running mean: 12.615168176307588\n",
      "resetting env. episode reward total was 11.0. running mean: 12.599016494544511\n",
      "resetting env. episode reward total was 11.0. running mean: 12.583026329599065\n",
      "resetting env. episode reward total was 7.0. running mean: 12.527196066303075\n",
      "resetting env. episode reward total was 17.0. running mean: 12.571924105640043\n",
      "resetting env. episode reward total was 18.0. running mean: 12.626204864583643\n",
      "resetting env. episode reward total was 13.0. running mean: 12.629942815937808\n",
      "resetting env. episode reward total was 12.0. running mean: 12.62364338777843\n",
      "resetting env. episode reward total was 12.0. running mean: 12.617406953900645\n",
      "resetting env. episode reward total was 16.0. running mean: 12.651232884361638\n",
      "resetting env. episode reward total was 13.0. running mean: 12.654720555518022\n",
      "resetting env. episode reward total was 2.0. running mean: 12.548173349962841\n",
      "resetting env. episode reward total was 18.0. running mean: 12.602691616463213\n",
      "resetting env. episode reward total was 15.0. running mean: 12.626664700298582\n",
      "resetting env. episode reward total was 15.0. running mean: 12.650398053295596\n",
      "resetting env. episode reward total was 8.0. running mean: 12.60389407276264\n",
      "resetting env. episode reward total was 10.0. running mean: 12.577855132035014\n",
      "resetting env. episode reward total was 10.0. running mean: 12.552076580714663\n",
      "resetting env. episode reward total was 10.0. running mean: 12.526555814907516\n",
      "resetting env. episode reward total was 11.0. running mean: 12.51129025675844\n",
      "resetting env. episode reward total was 11.0. running mean: 12.496177354190854\n",
      "resetting env. episode reward total was 14.0. running mean: 12.511215580648946\n",
      "resetting env. episode reward total was 15.0. running mean: 12.536103424842457\n",
      "resetting env. episode reward total was 11.0. running mean: 12.520742390594032\n",
      "resetting env. episode reward total was 14.0. running mean: 12.535534966688092\n",
      "resetting env. episode reward total was 9.0. running mean: 12.50017961702121\n",
      "resetting env. episode reward total was 13.0. running mean: 12.505177820851\n",
      "resetting env. episode reward total was 12.0. running mean: 12.500126042642488\n",
      "resetting env. episode reward total was 7.0. running mean: 12.445124782216064\n",
      "resetting env. episode reward total was 14.0. running mean: 12.460673534393903\n",
      "resetting env. episode reward total was 14.0. running mean: 12.476066799049965\n",
      "resetting env. episode reward total was 13.0. running mean: 12.481306131059466\n",
      "resetting env. episode reward total was 17.0. running mean: 12.52649306974887\n",
      "resetting env. episode reward total was 17.0. running mean: 12.571228139051382\n",
      "resetting env. episode reward total was 14.0. running mean: 12.585515857660868\n",
      "resetting env. episode reward total was 19.0. running mean: 12.649660699084258\n",
      "resetting env. episode reward total was 15.0. running mean: 12.673164092093415\n",
      "resetting env. episode reward total was 9.0. running mean: 12.636432451172482\n",
      "resetting env. episode reward total was 4.0. running mean: 12.550068126660756\n",
      "resetting env. episode reward total was 4.0. running mean: 12.464567445394147\n",
      "resetting env. episode reward total was 15.0. running mean: 12.489921770940207\n",
      "resetting env. episode reward total was 14.0. running mean: 12.505022553230805\n",
      "resetting env. episode reward total was 10.0. running mean: 12.479972327698498\n",
      "resetting env. episode reward total was 17.0. running mean: 12.525172604421513\n",
      "resetting env. episode reward total was 11.0. running mean: 12.509920878377297\n",
      "resetting env. episode reward total was 12.0. running mean: 12.504821669593523\n",
      "resetting env. episode reward total was 16.0. running mean: 12.539773452897588\n",
      "resetting env. episode reward total was 16.0. running mean: 12.574375718368612\n",
      "resetting env. episode reward total was 18.0. running mean: 12.628631961184926\n",
      "resetting env. episode reward total was 18.0. running mean: 12.682345641573075\n",
      "resetting env. episode reward total was 8.0. running mean: 12.635522185157345\n",
      "resetting env. episode reward total was 11.0. running mean: 12.619166963305771\n",
      "resetting env. episode reward total was 8.0. running mean: 12.572975293672714\n",
      "resetting env. episode reward total was 15.0. running mean: 12.597245540735987\n",
      "resetting env. episode reward total was 17.0. running mean: 12.641273085328626\n",
      "resetting env. episode reward total was 16.0. running mean: 12.67486035447534\n",
      "resetting env. episode reward total was 14.0. running mean: 12.688111750930588\n",
      "resetting env. episode reward total was 8.0. running mean: 12.641230633421282\n",
      "resetting env. episode reward total was 12.0. running mean: 12.634818327087068\n",
      "resetting env. episode reward total was 11.0. running mean: 12.618470143816197\n",
      "resetting env. episode reward total was 10.0. running mean: 12.592285442378033\n",
      "resetting env. episode reward total was 13.0. running mean: 12.596362587954253\n",
      "resetting env. episode reward total was 12.0. running mean: 12.59039896207471\n",
      "resetting env. episode reward total was 10.0. running mean: 12.564494972453963\n",
      "resetting env. episode reward total was 13.0. running mean: 12.568850022729423\n",
      "resetting env. episode reward total was 16.0. running mean: 12.603161522502129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 12.527129907277107\n",
      "resetting env. episode reward total was 12.0. running mean: 12.521858608204335\n",
      "resetting env. episode reward total was 15.0. running mean: 12.546640022122292\n",
      "resetting env. episode reward total was 13.0. running mean: 12.55117362190107\n",
      "resetting env. episode reward total was 6.0. running mean: 12.48566188568206\n",
      "resetting env. episode reward total was 13.0. running mean: 12.49080526682524\n",
      "resetting env. episode reward total was 6.0. running mean: 12.425897214156986\n",
      "resetting env. episode reward total was 14.0. running mean: 12.441638242015417\n",
      "resetting env. episode reward total was 10.0. running mean: 12.417221859595262\n",
      "resetting env. episode reward total was 17.0. running mean: 12.463049640999309\n",
      "resetting env. episode reward total was 18.0. running mean: 12.518419144589314\n",
      "resetting env. episode reward total was 14.0. running mean: 12.533234953143422\n",
      "resetting env. episode reward total was 15.0. running mean: 12.557902603611987\n",
      "resetting env. episode reward total was 14.0. running mean: 12.572323577575869\n",
      "resetting env. episode reward total was 10.0. running mean: 12.54660034180011\n",
      "resetting env. episode reward total was 13.0. running mean: 12.55113433838211\n",
      "resetting env. episode reward total was 3.0. running mean: 12.455622994998288\n",
      "resetting env. episode reward total was 16.0. running mean: 12.491066765048306\n",
      "resetting env. episode reward total was 14.0. running mean: 12.506156097397824\n",
      "resetting env. episode reward total was 9.0. running mean: 12.471094536423845\n",
      "resetting env. episode reward total was 13.0. running mean: 12.476383591059607\n",
      "resetting env. episode reward total was 11.0. running mean: 12.46161975514901\n",
      "resetting env. episode reward total was 13.0. running mean: 12.467003557597522\n",
      "resetting env. episode reward total was 16.0. running mean: 12.502333522021546\n",
      "resetting env. episode reward total was 6.0. running mean: 12.437310186801332\n",
      "resetting env. episode reward total was 10.0. running mean: 12.412937084933318\n",
      "resetting env. episode reward total was 15.0. running mean: 12.438807714083985\n",
      "resetting env. episode reward total was 3.0. running mean: 12.344419636943146\n",
      "resetting env. episode reward total was 14.0. running mean: 12.360975440573714\n",
      "resetting env. episode reward total was 13.0. running mean: 12.367365686167977\n",
      "resetting env. episode reward total was 5.0. running mean: 12.293692029306298\n",
      "resetting env. episode reward total was 14.0. running mean: 12.310755109013236\n",
      "resetting env. episode reward total was 14.0. running mean: 12.327647557923104\n",
      "resetting env. episode reward total was 14.0. running mean: 12.344371082343873\n",
      "resetting env. episode reward total was 8.0. running mean: 12.300927371520434\n",
      "resetting env. episode reward total was 14.0. running mean: 12.31791809780523\n",
      "resetting env. episode reward total was 12.0. running mean: 12.314738916827176\n",
      "resetting env. episode reward total was 12.0. running mean: 12.311591527658903\n",
      "resetting env. episode reward total was 10.0. running mean: 12.288475612382314\n",
      "resetting env. episode reward total was 12.0. running mean: 12.285590856258489\n",
      "resetting env. episode reward total was 14.0. running mean: 12.302734947695905\n",
      "resetting env. episode reward total was 12.0. running mean: 12.299707598218944\n",
      "resetting env. episode reward total was 15.0. running mean: 12.326710522236755\n",
      "resetting env. episode reward total was 18.0. running mean: 12.383443417014387\n",
      "resetting env. episode reward total was 12.0. running mean: 12.379608982844243\n",
      "resetting env. episode reward total was 9.0. running mean: 12.3458128930158\n",
      "resetting env. episode reward total was 15.0. running mean: 12.372354764085642\n",
      "resetting env. episode reward total was 6.0. running mean: 12.308631216444786\n",
      "resetting env. episode reward total was 12.0. running mean: 12.305544904280337\n",
      "resetting env. episode reward total was 15.0. running mean: 12.332489455237534\n",
      "resetting env. episode reward total was 12.0. running mean: 12.329164560685157\n",
      "resetting env. episode reward total was 15.0. running mean: 12.355872915078306\n",
      "resetting env. episode reward total was 13.0. running mean: 12.362314185927524\n",
      "resetting env. episode reward total was 12.0. running mean: 12.358691044068248\n",
      "resetting env. episode reward total was 17.0. running mean: 12.405104133627566\n",
      "resetting env. episode reward total was 16.0. running mean: 12.44105309229129\n",
      "resetting env. episode reward total was 11.0. running mean: 12.426642561368375\n",
      "resetting env. episode reward total was 15.0. running mean: 12.452376135754692\n",
      "resetting env. episode reward total was 15.0. running mean: 12.477852374397145\n",
      "resetting env. episode reward total was 19.0. running mean: 12.543073850653172\n",
      "resetting env. episode reward total was 7.0. running mean: 12.48764311214664\n",
      "resetting env. episode reward total was 7.0. running mean: 12.432766681025175\n",
      "resetting env. episode reward total was 13.0. running mean: 12.438439014214923\n",
      "resetting env. episode reward total was 17.0. running mean: 12.484054624072774\n",
      "resetting env. episode reward total was 19.0. running mean: 12.549214077832046\n",
      "resetting env. episode reward total was 16.0. running mean: 12.583721937053726\n",
      "resetting env. episode reward total was 13.0. running mean: 12.58788471768319\n",
      "resetting env. episode reward total was 12.0. running mean: 12.582005870506357\n",
      "resetting env. episode reward total was 9.0. running mean: 12.546185811801294\n",
      "resetting env. episode reward total was 12.0. running mean: 12.54072395368328\n",
      "resetting env. episode reward total was 11.0. running mean: 12.525316714146447\n",
      "resetting env. episode reward total was 6.0. running mean: 12.460063547004983\n",
      "resetting env. episode reward total was 13.0. running mean: 12.465462911534935\n",
      "resetting env. episode reward total was 11.0. running mean: 12.450808282419585\n",
      "resetting env. episode reward total was 6.0. running mean: 12.38630019959539\n",
      "resetting env. episode reward total was 11.0. running mean: 12.372437197599435\n",
      "resetting env. episode reward total was 14.0. running mean: 12.388712825623442\n",
      "resetting env. episode reward total was 11.0. running mean: 12.374825697367207\n",
      "resetting env. episode reward total was 13.0. running mean: 12.381077440393536\n",
      "resetting env. episode reward total was 13.0. running mean: 12.387266665989602\n",
      "resetting env. episode reward total was 15.0. running mean: 12.413393999329706\n",
      "resetting env. episode reward total was 6.0. running mean: 12.349260059336409\n",
      "resetting env. episode reward total was 15.0. running mean: 12.375767458743045\n",
      "resetting env. episode reward total was 14.0. running mean: 12.392009784155615\n",
      "resetting env. episode reward total was 16.0. running mean: 12.428089686314058\n",
      "resetting env. episode reward total was 10.0. running mean: 12.403808789450917\n",
      "resetting env. episode reward total was 9.0. running mean: 12.369770701556407\n",
      "resetting env. episode reward total was 14.0. running mean: 12.386072994540843\n",
      "resetting env. episode reward total was 9.0. running mean: 12.352212264595435\n",
      "resetting env. episode reward total was 8.0. running mean: 12.30869014194948\n",
      "resetting env. episode reward total was 14.0. running mean: 12.325603240529986\n",
      "resetting env. episode reward total was 15.0. running mean: 12.352347208124687\n",
      "resetting env. episode reward total was 13.0. running mean: 12.35882373604344\n",
      "resetting env. episode reward total was 2.0. running mean: 12.255235498683005\n",
      "resetting env. episode reward total was 11.0. running mean: 12.242683143696174\n",
      "resetting env. episode reward total was 12.0. running mean: 12.240256312259213\n",
      "resetting env. episode reward total was 13.0. running mean: 12.24785374913662\n",
      "resetting env. episode reward total was 16.0. running mean: 12.285375211645254\n",
      "resetting env. episode reward total was 14.0. running mean: 12.302521459528803\n",
      "resetting env. episode reward total was 13.0. running mean: 12.309496244933516\n",
      "resetting env. episode reward total was 9.0. running mean: 12.276401282484182\n",
      "resetting env. episode reward total was 9.0. running mean: 12.24363726965934\n",
      "resetting env. episode reward total was 19.0. running mean: 12.311200896962745\n",
      "resetting env. episode reward total was 14.0. running mean: 12.328088887993118\n",
      "resetting env. episode reward total was 17.0. running mean: 12.374807999113187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 12.391059919122055\n",
      "resetting env. episode reward total was 13.0. running mean: 12.397149319930834\n",
      "resetting env. episode reward total was 14.0. running mean: 12.413177826731527\n",
      "resetting env. episode reward total was 10.0. running mean: 12.38904604846421\n",
      "resetting env. episode reward total was 16.0. running mean: 12.42515558797957\n",
      "resetting env. episode reward total was 12.0. running mean: 12.420904032099772\n",
      "resetting env. episode reward total was 8.0. running mean: 12.376694991778773\n",
      "resetting env. episode reward total was 13.0. running mean: 12.382928041860986\n",
      "resetting env. episode reward total was 15.0. running mean: 12.409098761442376\n",
      "resetting env. episode reward total was 9.0. running mean: 12.375007773827951\n",
      "resetting env. episode reward total was 16.0. running mean: 12.411257696089672\n",
      "resetting env. episode reward total was 13.0. running mean: 12.417145119128776\n",
      "resetting env. episode reward total was 13.0. running mean: 12.42297366793749\n",
      "resetting env. episode reward total was 8.0. running mean: 12.378743931258114\n",
      "resetting env. episode reward total was 16.0. running mean: 12.414956491945533\n",
      "resetting env. episode reward total was 13.0. running mean: 12.420806927026078\n",
      "resetting env. episode reward total was 9.0. running mean: 12.386598857755818\n",
      "resetting env. episode reward total was 12.0. running mean: 12.382732869178259\n",
      "resetting env. episode reward total was 13.0. running mean: 12.388905540486476\n",
      "resetting env. episode reward total was 14.0. running mean: 12.405016485081612\n",
      "resetting env. episode reward total was 11.0. running mean: 12.390966320230795\n",
      "resetting env. episode reward total was 15.0. running mean: 12.417056657028487\n",
      "resetting env. episode reward total was 10.0. running mean: 12.392886090458202\n",
      "resetting env. episode reward total was 7.0. running mean: 12.33895722955362\n",
      "resetting env. episode reward total was 17.0. running mean: 12.385567657258083\n",
      "resetting env. episode reward total was 7.0. running mean: 12.331711980685501\n",
      "resetting env. episode reward total was 11.0. running mean: 12.318394860878646\n",
      "resetting env. episode reward total was 10.0. running mean: 12.295210912269859\n",
      "resetting env. episode reward total was 14.0. running mean: 12.312258803147161\n",
      "resetting env. episode reward total was 17.0. running mean: 12.35913621511569\n",
      "resetting env. episode reward total was 3.0. running mean: 12.265544852964533\n",
      "resetting env. episode reward total was 8.0. running mean: 12.222889404434888\n",
      "resetting env. episode reward total was 11.0. running mean: 12.210660510390538\n",
      "resetting env. episode reward total was 13.0. running mean: 12.218553905286633\n",
      "resetting env. episode reward total was 7.0. running mean: 12.166368366233767\n",
      "resetting env. episode reward total was 15.0. running mean: 12.19470468257143\n",
      "resetting env. episode reward total was 14.0. running mean: 12.212757635745717\n",
      "resetting env. episode reward total was 18.0. running mean: 12.27063005938826\n",
      "resetting env. episode reward total was 11.0. running mean: 12.257923758794377\n",
      "resetting env. episode reward total was 15.0. running mean: 12.285344521206433\n",
      "resetting env. episode reward total was 9.0. running mean: 12.252491075994369\n",
      "resetting env. episode reward total was 16.0. running mean: 12.289966165234425\n",
      "resetting env. episode reward total was 12.0. running mean: 12.28706650358208\n",
      "resetting env. episode reward total was 12.0. running mean: 12.284195838546259\n",
      "resetting env. episode reward total was 10.0. running mean: 12.261353880160796\n",
      "resetting env. episode reward total was 17.0. running mean: 12.308740341359188\n",
      "resetting env. episode reward total was 15.0. running mean: 12.335652937945596\n",
      "resetting env. episode reward total was 10.0. running mean: 12.312296408566139\n",
      "resetting env. episode reward total was 11.0. running mean: 12.299173444480477\n",
      "resetting env. episode reward total was 11.0. running mean: 12.286181710035672\n",
      "resetting env. episode reward total was 9.0. running mean: 12.253319892935314\n",
      "resetting env. episode reward total was 11.0. running mean: 12.24078669400596\n",
      "resetting env. episode reward total was 10.0. running mean: 12.2183788270659\n",
      "resetting env. episode reward total was 12.0. running mean: 12.21619503879524\n",
      "resetting env. episode reward total was 15.0. running mean: 12.244033088407289\n",
      "resetting env. episode reward total was 17.0. running mean: 12.291592757523215\n",
      "resetting env. episode reward total was 16.0. running mean: 12.328676829947984\n",
      "resetting env. episode reward total was 12.0. running mean: 12.325390061648504\n",
      "resetting env. episode reward total was 12.0. running mean: 12.322136161032018\n",
      "resetting env. episode reward total was 14.0. running mean: 12.3389147994217\n",
      "resetting env. episode reward total was 8.0. running mean: 12.295525651427482\n",
      "resetting env. episode reward total was 7.0. running mean: 12.242570394913207\n",
      "resetting env. episode reward total was 11.0. running mean: 12.230144690964075\n",
      "resetting env. episode reward total was 8.0. running mean: 12.187843244054434\n",
      "resetting env. episode reward total was 10.0. running mean: 12.16596481161389\n",
      "resetting env. episode reward total was 18.0. running mean: 12.22430516349775\n",
      "resetting env. episode reward total was 9.0. running mean: 12.192062111862771\n",
      "resetting env. episode reward total was 13.0. running mean: 12.200141490744144\n",
      "resetting env. episode reward total was 12.0. running mean: 12.198140075836703\n",
      "resetting env. episode reward total was 15.0. running mean: 12.226158675078336\n",
      "resetting env. episode reward total was 15.0. running mean: 12.253897088327554\n",
      "resetting env. episode reward total was 17.0. running mean: 12.301358117444277\n",
      "resetting env. episode reward total was 2.0. running mean: 12.198344536269834\n",
      "resetting env. episode reward total was 11.0. running mean: 12.186361090907136\n",
      "resetting env. episode reward total was 17.0. running mean: 12.234497479998064\n",
      "resetting env. episode reward total was 11.0. running mean: 12.222152505198082\n",
      "resetting env. episode reward total was 6.0. running mean: 12.159930980146102\n",
      "resetting env. episode reward total was 14.0. running mean: 12.178331670344642\n",
      "resetting env. episode reward total was 12.0. running mean: 12.176548353641195\n",
      "resetting env. episode reward total was 14.0. running mean: 12.194782870104783\n",
      "resetting env. episode reward total was 16.0. running mean: 12.232835041403735\n",
      "resetting env. episode reward total was 7.0. running mean: 12.180506690989699\n",
      "resetting env. episode reward total was 11.0. running mean: 12.168701624079802\n",
      "resetting env. episode reward total was 14.0. running mean: 12.187014607839004\n",
      "resetting env. episode reward total was 11.0. running mean: 12.175144461760613\n",
      "resetting env. episode reward total was 7.0. running mean: 12.123393017143007\n",
      "resetting env. episode reward total was 15.0. running mean: 12.152159086971578\n",
      "resetting env. episode reward total was 12.0. running mean: 12.150637496101862\n",
      "resetting env. episode reward total was 13.0. running mean: 12.159131121140843\n",
      "resetting env. episode reward total was 16.0. running mean: 12.197539809929435\n",
      "resetting env. episode reward total was 16.0. running mean: 12.23556441183014\n",
      "resetting env. episode reward total was 9.0. running mean: 12.203208767711839\n",
      "resetting env. episode reward total was 11.0. running mean: 12.19117668003472\n",
      "resetting env. episode reward total was 5.0. running mean: 12.119264913234375\n",
      "resetting env. episode reward total was 6.0. running mean: 12.058072264102032\n",
      "resetting env. episode reward total was 13.0. running mean: 12.067491541461012\n",
      "resetting env. episode reward total was 9.0. running mean: 12.0368166260464\n",
      "resetting env. episode reward total was 12.0. running mean: 12.036448459785936\n",
      "resetting env. episode reward total was 8.0. running mean: 11.996083975188077\n",
      "resetting env. episode reward total was 11.0. running mean: 11.986123135436195\n",
      "resetting env. episode reward total was 11.0. running mean: 11.976261904081833\n",
      "resetting env. episode reward total was 15.0. running mean: 12.006499285041015\n",
      "resetting env. episode reward total was 12.0. running mean: 12.006434292190603\n",
      "resetting env. episode reward total was 14.0. running mean: 12.026369949268698\n",
      "resetting env. episode reward total was 14.0. running mean: 12.046106249776011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 12.04564518727825\n",
      "resetting env. episode reward total was 12.0. running mean: 12.045188735405468\n",
      "resetting env. episode reward total was 17.0. running mean: 12.094736848051413\n",
      "resetting env. episode reward total was 14.0. running mean: 12.1137894795709\n",
      "resetting env. episode reward total was 10.0. running mean: 12.09265158477519\n",
      "resetting env. episode reward total was 13.0. running mean: 12.101725068927438\n",
      "resetting env. episode reward total was 15.0. running mean: 12.130707818238164\n",
      "resetting env. episode reward total was 14.0. running mean: 12.149400740055784\n",
      "resetting env. episode reward total was 17.0. running mean: 12.197906732655225\n",
      "resetting env. episode reward total was 11.0. running mean: 12.185927665328672\n",
      "resetting env. episode reward total was 14.0. running mean: 12.204068388675385\n",
      "resetting env. episode reward total was 16.0. running mean: 12.242027704788631\n",
      "resetting env. episode reward total was 11.0. running mean: 12.229607427740744\n",
      "resetting env. episode reward total was 8.0. running mean: 12.187311353463336\n",
      "resetting env. episode reward total was 14.0. running mean: 12.205438239928704\n",
      "resetting env. episode reward total was 17.0. running mean: 12.253383857529416\n",
      "resetting env. episode reward total was 10.0. running mean: 12.230850018954122\n",
      "resetting env. episode reward total was 11.0. running mean: 12.21854151876458\n",
      "resetting env. episode reward total was 11.0. running mean: 12.206356103576933\n",
      "resetting env. episode reward total was 9.0. running mean: 12.174292542541163\n",
      "resetting env. episode reward total was 19.0. running mean: 12.24254961711575\n",
      "resetting env. episode reward total was 16.0. running mean: 12.280124120944594\n",
      "resetting env. episode reward total was 18.0. running mean: 12.337322879735147\n",
      "resetting env. episode reward total was 7.0. running mean: 12.283949650937796\n",
      "resetting env. episode reward total was 18.0. running mean: 12.341110154428417\n",
      "resetting env. episode reward total was 16.0. running mean: 12.377699052884132\n",
      "resetting env. episode reward total was 8.0. running mean: 12.333922062355292\n",
      "resetting env. episode reward total was 12.0. running mean: 12.330582841731738\n",
      "resetting env. episode reward total was 3.0. running mean: 12.23727701331442\n",
      "resetting env. episode reward total was 19.0. running mean: 12.304904243181275\n",
      "resetting env. episode reward total was 8.0. running mean: 12.261855200749462\n",
      "resetting env. episode reward total was 15.0. running mean: 12.289236648741968\n",
      "resetting env. episode reward total was 12.0. running mean: 12.286344282254547\n",
      "resetting env. episode reward total was 12.0. running mean: 12.283480839432\n",
      "resetting env. episode reward total was 12.0. running mean: 12.28064603103768\n",
      "resetting env. episode reward total was 13.0. running mean: 12.287839570727304\n",
      "resetting env. episode reward total was 11.0. running mean: 12.27496117502003\n",
      "resetting env. episode reward total was 17.0. running mean: 12.32221156326983\n",
      "resetting env. episode reward total was 15.0. running mean: 12.348989447637132\n",
      "resetting env. episode reward total was 10.0. running mean: 12.32549955316076\n",
      "resetting env. episode reward total was 15.0. running mean: 12.352244557629152\n",
      "resetting env. episode reward total was 19.0. running mean: 12.41872211205286\n",
      "resetting env. episode reward total was 16.0. running mean: 12.454534890932331\n",
      "resetting env. episode reward total was 15.0. running mean: 12.479989542023008\n",
      "resetting env. episode reward total was 18.0. running mean: 12.535189646602777\n",
      "resetting env. episode reward total was 10.0. running mean: 12.509837750136748\n",
      "resetting env. episode reward total was 2.0. running mean: 12.40473937263538\n",
      "resetting env. episode reward total was 14.0. running mean: 12.420691978909026\n",
      "resetting env. episode reward total was 12.0. running mean: 12.416485059119935\n",
      "resetting env. episode reward total was 10.0. running mean: 12.392320208528735\n",
      "resetting env. episode reward total was 4.0. running mean: 12.308397006443448\n",
      "resetting env. episode reward total was 13.0. running mean: 12.315313036379013\n",
      "resetting env. episode reward total was 16.0. running mean: 12.352159906015224\n",
      "resetting env. episode reward total was 5.0. running mean: 12.278638306955072\n",
      "resetting env. episode reward total was 11.0. running mean: 12.26585192388552\n",
      "resetting env. episode reward total was 15.0. running mean: 12.293193404646665\n",
      "resetting env. episode reward total was 7.0. running mean: 12.240261470600199\n",
      "resetting env. episode reward total was 15.0. running mean: 12.267858855894197\n",
      "resetting env. episode reward total was 15.0. running mean: 12.295180267335255\n",
      "resetting env. episode reward total was 8.0. running mean: 12.252228464661902\n",
      "resetting env. episode reward total was 13.0. running mean: 12.259706180015284\n",
      "resetting env. episode reward total was 15.0. running mean: 12.287109118215131\n",
      "resetting env. episode reward total was 12.0. running mean: 12.284238027032979\n",
      "resetting env. episode reward total was 10.0. running mean: 12.261395646762649\n",
      "resetting env. episode reward total was 10.0. running mean: 12.238781690295022\n",
      "resetting env. episode reward total was 16.0. running mean: 12.276393873392072\n",
      "resetting env. episode reward total was 9.0. running mean: 12.24362993465815\n",
      "resetting env. episode reward total was 8.0. running mean: 12.201193635311569\n",
      "resetting env. episode reward total was 12.0. running mean: 12.199181698958451\n",
      "resetting env. episode reward total was 14.0. running mean: 12.217189881968867\n",
      "resetting env. episode reward total was 12.0. running mean: 12.215017983149178\n",
      "resetting env. episode reward total was 18.0. running mean: 12.272867803317686\n",
      "resetting env. episode reward total was 8.0. running mean: 12.23013912528451\n",
      "resetting env. episode reward total was 9.0. running mean: 12.197837734031664\n",
      "resetting env. episode reward total was 12.0. running mean: 12.195859356691345\n",
      "resetting env. episode reward total was 14.0. running mean: 12.213900763124432\n",
      "resetting env. episode reward total was 10.0. running mean: 12.191761755493188\n",
      "resetting env. episode reward total was 17.0. running mean: 12.239844137938256\n",
      "resetting env. episode reward total was 4.0. running mean: 12.157445696558872\n",
      "resetting env. episode reward total was 11.0. running mean: 12.145871239593282\n",
      "resetting env. episode reward total was 13.0. running mean: 12.15441252719735\n",
      "resetting env. episode reward total was 12.0. running mean: 12.152868401925375\n",
      "resetting env. episode reward total was 15.0. running mean: 12.181339717906122\n",
      "resetting env. episode reward total was 11.0. running mean: 12.16952632072706\n",
      "resetting env. episode reward total was 15.0. running mean: 12.19783105751979\n",
      "resetting env. episode reward total was 8.0. running mean: 12.155852746944593\n",
      "resetting env. episode reward total was 11.0. running mean: 12.144294219475146\n",
      "resetting env. episode reward total was 13.0. running mean: 12.152851277280396\n",
      "resetting env. episode reward total was 17.0. running mean: 12.201322764507593\n",
      "resetting env. episode reward total was 11.0. running mean: 12.189309536862517\n",
      "resetting env. episode reward total was 13.0. running mean: 12.197416441493893\n",
      "resetting env. episode reward total was 9.0. running mean: 12.165442277078954\n",
      "resetting env. episode reward total was 8.0. running mean: 12.123787854308164\n",
      "resetting env. episode reward total was 9.0. running mean: 12.092549975765081\n",
      "resetting env. episode reward total was 6.0. running mean: 12.031624476007432\n",
      "resetting env. episode reward total was 16.0. running mean: 12.071308231247357\n",
      "resetting env. episode reward total was 14.0. running mean: 12.090595148934884\n",
      "resetting env. episode reward total was 13.0. running mean: 12.099689197445537\n",
      "resetting env. episode reward total was 17.0. running mean: 12.148692305471082\n",
      "resetting env. episode reward total was 14.0. running mean: 12.167205382416372\n",
      "resetting env. episode reward total was 16.0. running mean: 12.205533328592209\n",
      "resetting env. episode reward total was 11.0. running mean: 12.193477995306285\n",
      "resetting env. episode reward total was 15.0. running mean: 12.221543215353222\n",
      "resetting env. episode reward total was 9.0. running mean: 12.189327783199689\n",
      "resetting env. episode reward total was 15.0. running mean: 12.217434505367692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 12.205260160314014\n",
      "resetting env. episode reward total was 13.0. running mean: 12.213207558710874\n",
      "resetting env. episode reward total was 10.0. running mean: 12.191075483123765\n",
      "resetting env. episode reward total was 6.0. running mean: 12.129164728292528\n",
      "resetting env. episode reward total was 14.0. running mean: 12.147873081009603\n",
      "resetting env. episode reward total was 16.0. running mean: 12.186394350199507\n",
      "resetting env. episode reward total was 18.0. running mean: 12.24453040669751\n",
      "resetting env. episode reward total was 17.0. running mean: 12.292085102630535\n",
      "resetting env. episode reward total was 15.0. running mean: 12.31916425160423\n",
      "resetting env. episode reward total was 17.0. running mean: 12.365972609088187\n",
      "resetting env. episode reward total was 12.0. running mean: 12.362312882997305\n",
      "resetting env. episode reward total was 12.0. running mean: 12.358689754167331\n",
      "resetting env. episode reward total was 14.0. running mean: 12.375102856625658\n",
      "resetting env. episode reward total was 10.0. running mean: 12.3513518280594\n",
      "resetting env. episode reward total was 15.0. running mean: 12.377838309778806\n",
      "resetting env. episode reward total was 8.0. running mean: 12.334059926681018\n",
      "resetting env. episode reward total was 5.0. running mean: 12.260719327414208\n",
      "resetting env. episode reward total was 7.0. running mean: 12.208112134140066\n",
      "resetting env. episode reward total was 8.0. running mean: 12.166031012798666\n",
      "resetting env. episode reward total was 17.0. running mean: 12.214370702670678\n",
      "resetting env. episode reward total was 11.0. running mean: 12.20222699564397\n",
      "resetting env. episode reward total was 10.0. running mean: 12.18020472568753\n",
      "resetting env. episode reward total was 4.0. running mean: 12.098402678430654\n",
      "resetting env. episode reward total was 10.0. running mean: 12.077418651646347\n",
      "resetting env. episode reward total was 11.0. running mean: 12.066644465129883\n",
      "resetting env. episode reward total was 5.0. running mean: 11.995978020478585\n",
      "resetting env. episode reward total was 16.0. running mean: 12.0360182402738\n",
      "resetting env. episode reward total was 16.0. running mean: 12.075658057871062\n",
      "resetting env. episode reward total was 11.0. running mean: 12.06490147729235\n",
      "resetting env. episode reward total was 14.0. running mean: 12.084252462519427\n",
      "resetting env. episode reward total was 13.0. running mean: 12.093409937894233\n",
      "resetting env. episode reward total was 18.0. running mean: 12.15247583851529\n",
      "resetting env. episode reward total was 8.0. running mean: 12.110951080130137\n",
      "resetting env. episode reward total was 11.0. running mean: 12.099841569328834\n",
      "resetting env. episode reward total was 15.0. running mean: 12.128843153635547\n",
      "resetting env. episode reward total was 11.0. running mean: 12.117554722099191\n",
      "resetting env. episode reward total was 13.0. running mean: 12.1263791748782\n",
      "resetting env. episode reward total was 14.0. running mean: 12.145115383129419\n",
      "resetting env. episode reward total was 8.0. running mean: 12.103664229298124\n",
      "resetting env. episode reward total was 17.0. running mean: 12.152627587005142\n",
      "resetting env. episode reward total was 16.0. running mean: 12.19110131113509\n",
      "resetting env. episode reward total was 12.0. running mean: 12.189190298023739\n",
      "resetting env. episode reward total was 18.0. running mean: 12.2472983950435\n",
      "resetting env. episode reward total was 9.0. running mean: 12.214825411093065\n",
      "resetting env. episode reward total was 12.0. running mean: 12.212677156982133\n",
      "resetting env. episode reward total was 12.0. running mean: 12.210550385412311\n",
      "resetting env. episode reward total was 13.0. running mean: 12.218444881558188\n",
      "resetting env. episode reward total was 16.0. running mean: 12.256260432742605\n",
      "resetting env. episode reward total was 12.0. running mean: 12.253697828415179\n",
      "resetting env. episode reward total was 8.0. running mean: 12.211160850131026\n",
      "resetting env. episode reward total was 9.0. running mean: 12.179049241629716\n",
      "resetting env. episode reward total was 7.0. running mean: 12.12725874921342\n",
      "resetting env. episode reward total was 11.0. running mean: 12.115986161721285\n",
      "resetting env. episode reward total was 13.0. running mean: 12.124826300104072\n",
      "resetting env. episode reward total was 15.0. running mean: 12.153578037103031\n",
      "resetting env. episode reward total was 15.0. running mean: 12.182042256732002\n",
      "resetting env. episode reward total was 11.0. running mean: 12.170221834164682\n",
      "resetting env. episode reward total was 15.0. running mean: 12.198519615823036\n",
      "resetting env. episode reward total was 3.0. running mean: 12.106534419664806\n",
      "resetting env. episode reward total was 12.0. running mean: 12.105469075468157\n",
      "resetting env. episode reward total was 8.0. running mean: 12.064414384713476\n",
      "resetting env. episode reward total was 14.0. running mean: 12.083770240866341\n",
      "resetting env. episode reward total was 12.0. running mean: 12.082932538457678\n",
      "resetting env. episode reward total was 9.0. running mean: 12.052103213073101\n",
      "resetting env. episode reward total was 14.0. running mean: 12.07158218094237\n",
      "resetting env. episode reward total was 17.0. running mean: 12.120866359132945\n",
      "resetting env. episode reward total was 14.0. running mean: 12.139657695541617\n",
      "resetting env. episode reward total was 12.0. running mean: 12.1382611185862\n",
      "resetting env. episode reward total was 15.0. running mean: 12.16687850740034\n",
      "resetting env. episode reward total was 20.0. running mean: 12.245209722326335\n",
      "resetting env. episode reward total was 5.0. running mean: 12.172757625103072\n",
      "resetting env. episode reward total was 10.0. running mean: 12.151030048852041\n",
      "resetting env. episode reward total was 13.0. running mean: 12.159519748363522\n",
      "resetting env. episode reward total was 15.0. running mean: 12.187924550879886\n",
      "resetting env. episode reward total was 16.0. running mean: 12.226045305371088\n",
      "resetting env. episode reward total was 17.0. running mean: 12.273784852317377\n",
      "resetting env. episode reward total was 10.0. running mean: 12.251047003794202\n",
      "resetting env. episode reward total was 13.0. running mean: 12.25853653375626\n",
      "resetting env. episode reward total was 8.0. running mean: 12.215951168418698\n",
      "resetting env. episode reward total was 14.0. running mean: 12.233791656734512\n",
      "resetting env. episode reward total was 12.0. running mean: 12.231453740167167\n",
      "resetting env. episode reward total was 16.0. running mean: 12.269139202765496\n",
      "resetting env. episode reward total was 9.0. running mean: 12.236447810737841\n",
      "resetting env. episode reward total was 8.0. running mean: 12.194083332630463\n",
      "resetting env. episode reward total was 14.0. running mean: 12.212142499304159\n",
      "resetting env. episode reward total was 18.0. running mean: 12.270021074311117\n",
      "resetting env. episode reward total was 15.0. running mean: 12.297320863568006\n",
      "resetting env. episode reward total was 10.0. running mean: 12.274347654932326\n",
      "resetting env. episode reward total was 17.0. running mean: 12.321604178383003\n",
      "resetting env. episode reward total was 16.0. running mean: 12.358388136599173\n",
      "resetting env. episode reward total was 12.0. running mean: 12.35480425523318\n",
      "resetting env. episode reward total was 12.0. running mean: 12.351256212680847\n",
      "resetting env. episode reward total was 14.0. running mean: 12.367743650554038\n",
      "resetting env. episode reward total was 13.0. running mean: 12.374066214048499\n",
      "resetting env. episode reward total was 13.0. running mean: 12.380325551908015\n",
      "resetting env. episode reward total was 11.0. running mean: 12.366522296388935\n",
      "resetting env. episode reward total was 9.0. running mean: 12.332857073425044\n",
      "resetting env. episode reward total was 7.0. running mean: 12.279528502690795\n",
      "resetting env. episode reward total was 17.0. running mean: 12.326733217663886\n",
      "resetting env. episode reward total was 8.0. running mean: 12.283465885487248\n",
      "resetting env. episode reward total was 12.0. running mean: 12.280631226632375\n",
      "resetting env. episode reward total was 12.0. running mean: 12.27782491436605\n",
      "resetting env. episode reward total was 12.0. running mean: 12.275046665222389\n",
      "resetting env. episode reward total was 11.0. running mean: 12.262296198570164\n",
      "resetting env. episode reward total was 18.0. running mean: 12.319673236584462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 12.346476504218618\n",
      "resetting env. episode reward total was 12.0. running mean: 12.343011739176431\n",
      "resetting env. episode reward total was 7.0. running mean: 12.289581621784667\n",
      "resetting env. episode reward total was 15.0. running mean: 12.31668580556682\n",
      "resetting env. episode reward total was 13.0. running mean: 12.323518947511152\n",
      "resetting env. episode reward total was 10.0. running mean: 12.30028375803604\n",
      "resetting env. episode reward total was 17.0. running mean: 12.34728092045568\n",
      "resetting env. episode reward total was 13.0. running mean: 12.353808111251123\n",
      "resetting env. episode reward total was 7.0. running mean: 12.300270030138611\n",
      "resetting env. episode reward total was 19.0. running mean: 12.367267329837224\n",
      "resetting env. episode reward total was 16.0. running mean: 12.403594656538852\n",
      "resetting env. episode reward total was 6.0. running mean: 12.339558709973463\n",
      "resetting env. episode reward total was 11.0. running mean: 12.326163122873728\n",
      "resetting env. episode reward total was 16.0. running mean: 12.36290149164499\n",
      "resetting env. episode reward total was 11.0. running mean: 12.34927247672854\n",
      "resetting env. episode reward total was 13.0. running mean: 12.355779751961256\n",
      "resetting env. episode reward total was 7.0. running mean: 12.302221954441643\n",
      "resetting env. episode reward total was 14.0. running mean: 12.319199734897227\n",
      "resetting env. episode reward total was 14.0. running mean: 12.336007737548256\n",
      "resetting env. episode reward total was 12.0. running mean: 12.332647660172773\n",
      "resetting env. episode reward total was 10.0. running mean: 12.309321183571045\n",
      "resetting env. episode reward total was 20.0. running mean: 12.386227971735334\n",
      "resetting env. episode reward total was 11.0. running mean: 12.37236569201798\n",
      "resetting env. episode reward total was 13.0. running mean: 12.3786420350978\n",
      "resetting env. episode reward total was 16.0. running mean: 12.414855614746822\n",
      "resetting env. episode reward total was 13.0. running mean: 12.420707058599355\n",
      "resetting env. episode reward total was 18.0. running mean: 12.47649998801336\n",
      "resetting env. episode reward total was 15.0. running mean: 12.501734988133228\n",
      "resetting env. episode reward total was 12.0. running mean: 12.496717638251894\n",
      "resetting env. episode reward total was 14.0. running mean: 12.511750461869376\n",
      "resetting env. episode reward total was 14.0. running mean: 12.526632957250682\n",
      "resetting env. episode reward total was 13.0. running mean: 12.531366627678176\n",
      "resetting env. episode reward total was 10.0. running mean: 12.506052961401394\n",
      "resetting env. episode reward total was 9.0. running mean: 12.47099243178738\n",
      "resetting env. episode reward total was 12.0. running mean: 12.466282507469506\n",
      "resetting env. episode reward total was 14.0. running mean: 12.481619682394811\n",
      "resetting env. episode reward total was 9.0. running mean: 12.446803485570863\n",
      "resetting env. episode reward total was 14.0. running mean: 12.462335450715155\n",
      "resetting env. episode reward total was 14.0. running mean: 12.477712096208004\n",
      "resetting env. episode reward total was 9.0. running mean: 12.442934975245924\n",
      "resetting env. episode reward total was 11.0. running mean: 12.428505625493464\n",
      "resetting env. episode reward total was 15.0. running mean: 12.45422056923853\n",
      "resetting env. episode reward total was 14.0. running mean: 12.469678363546144\n",
      "resetting env. episode reward total was 18.0. running mean: 12.524981579910682\n",
      "resetting env. episode reward total was 6.0. running mean: 12.459731764111575\n",
      "resetting env. episode reward total was 9.0. running mean: 12.425134446470459\n",
      "resetting env. episode reward total was 6.0. running mean: 12.360883102005754\n",
      "resetting env. episode reward total was 15.0. running mean: 12.387274270985698\n",
      "resetting env. episode reward total was 14.0. running mean: 12.403401528275841\n",
      "resetting env. episode reward total was 17.0. running mean: 12.449367512993083\n",
      "resetting env. episode reward total was 19.0. running mean: 12.514873837863151\n",
      "resetting env. episode reward total was 16.0. running mean: 12.549725099484519\n",
      "resetting env. episode reward total was 12.0. running mean: 12.544227848489673\n",
      "resetting env. episode reward total was 13.0. running mean: 12.548785570004776\n",
      "resetting env. episode reward total was 14.0. running mean: 12.56329771430473\n",
      "resetting env. episode reward total was 13.0. running mean: 12.567664737161683\n",
      "resetting env. episode reward total was 5.0. running mean: 12.491988089790068\n",
      "resetting env. episode reward total was 10.0. running mean: 12.467068208892167\n",
      "resetting env. episode reward total was 16.0. running mean: 12.502397526803245\n",
      "resetting env. episode reward total was 15.0. running mean: 12.527373551535213\n",
      "resetting env. episode reward total was 16.0. running mean: 12.562099816019861\n",
      "resetting env. episode reward total was 8.0. running mean: 12.516478817859662\n",
      "resetting env. episode reward total was 16.0. running mean: 12.551314029681066\n",
      "resetting env. episode reward total was 19.0. running mean: 12.615800889384255\n",
      "resetting env. episode reward total was 12.0. running mean: 12.609642880490412\n",
      "resetting env. episode reward total was 14.0. running mean: 12.623546451685508\n",
      "resetting env. episode reward total was 12.0. running mean: 12.617310987168652\n",
      "resetting env. episode reward total was 3.0. running mean: 12.521137877296965\n",
      "resetting env. episode reward total was 13.0. running mean: 12.525926498523996\n",
      "resetting env. episode reward total was 14.0. running mean: 12.540667233538755\n",
      "resetting env. episode reward total was 12.0. running mean: 12.535260561203367\n",
      "resetting env. episode reward total was 15.0. running mean: 12.559907955591333\n",
      "resetting env. episode reward total was 9.0. running mean: 12.52430887603542\n",
      "resetting env. episode reward total was 14.0. running mean: 12.539065787275065\n",
      "resetting env. episode reward total was 12.0. running mean: 12.533675129402313\n",
      "resetting env. episode reward total was 10.0. running mean: 12.50833837810829\n",
      "resetting env. episode reward total was 20.0. running mean: 12.583254994327206\n",
      "resetting env. episode reward total was 14.0. running mean: 12.597422444383934\n",
      "resetting env. episode reward total was 10.0. running mean: 12.571448219940095\n",
      "resetting env. episode reward total was 13.0. running mean: 12.575733737740695\n",
      "resetting env. episode reward total was 17.0. running mean: 12.619976400363287\n",
      "resetting env. episode reward total was 8.0. running mean: 12.573776636359653\n",
      "resetting env. episode reward total was 15.0. running mean: 12.598038869996056\n",
      "resetting env. episode reward total was 10.0. running mean: 12.572058481296095\n",
      "resetting env. episode reward total was 13.0. running mean: 12.576337896483134\n",
      "resetting env. episode reward total was 15.0. running mean: 12.600574517518302\n",
      "resetting env. episode reward total was 10.0. running mean: 12.574568772343119\n",
      "resetting env. episode reward total was 18.0. running mean: 12.628823084619688\n",
      "resetting env. episode reward total was 11.0. running mean: 12.612534853773491\n",
      "resetting env. episode reward total was 5.0. running mean: 12.536409505235756\n",
      "resetting env. episode reward total was 15.0. running mean: 12.561045410183398\n",
      "resetting env. episode reward total was 11.0. running mean: 12.545434956081564\n",
      "resetting env. episode reward total was 13.0. running mean: 12.54998060652075\n",
      "resetting env. episode reward total was 14.0. running mean: 12.564480800455543\n",
      "resetting env. episode reward total was 12.0. running mean: 12.558835992450987\n",
      "resetting env. episode reward total was 11.0. running mean: 12.543247632526477\n",
      "resetting env. episode reward total was 14.0. running mean: 12.557815156201212\n",
      "resetting env. episode reward total was 15.0. running mean: 12.5822370046392\n",
      "resetting env. episode reward total was 10.0. running mean: 12.556414634592807\n",
      "resetting env. episode reward total was 17.0. running mean: 12.600850488246879\n",
      "resetting env. episode reward total was 19.0. running mean: 12.66484198336441\n",
      "resetting env. episode reward total was 10.0. running mean: 12.638193563530765\n",
      "resetting env. episode reward total was 12.0. running mean: 12.631811627895456\n",
      "resetting env. episode reward total was 11.0. running mean: 12.615493511616501\n",
      "resetting env. episode reward total was 17.0. running mean: 12.659338576500335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 12.582745190735332\n",
      "resetting env. episode reward total was 9.0. running mean: 12.546917738827979\n",
      "resetting env. episode reward total was 9.0. running mean: 12.511448561439698\n",
      "resetting env. episode reward total was 17.0. running mean: 12.556334075825301\n",
      "resetting env. episode reward total was 12.0. running mean: 12.550770735067047\n",
      "resetting env. episode reward total was 12.0. running mean: 12.545263027716375\n",
      "resetting env. episode reward total was 11.0. running mean: 12.529810397439212\n",
      "resetting env. episode reward total was 11.0. running mean: 12.514512293464819\n",
      "resetting env. episode reward total was 13.0. running mean: 12.51936717053017\n",
      "resetting env. episode reward total was 17.0. running mean: 12.564173498824868\n",
      "resetting env. episode reward total was 11.0. running mean: 12.54853176383662\n",
      "resetting env. episode reward total was 16.0. running mean: 12.583046446198253\n",
      "resetting env. episode reward total was 12.0. running mean: 12.57721598173627\n",
      "resetting env. episode reward total was 16.0. running mean: 12.611443821918908\n",
      "resetting env. episode reward total was -5.0. running mean: 12.435329383699719\n",
      "resetting env. episode reward total was 14.0. running mean: 12.450976089862722\n",
      "resetting env. episode reward total was 17.0. running mean: 12.496466328964095\n",
      "resetting env. episode reward total was 14.0. running mean: 12.511501665674455\n",
      "resetting env. episode reward total was 18.0. running mean: 12.56638664901771\n",
      "resetting env. episode reward total was 11.0. running mean: 12.550722782527533\n",
      "resetting env. episode reward total was 13.0. running mean: 12.555215554702258\n",
      "resetting env. episode reward total was 13.0. running mean: 12.559663399155236\n",
      "resetting env. episode reward total was 16.0. running mean: 12.594066765163683\n",
      "resetting env. episode reward total was 15.0. running mean: 12.618126097512047\n",
      "resetting env. episode reward total was 8.0. running mean: 12.571944836536925\n",
      "resetting env. episode reward total was 11.0. running mean: 12.556225388171555\n",
      "resetting env. episode reward total was 6.0. running mean: 12.49066313428984\n",
      "resetting env. episode reward total was 13.0. running mean: 12.495756502946941\n",
      "resetting env. episode reward total was 13.0. running mean: 12.500798937917473\n",
      "resetting env. episode reward total was 11.0. running mean: 12.485790948538298\n",
      "resetting env. episode reward total was 3.0. running mean: 12.390933039052914\n",
      "resetting env. episode reward total was 10.0. running mean: 12.367023708662385\n",
      "resetting env. episode reward total was 9.0. running mean: 12.33335347157576\n",
      "resetting env. episode reward total was 5.0. running mean: 12.260019936860003\n",
      "resetting env. episode reward total was 10.0. running mean: 12.237419737491402\n",
      "resetting env. episode reward total was 13.0. running mean: 12.24504554011649\n",
      "resetting env. episode reward total was 14.0. running mean: 12.262595084715326\n",
      "resetting env. episode reward total was 12.0. running mean: 12.259969133868172\n",
      "resetting env. episode reward total was 7.0. running mean: 12.20736944252949\n",
      "resetting env. episode reward total was 15.0. running mean: 12.235295748104196\n",
      "resetting env. episode reward total was 14.0. running mean: 12.252942790623155\n",
      "resetting env. episode reward total was 17.0. running mean: 12.300413362716924\n",
      "resetting env. episode reward total was 11.0. running mean: 12.287409229089754\n",
      "resetting env. episode reward total was 14.0. running mean: 12.304535136798856\n",
      "resetting env. episode reward total was 7.0. running mean: 12.251489785430868\n",
      "resetting env. episode reward total was 15.0. running mean: 12.27897488757656\n",
      "resetting env. episode reward total was 7.0. running mean: 12.226185138700794\n",
      "resetting env. episode reward total was 14.0. running mean: 12.243923287313786\n",
      "resetting env. episode reward total was 18.0. running mean: 12.301484054440648\n",
      "resetting env. episode reward total was 8.0. running mean: 12.258469213896241\n",
      "resetting env. episode reward total was 9.0. running mean: 12.225884521757278\n",
      "resetting env. episode reward total was 11.0. running mean: 12.213625676539705\n",
      "resetting env. episode reward total was 16.0. running mean: 12.251489419774307\n",
      "resetting env. episode reward total was 9.0. running mean: 12.218974525576565\n",
      "resetting env. episode reward total was 16.0. running mean: 12.2567847803208\n",
      "resetting env. episode reward total was 14.0. running mean: 12.274216932517593\n",
      "resetting env. episode reward total was 15.0. running mean: 12.301474763192417\n",
      "resetting env. episode reward total was 16.0. running mean: 12.338460015560493\n",
      "resetting env. episode reward total was 8.0. running mean: 12.295075415404888\n",
      "resetting env. episode reward total was 4.0. running mean: 12.212124661250838\n",
      "resetting env. episode reward total was 10.0. running mean: 12.19000341463833\n",
      "resetting env. episode reward total was 11.0. running mean: 12.178103380491946\n",
      "resetting env. episode reward total was 12.0. running mean: 12.176322346687025\n",
      "resetting env. episode reward total was 15.0. running mean: 12.204559123220156\n",
      "resetting env. episode reward total was 11.0. running mean: 12.192513531987954\n",
      "resetting env. episode reward total was 18.0. running mean: 12.250588396668075\n",
      "resetting env. episode reward total was 7.0. running mean: 12.198082512701394\n",
      "resetting env. episode reward total was 8.0. running mean: 12.15610168757438\n",
      "resetting env. episode reward total was 11.0. running mean: 12.144540670698635\n",
      "resetting env. episode reward total was 9.0. running mean: 12.11309526399165\n",
      "resetting env. episode reward total was 14.0. running mean: 12.131964311351734\n",
      "resetting env. episode reward total was 11.0. running mean: 12.120644668238215\n",
      "resetting env. episode reward total was 8.0. running mean: 12.079438221555833\n",
      "resetting env. episode reward total was 13.0. running mean: 12.088643839340275\n",
      "resetting env. episode reward total was 11.0. running mean: 12.077757400946872\n",
      "resetting env. episode reward total was 17.0. running mean: 12.126979826937403\n",
      "resetting env. episode reward total was 12.0. running mean: 12.125710028668028\n",
      "resetting env. episode reward total was 11.0. running mean: 12.114452928381347\n",
      "resetting env. episode reward total was 14.0. running mean: 12.133308399097533\n",
      "resetting env. episode reward total was 15.0. running mean: 12.161975315106558\n",
      "resetting env. episode reward total was 14.0. running mean: 12.180355561955492\n",
      "resetting env. episode reward total was 14.0. running mean: 12.198552006335937\n",
      "resetting env. episode reward total was 12.0. running mean: 12.196566486272577\n",
      "resetting env. episode reward total was 12.0. running mean: 12.19460082140985\n",
      "resetting env. episode reward total was 14.0. running mean: 12.212654813195751\n",
      "resetting env. episode reward total was 13.0. running mean: 12.220528265063795\n",
      "resetting env. episode reward total was 11.0. running mean: 12.208322982413156\n",
      "resetting env. episode reward total was 12.0. running mean: 12.206239752589024\n",
      "resetting env. episode reward total was 16.0. running mean: 12.244177355063133\n",
      "resetting env. episode reward total was 16.0. running mean: 12.281735581512502\n",
      "resetting env. episode reward total was 12.0. running mean: 12.278918225697376\n",
      "resetting env. episode reward total was 15.0. running mean: 12.306129043440404\n",
      "resetting env. episode reward total was 9.0. running mean: 12.273067753006\n",
      "resetting env. episode reward total was 11.0. running mean: 12.26033707547594\n",
      "resetting env. episode reward total was 12.0. running mean: 12.25773370472118\n",
      "resetting env. episode reward total was 12.0. running mean: 12.255156367673967\n",
      "resetting env. episode reward total was 9.0. running mean: 12.222604803997227\n",
      "resetting env. episode reward total was 16.0. running mean: 12.260378755957255\n",
      "resetting env. episode reward total was 12.0. running mean: 12.257774968397682\n",
      "resetting env. episode reward total was 8.0. running mean: 12.215197218713705\n",
      "resetting env. episode reward total was 18.0. running mean: 12.273045246526568\n",
      "resetting env. episode reward total was 10.0. running mean: 12.250314794061302\n",
      "resetting env. episode reward total was 14.0. running mean: 12.26781164612069\n",
      "resetting env. episode reward total was 12.0. running mean: 12.265133529659481\n",
      "resetting env. episode reward total was 6.0. running mean: 12.202482194362887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 12.220457372419258\n",
      "resetting env. episode reward total was 16.0. running mean: 12.258252798695064\n",
      "resetting env. episode reward total was 13.0. running mean: 12.265670270708114\n",
      "resetting env. episode reward total was 15.0. running mean: 12.293013568001033\n",
      "resetting env. episode reward total was 14.0. running mean: 12.310083432321024\n",
      "resetting env. episode reward total was 16.0. running mean: 12.346982597997814\n",
      "resetting env. episode reward total was 8.0. running mean: 12.303512772017836\n",
      "resetting env. episode reward total was 16.0. running mean: 12.340477644297657\n",
      "resetting env. episode reward total was 14.0. running mean: 12.357072867854681\n",
      "resetting env. episode reward total was 9.0. running mean: 12.323502139176133\n",
      "resetting env. episode reward total was 12.0. running mean: 12.320267117784372\n",
      "resetting env. episode reward total was 17.0. running mean: 12.367064446606529\n",
      "resetting env. episode reward total was 17.0. running mean: 12.413393802140464\n",
      "resetting env. episode reward total was 8.0. running mean: 12.369259864119059\n",
      "resetting env. episode reward total was 12.0. running mean: 12.365567265477868\n",
      "resetting env. episode reward total was 7.0. running mean: 12.311911592823089\n",
      "resetting env. episode reward total was 8.0. running mean: 12.268792476894857\n",
      "resetting env. episode reward total was 14.0. running mean: 12.28610455212591\n",
      "resetting env. episode reward total was 10.0. running mean: 12.263243506604649\n",
      "resetting env. episode reward total was 5.0. running mean: 12.190611071538603\n",
      "resetting env. episode reward total was 12.0. running mean: 12.188704960823216\n",
      "resetting env. episode reward total was 12.0. running mean: 12.186817911214982\n",
      "resetting env. episode reward total was 14.0. running mean: 12.204949732102833\n",
      "resetting env. episode reward total was 12.0. running mean: 12.202900234781803\n",
      "resetting env. episode reward total was 13.0. running mean: 12.210871232433986\n",
      "resetting env. episode reward total was 14.0. running mean: 12.228762520109646\n",
      "resetting env. episode reward total was 14.0. running mean: 12.24647489490855\n",
      "resetting env. episode reward total was 14.0. running mean: 12.264010145959466\n",
      "resetting env. episode reward total was 13.0. running mean: 12.271370044499871\n",
      "resetting env. episode reward total was 18.0. running mean: 12.328656344054872\n",
      "resetting env. episode reward total was 11.0. running mean: 12.315369780614322\n",
      "resetting env. episode reward total was 4.0. running mean: 12.232216082808177\n",
      "resetting env. episode reward total was 14.0. running mean: 12.249893921980096\n",
      "resetting env. episode reward total was 17.0. running mean: 12.297394982760295\n",
      "resetting env. episode reward total was 9.0. running mean: 12.264421032932692\n",
      "resetting env. episode reward total was 14.0. running mean: 12.281776822603366\n",
      "resetting env. episode reward total was 12.0. running mean: 12.278959054377331\n",
      "resetting env. episode reward total was 16.0. running mean: 12.316169463833559\n",
      "resetting env. episode reward total was 15.0. running mean: 12.343007769195223\n",
      "resetting env. episode reward total was 6.0. running mean: 12.279577691503272\n",
      "resetting env. episode reward total was 11.0. running mean: 12.266781914588238\n",
      "resetting env. episode reward total was 9.0. running mean: 12.234114095442356\n",
      "resetting env. episode reward total was 10.0. running mean: 12.211772954487932\n",
      "resetting env. episode reward total was 13.0. running mean: 12.219655224943054\n",
      "resetting env. episode reward total was 6.0. running mean: 12.157458672693624\n",
      "resetting env. episode reward total was 18.0. running mean: 12.215884085966687\n",
      "resetting env. episode reward total was 12.0. running mean: 12.21372524510702\n",
      "resetting env. episode reward total was 9.0. running mean: 12.181587992655949\n",
      "resetting env. episode reward total was 12.0. running mean: 12.179772112729388\n",
      "resetting env. episode reward total was 15.0. running mean: 12.207974391602095\n",
      "resetting env. episode reward total was 5.0. running mean: 12.135894647686074\n",
      "resetting env. episode reward total was 8.0. running mean: 12.094535701209214\n",
      "resetting env. episode reward total was 15.0. running mean: 12.123590344197122\n",
      "resetting env. episode reward total was 11.0. running mean: 12.112354440755151\n",
      "resetting env. episode reward total was 15.0. running mean: 12.1412308963476\n",
      "resetting env. episode reward total was 7.0. running mean: 12.089818587384125\n",
      "resetting env. episode reward total was 16.0. running mean: 12.128920401510284\n",
      "resetting env. episode reward total was 17.0. running mean: 12.177631197495181\n",
      "resetting env. episode reward total was 9.0. running mean: 12.14585488552023\n",
      "resetting env. episode reward total was 16.0. running mean: 12.184396336665028\n",
      "resetting env. episode reward total was 11.0. running mean: 12.172552373298377\n",
      "resetting env. episode reward total was 6.0. running mean: 12.110826849565393\n",
      "resetting env. episode reward total was 15.0. running mean: 12.13971858106974\n",
      "resetting env. episode reward total was 14.0. running mean: 12.158321395259042\n",
      "resetting env. episode reward total was 17.0. running mean: 12.206738181306452\n",
      "resetting env. episode reward total was 15.0. running mean: 12.234670799493388\n",
      "resetting env. episode reward total was 12.0. running mean: 12.232324091498453\n",
      "resetting env. episode reward total was 18.0. running mean: 12.290000850583468\n",
      "resetting env. episode reward total was 11.0. running mean: 12.277100842077632\n",
      "resetting env. episode reward total was 13.0. running mean: 12.284329833656855\n",
      "resetting env. episode reward total was 14.0. running mean: 12.301486535320286\n",
      "resetting env. episode reward total was 11.0. running mean: 12.288471669967082\n",
      "resetting env. episode reward total was 14.0. running mean: 12.305586953267412\n",
      "resetting env. episode reward total was 5.0. running mean: 12.232531083734738\n",
      "resetting env. episode reward total was 10.0. running mean: 12.21020577289739\n",
      "resetting env. episode reward total was 9.0. running mean: 12.178103715168417\n",
      "resetting env. episode reward total was 14.0. running mean: 12.196322678016733\n",
      "resetting env. episode reward total was 15.0. running mean: 12.224359451236566\n",
      "resetting env. episode reward total was 13.0. running mean: 12.232115856724201\n",
      "resetting env. episode reward total was 12.0. running mean: 12.229794698156958\n",
      "resetting env. episode reward total was 15.0. running mean: 12.257496751175388\n",
      "resetting env. episode reward total was 7.0. running mean: 12.204921783663634\n",
      "resetting env. episode reward total was 16.0. running mean: 12.242872565826998\n",
      "resetting env. episode reward total was 14.0. running mean: 12.260443840168728\n",
      "resetting env. episode reward total was 15.0. running mean: 12.287839401767041\n",
      "resetting env. episode reward total was 13.0. running mean: 12.294961007749372\n",
      "resetting env. episode reward total was 16.0. running mean: 12.332011397671877\n",
      "resetting env. episode reward total was 8.0. running mean: 12.288691283695158\n",
      "resetting env. episode reward total was 9.0. running mean: 12.255804370858206\n",
      "resetting env. episode reward total was 11.0. running mean: 12.243246327149624\n",
      "resetting env. episode reward total was 17.0. running mean: 12.290813863878128\n",
      "resetting env. episode reward total was 10.0. running mean: 12.267905725239347\n",
      "resetting env. episode reward total was 10.0. running mean: 12.245226667986953\n",
      "resetting env. episode reward total was 8.0. running mean: 12.202774401307083\n",
      "resetting env. episode reward total was 15.0. running mean: 12.230746657294013\n",
      "resetting env. episode reward total was 10.0. running mean: 12.208439190721073\n",
      "resetting env. episode reward total was 5.0. running mean: 12.136354798813862\n",
      "resetting env. episode reward total was 12.0. running mean: 12.134991250825722\n",
      "resetting env. episode reward total was 17.0. running mean: 12.183641338317464\n",
      "resetting env. episode reward total was 6.0. running mean: 12.12180492493429\n",
      "resetting env. episode reward total was 14.0. running mean: 12.140586875684948\n",
      "resetting env. episode reward total was 14.0. running mean: 12.1591810069281\n",
      "resetting env. episode reward total was 14.0. running mean: 12.177589196858818\n",
      "resetting env. episode reward total was 14.0. running mean: 12.19581330489023\n",
      "resetting env. episode reward total was 14.0. running mean: 12.213855171841328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 12.241716620122915\n",
      "resetting env. episode reward total was 14.0. running mean: 12.259299453921686\n",
      "resetting env. episode reward total was 13.0. running mean: 12.26670645938247\n",
      "resetting env. episode reward total was 9.0. running mean: 12.234039394788645\n",
      "resetting env. episode reward total was 15.0. running mean: 12.261699000840759\n",
      "resetting env. episode reward total was 15.0. running mean: 12.28908201083235\n",
      "resetting env. episode reward total was 3.0. running mean: 12.196191190724026\n",
      "resetting env. episode reward total was 11.0. running mean: 12.184229278816785\n",
      "resetting env. episode reward total was 15.0. running mean: 12.212386986028617\n",
      "resetting env. episode reward total was 9.0. running mean: 12.18026311616833\n",
      "resetting env. episode reward total was 16.0. running mean: 12.218460485006647\n",
      "resetting env. episode reward total was 13.0. running mean: 12.226275880156582\n",
      "resetting env. episode reward total was 6.0. running mean: 12.164013121355016\n",
      "resetting env. episode reward total was 13.0. running mean: 12.172372990141467\n",
      "resetting env. episode reward total was 10.0. running mean: 12.150649260240051\n",
      "resetting env. episode reward total was 16.0. running mean: 12.189142767637652\n",
      "resetting env. episode reward total was 13.0. running mean: 12.197251339961277\n",
      "resetting env. episode reward total was 13.0. running mean: 12.205278826561665\n",
      "resetting env. episode reward total was 13.0. running mean: 12.21322603829605\n",
      "resetting env. episode reward total was 12.0. running mean: 12.211093777913089\n",
      "resetting env. episode reward total was 13.0. running mean: 12.218982840133958\n",
      "resetting env. episode reward total was 14.0. running mean: 12.236793011732619\n",
      "resetting env. episode reward total was 13.0. running mean: 12.244425081615294\n",
      "resetting env. episode reward total was 12.0. running mean: 12.24198083079914\n",
      "resetting env. episode reward total was 4.0. running mean: 12.159561022491147\n",
      "resetting env. episode reward total was 17.0. running mean: 12.207965412266235\n",
      "resetting env. episode reward total was 13.0. running mean: 12.215885758143573\n",
      "resetting env. episode reward total was 12.0. running mean: 12.213726900562136\n",
      "resetting env. episode reward total was 11.0. running mean: 12.201589631556514\n",
      "resetting env. episode reward total was 13.0. running mean: 12.20957373524095\n",
      "resetting env. episode reward total was 9.0. running mean: 12.17747799788854\n",
      "resetting env. episode reward total was 13.0. running mean: 12.185703217909655\n",
      "resetting env. episode reward total was 10.0. running mean: 12.163846185730558\n",
      "resetting env. episode reward total was 15.0. running mean: 12.192207723873253\n",
      "resetting env. episode reward total was 10.0. running mean: 12.17028564663452\n",
      "resetting env. episode reward total was 5.0. running mean: 12.098582790168175\n",
      "resetting env. episode reward total was 7.0. running mean: 12.047596962266493\n",
      "resetting env. episode reward total was 12.0. running mean: 12.047120992643826\n",
      "resetting env. episode reward total was 10.0. running mean: 12.026649782717387\n",
      "resetting env. episode reward total was 19.0. running mean: 12.096383284890212\n",
      "resetting env. episode reward total was 14.0. running mean: 12.11541945204131\n",
      "resetting env. episode reward total was 18.0. running mean: 12.174265257520897\n",
      "resetting env. episode reward total was 8.0. running mean: 12.132522604945688\n",
      "resetting env. episode reward total was 12.0. running mean: 12.13119737889623\n",
      "resetting env. episode reward total was 14.0. running mean: 12.149885405107268\n",
      "resetting env. episode reward total was 13.0. running mean: 12.158386551056196\n",
      "resetting env. episode reward total was 18.0. running mean: 12.216802685545634\n",
      "resetting env. episode reward total was 15.0. running mean: 12.244634658690178\n",
      "resetting env. episode reward total was 16.0. running mean: 12.282188312103276\n",
      "resetting env. episode reward total was 12.0. running mean: 12.279366428982243\n",
      "resetting env. episode reward total was 12.0. running mean: 12.27657276469242\n",
      "resetting env. episode reward total was 16.0. running mean: 12.313807037045494\n",
      "resetting env. episode reward total was 12.0. running mean: 12.310668966675038\n",
      "resetting env. episode reward total was 10.0. running mean: 12.287562277008288\n",
      "resetting env. episode reward total was 9.0. running mean: 12.254686654238204\n",
      "resetting env. episode reward total was 10.0. running mean: 12.232139787695822\n",
      "resetting env. episode reward total was 15.0. running mean: 12.259818389818864\n",
      "resetting env. episode reward total was 12.0. running mean: 12.257220205920675\n",
      "resetting env. episode reward total was 17.0. running mean: 12.304648003861468\n",
      "resetting env. episode reward total was 19.0. running mean: 12.371601523822852\n",
      "resetting env. episode reward total was 18.0. running mean: 12.427885508584623\n",
      "resetting env. episode reward total was 12.0. running mean: 12.423606653498776\n",
      "resetting env. episode reward total was 7.0. running mean: 12.36937058696379\n",
      "resetting env. episode reward total was 12.0. running mean: 12.365676881094151\n",
      "resetting env. episode reward total was 10.0. running mean: 12.342020112283208\n",
      "resetting env. episode reward total was 10.0. running mean: 12.318599911160376\n",
      "resetting env. episode reward total was 12.0. running mean: 12.315413912048772\n",
      "resetting env. episode reward total was 11.0. running mean: 12.302259772928284\n",
      "resetting env. episode reward total was 16.0. running mean: 12.339237175199\n",
      "resetting env. episode reward total was 17.0. running mean: 12.38584480344701\n",
      "resetting env. episode reward total was 16.0. running mean: 12.42198635541254\n",
      "resetting env. episode reward total was 15.0. running mean: 12.447766491858415\n",
      "resetting env. episode reward total was 10.0. running mean: 12.42328882693983\n",
      "resetting env. episode reward total was 11.0. running mean: 12.40905593867043\n",
      "resetting env. episode reward total was 17.0. running mean: 12.454965379283726\n",
      "resetting env. episode reward total was 12.0. running mean: 12.450415725490888\n",
      "resetting env. episode reward total was 14.0. running mean: 12.46591156823598\n",
      "resetting env. episode reward total was 19.0. running mean: 12.53125245255362\n",
      "resetting env. episode reward total was 16.0. running mean: 12.565939928028083\n",
      "resetting env. episode reward total was 9.0. running mean: 12.530280528747802\n",
      "resetting env. episode reward total was 20.0. running mean: 12.604977723460323\n",
      "resetting env. episode reward total was 15.0. running mean: 12.62892794622572\n",
      "resetting env. episode reward total was 15.0. running mean: 12.652638666763462\n",
      "resetting env. episode reward total was 13.0. running mean: 12.656112280095828\n",
      "resetting env. episode reward total was 16.0. running mean: 12.68955115729487\n",
      "resetting env. episode reward total was 5.0. running mean: 12.612655645721922\n",
      "resetting env. episode reward total was 18.0. running mean: 12.666529089264703\n",
      "resetting env. episode reward total was 13.0. running mean: 12.669863798372056\n",
      "resetting env. episode reward total was 11.0. running mean: 12.653165160388335\n",
      "resetting env. episode reward total was 8.0. running mean: 12.606633508784451\n",
      "resetting env. episode reward total was 11.0. running mean: 12.590567173696606\n",
      "resetting env. episode reward total was 16.0. running mean: 12.62466150195964\n",
      "resetting env. episode reward total was 16.0. running mean: 12.658414886940044\n",
      "resetting env. episode reward total was 14.0. running mean: 12.671830738070645\n",
      "resetting env. episode reward total was 16.0. running mean: 12.705112430689939\n",
      "resetting env. episode reward total was 14.0. running mean: 12.71806130638304\n",
      "resetting env. episode reward total was 15.0. running mean: 12.74088069331921\n",
      "resetting env. episode reward total was 10.0. running mean: 12.713471886386019\n",
      "resetting env. episode reward total was 13.0. running mean: 12.716337167522159\n",
      "resetting env. episode reward total was 13.0. running mean: 12.719173795846938\n",
      "resetting env. episode reward total was 17.0. running mean: 12.761982057888469\n",
      "resetting env. episode reward total was 11.0. running mean: 12.744362237309584\n",
      "resetting env. episode reward total was 14.0. running mean: 12.756918614936488\n",
      "resetting env. episode reward total was 10.0. running mean: 12.729349428787122\n",
      "resetting env. episode reward total was 5.0. running mean: 12.652055934499252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 12.58553537515426\n",
      "resetting env. episode reward total was 12.0. running mean: 12.579680021402716\n",
      "resetting env. episode reward total was 11.0. running mean: 12.563883221188688\n",
      "resetting env. episode reward total was 16.0. running mean: 12.5982443889768\n",
      "resetting env. episode reward total was 18.0. running mean: 12.652261945087032\n",
      "resetting env. episode reward total was 13.0. running mean: 12.655739325636162\n",
      "resetting env. episode reward total was 14.0. running mean: 12.6691819323798\n",
      "resetting env. episode reward total was 14.0. running mean: 12.682490113056003\n",
      "resetting env. episode reward total was 15.0. running mean: 12.705665211925444\n",
      "resetting env. episode reward total was 10.0. running mean: 12.67860855980619\n",
      "resetting env. episode reward total was 14.0. running mean: 12.691822474208129\n",
      "resetting env. episode reward total was 15.0. running mean: 12.714904249466048\n",
      "resetting env. episode reward total was 8.0. running mean: 12.667755206971387\n",
      "resetting env. episode reward total was 9.0. running mean: 12.631077654901674\n",
      "resetting env. episode reward total was 13.0. running mean: 12.634766878352657\n",
      "resetting env. episode reward total was 15.0. running mean: 12.65841920956913\n",
      "resetting env. episode reward total was 14.0. running mean: 12.67183501747344\n",
      "resetting env. episode reward total was 10.0. running mean: 12.645116667298705\n",
      "resetting env. episode reward total was 14.0. running mean: 12.658665500625718\n",
      "resetting env. episode reward total was 15.0. running mean: 12.682078845619461\n",
      "resetting env. episode reward total was 12.0. running mean: 12.675258057163266\n",
      "resetting env. episode reward total was 11.0. running mean: 12.658505476591632\n",
      "resetting env. episode reward total was 15.0. running mean: 12.681920421825716\n",
      "resetting env. episode reward total was 12.0. running mean: 12.675101217607457\n",
      "resetting env. episode reward total was 9.0. running mean: 12.638350205431383\n",
      "resetting env. episode reward total was 12.0. running mean: 12.631966703377069\n",
      "resetting env. episode reward total was 12.0. running mean: 12.625647036343297\n",
      "resetting env. episode reward total was 11.0. running mean: 12.609390565979863\n",
      "resetting env. episode reward total was 13.0. running mean: 12.613296660320065\n",
      "resetting env. episode reward total was 17.0. running mean: 12.657163693716864\n",
      "resetting env. episode reward total was 12.0. running mean: 12.650592056779695\n",
      "resetting env. episode reward total was 16.0. running mean: 12.684086136211898\n",
      "resetting env. episode reward total was 11.0. running mean: 12.667245274849778\n",
      "resetting env. episode reward total was 14.0. running mean: 12.680572822101281\n",
      "resetting env. episode reward total was 17.0. running mean: 12.723767093880268\n",
      "resetting env. episode reward total was 8.0. running mean: 12.676529422941465\n",
      "resetting env. episode reward total was 9.0. running mean: 12.63976412871205\n",
      "resetting env. episode reward total was 14.0. running mean: 12.65336648742493\n",
      "resetting env. episode reward total was 17.0. running mean: 12.69683282255068\n",
      "resetting env. episode reward total was 12.0. running mean: 12.689864494325173\n",
      "resetting env. episode reward total was 6.0. running mean: 12.622965849381922\n",
      "resetting env. episode reward total was 11.0. running mean: 12.606736190888101\n",
      "resetting env. episode reward total was 15.0. running mean: 12.630668828979221\n",
      "resetting env. episode reward total was 11.0. running mean: 12.614362140689428\n",
      "resetting env. episode reward total was 14.0. running mean: 12.628218519282534\n",
      "resetting env. episode reward total was 15.0. running mean: 12.651936334089708\n",
      "resetting env. episode reward total was 6.0. running mean: 12.585416970748811\n",
      "resetting env. episode reward total was 17.0. running mean: 12.629562801041324\n",
      "resetting env. episode reward total was 12.0. running mean: 12.623267173030909\n",
      "resetting env. episode reward total was 17.0. running mean: 12.6670345013006\n",
      "resetting env. episode reward total was 19.0. running mean: 12.730364156287594\n",
      "resetting env. episode reward total was 11.0. running mean: 12.713060514724718\n",
      "resetting env. episode reward total was 6.0. running mean: 12.645929909577472\n",
      "resetting env. episode reward total was 12.0. running mean: 12.639470610481697\n",
      "resetting env. episode reward total was 11.0. running mean: 12.62307590437688\n",
      "resetting env. episode reward total was 8.0. running mean: 12.57684514533311\n",
      "resetting env. episode reward total was 12.0. running mean: 12.571076693879778\n",
      "resetting env. episode reward total was 11.0. running mean: 12.55536592694098\n",
      "resetting env. episode reward total was 15.0. running mean: 12.579812267671569\n",
      "resetting env. episode reward total was 12.0. running mean: 12.574014144994852\n",
      "resetting env. episode reward total was 5.0. running mean: 12.498274003544903\n",
      "resetting env. episode reward total was 12.0. running mean: 12.493291263509454\n",
      "resetting env. episode reward total was 19.0. running mean: 12.558358350874359\n",
      "resetting env. episode reward total was 11.0. running mean: 12.542774767365614\n",
      "resetting env. episode reward total was 13.0. running mean: 12.547347019691959\n",
      "resetting env. episode reward total was 11.0. running mean: 12.531873549495039\n",
      "resetting env. episode reward total was 12.0. running mean: 12.526554814000088\n",
      "resetting env. episode reward total was 14.0. running mean: 12.541289265860087\n",
      "resetting env. episode reward total was 16.0. running mean: 12.575876373201487\n",
      "resetting env. episode reward total was 7.0. running mean: 12.520117609469471\n",
      "resetting env. episode reward total was 17.0. running mean: 12.564916433374776\n",
      "resetting env. episode reward total was 10.0. running mean: 12.539267269041028\n",
      "resetting env. episode reward total was 16.0. running mean: 12.573874596350619\n",
      "resetting env. episode reward total was 14.0. running mean: 12.588135850387113\n",
      "resetting env. episode reward total was 11.0. running mean: 12.57225449188324\n",
      "resetting env. episode reward total was 13.0. running mean: 12.576531946964408\n",
      "resetting env. episode reward total was 16.0. running mean: 12.610766627494764\n",
      "resetting env. episode reward total was 16.0. running mean: 12.644658961219816\n",
      "resetting env. episode reward total was 16.0. running mean: 12.678212371607618\n",
      "resetting env. episode reward total was 14.0. running mean: 12.691430247891542\n",
      "resetting env. episode reward total was 14.0. running mean: 12.704515945412627\n",
      "resetting env. episode reward total was 10.0. running mean: 12.6774707859585\n",
      "resetting env. episode reward total was 13.0. running mean: 12.680696078098915\n",
      "resetting env. episode reward total was 19.0. running mean: 12.743889117317925\n",
      "resetting env. episode reward total was 14.0. running mean: 12.756450226144747\n",
      "resetting env. episode reward total was 14.0. running mean: 12.7688857238833\n",
      "resetting env. episode reward total was 9.0. running mean: 12.731196866644465\n",
      "resetting env. episode reward total was 6.0. running mean: 12.66388489797802\n",
      "resetting env. episode reward total was 8.0. running mean: 12.61724604899824\n",
      "resetting env. episode reward total was 15.0. running mean: 12.641073588508258\n",
      "resetting env. episode reward total was 13.0. running mean: 12.644662852623176\n",
      "resetting env. episode reward total was 12.0. running mean: 12.638216224096944\n",
      "resetting env. episode reward total was 14.0. running mean: 12.651834061855974\n",
      "resetting env. episode reward total was 16.0. running mean: 12.685315721237414\n",
      "resetting env. episode reward total was 19.0. running mean: 12.74846256402504\n",
      "resetting env. episode reward total was 16.0. running mean: 12.78097793838479\n",
      "resetting env. episode reward total was 16.0. running mean: 12.813168159000943\n",
      "resetting env. episode reward total was 14.0. running mean: 12.825036477410935\n",
      "resetting env. episode reward total was 12.0. running mean: 12.816786112636825\n",
      "resetting env. episode reward total was 13.0. running mean: 12.818618251510458\n",
      "resetting env. episode reward total was 15.0. running mean: 12.840432068995353\n",
      "resetting env. episode reward total was 15.0. running mean: 12.8620277483054\n",
      "resetting env. episode reward total was 16.0. running mean: 12.893407470822345\n",
      "resetting env. episode reward total was 11.0. running mean: 12.874473396114121\n",
      "resetting env. episode reward total was 5.0. running mean: 12.79572866215298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 19.0. running mean: 12.857771375531449\n",
      "resetting env. episode reward total was 12.0. running mean: 12.849193661776134\n",
      "resetting env. episode reward total was 14.0. running mean: 12.860701725158373\n",
      "resetting env. episode reward total was 18.0. running mean: 12.912094707906789\n",
      "resetting env. episode reward total was 14.0. running mean: 12.922973760827722\n",
      "resetting env. episode reward total was 10.0. running mean: 12.893744023219444\n",
      "resetting env. episode reward total was 13.0. running mean: 12.89480658298725\n",
      "resetting env. episode reward total was 12.0. running mean: 12.885858517157377\n",
      "resetting env. episode reward total was 15.0. running mean: 12.906999931985803\n",
      "resetting env. episode reward total was 15.0. running mean: 12.927929932665945\n",
      "resetting env. episode reward total was 13.0. running mean: 12.928650633339286\n",
      "resetting env. episode reward total was 14.0. running mean: 12.939364127005893\n",
      "resetting env. episode reward total was 13.0. running mean: 12.939970485735834\n",
      "resetting env. episode reward total was 15.0. running mean: 12.960570780878477\n",
      "resetting env. episode reward total was 18.0. running mean: 13.010965073069691\n",
      "resetting env. episode reward total was 16.0. running mean: 13.040855422338995\n",
      "resetting env. episode reward total was 13.0. running mean: 13.040446868115605\n",
      "resetting env. episode reward total was 10.0. running mean: 13.010042399434449\n",
      "resetting env. episode reward total was 14.0. running mean: 13.019941975440105\n",
      "resetting env. episode reward total was 11.0. running mean: 12.999742555685703\n",
      "resetting env. episode reward total was 11.0. running mean: 12.979745130128846\n",
      "resetting env. episode reward total was 17.0. running mean: 13.019947678827558\n",
      "resetting env. episode reward total was 9.0. running mean: 12.979748202039282\n",
      "resetting env. episode reward total was 13.0. running mean: 12.97995072001889\n",
      "resetting env. episode reward total was 15.0. running mean: 13.0001512128187\n",
      "resetting env. episode reward total was 9.0. running mean: 12.960149700690513\n",
      "resetting env. episode reward total was 15.0. running mean: 12.980548203683608\n",
      "resetting env. episode reward total was 14.0. running mean: 12.990742721646772\n",
      "resetting env. episode reward total was 14.0. running mean: 13.000835294430305\n",
      "resetting env. episode reward total was 14.0. running mean: 13.010826941486002\n",
      "resetting env. episode reward total was 16.0. running mean: 13.040718672071142\n",
      "resetting env. episode reward total was 5.0. running mean: 12.96031148535043\n",
      "resetting env. episode reward total was 14.0. running mean: 12.970708370496927\n",
      "resetting env. episode reward total was 15.0. running mean: 12.991001286791958\n",
      "resetting env. episode reward total was 11.0. running mean: 12.971091273924038\n",
      "resetting env. episode reward total was 13.0. running mean: 12.9713803611848\n",
      "resetting env. episode reward total was 20.0. running mean: 13.04166655757295\n",
      "resetting env. episode reward total was 14.0. running mean: 13.051249891997221\n",
      "resetting env. episode reward total was 11.0. running mean: 13.03073739307725\n",
      "resetting env. episode reward total was 15.0. running mean: 13.050430019146477\n",
      "resetting env. episode reward total was 5.0. running mean: 12.969925718955013\n",
      "resetting env. episode reward total was 10.0. running mean: 12.940226461765462\n",
      "resetting env. episode reward total was 12.0. running mean: 12.930824197147807\n",
      "resetting env. episode reward total was 12.0. running mean: 12.921515955176329\n",
      "resetting env. episode reward total was 13.0. running mean: 12.922300795624565\n",
      "resetting env. episode reward total was 12.0. running mean: 12.91307778766832\n",
      "resetting env. episode reward total was 18.0. running mean: 12.963947009791635\n",
      "resetting env. episode reward total was 12.0. running mean: 12.954307539693717\n",
      "resetting env. episode reward total was 18.0. running mean: 13.00476446429678\n",
      "resetting env. episode reward total was 11.0. running mean: 12.984716819653812\n",
      "resetting env. episode reward total was 10.0. running mean: 12.954869651457274\n",
      "resetting env. episode reward total was 12.0. running mean: 12.945320954942702\n",
      "resetting env. episode reward total was 10.0. running mean: 12.915867745393275\n",
      "resetting env. episode reward total was 14.0. running mean: 12.926709067939342\n",
      "resetting env. episode reward total was 14.0. running mean: 12.93744197725995\n",
      "resetting env. episode reward total was 11.0. running mean: 12.91806755748735\n",
      "resetting env. episode reward total was 15.0. running mean: 12.938886881912476\n",
      "resetting env. episode reward total was 11.0. running mean: 12.91949801309335\n",
      "resetting env. episode reward total was 15.0. running mean: 12.940303032962417\n",
      "resetting env. episode reward total was 14.0. running mean: 12.950900002632793\n",
      "resetting env. episode reward total was 19.0. running mean: 13.011391002606464\n",
      "resetting env. episode reward total was 7.0. running mean: 12.9512770925804\n",
      "resetting env. episode reward total was 15.0. running mean: 12.971764321654597\n",
      "resetting env. episode reward total was 14.0. running mean: 12.982046678438051\n",
      "resetting env. episode reward total was 10.0. running mean: 12.95222621165367\n",
      "resetting env. episode reward total was 14.0. running mean: 12.962703949537135\n",
      "resetting env. episode reward total was 18.0. running mean: 13.013076910041763\n",
      "resetting env. episode reward total was 15.0. running mean: 13.032946140941345\n",
      "resetting env. episode reward total was 15.0. running mean: 13.052616679531932\n",
      "resetting env. episode reward total was 14.0. running mean: 13.062090512736614\n",
      "resetting env. episode reward total was 15.0. running mean: 13.081469607609248\n",
      "resetting env. episode reward total was 10.0. running mean: 13.050654911533156\n",
      "resetting env. episode reward total was 13.0. running mean: 13.050148362417826\n",
      "resetting env. episode reward total was 13.0. running mean: 13.049646878793649\n",
      "resetting env. episode reward total was 13.0. running mean: 13.049150410005712\n",
      "resetting env. episode reward total was 19.0. running mean: 13.108658905905655\n",
      "resetting env. episode reward total was 18.0. running mean: 13.157572316846597\n",
      "resetting env. episode reward total was 15.0. running mean: 13.175996593678132\n",
      "resetting env. episode reward total was 15.0. running mean: 13.19423662774135\n",
      "resetting env. episode reward total was 5.0. running mean: 13.112294261463937\n",
      "resetting env. episode reward total was 14.0. running mean: 13.121171318849298\n",
      "resetting env. episode reward total was 12.0. running mean: 13.109959605660803\n",
      "resetting env. episode reward total was 12.0. running mean: 13.098860009604195\n",
      "resetting env. episode reward total was 14.0. running mean: 13.107871409508153\n",
      "resetting env. episode reward total was 12.0. running mean: 13.09679269541307\n",
      "resetting env. episode reward total was 13.0. running mean: 13.09582476845894\n",
      "resetting env. episode reward total was 13.0. running mean: 13.094866520774351\n",
      "resetting env. episode reward total was 13.0. running mean: 13.093917855566609\n",
      "resetting env. episode reward total was 14.0. running mean: 13.102978677010944\n",
      "resetting env. episode reward total was 7.0. running mean: 13.041948890240834\n",
      "resetting env. episode reward total was 10.0. running mean: 13.011529401338425\n",
      "resetting env. episode reward total was 9.0. running mean: 12.97141410732504\n",
      "resetting env. episode reward total was 14.0. running mean: 12.98169996625179\n",
      "resetting env. episode reward total was 17.0. running mean: 13.021882966589272\n",
      "resetting env. episode reward total was 10.0. running mean: 12.99166413692338\n",
      "resetting env. episode reward total was 15.0. running mean: 13.011747495554145\n",
      "resetting env. episode reward total was 17.0. running mean: 13.051630020598603\n",
      "resetting env. episode reward total was 13.0. running mean: 13.051113720392618\n",
      "resetting env. episode reward total was 12.0. running mean: 13.04060258318869\n",
      "resetting env. episode reward total was 13.0. running mean: 13.040196557356804\n",
      "resetting env. episode reward total was 16.0. running mean: 13.069794591783236\n",
      "resetting env. episode reward total was 16.0. running mean: 13.099096645865403\n",
      "resetting env. episode reward total was 15.0. running mean: 13.11810567940675\n",
      "resetting env. episode reward total was 13.0. running mean: 13.116924622612682\n",
      "resetting env. episode reward total was 16.0. running mean: 13.145755376386555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 13.14429782262269\n",
      "resetting env. episode reward total was 7.0. running mean: 13.082854844396463\n",
      "resetting env. episode reward total was 10.0. running mean: 13.052026295952498\n",
      "resetting env. episode reward total was 17.0. running mean: 13.091506032992973\n",
      "resetting env. episode reward total was 13.0. running mean: 13.090590972663044\n",
      "resetting env. episode reward total was 10.0. running mean: 13.059685062936413\n",
      "resetting env. episode reward total was 16.0. running mean: 13.089088212307049\n",
      "resetting env. episode reward total was 19.0. running mean: 13.148197330183978\n",
      "resetting env. episode reward total was 13.0. running mean: 13.146715356882138\n",
      "resetting env. episode reward total was 11.0. running mean: 13.125248203313316\n",
      "resetting env. episode reward total was 11.0. running mean: 13.103995721280182\n",
      "resetting env. episode reward total was 13.0. running mean: 13.10295576406738\n",
      "resetting env. episode reward total was 13.0. running mean: 13.101926206426707\n",
      "resetting env. episode reward total was 6.0. running mean: 13.03090694436244\n",
      "resetting env. episode reward total was 15.0. running mean: 13.050597874918816\n",
      "resetting env. episode reward total was 16.0. running mean: 13.080091896169629\n",
      "resetting env. episode reward total was 14.0. running mean: 13.089290977207932\n",
      "resetting env. episode reward total was 11.0. running mean: 13.068398067435853\n",
      "resetting env. episode reward total was 16.0. running mean: 13.097714086761494\n",
      "resetting env. episode reward total was 8.0. running mean: 13.046736945893878\n",
      "resetting env. episode reward total was 17.0. running mean: 13.086269576434939\n",
      "resetting env. episode reward total was 12.0. running mean: 13.075406880670588\n",
      "resetting env. episode reward total was 4.0. running mean: 12.984652811863882\n",
      "resetting env. episode reward total was 16.0. running mean: 13.014806283745243\n",
      "resetting env. episode reward total was 14.0. running mean: 13.02465822090779\n",
      "resetting env. episode reward total was 14.0. running mean: 13.034411638698712\n",
      "resetting env. episode reward total was 9.0. running mean: 12.994067522311724\n",
      "resetting env. episode reward total was 15.0. running mean: 13.014126847088606\n",
      "resetting env. episode reward total was 16.0. running mean: 13.04398557861772\n",
      "resetting env. episode reward total was 9.0. running mean: 13.003545722831543\n",
      "resetting env. episode reward total was 9.0. running mean: 12.963510265603228\n",
      "resetting env. episode reward total was 10.0. running mean: 12.933875162947196\n",
      "resetting env. episode reward total was 4.0. running mean: 12.844536411317723\n",
      "resetting env. episode reward total was 15.0. running mean: 12.866091047204545\n",
      "resetting env. episode reward total was 13.0. running mean: 12.8674301367325\n",
      "resetting env. episode reward total was 10.0. running mean: 12.838755835365173\n",
      "resetting env. episode reward total was 14.0. running mean: 12.850368277011523\n",
      "resetting env. episode reward total was 9.0. running mean: 12.811864594241408\n",
      "resetting env. episode reward total was 12.0. running mean: 12.803745948298992\n",
      "resetting env. episode reward total was 15.0. running mean: 12.825708488816003\n",
      "resetting env. episode reward total was 17.0. running mean: 12.867451403927843\n",
      "resetting env. episode reward total was 13.0. running mean: 12.868776889888565\n",
      "resetting env. episode reward total was 10.0. running mean: 12.84008912098968\n",
      "resetting env. episode reward total was 10.0. running mean: 12.811688229779783\n",
      "resetting env. episode reward total was 12.0. running mean: 12.803571347481984\n",
      "resetting env. episode reward total was 14.0. running mean: 12.815535634007166\n",
      "resetting env. episode reward total was 11.0. running mean: 12.797380277667093\n",
      "resetting env. episode reward total was 9.0. running mean: 12.759406474890422\n",
      "resetting env. episode reward total was 10.0. running mean: 12.731812410141517\n",
      "resetting env. episode reward total was 13.0. running mean: 12.734494286040102\n",
      "resetting env. episode reward total was 12.0. running mean: 12.7271493431797\n",
      "resetting env. episode reward total was 18.0. running mean: 12.779877849747903\n",
      "resetting env. episode reward total was 18.0. running mean: 12.832079071250424\n",
      "resetting env. episode reward total was 17.0. running mean: 12.87375828053792\n",
      "resetting env. episode reward total was 13.0. running mean: 12.875020697732541\n",
      "resetting env. episode reward total was 14.0. running mean: 12.886270490755216\n",
      "resetting env. episode reward total was 13.0. running mean: 12.887407785847664\n",
      "resetting env. episode reward total was 7.0. running mean: 12.828533707989187\n",
      "resetting env. episode reward total was 12.0. running mean: 12.820248370909294\n",
      "resetting env. episode reward total was 10.0. running mean: 12.792045887200201\n",
      "resetting env. episode reward total was 11.0. running mean: 12.7741254283282\n",
      "resetting env. episode reward total was 12.0. running mean: 12.766384174044916\n",
      "resetting env. episode reward total was 5.0. running mean: 12.688720332304467\n",
      "resetting env. episode reward total was 14.0. running mean: 12.701833128981422\n",
      "resetting env. episode reward total was 15.0. running mean: 12.724814797691607\n",
      "resetting env. episode reward total was 17.0. running mean: 12.767566649714691\n",
      "resetting env. episode reward total was 13.0. running mean: 12.769890983217545\n",
      "resetting env. episode reward total was 12.0. running mean: 12.762192073385368\n",
      "resetting env. episode reward total was 13.0. running mean: 12.764570152651515\n",
      "resetting env. episode reward total was 5.0. running mean: 12.686924451125002\n",
      "resetting env. episode reward total was 14.0. running mean: 12.700055206613753\n",
      "resetting env. episode reward total was 11.0. running mean: 12.683054654547615\n",
      "resetting env. episode reward total was 12.0. running mean: 12.676224108002138\n",
      "resetting env. episode reward total was 18.0. running mean: 12.729461866922117\n",
      "resetting env. episode reward total was 6.0. running mean: 12.662167248252896\n",
      "resetting env. episode reward total was 7.0. running mean: 12.605545575770368\n",
      "resetting env. episode reward total was 16.0. running mean: 12.639490120012663\n",
      "resetting env. episode reward total was 16.0. running mean: 12.673095218812536\n",
      "resetting env. episode reward total was 11.0. running mean: 12.65636426662441\n",
      "resetting env. episode reward total was 17.0. running mean: 12.699800623958165\n",
      "resetting env. episode reward total was 14.0. running mean: 12.712802617718584\n",
      "resetting env. episode reward total was 17.0. running mean: 12.755674591541398\n",
      "resetting env. episode reward total was 12.0. running mean: 12.748117845625984\n",
      "resetting env. episode reward total was 17.0. running mean: 12.790636667169723\n",
      "resetting env. episode reward total was 10.0. running mean: 12.762730300498026\n",
      "resetting env. episode reward total was 15.0. running mean: 12.785102997493047\n",
      "resetting env. episode reward total was 10.0. running mean: 12.757251967518116\n",
      "resetting env. episode reward total was 16.0. running mean: 12.789679447842934\n",
      "resetting env. episode reward total was 13.0. running mean: 12.791782653364505\n",
      "resetting env. episode reward total was 12.0. running mean: 12.78386482683086\n",
      "resetting env. episode reward total was 13.0. running mean: 12.786026178562551\n",
      "resetting env. episode reward total was 7.0. running mean: 12.728165916776925\n",
      "resetting env. episode reward total was 16.0. running mean: 12.760884257609156\n",
      "resetting env. episode reward total was 20.0. running mean: 12.833275415033064\n",
      "resetting env. episode reward total was 13.0. running mean: 12.834942660882735\n",
      "resetting env. episode reward total was 10.0. running mean: 12.806593234273906\n",
      "resetting env. episode reward total was 18.0. running mean: 12.858527301931167\n",
      "resetting env. episode reward total was 14.0. running mean: 12.869942028911856\n",
      "resetting env. episode reward total was 13.0. running mean: 12.871242608622739\n",
      "resetting env. episode reward total was 8.0. running mean: 12.82253018253651\n",
      "resetting env. episode reward total was 17.0. running mean: 12.864304880711146\n",
      "resetting env. episode reward total was 14.0. running mean: 12.875661831904035\n",
      "resetting env. episode reward total was 15.0. running mean: 12.896905213584995\n",
      "resetting env. episode reward total was 17.0. running mean: 12.937936161449144\n",
      "resetting env. episode reward total was 16.0. running mean: 12.968556799834653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 18.0. running mean: 13.018871231836306\n",
      "resetting env. episode reward total was 10.0. running mean: 12.988682519517942\n",
      "resetting env. episode reward total was 14.0. running mean: 12.998795694322764\n",
      "resetting env. episode reward total was 15.0. running mean: 13.018807737379536\n",
      "resetting env. episode reward total was 7.0. running mean: 12.958619660005741\n",
      "resetting env. episode reward total was 16.0. running mean: 12.989033463405685\n",
      "resetting env. episode reward total was 13.0. running mean: 12.989143128771628\n",
      "resetting env. episode reward total was 14.0. running mean: 12.999251697483913\n",
      "resetting env. episode reward total was 15.0. running mean: 13.019259180509074\n",
      "resetting env. episode reward total was 14.0. running mean: 13.029066588703984\n",
      "resetting env. episode reward total was 16.0. running mean: 13.058775922816944\n",
      "resetting env. episode reward total was 9.0. running mean: 13.018188163588773\n",
      "resetting env. episode reward total was 17.0. running mean: 13.058006281952885\n",
      "resetting env. episode reward total was 7.0. running mean: 12.997426219133356\n",
      "resetting env. episode reward total was 15.0. running mean: 13.017451956942022\n",
      "resetting env. episode reward total was 9.0. running mean: 12.977277437372601\n",
      "resetting env. episode reward total was 16.0. running mean: 13.007504662998874\n",
      "resetting env. episode reward total was 14.0. running mean: 13.017429616368887\n",
      "resetting env. episode reward total was 6.0. running mean: 12.947255320205198\n",
      "resetting env. episode reward total was 11.0. running mean: 12.927782767003144\n",
      "resetting env. episode reward total was 17.0. running mean: 12.968504939333112\n",
      "resetting env. episode reward total was 12.0. running mean: 12.95881988993978\n",
      "resetting env. episode reward total was 9.0. running mean: 12.919231691040382\n",
      "resetting env. episode reward total was 14.0. running mean: 12.93003937412998\n",
      "resetting env. episode reward total was 11.0. running mean: 12.910738980388679\n",
      "resetting env. episode reward total was 13.0. running mean: 12.911631590584793\n",
      "resetting env. episode reward total was 10.0. running mean: 12.882515274678944\n",
      "resetting env. episode reward total was 15.0. running mean: 12.903690121932154\n",
      "resetting env. episode reward total was 17.0. running mean: 12.944653220712832\n",
      "resetting env. episode reward total was 16.0. running mean: 12.975206688505704\n",
      "resetting env. episode reward total was 15.0. running mean: 12.995454621620647\n",
      "resetting env. episode reward total was 16.0. running mean: 13.025500075404441\n",
      "resetting env. episode reward total was 17.0. running mean: 13.065245074650397\n",
      "resetting env. episode reward total was 14.0. running mean: 13.074592623903893\n",
      "resetting env. episode reward total was 13.0. running mean: 13.073846697664855\n",
      "resetting env. episode reward total was 15.0. running mean: 13.093108230688207\n",
      "resetting env. episode reward total was 14.0. running mean: 13.102177148381326\n",
      "resetting env. episode reward total was 10.0. running mean: 13.071155376897512\n",
      "resetting env. episode reward total was 7.0. running mean: 13.010443823128536\n",
      "resetting env. episode reward total was 11.0. running mean: 12.99033938489725\n",
      "resetting env. episode reward total was 14.0. running mean: 13.00043599104828\n",
      "resetting env. episode reward total was 15.0. running mean: 13.020431631137797\n",
      "resetting env. episode reward total was -7.0. running mean: 12.820227314826418\n",
      "resetting env. episode reward total was 10.0. running mean: 12.792025041678153\n",
      "resetting env. episode reward total was 9.0. running mean: 12.754104791261371\n",
      "resetting env. episode reward total was 12.0. running mean: 12.746563743348757\n",
      "resetting env. episode reward total was 4.0. running mean: 12.659098105915268\n",
      "resetting env. episode reward total was 20.0. running mean: 12.732507124856115\n",
      "resetting env. episode reward total was 11.0. running mean: 12.715182053607553\n",
      "resetting env. episode reward total was 11.0. running mean: 12.698030233071476\n",
      "resetting env. episode reward total was 12.0. running mean: 12.69104993074076\n",
      "resetting env. episode reward total was 15.0. running mean: 12.714139431433352\n",
      "resetting env. episode reward total was 16.0. running mean: 12.746998037119019\n",
      "resetting env. episode reward total was 14.0. running mean: 12.759528056747829\n",
      "resetting env. episode reward total was 19.0. running mean: 12.82193277618035\n",
      "resetting env. episode reward total was 14.0. running mean: 12.833713448418548\n",
      "resetting env. episode reward total was 16.0. running mean: 12.865376313934362\n",
      "resetting env. episode reward total was 12.0. running mean: 12.856722550795018\n",
      "resetting env. episode reward total was 10.0. running mean: 12.828155325287067\n",
      "resetting env. episode reward total was 16.0. running mean: 12.859873772034197\n",
      "resetting env. episode reward total was 16.0. running mean: 12.891275034313855\n",
      "resetting env. episode reward total was 10.0. running mean: 12.862362283970716\n",
      "resetting env. episode reward total was 15.0. running mean: 12.883738661131009\n",
      "resetting env. episode reward total was 15.0. running mean: 12.904901274519698\n",
      "resetting env. episode reward total was 16.0. running mean: 12.935852261774501\n",
      "resetting env. episode reward total was 10.0. running mean: 12.906493739156756\n",
      "resetting env. episode reward total was 17.0. running mean: 12.947428801765188\n",
      "resetting env. episode reward total was 10.0. running mean: 12.917954513747535\n",
      "resetting env. episode reward total was 8.0. running mean: 12.86877496861006\n",
      "resetting env. episode reward total was 14.0. running mean: 12.88008721892396\n",
      "resetting env. episode reward total was 12.0. running mean: 12.871286346734719\n",
      "resetting env. episode reward total was 10.0. running mean: 12.84257348326737\n",
      "resetting env. episode reward total was 17.0. running mean: 12.884147748434698\n",
      "resetting env. episode reward total was 12.0. running mean: 12.87530627095035\n",
      "resetting env. episode reward total was 12.0. running mean: 12.866553208240846\n",
      "resetting env. episode reward total was 14.0. running mean: 12.877887676158439\n",
      "resetting env. episode reward total was 15.0. running mean: 12.899108799396855\n",
      "resetting env. episode reward total was 13.0. running mean: 12.900117711402887\n",
      "resetting env. episode reward total was 13.0. running mean: 12.901116534288859\n",
      "resetting env. episode reward total was 8.0. running mean: 12.85210536894597\n",
      "resetting env. episode reward total was 13.0. running mean: 12.853584315256512\n",
      "resetting env. episode reward total was 15.0. running mean: 12.875048472103947\n",
      "resetting env. episode reward total was 11.0. running mean: 12.856297987382906\n",
      "resetting env. episode reward total was 14.0. running mean: 12.867735007509078\n",
      "resetting env. episode reward total was 16.0. running mean: 12.899057657433987\n",
      "resetting env. episode reward total was 18.0. running mean: 12.950067080859647\n",
      "resetting env. episode reward total was 12.0. running mean: 12.94056641005105\n",
      "resetting env. episode reward total was 13.0. running mean: 12.94116074595054\n",
      "resetting env. episode reward total was 14.0. running mean: 12.951749138491035\n",
      "resetting env. episode reward total was 15.0. running mean: 12.972231647106124\n",
      "resetting env. episode reward total was 11.0. running mean: 12.952509330635062\n",
      "resetting env. episode reward total was 16.0. running mean: 12.982984237328711\n",
      "resetting env. episode reward total was 10.0. running mean: 12.953154394955424\n",
      "resetting env. episode reward total was 18.0. running mean: 13.00362285100587\n",
      "resetting env. episode reward total was 13.0. running mean: 13.003586622495812\n",
      "resetting env. episode reward total was 17.0. running mean: 13.043550756270854\n",
      "resetting env. episode reward total was 16.0. running mean: 13.073115248708145\n",
      "resetting env. episode reward total was 13.0. running mean: 13.072384096221064\n",
      "resetting env. episode reward total was 12.0. running mean: 13.061660255258852\n",
      "resetting env. episode reward total was 14.0. running mean: 13.071043652706264\n",
      "resetting env. episode reward total was 7.0. running mean: 13.010333216179202\n",
      "resetting env. episode reward total was 12.0. running mean: 13.00022988401741\n",
      "resetting env. episode reward total was 11.0. running mean: 12.980227585177234\n",
      "resetting env. episode reward total was 14.0. running mean: 12.990425309325461\n",
      "resetting env. episode reward total was 9.0. running mean: 12.950521056232207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 12.961015845669886\n",
      "resetting env. episode reward total was 16.0. running mean: 12.991405687213186\n",
      "resetting env. episode reward total was 12.0. running mean: 12.981491630341054\n",
      "resetting env. episode reward total was 15.0. running mean: 13.001676714037643\n",
      "resetting env. episode reward total was 15.0. running mean: 13.021659946897266\n",
      "resetting env. episode reward total was 5.0. running mean: 12.941443347428294\n",
      "resetting env. episode reward total was 11.0. running mean: 12.92202891395401\n",
      "resetting env. episode reward total was 16.0. running mean: 12.95280862481447\n",
      "resetting env. episode reward total was 9.0. running mean: 12.913280538566324\n",
      "resetting env. episode reward total was 14.0. running mean: 12.92414773318066\n",
      "resetting env. episode reward total was 13.0. running mean: 12.924906255848855\n",
      "resetting env. episode reward total was 15.0. running mean: 12.945657193290367\n",
      "resetting env. episode reward total was 9.0. running mean: 12.906200621357463\n",
      "resetting env. episode reward total was 10.0. running mean: 12.877138615143888\n",
      "resetting env. episode reward total was 10.0. running mean: 12.84836722899245\n",
      "resetting env. episode reward total was 11.0. running mean: 12.829883556702525\n",
      "resetting env. episode reward total was 14.0. running mean: 12.8415847211355\n",
      "resetting env. episode reward total was 18.0. running mean: 12.893168873924145\n",
      "resetting env. episode reward total was 14.0. running mean: 12.904237185184904\n",
      "resetting env. episode reward total was 12.0. running mean: 12.895194813333054\n",
      "resetting env. episode reward total was 11.0. running mean: 12.876242865199723\n",
      "resetting env. episode reward total was 13.0. running mean: 12.877480436547726\n",
      "resetting env. episode reward total was 10.0. running mean: 12.848705632182249\n",
      "resetting env. episode reward total was 16.0. running mean: 12.880218575860425\n",
      "resetting env. episode reward total was 9.0. running mean: 12.84141639010182\n",
      "resetting env. episode reward total was 13.0. running mean: 12.843002226200802\n",
      "resetting env. episode reward total was 15.0. running mean: 12.864572203938794\n",
      "resetting env. episode reward total was 15.0. running mean: 12.885926481899405\n",
      "resetting env. episode reward total was 13.0. running mean: 12.887067217080412\n",
      "resetting env. episode reward total was 10.0. running mean: 12.858196544909609\n",
      "resetting env. episode reward total was 4.0. running mean: 12.769614579460512\n",
      "resetting env. episode reward total was 16.0. running mean: 12.801918433665907\n",
      "resetting env. episode reward total was 12.0. running mean: 12.793899249329247\n",
      "resetting env. episode reward total was 18.0. running mean: 12.845960256835953\n",
      "resetting env. episode reward total was 16.0. running mean: 12.877500654267594\n",
      "resetting env. episode reward total was 18.0. running mean: 12.928725647724917\n",
      "resetting env. episode reward total was 17.0. running mean: 12.969438391247667\n",
      "resetting env. episode reward total was 16.0. running mean: 12.99974400733519\n",
      "resetting env. episode reward total was 6.0. running mean: 12.929746567261839\n",
      "resetting env. episode reward total was 12.0. running mean: 12.92044910158922\n",
      "resetting env. episode reward total was 18.0. running mean: 12.971244610573327\n",
      "resetting env. episode reward total was 16.0. running mean: 13.001532164467594\n",
      "resetting env. episode reward total was 9.0. running mean: 12.961516842822919\n",
      "resetting env. episode reward total was 11.0. running mean: 12.941901674394689\n",
      "resetting env. episode reward total was 14.0. running mean: 12.952482657650743\n",
      "resetting env. episode reward total was 17.0. running mean: 12.992957831074236\n",
      "resetting env. episode reward total was 17.0. running mean: 13.033028252763494\n",
      "resetting env. episode reward total was 10.0. running mean: 13.002697970235857\n",
      "resetting env. episode reward total was 14.0. running mean: 13.012670990533499\n",
      "resetting env. episode reward total was 15.0. running mean: 13.032544280628164\n",
      "resetting env. episode reward total was 11.0. running mean: 13.012218837821882\n",
      "resetting env. episode reward total was 9.0. running mean: 12.972096649443662\n",
      "resetting env. episode reward total was 12.0. running mean: 12.962375682949224\n",
      "resetting env. episode reward total was 16.0. running mean: 12.992751926119732\n",
      "resetting env. episode reward total was 8.0. running mean: 12.942824406858534\n",
      "resetting env. episode reward total was 9.0. running mean: 12.90339616278995\n",
      "resetting env. episode reward total was 13.0. running mean: 12.904362201162051\n",
      "resetting env. episode reward total was 7.0. running mean: 12.845318579150431\n",
      "resetting env. episode reward total was 18.0. running mean: 12.896865393358926\n",
      "resetting env. episode reward total was 13.0. running mean: 12.897896739425338\n",
      "resetting env. episode reward total was 10.0. running mean: 12.868917772031084\n",
      "resetting env. episode reward total was 10.0. running mean: 12.840228594310773\n",
      "resetting env. episode reward total was 15.0. running mean: 12.861826308367664\n",
      "resetting env. episode reward total was 15.0. running mean: 12.883208045283988\n",
      "resetting env. episode reward total was 15.0. running mean: 12.904375964831148\n",
      "resetting env. episode reward total was 11.0. running mean: 12.885332205182836\n",
      "resetting env. episode reward total was 9.0. running mean: 12.846478883131008\n",
      "resetting env. episode reward total was 18.0. running mean: 12.898014094299697\n",
      "resetting env. episode reward total was 17.0. running mean: 12.9390339533567\n",
      "resetting env. episode reward total was 12.0. running mean: 12.929643613823133\n",
      "resetting env. episode reward total was 17.0. running mean: 12.970347177684902\n",
      "resetting env. episode reward total was 14.0. running mean: 12.980643705908053\n",
      "resetting env. episode reward total was 15.0. running mean: 13.000837268848972\n",
      "resetting env. episode reward total was 16.0. running mean: 13.030828896160482\n",
      "resetting env. episode reward total was 6.0. running mean: 12.960520607198879\n",
      "resetting env. episode reward total was 13.0. running mean: 12.96091540112689\n",
      "resetting env. episode reward total was 16.0. running mean: 12.99130624711562\n",
      "resetting env. episode reward total was 17.0. running mean: 13.031393184644465\n",
      "resetting env. episode reward total was 12.0. running mean: 13.02107925279802\n",
      "resetting env. episode reward total was 15.0. running mean: 13.040868460270039\n",
      "resetting env. episode reward total was 8.0. running mean: 12.990459775667338\n",
      "resetting env. episode reward total was 8.0. running mean: 12.940555177910664\n",
      "resetting env. episode reward total was 12.0. running mean: 12.931149626131557\n",
      "resetting env. episode reward total was 13.0. running mean: 12.931838129870242\n",
      "resetting env. episode reward total was 15.0. running mean: 12.95251974857154\n",
      "resetting env. episode reward total was 11.0. running mean: 12.932994551085823\n",
      "resetting env. episode reward total was 20.0. running mean: 13.003664605574963\n",
      "resetting env. episode reward total was 9.0. running mean: 12.963627959519213\n",
      "resetting env. episode reward total was 15.0. running mean: 12.98399167992402\n",
      "resetting env. episode reward total was 18.0. running mean: 13.03415176312478\n",
      "resetting env. episode reward total was 10.0. running mean: 13.003810245493533\n",
      "resetting env. episode reward total was 11.0. running mean: 12.983772143038596\n",
      "resetting env. episode reward total was 17.0. running mean: 13.02393442160821\n",
      "resetting env. episode reward total was 8.0. running mean: 12.973695077392128\n",
      "resetting env. episode reward total was 16.0. running mean: 13.003958126618206\n",
      "resetting env. episode reward total was 18.0. running mean: 13.053918545352024\n",
      "resetting env. episode reward total was 15.0. running mean: 13.073379359898505\n",
      "resetting env. episode reward total was 15.0. running mean: 13.09264556629952\n",
      "resetting env. episode reward total was 9.0. running mean: 13.051719110636524\n",
      "resetting env. episode reward total was 16.0. running mean: 13.081201919530159\n",
      "resetting env. episode reward total was 10.0. running mean: 13.050389900334856\n",
      "resetting env. episode reward total was 11.0. running mean: 13.029886001331507\n",
      "resetting env. episode reward total was 5.0. running mean: 12.949587141318192\n",
      "resetting env. episode reward total was 9.0. running mean: 12.91009126990501\n",
      "resetting env. episode reward total was 16.0. running mean: 12.94099035720596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 12.961580453633902\n",
      "resetting env. episode reward total was 11.0. running mean: 12.941964649097562\n",
      "resetting env. episode reward total was 12.0. running mean: 12.932545002606586\n",
      "resetting env. episode reward total was 11.0. running mean: 12.91321955258052\n",
      "resetting env. episode reward total was 13.0. running mean: 12.914087357054715\n",
      "resetting env. episode reward total was 13.0. running mean: 12.914946483484169\n",
      "resetting env. episode reward total was 18.0. running mean: 12.965797018649326\n",
      "resetting env. episode reward total was 16.0. running mean: 12.996139048462833\n",
      "resetting env. episode reward total was 17.0. running mean: 13.036177657978204\n",
      "resetting env. episode reward total was 13.0. running mean: 13.035815881398422\n",
      "resetting env. episode reward total was 15.0. running mean: 13.055457722584439\n",
      "resetting env. episode reward total was 12.0. running mean: 13.044903145358594\n",
      "resetting env. episode reward total was 16.0. running mean: 13.074454113905007\n",
      "resetting env. episode reward total was 11.0. running mean: 13.053709572765957\n",
      "resetting env. episode reward total was 8.0. running mean: 13.003172477038298\n",
      "resetting env. episode reward total was 14.0. running mean: 13.013140752267915\n",
      "resetting env. episode reward total was 11.0. running mean: 12.993009344745236\n",
      "resetting env. episode reward total was 9.0. running mean: 12.953079251297783\n",
      "resetting env. episode reward total was 12.0. running mean: 12.943548458784804\n",
      "resetting env. episode reward total was 5.0. running mean: 12.864112974196956\n",
      "resetting env. episode reward total was 10.0. running mean: 12.835471844454986\n",
      "resetting env. episode reward total was 14.0. running mean: 12.847117126010437\n",
      "resetting env. episode reward total was 17.0. running mean: 12.888645954750332\n",
      "resetting env. episode reward total was 7.0. running mean: 12.829759495202829\n",
      "resetting env. episode reward total was 11.0. running mean: 12.8114619002508\n",
      "resetting env. episode reward total was 8.0. running mean: 12.763347281248292\n",
      "resetting env. episode reward total was 7.0. running mean: 12.705713808435808\n",
      "resetting env. episode reward total was 12.0. running mean: 12.698656670351449\n",
      "resetting env. episode reward total was 18.0. running mean: 12.751670103647934\n",
      "resetting env. episode reward total was 11.0. running mean: 12.734153402611454\n",
      "resetting env. episode reward total was 10.0. running mean: 12.706811868585339\n",
      "resetting env. episode reward total was 14.0. running mean: 12.719743749899486\n",
      "resetting env. episode reward total was 19.0. running mean: 12.782546312400491\n",
      "resetting env. episode reward total was 8.0. running mean: 12.734720849276487\n",
      "resetting env. episode reward total was 17.0. running mean: 12.777373640783722\n",
      "resetting env. episode reward total was 15.0. running mean: 12.799599904375885\n",
      "resetting env. episode reward total was 11.0. running mean: 12.781603905332126\n",
      "resetting env. episode reward total was 11.0. running mean: 12.763787866278804\n",
      "resetting env. episode reward total was 7.0. running mean: 12.706149987616016\n",
      "resetting env. episode reward total was 14.0. running mean: 12.719088487739857\n",
      "resetting env. episode reward total was 13.0. running mean: 12.721897602862459\n",
      "resetting env. episode reward total was 8.0. running mean: 12.674678626833835\n",
      "resetting env. episode reward total was 15.0. running mean: 12.697931840565497\n",
      "resetting env. episode reward total was 15.0. running mean: 12.720952522159843\n",
      "resetting env. episode reward total was 14.0. running mean: 12.733742996938245\n",
      "resetting env. episode reward total was 14.0. running mean: 12.746405566968864\n",
      "resetting env. episode reward total was 10.0. running mean: 12.718941511299175\n",
      "resetting env. episode reward total was 12.0. running mean: 12.711752096186181\n",
      "resetting env. episode reward total was 14.0. running mean: 12.72463457522432\n",
      "resetting env. episode reward total was 14.0. running mean: 12.737388229472076\n",
      "resetting env. episode reward total was 9.0. running mean: 12.700014347177355\n",
      "resetting env. episode reward total was 15.0. running mean: 12.723014203705581\n",
      "resetting env. episode reward total was 19.0. running mean: 12.785784061668524\n",
      "resetting env. episode reward total was 15.0. running mean: 12.807926221051838\n",
      "resetting env. episode reward total was 11.0. running mean: 12.78984695884132\n",
      "resetting env. episode reward total was 10.0. running mean: 12.761948489252907\n",
      "resetting env. episode reward total was 10.0. running mean: 12.734329004360378\n",
      "resetting env. episode reward total was 14.0. running mean: 12.746985714316775\n",
      "resetting env. episode reward total was 14.0. running mean: 12.759515857173607\n",
      "resetting env. episode reward total was 17.0. running mean: 12.80192069860187\n",
      "resetting env. episode reward total was 6.0. running mean: 12.733901491615851\n",
      "resetting env. episode reward total was 7.0. running mean: 12.676562476699694\n",
      "resetting env. episode reward total was 13.0. running mean: 12.679796851932696\n",
      "resetting env. episode reward total was 14.0. running mean: 12.69299888341337\n",
      "resetting env. episode reward total was 17.0. running mean: 12.736068894579237\n",
      "resetting env. episode reward total was 9.0. running mean: 12.698708205633444\n",
      "resetting env. episode reward total was 16.0. running mean: 12.73172112357711\n",
      "resetting env. episode reward total was 9.0. running mean: 12.694403912341338\n",
      "resetting env. episode reward total was 14.0. running mean: 12.707459873217925\n",
      "resetting env. episode reward total was 13.0. running mean: 12.710385274485747\n",
      "resetting env. episode reward total was 16.0. running mean: 12.743281421740889\n",
      "resetting env. episode reward total was 15.0. running mean: 12.76584860752348\n",
      "resetting env. episode reward total was 15.0. running mean: 12.788190121448245\n",
      "resetting env. episode reward total was 17.0. running mean: 12.830308220233762\n",
      "resetting env. episode reward total was 13.0. running mean: 12.832005138031425\n",
      "resetting env. episode reward total was 15.0. running mean: 12.853685086651112\n",
      "resetting env. episode reward total was 10.0. running mean: 12.8251482357846\n",
      "resetting env. episode reward total was 11.0. running mean: 12.806896753426752\n",
      "resetting env. episode reward total was 12.0. running mean: 12.798827785892485\n",
      "resetting env. episode reward total was 17.0. running mean: 12.84083950803356\n",
      "resetting env. episode reward total was 13.0. running mean: 12.842431112953225\n",
      "resetting env. episode reward total was 10.0. running mean: 12.814006801823693\n",
      "resetting env. episode reward total was 17.0. running mean: 12.855866733805456\n",
      "resetting env. episode reward total was 13.0. running mean: 12.857308066467402\n",
      "resetting env. episode reward total was 14.0. running mean: 12.868734985802728\n",
      "resetting env. episode reward total was 9.0. running mean: 12.8300476359447\n",
      "resetting env. episode reward total was 9.0. running mean: 12.791747159585253\n",
      "resetting env. episode reward total was -1.0. running mean: 12.6538296879894\n",
      "resetting env. episode reward total was 14.0. running mean: 12.667291391109506\n",
      "resetting env. episode reward total was 14.0. running mean: 12.680618477198411\n",
      "resetting env. episode reward total was 14.0. running mean: 12.693812292426427\n",
      "resetting env. episode reward total was 12.0. running mean: 12.686874169502163\n",
      "resetting env. episode reward total was 11.0. running mean: 12.67000542780714\n",
      "resetting env. episode reward total was 14.0. running mean: 12.68330537352907\n",
      "resetting env. episode reward total was 11.0. running mean: 12.666472319793778\n",
      "resetting env. episode reward total was 14.0. running mean: 12.67980759659584\n",
      "resetting env. episode reward total was 8.0. running mean: 12.633009520629882\n",
      "resetting env. episode reward total was 10.0. running mean: 12.606679425423582\n",
      "resetting env. episode reward total was 12.0. running mean: 12.600612631169346\n",
      "resetting env. episode reward total was 13.0. running mean: 12.604606504857653\n",
      "resetting env. episode reward total was 7.0. running mean: 12.548560439809076\n",
      "resetting env. episode reward total was 14.0. running mean: 12.563074835410987\n",
      "resetting env. episode reward total was 13.0. running mean: 12.567444087056877\n",
      "resetting env. episode reward total was 19.0. running mean: 12.631769646186308\n",
      "resetting env. episode reward total was 15.0. running mean: 12.655451949724446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 18.0. running mean: 12.708897430227202\n",
      "resetting env. episode reward total was 12.0. running mean: 12.70180845592493\n",
      "resetting env. episode reward total was 17.0. running mean: 12.74479037136568\n",
      "resetting env. episode reward total was 17.0. running mean: 12.787342467652023\n",
      "resetting env. episode reward total was 12.0. running mean: 12.779469042975501\n",
      "resetting env. episode reward total was 13.0. running mean: 12.781674352545746\n",
      "resetting env. episode reward total was 14.0. running mean: 12.79385760902029\n",
      "resetting env. episode reward total was 15.0. running mean: 12.815919032930086\n",
      "resetting env. episode reward total was 9.0. running mean: 12.777759842600785\n",
      "resetting env. episode reward total was 13.0. running mean: 12.779982244174779\n",
      "resetting env. episode reward total was 14.0. running mean: 12.792182421733031\n",
      "resetting env. episode reward total was 16.0. running mean: 12.824260597515702\n",
      "resetting env. episode reward total was 13.0. running mean: 12.826017991540546\n",
      "resetting env. episode reward total was 13.0. running mean: 12.82775781162514\n",
      "resetting env. episode reward total was 12.0. running mean: 12.819480233508887\n",
      "resetting env. episode reward total was 13.0. running mean: 12.821285431173798\n",
      "resetting env. episode reward total was 16.0. running mean: 12.853072576862061\n",
      "resetting env. episode reward total was 8.0. running mean: 12.804541851093441\n",
      "resetting env. episode reward total was 13.0. running mean: 12.806496432582508\n",
      "resetting env. episode reward total was 13.0. running mean: 12.808431468256684\n",
      "resetting env. episode reward total was 17.0. running mean: 12.850347153574116\n",
      "resetting env. episode reward total was 12.0. running mean: 12.841843682038375\n",
      "resetting env. episode reward total was 14.0. running mean: 12.853425245217991\n",
      "resetting env. episode reward total was 9.0. running mean: 12.814890992765811\n",
      "resetting env. episode reward total was 1.0. running mean: 12.696742082838153\n",
      "resetting env. episode reward total was 12.0. running mean: 12.68977466200977\n",
      "resetting env. episode reward total was 15.0. running mean: 12.712876915389671\n",
      "resetting env. episode reward total was 16.0. running mean: 12.745748146235774\n",
      "resetting env. episode reward total was 12.0. running mean: 12.738290664773416\n",
      "resetting env. episode reward total was 9.0. running mean: 12.700907758125682\n",
      "resetting env. episode reward total was 16.0. running mean: 12.733898680544426\n",
      "resetting env. episode reward total was 13.0. running mean: 12.736559693738982\n",
      "resetting env. episode reward total was 14.0. running mean: 12.749194096801594\n",
      "resetting env. episode reward total was 9.0. running mean: 12.711702155833578\n",
      "resetting env. episode reward total was 17.0. running mean: 12.754585134275242\n",
      "resetting env. episode reward total was 14.0. running mean: 12.76703928293249\n",
      "resetting env. episode reward total was 12.0. running mean: 12.759368890103165\n",
      "resetting env. episode reward total was 14.0. running mean: 12.771775201202134\n",
      "resetting env. episode reward total was 10.0. running mean: 12.744057449190112\n",
      "resetting env. episode reward total was 15.0. running mean: 12.766616874698212\n",
      "resetting env. episode reward total was 14.0. running mean: 12.77895070595123\n",
      "resetting env. episode reward total was 16.0. running mean: 12.811161198891718\n",
      "resetting env. episode reward total was 17.0. running mean: 12.8530495869028\n",
      "resetting env. episode reward total was 11.0. running mean: 12.834519091033771\n",
      "resetting env. episode reward total was 12.0. running mean: 12.826173900123433\n",
      "resetting env. episode reward total was 9.0. running mean: 12.787912161122199\n",
      "resetting env. episode reward total was 15.0. running mean: 12.810033039510976\n",
      "resetting env. episode reward total was 17.0. running mean: 12.851932709115866\n",
      "resetting env. episode reward total was 15.0. running mean: 12.873413382024708\n",
      "resetting env. episode reward total was 13.0. running mean: 12.874679248204462\n",
      "resetting env. episode reward total was 3.0. running mean: 12.775932455722417\n",
      "resetting env. episode reward total was 15.0. running mean: 12.798173131165193\n",
      "resetting env. episode reward total was 16.0. running mean: 12.830191399853542\n",
      "resetting env. episode reward total was 12.0. running mean: 12.821889485855005\n",
      "resetting env. episode reward total was 15.0. running mean: 12.843670590996455\n",
      "resetting env. episode reward total was 17.0. running mean: 12.88523388508649\n",
      "resetting env. episode reward total was 15.0. running mean: 12.906381546235625\n",
      "resetting env. episode reward total was 17.0. running mean: 12.94731773077327\n",
      "resetting env. episode reward total was 12.0. running mean: 12.937844553465537\n",
      "resetting env. episode reward total was 10.0. running mean: 12.908466107930881\n",
      "resetting env. episode reward total was 14.0. running mean: 12.919381446851572\n",
      "resetting env. episode reward total was 20.0. running mean: 12.990187632383055\n",
      "resetting env. episode reward total was 15.0. running mean: 13.010285756059224\n",
      "resetting env. episode reward total was 13.0. running mean: 13.010182898498632\n",
      "resetting env. episode reward total was 12.0. running mean: 13.000081069513644\n",
      "resetting env. episode reward total was 11.0. running mean: 12.980080258818507\n",
      "resetting env. episode reward total was 12.0. running mean: 12.97027945623032\n",
      "resetting env. episode reward total was 15.0. running mean: 12.990576661668017\n",
      "resetting env. episode reward total was 18.0. running mean: 13.040670895051337\n",
      "resetting env. episode reward total was 9.0. running mean: 13.000264186100823\n",
      "resetting env. episode reward total was 14.0. running mean: 13.010261544239816\n",
      "resetting env. episode reward total was 11.0. running mean: 12.990158928797417\n",
      "resetting env. episode reward total was 13.0. running mean: 12.990257339509443\n",
      "resetting env. episode reward total was 11.0. running mean: 12.970354766114347\n",
      "resetting env. episode reward total was 15.0. running mean: 12.990651218453204\n",
      "resetting env. episode reward total was 12.0. running mean: 12.980744706268672\n",
      "resetting env. episode reward total was 17.0. running mean: 13.020937259205985\n",
      "resetting env. episode reward total was 16.0. running mean: 13.050727886613926\n",
      "resetting env. episode reward total was 17.0. running mean: 13.090220607747787\n",
      "resetting env. episode reward total was 13.0. running mean: 13.08931840167031\n",
      "resetting env. episode reward total was 15.0. running mean: 13.108425217653608\n",
      "resetting env. episode reward total was 13.0. running mean: 13.107340965477071\n",
      "resetting env. episode reward total was 15.0. running mean: 13.1262675558223\n",
      "resetting env. episode reward total was 4.0. running mean: 13.035004880264077\n",
      "resetting env. episode reward total was 12.0. running mean: 13.024654831461437\n",
      "resetting env. episode reward total was 16.0. running mean: 13.054408283146822\n",
      "resetting env. episode reward total was 15.0. running mean: 13.073864200315354\n",
      "resetting env. episode reward total was 17.0. running mean: 13.1131255583122\n",
      "resetting env. episode reward total was 21.0. running mean: 13.191994302729078\n",
      "resetting env. episode reward total was 10.0. running mean: 13.160074359701786\n",
      "resetting env. episode reward total was 10.0. running mean: 13.128473616104769\n",
      "resetting env. episode reward total was 17.0. running mean: 13.167188879943721\n",
      "resetting env. episode reward total was 12.0. running mean: 13.155516991144284\n",
      "resetting env. episode reward total was 16.0. running mean: 13.18396182123284\n",
      "resetting env. episode reward total was 13.0. running mean: 13.182122203020512\n",
      "resetting env. episode reward total was 16.0. running mean: 13.210300980990308\n",
      "resetting env. episode reward total was 12.0. running mean: 13.198197971180404\n",
      "resetting env. episode reward total was 16.0. running mean: 13.2262159914686\n",
      "resetting env. episode reward total was 11.0. running mean: 13.203953831553912\n",
      "resetting env. episode reward total was 13.0. running mean: 13.201914293238374\n",
      "resetting env. episode reward total was 15.0. running mean: 13.219895150305991\n",
      "resetting env. episode reward total was 16.0. running mean: 13.247696198802931\n",
      "resetting env. episode reward total was 19.0. running mean: 13.305219236814901\n",
      "resetting env. episode reward total was 16.0. running mean: 13.332167044446752\n",
      "resetting env. episode reward total was 13.0. running mean: 13.328845374002285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 13.345556920262261\n",
      "resetting env. episode reward total was 10.0. running mean: 13.312101351059638\n",
      "resetting env. episode reward total was 13.0. running mean: 13.308980337549043\n",
      "resetting env. episode reward total was 11.0. running mean: 13.285890534173552\n",
      "resetting env. episode reward total was 13.0. running mean: 13.283031628831816\n",
      "resetting env. episode reward total was 18.0. running mean: 13.330201312543497\n",
      "resetting env. episode reward total was 13.0. running mean: 13.326899299418063\n",
      "resetting env. episode reward total was 12.0. running mean: 13.313630306423882\n",
      "resetting env. episode reward total was 6.0. running mean: 13.240494003359643\n",
      "resetting env. episode reward total was 17.0. running mean: 13.278089063326046\n",
      "resetting env. episode reward total was 19.0. running mean: 13.335308172692786\n",
      "resetting env. episode reward total was 12.0. running mean: 13.321955090965856\n",
      "resetting env. episode reward total was 15.0. running mean: 13.338735540056199\n",
      "resetting env. episode reward total was 11.0. running mean: 13.315348184655637\n",
      "resetting env. episode reward total was 17.0. running mean: 13.352194702809081\n",
      "resetting env. episode reward total was 8.0. running mean: 13.29867275578099\n",
      "resetting env. episode reward total was 17.0. running mean: 13.33568602822318\n",
      "resetting env. episode reward total was 12.0. running mean: 13.322329167940946\n",
      "resetting env. episode reward total was 17.0. running mean: 13.359105876261538\n",
      "resetting env. episode reward total was 15.0. running mean: 13.375514817498923\n",
      "resetting env. episode reward total was 11.0. running mean: 13.351759669323933\n",
      "resetting env. episode reward total was 7.0. running mean: 13.288242072630693\n",
      "resetting env. episode reward total was 15.0. running mean: 13.305359651904386\n",
      "resetting env. episode reward total was 15.0. running mean: 13.322306055385342\n",
      "resetting env. episode reward total was 13.0. running mean: 13.31908299483149\n",
      "resetting env. episode reward total was 8.0. running mean: 13.265892164883175\n",
      "resetting env. episode reward total was 13.0. running mean: 13.263233243234344\n",
      "resetting env. episode reward total was 10.0. running mean: 13.230600910802\n",
      "resetting env. episode reward total was 17.0. running mean: 13.268294901693979\n",
      "resetting env. episode reward total was 13.0. running mean: 13.26561195267704\n",
      "resetting env. episode reward total was 12.0. running mean: 13.252955833150269\n",
      "resetting env. episode reward total was 12.0. running mean: 13.240426274818764\n",
      "resetting env. episode reward total was 20.0. running mean: 13.308022012070577\n",
      "resetting env. episode reward total was 14.0. running mean: 13.314941791949872\n",
      "resetting env. episode reward total was 13.0. running mean: 13.311792374030373\n",
      "resetting env. episode reward total was 15.0. running mean: 13.32867445029007\n",
      "resetting env. episode reward total was 19.0. running mean: 13.385387705787169\n",
      "resetting env. episode reward total was 9.0. running mean: 13.341533828729297\n",
      "resetting env. episode reward total was 15.0. running mean: 13.358118490442005\n",
      "resetting env. episode reward total was 4.0. running mean: 13.264537305537583\n",
      "resetting env. episode reward total was 15.0. running mean: 13.281891932482209\n",
      "resetting env. episode reward total was 16.0. running mean: 13.309073013157386\n",
      "resetting env. episode reward total was 16.0. running mean: 13.335982283025812\n",
      "resetting env. episode reward total was 12.0. running mean: 13.322622460195554\n",
      "resetting env. episode reward total was 10.0. running mean: 13.289396235593598\n",
      "resetting env. episode reward total was 14.0. running mean: 13.296502273237662\n",
      "resetting env. episode reward total was 11.0. running mean: 13.273537250505285\n",
      "resetting env. episode reward total was 15.0. running mean: 13.290801878000233\n",
      "resetting env. episode reward total was 14.0. running mean: 13.297893859220231\n",
      "resetting env. episode reward total was 6.0. running mean: 13.224914920628029\n",
      "resetting env. episode reward total was 17.0. running mean: 13.262665771421748\n",
      "resetting env. episode reward total was 7.0. running mean: 13.20003911370753\n",
      "resetting env. episode reward total was 3.0. running mean: 13.098038722570454\n",
      "resetting env. episode reward total was 10.0. running mean: 13.067058335344749\n",
      "resetting env. episode reward total was 14.0. running mean: 13.076387751991302\n",
      "resetting env. episode reward total was 17.0. running mean: 13.115623874471389\n",
      "resetting env. episode reward total was 19.0. running mean: 13.174467635726675\n",
      "resetting env. episode reward total was 17.0. running mean: 13.212722959369408\n",
      "resetting env. episode reward total was 15.0. running mean: 13.230595729775715\n",
      "resetting env. episode reward total was 15.0. running mean: 13.248289772477957\n",
      "resetting env. episode reward total was 14.0. running mean: 13.255806874753178\n",
      "resetting env. episode reward total was 14.0. running mean: 13.263248806005647\n",
      "resetting env. episode reward total was 12.0. running mean: 13.250616317945589\n",
      "resetting env. episode reward total was 17.0. running mean: 13.288110154766132\n",
      "resetting env. episode reward total was 17.0. running mean: 13.32522905321847\n",
      "resetting env. episode reward total was 15.0. running mean: 13.341976762686285\n",
      "resetting env. episode reward total was 14.0. running mean: 13.348556995059422\n",
      "resetting env. episode reward total was 20.0. running mean: 13.415071425108827\n",
      "resetting env. episode reward total was 9.0. running mean: 13.370920710857739\n",
      "resetting env. episode reward total was 12.0. running mean: 13.357211503749161\n",
      "resetting env. episode reward total was 18.0. running mean: 13.40363938871167\n",
      "resetting env. episode reward total was 13.0. running mean: 13.399602994824553\n",
      "resetting env. episode reward total was 13.0. running mean: 13.395606964876308\n",
      "resetting env. episode reward total was 14.0. running mean: 13.401650895227545\n",
      "resetting env. episode reward total was 13.0. running mean: 13.397634386275271\n",
      "resetting env. episode reward total was 16.0. running mean: 13.42365804241252\n",
      "resetting env. episode reward total was 12.0. running mean: 13.409421461988392\n",
      "resetting env. episode reward total was 13.0. running mean: 13.40532724736851\n",
      "resetting env. episode reward total was 15.0. running mean: 13.421273974894824\n",
      "resetting env. episode reward total was 8.0. running mean: 13.367061235145876\n",
      "resetting env. episode reward total was 10.0. running mean: 13.333390622794417\n",
      "resetting env. episode reward total was 13.0. running mean: 13.330056716566473\n",
      "resetting env. episode reward total was 4.0. running mean: 13.236756149400808\n",
      "resetting env. episode reward total was 11.0. running mean: 13.214388587906798\n",
      "resetting env. episode reward total was 10.0. running mean: 13.18224470202773\n",
      "resetting env. episode reward total was 11.0. running mean: 13.16042225500745\n",
      "resetting env. episode reward total was 11.0. running mean: 13.138818032457376\n",
      "resetting env. episode reward total was 18.0. running mean: 13.187429852132801\n",
      "resetting env. episode reward total was 18.0. running mean: 13.235555553611473\n",
      "resetting env. episode reward total was 15.0. running mean: 13.253199998075358\n",
      "resetting env. episode reward total was 9.0. running mean: 13.210667998094603\n",
      "resetting env. episode reward total was 13.0. running mean: 13.208561318113658\n",
      "resetting env. episode reward total was 15.0. running mean: 13.226475704932522\n",
      "resetting env. episode reward total was 10.0. running mean: 13.194210947883196\n",
      "resetting env. episode reward total was 11.0. running mean: 13.172268838404364\n",
      "resetting env. episode reward total was 12.0. running mean: 13.16054615002032\n",
      "resetting env. episode reward total was 19.0. running mean: 13.218940688520116\n",
      "resetting env. episode reward total was 9.0. running mean: 13.176751281634914\n",
      "resetting env. episode reward total was 14.0. running mean: 13.184983768818565\n",
      "resetting env. episode reward total was 16.0. running mean: 13.213133931130379\n",
      "resetting env. episode reward total was 15.0. running mean: 13.231002591819076\n",
      "resetting env. episode reward total was 11.0. running mean: 13.208692565900884\n",
      "resetting env. episode reward total was 14.0. running mean: 13.216605640241877\n",
      "resetting env. episode reward total was 7.0. running mean: 13.154439583839459\n",
      "resetting env. episode reward total was 16.0. running mean: 13.182895188001064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 13.161066236121053\n",
      "resetting env. episode reward total was 13.0. running mean: 13.159455573759843\n",
      "resetting env. episode reward total was 18.0. running mean: 13.207861018022244\n",
      "resetting env. episode reward total was 9.0. running mean: 13.165782407842022\n",
      "resetting env. episode reward total was 12.0. running mean: 13.1541245837636\n",
      "resetting env. episode reward total was 12.0. running mean: 13.142583337925963\n",
      "resetting env. episode reward total was 13.0. running mean: 13.141157504546705\n",
      "resetting env. episode reward total was 16.0. running mean: 13.169745929501238\n",
      "resetting env. episode reward total was 8.0. running mean: 13.118048470206226\n",
      "resetting env. episode reward total was 11.0. running mean: 13.096867985504163\n",
      "resetting env. episode reward total was 13.0. running mean: 13.095899305649123\n",
      "resetting env. episode reward total was 17.0. running mean: 13.134940312592631\n",
      "resetting env. episode reward total was 12.0. running mean: 13.123590909466705\n",
      "resetting env. episode reward total was 17.0. running mean: 13.162355000372038\n",
      "resetting env. episode reward total was 8.0. running mean: 13.110731450368318\n",
      "resetting env. episode reward total was 14.0. running mean: 13.119624135864635\n",
      "resetting env. episode reward total was 14.0. running mean: 13.12842789450599\n",
      "resetting env. episode reward total was 12.0. running mean: 13.117143615560929\n",
      "resetting env. episode reward total was 14.0. running mean: 13.12597217940532\n",
      "resetting env. episode reward total was 17.0. running mean: 13.164712457611266\n",
      "resetting env. episode reward total was 11.0. running mean: 13.143065333035153\n",
      "resetting env. episode reward total was 15.0. running mean: 13.161634679704802\n",
      "resetting env. episode reward total was 16.0. running mean: 13.190018332907755\n",
      "resetting env. episode reward total was 15.0. running mean: 13.208118149578677\n",
      "resetting env. episode reward total was 9.0. running mean: 13.16603696808289\n",
      "resetting env. episode reward total was 19.0. running mean: 13.224376598402062\n",
      "resetting env. episode reward total was 17.0. running mean: 13.262132832418041\n",
      "resetting env. episode reward total was 11.0. running mean: 13.23951150409386\n",
      "resetting env. episode reward total was 16.0. running mean: 13.267116389052921\n",
      "resetting env. episode reward total was 12.0. running mean: 13.25444522516239\n",
      "resetting env. episode reward total was 12.0. running mean: 13.241900772910766\n",
      "resetting env. episode reward total was 15.0. running mean: 13.259481765181658\n",
      "resetting env. episode reward total was 9.0. running mean: 13.21688694752984\n",
      "resetting env. episode reward total was 13.0. running mean: 13.214718078054542\n",
      "resetting env. episode reward total was 17.0. running mean: 13.252570897273996\n",
      "resetting env. episode reward total was 18.0. running mean: 13.300045188301256\n",
      "resetting env. episode reward total was 17.0. running mean: 13.337044736418244\n",
      "resetting env. episode reward total was 15.0. running mean: 13.353674289054062\n",
      "resetting env. episode reward total was 11.0. running mean: 13.33013754616352\n",
      "resetting env. episode reward total was 15.0. running mean: 13.346836170701886\n",
      "resetting env. episode reward total was 18.0. running mean: 13.393367808994867\n",
      "resetting env. episode reward total was 15.0. running mean: 13.409434130904918\n",
      "resetting env. episode reward total was 6.0. running mean: 13.335339789595869\n",
      "resetting env. episode reward total was 12.0. running mean: 13.321986391699909\n",
      "resetting env. episode reward total was 15.0. running mean: 13.33876652778291\n",
      "resetting env. episode reward total was 11.0. running mean: 13.31537886250508\n",
      "resetting env. episode reward total was 8.0. running mean: 13.262225073880028\n",
      "resetting env. episode reward total was 12.0. running mean: 13.249602823141228\n",
      "resetting env. episode reward total was 12.0. running mean: 13.237106794909815\n",
      "resetting env. episode reward total was 12.0. running mean: 13.224735726960716\n",
      "resetting env. episode reward total was 7.0. running mean: 13.16248836969111\n",
      "resetting env. episode reward total was 8.0. running mean: 13.110863485994198\n",
      "resetting env. episode reward total was 12.0. running mean: 13.099754851134255\n",
      "resetting env. episode reward total was 15.0. running mean: 13.118757302622914\n",
      "resetting env. episode reward total was 14.0. running mean: 13.127569729596685\n",
      "resetting env. episode reward total was 12.0. running mean: 13.116294032300717\n",
      "resetting env. episode reward total was 18.0. running mean: 13.16513109197771\n",
      "resetting env. episode reward total was 17.0. running mean: 13.203479781057933\n",
      "resetting env. episode reward total was 15.0. running mean: 13.221444983247354\n",
      "resetting env. episode reward total was 14.0. running mean: 13.229230533414881\n",
      "resetting env. episode reward total was 10.0. running mean: 13.196938228080732\n",
      "resetting env. episode reward total was 6.0. running mean: 13.124968845799925\n",
      "resetting env. episode reward total was 10.0. running mean: 13.093719157341926\n",
      "resetting env. episode reward total was 13.0. running mean: 13.092781965768507\n",
      "resetting env. episode reward total was 16.0. running mean: 13.121854146110822\n",
      "resetting env. episode reward total was 16.0. running mean: 13.150635604649715\n",
      "resetting env. episode reward total was 11.0. running mean: 13.129129248603217\n",
      "resetting env. episode reward total was 15.0. running mean: 13.147837956117185\n",
      "resetting env. episode reward total was 15.0. running mean: 13.166359576556014\n",
      "resetting env. episode reward total was 9.0. running mean: 13.124695980790452\n",
      "resetting env. episode reward total was 9.0. running mean: 13.083449020982547\n",
      "resetting env. episode reward total was 13.0. running mean: 13.082614530772723\n",
      "resetting env. episode reward total was 13.0. running mean: 13.081788385464996\n",
      "resetting env. episode reward total was 12.0. running mean: 13.070970501610345\n",
      "resetting env. episode reward total was 11.0. running mean: 13.050260796594241\n",
      "resetting env. episode reward total was 17.0. running mean: 13.089758188628299\n",
      "resetting env. episode reward total was 15.0. running mean: 13.108860606742017\n",
      "resetting env. episode reward total was 13.0. running mean: 13.107772000674597\n",
      "resetting env. episode reward total was 16.0. running mean: 13.136694280667852\n",
      "resetting env. episode reward total was 15.0. running mean: 13.155327337861173\n",
      "resetting env. episode reward total was 13.0. running mean: 13.153774064482562\n",
      "resetting env. episode reward total was 14.0. running mean: 13.162236323837737\n",
      "resetting env. episode reward total was 17.0. running mean: 13.200613960599359\n",
      "resetting env. episode reward total was 14.0. running mean: 13.208607820993366\n",
      "resetting env. episode reward total was 16.0. running mean: 13.236521742783433\n",
      "resetting env. episode reward total was 14.0. running mean: 13.2441565253556\n",
      "resetting env. episode reward total was 10.0. running mean: 13.211714960102043\n",
      "resetting env. episode reward total was 18.0. running mean: 13.259597810501022\n",
      "resetting env. episode reward total was 11.0. running mean: 13.237001832396011\n",
      "resetting env. episode reward total was 15.0. running mean: 13.25463181407205\n",
      "resetting env. episode reward total was 16.0. running mean: 13.28208549593133\n",
      "resetting env. episode reward total was 13.0. running mean: 13.279264640972018\n",
      "resetting env. episode reward total was 14.0. running mean: 13.286471994562298\n",
      "resetting env. episode reward total was 12.0. running mean: 13.273607274616674\n",
      "resetting env. episode reward total was 12.0. running mean: 13.260871201870506\n",
      "resetting env. episode reward total was 16.0. running mean: 13.288262489851801\n",
      "resetting env. episode reward total was 10.0. running mean: 13.255379864953284\n",
      "resetting env. episode reward total was 11.0. running mean: 13.23282606630375\n",
      "resetting env. episode reward total was 12.0. running mean: 13.220497805640711\n",
      "resetting env. episode reward total was 14.0. running mean: 13.228292827584305\n",
      "resetting env. episode reward total was 10.0. running mean: 13.19600989930846\n",
      "resetting env. episode reward total was 14.0. running mean: 13.204049800315376\n",
      "resetting env. episode reward total was 17.0. running mean: 13.242009302312223\n",
      "resetting env. episode reward total was 19.0. running mean: 13.299589209289099\n",
      "resetting env. episode reward total was 15.0. running mean: 13.316593317196208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 13.323427384024246\n",
      "resetting env. episode reward total was 12.0. running mean: 13.310193110184002\n",
      "resetting env. episode reward total was 16.0. running mean: 13.337091179082162\n",
      "resetting env. episode reward total was 7.0. running mean: 13.27372026729134\n",
      "resetting env. episode reward total was 12.0. running mean: 13.260983064618426\n",
      "resetting env. episode reward total was 13.0. running mean: 13.258373233972241\n",
      "resetting env. episode reward total was 16.0. running mean: 13.28578950163252\n",
      "resetting env. episode reward total was 13.0. running mean: 13.282931606616195\n",
      "resetting env. episode reward total was 17.0. running mean: 13.320102290550032\n",
      "resetting env. episode reward total was 9.0. running mean: 13.276901267644531\n",
      "resetting env. episode reward total was 13.0. running mean: 13.274132254968086\n",
      "resetting env. episode reward total was 10.0. running mean: 13.241390932418405\n",
      "resetting env. episode reward total was 10.0. running mean: 13.20897702309422\n",
      "resetting env. episode reward total was 17.0. running mean: 13.246887252863278\n",
      "resetting env. episode reward total was 11.0. running mean: 13.224418380334644\n",
      "resetting env. episode reward total was 13.0. running mean: 13.222174196531299\n",
      "resetting env. episode reward total was 14.0. running mean: 13.229952454565986\n",
      "resetting env. episode reward total was 16.0. running mean: 13.257652930020326\n",
      "resetting env. episode reward total was 14.0. running mean: 13.265076400720123\n",
      "resetting env. episode reward total was 14.0. running mean: 13.272425636712923\n",
      "resetting env. episode reward total was 6.0. running mean: 13.199701380345793\n",
      "resetting env. episode reward total was -1.0. running mean: 13.057704366542335\n",
      "resetting env. episode reward total was 17.0. running mean: 13.097127322876911\n",
      "resetting env. episode reward total was 10.0. running mean: 13.066156049648141\n",
      "resetting env. episode reward total was 13.0. running mean: 13.06549448915166\n",
      "resetting env. episode reward total was 14.0. running mean: 13.074839544260145\n",
      "resetting env. episode reward total was 12.0. running mean: 13.064091148817543\n",
      "resetting env. episode reward total was 18.0. running mean: 13.113450237329367\n",
      "resetting env. episode reward total was 9.0. running mean: 13.072315734956073\n",
      "resetting env. episode reward total was 14.0. running mean: 13.081592577606513\n",
      "resetting env. episode reward total was 12.0. running mean: 13.070776651830446\n",
      "resetting env. episode reward total was 12.0. running mean: 13.060068885312141\n",
      "resetting env. episode reward total was 16.0. running mean: 13.08946819645902\n",
      "resetting env. episode reward total was 14.0. running mean: 13.09857351449443\n",
      "resetting env. episode reward total was 16.0. running mean: 13.127587779349485\n",
      "resetting env. episode reward total was 14.0. running mean: 13.13631190155599\n",
      "resetting env. episode reward total was 10.0. running mean: 13.10494878254043\n",
      "resetting env. episode reward total was 14.0. running mean: 13.113899294715026\n",
      "resetting env. episode reward total was 9.0. running mean: 13.072760301767875\n",
      "resetting env. episode reward total was 9.0. running mean: 13.032032698750196\n",
      "resetting env. episode reward total was 14.0. running mean: 13.041712371762696\n",
      "resetting env. episode reward total was 15.0. running mean: 13.061295248045068\n",
      "resetting env. episode reward total was 13.0. running mean: 13.060682295564618\n",
      "resetting env. episode reward total was 18.0. running mean: 13.11007547260897\n",
      "resetting env. episode reward total was 12.0. running mean: 13.09897471788288\n",
      "resetting env. episode reward total was 11.0. running mean: 13.077984970704051\n",
      "resetting env. episode reward total was 10.0. running mean: 13.04720512099701\n",
      "resetting env. episode reward total was 11.0. running mean: 13.026733069787038\n",
      "resetting env. episode reward total was 16.0. running mean: 13.056465739089168\n",
      "resetting env. episode reward total was 17.0. running mean: 13.095901081698276\n",
      "resetting env. episode reward total was 16.0. running mean: 13.124942070881293\n",
      "resetting env. episode reward total was -3.0. running mean: 12.963692650172481\n",
      "resetting env. episode reward total was 12.0. running mean: 12.954055723670756\n",
      "resetting env. episode reward total was 13.0. running mean: 12.95451516643405\n",
      "resetting env. episode reward total was 14.0. running mean: 12.96497001476971\n",
      "resetting env. episode reward total was 14.0. running mean: 12.975320314622014\n",
      "resetting env. episode reward total was 18.0. running mean: 13.025567111475793\n",
      "resetting env. episode reward total was 5.0. running mean: 12.945311440361035\n",
      "resetting env. episode reward total was 16.0. running mean: 12.975858325957425\n",
      "resetting env. episode reward total was 12.0. running mean: 12.96609974269785\n",
      "resetting env. episode reward total was 9.0. running mean: 12.926438745270872\n",
      "resetting env. episode reward total was 17.0. running mean: 12.967174357818163\n",
      "resetting env. episode reward total was 18.0. running mean: 13.01750261423998\n",
      "resetting env. episode reward total was 15.0. running mean: 13.03732758809758\n",
      "resetting env. episode reward total was 10.0. running mean: 13.006954312216605\n",
      "resetting env. episode reward total was 14.0. running mean: 13.016884769094439\n",
      "resetting env. episode reward total was 13.0. running mean: 13.016715921403495\n",
      "resetting env. episode reward total was 20.0. running mean: 13.086548762189459\n",
      "resetting env. episode reward total was 12.0. running mean: 13.075683274567563\n",
      "resetting env. episode reward total was 13.0. running mean: 13.074926441821889\n",
      "resetting env. episode reward total was 13.0. running mean: 13.074177177403671\n",
      "resetting env. episode reward total was 17.0. running mean: 13.113435405629634\n",
      "resetting env. episode reward total was 10.0. running mean: 13.082301051573337\n",
      "resetting env. episode reward total was 17.0. running mean: 13.121478041057603\n",
      "resetting env. episode reward total was 14.0. running mean: 13.130263260647027\n",
      "resetting env. episode reward total was 15.0. running mean: 13.148960628040557\n",
      "resetting env. episode reward total was 14.0. running mean: 13.157471021760152\n",
      "resetting env. episode reward total was 8.0. running mean: 13.105896311542551\n",
      "resetting env. episode reward total was 14.0. running mean: 13.114837348427127\n",
      "resetting env. episode reward total was 12.0. running mean: 13.103688974942855\n",
      "resetting env. episode reward total was 10.0. running mean: 13.072652085193427\n",
      "resetting env. episode reward total was 15.0. running mean: 13.091925564341492\n",
      "resetting env. episode reward total was 11.0. running mean: 13.071006308698077\n",
      "resetting env. episode reward total was 8.0. running mean: 13.020296245611096\n",
      "resetting env. episode reward total was 13.0. running mean: 13.020093283154985\n",
      "resetting env. episode reward total was 11.0. running mean: 12.999892350323435\n",
      "resetting env. episode reward total was 11.0. running mean: 12.9798934268202\n",
      "resetting env. episode reward total was 16.0. running mean: 13.010094492551998\n",
      "resetting env. episode reward total was 12.0. running mean: 12.999993547626477\n",
      "resetting env. episode reward total was 17.0. running mean: 13.039993612150212\n",
      "resetting env. episode reward total was 17.0. running mean: 13.07959367602871\n",
      "resetting env. episode reward total was 7.0. running mean: 13.018797739268422\n",
      "resetting env. episode reward total was 7.0. running mean: 12.958609761875739\n",
      "resetting env. episode reward total was 11.0. running mean: 12.93902366425698\n",
      "resetting env. episode reward total was 13.0. running mean: 12.939633427614412\n",
      "resetting env. episode reward total was 10.0. running mean: 12.910237093338267\n",
      "resetting env. episode reward total was 20.0. running mean: 12.981134722404883\n",
      "resetting env. episode reward total was 15.0. running mean: 13.001323375180835\n",
      "resetting env. episode reward total was 16.0. running mean: 13.031310141429026\n",
      "resetting env. episode reward total was 15.0. running mean: 13.050997040014737\n",
      "resetting env. episode reward total was 15.0. running mean: 13.07048706961459\n",
      "resetting env. episode reward total was 12.0. running mean: 13.059782198918443\n",
      "resetting env. episode reward total was 11.0. running mean: 13.039184376929258\n",
      "resetting env. episode reward total was 7.0. running mean: 12.978792533159966\n",
      "resetting env. episode reward total was 6.0. running mean: 12.909004607828367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: 12.809914561750082\n",
      "resetting env. episode reward total was 16.0. running mean: 12.841815416132581\n",
      "resetting env. episode reward total was 17.0. running mean: 12.883397261971256\n",
      "resetting env. episode reward total was 16.0. running mean: 12.914563289351543\n",
      "resetting env. episode reward total was 15.0. running mean: 12.935417656458029\n",
      "resetting env. episode reward total was 13.0. running mean: 12.936063479893448\n",
      "resetting env. episode reward total was 12.0. running mean: 12.926702845094512\n",
      "resetting env. episode reward total was 13.0. running mean: 12.927435816643568\n",
      "resetting env. episode reward total was 17.0. running mean: 12.968161458477132\n",
      "resetting env. episode reward total was 15.0. running mean: 12.98847984389236\n",
      "resetting env. episode reward total was 13.0. running mean: 12.988595045453437\n",
      "resetting env. episode reward total was 16.0. running mean: 13.018709094998902\n",
      "resetting env. episode reward total was 16.0. running mean: 13.048522004048914\n",
      "resetting env. episode reward total was 15.0. running mean: 13.068036784008425\n",
      "resetting env. episode reward total was 5.0. running mean: 12.987356416168343\n",
      "resetting env. episode reward total was 15.0. running mean: 13.007482852006659\n",
      "resetting env. episode reward total was 16.0. running mean: 13.037408023486591\n",
      "resetting env. episode reward total was 16.0. running mean: 13.067033943251726\n",
      "resetting env. episode reward total was 13.0. running mean: 13.066363603819209\n",
      "resetting env. episode reward total was 13.0. running mean: 13.065699967781017\n",
      "resetting env. episode reward total was 15.0. running mean: 13.085042968103206\n",
      "resetting env. episode reward total was 11.0. running mean: 13.064192538422173\n",
      "resetting env. episode reward total was 18.0. running mean: 13.113550613037951\n",
      "resetting env. episode reward total was 11.0. running mean: 13.092415106907572\n",
      "resetting env. episode reward total was 16.0. running mean: 13.121490955838496\n",
      "resetting env. episode reward total was 11.0. running mean: 13.10027604628011\n",
      "resetting env. episode reward total was 16.0. running mean: 13.129273285817309\n",
      "resetting env. episode reward total was 15.0. running mean: 13.147980552959137\n",
      "resetting env. episode reward total was 16.0. running mean: 13.176500747429545\n",
      "resetting env. episode reward total was 18.0. running mean: 13.224735739955248\n",
      "resetting env. episode reward total was 18.0. running mean: 13.272488382555695\n",
      "resetting env. episode reward total was 7.0. running mean: 13.209763498730139\n",
      "resetting env. episode reward total was 10.0. running mean: 13.177665863742837\n",
      "resetting env. episode reward total was 15.0. running mean: 13.19588920510541\n",
      "resetting env. episode reward total was 14.0. running mean: 13.203930313054355\n",
      "resetting env. episode reward total was 10.0. running mean: 13.171891009923812\n",
      "resetting env. episode reward total was 15.0. running mean: 13.190172099824574\n",
      "resetting env. episode reward total was 16.0. running mean: 13.218270378826329\n",
      "resetting env. episode reward total was 8.0. running mean: 13.166087675038066\n",
      "resetting env. episode reward total was 9.0. running mean: 13.124426798287685\n",
      "resetting env. episode reward total was 17.0. running mean: 13.163182530304807\n",
      "resetting env. episode reward total was 2.0. running mean: 13.051550705001759\n",
      "resetting env. episode reward total was 14.0. running mean: 13.061035197951743\n",
      "resetting env. episode reward total was 10.0. running mean: 13.030424845972224\n",
      "resetting env. episode reward total was 5.0. running mean: 12.950120597512502\n",
      "resetting env. episode reward total was 13.0. running mean: 12.950619391537378\n",
      "resetting env. episode reward total was 13.0. running mean: 12.951113197622005\n",
      "resetting env. episode reward total was 9.0. running mean: 12.911602065645784\n",
      "resetting env. episode reward total was 18.0. running mean: 12.962486044989326\n",
      "resetting env. episode reward total was 18.0. running mean: 13.012861184539432\n",
      "resetting env. episode reward total was 10.0. running mean: 12.982732572694037\n",
      "resetting env. episode reward total was 14.0. running mean: 12.992905246967096\n",
      "resetting env. episode reward total was 17.0. running mean: 13.032976194497424\n",
      "resetting env. episode reward total was 17.0. running mean: 13.07264643255245\n",
      "resetting env. episode reward total was 13.0. running mean: 13.071919968226926\n",
      "resetting env. episode reward total was 10.0. running mean: 13.041200768544655\n",
      "resetting env. episode reward total was 18.0. running mean: 13.090788760859208\n",
      "resetting env. episode reward total was 10.0. running mean: 13.059880873250616\n",
      "resetting env. episode reward total was 16.0. running mean: 13.08928206451811\n",
      "resetting env. episode reward total was 10.0. running mean: 13.058389243872929\n",
      "resetting env. episode reward total was 2.0. running mean: 12.9478053514342\n",
      "resetting env. episode reward total was 17.0. running mean: 12.988327297919858\n",
      "resetting env. episode reward total was 18.0. running mean: 13.03844402494066\n",
      "resetting env. episode reward total was 14.0. running mean: 13.048059584691254\n",
      "resetting env. episode reward total was 15.0. running mean: 13.06757898884434\n",
      "resetting env. episode reward total was 9.0. running mean: 13.026903198955898\n",
      "resetting env. episode reward total was 12.0. running mean: 13.016634166966337\n",
      "resetting env. episode reward total was 15.0. running mean: 13.036467825296674\n",
      "resetting env. episode reward total was 19.0. running mean: 13.096103147043706\n",
      "resetting env. episode reward total was 9.0. running mean: 13.055142115573268\n",
      "resetting env. episode reward total was 13.0. running mean: 13.054590694417536\n",
      "resetting env. episode reward total was 17.0. running mean: 13.09404478747336\n",
      "resetting env. episode reward total was 9.0. running mean: 13.053104339598626\n",
      "resetting env. episode reward total was 14.0. running mean: 13.06257329620264\n",
      "resetting env. episode reward total was 13.0. running mean: 13.061947563240613\n",
      "resetting env. episode reward total was 12.0. running mean: 13.051328087608207\n",
      "resetting env. episode reward total was 8.0. running mean: 13.000814806732125\n",
      "resetting env. episode reward total was 10.0. running mean: 12.970806658664802\n",
      "resetting env. episode reward total was 13.0. running mean: 12.971098592078155\n",
      "resetting env. episode reward total was 7.0. running mean: 12.911387606157374\n",
      "resetting env. episode reward total was 15.0. running mean: 12.932273730095801\n",
      "resetting env. episode reward total was 9.0. running mean: 12.892950992794843\n",
      "resetting env. episode reward total was 16.0. running mean: 12.924021482866895\n",
      "resetting env. episode reward total was 12.0. running mean: 12.914781268038224\n",
      "resetting env. episode reward total was 11.0. running mean: 12.89563345535784\n",
      "resetting env. episode reward total was 11.0. running mean: 12.876677120804262\n",
      "resetting env. episode reward total was 14.0. running mean: 12.88791034959622\n",
      "resetting env. episode reward total was 13.0. running mean: 12.88903124610026\n",
      "resetting env. episode reward total was 18.0. running mean: 12.940140933639256\n",
      "resetting env. episode reward total was 16.0. running mean: 12.970739524302864\n",
      "resetting env. episode reward total was 9.0. running mean: 12.931032129059835\n",
      "resetting env. episode reward total was 11.0. running mean: 12.911721807769236\n",
      "resetting env. episode reward total was 16.0. running mean: 12.942604589691545\n",
      "resetting env. episode reward total was 9.0. running mean: 12.90317854379463\n",
      "resetting env. episode reward total was 14.0. running mean: 12.914146758356683\n",
      "resetting env. episode reward total was 18.0. running mean: 12.965005290773115\n",
      "resetting env. episode reward total was 7.0. running mean: 12.905355237865384\n",
      "resetting env. episode reward total was 16.0. running mean: 12.93630168548673\n",
      "resetting env. episode reward total was 14.0. running mean: 12.946938668631864\n",
      "resetting env. episode reward total was 15.0. running mean: 12.967469281945545\n",
      "resetting env. episode reward total was 2.0. running mean: 12.85779458912609\n",
      "resetting env. episode reward total was 14.0. running mean: 12.86921664323483\n",
      "resetting env. episode reward total was 7.0. running mean: 12.810524476802483\n",
      "resetting env. episode reward total was 17.0. running mean: 12.852419232034459\n",
      "resetting env. episode reward total was 16.0. running mean: 12.883895039714114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 19.0. running mean: 12.945056089316973\n",
      "resetting env. episode reward total was 14.0. running mean: 12.955605528423803\n",
      "resetting env. episode reward total was 18.0. running mean: 13.006049473139564\n",
      "resetting env. episode reward total was 11.0. running mean: 12.985988978408168\n",
      "resetting env. episode reward total was 7.0. running mean: 12.926129088624085\n",
      "resetting env. episode reward total was 17.0. running mean: 12.966867797737844\n",
      "resetting env. episode reward total was 14.0. running mean: 12.977199119760467\n",
      "resetting env. episode reward total was 10.0. running mean: 12.947427128562861\n",
      "resetting env. episode reward total was 15.0. running mean: 12.967952857277233\n",
      "resetting env. episode reward total was 8.0. running mean: 12.91827332870446\n",
      "resetting env. episode reward total was 5.0. running mean: 12.839090595417415\n",
      "resetting env. episode reward total was 10.0. running mean: 12.810699689463242\n",
      "resetting env. episode reward total was 15.0. running mean: 12.832592692568609\n",
      "resetting env. episode reward total was 4.0. running mean: 12.744266765642921\n",
      "resetting env. episode reward total was 19.0. running mean: 12.80682409798649\n",
      "resetting env. episode reward total was 10.0. running mean: 12.778755857006626\n",
      "resetting env. episode reward total was 14.0. running mean: 12.79096829843656\n",
      "resetting env. episode reward total was 10.0. running mean: 12.763058615452195\n",
      "resetting env. episode reward total was 15.0. running mean: 12.785428029297673\n",
      "resetting env. episode reward total was 21.0. running mean: 12.867573749004697\n",
      "resetting env. episode reward total was 13.0. running mean: 12.86889801151465\n",
      "resetting env. episode reward total was 17.0. running mean: 12.910209031399503\n",
      "resetting env. episode reward total was 15.0. running mean: 12.931106941085508\n",
      "resetting env. episode reward total was 9.0. running mean: 12.891795871674653\n",
      "resetting env. episode reward total was 17.0. running mean: 12.932877912957906\n",
      "resetting env. episode reward total was 11.0. running mean: 12.913549133828326\n",
      "resetting env. episode reward total was 15.0. running mean: 12.934413642490043\n",
      "resetting env. episode reward total was 16.0. running mean: 12.965069506065142\n",
      "resetting env. episode reward total was 11.0. running mean: 12.945418811004489\n",
      "resetting env. episode reward total was 6.0. running mean: 12.875964622894443\n",
      "resetting env. episode reward total was 12.0. running mean: 12.867204976665498\n",
      "resetting env. episode reward total was 16.0. running mean: 12.898532926898843\n",
      "resetting env. episode reward total was 10.0. running mean: 12.869547597629854\n",
      "resetting env. episode reward total was 18.0. running mean: 12.920852121653555\n",
      "resetting env. episode reward total was 13.0. running mean: 12.92164360043702\n",
      "resetting env. episode reward total was 11.0. running mean: 12.90242716443265\n",
      "resetting env. episode reward total was 16.0. running mean: 12.933402892788324\n",
      "resetting env. episode reward total was 16.0. running mean: 12.96406886386044\n",
      "resetting env. episode reward total was 16.0. running mean: 12.994428175221836\n",
      "resetting env. episode reward total was 13.0. running mean: 12.994483893469619\n",
      "resetting env. episode reward total was 3.0. running mean: 12.894539054534922\n",
      "resetting env. episode reward total was 13.0. running mean: 12.895593663989574\n",
      "resetting env. episode reward total was 13.0. running mean: 12.89663772734968\n",
      "resetting env. episode reward total was 7.0. running mean: 12.837671350076183\n",
      "resetting env. episode reward total was 17.0. running mean: 12.879294636575422\n",
      "resetting env. episode reward total was 17.0. running mean: 12.920501690209667\n",
      "resetting env. episode reward total was 8.0. running mean: 12.87129667330757\n",
      "resetting env. episode reward total was 11.0. running mean: 12.852583706574494\n",
      "resetting env. episode reward total was 3.0. running mean: 12.754057869508749\n",
      "resetting env. episode reward total was 11.0. running mean: 12.73651729081366\n",
      "resetting env. episode reward total was 19.0. running mean: 12.799152117905523\n",
      "resetting env. episode reward total was 16.0. running mean: 12.831160596726468\n",
      "resetting env. episode reward total was 11.0. running mean: 12.812848990759203\n",
      "resetting env. episode reward total was 11.0. running mean: 12.79472050085161\n",
      "resetting env. episode reward total was 12.0. running mean: 12.786773295843094\n",
      "resetting env. episode reward total was 15.0. running mean: 12.808905562884663\n",
      "resetting env. episode reward total was 15.0. running mean: 12.830816507255816\n",
      "resetting env. episode reward total was 15.0. running mean: 12.852508342183258\n",
      "resetting env. episode reward total was 11.0. running mean: 12.833983258761425\n",
      "resetting env. episode reward total was 9.0. running mean: 12.795643426173811\n",
      "resetting env. episode reward total was 10.0. running mean: 12.767686991912072\n",
      "resetting env. episode reward total was 15.0. running mean: 12.790010121992951\n",
      "resetting env. episode reward total was 12.0. running mean: 12.782110020773022\n",
      "resetting env. episode reward total was 15.0. running mean: 12.804288920565291\n",
      "resetting env. episode reward total was 13.0. running mean: 12.806246031359638\n",
      "resetting env. episode reward total was 6.0. running mean: 12.738183571046042\n",
      "resetting env. episode reward total was 17.0. running mean: 12.780801735335581\n",
      "resetting env. episode reward total was 6.0. running mean: 12.712993717982226\n",
      "resetting env. episode reward total was 9.0. running mean: 12.675863780802404\n",
      "resetting env. episode reward total was 16.0. running mean: 12.70910514299438\n",
      "resetting env. episode reward total was 9.0. running mean: 12.672014091564437\n",
      "resetting env. episode reward total was 11.0. running mean: 12.655293950648792\n",
      "resetting env. episode reward total was 9.0. running mean: 12.618741011142303\n",
      "resetting env. episode reward total was 11.0. running mean: 12.602553601030879\n",
      "resetting env. episode reward total was 18.0. running mean: 12.65652806502057\n",
      "resetting env. episode reward total was 2.0. running mean: 12.549962784370363\n",
      "resetting env. episode reward total was 10.0. running mean: 12.524463156526659\n",
      "resetting env. episode reward total was 10.0. running mean: 12.499218524961393\n",
      "resetting env. episode reward total was 16.0. running mean: 12.534226339711779\n",
      "resetting env. episode reward total was 14.0. running mean: 12.548884076314662\n",
      "resetting env. episode reward total was 8.0. running mean: 12.503395235551515\n",
      "resetting env. episode reward total was 16.0. running mean: 12.538361283196\n",
      "resetting env. episode reward total was 8.0. running mean: 12.49297767036404\n",
      "resetting env. episode reward total was 12.0. running mean: 12.488047893660399\n",
      "resetting env. episode reward total was 17.0. running mean: 12.533167414723795\n",
      "resetting env. episode reward total was 7.0. running mean: 12.477835740576557\n",
      "resetting env. episode reward total was 14.0. running mean: 12.493057383170791\n",
      "resetting env. episode reward total was 9.0. running mean: 12.458126809339083\n",
      "resetting env. episode reward total was 15.0. running mean: 12.483545541245693\n",
      "resetting env. episode reward total was 9.0. running mean: 12.448710085833236\n",
      "resetting env. episode reward total was 12.0. running mean: 12.444222984974903\n",
      "resetting env. episode reward total was 14.0. running mean: 12.459780755125156\n",
      "resetting env. episode reward total was 6.0. running mean: 12.395182947573904\n",
      "resetting env. episode reward total was 14.0. running mean: 12.411231118098165\n",
      "resetting env. episode reward total was 16.0. running mean: 12.447118806917183\n",
      "resetting env. episode reward total was 11.0. running mean: 12.43264761884801\n",
      "resetting env. episode reward total was 20.0. running mean: 12.508321142659529\n",
      "resetting env. episode reward total was 14.0. running mean: 12.523237931232934\n",
      "resetting env. episode reward total was 13.0. running mean: 12.528005551920605\n",
      "resetting env. episode reward total was 6.0. running mean: 12.4627254964014\n",
      "resetting env. episode reward total was 13.0. running mean: 12.468098241437387\n",
      "resetting env. episode reward total was 15.0. running mean: 12.493417259023014\n",
      "resetting env. episode reward total was 19.0. running mean: 12.558483086432783\n",
      "resetting env. episode reward total was 14.0. running mean: 12.572898255568456\n",
      "resetting env. episode reward total was 7.0. running mean: 12.51716927301277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 17.0. running mean: 12.561997580282643\n",
      "resetting env. episode reward total was 7.0. running mean: 12.506377604479816\n",
      "resetting env. episode reward total was 14.0. running mean: 12.521313828435018\n",
      "resetting env. episode reward total was 11.0. running mean: 12.506100690150667\n",
      "resetting env. episode reward total was 13.0. running mean: 12.51103968324916\n",
      "resetting env. episode reward total was 11.0. running mean: 12.495929286416668\n",
      "resetting env. episode reward total was 15.0. running mean: 12.520969993552502\n",
      "resetting env. episode reward total was 12.0. running mean: 12.515760293616976\n",
      "resetting env. episode reward total was 10.0. running mean: 12.490602690680806\n",
      "resetting env. episode reward total was 10.0. running mean: 12.465696663773997\n",
      "resetting env. episode reward total was 11.0. running mean: 12.451039697136256\n",
      "resetting env. episode reward total was 10.0. running mean: 12.426529300164892\n",
      "resetting env. episode reward total was 17.0. running mean: 12.472264007163243\n",
      "resetting env. episode reward total was 8.0. running mean: 12.42754136709161\n",
      "resetting env. episode reward total was 14.0. running mean: 12.443265953420694\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m dlogps\u001b[38;5;241m.\u001b[39mappend(y \u001b[38;5;241m-\u001b[39m aprob)  \u001b[38;5;66;03m# 梯度鼓励采取的动作\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# 环境步进，获取新状态\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 更新为新的返回值\u001b[39;00m\n\u001b[1;32m     93\u001b[0m reward_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m     95\u001b[0m drs\u001b[38;5;241m.\u001b[39mappend(reward)  \u001b[38;5;66;03m# 记录奖励\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/ale_py/env/gym.py:256\u001b[0m, in \u001b[0;36mAtariEnv.step\u001b[0;34m(self, action_ind)\u001b[0m\n\u001b[1;32m    254\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(frameskip):\n\u001b[0;32m--> 256\u001b[0m     reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43male\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m is_terminal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_over(with_truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    258\u001b[0m is_truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_truncated()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle  # 用 pickle 替代 cPickle\n",
    "import gym\n",
    "np.bool8 = np.bool_\n",
    "\n",
    "# 超参数\n",
    "H = 200  # 隐藏层神经元数量\n",
    "batch_size = 10  # 每多少集进行一次参数更新\n",
    "learning_rate = 1e-3\n",
    "gamma = 0.99  # 折扣因子\n",
    "decay_rate = 0.99  # RMSProp 衰减因子\n",
    "resume = False  # 是否从以前的检查点恢复\n",
    "render = False\n",
    "\n",
    "# 模型初始化\n",
    "D = 80 * 80  # 输入维度：80x80 网格\n",
    "\n",
    "\n",
    "model = {}\n",
    "model['W1'] = np.random.randn(H, D) / np.sqrt(D)  # \"Xavier\" 初始化\n",
    "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
    "\n",
    "# 更新缓存，用于 RMSProp 平滑梯度\n",
    "grad_buffer = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "rmsprop_cache = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))  # sigmoid 函数\n",
    "\n",
    "def prepro(I):\n",
    "    \"\"\"将 210x160x3 uint8 帧预处理为 6400 (80x80) 1D float 向量\"\"\"\n",
    "    I = I[35:195]  # 裁剪\n",
    "    I = I[::2, ::2, 0]  # 下采样因子为 2\n",
    "    I[I == 144] = 0  # 删除背景类型 1\n",
    "    I[I == 109] = 0  # 删除背景类型 2\n",
    "    I[I != 0] = 1  # 其他设置为 1\n",
    "    return I.astype(np.float32).ravel()\n",
    "\n",
    "def discount_rewards(r):\n",
    "    \"\"\"对奖励进行折扣\"\"\"\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    for t in reversed(range(r.size)):\n",
    "        if r[t] != 0: running_add = 0  # 如果是游戏边界（仅对 Pong 特有）\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "    return discounted_r\n",
    "\n",
    "def policy_forward(x):\n",
    "    h = np.dot(model['W1'], x)\n",
    "    h[h < 0] = 0  # ReLU\n",
    "    logp = np.dot(model['W2'], h)\n",
    "    p = sigmoid(logp)\n",
    "    return p, h  # 返回采取动作 2 的概率和隐藏状态\n",
    "\n",
    "def policy_backward(eph, epdlogp):\n",
    "    \"\"\"反向传播（eph 为隐藏状态数组）\"\"\"\n",
    "    dW2 = np.dot(eph.T, epdlogp).ravel()\n",
    "    dh = np.outer(epdlogp, model['W2'])\n",
    "    dh[eph <= 0] = 0  # Backprop ReLU\n",
    "    dW1 = np.dot(dh.T, epx)\n",
    "    return {'W1': dW1, 'W2': dW2}\n",
    "\n",
    "# 训练\n",
    "env = gym.make(\"Pong-v4\")\n",
    "observation, _ = env.reset()\n",
    "prev_x = None  # 用于计算差分帧\n",
    "xs, hs, dlogps, drs = [], [], [], []\n",
    "running_reward = None\n",
    "reward_sum = 0\n",
    "episode_number = 0\n",
    "\n",
    "while True:\n",
    "    if render: env.render()\n",
    "\n",
    "    # 预处理观测，设定网络输入为差分图像\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    # 前向传播并采样动作\n",
    "    aprob, h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3  # 投掷骰子！\n",
    "\n",
    "    # 记录中间变量（后续用于反向传播）\n",
    "    xs.append(x)  # 观测值\n",
    "    hs.append(h)  # 隐藏状态\n",
    "    y = 1 if action == 2 else 0  # “伪标签”\n",
    "    dlogps.append(y - aprob)  # 梯度鼓励采取的动作\n",
    "\n",
    "    # 环境步进，获取新状态\n",
    "    observation, reward, terminated, truncated, info = env.step(action)  # 更新为新的返回值\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward)  # 记录奖励\n",
    "\n",
    "    if terminated or truncated:  # 一个回合结束\n",
    "        episode_number += 1\n",
    "\n",
    "        # 堆叠输入、隐藏状态、动作梯度和奖励\n",
    "        epx = np.vstack(xs)\n",
    "        eph = np.vstack(hs)\n",
    "        epdlogp = np.vstack(dlogps)\n",
    "        epr = np.vstack(drs)\n",
    "        xs, hs, dlogps, drs = [], [], [], []  # 重置数组\n",
    "\n",
    "        # 计算折扣奖励\n",
    "        discounted_epr = discount_rewards(epr)\n",
    "        # 标准化奖励\n",
    "        discounted_epr -= np.mean(discounted_epr)\n",
    "        discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "        epdlogp *= discounted_epr  # 使用优势调制梯度\n",
    "        grad = policy_backward(eph, epdlogp)\n",
    "        for k in model: grad_buffer[k] += grad[k]  # 在 batch 中累积梯度\n",
    "\n",
    "        # 每 batch_size 集执行 RMSProp 参数更新\n",
    "        if episode_number % batch_size == 0:\n",
    "            for k, v in model.items():\n",
    "                g = grad_buffer[k]\n",
    "                rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g ** 2\n",
    "                model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "                grad_buffer[k] = np.zeros_like(v)  # 重置 batch 梯度缓存\n",
    "\n",
    "        # 记录\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        print(f'resetting env. episode reward total was {reward_sum}. running mean: {running_reward}')\n",
    "        if episode_number % 100 == 0:\n",
    "            with open('save.p', 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "        reward_sum = 0\n",
    "        observation, _ = env.reset()\n",
    "        prev_x = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7dabd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
