{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a14ba258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import copy\n",
    "from torch.optim import Adam\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ba47f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_state,n_action,hidden_dim=200):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_state,hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim,n_action)\n",
    "    \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "135bb49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.buffer = deque(maxlen=200)\n",
    "    \n",
    "    def push(self,transitions):\n",
    "        self.buffer.append(transitions)\n",
    "    \n",
    "    def sample(self):\n",
    "        return zip(*self.buffer)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.buffer.clear()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b498c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self,n_states,n_actions):\n",
    "        self.qnet = MLP(n_states,n_actions)\n",
    "        self.target_net = MLP(n_states,n_actions)\n",
    "#         for p1,p2 in zip(self.qnet.parameters(),self.target_net.parameters()):\n",
    "#             p2.data.copy_(p1.data)\n",
    "        \n",
    "        self.optimizer = Adam(self.qnet.parameters())\n",
    "        self.memory = Memory()\n",
    "        self.n_actions = n_actions\n",
    "    \n",
    "    def sample_action(self,state):\n",
    "        if np.random.random() < 0.1:\n",
    "            return np.random.choice(n_actions)\n",
    "        else:\n",
    "            values = self.qnet(state)\n",
    "            return values.max(1)[1].item()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_action(self,state):\n",
    "        values = self.qnet(state)\n",
    "        return values.max(1)[1].item()\n",
    "    \n",
    "    def update(self):\n",
    "        if len(self.memory) != 200:\n",
    "            return\n",
    "        states,actions,rewards,next_states,dones = self.memory.sample()\n",
    "        states = torch.tensor(states) # n n_states\n",
    "        actions = torch.tensor(actions).view(-1,1) # n \n",
    "        next_states = torch.tensor(next_states)\n",
    "        dones = torch.tensor(np.float32(dones))\n",
    "        rewards = torch.tensor(rewards) # n 1\n",
    "        qvalues = self.qnet(states) # n n_actions\n",
    "        qvalues = qvalues.gather(1,actions)\n",
    "        next_qvalues = self.target_net(next_states) # n n_actions\n",
    "        target_values = rewards + 0.95 * next_qvalues.max(1)[0].detach()*(1-dones) # max(1)[1]: n values\n",
    "        loss = F.mse_loss(qvalues.view(-1),target_values.view(-1))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d5ec10ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "np.bool8 = np.bool_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "75e47336",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v0'\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "bb6dde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f77d116e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_states,n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "970ef55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(n_states,n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "a12f173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 : reward: 10.0\n",
      "epoch: 100 : reward: 10.0\n",
      "epoch: 200 : reward: 20.0\n",
      "epoch: 300 : reward: 10.0\n",
      "epoch: 400 : reward: 200.0\n",
      "epoch: 500 : reward: 95.0\n",
      "epoch: 600 : reward: 11.0\n",
      "epoch: 700 : reward: 32.0\n",
      "epoch: 800 : reward: 20.0\n",
      "epoch: 900 : reward: 195.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    \n",
    "    state,_ = env.reset()\n",
    "    \n",
    "    for i in range(200):\n",
    "        action = agent.sample_action(torch.tensor(state).unsqueeze(0))\n",
    "        next_state, reward, done, _,_ = env.step(action)  # 更新环境，返回transition\n",
    "        agent.memory.push((state, action, reward,next_state, done))  # 保存transition\n",
    "        state = next_state\n",
    "        agent.update()\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        for p1,p2 in zip(agent.qnet.parameters(),agent.target_net.parameters()):\n",
    "            p2.data.copy_(p1.data)\n",
    "    \n",
    "    \n",
    "    ### test\n",
    "    if epoch % 100 == 0:\n",
    "        rewards = 0\n",
    "        state,_ = env.reset()\n",
    "        for i in range(200):\n",
    "            action = agent.predict_action(torch.tensor(state).unsqueeze(0))\n",
    "            next_state, reward, done, _,_ = env.step(action)  # 更新环境，返回transition\n",
    "            rewards += reward\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "        print(f'epoch: {epoch} : reward: {rewards}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "7bf61b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([1,3,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "7b0b465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq = torch.randn(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "50394ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5260, -0.9328],\n",
       "        [ 1.6860, -1.6825],\n",
       "        [-1.6531,  0.9750],\n",
       "        [ 1.0478, -0.9798]])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ee4a4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = torch.LongTensor(\n",
    "    [\n",
    "        [1],\n",
    "        [0],\n",
    "        [1],\n",
    "        [1]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "6dd6a5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "171433db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9328],\n",
       "        [ 1.6860],\n",
       "        [ 0.9750],\n",
       "        [-0.9798]])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(qq,1,indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "72a60b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9328],\n",
       "        [ 1.6860],\n",
       "        [ 0.9750],\n",
       "        [-0.9798]])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq.gather(1,indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acea299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9793606c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd98fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8147e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78968de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
