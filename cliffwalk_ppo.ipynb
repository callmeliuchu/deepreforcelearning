{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079ae293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f433a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建环境\n",
    "env = gym.make('CliffWalking-v0',render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22381a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9b85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6e0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca907a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e89cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46d2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim,200)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(200,output_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self,state):\n",
    "        ### n\n",
    "        x = self.linear1(state)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x) # n\n",
    "        x = self.softmax(x) # n\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d99dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNet(nn.Module):\n",
    "    ### 用来学习值\n",
    "    \n",
    "    def __init__(self,input_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim,200)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(200,1)\n",
    "    \n",
    "    def forward(self,state):\n",
    "        ### n\n",
    "        x = self.linear1(state)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x) # n\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0709fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "np.bool8 = np.bool_\n",
    "\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8320648",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.policy_net = PolicyNet(48,4)\n",
    "        self.value_net = ValueNet(48)\n",
    "        self.optimizer = AdamW(self.policy_net.parameters(),lr=1e-3)\n",
    "        self.value_optimizer = AdamW(self.value_net.parameters(),lr=1e-3)\n",
    "    \n",
    "    def sample_action(self,state):\n",
    "        probs = self.policy_net(state) # 4\n",
    "        if np.random.uniform() < 0.5:\n",
    "            action = np.random.randint(0,4)\n",
    "            return action, torch.log(probs[action]+1e-8).detach()\n",
    "        dist = Categorical(probs)\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action).detach()\n",
    "        return action.item(),log_prob\n",
    "    \n",
    "    def update(self,rewards,log_probs,xs,old_actions):\n",
    "        ### 一次游戏时间\n",
    "        ret = []\n",
    "        adding = 0\n",
    "        for r in rewards[::-1]:\n",
    "            adding = adding * 0.99 + r\n",
    "            ret.insert(0,adding)\n",
    "        ret = torch.FloatTensor(ret)\n",
    "        ret = ret - ret.mean()\n",
    "        ret = ret / (ret.std()+1e-8)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for _ in range(4):\n",
    "            values = self.value_net(xs) ## B,48 ==> B,1\n",
    "#             print(values.shape)\n",
    "\n",
    "            new_probs = self.policy_net(xs) ## B,4\n",
    "            dist = Categorical(new_probs) # B,4\n",
    "#             actions = dist.sample() # B,1\n",
    "            new_logprobs = dist.log_prob(old_actions.squeeze(-1)) # B,1\n",
    "#             print('new log probs',new_logprobs.shape)\n",
    "            advantages = ret - values.squeeze(-1).detach() # B\n",
    "#             print('adv shape',advantages.shape,'ret shape',ret.shape,'value shape',values.shape,'log',log_probs.shape)\n",
    "#             print('new_probs',new_probs.shape,'new_logprobs shape',new_logprobs.shape,'old_actions',old_actions.shape)\n",
    "            ratio = torch.exp(new_logprobs - log_probs.squeeze(-1)) ## B\n",
    "#             print('shape',ratio.shape)\n",
    "            surr1 = ratio * advantages.squeeze(-1)\n",
    "            surr2 = torch.clamp(ratio,0.8,1.2) * advantages\n",
    "            loss = -torch.min(surr1,surr2).mean()\n",
    "\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "\n",
    "            value_loss = (values.squeeze(0) - ret).pow(2).mean()\n",
    "            self.value_optimizer.zero_grad()\n",
    "            value_loss.backward()\n",
    "            self.value_optimizer.step()\n",
    "\n",
    "\n",
    "    #         r_log_probs = []\n",
    "    #         for r,log_prob in zip(ret,log_probs):\n",
    "    #             r_log_probs.append(-r*log_prob)\n",
    "    #         r_log_probs = torch.vstack(r_log_probs)\n",
    "\n",
    "    #         loss = r_log_probs.sum()\n",
    "\n",
    "\n",
    "\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b173633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2tensor(state):\n",
    "    state_arr = np.zeros(48)\n",
    "    state_arr[state] = 1\n",
    "    state_arr = torch.FloatTensor(state_arr)\n",
    "    return state_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e04e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env):\n",
    "    success_count = []\n",
    "    max_size = 1000\n",
    "    for epoch in range(200000):\n",
    "        rewards = []\n",
    "        xs = []\n",
    "        log_probs = []\n",
    "        old_actions = []\n",
    "        terminated = False\n",
    "        success = True\n",
    "        state,_ = env.reset()\n",
    "        while not terminated and len(log_probs) < max_size:\n",
    "            state_arr = convert2tensor(state)\n",
    "            xs.append(state_arr)\n",
    "            action, log_prob = agent.sample_action(state_arr)\n",
    "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            if reward == -100:\n",
    "                reward = -10\n",
    "                success = False\n",
    "            if reward == -1 and state == 47:\n",
    "                reward = 10\n",
    "            state = next_state\n",
    "            rewards.append(reward)\n",
    "            log_probs.append(log_prob)\n",
    "            old_actions.append(action)\n",
    "        xs = torch.vstack(xs)\n",
    "        log_probs = torch.vstack(log_probs)\n",
    "        old_actions = torch.LongTensor(old_actions)\n",
    "        loss = agent.update(rewards,log_probs,xs,old_actions) \n",
    "        success_count.append(success)\n",
    "        \n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'success rate:  {len([s for s in success_count[-100:] if s]) / 100}')\n",
    "            print(f'epoch: {epoch}, loss: {loss}, rewards: {sum(rewards)}, count: {len(rewards)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd4c7dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deb153a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate:  0.1\n",
      "epoch: 9, loss: -0.0021670260466635227, rewards: -232, count: 232\n",
      "success rate:  0.2\n",
      "epoch: 19, loss: -4.142966281506233e-05, rewards: -121, count: 121\n",
      "success rate:  0.3\n",
      "epoch: 29, loss: -3.549348912201822e-05, rewards: -332, count: 332\n",
      "success rate:  0.4\n",
      "epoch: 39, loss: 0.043539464473724365, rewards: -221, count: 221\n",
      "success rate:  0.5\n",
      "epoch: 49, loss: -3.709710290422663e-05, rewards: -202, count: 202\n",
      "success rate:  0.6\n",
      "epoch: 59, loss: -0.004479533061385155, rewards: -22, count: 22\n",
      "success rate:  0.7\n",
      "epoch: 69, loss: -0.0008025957504287362, rewards: -413, count: 413\n",
      "success rate:  0.8\n",
      "epoch: 79, loss: -7.551795988547383e-07, rewards: -212, count: 212\n",
      "success rate:  0.9\n",
      "epoch: 89, loss: -3.5992036373500014e-07, rewards: -26, count: 26\n",
      "success rate:  0.99\n",
      "epoch: 99, loss: 6.308158049250778e-07, rewards: -48, count: 48\n",
      "success rate:  0.99\n",
      "epoch: 109, loss: -2.554484801464696e-08, rewards: -35, count: 35\n",
      "success rate:  0.99\n",
      "epoch: 119, loss: -8.195011469069868e-05, rewards: -38, count: 38\n",
      "success rate:  0.99\n",
      "epoch: 129, loss: -5.185603981772147e-07, rewards: -40, count: 40\n",
      "success rate:  0.99\n",
      "epoch: 139, loss: 1.110813840909941e-07, rewards: -22, count: 22\n",
      "success rate:  0.99\n",
      "epoch: 149, loss: -0.00012525200145319104, rewards: -50, count: 50\n",
      "success rate:  0.99\n",
      "epoch: 159, loss: -0.00015210041601676494, rewards: -56, count: 56\n",
      "success rate:  0.99\n",
      "epoch: 169, loss: -1.758337049295733e-07, rewards: -20, count: 20\n",
      "success rate:  0.98\n",
      "epoch: 179, loss: -4.294591064990527e-07, rewards: -78, count: 78\n",
      "success rate:  0.98\n",
      "epoch: 189, loss: -2.0907475573039846e-07, rewards: -65, count: 65\n",
      "success rate:  0.99\n",
      "epoch: 199, loss: -5.414088377619919e-07, rewards: -24, count: 24\n",
      "success rate:  0.99\n",
      "epoch: 209, loss: 1.7285346984863281e-06, rewards: -50, count: 50\n",
      "success rate:  0.99\n",
      "epoch: 219, loss: 2.593410272311303e-06, rewards: -49, count: 49\n",
      "success rate:  0.99\n",
      "epoch: 229, loss: -2.1431756067613605e-06, rewards: -23, count: 23\n",
      "success rate:  0.99\n",
      "epoch: 239, loss: -9.01222222182696e-07, rewards: -25, count: 25\n",
      "success rate:  0.99\n",
      "epoch: 249, loss: 2.086162567138672e-07, rewards: -44, count: 44\n",
      "success rate:  0.99\n",
      "epoch: 259, loss: -0.00013801787281408906, rewards: -27, count: 27\n",
      "success rate:  0.99\n",
      "epoch: 269, loss: -2.587383391983167e-07, rewards: -22, count: 22\n",
      "success rate:  0.98\n",
      "epoch: 279, loss: -5.64824972570932e-07, rewards: -21, count: 21\n",
      "success rate:  0.98\n",
      "epoch: 289, loss: 1.0686485438782256e-05, rewards: -38, count: 38\n",
      "success rate:  0.98\n",
      "epoch: 299, loss: 1.1833090866275597e-05, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 309, loss: 2.4295370621985057e-06, rewards: -23, count: 23\n",
      "success rate:  0.98\n",
      "epoch: 319, loss: 3.623962356869015e-06, rewards: -25, count: 25\n",
      "success rate:  0.98\n",
      "epoch: 329, loss: -2.5441249817959033e-05, rewards: -21, count: 21\n",
      "success rate:  0.98\n",
      "epoch: 339, loss: -1.658434484852478e-05, rewards: -23, count: 23\n",
      "success rate:  0.98\n",
      "epoch: 349, loss: -4.852519396081334e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 359, loss: 8.127268301905133e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 369, loss: 0.004358347039669752, rewards: -39, count: 30\n",
      "success rate:  0.98\n",
      "epoch: 379, loss: 9.024844075611327e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 389, loss: 6.58184308122145e-06, rewards: -20, count: 20\n",
      "success rate:  0.98\n",
      "epoch: 399, loss: 9.548001980874687e-05, rewards: -18, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 409, loss: -3.0412393243750557e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 419, loss: -7.440062290697824e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 429, loss: 2.192823558289092e-05, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 439, loss: 1.141760094469646e-05, rewards: -18, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 449, loss: -1.3702056094189174e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 459, loss: 7.740340515738353e-05, rewards: -22, count: 22\n",
      "success rate:  0.99\n",
      "epoch: 469, loss: 5.301307282934431e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 479, loss: 1.2035171494062524e-05, rewards: -24, count: 24\n",
      "success rate:  0.99\n",
      "epoch: 489, loss: -6.635487079620361e-05, rewards: -24, count: 24\n",
      "success rate:  0.99\n",
      "epoch: 499, loss: 1.3203997696109582e-05, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 509, loss: -8.443991646345239e-06, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 519, loss: 2.2116830223239958e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 529, loss: -6.696757282043109e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 539, loss: -4.56364250567276e-06, rewards: -23, count: 23\n",
      "success rate:  0.98\n",
      "epoch: 549, loss: 1.9704593796632253e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 559, loss: -5.642572887154529e-06, rewards: -27, count: 27\n",
      "success rate:  0.98\n",
      "epoch: 569, loss: 5.729058102588169e-06, rewards: -34, count: 34\n",
      "success rate:  0.99\n",
      "epoch: 579, loss: -1.999593905566144e-06, rewards: -21, count: 21\n",
      "success rate:  0.99\n",
      "epoch: 589, loss: -7.947286206899662e-08, rewards: -24, count: 24\n",
      "success rate:  0.99\n",
      "epoch: 599, loss: 0.026665672659873962, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 609, loss: -9.116004662246269e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 619, loss: 4.893855020782212e-06, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 629, loss: -1.0399257007520646e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 639, loss: 6.640658739343053e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 649, loss: -4.307925792090828e-06, rewards: -20, count: 20\n",
      "success rate:  0.99\n",
      "epoch: 659, loss: -1.1462431359632319e-07, rewards: -26, count: 26\n",
      "success rate:  0.99\n",
      "epoch: 669, loss: 7.90907790815254e-07, rewards: -26, count: 26\n",
      "success rate:  0.99\n",
      "epoch: 679, loss: -1.831187091738684e-06, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 689, loss: 1.268386881747574e-06, rewards: -25, count: 25\n",
      "success rate:  0.99\n",
      "epoch: 699, loss: -7.372153163487383e-07, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 709, loss: 1.5406505553983152e-05, rewards: -23, count: 23\n",
      "success rate:  0.99\n",
      "epoch: 719, loss: -1.2195110684842803e-05, rewards: -20, count: 20\n",
      "success rate:  0.99\n",
      "epoch: 729, loss: 7.692136023251805e-06, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 739, loss: -4.423292011779267e-06, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 749, loss: 1.0574564839771483e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 759, loss: -4.441597775439732e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 769, loss: 2.2265645384322852e-05, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 779, loss: -1.4599826499761548e-05, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 789, loss: 1.567952858749777e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 799, loss: -5.44856584383524e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 809, loss: 1.6268561466858955e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 819, loss: 3.7165250432735775e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 829, loss: 1.4789402484893799e-06, rewards: -32, count: 32\n",
      "success rate:  0.99\n",
      "epoch: 839, loss: 4.2007081901829224e-07, rewards: -21, count: 21\n",
      "success rate:  0.99\n",
      "epoch: 849, loss: -1.7194644215123844e-06, rewards: -23, count: 23\n",
      "success rate:  0.99\n",
      "epoch: 859, loss: 1.890318685582315e-06, rewards: -21, count: 21\n",
      "success rate:  0.99\n",
      "epoch: 869, loss: -1.5927685126371216e-06, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 879, loss: -2.5735182589414762e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 889, loss: 2.5244319203920895e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 899, loss: -1.8694183836487355e-06, rewards: -22, count: 22\n",
      "success rate:  0.99\n",
      "epoch: 909, loss: 0.015003652311861515, rewards: -33, count: 33\n",
      "success rate:  0.99\n",
      "epoch: 919, loss: 1.712849211799039e-06, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 929, loss: 5.118986905472411e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 939, loss: -6.109476089477539e-07, rewards: -24, count: 24\n",
      "success rate:  0.99\n",
      "epoch: 949, loss: 1.2546777270472376e-06, rewards: -20, count: 20\n",
      "success rate:  0.99\n",
      "epoch: 959, loss: -2.2120097128208727e-05, rewards: -22, count: 22\n",
      "success rate:  0.99\n",
      "epoch: 969, loss: -1.1219697626074776e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 979, loss: 2.86102294921875e-05, rewards: -18, count: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate:  0.97\n",
      "epoch: 989, loss: 1.4131409443507437e-05, rewards: -44, count: 35\n",
      "success rate:  0.97\n",
      "epoch: 999, loss: -1.6732796211726964e-05, rewards: -37, count: 37\n",
      "success rate:  0.96\n",
      "epoch: 1009, loss: -1.5368064850918017e-05, rewards: -21, count: 21\n",
      "success rate:  0.96\n",
      "epoch: 1019, loss: 1.2699295439233538e-05, rewards: -17, count: 17\n",
      "success rate:  0.95\n",
      "epoch: 1029, loss: 1.3030387890466955e-05, rewards: -22, count: 22\n",
      "success rate:  0.95\n",
      "epoch: 1039, loss: 3.680762165458873e-05, rewards: -17, count: 17\n",
      "success rate:  0.95\n",
      "epoch: 1049, loss: 1.0227615348412655e-05, rewards: -22, count: 22\n",
      "success rate:  0.94\n",
      "epoch: 1059, loss: -3.333389759063721e-05, rewards: -20, count: 20\n",
      "success rate:  0.94\n",
      "epoch: 1069, loss: 0.7994296550750732, rewards: -19, count: 19\n",
      "success rate:  0.94\n",
      "epoch: 1079, loss: -1.8080075960824615e-06, rewards: -18, count: 18\n",
      "success rate:  0.96\n",
      "epoch: 1089, loss: 1.961986163223628e-05, rewards: -18, count: 18\n",
      "success rate:  0.96\n",
      "epoch: 1099, loss: 4.579039341479074e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1109, loss: 1.6202529877773486e-05, rewards: -18, count: 18\n",
      "success rate:  0.97\n",
      "epoch: 1119, loss: -4.793468178831972e-06, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 1129, loss: -5.845228770340327e-06, rewards: -30, count: 30\n",
      "success rate:  0.98\n",
      "epoch: 1139, loss: -4.220009031996597e-06, rewards: -20, count: 20\n",
      "success rate:  0.98\n",
      "epoch: 1149, loss: -3.8084231164248195e-06, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 1159, loss: -2.7305939511279576e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1169, loss: -3.2901763916015625e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1179, loss: -1.4702479347761255e-05, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 1189, loss: -3.1415154353453545e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1199, loss: -4.172325134277344e-05, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 1209, loss: -9.52973095991183e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 1219, loss: 3.591004497138783e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 1229, loss: 1.5048419300001115e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 1239, loss: -1.2769418390234932e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 1249, loss: 1.329481619904982e-05, rewards: -20, count: 20\n",
      "success rate:  1.0\n",
      "epoch: 1259, loss: 3.6390204058989184e-06, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 1269, loss: 7.5873208515986335e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 1279, loss: 7.1104836933955085e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 1289, loss: -1.1864830412378069e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 1299, loss: 4.503461923377472e-07, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 1309, loss: -2.9003078907408053e-06, rewards: -22, count: 22\n",
      "success rate:  0.98\n",
      "epoch: 1319, loss: 5.841255187988281e-06, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 1329, loss: 1.2019276255159639e-05, rewards: -20, count: 20\n",
      "success rate:  0.98\n",
      "epoch: 1339, loss: 5.772168151452206e-06, rewards: -22, count: 22\n",
      "success rate:  0.98\n",
      "epoch: 1349, loss: 7.899034244474024e-06, rewards: -21, count: 21\n",
      "success rate:  0.98\n",
      "epoch: 1359, loss: 9.70928249444114e-06, rewards: -19, count: 19\n",
      "success rate:  0.97\n",
      "epoch: 1369, loss: -2.762850499493652e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 1379, loss: -7.3909759521484375e-06, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 1389, loss: 0.004622467327862978, rewards: -40, count: 31\n",
      "success rate:  0.96\n",
      "epoch: 1399, loss: -5.364418029785156e-07, rewards: -18, count: 18\n",
      "success rate:  0.97\n",
      "epoch: 1409, loss: -1.1009328773070592e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1419, loss: -4.4878791527480644e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1429, loss: 1.7745928744261619e-06, rewards: -22, count: 22\n",
      "success rate:  0.98\n",
      "epoch: 1439, loss: 4.130251454625977e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 1449, loss: -4.3660401161105256e-07, rewards: -20, count: 20\n",
      "success rate:  0.97\n",
      "epoch: 1459, loss: -9.116004662246269e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1469, loss: 8.975758305496129e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1479, loss: -0.003503771498799324, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1489, loss: -3.708811345859431e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1499, loss: -1.9781729861279018e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1509, loss: 6.333777946565533e-06, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 1519, loss: -2.576245151431067e-06, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 1529, loss: -6.40224016024149e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 1539, loss: -6.563523129443638e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1549, loss: 4.3476327959979244e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1559, loss: 6.731818871230644e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1569, loss: 7.783665409988316e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1579, loss: -1.0917061672444106e-06, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 1589, loss: -4.62812522528111e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1599, loss: 3.1906015465210658e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1609, loss: 1.1289821486570872e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1619, loss: 3.939553425880149e-05, rewards: -19, count: 19\n",
      "success rate:  0.97\n",
      "epoch: 1629, loss: 3.368013130966574e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1639, loss: -7.063501107040793e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1649, loss: 7.012817513896152e-05, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 1659, loss: 7.376951543847099e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1669, loss: -2.42205223912606e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1679, loss: 2.0749428585986607e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1689, loss: -1.18578182082274e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1699, loss: 4.093787356396206e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1709, loss: 3.2040807127486914e-05, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 1719, loss: -4.918434933642857e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1729, loss: 5.911526022828184e-05, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 1739, loss: -3.133801874355413e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1749, loss: -5.683478229911998e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1759, loss: -5.541977225220762e-05, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 1769, loss: -8.751364657655358e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1779, loss: 0.23102042078971863, rewards: -20, count: 20\n",
      "success rate:  0.98\n",
      "epoch: 1789, loss: 5.5803971918066964e-05, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 1799, loss: 5.450513526739087e-06, rewards: -18, count: 18\n",
      "success rate:  0.97\n",
      "epoch: 1809, loss: -0.00010281450522597879, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 1819, loss: 1.539202276035212e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1829, loss: 4.086073749931529e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1839, loss: -3.1555400710203685e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1849, loss: -9.541651525069028e-05, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 1859, loss: -0.00011414640175644308, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1869, loss: -4.6438639401458204e-05, rewards: -18, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 1879, loss: 7.956869376357645e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1889, loss: 2.560896064096596e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1899, loss: -2.4199485778808594e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1909, loss: -2.4178449166356586e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1919, loss: -8.993288793135434e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1929, loss: -6.351345655275509e-05, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 1939, loss: -7.919704512460157e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1949, loss: 1.591093314345926e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1959, loss: 3.405879397178069e-05, rewards: -17, count: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate:  0.99\n",
      "epoch: 1969, loss: 1.4129806913842913e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 1979, loss: -1.2068187061231583e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 1989, loss: -5.1372189773246646e-05, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 1999, loss: 0.03667224943637848, rewards: -38, count: 29\n",
      "success rate:  0.95\n",
      "epoch: 2009, loss: 3.4844175388570875e-05, rewards: -17, count: 17\n",
      "success rate:  0.95\n",
      "epoch: 2019, loss: 9.038869393407367e-06, rewards: -17, count: 17\n",
      "success rate:  0.95\n",
      "epoch: 2029, loss: -2.2600679585593753e-05, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 2039, loss: -6.472363111242885e-06, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 2049, loss: 5.5775923101464286e-05, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 2059, loss: 9.186127499560826e-06, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 2069, loss: -8.57605664350558e-06, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 2079, loss: -5.630885880236747e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 2089, loss: 1.2383741704979911e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2099, loss: 9.608896107238252e-06, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 2109, loss: -4.677211563830497e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2119, loss: 1.0013580322265625e-05, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 2129, loss: -2.8327892778179375e-06, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 2139, loss: 9.186127840621339e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2149, loss: 4.0250665733765345e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2159, loss: -2.7418136596679688e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2169, loss: 4.69824840365618e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2179, loss: -7.853788588363386e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2189, loss: -1.2972775493835798e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 2199, loss: 6.703769486193778e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 2209, loss: -1.2692282780335518e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2219, loss: 4.2494607441767585e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2229, loss: -2.0125332866882673e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2239, loss: -8.344650268554688e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2249, loss: -9.045881483871199e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2259, loss: -1.1009328773070592e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2269, loss: 2.5665058274171315e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2279, loss: -7.0123111761688506e-09, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2289, loss: -8.765388770370919e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2299, loss: 7.573295874863106e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2309, loss: -3.17587582685519e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 2319, loss: 1.6080704881460406e-05, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 2329, loss: 1.660515226831194e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 2339, loss: 1.0988291251123883e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2349, loss: 1.8743907276075333e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2359, loss: -3.38484242092818e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2369, loss: 0.2873421311378479, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 2379, loss: -2.6864163373829797e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2389, loss: 0.0001178629245259799, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2399, loss: -3.1281921110348776e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2409, loss: 1.958538450708147e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2419, loss: 3.57347380486317e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2429, loss: 2.631720417411998e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2439, loss: -5.136517938808538e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2449, loss: 3.8203070289455354e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2459, loss: -6.177845989441266e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2469, loss: 4.331504533183761e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2479, loss: 5.434540980786551e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2489, loss: 3.2046260457718745e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2499, loss: -4.030842683278024e-05, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 2509, loss: 8.884598173608538e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2519, loss: -4.3392181396484375e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2529, loss: 8.315475133713335e-05, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 2539, loss: -4.8279762268066406e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 2549, loss: 1.4220967386791017e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 2559, loss: 2.655562275322154e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 2569, loss: -2.4318695068359375e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 2579, loss: 2.4808081434457563e-05, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 2589, loss: 0.9393667578697205, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 2599, loss: 9.49537061387673e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2609, loss: -4.778188667842187e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2619, loss: 2.1123223632457666e-05, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 2629, loss: -2.8806574846385047e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2639, loss: 3.8574722566409037e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2649, loss: -9.712050996313337e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2659, loss: 1.0104740795213729e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2669, loss: -9.936445167113561e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2679, loss: 3.821709469775669e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 2689, loss: 4.49489152742899e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 2699, loss: -3.676665528473677e-06, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 2709, loss: -4.235435881128069e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 2719, loss: 0.2223012000322342, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 2729, loss: 5.679971764038783e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2739, loss: 8.609559927208466e-07, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 2749, loss: -0.00014716386795043945, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 2759, loss: -7.573295874863106e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2769, loss: -7.012311442622376e-08, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2779, loss: -2.4613211735413643e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2789, loss: -3.786647937431553e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2799, loss: -1.2622160738828825e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 2809, loss: -1.0666094141242866e-07, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 2819, loss: -3.085417006332136e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2829, loss: 2.3179583763521805e-07, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 2839, loss: 1.8933239687157766e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2849, loss: 9.81723587756278e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2859, loss: -9.60686634243757e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2869, loss: -4.2775099018399487e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2879, loss: 2.314062612640555e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2889, loss: 8.260502909251954e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2899, loss: 2.1317426217137836e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2909, loss: 2.4613211735413643e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2919, loss: 2.0204484826535918e-05, rewards: -20, count: 20\n",
      "success rate:  0.98\n",
      "epoch: 2929, loss: -1.116359908337472e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2939, loss: 2.3350996798399137e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2949, loss: 8.470871762256138e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 2959, loss: -2.860321728803683e-05, rewards: -17, count: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate:  0.97\n",
      "epoch: 2969, loss: 3.195510362274945e-05, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 2979, loss: -3.5545406717574224e-05, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 2989, loss: -0.00023607646289747208, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 2999, loss: -0.00024008049513213336, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3009, loss: -9.400003182236105e-05, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 3019, loss: 4.100799560546875e-05, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3029, loss: -0.00010611029574647546, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3039, loss: 0.00015987534425221384, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 3049, loss: -0.00016066606622189283, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 3059, loss: -3.637987174442969e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 3069, loss: 0.00016046271775849164, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3079, loss: 6.250331352930516e-05, rewards: -19, count: 19\n",
      "success rate:  0.96\n",
      "epoch: 3089, loss: -3.256517447880469e-05, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 3099, loss: -5.8917437854688615e-05, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 3109, loss: -5.520792547031306e-05, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3119, loss: -9.066918210010044e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3129, loss: -9.02348074305337e-06, rewards: -18, count: 18\n",
      "success rate:  0.97\n",
      "epoch: 3139, loss: -2.6787029128172435e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3149, loss: 3.295786200396833e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3159, loss: -1.3669331565324683e-05, rewards: -18, count: 18\n",
      "success rate:  0.97\n",
      "epoch: 3169, loss: 6.2970552789920475e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3179, loss: 8.463859558105469e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 3189, loss: 1.672436155786272e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 3199, loss: -1.0679749721020926e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 3209, loss: -4.459830051928293e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 3219, loss: -6.170834012664272e-07, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3229, loss: 2.6015675302915042e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3239, loss: -2.7894973754882812e-05, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3249, loss: -1.0805971214722376e-05, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 3259, loss: 9.207164112012833e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 3269, loss: 5.762828095612349e-06, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 3279, loss: -3.676665528473677e-06, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 3289, loss: 3.850459961540764e-06, rewards: -20, count: 20\n",
      "success rate:  0.99\n",
      "epoch: 3299, loss: -3.2887739962461637e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3309, loss: 2.0966811007383512e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3319, loss: -2.2579642973141745e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3329, loss: -1.2208433872729074e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3339, loss: 1.0693774129322264e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3349, loss: -5.947507020209741e-07, rewards: -23, count: 23\n",
      "success rate:  1.0\n",
      "epoch: 3359, loss: 5.365837296267273e-06, rewards: -21, count: 21\n",
      "success rate:  1.0\n",
      "epoch: 3369, loss: -4.684223767981166e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3379, loss: 5.8482673921389505e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3389, loss: -1.1675498171825893e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3399, loss: 3.975980234827148e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3409, loss: 8.31660145195201e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3419, loss: 1.4536910839524353e-06, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 3429, loss: 0.10692264139652252, rewards: -39, count: 30\n",
      "success rate:  0.99\n",
      "epoch: 3439, loss: -7.4190252234984655e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3449, loss: 1.2616316098501557e-06, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 3459, loss: -8.17635464045452e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3469, loss: 4.76837158203125e-07, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 3479, loss: -9.27728797250893e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3489, loss: 1.3652969755639788e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3499, loss: -9.5367431640625e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3509, loss: -2.2930257728148717e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3519, loss: 2.1443647710839286e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3529, loss: 0.20224925875663757, rewards: -37, count: 28\n",
      "success rate:  0.99\n",
      "epoch: 3539, loss: 0.07382319122552872, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 3549, loss: -5.329356554284459e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3559, loss: 0.07596413791179657, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3569, loss: -1.3414551176538225e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3579, loss: -9.368447535962332e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3589, loss: -6.7738924371951725e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3599, loss: 1.1998064110230189e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3609, loss: 4.8272748244926333e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3619, loss: -1.0329134056519251e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3629, loss: -7.601345259899972e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3639, loss: -7.958973583299667e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3649, loss: -8.75560817803489e-06, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 3659, loss: 4.063634332851507e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3669, loss: 6.264798867050558e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3679, loss: 1.6927719116210938e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3689, loss: 4.8665438043826725e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3699, loss: 1.93259293155279e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3709, loss: 2.2649765014648438e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3719, loss: 1.1808731869678013e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3729, loss: 4.0629329305374995e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3739, loss: -1.674539817031473e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3749, loss: 4.2606803617672995e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3759, loss: -3.493533586151898e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3769, loss: 1.6171681636478752e-05, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 3779, loss: 4.107110726181418e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3789, loss: 4.449311381904408e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3799, loss: 1.569355299579911e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3809, loss: 7.068409558996791e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3819, loss: 1.7341444618068635e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3829, loss: 2.8820597890444333e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3839, loss: 1.171055919257924e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3849, loss: -3.6029254260938615e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3859, loss: -5.04185163663351e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3869, loss: 2.5524811917421175e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3879, loss: 4.212061412545154e-06, rewards: -21, count: 21\n",
      "success rate:  1.0\n",
      "epoch: 3889, loss: -5.336368758435128e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3899, loss: 4.543977411231026e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3909, loss: -5.000516011932632e-06, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 3919, loss: -6.0726615629391745e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 3929, loss: 7.482135970349191e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3939, loss: -1.1100488336523995e-05, rewards: -17, count: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate:  0.99\n",
      "epoch: 3949, loss: 2.3057064026943408e-05, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 3959, loss: -2.7060508728027344e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3969, loss: 4.377084769657813e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 3979, loss: -0.00014030933380126953, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 3989, loss: -0.0001513677416369319, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 3999, loss: -0.0002603601024020463, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4009, loss: -0.00024473335361108184, rewards: -18, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 4019, loss: 0.00011493878992041573, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4029, loss: 9.954677079804242e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4039, loss: 2.4907729311962612e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4049, loss: 3.0293183954199776e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4059, loss: -5.259233262222551e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4069, loss: -4.718491982202977e-05, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 4079, loss: -2.1731151718995534e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4089, loss: -1.4270052815845702e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4099, loss: -1.4536521121044643e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4109, loss: -8.947708920459263e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4119, loss: -9.214878446073271e-06, rewards: -20, count: 20\n",
      "success rate:  1.0\n",
      "epoch: 4129, loss: -3.933906555175781e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4139, loss: -3.94793096347712e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4149, loss: -7.994034945113526e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4159, loss: -1.612831539432591e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4169, loss: -1.1500189884827705e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4179, loss: -1.6899670072234585e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4189, loss: -1.1219698308195802e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4199, loss: 3.2562959404458525e-06, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 4209, loss: -6.872064659546595e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4219, loss: 9.116004662246269e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4229, loss: -1.3042898672210868e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4239, loss: -7.503172696488036e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4249, loss: -3.295786257240252e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4259, loss: 4.9086178677271164e-08, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4269, loss: -6.430678695323877e-06, rewards: -18, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 4279, loss: -1.6871621483005583e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4289, loss: -1.5076468571351143e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4299, loss: 3.3027986319211777e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4309, loss: -2.784861408144934e-06, rewards: -18, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 4319, loss: 6.311079800980224e-07, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4329, loss: 2.0686318293883232e-06, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 4339, loss: -4.90160527988337e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4349, loss: 2.6716904812928988e-06, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 4359, loss: 2.846998313543736e-06, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 4369, loss: 7.483694162147003e-07, rewards: -18, count: 18\n",
      "success rate:  0.97\n",
      "epoch: 4379, loss: -8.765388770370919e-07, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4389, loss: -3.295786257240252e-07, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4399, loss: 4.4878791527480644e-07, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 4409, loss: -5.750094942413853e-07, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 4419, loss: 1.0038677373813698e-06, rewards: -19, count: 19\n",
      "success rate:  0.97\n",
      "epoch: 4429, loss: -9.5367431640625e-07, rewards: -18, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 4439, loss: -8.414773446929757e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4449, loss: 6.311080369414412e-08, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4459, loss: 2.3771735868649557e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4469, loss: -9.67698952081264e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4479, loss: 1.3113021850585938e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4489, loss: -2.6633865672920365e-06, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 4499, loss: 2.8119368380430387e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4509, loss: -7.000390178291127e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4519, loss: 1.0181875950365793e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4529, loss: 4.011743294540793e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4539, loss: -1.3807240975438617e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4549, loss: -1.1528793038451113e-05, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 4559, loss: 2.821052839863114e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4569, loss: -4.4286251068115234e-05, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 4579, loss: 3.36766242980957e-05, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 4589, loss: -1.7460653907619417e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4599, loss: 3.361000563018024e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4609, loss: -1.921373268487514e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4619, loss: -1.677344880590681e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4629, loss: 1.1121525858470704e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4639, loss: 2.9521829674195033e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4649, loss: -2.8049245770489506e-07, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4659, loss: 1.1490451470308471e-06, rewards: -18, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 4669, loss: -4.078212441527285e-06, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 4679, loss: 6.372278221533634e-06, rewards: -22, count: 22\n",
      "success rate:  0.98\n",
      "epoch: 4689, loss: -1.4936222214601003e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4699, loss: -1.8091762967742397e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4709, loss: 1.584228698447987e-06, rewards: -19, count: 19\n",
      "success rate:  0.97\n",
      "epoch: 4719, loss: 6.521449336105434e-07, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4729, loss: -3.2186508178710938e-06, rewards: -17, count: 17\n",
      "success rate:  0.96\n",
      "epoch: 4739, loss: 2.7418136596679688e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4749, loss: -8.977160905487835e-05, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4759, loss: 4.809043093700893e-05, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4769, loss: 1.3014849173487164e-05, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 4779, loss: 0.000393785914639011, rewards: -19, count: 19\n",
      "success rate:  0.97\n",
      "epoch: 4789, loss: -0.0002525764284655452, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4799, loss: 5.613355097011663e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4809, loss: 0.00015404645819216967, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 4819, loss: -4.536965207080357e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4829, loss: -3.9689679397270083e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4839, loss: -1.3961511285742745e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4849, loss: -9.228201633959543e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4859, loss: 9.522718755761161e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4869, loss: 1.0315109648217913e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4879, loss: 1.6619177358734305e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4889, loss: -2.6716904812928988e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4899, loss: 0.7048923373222351, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 4909, loss: 0.5099852681159973, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 4919, loss: 3.5762786865234375e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 4929, loss: -0.00020214130927342921, rewards: -19, count: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate:  1.0\n",
      "epoch: 4939, loss: -4.492787775234319e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4949, loss: 8.15812309156172e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4959, loss: 2.6737941880128346e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4969, loss: -1.7530388504383154e-05, rewards: -18, count: 18\n",
      "success rate:  1.0\n",
      "epoch: 4979, loss: 9.817235735454233e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4989, loss: -5.329356440597621e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 4999, loss: 3.814697265625e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5009, loss: -1.2649429663724732e-06, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 5019, loss: -1.430511474609375e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5029, loss: -2.0298693925724365e-06, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 5039, loss: -3.085417006332136e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5049, loss: -0.0, rewards: -18, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 5059, loss: 0.7663184404373169, rewards: -20, count: 20\n",
      "success rate:  0.98\n",
      "epoch: 5069, loss: 8.344650268554688e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5079, loss: -4.956596626470855e-07, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 5089, loss: -1.0728836059570312e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5099, loss: 5.6098489409350805e-08, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5109, loss: -2.314062612640555e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5119, loss: 3.365909435615322e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5129, loss: -6.591572514480504e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5139, loss: 2.5945550419237406e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5149, loss: -4.137263545089809e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5159, loss: 7.0123111761688506e-09, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5169, loss: -3.506155721311188e-08, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5179, loss: 3.7165250432735775e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5189, loss: -7.853788588363386e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5199, loss: -0.0, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5209, loss: 4.6690306021446304e-07, rewards: -18, count: 18\n",
      "success rate:  1.0\n",
      "epoch: 5219, loss: -7.152557373046875e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5229, loss: 8.414773589038305e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5239, loss: -7.0123111761688506e-09, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5249, loss: 6.311080369414412e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5259, loss: 7.0123111761688506e-09, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5269, loss: -4.9086178677271164e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5279, loss: 6.311080369414412e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5289, loss: 2.103693397259576e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5299, loss: -5.750094942413853e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5309, loss: 9.74711269918771e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5319, loss: -1.002760541268799e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5329, loss: 4.207386794519152e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5339, loss: -1.504307647337555e-07, rewards: -21, count: 21\n",
      "success rate:  1.0\n",
      "epoch: 5349, loss: 6.311080369414412e-08, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5359, loss: 0.016048112884163857, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 5369, loss: -1.2481914382078685e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5379, loss: 2.1036933617324394e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5389, loss: -5.750094942413853e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5399, loss: -3.997017472556763e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5409, loss: 1.0658712881195243e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5419, loss: -2.6646782202988106e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5429, loss: 5.469602797347761e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5439, loss: 5.082080178908654e-07, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 5449, loss: 4.207386794519152e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5459, loss: -7.082434194671805e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5469, loss: -3.015293827957066e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5479, loss: 7.012311442622376e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5489, loss: 2.0335701833573694e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5499, loss: -4.207386723464879e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5509, loss: 6.801942049605714e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5519, loss: -1.9634471470908466e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5529, loss: 1.8933239687157766e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5539, loss: 4.4177559743729944e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5549, loss: -3.506155721311188e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5559, loss: -2.3815366148483008e-05, rewards: -18, count: 18\n",
      "success rate:  1.0\n",
      "epoch: 5569, loss: -5.7360703067388386e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5579, loss: 1.4690791431348771e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5589, loss: 1.1780682598327985e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5599, loss: -5.196122401684988e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5609, loss: 3.3869462185975863e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5619, loss: 1.9564347439882113e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5629, loss: -1.7320408005616628e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5639, loss: -2.2299150259641465e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5649, loss: -6.528127727278843e-08, rewards: -21, count: 21\n",
      "success rate:  0.99\n",
      "epoch: 5659, loss: 2.6646782202988106e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5669, loss: -1.1219697881870161e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5679, loss: -1.291433932237851e-06, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 5689, loss: 5.6322882301174104e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5699, loss: 0.4683620035648346, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 5709, loss: 4.082918167114258e-06, rewards: -21, count: 21\n",
      "success rate:  0.99\n",
      "epoch: 5719, loss: -1.128982057707617e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5729, loss: -9.073930414160714e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5739, loss: -2.6436412099428708e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5749, loss: 1.5497207641601562e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5759, loss: 7.222680551421945e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5769, loss: 4.3476327959979244e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5779, loss: 1.682954717807661e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5789, loss: -4.207386794519152e-08, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5799, loss: 0.0505380779504776, rewards: -39, count: 30\n",
      "success rate:  0.98\n",
      "epoch: 5809, loss: 3.856771115806623e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5819, loss: 3.510051271859993e-07, rewards: -18, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 5829, loss: 1.7975505670619896e-06, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 5839, loss: -2.4192472665163223e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5849, loss: -1.8676122408578522e-06, rewards: -21, count: 21\n",
      "success rate:  0.98\n",
      "epoch: 5859, loss: -7.713542231613246e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5869, loss: -5.750094942413853e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5879, loss: -1.0518466524445103e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 5889, loss: -5.259233262222551e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5899, loss: 0.7046831250190735, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 5909, loss: -6.942187837921665e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5919, loss: 6.311080369414412e-08, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5929, loss: 1.2201421668578405e-06, rewards: -17, count: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate:  0.99\n",
      "epoch: 5939, loss: 4.3476327959979244e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5949, loss: 2.0077354179193208e-07, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 5959, loss: 5.6098489409350805e-08, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 5969, loss: 9.817235735454233e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5979, loss: 1.4024622352337701e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5989, loss: 1.472585324790998e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 5999, loss: -4.207386794519152e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6009, loss: -1.4024622352337701e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6019, loss: 1.3323391101494053e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6029, loss: 7.020102543719986e-07, rewards: -18, count: 18\n",
      "success rate:  1.0\n",
      "epoch: 6039, loss: 4.9086178677271164e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6049, loss: 2.945170649581996e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6059, loss: 1.542708503166068e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6069, loss: -1.7253976238862379e-06, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 6079, loss: -6.100710834289202e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6089, loss: 4.207386794519152e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6099, loss: -7.0123111761688506e-09, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6109, loss: -1.4024622352337701e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6119, loss: -1.472585324790998e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6129, loss: -1.682954717807661e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6139, loss: 6.451326157730364e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6149, loss: -7.082434194671805e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6159, loss: 4.067140366714739e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6169, loss: -4.62812522528111e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6179, loss: 3.085417006332136e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6189, loss: -2.8049244704675402e-08, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6199, loss: -1.4024622352337701e-08, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6209, loss: 8.414773589038305e-08, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6219, loss: 7.012311442622376e-08, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6229, loss: 2.945170649581996e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6239, loss: -2.6646782202988106e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6249, loss: 3.5061555081483675e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6259, loss: -2.8547486863317317e-07, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 6269, loss: 2.8049244704675402e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6279, loss: -7.0123111761688506e-09, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6289, loss: 1.472585324790998e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6299, loss: 5.118986905472411e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6309, loss: 3.295786257240252e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6319, loss: -2.8049245770489506e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6329, loss: 5.890341299163993e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6339, loss: -2.8750474712069263e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6349, loss: 8.783842417869892e-07, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 6359, loss: -0.0, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6369, loss: 2.103693397259576e-08, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6379, loss: -4.207386794519152e-08, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6389, loss: -1.9634471470908466e-07, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 6399, loss: 2.945170649581996e-07, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 6409, loss: 9.116004662246269e-08, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 6419, loss: 2.8049245770489506e-07, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 6429, loss: -2.1036933617324394e-07, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 6439, loss: -5.399479618972691e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6449, loss: -3.4360323297732975e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6459, loss: 0.6004591584205627, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 6469, loss: -7.503172696488036e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6479, loss: -3.225663078865182e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6489, loss: 1.612831539432591e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6499, loss: 0.050139494240283966, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 6509, loss: 0.6062923669815063, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 6519, loss: 2.8049244704675402e-08, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6529, loss: -0.002903379499912262, rewards: -15, count: 15\n",
      "success rate:  0.99\n",
      "epoch: 6539, loss: -2.3491243155149277e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6549, loss: -2.271988705615513e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6559, loss: -9.186127840621339e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6569, loss: 0.24357855319976807, rewards: -20, count: 20\n",
      "success rate:  1.0\n",
      "epoch: 6579, loss: 2.6602494926919462e-06, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 6589, loss: 6.942187837921665e-07, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6599, loss: -2.0077354179193208e-07, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 6609, loss: -1.1710559419952915e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6619, loss: 3.0643800528196152e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6629, loss: 1.1500189884827705e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6639, loss: -1.0378220167694963e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6649, loss: -6.258487701416016e-07, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 6659, loss: -1.1640436241577845e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6669, loss: 2.016623739109491e-06, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 6679, loss: -1.7881393432617188e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6689, loss: -3.1485276394960238e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6699, loss: 5.8763166634889785e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6709, loss: 3.0433429856202565e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6719, loss: -3.422007921471959e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6729, loss: -1.0525479410716798e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6739, loss: -8.344650268554688e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6749, loss: 2.452906483085826e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6759, loss: 9.596034215064719e-05, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 6769, loss: -8.543098374502733e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 6779, loss: 2.134787428076379e-05, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 6789, loss: 2.1429623302537948e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6799, loss: -1.4010597624292132e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6809, loss: 5.462590252136579e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6819, loss: -2.1317425762390485e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6829, loss: 8.905635127121059e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6839, loss: -1.7039916428984725e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6849, loss: -5.679971764038783e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6859, loss: 1.3444158639686066e-06, rewards: -18, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 6869, loss: -7.456854746124009e-06, rewards: -19, count: 19\n",
      "success rate:  0.97\n",
      "epoch: 6879, loss: -7.410844318656018e-06, rewards: -18, count: 18\n",
      "success rate:  0.97\n",
      "epoch: 6889, loss: -1.2796175724361092e-05, rewards: -19, count: 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate:  0.98\n",
      "epoch: 6899, loss: -5.743082965636859e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6909, loss: -1.116359908337472e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6919, loss: 5.220112143433653e-06, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 6929, loss: 0.8668215274810791, rewards: -27, count: 18\n",
      "success rate:  0.98\n",
      "epoch: 6939, loss: -4.184246063232422e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6949, loss: -3.834331801044755e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6959, loss: 2.2579642973141745e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 6969, loss: 2.154182038793806e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6979, loss: 2.086162567138672e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 6989, loss: 0.9196115136146545, rewards: -21, count: 21\n",
      "success rate:  0.99\n",
      "epoch: 6999, loss: 2.6015675302915042e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7009, loss: -1.2692282780335518e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7019, loss: -2.6085797344421735e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7029, loss: -1.5085652194102295e-06, rewards: -21, count: 21\n",
      "success rate:  0.99\n",
      "epoch: 7039, loss: 0.7048946619033813, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 7049, loss: 0.7048951387405396, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 7059, loss: 8.274527090179618e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7069, loss: 1.0378220167694963e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7079, loss: 3.3002149848471163e-06, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 7089, loss: 5.85527959628962e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7099, loss: -1.417963176209014e-06, rewards: -19, count: 19\n",
      "success rate:  0.97\n",
      "epoch: 7109, loss: -2.2649765014648438e-06, rewards: -17, count: 17\n",
      "success rate:  0.97\n",
      "epoch: 7119, loss: -2.5945550419237406e-07, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7129, loss: 1.963447175512556e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7139, loss: -1.472585381634417e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7149, loss: -2.1597918475890765e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7159, loss: 1.381425249746826e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7169, loss: -4.116226591577288e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7179, loss: 2.356136519665597e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7189, loss: -5.609849154097901e-07, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7199, loss: 6.311080369414412e-08, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 7209, loss: -2.4613211735413643e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 7219, loss: 8.414773589038305e-08, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7229, loss: 7.187618848547572e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7239, loss: 1.876494388852734e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7249, loss: 8.655295823700726e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7259, loss: -1.55112320499029e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7269, loss: 2.734912050073035e-05, rewards: -19, count: 19\n",
      "success rate:  0.98\n",
      "epoch: 7279, loss: -9.957481779565569e-06, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7289, loss: 3.4921307815238833e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7299, loss: -4.3623585952445865e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7309, loss: 1.2418802725733258e-05, rewards: -17, count: 17\n",
      "success rate:  0.98\n",
      "epoch: 7319, loss: -2.3778746253810823e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 7329, loss: 6.304067937890068e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 7339, loss: -1.3856326404493302e-05, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 7349, loss: 5.9604644775390625e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 7359, loss: 4.284522219677456e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 7369, loss: 1.7811270254242118e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 7379, loss: -5.462590252136579e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7389, loss: -2.5833354811766185e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7399, loss: -2.9838747650501318e-05, rewards: -18, count: 18\n",
      "success rate:  0.99\n",
      "epoch: 7409, loss: 0.7047064900398254, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 7419, loss: -2.302141729160212e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7429, loss: -5.2830753702437505e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7439, loss: 2.1668040517397458e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7449, loss: -6.827869219705462e-05, rewards: -19, count: 19\n",
      "success rate:  0.99\n",
      "epoch: 7459, loss: 8.232453183154576e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7469, loss: -6.051624495739816e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7479, loss: 0.5126813054084778, rewards: -19, count: 19\n",
      "success rate:  1.0\n",
      "epoch: 7489, loss: 0.8349290490150452, rewards: -18, count: 18\n",
      "success rate:  1.0\n",
      "epoch: 7499, loss: 7.91689944890095e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 7509, loss: -3.849758741125697e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 7519, loss: -3.0433429856202565e-06, rewards: -17, count: 17\n",
      "success rate:  1.0\n",
      "epoch: 7529, loss: 3.5832908906741068e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7539, loss: -4.21439881392871e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7549, loss: 1.430511474609375e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7559, loss: 2.6857151169679128e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7569, loss: -2.426259698040667e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7579, loss: 2.748825863818638e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7589, loss: 2.0265579223632812e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7599, loss: -7.713541890552733e-06, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7609, loss: -1.6282587239402346e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7619, loss: -3.9479313272750005e-05, rewards: -17, count: 17\n",
      "success rate:  0.99\n",
      "epoch: 7629, loss: -5.218562000663951e-05, rewards: -17, count: 17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCliffWalking-v0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(agent, env)\u001b[0m\n\u001b[1;32m     13\u001b[0m state_arr \u001b[38;5;241m=\u001b[39m convert2tensor(state)\n\u001b[1;32m     14\u001b[0m xs\u001b[38;5;241m.\u001b[39mappend(state_arr)\n\u001b[0;32m---> 15\u001b[0m action, log_prob \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_arr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m next_state, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m:\n",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m, in \u001b[0;36msample_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m      6\u001b[0m dist \u001b[38;5;241m=\u001b[39m Categorical(probs)\n\u001b[1;32m      7\u001b[0m action \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m----> 8\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\u001b[38;5;241m.\u001b[39mitem(),log_prob\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/torch/distributions/categorical.py:139\u001b[0m, in \u001b[0;36mCategorical.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n\u001b[1;32m    138\u001b[0m value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m value, log_pmf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(value, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m)\n\u001b[1;32m    140\u001b[0m value \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_pmf\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, value)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/torch/distributions/utils.py:126\u001b[0m, in \u001b[0;36mlazy_property.__get__\u001b[0;34m(self, instance, obj_type)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _lazy_property_and_property(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 126\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28msetattr\u001b[39m(instance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, value)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/torch/distributions/categorical.py:96\u001b[0m, in \u001b[0;36mCategorical.logits\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@lazy_property\u001b[39m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlogits\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprobs_to_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/torch/distributions/utils.py:104\u001b[0m, in \u001b[0;36mprobs_to_logits\u001b[0;34m(probs, is_binary)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprobs_to_logits\u001b[39m(probs, is_binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    Converts a tensor of probabilities into logits. For the binary case,\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    this denotes the probability of occurrence of the event indexed by `1`.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    For the multi-dimensional case, the values along the last dimension\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    denote the probabilities of occurrence of each of the events.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     ps_clamped \u001b[38;5;241m=\u001b[39m \u001b[43mclamp_probs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_binary:\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlog(ps_clamped) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog1p(\u001b[38;5;241m-\u001b[39mps_clamped)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/torch/distributions/utils.py:94\u001b[0m, in \u001b[0;36mclamp_probs\u001b[0;34m(probs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclamp_probs\u001b[39m(probs):\n\u001b[1;32m     93\u001b[0m     eps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfinfo(probs\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39meps\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('CliffWalking-v0')\n",
    "train(agent,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82cefaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_action(self,state):\n",
    "    probs = self.policy_net(state) # 4\n",
    "    if np.random.uniform() < 0.01:\n",
    "        action = np.random.randint(0,4)\n",
    "        return action, torch.log(probs[action]+1e-8).detach()\n",
    "    dist = Categorical(probs)\n",
    "    action = dist.sample()\n",
    "    log_prob = dist.log_prob(action)\n",
    "    return action.item(),log_prob.detach()\n",
    "\n",
    "# 替换方法\n",
    "import types\n",
    "agent.sample_action = types.MethodType(sample_action, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5aa3ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizing trained agent behavior...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 13:52:09.865 python[67964:170339742] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-04-27 13:52:09.865 python[67964:170339742] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 1\n",
      "Episode finished after 17 steps. Total reward: -17\n",
      "\n",
      "Episode 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVisualizing trained agent behavior...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCliffWalking-v0\u001b[39m\u001b[38;5;124m'\u001b[39m,render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m \u001b[43mvisualize_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 34\u001b[0m, in \u001b[0;36mvisualize_agent\u001b[0;34m(env, agent, num_episodes)\u001b[0m\n\u001b[1;32m     31\u001b[0m         action \u001b[38;5;241m=\u001b[39m probs\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# 使用最可能的动作\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 执行动作\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m step_result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(step_result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m     36\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m step_result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/envs/toy_text/cliffwalking.py:153\u001b[0m, in \u001b[0;36mCliffWalkingEnv.step\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlastaction \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mint\u001b[39m(s), r, t, \u001b[38;5;28;01mFalse\u001b[39;00m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m\"\u001b[39m: p})\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/envs/toy_text/cliffwalking.py:175\u001b[0m, in \u001b[0;36mCliffWalkingEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_text()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_gui\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/envs/toy_text/cliffwalking.py:262\u001b[0m, in \u001b[0;36mCliffWalkingEnv._render_gui\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    260\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[1;32m    261\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# rgb_array\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[1;32m    265\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(pygame\u001b[38;5;241m.\u001b[39msurfarray\u001b[38;5;241m.\u001b[39mpixels3d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_surface)), axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    266\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "def visualize_agent(env, agent, num_episodes=5):\n",
    "    \"\"\"\n",
    "    渲染显示智能体的行动\n",
    "    \"\"\"\n",
    "    env = gym.make('CliffWalking-v0', render_mode='human')  # 创建可视化环境\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state_tuple = env.reset()\n",
    "        state = state_tuple[0] if isinstance(state_tuple, tuple) else state_tuple\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        done = False\n",
    "        \n",
    "        print(f\"\\nEpisode {episode + 1}\")\n",
    "        \n",
    "        while not done:\n",
    "            env.render()  # 渲染当前状态\n",
    "            \n",
    "            # 将状态转换为one-hot编码\n",
    "            state_onehot = np.zeros(48)\n",
    "            state_onehot[state] = 1\n",
    "            \n",
    "            # 使用训练好的策略选择动作\n",
    "            with torch.no_grad():\n",
    "                if np.random.random() < 0.0:\n",
    "                    action = np.random.randint(0, 4)\n",
    "                else:\n",
    "                    state_tensor = torch.FloatTensor(state_onehot)\n",
    "                    probs = agent.policy_net(state_tensor)\n",
    "                    action = probs.argmax().item()  # 使用最可能的动作\n",
    "            \n",
    "            # 执行动作\n",
    "            step_result = env.step(action)\n",
    "            if len(step_result) == 4:\n",
    "                next_state, reward, done, _ = step_result\n",
    "            else:\n",
    "                next_state, reward, terminated, truncated, _ = step_result\n",
    "                done = terminated or truncated\n",
    "            \n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "            state = next_state\n",
    "            \n",
    "            # 添加小延迟使动作更容易观察\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        print(f\"Episode finished after {steps} steps. Total reward: {total_reward}\")\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "# 在主程序最后添加：\n",
    "if __name__ == \"__main__\":    \n",
    "    # 训练完成后显示智能体行动\n",
    "    print(\"\\nVisualizing trained agent behavior...\")\n",
    "    env = gym.make('CliffWalking-v0',render_mode='human')\n",
    "    visualize_agent(env, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9df7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9fd0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
