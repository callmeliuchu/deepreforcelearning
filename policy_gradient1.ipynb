{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3b670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle  # 用 pickle 替代 cPickle\n",
    "import gym\n",
    "np.bool8 = np.bool_\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d593720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef44cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Pong-v4\")\n",
    "observation, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "143f0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(observation):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # 创建一个随机的 (210, 160, 3) 矩阵\n",
    "    image = observation\n",
    "    # image = prepro_1(observation)\n",
    "\n",
    "    # 使用 matplotlib 显示图像\n",
    "    plt.imshow(image)\n",
    "    # plt.axis('off')  # 隐藏坐标轴\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55026ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fdedf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## action=2 up action=3 down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "262dbcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(I):\n",
    "    \"\"\"将 210x160x3 uint8 帧预处理为 6400 (80x80) 1D float 向量\"\"\"\n",
    "    I = I[35:195]  # 裁剪\n",
    "    I = I[::2, ::2, 0]  # 下采样因子为 2\n",
    "    I[I == 144] = 0  # 删除背景类型 1\n",
    "    I[I == 109] = 0  # 删除背景类型 2\n",
    "    I[I != 0] = 1  # 其他设置为 1\n",
    "    return I.astype(np.float32).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0007d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "324e858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 6400\n",
    "H = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecf189d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {'W1':np.random.randn(H,D),'W2':np.random.randn(H)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b9c0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8085db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_forward(x):\n",
    "    ### x: 6400\n",
    "    h = model['W1'] @ x\n",
    "    h[h<0] = 0\n",
    "    v = model['W2'] @ h\n",
    "    return h, sigmoid(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d7b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ac14eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(6400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dc9f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,p = policy_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3ad20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e4a5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_backward(xs,logps,hs):\n",
    "    ### xs: N,D logps: N, hs: N,H\n",
    "    dW2 = logps @ hs\n",
    "    h1 = np.outer(logps,model['W2']) ### N,H\n",
    "    h1[hs <= 0] = 0\n",
    "    dW1 = h1.T @ xs ## H,N @ N,D  ## H,D \n",
    "    return {'W1':dW1,'W2':dW2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e24b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_rewards(rewards):\n",
    "    ans = np.zeros_like(rewards)\n",
    "    adding = 0\n",
    "    for t in reversed(range(len(rewards))):\n",
    "        if rewards[t] != 0:adding = 0\n",
    "        adding = adding * 0.99 + rewards[t]\n",
    "        ans[t] = adding\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f3dda3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def discounted_rewards(r):\n",
    "#     \"\"\"对奖励进行折扣\"\"\"\n",
    "#     discounted_r = np.zeros_like(r)\n",
    "#     running_add = 0\n",
    "#     for t in reversed(range(r.size)):\n",
    "#         if r[t] != 0: running_add = 0  # 如果是游戏边界（仅对 Pong 特有）\n",
    "#         running_add = running_add * 0.99 + r[t]\n",
    "#         discounted_r[t] = running_add\n",
    "#     return discounted_r\n",
    "\n",
    "# def policy_forward(x):\n",
    "#     h = np.dot(model['W1'], x)\n",
    "#     h[h < 0] = 0  # ReLU\n",
    "#     logp = np.dot(model['W2'], h)\n",
    "#     p = sigmoid(logp)\n",
    "#     return  h,p  # 返回采取动作 2 的概率和隐藏状态\n",
    "\n",
    "# def policy_backward(epx,epdlogp,eph):\n",
    "#     \"\"\"反向传播（eph 为隐藏状态数组）\"\"\"\n",
    "#     dW2 = np.dot(eph.T, epdlogp).ravel()\n",
    "#     dh = np.outer(epdlogp, model['W2'])\n",
    "#     dh[eph <= 0] = 0  # Backprop ReLU\n",
    "#     dW1 = np.dot(dh.T, epx)\n",
    "#     return {'W1': dW1, 'W2': dW2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "621e63e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {'W1':np.random.randn(H,D),'W2':np.random.randn(H)}\n",
    "model['W1'] = np.random.randn(H, D) / np.sqrt(D)  # \"Xavier\" 初始化\n",
    "model['W2'] = np.random.randn(H) / np.sqrt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4adb317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -20.0. running mean: -20.0\n",
      "resetting env. episode reward total was -21.0. running mean: -20.01\n",
      "resetting env. episode reward total was -21.0. running mean: -20.019900000000003\n",
      "resetting env. episode reward total was -21.0. running mean: -20.029701000000003\n",
      "resetting env. episode reward total was -19.0. running mean: -20.019403990000004\n",
      "resetting env. episode reward total was -21.0. running mean: -20.029209950100004\n",
      "resetting env. episode reward total was -20.0. running mean: -20.028917850599004\n",
      "resetting env. episode reward total was -18.0. running mean: -20.008628672093014\n",
      "resetting env. episode reward total was -20.0. running mean: -20.00854238537208\n",
      "resetting env. episode reward total was -21.0. running mean: -20.01845696151836\n",
      "resetting env. episode reward total was -21.0. running mean: -20.028272391903176\n",
      "resetting env. episode reward total was -21.0. running mean: -20.037989667984146\n",
      "resetting env. episode reward total was -21.0. running mean: -20.047609771304305\n",
      "resetting env. episode reward total was -21.0. running mean: -20.057133673591263\n",
      "resetting env. episode reward total was -21.0. running mean: -20.066562336855352\n",
      "resetting env. episode reward total was -18.0. running mean: -20.045896713486798\n",
      "resetting env. episode reward total was -21.0. running mean: -20.05543774635193\n",
      "resetting env. episode reward total was -21.0. running mean: -20.064883368888413\n",
      "resetting env. episode reward total was -21.0. running mean: -20.07423453519953\n",
      "resetting env. episode reward total was -21.0. running mean: -20.083492189847536\n",
      "resetting env. episode reward total was -19.0. running mean: -20.07265726794906\n",
      "resetting env. episode reward total was -21.0. running mean: -20.081930695269573\n",
      "resetting env. episode reward total was -21.0. running mean: -20.09111138831688\n",
      "resetting env. episode reward total was -21.0. running mean: -20.10020027443371\n",
      "resetting env. episode reward total was -21.0. running mean: -20.109198271689372\n",
      "resetting env. episode reward total was -21.0. running mean: -20.11810628897248\n",
      "resetting env. episode reward total was -21.0. running mean: -20.126925226082758\n",
      "resetting env. episode reward total was -21.0. running mean: -20.13565597382193\n",
      "resetting env. episode reward total was -21.0. running mean: -20.14429941408371\n",
      "resetting env. episode reward total was -21.0. running mean: -20.152856419942875\n",
      "resetting env. episode reward total was -21.0. running mean: -20.161327855743448\n",
      "resetting env. episode reward total was -21.0. running mean: -20.169714577186014\n",
      "resetting env. episode reward total was -21.0. running mean: -20.178017431414155\n",
      "resetting env. episode reward total was -21.0. running mean: -20.186237257100014\n",
      "resetting env. episode reward total was -20.0. running mean: -20.184374884529014\n",
      "resetting env. episode reward total was -21.0. running mean: -20.192531135683723\n",
      "resetting env. episode reward total was -21.0. running mean: -20.200605824326885\n",
      "resetting env. episode reward total was -20.0. running mean: -20.198599766083614\n",
      "resetting env. episode reward total was -21.0. running mean: -20.206613768422777\n",
      "resetting env. episode reward total was -21.0. running mean: -20.21454763073855\n",
      "resetting env. episode reward total was -20.0. running mean: -20.212402154431164\n",
      "resetting env. episode reward total was -21.0. running mean: -20.220278132886854\n",
      "resetting env. episode reward total was -20.0. running mean: -20.218075351557985\n",
      "resetting env. episode reward total was -21.0. running mean: -20.225894598042405\n",
      "resetting env. episode reward total was -20.0. running mean: -20.22363565206198\n",
      "resetting env. episode reward total was -21.0. running mean: -20.23139929554136\n",
      "resetting env. episode reward total was -21.0. running mean: -20.23908530258595\n",
      "resetting env. episode reward total was -21.0. running mean: -20.24669444956009\n",
      "resetting env. episode reward total was -21.0. running mean: -20.254227505064488\n",
      "resetting env. episode reward total was -21.0. running mean: -20.261685230013843\n",
      "resetting env. episode reward total was -21.0. running mean: -20.269068377713705\n",
      "resetting env. episode reward total was -21.0. running mean: -20.276377693936567\n",
      "resetting env. episode reward total was -21.0. running mean: -20.2836139169972\n",
      "resetting env. episode reward total was -20.0. running mean: -20.28077777782723\n",
      "resetting env. episode reward total was -19.0. running mean: -20.267970000048958\n",
      "resetting env. episode reward total was -21.0. running mean: -20.275290300048468\n",
      "resetting env. episode reward total was -20.0. running mean: -20.272537397047984\n",
      "resetting env. episode reward total was -20.0. running mean: -20.269812023077503\n",
      "resetting env. episode reward total was -20.0. running mean: -20.267113902846727\n",
      "resetting env. episode reward total was -18.0. running mean: -20.24444276381826\n",
      "resetting env. episode reward total was -21.0. running mean: -20.251998336180076\n",
      "resetting env. episode reward total was -21.0. running mean: -20.259478352818277\n",
      "resetting env. episode reward total was -19.0. running mean: -20.246883569290095\n",
      "resetting env. episode reward total was -20.0. running mean: -20.244414733597193\n",
      "resetting env. episode reward total was -21.0. running mean: -20.251970586261223\n",
      "resetting env. episode reward total was -18.0. running mean: -20.22945088039861\n",
      "resetting env. episode reward total was -21.0. running mean: -20.237156371594622\n",
      "resetting env. episode reward total was -21.0. running mean: -20.244784807878677\n",
      "resetting env. episode reward total was -21.0. running mean: -20.25233695979989\n",
      "resetting env. episode reward total was -20.0. running mean: -20.249813590201892\n",
      "resetting env. episode reward total was -21.0. running mean: -20.257315454299874\n",
      "resetting env. episode reward total was -21.0. running mean: -20.264742299756875\n",
      "resetting env. episode reward total was -21.0. running mean: -20.272094876759308\n",
      "resetting env. episode reward total was -21.0. running mean: -20.279373927991717\n",
      "resetting env. episode reward total was -21.0. running mean: -20.2865801887118\n",
      "resetting env. episode reward total was -20.0. running mean: -20.28371438682468\n",
      "resetting env. episode reward total was -20.0. running mean: -20.280877242956432\n",
      "resetting env. episode reward total was -20.0. running mean: -20.27806847052687\n",
      "resetting env. episode reward total was -21.0. running mean: -20.285287785821602\n",
      "resetting env. episode reward total was -21.0. running mean: -20.292434907963386\n",
      "resetting env. episode reward total was -18.0. running mean: -20.269510558883752\n",
      "resetting env. episode reward total was -21.0. running mean: -20.276815453294915\n",
      "resetting env. episode reward total was -19.0. running mean: -20.264047298761966\n",
      "resetting env. episode reward total was -20.0. running mean: -20.261406825774344\n",
      "resetting env. episode reward total was -21.0. running mean: -20.2687927575166\n",
      "resetting env. episode reward total was -21.0. running mean: -20.276104829941435\n",
      "resetting env. episode reward total was -21.0. running mean: -20.28334378164202\n",
      "resetting env. episode reward total was -21.0. running mean: -20.290510343825602\n",
      "resetting env. episode reward total was -21.0. running mean: -20.297605240387348\n",
      "resetting env. episode reward total was -21.0. running mean: -20.304629187983476\n",
      "resetting env. episode reward total was -19.0. running mean: -20.29158289610364\n",
      "resetting env. episode reward total was -21.0. running mean: -20.298667067142606\n",
      "resetting env. episode reward total was -20.0. running mean: -20.29568039647118\n",
      "resetting env. episode reward total was -21.0. running mean: -20.30272359250647\n",
      "resetting env. episode reward total was -20.0. running mean: -20.299696356581403\n",
      "resetting env. episode reward total was -21.0. running mean: -20.30669939301559\n",
      "resetting env. episode reward total was -21.0. running mean: -20.313632399085435\n",
      "resetting env. episode reward total was -21.0. running mean: -20.32049607509458\n",
      "resetting env. episode reward total was -20.0. running mean: -20.317291114343636\n",
      "resetting env. episode reward total was -21.0. running mean: -20.3241182032002\n",
      "resetting env. episode reward total was -20.0. running mean: -20.320877021168197\n",
      "resetting env. episode reward total was -21.0. running mean: -20.327668250956517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -21.0. running mean: -20.334391568446954\n",
      "resetting env. episode reward total was -21.0. running mean: -20.341047652762484\n",
      "resetting env. episode reward total was -21.0. running mean: -20.34763717623486\n",
      "resetting env. episode reward total was -20.0. running mean: -20.34416080447251\n",
      "resetting env. episode reward total was -21.0. running mean: -20.350719196427786\n",
      "resetting env. episode reward total was -21.0. running mean: -20.35721200446351\n",
      "resetting env. episode reward total was -21.0. running mean: -20.363639884418873\n",
      "resetting env. episode reward total was -21.0. running mean: -20.370003485574685\n",
      "resetting env. episode reward total was -21.0. running mean: -20.37630345071894\n",
      "resetting env. episode reward total was -21.0. running mean: -20.38254041621175\n",
      "resetting env. episode reward total was -21.0. running mean: -20.388715012049634\n",
      "resetting env. episode reward total was -20.0. running mean: -20.384827861929136\n",
      "resetting env. episode reward total was -21.0. running mean: -20.390979583309846\n",
      "resetting env. episode reward total was -21.0. running mean: -20.39706978747675\n",
      "resetting env. episode reward total was -21.0. running mean: -20.403099089601984\n",
      "resetting env. episode reward total was -20.0. running mean: -20.399068098705964\n",
      "resetting env. episode reward total was -21.0. running mean: -20.405077417718903\n",
      "resetting env. episode reward total was -21.0. running mean: -20.411026643541714\n",
      "resetting env. episode reward total was -20.0. running mean: -20.406916377106295\n",
      "resetting env. episode reward total was -21.0. running mean: -20.412847213335233\n",
      "resetting env. episode reward total was -20.0. running mean: -20.40871874120188\n",
      "resetting env. episode reward total was -20.0. running mean: -20.404631553789862\n",
      "resetting env. episode reward total was -19.0. running mean: -20.390585238251965\n",
      "resetting env. episode reward total was -21.0. running mean: -20.396679385869447\n",
      "resetting env. episode reward total was -21.0. running mean: -20.402712592010754\n",
      "resetting env. episode reward total was -21.0. running mean: -20.40868546609065\n",
      "resetting env. episode reward total was -21.0. running mean: -20.414598611429742\n",
      "resetting env. episode reward total was -21.0. running mean: -20.420452625315445\n",
      "resetting env. episode reward total was -20.0. running mean: -20.41624809906229\n",
      "resetting env. episode reward total was -21.0. running mean: -20.42208561807167\n",
      "resetting env. episode reward total was -17.0. running mean: -20.387864761890953\n",
      "resetting env. episode reward total was -21.0. running mean: -20.393986114272042\n",
      "resetting env. episode reward total was -20.0. running mean: -20.39004625312932\n",
      "resetting env. episode reward total was -21.0. running mean: -20.396145790598027\n",
      "resetting env. episode reward total was -21.0. running mean: -20.40218433269205\n",
      "resetting env. episode reward total was -21.0. running mean: -20.40816248936513\n",
      "resetting env. episode reward total was -21.0. running mean: -20.41408086447148\n",
      "resetting env. episode reward total was -20.0. running mean: -20.409940055826763\n",
      "resetting env. episode reward total was -21.0. running mean: -20.415840655268497\n",
      "resetting env. episode reward total was -21.0. running mean: -20.42168224871581\n",
      "resetting env. episode reward total was -21.0. running mean: -20.427465426228654\n",
      "resetting env. episode reward total was -21.0. running mean: -20.43319077196637\n",
      "resetting env. episode reward total was -20.0. running mean: -20.428858864246706\n",
      "resetting env. episode reward total was -21.0. running mean: -20.43457027560424\n",
      "resetting env. episode reward total was -20.0. running mean: -20.430224572848196\n",
      "resetting env. episode reward total was -20.0. running mean: -20.425922327119714\n",
      "resetting env. episode reward total was -19.0. running mean: -20.411663103848518\n",
      "resetting env. episode reward total was -20.0. running mean: -20.407546472810033\n",
      "resetting env. episode reward total was -20.0. running mean: -20.403471008081933\n",
      "resetting env. episode reward total was -21.0. running mean: -20.409436298001115\n",
      "resetting env. episode reward total was -20.0. running mean: -20.405341935021102\n",
      "resetting env. episode reward total was -20.0. running mean: -20.401288515670892\n",
      "resetting env. episode reward total was -20.0. running mean: -20.397275630514184\n",
      "resetting env. episode reward total was -21.0. running mean: -20.403302874209043\n",
      "resetting env. episode reward total was -21.0. running mean: -20.40926984546695\n",
      "resetting env. episode reward total was -19.0. running mean: -20.395177147012284\n",
      "resetting env. episode reward total was -20.0. running mean: -20.39122537554216\n",
      "resetting env. episode reward total was -20.0. running mean: -20.387313121786736\n",
      "resetting env. episode reward total was -21.0. running mean: -20.39343999056887\n",
      "resetting env. episode reward total was -21.0. running mean: -20.399505590663182\n",
      "resetting env. episode reward total was -20.0. running mean: -20.39551053475655\n",
      "resetting env. episode reward total was -21.0. running mean: -20.401555429408987\n",
      "resetting env. episode reward total was -20.0. running mean: -20.397539875114894\n",
      "resetting env. episode reward total was -21.0. running mean: -20.403564476363748\n",
      "resetting env. episode reward total was -20.0. running mean: -20.399528831600108\n",
      "resetting env. episode reward total was -21.0. running mean: -20.405533543284108\n",
      "resetting env. episode reward total was -21.0. running mean: -20.411478207851268\n",
      "resetting env. episode reward total was -20.0. running mean: -20.407363425772754\n",
      "resetting env. episode reward total was -21.0. running mean: -20.413289791515027\n",
      "resetting env. episode reward total was -21.0. running mean: -20.419156893599876\n",
      "resetting env. episode reward total was -21.0. running mean: -20.424965324663876\n",
      "resetting env. episode reward total was -21.0. running mean: -20.43071567141724\n",
      "resetting env. episode reward total was -21.0. running mean: -20.436408514703068\n",
      "resetting env. episode reward total was -21.0. running mean: -20.442044429556038\n",
      "resetting env. episode reward total was -20.0. running mean: -20.437623985260476\n",
      "resetting env. episode reward total was -21.0. running mean: -20.443247745407874\n",
      "resetting env. episode reward total was -19.0. running mean: -20.428815267953794\n",
      "resetting env. episode reward total was -21.0. running mean: -20.434527115274257\n",
      "resetting env. episode reward total was -19.0. running mean: -20.420181844121515\n",
      "resetting env. episode reward total was -21.0. running mean: -20.4259800256803\n",
      "resetting env. episode reward total was -21.0. running mean: -20.431720225423497\n",
      "resetting env. episode reward total was -21.0. running mean: -20.437403023169264\n",
      "resetting env. episode reward total was -20.0. running mean: -20.43302899293757\n",
      "resetting env. episode reward total was -21.0. running mean: -20.438698703008193\n",
      "resetting env. episode reward total was -20.0. running mean: -20.434311715978108\n",
      "resetting env. episode reward total was -21.0. running mean: -20.43996859881833\n",
      "resetting env. episode reward total was -21.0. running mean: -20.445568912830147\n",
      "resetting env. episode reward total was -21.0. running mean: -20.451113223701846\n",
      "resetting env. episode reward total was -21.0. running mean: -20.456602091464827\n",
      "resetting env. episode reward total was -21.0. running mean: -20.46203607055018\n",
      "resetting env. episode reward total was -20.0. running mean: -20.45741570984468\n",
      "resetting env. episode reward total was -21.0. running mean: -20.462841552746234\n",
      "resetting env. episode reward total was -21.0. running mean: -20.468213137218772\n",
      "resetting env. episode reward total was -20.0. running mean: -20.463531005846583\n",
      "resetting env. episode reward total was -20.0. running mean: -20.458895695788115\n",
      "resetting env. episode reward total was -21.0. running mean: -20.464306738830235\n",
      "resetting env. episode reward total was -21.0. running mean: -20.469663671441932\n",
      "resetting env. episode reward total was -21.0. running mean: -20.474967034727513\n",
      "resetting env. episode reward total was -21.0. running mean: -20.480217364380238\n",
      "resetting env. episode reward total was -21.0. running mean: -20.485415190736436\n",
      "resetting env. episode reward total was -21.0. running mean: -20.49056103882907\n",
      "resetting env. episode reward total was -20.0. running mean: -20.48565542844078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -21.0. running mean: -20.490798874156372\n",
      "resetting env. episode reward total was -21.0. running mean: -20.49589088541481\n",
      "resetting env. episode reward total was -20.0. running mean: -20.49093197656066\n",
      "resetting env. episode reward total was -21.0. running mean: -20.496022656795052\n",
      "resetting env. episode reward total was -21.0. running mean: -20.5010624302271\n",
      "resetting env. episode reward total was -21.0. running mean: -20.50605180592483\n",
      "resetting env. episode reward total was -21.0. running mean: -20.510991287865583\n",
      "resetting env. episode reward total was -20.0. running mean: -20.505881374986927\n",
      "resetting env. episode reward total was -21.0. running mean: -20.51082256123706\n",
      "resetting env. episode reward total was -21.0. running mean: -20.51571433562469\n",
      "resetting env. episode reward total was -21.0. running mean: -20.520557192268445\n",
      "resetting env. episode reward total was -20.0. running mean: -20.515351620345758\n",
      "resetting env. episode reward total was -21.0. running mean: -20.520198104142302\n",
      "resetting env. episode reward total was -21.0. running mean: -20.52499612310088\n",
      "resetting env. episode reward total was -20.0. running mean: -20.51974616186987\n",
      "resetting env. episode reward total was -20.0. running mean: -20.514548700251172\n",
      "resetting env. episode reward total was -21.0. running mean: -20.519403213248662\n",
      "resetting env. episode reward total was -21.0. running mean: -20.524209181116177\n",
      "resetting env. episode reward total was -21.0. running mean: -20.528967089305016\n",
      "resetting env. episode reward total was -20.0. running mean: -20.523677418411964\n",
      "resetting env. episode reward total was -17.0. running mean: -20.488440644227847\n",
      "resetting env. episode reward total was -17.0. running mean: -20.45355623778557\n",
      "resetting env. episode reward total was -20.0. running mean: -20.449020675407713\n",
      "resetting env. episode reward total was -21.0. running mean: -20.454530468653637\n",
      "resetting env. episode reward total was -19.0. running mean: -20.4399851639671\n",
      "resetting env. episode reward total was -21.0. running mean: -20.44558531232743\n",
      "resetting env. episode reward total was -20.0. running mean: -20.441129459204156\n",
      "resetting env. episode reward total was -19.0. running mean: -20.426718164612115\n",
      "resetting env. episode reward total was -20.0. running mean: -20.422450982965994\n",
      "resetting env. episode reward total was -19.0. running mean: -20.408226473136335\n",
      "resetting env. episode reward total was -21.0. running mean: -20.414144208404974\n",
      "resetting env. episode reward total was -21.0. running mean: -20.420002766320923\n",
      "resetting env. episode reward total was -19.0. running mean: -20.405802738657716\n",
      "resetting env. episode reward total was -21.0. running mean: -20.41174471127114\n",
      "resetting env. episode reward total was -21.0. running mean: -20.41762726415843\n",
      "resetting env. episode reward total was -21.0. running mean: -20.423450991516845\n",
      "resetting env. episode reward total was -20.0. running mean: -20.419216481601676\n",
      "resetting env. episode reward total was -21.0. running mean: -20.42502431678566\n",
      "resetting env. episode reward total was -21.0. running mean: -20.430774073617805\n",
      "resetting env. episode reward total was -20.0. running mean: -20.426466332881624\n",
      "resetting env. episode reward total was -20.0. running mean: -20.422201669552805\n",
      "resetting env. episode reward total was -21.0. running mean: -20.427979652857278\n",
      "resetting env. episode reward total was -20.0. running mean: -20.423699856328703\n",
      "resetting env. episode reward total was -20.0. running mean: -20.419462857765414\n",
      "resetting env. episode reward total was -19.0. running mean: -20.40526822918776\n",
      "resetting env. episode reward total was -21.0. running mean: -20.411215546895885\n",
      "resetting env. episode reward total was -19.0. running mean: -20.397103391426928\n",
      "resetting env. episode reward total was -19.0. running mean: -20.38313235751266\n",
      "resetting env. episode reward total was -21.0. running mean: -20.389301033937535\n",
      "resetting env. episode reward total was -19.0. running mean: -20.375408023598162\n",
      "resetting env. episode reward total was -19.0. running mean: -20.36165394336218\n",
      "resetting env. episode reward total was -21.0. running mean: -20.36803740392856\n",
      "resetting env. episode reward total was -20.0. running mean: -20.364357029889273\n",
      "resetting env. episode reward total was -19.0. running mean: -20.35071345959038\n",
      "resetting env. episode reward total was -19.0. running mean: -20.33720632499448\n",
      "resetting env. episode reward total was -21.0. running mean: -20.343834261744536\n",
      "resetting env. episode reward total was -21.0. running mean: -20.35039591912709\n",
      "resetting env. episode reward total was -21.0. running mean: -20.356891959935822\n",
      "resetting env. episode reward total was -21.0. running mean: -20.363323040336464\n",
      "resetting env. episode reward total was -21.0. running mean: -20.3696898099331\n",
      "resetting env. episode reward total was -20.0. running mean: -20.365992911833768\n",
      "resetting env. episode reward total was -18.0. running mean: -20.34233298271543\n",
      "resetting env. episode reward total was -21.0. running mean: -20.348909652888278\n",
      "resetting env. episode reward total was -20.0. running mean: -20.345420556359393\n",
      "resetting env. episode reward total was -21.0. running mean: -20.3519663507958\n",
      "resetting env. episode reward total was -21.0. running mean: -20.35844668728784\n",
      "resetting env. episode reward total was -21.0. running mean: -20.364862220414963\n",
      "resetting env. episode reward total was -20.0. running mean: -20.361213598210814\n",
      "resetting env. episode reward total was -21.0. running mean: -20.367601462228706\n",
      "resetting env. episode reward total was -21.0. running mean: -20.373925447606418\n",
      "resetting env. episode reward total was -19.0. running mean: -20.360186193130353\n",
      "resetting env. episode reward total was -21.0. running mean: -20.36658433119905\n",
      "resetting env. episode reward total was -21.0. running mean: -20.37291848788706\n",
      "resetting env. episode reward total was -21.0. running mean: -20.37918930300819\n",
      "resetting env. episode reward total was -20.0. running mean: -20.375397409978106\n",
      "resetting env. episode reward total was -20.0. running mean: -20.371643435878322\n",
      "resetting env. episode reward total was -21.0. running mean: -20.37792700151954\n",
      "resetting env. episode reward total was -19.0. running mean: -20.364147731504346\n",
      "resetting env. episode reward total was -19.0. running mean: -20.350506254189305\n",
      "resetting env. episode reward total was -20.0. running mean: -20.34700119164741\n",
      "resetting env. episode reward total was -20.0. running mean: -20.343531179730935\n",
      "resetting env. episode reward total was -21.0. running mean: -20.350095867933625\n",
      "resetting env. episode reward total was -18.0. running mean: -20.32659490925429\n",
      "resetting env. episode reward total was -16.0. running mean: -20.283328960161747\n",
      "resetting env. episode reward total was -21.0. running mean: -20.29049567056013\n",
      "resetting env. episode reward total was -21.0. running mean: -20.29759071385453\n",
      "resetting env. episode reward total was -21.0. running mean: -20.304614806715986\n",
      "resetting env. episode reward total was -21.0. running mean: -20.311568658648827\n",
      "resetting env. episode reward total was -21.0. running mean: -20.31845297206234\n",
      "resetting env. episode reward total was -21.0. running mean: -20.325268442341716\n",
      "resetting env. episode reward total was -21.0. running mean: -20.3320157579183\n",
      "resetting env. episode reward total was -21.0. running mean: -20.33869560033912\n",
      "resetting env. episode reward total was -20.0. running mean: -20.335308644335726\n",
      "resetting env. episode reward total was -19.0. running mean: -20.32195555789237\n",
      "resetting env. episode reward total was -21.0. running mean: -20.32873600231345\n",
      "resetting env. episode reward total was -21.0. running mean: -20.335448642290313\n",
      "resetting env. episode reward total was -21.0. running mean: -20.34209415586741\n",
      "resetting env. episode reward total was -21.0. running mean: -20.348673214308736\n",
      "resetting env. episode reward total was -21.0. running mean: -20.35518648216565\n",
      "resetting env. episode reward total was -18.0. running mean: -20.331634617343994\n",
      "resetting env. episode reward total was -21.0. running mean: -20.338318271170554\n",
      "resetting env. episode reward total was -20.0. running mean: -20.33493508845885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -21.0. running mean: -20.34158573757426\n",
      "resetting env. episode reward total was -21.0. running mean: -20.34816988019852\n",
      "resetting env. episode reward total was -21.0. running mean: -20.354688181396533\n",
      "resetting env. episode reward total was -21.0. running mean: -20.361141299582567\n",
      "resetting env. episode reward total was -20.0. running mean: -20.35752988658674\n",
      "resetting env. episode reward total was -21.0. running mean: -20.363954587720873\n",
      "resetting env. episode reward total was -21.0. running mean: -20.370315041843664\n",
      "resetting env. episode reward total was -18.0. running mean: -20.346611891425226\n",
      "resetting env. episode reward total was -21.0. running mean: -20.353145772510974\n",
      "resetting env. episode reward total was -21.0. running mean: -20.359614314785865\n",
      "resetting env. episode reward total was -21.0. running mean: -20.366018171638007\n",
      "resetting env. episode reward total was -21.0. running mean: -20.37235798992163\n",
      "resetting env. episode reward total was -18.0. running mean: -20.348634410022413\n",
      "resetting env. episode reward total was -21.0. running mean: -20.35514806592219\n",
      "resetting env. episode reward total was -20.0. running mean: -20.351596585262968\n",
      "resetting env. episode reward total was -19.0. running mean: -20.338080619410338\n",
      "resetting env. episode reward total was -20.0. running mean: -20.334699813216233\n",
      "resetting env. episode reward total was -21.0. running mean: -20.341352815084072\n",
      "resetting env. episode reward total was -21.0. running mean: -20.347939286933233\n",
      "resetting env. episode reward total was -17.0. running mean: -20.3144598940639\n",
      "resetting env. episode reward total was -21.0. running mean: -20.321315295123263\n",
      "resetting env. episode reward total was -20.0. running mean: -20.31810214217203\n",
      "resetting env. episode reward total was -19.0. running mean: -20.30492112075031\n",
      "resetting env. episode reward total was -21.0. running mean: -20.31187190954281\n",
      "resetting env. episode reward total was -21.0. running mean: -20.31875319044738\n",
      "resetting env. episode reward total was -20.0. running mean: -20.31556565854291\n",
      "resetting env. episode reward total was -20.0. running mean: -20.312410001957478\n",
      "resetting env. episode reward total was -20.0. running mean: -20.3092859019379\n",
      "resetting env. episode reward total was -21.0. running mean: -20.316193042918524\n",
      "resetting env. episode reward total was -21.0. running mean: -20.32303111248934\n",
      "resetting env. episode reward total was -21.0. running mean: -20.329800801364446\n",
      "resetting env. episode reward total was -19.0. running mean: -20.316502793350804\n",
      "resetting env. episode reward total was -21.0. running mean: -20.323337765417296\n",
      "resetting env. episode reward total was -21.0. running mean: -20.330104387763125\n",
      "resetting env. episode reward total was -20.0. running mean: -20.326803343885494\n",
      "resetting env. episode reward total was -21.0. running mean: -20.33353531044664\n",
      "resetting env. episode reward total was -17.0. running mean: -20.300199957342173\n",
      "resetting env. episode reward total was -19.0. running mean: -20.28719795776875\n",
      "resetting env. episode reward total was -21.0. running mean: -20.294325978191065\n",
      "resetting env. episode reward total was -21.0. running mean: -20.301382718409155\n",
      "resetting env. episode reward total was -21.0. running mean: -20.308368891225065\n",
      "resetting env. episode reward total was -21.0. running mean: -20.315285202312815\n",
      "resetting env. episode reward total was -21.0. running mean: -20.32213235028969\n",
      "resetting env. episode reward total was -21.0. running mean: -20.32891102678679\n",
      "resetting env. episode reward total was -20.0. running mean: -20.325621916518923\n",
      "resetting env. episode reward total was -21.0. running mean: -20.332365697353733\n",
      "resetting env. episode reward total was -21.0. running mean: -20.339042040380196\n",
      "resetting env. episode reward total was -18.0. running mean: -20.315651619976393\n",
      "resetting env. episode reward total was -20.0. running mean: -20.312495103776627\n",
      "resetting env. episode reward total was -21.0. running mean: -20.319370152738863\n",
      "resetting env. episode reward total was -19.0. running mean: -20.306176451211474\n",
      "resetting env. episode reward total was -21.0. running mean: -20.31311468669936\n",
      "resetting env. episode reward total was -20.0. running mean: -20.309983539832366\n",
      "resetting env. episode reward total was -21.0. running mean: -20.316883704434044\n",
      "resetting env. episode reward total was -20.0. running mean: -20.313714867389702\n",
      "resetting env. episode reward total was -21.0. running mean: -20.320577718715807\n",
      "resetting env. episode reward total was -21.0. running mean: -20.32737194152865\n",
      "resetting env. episode reward total was -20.0. running mean: -20.324098222113363\n",
      "resetting env. episode reward total was -20.0. running mean: -20.32085723989223\n",
      "resetting env. episode reward total was -20.0. running mean: -20.31764866749331\n",
      "resetting env. episode reward total was -20.0. running mean: -20.314472180818374\n",
      "resetting env. episode reward total was -21.0. running mean: -20.32132745901019\n",
      "resetting env. episode reward total was -19.0. running mean: -20.30811418442009\n",
      "resetting env. episode reward total was -20.0. running mean: -20.30503304257589\n",
      "resetting env. episode reward total was -19.0. running mean: -20.29198271215013\n",
      "resetting env. episode reward total was -19.0. running mean: -20.27906288502863\n",
      "resetting env. episode reward total was -19.0. running mean: -20.266272256178343\n",
      "resetting env. episode reward total was -17.0. running mean: -20.233609533616562\n",
      "resetting env. episode reward total was -20.0. running mean: -20.231273438280397\n",
      "resetting env. episode reward total was -20.0. running mean: -20.22896070389759\n",
      "resetting env. episode reward total was -21.0. running mean: -20.236671096858615\n",
      "resetting env. episode reward total was -21.0. running mean: -20.24430438589003\n",
      "resetting env. episode reward total was -21.0. running mean: -20.25186134203113\n",
      "resetting env. episode reward total was -21.0. running mean: -20.259342728610818\n",
      "resetting env. episode reward total was -20.0. running mean: -20.25674930132471\n",
      "resetting env. episode reward total was -21.0. running mean: -20.264181808311463\n",
      "resetting env. episode reward total was -21.0. running mean: -20.271539990228348\n",
      "resetting env. episode reward total was -20.0. running mean: -20.268824590326062\n",
      "resetting env. episode reward total was -21.0. running mean: -20.276136344422802\n",
      "resetting env. episode reward total was -21.0. running mean: -20.283374980978575\n",
      "resetting env. episode reward total was -21.0. running mean: -20.29054123116879\n",
      "resetting env. episode reward total was -21.0. running mean: -20.297635818857103\n",
      "resetting env. episode reward total was -21.0. running mean: -20.304659460668532\n",
      "resetting env. episode reward total was -19.0. running mean: -20.291612866061847\n",
      "resetting env. episode reward total was -20.0. running mean: -20.288696737401228\n",
      "resetting env. episode reward total was -20.0. running mean: -20.285809770027214\n",
      "resetting env. episode reward total was -21.0. running mean: -20.292951672326943\n",
      "resetting env. episode reward total was -21.0. running mean: -20.300022155603674\n",
      "resetting env. episode reward total was -20.0. running mean: -20.297021934047635\n",
      "resetting env. episode reward total was -21.0. running mean: -20.30405171470716\n",
      "resetting env. episode reward total was -21.0. running mean: -20.311011197560088\n",
      "resetting env. episode reward total was -19.0. running mean: -20.29790108558449\n",
      "resetting env. episode reward total was -21.0. running mean: -20.304922074728644\n",
      "resetting env. episode reward total was -20.0. running mean: -20.301872853981358\n",
      "resetting env. episode reward total was -21.0. running mean: -20.308854125441545\n",
      "resetting env. episode reward total was -19.0. running mean: -20.29576558418713\n",
      "resetting env. episode reward total was -20.0. running mean: -20.29280792834526\n",
      "resetting env. episode reward total was -20.0. running mean: -20.289879849061805\n",
      "resetting env. episode reward total was -18.0. running mean: -20.266981050571186\n",
      "resetting env. episode reward total was -21.0. running mean: -20.274311240065476\n",
      "resetting env. episode reward total was -20.0. running mean: -20.27156812766482\n",
      "resetting env. episode reward total was -17.0. running mean: -20.238852446388176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -19.0. running mean: -20.226463921924296\n",
      "resetting env. episode reward total was -20.0. running mean: -20.22419928270505\n",
      "resetting env. episode reward total was -19.0. running mean: -20.211957289878\n",
      "resetting env. episode reward total was -18.0. running mean: -20.18983771697922\n",
      "resetting env. episode reward total was -21.0. running mean: -20.197939339809427\n",
      "resetting env. episode reward total was -21.0. running mean: -20.205959946411333\n",
      "resetting env. episode reward total was -21.0. running mean: -20.21390034694722\n",
      "resetting env. episode reward total was -19.0. running mean: -20.20176134347775\n",
      "resetting env. episode reward total was -20.0. running mean: -20.19974373004297\n",
      "resetting env. episode reward total was -20.0. running mean: -20.19774629274254\n",
      "resetting env. episode reward total was -18.0. running mean: -20.175768829815112\n",
      "resetting env. episode reward total was -21.0. running mean: -20.18401114151696\n",
      "resetting env. episode reward total was -20.0. running mean: -20.18217103010179\n",
      "resetting env. episode reward total was -21.0. running mean: -20.190349319800774\n",
      "resetting env. episode reward total was -20.0. running mean: -20.188445826602766\n",
      "resetting env. episode reward total was -20.0. running mean: -20.186561368336736\n",
      "resetting env. episode reward total was -21.0. running mean: -20.19469575465337\n",
      "resetting env. episode reward total was -20.0. running mean: -20.192748797106837\n",
      "resetting env. episode reward total was -20.0. running mean: -20.190821309135767\n",
      "resetting env. episode reward total was -21.0. running mean: -20.19891309604441\n",
      "resetting env. episode reward total was -21.0. running mean: -20.206923965083966\n",
      "resetting env. episode reward total was -19.0. running mean: -20.194854725433128\n",
      "resetting env. episode reward total was -20.0. running mean: -20.192906178178795\n",
      "resetting env. episode reward total was -20.0. running mean: -20.190977116397008\n",
      "resetting env. episode reward total was -21.0. running mean: -20.19906734523304\n",
      "resetting env. episode reward total was -21.0. running mean: -20.20707667178071\n",
      "resetting env. episode reward total was -20.0. running mean: -20.205005905062905\n",
      "resetting env. episode reward total was -20.0. running mean: -20.202955846012273\n",
      "resetting env. episode reward total was -21.0. running mean: -20.21092628755215\n",
      "resetting env. episode reward total was -20.0. running mean: -20.20881702467663\n",
      "resetting env. episode reward total was -21.0. running mean: -20.216728854429864\n",
      "resetting env. episode reward total was -20.0. running mean: -20.214561565885564\n",
      "resetting env. episode reward total was -21.0. running mean: -20.222415950226708\n",
      "resetting env. episode reward total was -20.0. running mean: -20.22019179072444\n",
      "resetting env. episode reward total was -21.0. running mean: -20.227989872817194\n",
      "resetting env. episode reward total was -20.0. running mean: -20.22570997408902\n",
      "resetting env. episode reward total was -21.0. running mean: -20.23345287434813\n",
      "resetting env. episode reward total was -20.0. running mean: -20.23111834560465\n",
      "resetting env. episode reward total was -21.0. running mean: -20.238807162148603\n",
      "resetting env. episode reward total was -21.0. running mean: -20.24641909052712\n",
      "resetting env. episode reward total was -21.0. running mean: -20.25395489962185\n",
      "resetting env. episode reward total was -20.0. running mean: -20.25141535062563\n",
      "resetting env. episode reward total was -21.0. running mean: -20.258901197119375\n",
      "resetting env. episode reward total was -21.0. running mean: -20.26631218514818\n",
      "resetting env. episode reward total was -20.0. running mean: -20.263649063296697\n",
      "resetting env. episode reward total was -17.0. running mean: -20.231012572663733\n",
      "resetting env. episode reward total was -21.0. running mean: -20.238702446937097\n",
      "resetting env. episode reward total was -21.0. running mean: -20.246315422467728\n",
      "resetting env. episode reward total was -20.0. running mean: -20.24385226824305\n",
      "resetting env. episode reward total was -20.0. running mean: -20.241413745560617\n",
      "resetting env. episode reward total was -21.0. running mean: -20.248999608105013\n",
      "resetting env. episode reward total was -20.0. running mean: -20.246509612023964\n",
      "resetting env. episode reward total was -21.0. running mean: -20.254044515903725\n",
      "resetting env. episode reward total was -21.0. running mean: -20.26150407074469\n",
      "resetting env. episode reward total was -21.0. running mean: -20.268889030037244\n",
      "resetting env. episode reward total was -21.0. running mean: -20.276200139736872\n",
      "resetting env. episode reward total was -21.0. running mean: -20.283438138339505\n",
      "resetting env. episode reward total was -19.0. running mean: -20.270603756956113\n",
      "resetting env. episode reward total was -17.0. running mean: -20.237897719386552\n",
      "resetting env. episode reward total was -20.0. running mean: -20.235518742192685\n",
      "resetting env. episode reward total was -20.0. running mean: -20.23316355477076\n",
      "resetting env. episode reward total was -21.0. running mean: -20.24083191922305\n",
      "resetting env. episode reward total was -21.0. running mean: -20.248423600030822\n",
      "resetting env. episode reward total was -21.0. running mean: -20.255939364030514\n",
      "resetting env. episode reward total was -20.0. running mean: -20.253379970390206\n",
      "resetting env. episode reward total was -21.0. running mean: -20.260846170686303\n",
      "resetting env. episode reward total was -19.0. running mean: -20.248237708979442\n",
      "resetting env. episode reward total was -21.0. running mean: -20.25575533188965\n",
      "resetting env. episode reward total was -21.0. running mean: -20.263197778570753\n",
      "resetting env. episode reward total was -19.0. running mean: -20.250565800785047\n",
      "resetting env. episode reward total was -21.0. running mean: -20.258060142777197\n",
      "resetting env. episode reward total was -18.0. running mean: -20.235479541349424\n",
      "resetting env. episode reward total was -20.0. running mean: -20.23312474593593\n",
      "resetting env. episode reward total was -20.0. running mean: -20.23079349847657\n",
      "resetting env. episode reward total was -20.0. running mean: -20.2284855634918\n",
      "resetting env. episode reward total was -20.0. running mean: -20.226200707856883\n",
      "resetting env. episode reward total was -21.0. running mean: -20.233938700778314\n",
      "resetting env. episode reward total was -20.0. running mean: -20.23159931377053\n",
      "resetting env. episode reward total was -21.0. running mean: -20.239283320632826\n",
      "resetting env. episode reward total was -19.0. running mean: -20.2268904874265\n",
      "resetting env. episode reward total was -19.0. running mean: -20.214621582552233\n",
      "resetting env. episode reward total was -21.0. running mean: -20.222475366726712\n",
      "resetting env. episode reward total was -21.0. running mean: -20.230250613059447\n",
      "resetting env. episode reward total was -21.0. running mean: -20.237948106928854\n",
      "resetting env. episode reward total was -21.0. running mean: -20.245568625859566\n",
      "resetting env. episode reward total was -21.0. running mean: -20.25311293960097\n",
      "resetting env. episode reward total was -21.0. running mean: -20.26058181020496\n",
      "resetting env. episode reward total was -21.0. running mean: -20.26797599210291\n",
      "resetting env. episode reward total was -20.0. running mean: -20.265296232181882\n",
      "resetting env. episode reward total was -20.0. running mean: -20.262643269860064\n",
      "resetting env. episode reward total was -21.0. running mean: -20.270016837161464\n",
      "resetting env. episode reward total was -20.0. running mean: -20.26731666878985\n",
      "resetting env. episode reward total was -21.0. running mean: -20.274643502101952\n",
      "resetting env. episode reward total was -20.0. running mean: -20.271897067080932\n",
      "resetting env. episode reward total was -21.0. running mean: -20.279178096410124\n",
      "resetting env. episode reward total was -21.0. running mean: -20.286386315446023\n",
      "resetting env. episode reward total was -21.0. running mean: -20.293522452291565\n",
      "resetting env. episode reward total was -20.0. running mean: -20.29058722776865\n",
      "resetting env. episode reward total was -19.0. running mean: -20.277681355490966\n",
      "resetting env. episode reward total was -21.0. running mean: -20.284904541936058\n",
      "resetting env. episode reward total was -21.0. running mean: -20.2920554965167\n",
      "resetting env. episode reward total was -20.0. running mean: -20.28913494155153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -21.0. running mean: -20.296243592136015\n",
      "resetting env. episode reward total was -21.0. running mean: -20.303281156214656\n",
      "resetting env. episode reward total was -20.0. running mean: -20.30024834465251\n",
      "resetting env. episode reward total was -20.0. running mean: -20.297245861205983\n",
      "resetting env. episode reward total was -21.0. running mean: -20.304273402593925\n",
      "resetting env. episode reward total was -19.0. running mean: -20.291230668567987\n",
      "resetting env. episode reward total was -21.0. running mean: -20.29831836188231\n",
      "resetting env. episode reward total was -18.0. running mean: -20.275335178263486\n",
      "resetting env. episode reward total was -20.0. running mean: -20.27258182648085\n",
      "resetting env. episode reward total was -20.0. running mean: -20.26985600821604\n",
      "resetting env. episode reward total was -20.0. running mean: -20.267157448133876\n",
      "resetting env. episode reward total was -20.0. running mean: -20.264485873652536\n",
      "resetting env. episode reward total was -20.0. running mean: -20.26184101491601\n",
      "resetting env. episode reward total was -21.0. running mean: -20.26922260476685\n",
      "resetting env. episode reward total was -21.0. running mean: -20.27653037871918\n",
      "resetting env. episode reward total was -19.0. running mean: -20.26376507493199\n",
      "resetting env. episode reward total was -19.0. running mean: -20.25112742418267\n",
      "resetting env. episode reward total was -20.0. running mean: -20.248616149940844\n",
      "resetting env. episode reward total was -21.0. running mean: -20.256129988441437\n",
      "resetting env. episode reward total was -21.0. running mean: -20.263568688557022\n",
      "resetting env. episode reward total was -17.0. running mean: -20.230933001671453\n",
      "resetting env. episode reward total was -21.0. running mean: -20.23862367165474\n",
      "resetting env. episode reward total was -21.0. running mean: -20.24623743493819\n",
      "resetting env. episode reward total was -20.0. running mean: -20.24377506058881\n",
      "resetting env. episode reward total was -20.0. running mean: -20.24133730998292\n",
      "resetting env. episode reward total was -20.0. running mean: -20.23892393688309\n",
      "resetting env. episode reward total was -21.0. running mean: -20.24653469751426\n",
      "resetting env. episode reward total was -19.0. running mean: -20.23406935053912\n",
      "resetting env. episode reward total was -18.0. running mean: -20.211728657033728\n",
      "resetting env. episode reward total was -21.0. running mean: -20.21961137046339\n",
      "resetting env. episode reward total was -20.0. running mean: -20.217415256758756\n",
      "resetting env. episode reward total was -20.0. running mean: -20.21524110419117\n",
      "resetting env. episode reward total was -21.0. running mean: -20.223088693149258\n",
      "resetting env. episode reward total was -21.0. running mean: -20.230857806217767\n",
      "resetting env. episode reward total was -20.0. running mean: -20.22854922815559\n",
      "resetting env. episode reward total was -20.0. running mean: -20.22626373587403\n",
      "resetting env. episode reward total was -21.0. running mean: -20.234001098515293\n",
      "resetting env. episode reward total was -20.0. running mean: -20.23166108753014\n",
      "resetting env. episode reward total was -20.0. running mean: -20.229344476654838\n",
      "resetting env. episode reward total was -21.0. running mean: -20.23705103188829\n",
      "resetting env. episode reward total was -21.0. running mean: -20.244680521569407\n",
      "resetting env. episode reward total was -21.0. running mean: -20.252233716353714\n",
      "resetting env. episode reward total was -20.0. running mean: -20.249711379190177\n",
      "resetting env. episode reward total was -20.0. running mean: -20.247214265398274\n",
      "resetting env. episode reward total was -21.0. running mean: -20.254742122744293\n",
      "resetting env. episode reward total was -20.0. running mean: -20.25219470151685\n",
      "resetting env. episode reward total was -18.0. running mean: -20.22967275450168\n",
      "resetting env. episode reward total was -21.0. running mean: -20.237376026956664\n",
      "resetting env. episode reward total was -20.0. running mean: -20.235002266687097\n",
      "resetting env. episode reward total was -20.0. running mean: -20.232652244020226\n",
      "resetting env. episode reward total was -20.0. running mean: -20.230325721580023\n",
      "resetting env. episode reward total was -19.0. running mean: -20.218022464364225\n",
      "resetting env. episode reward total was -21.0. running mean: -20.225842239720585\n",
      "resetting env. episode reward total was -21.0. running mean: -20.233583817323378\n",
      "resetting env. episode reward total was -17.0. running mean: -20.201247979150146\n",
      "resetting env. episode reward total was -19.0. running mean: -20.189235499358645\n",
      "resetting env. episode reward total was -20.0. running mean: -20.18734314436506\n",
      "resetting env. episode reward total was -21.0. running mean: -20.19546971292141\n",
      "resetting env. episode reward total was -18.0. running mean: -20.173515015792194\n",
      "resetting env. episode reward total was -20.0. running mean: -20.17177986563427\n",
      "resetting env. episode reward total was -17.0. running mean: -20.14006206697793\n",
      "resetting env. episode reward total was -20.0. running mean: -20.13866144630815\n",
      "resetting env. episode reward total was -18.0. running mean: -20.117274831845066\n",
      "resetting env. episode reward total was -20.0. running mean: -20.116102083526613\n",
      "resetting env. episode reward total was -21.0. running mean: -20.12494106269135\n",
      "resetting env. episode reward total was -20.0. running mean: -20.123691652064434\n",
      "resetting env. episode reward total was -19.0. running mean: -20.11245473554379\n",
      "resetting env. episode reward total was -19.0. running mean: -20.101330188188353\n",
      "resetting env. episode reward total was -20.0. running mean: -20.10031688630647\n",
      "resetting env. episode reward total was -21.0. running mean: -20.109313717443406\n",
      "resetting env. episode reward total was -20.0. running mean: -20.10822058026897\n",
      "resetting env. episode reward total was -20.0. running mean: -20.10713837446628\n",
      "resetting env. episode reward total was -19.0. running mean: -20.09606699072162\n",
      "resetting env. episode reward total was -18.0. running mean: -20.075106320814402\n",
      "resetting env. episode reward total was -19.0. running mean: -20.06435525760626\n",
      "resetting env. episode reward total was -20.0. running mean: -20.063711705030194\n",
      "resetting env. episode reward total was -21.0. running mean: -20.073074587979892\n",
      "resetting env. episode reward total was -19.0. running mean: -20.062343842100095\n",
      "resetting env. episode reward total was -21.0. running mean: -20.071720403679095\n",
      "resetting env. episode reward total was -20.0. running mean: -20.071003199642302\n",
      "resetting env. episode reward total was -21.0. running mean: -20.08029316764588\n",
      "resetting env. episode reward total was -19.0. running mean: -20.069490235969422\n",
      "resetting env. episode reward total was -20.0. running mean: -20.068795333609728\n",
      "resetting env. episode reward total was -20.0. running mean: -20.06810738027363\n",
      "resetting env. episode reward total was -21.0. running mean: -20.077426306470894\n",
      "resetting env. episode reward total was -19.0. running mean: -20.066652043406187\n",
      "resetting env. episode reward total was -21.0. running mean: -20.075985522972125\n",
      "resetting env. episode reward total was -20.0. running mean: -20.0752256677424\n",
      "resetting env. episode reward total was -20.0. running mean: -20.074473411064975\n",
      "resetting env. episode reward total was -20.0. running mean: -20.073728676954325\n",
      "resetting env. episode reward total was -21.0. running mean: -20.08299139018478\n",
      "resetting env. episode reward total was -19.0. running mean: -20.072161476282933\n",
      "resetting env. episode reward total was -19.0. running mean: -20.061439861520103\n",
      "resetting env. episode reward total was -21.0. running mean: -20.070825462904903\n",
      "resetting env. episode reward total was -20.0. running mean: -20.070117208275853\n",
      "resetting env. episode reward total was -21.0. running mean: -20.079416036193095\n",
      "resetting env. episode reward total was -20.0. running mean: -20.078621875831164\n",
      "resetting env. episode reward total was -21.0. running mean: -20.08783565707285\n",
      "resetting env. episode reward total was -20.0. running mean: -20.08695730050212\n",
      "resetting env. episode reward total was -18.0. running mean: -20.0660877274971\n",
      "resetting env. episode reward total was -20.0. running mean: -20.065426850222128\n",
      "resetting env. episode reward total was -19.0. running mean: -20.054772581719906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -18.0. running mean: -20.034224855902707\n",
      "resetting env. episode reward total was -21.0. running mean: -20.04388260734368\n",
      "resetting env. episode reward total was -21.0. running mean: -20.053443781270243\n",
      "resetting env. episode reward total was -20.0. running mean: -20.05290934345754\n",
      "resetting env. episode reward total was -21.0. running mean: -20.062380250022965\n",
      "resetting env. episode reward total was -19.0. running mean: -20.051756447522738\n",
      "resetting env. episode reward total was -21.0. running mean: -20.061238883047512\n",
      "resetting env. episode reward total was -21.0. running mean: -20.070626494217038\n",
      "resetting env. episode reward total was -20.0. running mean: -20.069920229274867\n",
      "resetting env. episode reward total was -21.0. running mean: -20.07922102698212\n",
      "resetting env. episode reward total was -18.0. running mean: -20.058428816712297\n",
      "resetting env. episode reward total was -21.0. running mean: -20.067844528545173\n",
      "resetting env. episode reward total was -19.0. running mean: -20.057166083259723\n",
      "resetting env. episode reward total was -19.0. running mean: -20.046594422427127\n",
      "resetting env. episode reward total was -21.0. running mean: -20.056128478202858\n",
      "resetting env. episode reward total was -20.0. running mean: -20.055567193420828\n",
      "resetting env. episode reward total was -20.0. running mean: -20.05501152148662\n",
      "resetting env. episode reward total was -19.0. running mean: -20.044461406271754\n",
      "resetting env. episode reward total was -21.0. running mean: -20.054016792209037\n",
      "resetting env. episode reward total was -21.0. running mean: -20.06347662428695\n",
      "resetting env. episode reward total was -20.0. running mean: -20.062841858044077\n",
      "resetting env. episode reward total was -20.0. running mean: -20.062213439463637\n",
      "resetting env. episode reward total was -21.0. running mean: -20.071591305069003\n",
      "resetting env. episode reward total was -20.0. running mean: -20.070875392018312\n",
      "resetting env. episode reward total was -21.0. running mean: -20.08016663809813\n",
      "resetting env. episode reward total was -21.0. running mean: -20.08936497171715\n",
      "resetting env. episode reward total was -20.0. running mean: -20.088471321999975\n",
      "resetting env. episode reward total was -20.0. running mean: -20.087586608779976\n",
      "resetting env. episode reward total was -20.0. running mean: -20.086710742692176\n",
      "resetting env. episode reward total was -21.0. running mean: -20.095843635265254\n",
      "resetting env. episode reward total was -20.0. running mean: -20.0948851989126\n",
      "resetting env. episode reward total was -21.0. running mean: -20.103936346923476\n",
      "resetting env. episode reward total was -19.0. running mean: -20.092896983454242\n",
      "resetting env. episode reward total was -21.0. running mean: -20.1019680136197\n",
      "resetting env. episode reward total was -21.0. running mean: -20.110948333483503\n",
      "resetting env. episode reward total was -21.0. running mean: -20.119838850148668\n",
      "resetting env. episode reward total was -20.0. running mean: -20.11864046164718\n",
      "resetting env. episode reward total was -21.0. running mean: -20.127454057030707\n",
      "resetting env. episode reward total was -19.0. running mean: -20.116179516460402\n",
      "resetting env. episode reward total was -21.0. running mean: -20.125017721295798\n",
      "resetting env. episode reward total was -19.0. running mean: -20.11376754408284\n",
      "resetting env. episode reward total was -19.0. running mean: -20.102629868642012\n",
      "resetting env. episode reward total was -19.0. running mean: -20.09160356995559\n",
      "resetting env. episode reward total was -19.0. running mean: -20.080687534256036\n",
      "resetting env. episode reward total was -20.0. running mean: -20.079880658913474\n",
      "resetting env. episode reward total was -20.0. running mean: -20.07908185232434\n",
      "resetting env. episode reward total was -19.0. running mean: -20.068291033801096\n",
      "resetting env. episode reward total was -19.0. running mean: -20.057608123463087\n",
      "resetting env. episode reward total was -19.0. running mean: -20.04703204222846\n",
      "resetting env. episode reward total was -19.0. running mean: -20.036561721806176\n",
      "resetting env. episode reward total was -20.0. running mean: -20.036196104588115\n",
      "resetting env. episode reward total was -20.0. running mean: -20.035834143542232\n",
      "resetting env. episode reward total was -21.0. running mean: -20.04547580210681\n",
      "resetting env. episode reward total was -19.0. running mean: -20.035021044085745\n",
      "resetting env. episode reward total was -20.0. running mean: -20.03467083364489\n",
      "resetting env. episode reward total was -20.0. running mean: -20.034324125308437\n",
      "resetting env. episode reward total was -19.0. running mean: -20.023980884055355\n",
      "resetting env. episode reward total was -19.0. running mean: -20.013741075214803\n",
      "resetting env. episode reward total was -20.0. running mean: -20.013603664462654\n",
      "resetting env. episode reward total was -20.0. running mean: -20.013467627818027\n",
      "resetting env. episode reward total was -18.0. running mean: -19.993332951539845\n",
      "resetting env. episode reward total was -18.0. running mean: -19.973399622024445\n",
      "resetting env. episode reward total was -21.0. running mean: -19.9836656258042\n",
      "resetting env. episode reward total was -21.0. running mean: -19.993828969546158\n",
      "resetting env. episode reward total was -20.0. running mean: -19.993890679850697\n",
      "resetting env. episode reward total was -20.0. running mean: -19.99395177305219\n",
      "resetting env. episode reward total was -21.0. running mean: -20.00401225532167\n",
      "resetting env. episode reward total was -20.0. running mean: -20.003972132768453\n",
      "resetting env. episode reward total was -20.0. running mean: -20.00393241144077\n",
      "resetting env. episode reward total was -20.0. running mean: -20.00389308732636\n",
      "resetting env. episode reward total was -21.0. running mean: -20.0138541564531\n",
      "resetting env. episode reward total was -21.0. running mean: -20.02371561488857\n",
      "resetting env. episode reward total was -19.0. running mean: -20.013478458739684\n",
      "resetting env. episode reward total was -19.0. running mean: -20.003343674152287\n",
      "resetting env. episode reward total was -18.0. running mean: -19.983310237410763\n",
      "resetting env. episode reward total was -20.0. running mean: -19.983477135036654\n",
      "resetting env. episode reward total was -20.0. running mean: -19.983642363686286\n",
      "resetting env. episode reward total was -20.0. running mean: -19.98380594004942\n",
      "resetting env. episode reward total was -21.0. running mean: -19.993967880648928\n",
      "resetting env. episode reward total was -20.0. running mean: -19.994028201842436\n",
      "resetting env. episode reward total was -20.0. running mean: -19.99408791982401\n",
      "resetting env. episode reward total was -21.0. running mean: -20.00414704062577\n",
      "resetting env. episode reward total was -21.0. running mean: -20.014105570219513\n",
      "resetting env. episode reward total was -19.0. running mean: -20.003964514517317\n",
      "resetting env. episode reward total was -21.0. running mean: -20.013924869372143\n",
      "resetting env. episode reward total was -20.0. running mean: -20.013785620678423\n",
      "resetting env. episode reward total was -19.0. running mean: -20.00364776447164\n",
      "resetting env. episode reward total was -19.0. running mean: -19.993611286826926\n",
      "resetting env. episode reward total was -20.0. running mean: -19.993675173958657\n",
      "resetting env. episode reward total was -20.0. running mean: -19.99373842221907\n",
      "resetting env. episode reward total was -19.0. running mean: -19.98380103799688\n",
      "resetting env. episode reward total was -20.0. running mean: -19.98396302761691\n",
      "resetting env. episode reward total was -19.0. running mean: -19.97412339734074\n",
      "resetting env. episode reward total was -21.0. running mean: -19.984382163367332\n",
      "resetting env. episode reward total was -17.0. running mean: -19.95453834173366\n",
      "resetting env. episode reward total was -20.0. running mean: -19.95499295831632\n",
      "resetting env. episode reward total was -20.0. running mean: -19.955443028733157\n",
      "resetting env. episode reward total was -21.0. running mean: -19.965888598445826\n",
      "resetting env. episode reward total was -21.0. running mean: -19.976229712461368\n",
      "resetting env. episode reward total was -19.0. running mean: -19.966467415336755\n",
      "resetting env. episode reward total was -19.0. running mean: -19.956802741183388\n",
      "resetting env. episode reward total was -18.0. running mean: -19.937234713771552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -19.0. running mean: -19.92786236663384\n",
      "resetting env. episode reward total was -20.0. running mean: -19.9285837429675\n",
      "resetting env. episode reward total was -21.0. running mean: -19.939297905537828\n",
      "resetting env. episode reward total was -18.0. running mean: -19.91990492648245\n",
      "resetting env. episode reward total was -20.0. running mean: -19.920705877217625\n",
      "resetting env. episode reward total was -21.0. running mean: -19.931498818445448\n",
      "resetting env. episode reward total was -21.0. running mean: -19.942183830260994\n",
      "resetting env. episode reward total was -21.0. running mean: -19.952761991958386\n",
      "resetting env. episode reward total was -19.0. running mean: -19.943234372038802\n",
      "resetting env. episode reward total was -20.0. running mean: -19.943802028318412\n",
      "resetting env. episode reward total was -19.0. running mean: -19.934364008035228\n",
      "resetting env. episode reward total was -17.0. running mean: -19.905020367954876\n",
      "resetting env. episode reward total was -17.0. running mean: -19.87597016427533\n",
      "resetting env. episode reward total was -20.0. running mean: -19.877210462632576\n",
      "resetting env. episode reward total was -18.0. running mean: -19.85843835800625\n",
      "resetting env. episode reward total was -20.0. running mean: -19.859853974426187\n",
      "resetting env. episode reward total was -20.0. running mean: -19.861255434681926\n",
      "resetting env. episode reward total was -21.0. running mean: -19.872642880335107\n",
      "resetting env. episode reward total was -20.0. running mean: -19.873916451531755\n",
      "resetting env. episode reward total was -19.0. running mean: -19.86517728701644\n",
      "resetting env. episode reward total was -16.0. running mean: -19.826525514146276\n",
      "resetting env. episode reward total was -19.0. running mean: -19.818260259004813\n",
      "resetting env. episode reward total was -19.0. running mean: -19.810077656414766\n",
      "resetting env. episode reward total was -19.0. running mean: -19.80197687985062\n",
      "resetting env. episode reward total was -21.0. running mean: -19.813957111052115\n",
      "resetting env. episode reward total was -17.0. running mean: -19.785817539941597\n",
      "resetting env. episode reward total was -21.0. running mean: -19.79795936454218\n",
      "resetting env. episode reward total was -21.0. running mean: -19.80997977089676\n",
      "resetting env. episode reward total was -20.0. running mean: -19.811879973187793\n",
      "resetting env. episode reward total was -21.0. running mean: -19.823761173455914\n",
      "resetting env. episode reward total was -19.0. running mean: -19.815523561721356\n",
      "resetting env. episode reward total was -20.0. running mean: -19.81736832610414\n",
      "resetting env. episode reward total was -21.0. running mean: -19.8291946428431\n",
      "resetting env. episode reward total was -19.0. running mean: -19.82090269641467\n",
      "resetting env. episode reward total was -20.0. running mean: -19.822693669450523\n",
      "resetting env. episode reward total was -19.0. running mean: -19.814466732756017\n",
      "resetting env. episode reward total was -18.0. running mean: -19.796322065428456\n",
      "resetting env. episode reward total was -20.0. running mean: -19.79835884477417\n",
      "resetting env. episode reward total was -19.0. running mean: -19.79037525632643\n",
      "resetting env. episode reward total was -21.0. running mean: -19.80247150376317\n",
      "resetting env. episode reward total was -18.0. running mean: -19.784446788725536\n",
      "resetting env. episode reward total was -20.0. running mean: -19.78660232083828\n",
      "resetting env. episode reward total was -19.0. running mean: -19.778736297629898\n",
      "resetting env. episode reward total was -21.0. running mean: -19.7909489346536\n",
      "resetting env. episode reward total was -20.0. running mean: -19.793039445307063\n",
      "resetting env. episode reward total was -21.0. running mean: -19.805109050853993\n",
      "resetting env. episode reward total was -19.0. running mean: -19.797057960345455\n",
      "resetting env. episode reward total was -21.0. running mean: -19.809087380742003\n",
      "resetting env. episode reward total was -20.0. running mean: -19.810996506934583\n",
      "resetting env. episode reward total was -20.0. running mean: -19.812886541865236\n",
      "resetting env. episode reward total was -19.0. running mean: -19.804757676446584\n",
      "resetting env. episode reward total was -19.0. running mean: -19.79671009968212\n",
      "resetting env. episode reward total was -19.0. running mean: -19.7887429986853\n",
      "resetting env. episode reward total was -21.0. running mean: -19.80085556869845\n",
      "resetting env. episode reward total was -19.0. running mean: -19.792847013011464\n",
      "resetting env. episode reward total was -19.0. running mean: -19.78491854288135\n",
      "resetting env. episode reward total was -17.0. running mean: -19.757069357452536\n",
      "resetting env. episode reward total was -20.0. running mean: -19.75949866387801\n",
      "resetting env. episode reward total was -20.0. running mean: -19.76190367723923\n",
      "resetting env. episode reward total was -19.0. running mean: -19.75428464046684\n",
      "resetting env. episode reward total was -20.0. running mean: -19.75674179406217\n",
      "resetting env. episode reward total was -21.0. running mean: -19.769174376121548\n",
      "resetting env. episode reward total was -21.0. running mean: -19.781482632360333\n",
      "resetting env. episode reward total was -19.0. running mean: -19.77366780603673\n",
      "resetting env. episode reward total was -19.0. running mean: -19.765931127976366\n",
      "resetting env. episode reward total was -21.0. running mean: -19.778271816696602\n",
      "resetting env. episode reward total was -21.0. running mean: -19.790489098529637\n",
      "resetting env. episode reward total was -20.0. running mean: -19.79258420754434\n",
      "resetting env. episode reward total was -18.0. running mean: -19.7746583654689\n",
      "resetting env. episode reward total was -21.0. running mean: -19.78691178181421\n",
      "resetting env. episode reward total was -20.0. running mean: -19.789042663996067\n",
      "resetting env. episode reward total was -19.0. running mean: -19.781152237356107\n",
      "resetting env. episode reward total was -17.0. running mean: -19.753340714982546\n",
      "resetting env. episode reward total was -19.0. running mean: -19.74580730783272\n",
      "resetting env. episode reward total was -18.0. running mean: -19.728349234754393\n",
      "resetting env. episode reward total was -17.0. running mean: -19.70106574240685\n",
      "resetting env. episode reward total was -19.0. running mean: -19.694055084982782\n",
      "resetting env. episode reward total was -16.0. running mean: -19.657114534132955\n",
      "resetting env. episode reward total was -20.0. running mean: -19.660543388791623\n",
      "resetting env. episode reward total was -20.0. running mean: -19.663937954903705\n",
      "resetting env. episode reward total was -19.0. running mean: -19.65729857535467\n",
      "resetting env. episode reward total was -17.0. running mean: -19.630725589601123\n",
      "resetting env. episode reward total was -21.0. running mean: -19.64441833370511\n",
      "resetting env. episode reward total was -19.0. running mean: -19.637974150368063\n",
      "resetting env. episode reward total was -19.0. running mean: -19.631594408864384\n",
      "resetting env. episode reward total was -18.0. running mean: -19.615278464775738\n",
      "resetting env. episode reward total was -19.0. running mean: -19.60912568012798\n",
      "resetting env. episode reward total was -16.0. running mean: -19.5730344233267\n",
      "resetting env. episode reward total was -20.0. running mean: -19.57730407909343\n",
      "resetting env. episode reward total was -19.0. running mean: -19.571531038302496\n",
      "resetting env. episode reward total was -19.0. running mean: -19.56581572791947\n",
      "resetting env. episode reward total was -17.0. running mean: -19.54015757064028\n",
      "resetting env. episode reward total was -18.0. running mean: -19.524755994933876\n",
      "resetting env. episode reward total was -21.0. running mean: -19.539508434984537\n",
      "resetting env. episode reward total was -21.0. running mean: -19.554113350634694\n",
      "resetting env. episode reward total was -19.0. running mean: -19.54857221712835\n",
      "resetting env. episode reward total was -21.0. running mean: -19.563086494957066\n",
      "resetting env. episode reward total was -21.0. running mean: -19.577455630007496\n",
      "resetting env. episode reward total was -19.0. running mean: -19.57168107370742\n",
      "resetting env. episode reward total was -21.0. running mean: -19.585964262970347\n",
      "resetting env. episode reward total was -21.0. running mean: -19.600104620340645\n",
      "resetting env. episode reward total was -19.0. running mean: -19.59410357413724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -18.0. running mean: -19.578162538395866\n",
      "resetting env. episode reward total was -21.0. running mean: -19.592380913011908\n",
      "resetting env. episode reward total was -20.0. running mean: -19.59645710388179\n",
      "resetting env. episode reward total was -20.0. running mean: -19.60049253284297\n",
      "resetting env. episode reward total was -15.0. running mean: -19.554487607514538\n",
      "resetting env. episode reward total was -19.0. running mean: -19.548942731439393\n",
      "resetting env. episode reward total was -21.0. running mean: -19.563453304124998\n",
      "resetting env. episode reward total was -20.0. running mean: -19.567818771083747\n",
      "resetting env. episode reward total was -21.0. running mean: -19.58214058337291\n",
      "resetting env. episode reward total was -20.0. running mean: -19.58631917753918\n",
      "resetting env. episode reward total was -20.0. running mean: -19.59045598576379\n",
      "resetting env. episode reward total was -18.0. running mean: -19.57455142590615\n",
      "resetting env. episode reward total was -20.0. running mean: -19.578805911647088\n",
      "resetting env. episode reward total was -18.0. running mean: -19.563017852530617\n",
      "resetting env. episode reward total was -17.0. running mean: -19.537387674005313\n",
      "resetting env. episode reward total was -17.0. running mean: -19.51201379726526\n",
      "resetting env. episode reward total was -19.0. running mean: -19.50689365929261\n",
      "resetting env. episode reward total was -20.0. running mean: -19.511824722699686\n",
      "resetting env. episode reward total was -20.0. running mean: -19.516706475472688\n",
      "resetting env. episode reward total was -20.0. running mean: -19.52153941071796\n",
      "resetting env. episode reward total was -19.0. running mean: -19.51632401661078\n",
      "resetting env. episode reward total was -18.0. running mean: -19.501160776444674\n",
      "resetting env. episode reward total was -15.0. running mean: -19.456149168680227\n",
      "resetting env. episode reward total was -19.0. running mean: -19.451587676993427\n",
      "resetting env. episode reward total was -19.0. running mean: -19.447071800223494\n",
      "resetting env. episode reward total was -20.0. running mean: -19.452601082221257\n",
      "resetting env. episode reward total was -20.0. running mean: -19.458075071399044\n",
      "resetting env. episode reward total was -18.0. running mean: -19.443494320685055\n",
      "resetting env. episode reward total was -18.0. running mean: -19.429059377478204\n",
      "resetting env. episode reward total was -19.0. running mean: -19.424768783703424\n",
      "resetting env. episode reward total was -21.0. running mean: -19.44052109586639\n",
      "resetting env. episode reward total was -18.0. running mean: -19.426115884907727\n",
      "resetting env. episode reward total was -18.0. running mean: -19.41185472605865\n",
      "resetting env. episode reward total was -19.0. running mean: -19.407736178798064\n",
      "resetting env. episode reward total was -19.0. running mean: -19.403658817010086\n",
      "resetting env. episode reward total was -18.0. running mean: -19.389622228839986\n",
      "resetting env. episode reward total was -19.0. running mean: -19.385726006551586\n",
      "resetting env. episode reward total was -18.0. running mean: -19.37186874648607\n",
      "resetting env. episode reward total was -20.0. running mean: -19.378150059021205\n",
      "resetting env. episode reward total was -18.0. running mean: -19.364368558430993\n",
      "resetting env. episode reward total was -20.0. running mean: -19.370724872846683\n",
      "resetting env. episode reward total was -18.0. running mean: -19.357017624118217\n",
      "resetting env. episode reward total was -18.0. running mean: -19.343447447877036\n",
      "resetting env. episode reward total was -21.0. running mean: -19.360012973398266\n",
      "resetting env. episode reward total was -20.0. running mean: -19.366412843664282\n",
      "resetting env. episode reward total was -17.0. running mean: -19.34274871522764\n",
      "resetting env. episode reward total was -19.0. running mean: -19.339321228075363\n",
      "resetting env. episode reward total was -19.0. running mean: -19.33592801579461\n",
      "resetting env. episode reward total was -18.0. running mean: -19.322568735636665\n",
      "resetting env. episode reward total was -17.0. running mean: -19.2993430482803\n",
      "resetting env. episode reward total was -19.0. running mean: -19.296349617797496\n",
      "resetting env. episode reward total was -18.0. running mean: -19.28338612161952\n",
      "resetting env. episode reward total was -19.0. running mean: -19.28055226040333\n",
      "resetting env. episode reward total was -19.0. running mean: -19.277746737799298\n",
      "resetting env. episode reward total was -19.0. running mean: -19.274969270421305\n",
      "resetting env. episode reward total was -16.0. running mean: -19.24221957771709\n",
      "resetting env. episode reward total was -19.0. running mean: -19.23979738193992\n",
      "resetting env. episode reward total was -19.0. running mean: -19.23739940812052\n",
      "resetting env. episode reward total was -19.0. running mean: -19.235025414039317\n",
      "resetting env. episode reward total was -19.0. running mean: -19.232675159898925\n",
      "resetting env. episode reward total was -18.0. running mean: -19.220348408299934\n",
      "resetting env. episode reward total was -19.0. running mean: -19.218144924216936\n",
      "resetting env. episode reward total was -20.0. running mean: -19.225963474974765\n",
      "resetting env. episode reward total was -19.0. running mean: -19.22370384022502\n",
      "resetting env. episode reward total was -19.0. running mean: -19.22146680182277\n",
      "resetting env. episode reward total was -18.0. running mean: -19.209252133804544\n",
      "resetting env. episode reward total was -17.0. running mean: -19.1871596124665\n",
      "resetting env. episode reward total was -21.0. running mean: -19.205288016341832\n",
      "resetting env. episode reward total was -13.0. running mean: -19.14323513617841\n",
      "resetting env. episode reward total was -18.0. running mean: -19.131802784816628\n",
      "resetting env. episode reward total was -21.0. running mean: -19.150484756968464\n",
      "resetting env. episode reward total was -19.0. running mean: -19.14897990939878\n",
      "resetting env. episode reward total was -20.0. running mean: -19.157490110304792\n",
      "resetting env. episode reward total was -16.0. running mean: -19.125915209201743\n",
      "resetting env. episode reward total was -16.0. running mean: -19.094656057109727\n",
      "resetting env. episode reward total was -19.0. running mean: -19.09370949653863\n",
      "resetting env. episode reward total was -17.0. running mean: -19.072772401573246\n",
      "resetting env. episode reward total was -15.0. running mean: -19.03204467755751\n",
      "resetting env. episode reward total was -18.0. running mean: -19.021724230781935\n",
      "resetting env. episode reward total was -18.0. running mean: -19.011506988474114\n",
      "resetting env. episode reward total was -17.0. running mean: -18.991391918589375\n",
      "resetting env. episode reward total was -19.0. running mean: -18.991477999403482\n",
      "resetting env. episode reward total was -19.0. running mean: -18.99156321940945\n",
      "resetting env. episode reward total was -17.0. running mean: -18.971647587215358\n",
      "resetting env. episode reward total was -18.0. running mean: -18.961931111343205\n",
      "resetting env. episode reward total was -21.0. running mean: -18.982311800229773\n",
      "resetting env. episode reward total was -16.0. running mean: -18.952488682227475\n",
      "resetting env. episode reward total was -18.0. running mean: -18.9429637954052\n",
      "resetting env. episode reward total was -18.0. running mean: -18.933534157451145\n",
      "resetting env. episode reward total was -19.0. running mean: -18.934198815876634\n",
      "resetting env. episode reward total was -19.0. running mean: -18.93485682771787\n",
      "resetting env. episode reward total was -16.0. running mean: -18.90550825944069\n",
      "resetting env. episode reward total was -21.0. running mean: -18.926453176846284\n",
      "resetting env. episode reward total was -19.0. running mean: -18.927188645077823\n",
      "resetting env. episode reward total was -20.0. running mean: -18.937916758627043\n",
      "resetting env. episode reward total was -16.0. running mean: -18.908537591040773\n",
      "resetting env. episode reward total was -19.0. running mean: -18.909452215130365\n",
      "resetting env. episode reward total was -18.0. running mean: -18.90035769297906\n",
      "resetting env. episode reward total was -17.0. running mean: -18.88135411604927\n",
      "resetting env. episode reward total was -17.0. running mean: -18.86254057488878\n",
      "resetting env. episode reward total was -21.0. running mean: -18.883915169139893\n",
      "resetting env. episode reward total was -18.0. running mean: -18.875076017448492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -19.0. running mean: -18.876325257274008\n",
      "resetting env. episode reward total was -16.0. running mean: -18.847562004701267\n",
      "resetting env. episode reward total was -21.0. running mean: -18.869086384654256\n",
      "resetting env. episode reward total was -20.0. running mean: -18.880395520807713\n",
      "resetting env. episode reward total was -20.0. running mean: -18.891591565599636\n",
      "resetting env. episode reward total was -21.0. running mean: -18.91267564994364\n",
      "resetting env. episode reward total was -19.0. running mean: -18.913548893444204\n",
      "resetting env. episode reward total was -20.0. running mean: -18.92441340450976\n",
      "resetting env. episode reward total was -17.0. running mean: -18.905169270464665\n",
      "resetting env. episode reward total was -18.0. running mean: -18.896117577760016\n",
      "resetting env. episode reward total was -19.0. running mean: -18.897156401982418\n",
      "resetting env. episode reward total was -21.0. running mean: -18.918184837962595\n",
      "resetting env. episode reward total was -15.0. running mean: -18.87900298958297\n",
      "resetting env. episode reward total was -21.0. running mean: -18.90021295968714\n",
      "resetting env. episode reward total was -18.0. running mean: -18.891210830090266\n",
      "resetting env. episode reward total was -16.0. running mean: -18.86229872178936\n",
      "resetting env. episode reward total was -18.0. running mean: -18.853675734571468\n",
      "resetting env. episode reward total was -21.0. running mean: -18.875138977225753\n",
      "resetting env. episode reward total was -21.0. running mean: -18.896387587453496\n",
      "resetting env. episode reward total was -16.0. running mean: -18.86742371157896\n",
      "resetting env. episode reward total was -15.0. running mean: -18.82874947446317\n",
      "resetting env. episode reward total was -21.0. running mean: -18.85046197971854\n",
      "resetting env. episode reward total was -16.0. running mean: -18.821957359921353\n",
      "resetting env. episode reward total was -18.0. running mean: -18.81373778632214\n",
      "resetting env. episode reward total was -21.0. running mean: -18.83560040845892\n",
      "resetting env. episode reward total was -19.0. running mean: -18.83724440437433\n",
      "resetting env. episode reward total was -21.0. running mean: -18.85887196033059\n",
      "resetting env. episode reward total was -21.0. running mean: -18.880283240727284\n",
      "resetting env. episode reward total was -19.0. running mean: -18.881480408320012\n",
      "resetting env. episode reward total was -21.0. running mean: -18.902665604236812\n",
      "resetting env. episode reward total was -14.0. running mean: -18.853638948194444\n",
      "resetting env. episode reward total was -20.0. running mean: -18.865102558712497\n",
      "resetting env. episode reward total was -20.0. running mean: -18.876451533125373\n",
      "resetting env. episode reward total was -16.0. running mean: -18.84768701779412\n",
      "resetting env. episode reward total was -19.0. running mean: -18.84921014761618\n",
      "resetting env. episode reward total was -17.0. running mean: -18.83071804614002\n",
      "resetting env. episode reward total was -15.0. running mean: -18.79241086567862\n",
      "resetting env. episode reward total was -17.0. running mean: -18.774486757021833\n",
      "resetting env. episode reward total was -21.0. running mean: -18.796741889451617\n",
      "resetting env. episode reward total was -19.0. running mean: -18.798774470557102\n",
      "resetting env. episode reward total was -19.0. running mean: -18.800786725851534\n",
      "resetting env. episode reward total was -18.0. running mean: -18.792778858593017\n",
      "resetting env. episode reward total was -17.0. running mean: -18.774851070007088\n",
      "resetting env. episode reward total was -19.0. running mean: -18.777102559307018\n",
      "resetting env. episode reward total was -17.0. running mean: -18.75933153371395\n",
      "resetting env. episode reward total was -17.0. running mean: -18.741738218376813\n",
      "resetting env. episode reward total was -17.0. running mean: -18.724320836193048\n",
      "resetting env. episode reward total was -17.0. running mean: -18.724320836193048\n",
      "resetting env. episode reward total was -20.0. running mean: -18.737077627831116\n",
      "resetting env. episode reward total was -18.0. running mean: -18.729706851552805\n",
      "resetting env. episode reward total was -17.0. running mean: -18.71240978303728\n",
      "resetting env. episode reward total was -19.0. running mean: -18.715285685206908\n",
      "resetting env. episode reward total was -15.0. running mean: -18.678132828354837\n",
      "resetting env. episode reward total was -17.0. running mean: -18.66135150007129\n",
      "resetting env. episode reward total was -19.0. running mean: -18.66473798507058\n",
      "resetting env. episode reward total was -19.0. running mean: -18.668090605219877\n",
      "resetting env. episode reward total was -18.0. running mean: -18.661409699167677\n",
      "resetting env. episode reward total was -19.0. running mean: -18.664795602176003\n",
      "resetting env. episode reward total was -19.0. running mean: -18.668147646154246\n",
      "resetting env. episode reward total was -17.0. running mean: -18.651466169692704\n",
      "resetting env. episode reward total was -15.0. running mean: -18.614951507995777\n",
      "resetting env. episode reward total was -20.0. running mean: -18.628801992915818\n",
      "resetting env. episode reward total was -19.0. running mean: -18.63251397298666\n",
      "resetting env. episode reward total was -17.0. running mean: -18.616188833256796\n",
      "resetting env. episode reward total was -20.0. running mean: -18.63002694492423\n",
      "resetting env. episode reward total was -15.0. running mean: -18.593726675474986\n",
      "resetting env. episode reward total was -17.0. running mean: -18.57778940872024\n",
      "resetting env. episode reward total was -18.0. running mean: -18.572011514633036\n",
      "resetting env. episode reward total was -17.0. running mean: -18.556291399486707\n",
      "resetting env. episode reward total was -14.0. running mean: -18.51072848549184\n",
      "resetting env. episode reward total was -18.0. running mean: -18.50562120063692\n",
      "resetting env. episode reward total was -18.0. running mean: -18.50056498863055\n",
      "resetting env. episode reward total was -16.0. running mean: -18.475559338744244\n",
      "resetting env. episode reward total was -15.0. running mean: -18.4408037453568\n",
      "resetting env. episode reward total was -17.0. running mean: -18.426395707903232\n",
      "resetting env. episode reward total was -21.0. running mean: -18.4521317508242\n",
      "resetting env. episode reward total was -14.0. running mean: -18.40761043331596\n",
      "resetting env. episode reward total was -13.0. running mean: -18.3535343289828\n",
      "resetting env. episode reward total was -20.0. running mean: -18.36999898569297\n",
      "resetting env. episode reward total was -18.0. running mean: -18.36629899583604\n",
      "resetting env. episode reward total was -17.0. running mean: -18.35263600587768\n",
      "resetting env. episode reward total was -15.0. running mean: -18.3191096458189\n",
      "resetting env. episode reward total was -16.0. running mean: -18.295918549360714\n",
      "resetting env. episode reward total was -20.0. running mean: -18.312959363867105\n",
      "resetting env. episode reward total was -19.0. running mean: -18.319829770228434\n",
      "resetting env. episode reward total was -17.0. running mean: -18.306631472526153\n",
      "resetting env. episode reward total was -16.0. running mean: -18.28356515780089\n",
      "resetting env. episode reward total was -17.0. running mean: -18.27072950622288\n",
      "resetting env. episode reward total was -19.0. running mean: -18.278022211160653\n",
      "resetting env. episode reward total was -19.0. running mean: -18.285241989049048\n",
      "resetting env. episode reward total was -16.0. running mean: -18.262389569158557\n",
      "resetting env. episode reward total was -18.0. running mean: -18.259765673466973\n",
      "resetting env. episode reward total was -19.0. running mean: -18.267168016732303\n",
      "resetting env. episode reward total was -20.0. running mean: -18.284496336564978\n",
      "resetting env. episode reward total was -15.0. running mean: -18.251651373199326\n",
      "resetting env. episode reward total was -19.0. running mean: -18.259134859467334\n",
      "resetting env. episode reward total was -17.0. running mean: -18.246543510872662\n",
      "resetting env. episode reward total was -19.0. running mean: -18.254078075763935\n",
      "resetting env. episode reward total was -19.0. running mean: -18.261537295006296\n",
      "resetting env. episode reward total was -15.0. running mean: -18.22892192205623\n",
      "resetting env. episode reward total was -20.0. running mean: -18.24663270283567\n",
      "resetting env. episode reward total was -15.0. running mean: -18.21416637580731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -20.0. running mean: -18.232024712049235\n",
      "resetting env. episode reward total was -18.0. running mean: -18.22970446492874\n",
      "resetting env. episode reward total was -19.0. running mean: -18.237407420279453\n",
      "resetting env. episode reward total was -13.0. running mean: -18.185033346076658\n",
      "resetting env. episode reward total was -13.0. running mean: -18.13318301261589\n",
      "resetting env. episode reward total was -20.0. running mean: -18.151851182489732\n",
      "resetting env. episode reward total was -21.0. running mean: -18.180332670664836\n",
      "resetting env. episode reward total was -17.0. running mean: -18.168529343958188\n",
      "resetting env. episode reward total was -16.0. running mean: -18.146844050518606\n",
      "resetting env. episode reward total was -17.0. running mean: -18.135375610013423\n",
      "resetting env. episode reward total was -20.0. running mean: -18.15402185391329\n",
      "resetting env. episode reward total was -15.0. running mean: -18.122481635374154\n",
      "resetting env. episode reward total was -19.0. running mean: -18.131256819020415\n",
      "resetting env. episode reward total was -19.0. running mean: -18.13994425083021\n",
      "resetting env. episode reward total was -17.0. running mean: -18.128544808321912\n",
      "resetting env. episode reward total was -17.0. running mean: -18.117259360238695\n",
      "resetting env. episode reward total was -14.0. running mean: -18.07608676663631\n",
      "resetting env. episode reward total was -17.0. running mean: -18.065325898969945\n",
      "resetting env. episode reward total was -18.0. running mean: -18.064672639980245\n",
      "resetting env. episode reward total was -16.0. running mean: -18.04402591358044\n",
      "resetting env. episode reward total was -18.0. running mean: -18.043585654444637\n",
      "resetting env. episode reward total was -20.0. running mean: -18.06314979790019\n",
      "resetting env. episode reward total was -19.0. running mean: -18.07251829992119\n",
      "resetting env. episode reward total was -16.0. running mean: -18.051793116921978\n",
      "resetting env. episode reward total was -16.0. running mean: -18.031275185752758\n",
      "resetting env. episode reward total was -17.0. running mean: -18.02096243389523\n",
      "resetting env. episode reward total was -16.0. running mean: -18.00075280955628\n",
      "resetting env. episode reward total was -12.0. running mean: -17.940745281460718\n",
      "resetting env. episode reward total was -18.0. running mean: -17.94133782864611\n",
      "resetting env. episode reward total was -17.0. running mean: -17.93192445035965\n",
      "resetting env. episode reward total was -14.0. running mean: -17.892605205856054\n",
      "resetting env. episode reward total was -18.0. running mean: -17.893679153797493\n",
      "resetting env. episode reward total was -20.0. running mean: -17.914742362259517\n",
      "resetting env. episode reward total was -14.0. running mean: -17.875594938636922\n",
      "resetting env. episode reward total was -16.0. running mean: -17.85683898925055\n",
      "resetting env. episode reward total was -18.0. running mean: -17.858270599358047\n",
      "resetting env. episode reward total was -20.0. running mean: -17.879687893364466\n",
      "resetting env. episode reward total was -17.0. running mean: -17.87089101443082\n",
      "resetting env. episode reward total was -21.0. running mean: -17.902182104286513\n",
      "resetting env. episode reward total was -15.0. running mean: -17.873160283243646\n",
      "resetting env. episode reward total was -17.0. running mean: -17.864428680411212\n",
      "resetting env. episode reward total was -19.0. running mean: -17.875784393607102\n",
      "resetting env. episode reward total was -17.0. running mean: -17.86702654967103\n",
      "resetting env. episode reward total was -14.0. running mean: -17.828356284174323\n",
      "resetting env. episode reward total was -18.0. running mean: -17.83007272133258\n",
      "resetting env. episode reward total was -17.0. running mean: -17.821771994119256\n",
      "resetting env. episode reward total was -17.0. running mean: -17.813554274178067\n",
      "resetting env. episode reward total was -18.0. running mean: -17.815418731436285\n",
      "resetting env. episode reward total was -16.0. running mean: -17.797264544121923\n",
      "resetting env. episode reward total was -17.0. running mean: -17.789291898680705\n",
      "resetting env. episode reward total was -14.0. running mean: -17.7513989796939\n",
      "resetting env. episode reward total was -16.0. running mean: -17.73388498989696\n",
      "resetting env. episode reward total was -17.0. running mean: -17.726546139997993\n",
      "resetting env. episode reward total was -19.0. running mean: -17.739280678598014\n",
      "resetting env. episode reward total was -19.0. running mean: -17.751887871812034\n",
      "resetting env. episode reward total was -16.0. running mean: -17.734368993093913\n",
      "resetting env. episode reward total was -19.0. running mean: -17.747025303162975\n",
      "resetting env. episode reward total was -17.0. running mean: -17.739555050131347\n",
      "resetting env. episode reward total was -15.0. running mean: -17.712159499630033\n",
      "resetting env. episode reward total was -18.0. running mean: -17.715037904633732\n",
      "resetting env. episode reward total was -18.0. running mean: -17.717887525587393\n",
      "resetting env. episode reward total was -20.0. running mean: -17.74070865033152\n",
      "resetting env. episode reward total was -17.0. running mean: -17.733301563828206\n",
      "resetting env. episode reward total was -18.0. running mean: -17.735968548189923\n",
      "resetting env. episode reward total was -18.0. running mean: -17.738608862708023\n",
      "resetting env. episode reward total was -14.0. running mean: -17.701222774080943\n",
      "resetting env. episode reward total was -20.0. running mean: -17.72421054634013\n",
      "resetting env. episode reward total was -16.0. running mean: -17.70696844087673\n",
      "resetting env. episode reward total was -17.0. running mean: -17.699898756467963\n",
      "resetting env. episode reward total was -13.0. running mean: -17.652899768903282\n",
      "resetting env. episode reward total was -16.0. running mean: -17.63637077121425\n",
      "resetting env. episode reward total was -13.0. running mean: -17.590007063502107\n",
      "resetting env. episode reward total was -9.0. running mean: -17.504106992867086\n",
      "resetting env. episode reward total was -15.0. running mean: -17.479065922938414\n",
      "resetting env. episode reward total was -20.0. running mean: -17.50427526370903\n",
      "resetting env. episode reward total was -17.0. running mean: -17.49923251107194\n",
      "resetting env. episode reward total was -17.0. running mean: -17.494240185961225\n",
      "resetting env. episode reward total was -14.0. running mean: -17.45929778410161\n",
      "resetting env. episode reward total was -17.0. running mean: -17.454704806260597\n",
      "resetting env. episode reward total was -14.0. running mean: -17.42015775819799\n",
      "resetting env. episode reward total was -18.0. running mean: -17.425956180616012\n",
      "resetting env. episode reward total was -15.0. running mean: -17.40169661880985\n",
      "resetting env. episode reward total was -16.0. running mean: -17.387679652621753\n",
      "resetting env. episode reward total was -16.0. running mean: -17.373802856095534\n",
      "resetting env. episode reward total was -19.0. running mean: -17.39006482753458\n",
      "resetting env. episode reward total was -19.0. running mean: -17.406164179259235\n",
      "resetting env. episode reward total was -19.0. running mean: -17.422102537466643\n",
      "resetting env. episode reward total was -16.0. running mean: -17.407881512091976\n",
      "resetting env. episode reward total was -19.0. running mean: -17.423802696971055\n",
      "resetting env. episode reward total was -17.0. running mean: -17.419564670001346\n",
      "resetting env. episode reward total was -19.0. running mean: -17.435369023301334\n",
      "resetting env. episode reward total was -17.0. running mean: -17.431015333068324\n",
      "resetting env. episode reward total was -17.0. running mean: -17.42670517973764\n",
      "resetting env. episode reward total was -17.0. running mean: -17.422438127940268\n",
      "resetting env. episode reward total was -13.0. running mean: -17.378213746660865\n",
      "resetting env. episode reward total was -18.0. running mean: -17.384431609194255\n",
      "resetting env. episode reward total was -16.0. running mean: -17.370587293102314\n",
      "resetting env. episode reward total was -13.0. running mean: -17.32688142017129\n",
      "resetting env. episode reward total was -19.0. running mean: -17.34361260596958\n",
      "resetting env. episode reward total was -16.0. running mean: -17.330176479909884\n",
      "resetting env. episode reward total was -15.0. running mean: -17.306874715110784\n",
      "resetting env. episode reward total was -15.0. running mean: -17.283805967959673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -12.0. running mean: -17.230967908280075\n",
      "resetting env. episode reward total was -14.0. running mean: -17.198658229197274\n",
      "resetting env. episode reward total was -15.0. running mean: -17.1766716469053\n",
      "resetting env. episode reward total was -19.0. running mean: -17.19490493043625\n",
      "resetting env. episode reward total was -16.0. running mean: -17.182955881131885\n",
      "resetting env. episode reward total was -18.0. running mean: -17.191126322320567\n",
      "resetting env. episode reward total was -13.0. running mean: -17.14921505909736\n",
      "resetting env. episode reward total was -15.0. running mean: -17.127722908506385\n",
      "resetting env. episode reward total was -15.0. running mean: -17.10644567942132\n",
      "resetting env. episode reward total was -14.0. running mean: -17.075381222627108\n",
      "resetting env. episode reward total was -11.0. running mean: -17.014627410400838\n",
      "resetting env. episode reward total was -17.0. running mean: -17.01448113629683\n",
      "resetting env. episode reward total was -15.0. running mean: -16.994336324933858\n",
      "resetting env. episode reward total was -17.0. running mean: -16.99439296168452\n",
      "resetting env. episode reward total was -21.0. running mean: -17.034449032067677\n",
      "resetting env. episode reward total was -14.0. running mean: -17.004104541747\n",
      "resetting env. episode reward total was -17.0. running mean: -17.004063496329533\n",
      "resetting env. episode reward total was -16.0. running mean: -16.994022861366236\n",
      "resetting env. episode reward total was -20.0. running mean: -17.024082632752574\n",
      "resetting env. episode reward total was -17.0. running mean: -17.02384180642505\n",
      "resetting env. episode reward total was -13.0. running mean: -16.983603388360798\n",
      "resetting env. episode reward total was -13.0. running mean: -16.94376735447719\n",
      "resetting env. episode reward total was -17.0. running mean: -16.94432968093242\n",
      "resetting env. episode reward total was -16.0. running mean: -16.934886384123097\n",
      "resetting env. episode reward total was -14.0. running mean: -16.905537520281865\n",
      "resetting env. episode reward total was -15.0. running mean: -16.886482145079043\n",
      "resetting env. episode reward total was -15.0. running mean: -16.867617323628252\n",
      "resetting env. episode reward total was -17.0. running mean: -16.868941150391972\n",
      "resetting env. episode reward total was -19.0. running mean: -16.890251738888054\n",
      "resetting env. episode reward total was -17.0. running mean: -16.891349221499176\n",
      "resetting env. episode reward total was -16.0. running mean: -16.882435729284186\n",
      "resetting env. episode reward total was -17.0. running mean: -16.883611371991346\n",
      "resetting env. episode reward total was -16.0. running mean: -16.874775258271434\n",
      "resetting env. episode reward total was -16.0. running mean: -16.86602750568872\n",
      "resetting env. episode reward total was -13.0. running mean: -16.827367230631832\n",
      "resetting env. episode reward total was -14.0. running mean: -16.799093558325513\n",
      "resetting env. episode reward total was -14.0. running mean: -16.77110262274226\n",
      "resetting env. episode reward total was -18.0. running mean: -16.783391596514836\n",
      "resetting env. episode reward total was -17.0. running mean: -16.78555768054969\n",
      "resetting env. episode reward total was -16.0. running mean: -16.777702103744193\n",
      "resetting env. episode reward total was -19.0. running mean: -16.799925082706753\n",
      "resetting env. episode reward total was -16.0. running mean: -16.791925831879684\n",
      "resetting env. episode reward total was -13.0. running mean: -16.754006573560886\n",
      "resetting env. episode reward total was -16.0. running mean: -16.74646650782528\n",
      "resetting env. episode reward total was -19.0. running mean: -16.769001842747027\n",
      "resetting env. episode reward total was -21.0. running mean: -16.811311824319557\n",
      "resetting env. episode reward total was -17.0. running mean: -16.813198706076363\n",
      "resetting env. episode reward total was -18.0. running mean: -16.8250667190156\n",
      "resetting env. episode reward total was -13.0. running mean: -16.78681605182544\n",
      "resetting env. episode reward total was -15.0. running mean: -16.768947891307185\n",
      "resetting env. episode reward total was -13.0. running mean: -16.731258412394112\n",
      "resetting env. episode reward total was -14.0. running mean: -16.70394582827017\n",
      "resetting env. episode reward total was -16.0. running mean: -16.69690636998747\n",
      "resetting env. episode reward total was -15.0. running mean: -16.679937306287595\n",
      "resetting env. episode reward total was -10.0. running mean: -16.61313793322472\n",
      "resetting env. episode reward total was -17.0. running mean: -16.617006553892477\n",
      "resetting env. episode reward total was -14.0. running mean: -16.590836488353553\n",
      "resetting env. episode reward total was -14.0. running mean: -16.56492812347002\n",
      "resetting env. episode reward total was -17.0. running mean: -16.56927884223532\n",
      "resetting env. episode reward total was -15.0. running mean: -16.553586053812964\n",
      "resetting env. episode reward total was -13.0. running mean: -16.518050193274835\n",
      "resetting env. episode reward total was -13.0. running mean: -16.482869691342085\n",
      "resetting env. episode reward total was -19.0. running mean: -16.508040994428665\n",
      "resetting env. episode reward total was -17.0. running mean: -16.51296058448438\n",
      "resetting env. episode reward total was -11.0. running mean: -16.457830978639535\n",
      "resetting env. episode reward total was -15.0. running mean: -16.443252668853138\n",
      "resetting env. episode reward total was -15.0. running mean: -16.428820142164604\n",
      "resetting env. episode reward total was -18.0. running mean: -16.44453194074296\n",
      "resetting env. episode reward total was -18.0. running mean: -16.460086621335527\n",
      "resetting env. episode reward total was -19.0. running mean: -16.485485755122173\n",
      "resetting env. episode reward total was -7.0. running mean: -16.39063089757095\n",
      "resetting env. episode reward total was -14.0. running mean: -16.366724588595243\n",
      "resetting env. episode reward total was -17.0. running mean: -16.37305734270929\n",
      "resetting env. episode reward total was -15.0. running mean: -16.359326769282198\n",
      "resetting env. episode reward total was -13.0. running mean: -16.325733501589376\n",
      "resetting env. episode reward total was -18.0. running mean: -16.34247616657348\n",
      "resetting env. episode reward total was -13.0. running mean: -16.309051404907745\n",
      "resetting env. episode reward total was -18.0. running mean: -16.325960890858667\n",
      "resetting env. episode reward total was -17.0. running mean: -16.332701281950083\n",
      "resetting env. episode reward total was -15.0. running mean: -16.31937426913058\n",
      "resetting env. episode reward total was -11.0. running mean: -16.266180526439275\n",
      "resetting env. episode reward total was -13.0. running mean: -16.23351872117488\n",
      "resetting env. episode reward total was -15.0. running mean: -16.22118353396313\n",
      "resetting env. episode reward total was -14.0. running mean: -16.1989716986235\n",
      "resetting env. episode reward total was -11.0. running mean: -16.146981981637264\n",
      "resetting env. episode reward total was -14.0. running mean: -16.12551216182089\n",
      "resetting env. episode reward total was -18.0. running mean: -16.14425704020268\n",
      "resetting env. episode reward total was -14.0. running mean: -16.122814469800655\n",
      "resetting env. episode reward total was -17.0. running mean: -16.13158632510265\n",
      "resetting env. episode reward total was -18.0. running mean: -16.150270461851623\n",
      "resetting env. episode reward total was -18.0. running mean: -16.168767757233105\n",
      "resetting env. episode reward total was -14.0. running mean: -16.147080079660775\n",
      "resetting env. episode reward total was -17.0. running mean: -16.15560927886417\n",
      "resetting env. episode reward total was -15.0. running mean: -16.144053186075528\n",
      "resetting env. episode reward total was -16.0. running mean: -16.142612654214773\n",
      "resetting env. episode reward total was -11.0. running mean: -16.091186527672626\n",
      "resetting env. episode reward total was -19.0. running mean: -16.1202746623959\n",
      "resetting env. episode reward total was -12.0. running mean: -16.07907191577194\n",
      "resetting env. episode reward total was -14.0. running mean: -16.05828119661422\n",
      "resetting env. episode reward total was -19.0. running mean: -16.08769838464808\n",
      "resetting env. episode reward total was -16.0. running mean: -16.086821400801597\n",
      "resetting env. episode reward total was -17.0. running mean: -16.095953186793583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -17.0. running mean: -16.104993654925646\n",
      "resetting env. episode reward total was -15.0. running mean: -16.09394371837639\n",
      "resetting env. episode reward total was -15.0. running mean: -16.083004281192625\n",
      "resetting env. episode reward total was -14.0. running mean: -16.0621742383807\n",
      "resetting env. episode reward total was -13.0. running mean: -16.03155249599689\n",
      "resetting env. episode reward total was -17.0. running mean: -16.041236971036923\n",
      "resetting env. episode reward total was -14.0. running mean: -16.020824601326552\n",
      "resetting env. episode reward total was -14.0. running mean: -16.000616355313287\n",
      "resetting env. episode reward total was -12.0. running mean: -15.960610191760153\n",
      "resetting env. episode reward total was -15.0. running mean: -15.951004089842552\n",
      "resetting env. episode reward total was -16.0. running mean: -15.951494048944127\n",
      "resetting env. episode reward total was -18.0. running mean: -15.971979108454686\n",
      "resetting env. episode reward total was -16.0. running mean: -15.97225931737014\n",
      "resetting env. episode reward total was -20.0. running mean: -16.01253672419644\n",
      "resetting env. episode reward total was -15.0. running mean: -16.002411356954475\n",
      "resetting env. episode reward total was -14.0. running mean: -15.982387243384931\n",
      "resetting env. episode reward total was -11.0. running mean: -15.932563370951081\n",
      "resetting env. episode reward total was -15.0. running mean: -15.923237737241571\n",
      "resetting env. episode reward total was -14.0. running mean: -15.904005359869156\n",
      "resetting env. episode reward total was -17.0. running mean: -15.914965306270465\n",
      "resetting env. episode reward total was -11.0. running mean: -15.86581565320776\n",
      "resetting env. episode reward total was -15.0. running mean: -15.857157496675683\n",
      "resetting env. episode reward total was -15.0. running mean: -15.848585921708926\n",
      "resetting env. episode reward total was -16.0. running mean: -15.850100062491837\n",
      "resetting env. episode reward total was -19.0. running mean: -15.881599061866918\n",
      "resetting env. episode reward total was -12.0. running mean: -15.842783071248249\n",
      "resetting env. episode reward total was -16.0. running mean: -15.844355240535766\n",
      "resetting env. episode reward total was -7.0. running mean: -15.755911688130409\n",
      "resetting env. episode reward total was -14.0. running mean: -15.738352571249106\n",
      "resetting env. episode reward total was -15.0. running mean: -15.730969045536614\n",
      "resetting env. episode reward total was -11.0. running mean: -15.683659355081248\n",
      "resetting env. episode reward total was -14.0. running mean: -15.666822761530437\n",
      "resetting env. episode reward total was -17.0. running mean: -15.680154533915132\n",
      "resetting env. episode reward total was -18.0. running mean: -15.70335298857598\n",
      "resetting env. episode reward total was -16.0. running mean: -15.70631945869022\n",
      "resetting env. episode reward total was -15.0. running mean: -15.699256264103319\n",
      "resetting env. episode reward total was -13.0. running mean: -15.672263701462287\n",
      "resetting env. episode reward total was -12.0. running mean: -15.635541064447663\n",
      "resetting env. episode reward total was -15.0. running mean: -15.629185653803187\n",
      "resetting env. episode reward total was -16.0. running mean: -15.632893797265156\n",
      "resetting env. episode reward total was -17.0. running mean: -15.646564859292505\n",
      "resetting env. episode reward total was -12.0. running mean: -15.610099210699579\n",
      "resetting env. episode reward total was -14.0. running mean: -15.593998218592583\n",
      "resetting env. episode reward total was -16.0. running mean: -15.598058236406658\n",
      "resetting env. episode reward total was -20.0. running mean: -15.642077654042591\n",
      "resetting env. episode reward total was -16.0. running mean: -15.645656877502166\n",
      "resetting env. episode reward total was -21.0. running mean: -15.699200308727145\n",
      "resetting env. episode reward total was -18.0. running mean: -15.722208305639873\n",
      "resetting env. episode reward total was -11.0. running mean: -15.674986222583474\n",
      "resetting env. episode reward total was -13.0. running mean: -15.64823636035764\n",
      "resetting env. episode reward total was -12.0. running mean: -15.611753996754063\n",
      "resetting env. episode reward total was -16.0. running mean: -15.615636456786522\n",
      "resetting env. episode reward total was -11.0. running mean: -15.569480092218656\n",
      "resetting env. episode reward total was -17.0. running mean: -15.58378529129647\n",
      "resetting env. episode reward total was -15.0. running mean: -15.577947438383505\n",
      "resetting env. episode reward total was -15.0. running mean: -15.572167963999672\n",
      "resetting env. episode reward total was -12.0. running mean: -15.536446284359673\n",
      "resetting env. episode reward total was -19.0. running mean: -15.571081821516076\n",
      "resetting env. episode reward total was -14.0. running mean: -15.555371003300916\n",
      "resetting env. episode reward total was -15.0. running mean: -15.549817293267907\n",
      "resetting env. episode reward total was -9.0. running mean: -15.484319120335227\n",
      "resetting env. episode reward total was -15.0. running mean: -15.479475929131874\n",
      "resetting env. episode reward total was -17.0. running mean: -15.494681169840556\n",
      "resetting env. episode reward total was -17.0. running mean: -15.50973435814215\n",
      "resetting env. episode reward total was -15.0. running mean: -15.504637014560728\n",
      "resetting env. episode reward total was -17.0. running mean: -15.519590644415121\n",
      "resetting env. episode reward total was -13.0. running mean: -15.494394737970971\n",
      "resetting env. episode reward total was -19.0. running mean: -15.52945079059126\n",
      "resetting env. episode reward total was -15.0. running mean: -15.524156282685349\n",
      "resetting env. episode reward total was -16.0. running mean: -15.528914719858495\n",
      "resetting env. episode reward total was -19.0. running mean: -15.563625572659909\n",
      "resetting env. episode reward total was -15.0. running mean: -15.55798931693331\n",
      "resetting env. episode reward total was -17.0. running mean: -15.572409423763977\n",
      "resetting env. episode reward total was -15.0. running mean: -15.566685329526338\n",
      "resetting env. episode reward total was -15.0. running mean: -15.561018476231075\n",
      "resetting env. episode reward total was -13.0. running mean: -15.535408291468764\n",
      "resetting env. episode reward total was -19.0. running mean: -15.570054208554076\n",
      "resetting env. episode reward total was -18.0. running mean: -15.594353666468535\n",
      "resetting env. episode reward total was -13.0. running mean: -15.568410129803851\n",
      "resetting env. episode reward total was -15.0. running mean: -15.562726028505812\n",
      "resetting env. episode reward total was -12.0. running mean: -15.527098768220753\n",
      "resetting env. episode reward total was -14.0. running mean: -15.511827780538546\n",
      "resetting env. episode reward total was -14.0. running mean: -15.496709502733161\n",
      "resetting env. episode reward total was -13.0. running mean: -15.47174240770583\n",
      "resetting env. episode reward total was -15.0. running mean: -15.467024983628773\n",
      "resetting env. episode reward total was -19.0. running mean: -15.502354733792485\n",
      "resetting env. episode reward total was -17.0. running mean: -15.51733118645456\n",
      "resetting env. episode reward total was -16.0. running mean: -15.522157874590015\n",
      "resetting env. episode reward total was -17.0. running mean: -15.536936295844114\n",
      "resetting env. episode reward total was -12.0. running mean: -15.501566932885673\n",
      "resetting env. episode reward total was -17.0. running mean: -15.516551263556817\n",
      "resetting env. episode reward total was -14.0. running mean: -15.50138575092125\n",
      "resetting env. episode reward total was -14.0. running mean: -15.486371893412038\n",
      "resetting env. episode reward total was -11.0. running mean: -15.441508174477917\n",
      "resetting env. episode reward total was -17.0. running mean: -15.457093092733137\n",
      "resetting env. episode reward total was -14.0. running mean: -15.442522161805806\n",
      "resetting env. episode reward total was -16.0. running mean: -15.448096940187748\n",
      "resetting env. episode reward total was -12.0. running mean: -15.41361597078587\n",
      "resetting env. episode reward total was -16.0. running mean: -15.419479811078011\n",
      "resetting env. episode reward total was -13.0. running mean: -15.395285012967232\n",
      "resetting env. episode reward total was -14.0. running mean: -15.38133216283756\n",
      "resetting env. episode reward total was -12.0. running mean: -15.347518841209185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -16.0. running mean: -15.354043652797094\n",
      "resetting env. episode reward total was -13.0. running mean: -15.330503216269124\n",
      "resetting env. episode reward total was -10.0. running mean: -15.277198184106432\n",
      "resetting env. episode reward total was -17.0. running mean: -15.294426202265367\n",
      "resetting env. episode reward total was -14.0. running mean: -15.281481940242713\n",
      "resetting env. episode reward total was -13.0. running mean: -15.258667120840286\n",
      "resetting env. episode reward total was -13.0. running mean: -15.236080449631883\n",
      "resetting env. episode reward total was -14.0. running mean: -15.223719645135565\n",
      "resetting env. episode reward total was -16.0. running mean: -15.23148244868421\n",
      "resetting env. episode reward total was -17.0. running mean: -15.249167624197367\n",
      "resetting env. episode reward total was -8.0. running mean: -15.176675947955394\n",
      "resetting env. episode reward total was -14.0. running mean: -15.164909188475841\n",
      "resetting env. episode reward total was -15.0. running mean: -15.163260096591083\n",
      "resetting env. episode reward total was -17.0. running mean: -15.181627495625172\n",
      "resetting env. episode reward total was -16.0. running mean: -15.18981122066892\n",
      "resetting env. episode reward total was -13.0. running mean: -15.167913108462232\n",
      "resetting env. episode reward total was -14.0. running mean: -15.15623397737761\n",
      "resetting env. episode reward total was -11.0. running mean: -15.114671637603834\n",
      "resetting env. episode reward total was -14.0. running mean: -15.103524921227796\n",
      "resetting env. episode reward total was -17.0. running mean: -15.122489672015519\n",
      "resetting env. episode reward total was -17.0. running mean: -15.141264775295364\n",
      "resetting env. episode reward total was -17.0. running mean: -15.15985212754241\n",
      "resetting env. episode reward total was -14.0. running mean: -15.148253606266985\n",
      "resetting env. episode reward total was -18.0. running mean: -15.176771070204316\n",
      "resetting env. episode reward total was -15.0. running mean: -15.175003359502274\n",
      "resetting env. episode reward total was -18.0. running mean: -15.20325332590725\n",
      "resetting env. episode reward total was -15.0. running mean: -15.201220792648177\n",
      "resetting env. episode reward total was -18.0. running mean: -15.229208584721695\n",
      "resetting env. episode reward total was -15.0. running mean: -15.226916498874479\n",
      "resetting env. episode reward total was -13.0. running mean: -15.204647333885735\n",
      "resetting env. episode reward total was -18.0. running mean: -15.232600860546876\n",
      "resetting env. episode reward total was -16.0. running mean: -15.240274851941408\n",
      "resetting env. episode reward total was -15.0. running mean: -15.237872103421994\n",
      "resetting env. episode reward total was -14.0. running mean: -15.225493382387775\n",
      "resetting env. episode reward total was -15.0. running mean: -15.223238448563897\n",
      "resetting env. episode reward total was -21.0. running mean: -15.281006064078259\n",
      "resetting env. episode reward total was -15.0. running mean: -15.278196003437477\n",
      "resetting env. episode reward total was -13.0. running mean: -15.255414043403103\n",
      "resetting env. episode reward total was -12.0. running mean: -15.222859902969072\n",
      "resetting env. episode reward total was -20.0. running mean: -15.27063130393938\n",
      "resetting env. episode reward total was -16.0. running mean: -15.277924990899987\n",
      "resetting env. episode reward total was -12.0. running mean: -15.245145740990985\n",
      "resetting env. episode reward total was -17.0. running mean: -15.262694283581075\n",
      "resetting env. episode reward total was -15.0. running mean: -15.260067340745264\n",
      "resetting env. episode reward total was -14.0. running mean: -15.247466667337813\n",
      "resetting env. episode reward total was -13.0. running mean: -15.224992000664436\n",
      "resetting env. episode reward total was -12.0. running mean: -15.19274208065779\n",
      "resetting env. episode reward total was -16.0. running mean: -15.200814659851213\n",
      "resetting env. episode reward total was -15.0. running mean: -15.198806513252702\n",
      "resetting env. episode reward total was -15.0. running mean: -15.196818448120176\n",
      "resetting env. episode reward total was -14.0. running mean: -15.184850263638975\n",
      "resetting env. episode reward total was -16.0. running mean: -15.193001761002584\n",
      "resetting env. episode reward total was -17.0. running mean: -15.211071743392559\n",
      "resetting env. episode reward total was -13.0. running mean: -15.188961025958633\n",
      "resetting env. episode reward total was -14.0. running mean: -15.177071415699048\n",
      "resetting env. episode reward total was -16.0. running mean: -15.185300701542058\n",
      "resetting env. episode reward total was -16.0. running mean: -15.193447694526638\n",
      "resetting env. episode reward total was -15.0. running mean: -15.191513217581372\n",
      "resetting env. episode reward total was -13.0. running mean: -15.169598085405559\n",
      "resetting env. episode reward total was -18.0. running mean: -15.197902104551503\n",
      "resetting env. episode reward total was -17.0. running mean: -15.215923083505988\n",
      "resetting env. episode reward total was -11.0. running mean: -15.173763852670927\n",
      "resetting env. episode reward total was -17.0. running mean: -15.192026214144217\n",
      "resetting env. episode reward total was -15.0. running mean: -15.190105952002776\n",
      "resetting env. episode reward total was -13.0. running mean: -15.168204892482748\n",
      "resetting env. episode reward total was -18.0. running mean: -15.19652284355792\n",
      "resetting env. episode reward total was -8.0. running mean: -15.124557615122342\n",
      "resetting env. episode reward total was -14.0. running mean: -15.113312038971118\n",
      "resetting env. episode reward total was -13.0. running mean: -15.092178918581407\n",
      "resetting env. episode reward total was -18.0. running mean: -15.121257129395593\n",
      "resetting env. episode reward total was -14.0. running mean: -15.110044558101638\n",
      "resetting env. episode reward total was -1.0. running mean: -14.96894411252062\n",
      "resetting env. episode reward total was -11.0. running mean: -14.929254671395414\n",
      "resetting env. episode reward total was -18.0. running mean: -14.959962124681459\n",
      "resetting env. episode reward total was -15.0. running mean: -14.960362503434645\n",
      "resetting env. episode reward total was -15.0. running mean: -14.960758878400298\n",
      "resetting env. episode reward total was -13.0. running mean: -14.941151289616297\n",
      "resetting env. episode reward total was -9.0. running mean: -14.881739776720133\n",
      "resetting env. episode reward total was -15.0. running mean: -14.882922378952932\n",
      "resetting env. episode reward total was -10.0. running mean: -14.834093155163401\n",
      "resetting env. episode reward total was -18.0. running mean: -14.865752223611768\n",
      "resetting env. episode reward total was -16.0. running mean: -14.87709470137565\n",
      "resetting env. episode reward total was -17.0. running mean: -14.898323754361893\n",
      "resetting env. episode reward total was -17.0. running mean: -14.919340516818274\n",
      "resetting env. episode reward total was -20.0. running mean: -14.97014711165009\n",
      "resetting env. episode reward total was -18.0. running mean: -15.00044564053359\n",
      "resetting env. episode reward total was -16.0. running mean: -15.010441184128254\n",
      "resetting env. episode reward total was -15.0. running mean: -15.010336772286971\n",
      "resetting env. episode reward total was -13.0. running mean: -14.990233404564101\n",
      "resetting env. episode reward total was -12.0. running mean: -14.960331070518459\n",
      "resetting env. episode reward total was -19.0. running mean: -15.000727759813273\n",
      "resetting env. episode reward total was -13.0. running mean: -14.98072048221514\n",
      "resetting env. episode reward total was -14.0. running mean: -14.97091327739299\n",
      "resetting env. episode reward total was -15.0. running mean: -14.97120414461906\n",
      "resetting env. episode reward total was -17.0. running mean: -14.991492103172869\n",
      "resetting env. episode reward total was -15.0. running mean: -14.99157718214114\n",
      "resetting env. episode reward total was -15.0. running mean: -14.991661410319729\n",
      "resetting env. episode reward total was -15.0. running mean: -14.991744796216532\n",
      "resetting env. episode reward total was -13.0. running mean: -14.971827348254367\n",
      "resetting env. episode reward total was -14.0. running mean: -14.962109074771824\n",
      "resetting env. episode reward total was -15.0. running mean: -14.962487984024106\n",
      "resetting env. episode reward total was -15.0. running mean: -14.962863104183866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -13.0. running mean: -14.943234473142027\n",
      "resetting env. episode reward total was -15.0. running mean: -14.943802128410606\n",
      "resetting env. episode reward total was -15.0. running mean: -14.9443641071265\n",
      "resetting env. episode reward total was -17.0. running mean: -14.964920466055235\n",
      "resetting env. episode reward total was -14.0. running mean: -14.955271261394683\n",
      "resetting env. episode reward total was -15.0. running mean: -14.955718548780737\n",
      "resetting env. episode reward total was -9.0. running mean: -14.89616136329293\n",
      "resetting env. episode reward total was -12.0. running mean: -14.86719974966\n",
      "resetting env. episode reward total was -12.0. running mean: -14.8385277521634\n",
      "resetting env. episode reward total was -14.0. running mean: -14.830142474641766\n",
      "resetting env. episode reward total was -11.0. running mean: -14.791841049895348\n",
      "resetting env. episode reward total was -17.0. running mean: -14.813922639396395\n",
      "resetting env. episode reward total was -15.0. running mean: -14.815783413002432\n",
      "resetting env. episode reward total was -19.0. running mean: -14.857625578872407\n",
      "resetting env. episode reward total was -13.0. running mean: -14.839049323083684\n",
      "resetting env. episode reward total was -15.0. running mean: -14.840658829852847\n",
      "resetting env. episode reward total was -16.0. running mean: -14.852252241554318\n",
      "resetting env. episode reward total was -10.0. running mean: -14.803729719138774\n",
      "resetting env. episode reward total was -12.0. running mean: -14.775692421947385\n",
      "resetting env. episode reward total was -14.0. running mean: -14.767935497727912\n",
      "resetting env. episode reward total was -12.0. running mean: -14.740256142750631\n",
      "resetting env. episode reward total was -17.0. running mean: -14.762853581323125\n",
      "resetting env. episode reward total was -15.0. running mean: -14.765225045509894\n",
      "resetting env. episode reward total was -17.0. running mean: -14.787572795054794\n",
      "resetting env. episode reward total was -15.0. running mean: -14.789697067104246\n",
      "resetting env. episode reward total was -16.0. running mean: -14.801800096433203\n",
      "resetting env. episode reward total was -10.0. running mean: -14.75378209546887\n",
      "resetting env. episode reward total was -12.0. running mean: -14.72624427451418\n",
      "resetting env. episode reward total was -16.0. running mean: -14.738981831769038\n",
      "resetting env. episode reward total was -10.0. running mean: -14.691592013451347\n",
      "resetting env. episode reward total was -16.0. running mean: -14.704676093316833\n",
      "resetting env. episode reward total was -15.0. running mean: -14.707629332383664\n",
      "resetting env. episode reward total was -12.0. running mean: -14.680553039059827\n",
      "resetting env. episode reward total was -16.0. running mean: -14.69374750866923\n",
      "resetting env. episode reward total was -17.0. running mean: -14.716810033582536\n",
      "resetting env. episode reward total was -12.0. running mean: -14.68964193324671\n",
      "resetting env. episode reward total was -11.0. running mean: -14.652745513914242\n",
      "resetting env. episode reward total was -15.0. running mean: -14.6562180587751\n",
      "resetting env. episode reward total was -17.0. running mean: -14.679655878187349\n",
      "resetting env. episode reward total was -15.0. running mean: -14.682859319405475\n",
      "resetting env. episode reward total was -18.0. running mean: -14.71603072621142\n",
      "resetting env. episode reward total was -18.0. running mean: -14.748870418949306\n",
      "resetting env. episode reward total was -14.0. running mean: -14.741381714759813\n",
      "resetting env. episode reward total was -15.0. running mean: -14.743967897612215\n",
      "resetting env. episode reward total was -13.0. running mean: -14.726528218636094\n",
      "resetting env. episode reward total was -9.0. running mean: -14.669262936449734\n",
      "resetting env. episode reward total was -19.0. running mean: -14.712570307085235\n",
      "resetting env. episode reward total was -12.0. running mean: -14.685444604014382\n",
      "resetting env. episode reward total was -13.0. running mean: -14.668590157974238\n",
      "resetting env. episode reward total was -17.0. running mean: -14.691904256394496\n",
      "resetting env. episode reward total was -13.0. running mean: -14.674985213830551\n",
      "resetting env. episode reward total was -14.0. running mean: -14.668235361692245\n",
      "resetting env. episode reward total was -15.0. running mean: -14.671553008075323\n",
      "resetting env. episode reward total was -16.0. running mean: -14.68483747799457\n",
      "resetting env. episode reward total was -13.0. running mean: -14.667989103214625\n",
      "resetting env. episode reward total was -14.0. running mean: -14.661309212182479\n",
      "resetting env. episode reward total was -15.0. running mean: -14.664696120060654\n",
      "resetting env. episode reward total was -13.0. running mean: -14.648049158860049\n",
      "resetting env. episode reward total was -17.0. running mean: -14.671568667271448\n",
      "resetting env. episode reward total was -16.0. running mean: -14.684852980598734\n",
      "resetting env. episode reward total was -15.0. running mean: -14.688004450792747\n",
      "resetting env. episode reward total was -15.0. running mean: -14.69112440628482\n",
      "resetting env. episode reward total was -20.0. running mean: -14.744213162221971\n",
      "resetting env. episode reward total was -19.0. running mean: -14.78677103059975\n",
      "resetting env. episode reward total was -16.0. running mean: -14.798903320293753\n",
      "resetting env. episode reward total was -19.0. running mean: -14.840914287090815\n",
      "resetting env. episode reward total was -6.0. running mean: -14.752505144219906\n",
      "resetting env. episode reward total was -15.0. running mean: -14.754980092777707\n",
      "resetting env. episode reward total was -17.0. running mean: -14.77743029184993\n",
      "resetting env. episode reward total was -18.0. running mean: -14.80965598893143\n",
      "resetting env. episode reward total was -15.0. running mean: -14.811559429042116\n",
      "resetting env. episode reward total was -17.0. running mean: -14.833443834751694\n",
      "resetting env. episode reward total was -19.0. running mean: -14.875109396404177\n",
      "resetting env. episode reward total was -11.0. running mean: -14.836358302440134\n",
      "resetting env. episode reward total was -19.0. running mean: -14.877994719415732\n",
      "resetting env. episode reward total was -12.0. running mean: -14.849214772221574\n",
      "resetting env. episode reward total was -17.0. running mean: -14.870722624499358\n",
      "resetting env. episode reward total was -16.0. running mean: -14.882015398254364\n",
      "resetting env. episode reward total was -11.0. running mean: -14.84319524427182\n",
      "resetting env. episode reward total was -14.0. running mean: -14.834763291829102\n",
      "resetting env. episode reward total was -17.0. running mean: -14.85641565891081\n",
      "resetting env. episode reward total was -17.0. running mean: -14.877851502321702\n",
      "resetting env. episode reward total was -17.0. running mean: -14.899072987298485\n",
      "resetting env. episode reward total was -14.0. running mean: -14.890082257425501\n",
      "resetting env. episode reward total was -17.0. running mean: -14.911181434851246\n",
      "resetting env. episode reward total was -17.0. running mean: -14.932069620502734\n",
      "resetting env. episode reward total was -9.0. running mean: -14.872748924297706\n",
      "resetting env. episode reward total was -11.0. running mean: -14.834021435054728\n",
      "resetting env. episode reward total was -12.0. running mean: -14.80568122070418\n",
      "resetting env. episode reward total was -13.0. running mean: -14.78762440849714\n",
      "resetting env. episode reward total was -13.0. running mean: -14.769748164412169\n",
      "resetting env. episode reward total was -13.0. running mean: -14.752050682768049\n",
      "resetting env. episode reward total was -16.0. running mean: -14.764530175940369\n",
      "resetting env. episode reward total was -15.0. running mean: -14.766884874180965\n",
      "resetting env. episode reward total was -18.0. running mean: -14.799216025439154\n",
      "resetting env. episode reward total was -13.0. running mean: -14.781223865184764\n",
      "resetting env. episode reward total was -19.0. running mean: -14.823411626532915\n",
      "resetting env. episode reward total was -18.0. running mean: -14.855177510267586\n",
      "resetting env. episode reward total was -16.0. running mean: -14.86662573516491\n",
      "resetting env. episode reward total was -13.0. running mean: -14.84795947781326\n",
      "resetting env. episode reward total was -13.0. running mean: -14.829479883035129\n",
      "resetting env. episode reward total was -19.0. running mean: -14.871185084204777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -16.0. running mean: -14.88247323336273\n",
      "resetting env. episode reward total was -17.0. running mean: -14.903648501029101\n",
      "resetting env. episode reward total was -15.0. running mean: -14.904612016018811\n",
      "resetting env. episode reward total was -15.0. running mean: -14.905565895858624\n",
      "resetting env. episode reward total was -18.0. running mean: -14.936510236900038\n",
      "resetting env. episode reward total was -18.0. running mean: -14.967145134531037\n",
      "resetting env. episode reward total was -17.0. running mean: -14.987473683185726\n",
      "resetting env. episode reward total was -16.0. running mean: -14.997598946353868\n",
      "resetting env. episode reward total was -16.0. running mean: -15.00762295689033\n",
      "resetting env. episode reward total was -19.0. running mean: -15.047546727321427\n",
      "resetting env. episode reward total was -15.0. running mean: -15.047071260048213\n",
      "resetting env. episode reward total was -9.0. running mean: -14.98660054744773\n",
      "resetting env. episode reward total was -16.0. running mean: -14.996734541973254\n",
      "resetting env. episode reward total was -13.0. running mean: -14.976767196553523\n",
      "resetting env. episode reward total was -19.0. running mean: -15.016999524587987\n",
      "resetting env. episode reward total was -17.0. running mean: -15.036829529342107\n",
      "resetting env. episode reward total was -5.0. running mean: -14.936461234048686\n",
      "resetting env. episode reward total was -14.0. running mean: -14.9270966217082\n",
      "resetting env. episode reward total was -15.0. running mean: -14.927825655491118\n",
      "resetting env. episode reward total was -14.0. running mean: -14.918547398936207\n",
      "resetting env. episode reward total was -14.0. running mean: -14.909361924946845\n",
      "resetting env. episode reward total was -18.0. running mean: -14.940268305697376\n",
      "resetting env. episode reward total was -13.0. running mean: -14.920865622640404\n",
      "resetting env. episode reward total was -17.0. running mean: -14.941656966414\n",
      "resetting env. episode reward total was -10.0. running mean: -14.892240396749859\n",
      "resetting env. episode reward total was -17.0. running mean: -14.91331799278236\n",
      "resetting env. episode reward total was -19.0. running mean: -14.954184812854535\n",
      "resetting env. episode reward total was -18.0. running mean: -14.984642964725989\n",
      "resetting env. episode reward total was -15.0. running mean: -14.984796535078729\n",
      "resetting env. episode reward total was -10.0. running mean: -14.934948569727942\n",
      "resetting env. episode reward total was -12.0. running mean: -14.905599084030662\n",
      "resetting env. episode reward total was -14.0. running mean: -14.896543093190356\n",
      "resetting env. episode reward total was -16.0. running mean: -14.907577662258452\n",
      "resetting env. episode reward total was -15.0. running mean: -14.908501885635868\n",
      "resetting env. episode reward total was -14.0. running mean: -14.899416866779509\n",
      "resetting env. episode reward total was -14.0. running mean: -14.890422698111715\n",
      "resetting env. episode reward total was -15.0. running mean: -14.891518471130599\n",
      "resetting env. episode reward total was -13.0. running mean: -14.872603286419293\n",
      "resetting env. episode reward total was -13.0. running mean: -14.853877253555101\n",
      "resetting env. episode reward total was -13.0. running mean: -14.835338481019551\n",
      "resetting env. episode reward total was -16.0. running mean: -14.846985096209355\n",
      "resetting env. episode reward total was -15.0. running mean: -14.848515245247262\n",
      "resetting env. episode reward total was -13.0. running mean: -14.83003009279479\n",
      "resetting env. episode reward total was -17.0. running mean: -14.851729791866841\n",
      "resetting env. episode reward total was -13.0. running mean: -14.833212493948173\n",
      "resetting env. episode reward total was -15.0. running mean: -14.83488036900869\n",
      "resetting env. episode reward total was -17.0. running mean: -14.856531565318603\n",
      "resetting env. episode reward total was -11.0. running mean: -14.817966249665416\n",
      "resetting env. episode reward total was -14.0. running mean: -14.809786587168762\n",
      "resetting env. episode reward total was -12.0. running mean: -14.781688721297074\n",
      "resetting env. episode reward total was -10.0. running mean: -14.733871834084104\n",
      "resetting env. episode reward total was -13.0. running mean: -14.716533115743264\n",
      "resetting env. episode reward total was -15.0. running mean: -14.719367784585831\n",
      "resetting env. episode reward total was -19.0. running mean: -14.762174106739971\n",
      "resetting env. episode reward total was -19.0. running mean: -14.80455236567257\n",
      "resetting env. episode reward total was -16.0. running mean: -14.816506842015844\n",
      "resetting env. episode reward total was -15.0. running mean: -14.818341773595685\n",
      "resetting env. episode reward total was -15.0. running mean: -14.820158355859729\n",
      "resetting env. episode reward total was -13.0. running mean: -14.801956772301132\n",
      "resetting env. episode reward total was -17.0. running mean: -14.82393720457812\n",
      "resetting env. episode reward total was -16.0. running mean: -14.83569783253234\n",
      "resetting env. episode reward total was -14.0. running mean: -14.827340854207018\n",
      "resetting env. episode reward total was -15.0. running mean: -14.829067445664947\n",
      "resetting env. episode reward total was -14.0. running mean: -14.820776771208298\n",
      "resetting env. episode reward total was -16.0. running mean: -14.832569003496214\n",
      "resetting env. episode reward total was -16.0. running mean: -14.844243313461252\n",
      "resetting env. episode reward total was -17.0. running mean: -14.86580088032664\n",
      "resetting env. episode reward total was -18.0. running mean: -14.897142871523373\n",
      "resetting env. episode reward total was -8.0. running mean: -14.82817144280814\n",
      "resetting env. episode reward total was -17.0. running mean: -14.849889728380058\n",
      "resetting env. episode reward total was -20.0. running mean: -14.901390831096256\n",
      "resetting env. episode reward total was -19.0. running mean: -14.942376922785293\n",
      "resetting env. episode reward total was -18.0. running mean: -14.97295315355744\n",
      "resetting env. episode reward total was -16.0. running mean: -14.983223622021864\n",
      "resetting env. episode reward total was -15.0. running mean: -14.983391385801646\n",
      "resetting env. episode reward total was -17.0. running mean: -15.00355747194363\n",
      "resetting env. episode reward total was -14.0. running mean: -14.993521897224193\n",
      "resetting env. episode reward total was -16.0. running mean: -15.003586678251951\n",
      "resetting env. episode reward total was -13.0. running mean: -14.983550811469431\n",
      "resetting env. episode reward total was -15.0. running mean: -14.983715303354737\n",
      "resetting env. episode reward total was -14.0. running mean: -14.97387815032119\n",
      "resetting env. episode reward total was -15.0. running mean: -14.974139368817978\n",
      "resetting env. episode reward total was -16.0. running mean: -14.984397975129799\n",
      "resetting env. episode reward total was -12.0. running mean: -14.9545539953785\n",
      "resetting env. episode reward total was -15.0. running mean: -14.955008455424716\n",
      "resetting env. episode reward total was -10.0. running mean: -14.905458370870468\n",
      "resetting env. episode reward total was -19.0. running mean: -14.946403787161763\n",
      "resetting env. episode reward total was -13.0. running mean: -14.926939749290147\n",
      "resetting env. episode reward total was -16.0. running mean: -14.937670351797246\n",
      "resetting env. episode reward total was -12.0. running mean: -14.908293648279273\n",
      "resetting env. episode reward total was -14.0. running mean: -14.89921071179648\n",
      "resetting env. episode reward total was -13.0. running mean: -14.880218604678516\n",
      "resetting env. episode reward total was -14.0. running mean: -14.871416418631732\n",
      "resetting env. episode reward total was -17.0. running mean: -14.892702254445414\n",
      "resetting env. episode reward total was -15.0. running mean: -14.89377523190096\n",
      "resetting env. episode reward total was -12.0. running mean: -14.86483747958195\n",
      "resetting env. episode reward total was -18.0. running mean: -14.896189104786131\n",
      "resetting env. episode reward total was -18.0. running mean: -14.92722721373827\n",
      "resetting env. episode reward total was -15.0. running mean: -14.927954941600888\n",
      "resetting env. episode reward total was -8.0. running mean: -14.858675392184878\n",
      "resetting env. episode reward total was -14.0. running mean: -14.85008863826303\n",
      "resetting env. episode reward total was -12.0. running mean: -14.821587751880399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -19.0. running mean: -14.863371874361594\n",
      "resetting env. episode reward total was -16.0. running mean: -14.874738155617978\n",
      "resetting env. episode reward total was -14.0. running mean: -14.865990774061798\n",
      "resetting env. episode reward total was -17.0. running mean: -14.887330866321179\n",
      "resetting env. episode reward total was -17.0. running mean: -14.908457557657966\n",
      "resetting env. episode reward total was -16.0. running mean: -14.919372982081386\n",
      "resetting env. episode reward total was -15.0. running mean: -14.920179252260573\n",
      "resetting env. episode reward total was -18.0. running mean: -14.950977459737967\n",
      "resetting env. episode reward total was -15.0. running mean: -14.951467685140587\n",
      "resetting env. episode reward total was -14.0. running mean: -14.94195300828918\n",
      "resetting env. episode reward total was -19.0. running mean: -14.982533478206289\n",
      "resetting env. episode reward total was -11.0. running mean: -14.942708143424225\n",
      "resetting env. episode reward total was -9.0. running mean: -14.883281061989983\n",
      "resetting env. episode reward total was -12.0. running mean: -14.854448251370082\n",
      "resetting env. episode reward total was -18.0. running mean: -14.88590376885638\n",
      "resetting env. episode reward total was -12.0. running mean: -14.857044731167816\n",
      "resetting env. episode reward total was -14.0. running mean: -14.848474283856138\n",
      "resetting env. episode reward total was -14.0. running mean: -14.839989541017577\n",
      "resetting env. episode reward total was -14.0. running mean: -14.831589645607401\n",
      "resetting env. episode reward total was -11.0. running mean: -14.793273749151327\n",
      "resetting env. episode reward total was -19.0. running mean: -14.835341011659812\n",
      "resetting env. episode reward total was -13.0. running mean: -14.816987601543214\n",
      "resetting env. episode reward total was -12.0. running mean: -14.788817725527782\n",
      "resetting env. episode reward total was -15.0. running mean: -14.790929548272505\n",
      "resetting env. episode reward total was -13.0. running mean: -14.773020252789781\n",
      "resetting env. episode reward total was -15.0. running mean: -14.775290050261884\n",
      "resetting env. episode reward total was -17.0. running mean: -14.797537149759265\n",
      "resetting env. episode reward total was -17.0. running mean: -14.819561778261672\n",
      "resetting env. episode reward total was -12.0. running mean: -14.791366160479054\n",
      "resetting env. episode reward total was -19.0. running mean: -14.833452498874262\n",
      "resetting env. episode reward total was -15.0. running mean: -14.83511797388552\n",
      "resetting env. episode reward total was -14.0. running mean: -14.826766794146666\n",
      "resetting env. episode reward total was -9.0. running mean: -14.7684991262052\n",
      "resetting env. episode reward total was -17.0. running mean: -14.790814134943147\n",
      "resetting env. episode reward total was -15.0. running mean: -14.792905993593717\n",
      "resetting env. episode reward total was -13.0. running mean: -14.774976933657781\n",
      "resetting env. episode reward total was -14.0. running mean: -14.767227164321204\n",
      "resetting env. episode reward total was -13.0. running mean: -14.749554892677992\n",
      "resetting env. episode reward total was -15.0. running mean: -14.752059343751212\n",
      "resetting env. episode reward total was -15.0. running mean: -14.7545387503137\n",
      "resetting env. episode reward total was -18.0. running mean: -14.786993362810563\n",
      "resetting env. episode reward total was -18.0. running mean: -14.819123429182456\n",
      "resetting env. episode reward total was -16.0. running mean: -14.830932194890632\n",
      "resetting env. episode reward total was -12.0. running mean: -14.802622872941726\n",
      "resetting env. episode reward total was -15.0. running mean: -14.804596644212308\n",
      "resetting env. episode reward total was -12.0. running mean: -14.776550677770185\n",
      "resetting env. episode reward total was -13.0. running mean: -14.758785170992484\n",
      "resetting env. episode reward total was -10.0. running mean: -14.711197319282558\n",
      "resetting env. episode reward total was -12.0. running mean: -14.68408534608973\n",
      "resetting env. episode reward total was -10.0. running mean: -14.637244492628833\n",
      "resetting env. episode reward total was -13.0. running mean: -14.620872047702544\n",
      "resetting env. episode reward total was -13.0. running mean: -14.60466332722552\n",
      "resetting env. episode reward total was -14.0. running mean: -14.598616693953264\n",
      "resetting env. episode reward total was -6.0. running mean: -14.512630527013732\n",
      "resetting env. episode reward total was -17.0. running mean: -14.537504221743594\n",
      "resetting env. episode reward total was -15.0. running mean: -14.542129179526158\n",
      "resetting env. episode reward total was -13.0. running mean: -14.526707887730897\n",
      "resetting env. episode reward total was -16.0. running mean: -14.541440808853588\n",
      "resetting env. episode reward total was -14.0. running mean: -14.536026400765053\n",
      "resetting env. episode reward total was -11.0. running mean: -14.5006661367574\n",
      "resetting env. episode reward total was -15.0. running mean: -14.505659475389827\n",
      "resetting env. episode reward total was -18.0. running mean: -14.540602880635928\n",
      "resetting env. episode reward total was -14.0. running mean: -14.53519685182957\n",
      "resetting env. episode reward total was -16.0. running mean: -14.549844883311273\n",
      "resetting env. episode reward total was -9.0. running mean: -14.49434643447816\n",
      "resetting env. episode reward total was -17.0. running mean: -14.51940297013338\n",
      "resetting env. episode reward total was -19.0. running mean: -14.564208940432044\n",
      "resetting env. episode reward total was -14.0. running mean: -14.558566851027724\n",
      "resetting env. episode reward total was -9.0. running mean: -14.502981182517447\n",
      "resetting env. episode reward total was -18.0. running mean: -14.537951370692271\n",
      "resetting env. episode reward total was -18.0. running mean: -14.572571856985348\n",
      "resetting env. episode reward total was -13.0. running mean: -14.556846138415496\n",
      "resetting env. episode reward total was -19.0. running mean: -14.60127767703134\n",
      "resetting env. episode reward total was -19.0. running mean: -14.645264900261028\n",
      "resetting env. episode reward total was -15.0. running mean: -14.648812251258418\n",
      "resetting env. episode reward total was -17.0. running mean: -14.672324128745833\n",
      "resetting env. episode reward total was -12.0. running mean: -14.645600887458373\n",
      "resetting env. episode reward total was -11.0. running mean: -14.60914487858379\n",
      "resetting env. episode reward total was -12.0. running mean: -14.58305342979795\n",
      "resetting env. episode reward total was -17.0. running mean: -14.60722289549997\n",
      "resetting env. episode reward total was -15.0. running mean: -14.61115066654497\n",
      "resetting env. episode reward total was -18.0. running mean: -14.64503915987952\n",
      "resetting env. episode reward total was -17.0. running mean: -14.668588768280724\n",
      "resetting env. episode reward total was -16.0. running mean: -14.681902880597917\n",
      "resetting env. episode reward total was -16.0. running mean: -14.695083851791939\n",
      "resetting env. episode reward total was -15.0. running mean: -14.698133013274019\n",
      "resetting env. episode reward total was -12.0. running mean: -14.671151683141277\n",
      "resetting env. episode reward total was -16.0. running mean: -14.684440166309864\n",
      "resetting env. episode reward total was -9.0. running mean: -14.627595764646765\n",
      "resetting env. episode reward total was -14.0. running mean: -14.621319807000297\n",
      "resetting env. episode reward total was -13.0. running mean: -14.605106608930296\n",
      "resetting env. episode reward total was -18.0. running mean: -14.639055542840993\n",
      "resetting env. episode reward total was -18.0. running mean: -14.672664987412583\n",
      "resetting env. episode reward total was -17.0. running mean: -14.695938337538458\n",
      "resetting env. episode reward total was -14.0. running mean: -14.688978954163073\n",
      "resetting env. episode reward total was -16.0. running mean: -14.702089164621443\n",
      "resetting env. episode reward total was -13.0. running mean: -14.68506827297523\n",
      "resetting env. episode reward total was -14.0. running mean: -14.678217590245477\n",
      "resetting env. episode reward total was -11.0. running mean: -14.641435414343022\n",
      "resetting env. episode reward total was -12.0. running mean: -14.61502106019959\n",
      "resetting env. episode reward total was -7.0. running mean: -14.538870849597593\n",
      "resetting env. episode reward total was -15.0. running mean: -14.543482141101618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -20.0. running mean: -14.598047319690602\n",
      "resetting env. episode reward total was -4.0. running mean: -14.492066846493696\n",
      "resetting env. episode reward total was -19.0. running mean: -14.537146178028758\n",
      "resetting env. episode reward total was -14.0. running mean: -14.53177471624847\n",
      "resetting env. episode reward total was -15.0. running mean: -14.536456969085986\n",
      "resetting env. episode reward total was -8.0. running mean: -14.471092399395125\n",
      "resetting env. episode reward total was -14.0. running mean: -14.466381475401175\n",
      "resetting env. episode reward total was -15.0. running mean: -14.471717660647164\n",
      "resetting env. episode reward total was -12.0. running mean: -14.447000484040691\n",
      "resetting env. episode reward total was -11.0. running mean: -14.412530479200283\n",
      "resetting env. episode reward total was -13.0. running mean: -14.398405174408282\n",
      "resetting env. episode reward total was -18.0. running mean: -14.4344211226642\n",
      "resetting env. episode reward total was -14.0. running mean: -14.430076911437558\n",
      "resetting env. episode reward total was -16.0. running mean: -14.445776142323183\n",
      "resetting env. episode reward total was -18.0. running mean: -14.481318380899951\n",
      "resetting env. episode reward total was -15.0. running mean: -14.486505197090953\n",
      "resetting env. episode reward total was -8.0. running mean: -14.421640145120042\n",
      "resetting env. episode reward total was -19.0. running mean: -14.46742374366884\n",
      "resetting env. episode reward total was -12.0. running mean: -14.44274950623215\n",
      "resetting env. episode reward total was -6.0. running mean: -14.358322011169829\n",
      "resetting env. episode reward total was -15.0. running mean: -14.36473879105813\n",
      "resetting env. episode reward total was -10.0. running mean: -14.321091403147548\n",
      "resetting env. episode reward total was -14.0. running mean: -14.317880489116073\n",
      "resetting env. episode reward total was -9.0. running mean: -14.264701684224912\n",
      "resetting env. episode reward total was -12.0. running mean: -14.242054667382662\n",
      "resetting env. episode reward total was -14.0. running mean: -14.239634120708835\n",
      "resetting env. episode reward total was -20.0. running mean: -14.297237779501746\n",
      "resetting env. episode reward total was -11.0. running mean: -14.264265401706728\n",
      "resetting env. episode reward total was -14.0. running mean: -14.261622747689662\n",
      "resetting env. episode reward total was -15.0. running mean: -14.269006520212766\n",
      "resetting env. episode reward total was -13.0. running mean: -14.256316455010639\n",
      "resetting env. episode reward total was -16.0. running mean: -14.273753290460533\n",
      "resetting env. episode reward total was -16.0. running mean: -14.291015757555927\n",
      "resetting env. episode reward total was -18.0. running mean: -14.328105599980367\n",
      "resetting env. episode reward total was -6.0. running mean: -14.244824543980563\n",
      "resetting env. episode reward total was -11.0. running mean: -14.212376298540757\n",
      "resetting env. episode reward total was -17.0. running mean: -14.24025253555535\n",
      "resetting env. episode reward total was -13.0. running mean: -14.227850010199797\n",
      "resetting env. episode reward total was -9.0. running mean: -14.175571510097798\n",
      "resetting env. episode reward total was -10.0. running mean: -14.13381579499682\n",
      "resetting env. episode reward total was -11.0. running mean: -14.102477637046851\n",
      "resetting env. episode reward total was -13.0. running mean: -14.091452860676384\n",
      "resetting env. episode reward total was -2.0. running mean: -13.97053833206962\n",
      "resetting env. episode reward total was -9.0. running mean: -13.920832948748922\n",
      "resetting env. episode reward total was -11.0. running mean: -13.891624619261432\n",
      "resetting env. episode reward total was -12.0. running mean: -13.872708373068816\n",
      "resetting env. episode reward total was -17.0. running mean: -13.903981289338128\n",
      "resetting env. episode reward total was -5.0. running mean: -13.814941476444748\n",
      "resetting env. episode reward total was -19.0. running mean: -13.8667920616803\n",
      "resetting env. episode reward total was -17.0. running mean: -13.898124141063496\n",
      "resetting env. episode reward total was -4.0. running mean: -13.79914289965286\n",
      "resetting env. episode reward total was -13.0. running mean: -13.791151470656333\n",
      "resetting env. episode reward total was -16.0. running mean: -13.81323995594977\n",
      "resetting env. episode reward total was -8.0. running mean: -13.755107556390273\n",
      "resetting env. episode reward total was -10.0. running mean: -13.71755648082637\n",
      "resetting env. episode reward total was -12.0. running mean: -13.700380916018107\n",
      "resetting env. episode reward total was -13.0. running mean: -13.693377106857927\n",
      "resetting env. episode reward total was -14.0. running mean: -13.696443335789349\n",
      "resetting env. episode reward total was -11.0. running mean: -13.669478902431454\n",
      "resetting env. episode reward total was -11.0. running mean: -13.642784113407139\n",
      "resetting env. episode reward total was -15.0. running mean: -13.656356272273067\n",
      "resetting env. episode reward total was -10.0. running mean: -13.619792709550335\n",
      "resetting env. episode reward total was -11.0. running mean: -13.593594782454831\n",
      "resetting env. episode reward total was -11.0. running mean: -13.567658834630283\n",
      "resetting env. episode reward total was -10.0. running mean: -13.53198224628398\n",
      "resetting env. episode reward total was -15.0. running mean: -13.54666242382114\n",
      "resetting env. episode reward total was -7.0. running mean: -13.481195799582927\n",
      "resetting env. episode reward total was -13.0. running mean: -13.476383841587099\n",
      "resetting env. episode reward total was -11.0. running mean: -13.451620003171227\n",
      "resetting env. episode reward total was -11.0. running mean: -13.427103803139515\n",
      "resetting env. episode reward total was -6.0. running mean: -13.35283276510812\n",
      "resetting env. episode reward total was -16.0. running mean: -13.379304437457039\n",
      "resetting env. episode reward total was -17.0. running mean: -13.415511393082468\n",
      "resetting env. episode reward total was -13.0. running mean: -13.411356279151644\n",
      "resetting env. episode reward total was -14.0. running mean: -13.417242716360128\n",
      "resetting env. episode reward total was -17.0. running mean: -13.453070289196527\n",
      "resetting env. episode reward total was -19.0. running mean: -13.508539586304561\n",
      "resetting env. episode reward total was -17.0. running mean: -13.543454190441516\n",
      "resetting env. episode reward total was -13.0. running mean: -13.538019648537102\n",
      "resetting env. episode reward total was -13.0. running mean: -13.53263945205173\n",
      "resetting env. episode reward total was -12.0. running mean: -13.517313057531213\n",
      "resetting env. episode reward total was -5.0. running mean: -13.432139926955902\n",
      "resetting env. episode reward total was -16.0. running mean: -13.457818527686342\n",
      "resetting env. episode reward total was -11.0. running mean: -13.433240342409478\n",
      "resetting env. episode reward total was -11.0. running mean: -13.408907938985383\n",
      "resetting env. episode reward total was -6.0. running mean: -13.33481885959553\n",
      "resetting env. episode reward total was -11.0. running mean: -13.311470670999574\n",
      "resetting env. episode reward total was -14.0. running mean: -13.318355964289578\n",
      "resetting env. episode reward total was -10.0. running mean: -13.285172404646682\n",
      "resetting env. episode reward total was -19.0. running mean: -13.342320680600213\n",
      "resetting env. episode reward total was -11.0. running mean: -13.31889747379421\n",
      "resetting env. episode reward total was -8.0. running mean: -13.265708499056268\n",
      "resetting env. episode reward total was -11.0. running mean: -13.243051414065706\n",
      "resetting env. episode reward total was -17.0. running mean: -13.280620899925049\n",
      "resetting env. episode reward total was -15.0. running mean: -13.297814690925799\n",
      "resetting env. episode reward total was -8.0. running mean: -13.244836544016541\n",
      "resetting env. episode reward total was -12.0. running mean: -13.232388178576375\n",
      "resetting env. episode reward total was -15.0. running mean: -13.250064296790612\n",
      "resetting env. episode reward total was -16.0. running mean: -13.277563653822705\n",
      "resetting env. episode reward total was -13.0. running mean: -13.274788017284479\n",
      "resetting env. episode reward total was -14.0. running mean: -13.282040137111634\n",
      "resetting env. episode reward total was -13.0. running mean: -13.279219735740519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: -13.226427538383113\n",
      "resetting env. episode reward total was -13.0. running mean: -13.224163262999284\n",
      "resetting env. episode reward total was -12.0. running mean: -13.21192163036929\n",
      "resetting env. episode reward total was -15.0. running mean: -13.229802414065597\n",
      "resetting env. episode reward total was -10.0. running mean: -13.19750438992494\n",
      "resetting env. episode reward total was -10.0. running mean: -13.165529346025691\n",
      "resetting env. episode reward total was -15.0. running mean: -13.183874052565434\n",
      "resetting env. episode reward total was -16.0. running mean: -13.212035312039779\n",
      "resetting env. episode reward total was -17.0. running mean: -13.249914958919382\n",
      "resetting env. episode reward total was -16.0. running mean: -13.277415809330188\n",
      "resetting env. episode reward total was -8.0. running mean: -13.224641651236887\n",
      "resetting env. episode reward total was -11.0. running mean: -13.202395234724516\n",
      "resetting env. episode reward total was -15.0. running mean: -13.220371282377272\n",
      "resetting env. episode reward total was -13.0. running mean: -13.2181675695535\n",
      "resetting env. episode reward total was -12.0. running mean: -13.205985893857966\n",
      "resetting env. episode reward total was -19.0. running mean: -13.263926034919384\n",
      "resetting env. episode reward total was -17.0. running mean: -13.30128677457019\n",
      "resetting env. episode reward total was -12.0. running mean: -13.288273906824488\n",
      "resetting env. episode reward total was -10.0. running mean: -13.255391167756242\n",
      "resetting env. episode reward total was -14.0. running mean: -13.26283725607868\n",
      "resetting env. episode reward total was -14.0. running mean: -13.270208883517894\n",
      "resetting env. episode reward total was -17.0. running mean: -13.307506794682714\n",
      "resetting env. episode reward total was -15.0. running mean: -13.324431726735888\n",
      "resetting env. episode reward total was -11.0. running mean: -13.301187409468529\n",
      "resetting env. episode reward total was -15.0. running mean: -13.318175535373843\n",
      "resetting env. episode reward total was -17.0. running mean: -13.354993780020104\n",
      "resetting env. episode reward total was -16.0. running mean: -13.381443842219904\n",
      "resetting env. episode reward total was -13.0. running mean: -13.377629403797705\n",
      "resetting env. episode reward total was -11.0. running mean: -13.353853109759728\n",
      "resetting env. episode reward total was -13.0. running mean: -13.35031457866213\n",
      "resetting env. episode reward total was -11.0. running mean: -13.326811432875509\n",
      "resetting env. episode reward total was -14.0. running mean: -13.333543318546754\n",
      "resetting env. episode reward total was -11.0. running mean: -13.310207885361287\n",
      "resetting env. episode reward total was -15.0. running mean: -13.327105806507674\n",
      "resetting env. episode reward total was -15.0. running mean: -13.343834748442598\n",
      "resetting env. episode reward total was -15.0. running mean: -13.360396400958171\n",
      "resetting env. episode reward total was -10.0. running mean: -13.326792436948589\n",
      "resetting env. episode reward total was -9.0. running mean: -13.283524512579103\n",
      "resetting env. episode reward total was -6.0. running mean: -13.210689267453311\n",
      "resetting env. episode reward total was -18.0. running mean: -13.258582374778777\n",
      "resetting env. episode reward total was -13.0. running mean: -13.255996551030991\n",
      "resetting env. episode reward total was -8.0. running mean: -13.20343658552068\n",
      "resetting env. episode reward total was -17.0. running mean: -13.241402219665474\n",
      "resetting env. episode reward total was -15.0. running mean: -13.25898819746882\n",
      "resetting env. episode reward total was -12.0. running mean: -13.246398315494131\n",
      "resetting env. episode reward total was -18.0. running mean: -13.29393433233919\n",
      "resetting env. episode reward total was -13.0. running mean: -13.290994989015799\n",
      "resetting env. episode reward total was -17.0. running mean: -13.328085039125641\n",
      "resetting env. episode reward total was -10.0. running mean: -13.294804188734384\n",
      "resetting env. episode reward total was -9.0. running mean: -13.25185614684704\n",
      "resetting env. episode reward total was -9.0. running mean: -13.209337585378568\n",
      "resetting env. episode reward total was -17.0. running mean: -13.247244209524782\n",
      "resetting env. episode reward total was -12.0. running mean: -13.234771767429534\n",
      "resetting env. episode reward total was -10.0. running mean: -13.202424049755237\n",
      "resetting env. episode reward total was -17.0. running mean: -13.240399809257685\n",
      "resetting env. episode reward total was -17.0. running mean: -13.277995811165107\n",
      "resetting env. episode reward total was -16.0. running mean: -13.305215853053456\n",
      "resetting env. episode reward total was -21.0. running mean: -13.382163694522921\n",
      "resetting env. episode reward total was -8.0. running mean: -13.328342057577691\n",
      "resetting env. episode reward total was -15.0. running mean: -13.345058637001914\n",
      "resetting env. episode reward total was -14.0. running mean: -13.351608050631896\n",
      "resetting env. episode reward total was -18.0. running mean: -13.398091970125577\n",
      "resetting env. episode reward total was -13.0. running mean: -13.394111050424321\n",
      "resetting env. episode reward total was -7.0. running mean: -13.330169939920077\n",
      "resetting env. episode reward total was -11.0. running mean: -13.306868240520876\n",
      "resetting env. episode reward total was -15.0. running mean: -13.323799558115667\n",
      "resetting env. episode reward total was -6.0. running mean: -13.25056156253451\n",
      "resetting env. episode reward total was -12.0. running mean: -13.238055946909165\n",
      "resetting env. episode reward total was -17.0. running mean: -13.275675387440074\n",
      "resetting env. episode reward total was -15.0. running mean: -13.292918633565673\n",
      "resetting env. episode reward total was -16.0. running mean: -13.319989447230016\n",
      "resetting env. episode reward total was -11.0. running mean: -13.296789552757716\n",
      "resetting env. episode reward total was -1.0. running mean: -13.173821657230137\n",
      "resetting env. episode reward total was -13.0. running mean: -13.172083440657836\n",
      "resetting env. episode reward total was -11.0. running mean: -13.150362606251257\n",
      "resetting env. episode reward total was -10.0. running mean: -13.118858980188744\n",
      "resetting env. episode reward total was -7.0. running mean: -13.057670390386857\n",
      "resetting env. episode reward total was -19.0. running mean: -13.117093686482988\n",
      "resetting env. episode reward total was -16.0. running mean: -13.145922749618158\n",
      "resetting env. episode reward total was -13.0. running mean: -13.144463522121978\n",
      "resetting env. episode reward total was -13.0. running mean: -13.143018886900759\n",
      "resetting env. episode reward total was -11.0. running mean: -13.12158869803175\n",
      "resetting env. episode reward total was -8.0. running mean: -13.070372811051433\n",
      "resetting env. episode reward total was -11.0. running mean: -13.049669082940918\n",
      "resetting env. episode reward total was -12.0. running mean: -13.039172392111508\n",
      "resetting env. episode reward total was -18.0. running mean: -13.088780668190394\n",
      "resetting env. episode reward total was -15.0. running mean: -13.107892861508489\n",
      "resetting env. episode reward total was -9.0. running mean: -13.066813932893403\n",
      "resetting env. episode reward total was -13.0. running mean: -13.06614579356447\n",
      "resetting env. episode reward total was -8.0. running mean: -13.015484335628825\n",
      "resetting env. episode reward total was -18.0. running mean: -13.065329492272536\n",
      "resetting env. episode reward total was -15.0. running mean: -13.084676197349811\n",
      "resetting env. episode reward total was -12.0. running mean: -13.073829435376313\n",
      "resetting env. episode reward total was -5.0. running mean: -12.99309114102255\n",
      "resetting env. episode reward total was -14.0. running mean: -13.003160229612325\n",
      "resetting env. episode reward total was -8.0. running mean: -12.953128627316202\n",
      "resetting env. episode reward total was -12.0. running mean: -12.94359734104304\n",
      "resetting env. episode reward total was -19.0. running mean: -13.004161367632609\n",
      "resetting env. episode reward total was -11.0. running mean: -12.984119753956282\n",
      "resetting env. episode reward total was -11.0. running mean: -12.96427855641672\n",
      "resetting env. episode reward total was -11.0. running mean: -12.944635770852551\n",
      "resetting env. episode reward total was -9.0. running mean: -12.905189413144026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -10.0. running mean: -12.876137519012586\n",
      "resetting env. episode reward total was -10.0. running mean: -12.84737614382246\n",
      "resetting env. episode reward total was -11.0. running mean: -12.828902382384236\n",
      "resetting env. episode reward total was -14.0. running mean: -12.840613358560393\n",
      "resetting env. episode reward total was -11.0. running mean: -12.822207224974788\n",
      "resetting env. episode reward total was -11.0. running mean: -12.803985152725039\n",
      "resetting env. episode reward total was -5.0. running mean: -12.72594530119779\n",
      "resetting env. episode reward total was -9.0. running mean: -12.688685848185811\n",
      "resetting env. episode reward total was -10.0. running mean: -12.661798989703952\n",
      "resetting env. episode reward total was -11.0. running mean: -12.645180999806911\n",
      "resetting env. episode reward total was -14.0. running mean: -12.658729189808842\n",
      "resetting env. episode reward total was -11.0. running mean: -12.642141897910752\n",
      "resetting env. episode reward total was -6.0. running mean: -12.575720478931645\n",
      "resetting env. episode reward total was -17.0. running mean: -12.619963274142329\n",
      "resetting env. episode reward total was -18.0. running mean: -12.673763641400905\n",
      "resetting env. episode reward total was -19.0. running mean: -12.737026004986895\n",
      "resetting env. episode reward total was -6.0. running mean: -12.669655744937026\n",
      "resetting env. episode reward total was -15.0. running mean: -12.692959187487656\n",
      "resetting env. episode reward total was -10.0. running mean: -12.666029595612779\n",
      "resetting env. episode reward total was -15.0. running mean: -12.68936929965665\n",
      "resetting env. episode reward total was -11.0. running mean: -12.672475606660084\n",
      "resetting env. episode reward total was -12.0. running mean: -12.665750850593483\n",
      "resetting env. episode reward total was -19.0. running mean: -12.729093342087547\n",
      "resetting env. episode reward total was -9.0. running mean: -12.691802408666671\n",
      "resetting env. episode reward total was -14.0. running mean: -12.704884384580005\n",
      "resetting env. episode reward total was -3.0. running mean: -12.607835540734204\n",
      "resetting env. episode reward total was -11.0. running mean: -12.59175718532686\n",
      "resetting env. episode reward total was -15.0. running mean: -12.615839613473593\n",
      "resetting env. episode reward total was -17.0. running mean: -12.659681217338857\n",
      "resetting env. episode reward total was -17.0. running mean: -12.703084405165468\n",
      "resetting env. episode reward total was -14.0. running mean: -12.716053561113814\n",
      "resetting env. episode reward total was -13.0. running mean: -12.718893025502677\n",
      "resetting env. episode reward total was -16.0. running mean: -12.75170409524765\n",
      "resetting env. episode reward total was -18.0. running mean: -12.804187054295173\n",
      "resetting env. episode reward total was -13.0. running mean: -12.806145183752223\n",
      "resetting env. episode reward total was -15.0. running mean: -12.8280837319147\n",
      "resetting env. episode reward total was -18.0. running mean: -12.879802894595553\n",
      "resetting env. episode reward total was -14.0. running mean: -12.891004865649597\n",
      "resetting env. episode reward total was -9.0. running mean: -12.8520948169931\n",
      "resetting env. episode reward total was -7.0. running mean: -12.793573868823168\n",
      "resetting env. episode reward total was -10.0. running mean: -12.765638130134937\n",
      "resetting env. episode reward total was -14.0. running mean: -12.777981748833588\n",
      "resetting env. episode reward total was -8.0. running mean: -12.730201931345253\n",
      "resetting env. episode reward total was -14.0. running mean: -12.7428999120318\n",
      "resetting env. episode reward total was -13.0. running mean: -12.745470912911484\n",
      "resetting env. episode reward total was -11.0. running mean: -12.728016203782369\n",
      "resetting env. episode reward total was -11.0. running mean: -12.710736041744545\n",
      "resetting env. episode reward total was -4.0. running mean: -12.623628681327098\n",
      "resetting env. episode reward total was -4.0. running mean: -12.537392394513827\n",
      "resetting env. episode reward total was -14.0. running mean: -12.552018470568688\n",
      "resetting env. episode reward total was -11.0. running mean: -12.536498285863\n",
      "resetting env. episode reward total was -12.0. running mean: -12.53113330300437\n",
      "resetting env. episode reward total was -16.0. running mean: -12.565821969974326\n",
      "resetting env. episode reward total was -11.0. running mean: -12.550163750274582\n",
      "resetting env. episode reward total was -7.0. running mean: -12.494662112771836\n",
      "resetting env. episode reward total was -10.0. running mean: -12.469715491644118\n",
      "resetting env. episode reward total was -18.0. running mean: -12.525018336727676\n",
      "resetting env. episode reward total was -13.0. running mean: -12.5297681533604\n",
      "resetting env. episode reward total was -9.0. running mean: -12.494470471826796\n",
      "resetting env. episode reward total was -6.0. running mean: -12.429525767108528\n",
      "resetting env. episode reward total was -14.0. running mean: -12.445230509437444\n",
      "resetting env. episode reward total was -11.0. running mean: -12.430778204343069\n",
      "resetting env. episode reward total was -13.0. running mean: -12.436470422299639\n",
      "resetting env. episode reward total was -11.0. running mean: -12.422105718076642\n",
      "resetting env. episode reward total was -11.0. running mean: -12.407884660895874\n",
      "resetting env. episode reward total was -7.0. running mean: -12.353805814286915\n",
      "resetting env. episode reward total was -9.0. running mean: -12.320267756144045\n",
      "resetting env. episode reward total was -17.0. running mean: -12.367065078582604\n",
      "resetting env. episode reward total was -14.0. running mean: -12.383394427796778\n",
      "resetting env. episode reward total was -15.0. running mean: -12.409560483518812\n",
      "resetting env. episode reward total was -9.0. running mean: -12.375464878683623\n",
      "resetting env. episode reward total was -13.0. running mean: -12.381710229896788\n",
      "resetting env. episode reward total was -7.0. running mean: -12.32789312759782\n",
      "resetting env. episode reward total was -11.0. running mean: -12.314614196321841\n",
      "resetting env. episode reward total was -14.0. running mean: -12.331468054358623\n",
      "resetting env. episode reward total was -11.0. running mean: -12.318153373815036\n",
      "resetting env. episode reward total was -8.0. running mean: -12.274971840076885\n",
      "resetting env. episode reward total was -15.0. running mean: -12.302222121676117\n",
      "resetting env. episode reward total was -12.0. running mean: -12.299199900459355\n",
      "resetting env. episode reward total was -11.0. running mean: -12.28620790145476\n",
      "resetting env. episode reward total was -11.0. running mean: -12.273345822440213\n",
      "resetting env. episode reward total was -17.0. running mean: -12.32061236421581\n",
      "resetting env. episode reward total was -5.0. running mean: -12.247406240573653\n",
      "resetting env. episode reward total was -4.0. running mean: -12.164932178167916\n",
      "resetting env. episode reward total was -3.0. running mean: -12.073282856386236\n",
      "resetting env. episode reward total was -15.0. running mean: -12.102550027822373\n",
      "resetting env. episode reward total was -13.0. running mean: -12.11152452754415\n",
      "resetting env. episode reward total was -13.0. running mean: -12.120409282268708\n",
      "resetting env. episode reward total was -14.0. running mean: -12.139205189446022\n",
      "resetting env. episode reward total was -13.0. running mean: -12.147813137551562\n",
      "resetting env. episode reward total was -10.0. running mean: -12.126335006176046\n",
      "resetting env. episode reward total was -9.0. running mean: -12.095071656114285\n",
      "resetting env. episode reward total was -11.0. running mean: -12.084120939553141\n",
      "resetting env. episode reward total was -15.0. running mean: -12.113279730157611\n",
      "resetting env. episode reward total was -11.0. running mean: -12.102146932856034\n",
      "resetting env. episode reward total was -14.0. running mean: -12.121125463527473\n",
      "resetting env. episode reward total was -3.0. running mean: -12.029914208892198\n",
      "resetting env. episode reward total was -13.0. running mean: -12.039615066803277\n",
      "resetting env. episode reward total was -12.0. running mean: -12.039218916135244\n",
      "resetting env. episode reward total was -13.0. running mean: -12.048826726973893\n",
      "resetting env. episode reward total was -8.0. running mean: -12.008338459704154\n",
      "resetting env. episode reward total was -8.0. running mean: -11.968255075107113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -9.0. running mean: -11.938572524356042\n",
      "resetting env. episode reward total was -9.0. running mean: -11.909186799112481\n",
      "resetting env. episode reward total was -13.0. running mean: -11.920094931121357\n",
      "resetting env. episode reward total was -11.0. running mean: -11.910893981810142\n",
      "resetting env. episode reward total was -12.0. running mean: -11.91178504199204\n",
      "resetting env. episode reward total was -8.0. running mean: -11.87266719157212\n",
      "resetting env. episode reward total was -15.0. running mean: -11.903940519656398\n",
      "resetting env. episode reward total was -14.0. running mean: -11.924901114459836\n",
      "resetting env. episode reward total was -17.0. running mean: -11.975652103315237\n",
      "resetting env. episode reward total was -18.0. running mean: -12.035895582282084\n",
      "resetting env. episode reward total was -13.0. running mean: -12.045536626459263\n",
      "resetting env. episode reward total was -16.0. running mean: -12.08508126019467\n",
      "resetting env. episode reward total was -8.0. running mean: -12.044230447592723\n",
      "resetting env. episode reward total was -11.0. running mean: -12.033788143116794\n",
      "resetting env. episode reward total was -15.0. running mean: -12.063450261685627\n",
      "resetting env. episode reward total was -9.0. running mean: -12.032815759068772\n",
      "resetting env. episode reward total was -13.0. running mean: -12.042487601478085\n",
      "resetting env. episode reward total was -15.0. running mean: -12.072062725463304\n",
      "resetting env. episode reward total was -16.0. running mean: -12.111342098208672\n",
      "resetting env. episode reward total was -13.0. running mean: -12.120228677226585\n",
      "resetting env. episode reward total was -14.0. running mean: -12.139026390454319\n",
      "resetting env. episode reward total was -14.0. running mean: -12.157636126549777\n",
      "resetting env. episode reward total was -8.0. running mean: -12.116059765284279\n",
      "resetting env. episode reward total was -8.0. running mean: -12.074899167631436\n",
      "resetting env. episode reward total was -18.0. running mean: -12.13415017595512\n",
      "resetting env. episode reward total was -3.0. running mean: -12.04280867419557\n",
      "resetting env. episode reward total was -19.0. running mean: -12.112380587453613\n",
      "resetting env. episode reward total was -13.0. running mean: -12.121256781579078\n",
      "resetting env. episode reward total was -18.0. running mean: -12.180044213763287\n",
      "resetting env. episode reward total was -9.0. running mean: -12.148243771625653\n",
      "resetting env. episode reward total was -12.0. running mean: -12.146761333909396\n",
      "resetting env. episode reward total was -7.0. running mean: -12.095293720570302\n",
      "resetting env. episode reward total was -8.0. running mean: -12.0543407833646\n",
      "resetting env. episode reward total was -8.0. running mean: -12.013797375530954\n",
      "resetting env. episode reward total was -9.0. running mean: -11.983659401775645\n",
      "resetting env. episode reward total was -13.0. running mean: -11.993822807757889\n",
      "resetting env. episode reward total was -14.0. running mean: -12.01388457968031\n",
      "resetting env. episode reward total was -16.0. running mean: -12.053745733883506\n",
      "resetting env. episode reward total was -11.0. running mean: -12.04320827654467\n",
      "resetting env. episode reward total was -6.0. running mean: -11.982776193779223\n",
      "resetting env. episode reward total was -16.0. running mean: -12.022948431841431\n",
      "resetting env. episode reward total was -9.0. running mean: -11.992718947523016\n",
      "resetting env. episode reward total was -8.0. running mean: -11.952791758047786\n",
      "resetting env. episode reward total was -15.0. running mean: -11.983263840467309\n",
      "resetting env. episode reward total was -11.0. running mean: -11.973431202062635\n",
      "resetting env. episode reward total was -13.0. running mean: -11.98369689004201\n",
      "resetting env. episode reward total was -4.0. running mean: -11.903859921141589\n",
      "resetting env. episode reward total was -10.0. running mean: -11.884821321930172\n",
      "resetting env. episode reward total was -15.0. running mean: -11.91597310871087\n",
      "resetting env. episode reward total was -11.0. running mean: -11.906813377623761\n",
      "resetting env. episode reward total was -3.0. running mean: -11.817745243847522\n",
      "resetting env. episode reward total was -13.0. running mean: -11.829567791409048\n",
      "resetting env. episode reward total was -14.0. running mean: -11.851272113494957\n",
      "resetting env. episode reward total was -11.0. running mean: -11.842759392360007\n",
      "resetting env. episode reward total was -12.0. running mean: -11.844331798436405\n",
      "resetting env. episode reward total was -7.0. running mean: -11.795888480452042\n",
      "resetting env. episode reward total was -8.0. running mean: -11.757929595647521\n",
      "resetting env. episode reward total was -11.0. running mean: -11.750350299691046\n",
      "resetting env. episode reward total was -13.0. running mean: -11.762846796694136\n",
      "resetting env. episode reward total was -7.0. running mean: -11.715218328727195\n",
      "resetting env. episode reward total was -3.0. running mean: -11.628066145439922\n",
      "resetting env. episode reward total was -11.0. running mean: -11.621785483985523\n",
      "resetting env. episode reward total was -13.0. running mean: -11.635567629145669\n",
      "resetting env. episode reward total was -17.0. running mean: -11.689211952854212\n",
      "resetting env. episode reward total was -10.0. running mean: -11.67231983332567\n",
      "resetting env. episode reward total was -15.0. running mean: -11.705596634992414\n",
      "resetting env. episode reward total was 2.0. running mean: -11.56854066864249\n",
      "resetting env. episode reward total was -14.0. running mean: -11.592855261956066\n",
      "resetting env. episode reward total was -12.0. running mean: -11.596926709336504\n",
      "resetting env. episode reward total was -15.0. running mean: -11.630957442243139\n",
      "resetting env. episode reward total was -15.0. running mean: -11.664647867820708\n",
      "resetting env. episode reward total was -9.0. running mean: -11.6380013891425\n",
      "resetting env. episode reward total was -9.0. running mean: -11.611621375251076\n",
      "resetting env. episode reward total was -15.0. running mean: -11.645505161498566\n",
      "resetting env. episode reward total was -15.0. running mean: -11.67905010988358\n",
      "resetting env. episode reward total was -15.0. running mean: -11.712259608784745\n",
      "resetting env. episode reward total was -13.0. running mean: -11.725137012696898\n",
      "resetting env. episode reward total was -15.0. running mean: -11.75788564256993\n",
      "resetting env. episode reward total was -7.0. running mean: -11.71030678614423\n",
      "resetting env. episode reward total was -7.0. running mean: -11.663203718282787\n",
      "resetting env. episode reward total was -15.0. running mean: -11.69657168109996\n",
      "resetting env. episode reward total was -13.0. running mean: -11.70960596428896\n",
      "resetting env. episode reward total was -8.0. running mean: -11.67250990464607\n",
      "resetting env. episode reward total was -10.0. running mean: -11.655784805599609\n",
      "resetting env. episode reward total was -12.0. running mean: -11.659226957543613\n",
      "resetting env. episode reward total was -15.0. running mean: -11.692634687968177\n",
      "resetting env. episode reward total was -18.0. running mean: -11.755708341088495\n",
      "resetting env. episode reward total was -7.0. running mean: -11.70815125767761\n",
      "resetting env. episode reward total was -16.0. running mean: -11.751069745100834\n",
      "resetting env. episode reward total was -17.0. running mean: -11.803559047649825\n",
      "resetting env. episode reward total was -16.0. running mean: -11.845523457173327\n",
      "resetting env. episode reward total was -15.0. running mean: -11.877068222601594\n",
      "resetting env. episode reward total was -6.0. running mean: -11.818297540375578\n",
      "resetting env. episode reward total was -13.0. running mean: -11.830114564971824\n",
      "resetting env. episode reward total was -1.0. running mean: -11.721813419322105\n",
      "resetting env. episode reward total was -15.0. running mean: -11.754595285128884\n",
      "resetting env. episode reward total was -13.0. running mean: -11.767049332277596\n",
      "resetting env. episode reward total was -11.0. running mean: -11.759378838954818\n",
      "resetting env. episode reward total was -12.0. running mean: -11.761785050565269\n",
      "resetting env. episode reward total was -13.0. running mean: -11.774167200059617\n",
      "resetting env. episode reward total was -13.0. running mean: -11.786425528059022\n",
      "resetting env. episode reward total was -11.0. running mean: -11.77856127277843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -12.0. running mean: -11.780775660050645\n",
      "resetting env. episode reward total was -3.0. running mean: -11.692967903450139\n",
      "resetting env. episode reward total was -9.0. running mean: -11.666038224415637\n",
      "resetting env. episode reward total was -9.0. running mean: -11.63937784217148\n",
      "resetting env. episode reward total was -13.0. running mean: -11.652984063749766\n",
      "resetting env. episode reward total was 1.0. running mean: -11.52645422311227\n",
      "resetting env. episode reward total was -18.0. running mean: -11.591189680881147\n",
      "resetting env. episode reward total was -15.0. running mean: -11.625277784072336\n",
      "resetting env. episode reward total was -13.0. running mean: -11.639025006231615\n",
      "resetting env. episode reward total was -13.0. running mean: -11.652634756169299\n",
      "resetting env. episode reward total was -17.0. running mean: -11.706108408607605\n",
      "resetting env. episode reward total was -12.0. running mean: -11.709047324521528\n",
      "resetting env. episode reward total was -8.0. running mean: -11.671956851276313\n",
      "resetting env. episode reward total was -13.0. running mean: -11.68523728276355\n",
      "resetting env. episode reward total was -11.0. running mean: -11.678384909935914\n",
      "resetting env. episode reward total was -11.0. running mean: -11.671601060836554\n",
      "resetting env. episode reward total was -12.0. running mean: -11.674885050228188\n",
      "resetting env. episode reward total was -12.0. running mean: -11.678136199725905\n",
      "resetting env. episode reward total was -19.0. running mean: -11.751354837728647\n",
      "resetting env. episode reward total was -7.0. running mean: -11.70384128935136\n",
      "resetting env. episode reward total was -15.0. running mean: -11.736802876457846\n",
      "resetting env. episode reward total was -10.0. running mean: -11.719434847693266\n",
      "resetting env. episode reward total was -13.0. running mean: -11.732240499216335\n",
      "resetting env. episode reward total was -12.0. running mean: -11.73491809422417\n",
      "resetting env. episode reward total was -17.0. running mean: -11.787568913281929\n",
      "resetting env. episode reward total was -16.0. running mean: -11.829693224149109\n",
      "resetting env. episode reward total was -14.0. running mean: -11.851396291907617\n",
      "resetting env. episode reward total was -13.0. running mean: -11.862882328988542\n",
      "resetting env. episode reward total was -11.0. running mean: -11.854253505698656\n",
      "resetting env. episode reward total was -17.0. running mean: -11.90571097064167\n",
      "resetting env. episode reward total was -18.0. running mean: -11.966653860935253\n",
      "resetting env. episode reward total was -12.0. running mean: -11.966987322325899\n",
      "resetting env. episode reward total was -16.0. running mean: -12.00731744910264\n",
      "resetting env. episode reward total was -14.0. running mean: -12.027244274611615\n",
      "resetting env. episode reward total was -11.0. running mean: -12.016971831865497\n",
      "resetting env. episode reward total was -17.0. running mean: -12.066802113546842\n",
      "resetting env. episode reward total was -14.0. running mean: -12.086134092411374\n",
      "resetting env. episode reward total was -13.0. running mean: -12.095272751487261\n",
      "resetting env. episode reward total was -10.0. running mean: -12.074320023972389\n",
      "resetting env. episode reward total was -19.0. running mean: -12.143576823732664\n",
      "resetting env. episode reward total was -20.0. running mean: -12.222141055495337\n",
      "resetting env. episode reward total was -16.0. running mean: -12.259919644940384\n",
      "resetting env. episode reward total was -19.0. running mean: -12.32732044849098\n",
      "resetting env. episode reward total was -13.0. running mean: -12.33404724400607\n",
      "resetting env. episode reward total was -13.0. running mean: -12.34070677156601\n",
      "resetting env. episode reward total was -14.0. running mean: -12.35729970385035\n",
      "resetting env. episode reward total was -10.0. running mean: -12.333726706811845\n",
      "resetting env. episode reward total was -13.0. running mean: -12.340389439743728\n",
      "resetting env. episode reward total was -14.0. running mean: -12.35698554534629\n",
      "resetting env. episode reward total was -16.0. running mean: -12.393415689892828\n",
      "resetting env. episode reward total was -11.0. running mean: -12.3794815329939\n",
      "resetting env. episode reward total was -15.0. running mean: -12.405686717663961\n",
      "resetting env. episode reward total was -14.0. running mean: -12.421629850487323\n",
      "resetting env. episode reward total was -15.0. running mean: -12.44741355198245\n",
      "resetting env. episode reward total was -16.0. running mean: -12.482939416462626\n",
      "resetting env. episode reward total was -5.0. running mean: -12.408110022298\n",
      "resetting env. episode reward total was -17.0. running mean: -12.45402892207502\n",
      "resetting env. episode reward total was -19.0. running mean: -12.51948863285427\n",
      "resetting env. episode reward total was -13.0. running mean: -12.524293746525727\n",
      "resetting env. episode reward total was -7.0. running mean: -12.46905080906047\n",
      "resetting env. episode reward total was -12.0. running mean: -12.464360300969863\n",
      "resetting env. episode reward total was -15.0. running mean: -12.489716697960166\n",
      "resetting env. episode reward total was -11.0. running mean: -12.474819530980563\n",
      "resetting env. episode reward total was -18.0. running mean: -12.530071335670756\n",
      "resetting env. episode reward total was -11.0. running mean: -12.514770622314048\n",
      "resetting env. episode reward total was -13.0. running mean: -12.519622916090908\n",
      "resetting env. episode reward total was -15.0. running mean: -12.544426686929999\n",
      "resetting env. episode reward total was -14.0. running mean: -12.5589824200607\n",
      "resetting env. episode reward total was -12.0. running mean: -12.55339259586009\n",
      "resetting env. episode reward total was -11.0. running mean: -12.537858669901489\n",
      "resetting env. episode reward total was -17.0. running mean: -12.582480083202475\n",
      "resetting env. episode reward total was -18.0. running mean: -12.63665528237045\n",
      "resetting env. episode reward total was -12.0. running mean: -12.630288729546745\n",
      "resetting env. episode reward total was -8.0. running mean: -12.583985842251277\n",
      "resetting env. episode reward total was -16.0. running mean: -12.618145983828764\n",
      "resetting env. episode reward total was -5.0. running mean: -12.541964523990478\n",
      "resetting env. episode reward total was -15.0. running mean: -12.566544878750573\n",
      "resetting env. episode reward total was -16.0. running mean: -12.600879429963067\n",
      "resetting env. episode reward total was -17.0. running mean: -12.644870635663436\n",
      "resetting env. episode reward total was -17.0. running mean: -12.6884219293068\n",
      "resetting env. episode reward total was -11.0. running mean: -12.671537710013732\n",
      "resetting env. episode reward total was -11.0. running mean: -12.654822332913595\n",
      "resetting env. episode reward total was -11.0. running mean: -12.638274109584458\n",
      "resetting env. episode reward total was -13.0. running mean: -12.641891368488613\n",
      "resetting env. episode reward total was -13.0. running mean: -12.645472454803727\n",
      "resetting env. episode reward total was -10.0. running mean: -12.61901773025569\n",
      "resetting env. episode reward total was -13.0. running mean: -12.622827552953133\n",
      "resetting env. episode reward total was -17.0. running mean: -12.666599277423602\n",
      "resetting env. episode reward total was -16.0. running mean: -12.699933284649367\n",
      "resetting env. episode reward total was -15.0. running mean: -12.722933951802874\n",
      "resetting env. episode reward total was -10.0. running mean: -12.695704612284844\n",
      "resetting env. episode reward total was -14.0. running mean: -12.708747566161996\n",
      "resetting env. episode reward total was -17.0. running mean: -12.751660090500376\n",
      "resetting env. episode reward total was -13.0. running mean: -12.754143489595373\n",
      "resetting env. episode reward total was -17.0. running mean: -12.796602054699418\n",
      "resetting env. episode reward total was -18.0. running mean: -12.848636034152424\n",
      "resetting env. episode reward total was -15.0. running mean: -12.8701496738109\n",
      "resetting env. episode reward total was -7.0. running mean: -12.81144817707279\n",
      "resetting env. episode reward total was -9.0. running mean: -12.773333695302062\n",
      "resetting env. episode reward total was -14.0. running mean: -12.785600358349042\n",
      "resetting env. episode reward total was -17.0. running mean: -12.827744354765551\n",
      "resetting env. episode reward total was -14.0. running mean: -12.839466911217896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -15.0. running mean: -12.861072242105717\n",
      "resetting env. episode reward total was -13.0. running mean: -12.862461519684661\n",
      "resetting env. episode reward total was -13.0. running mean: -12.863836904487815\n",
      "resetting env. episode reward total was -16.0. running mean: -12.895198535442937\n",
      "resetting env. episode reward total was -19.0. running mean: -12.956246550088506\n",
      "resetting env. episode reward total was -13.0. running mean: -12.956684084587621\n",
      "resetting env. episode reward total was -14.0. running mean: -12.967117243741745\n",
      "resetting env. episode reward total was -16.0. running mean: -12.997446071304328\n",
      "resetting env. episode reward total was -19.0. running mean: -13.057471610591284\n",
      "resetting env. episode reward total was -16.0. running mean: -13.08689689448537\n",
      "resetting env. episode reward total was -17.0. running mean: -13.126027925540516\n",
      "resetting env. episode reward total was -16.0. running mean: -13.15476764628511\n",
      "resetting env. episode reward total was -16.0. running mean: -13.18321996982226\n",
      "resetting env. episode reward total was -19.0. running mean: -13.241387770124035\n",
      "resetting env. episode reward total was -6.0. running mean: -13.168973892422795\n",
      "resetting env. episode reward total was -12.0. running mean: -13.157284153498566\n",
      "resetting env. episode reward total was -12.0. running mean: -13.145711311963579\n",
      "resetting env. episode reward total was -16.0. running mean: -13.174254198843943\n",
      "resetting env. episode reward total was -17.0. running mean: -13.212511656855504\n",
      "resetting env. episode reward total was -15.0. running mean: -13.230386540286949\n",
      "resetting env. episode reward total was -15.0. running mean: -13.24808267488408\n",
      "resetting env. episode reward total was -15.0. running mean: -13.265601848135239\n",
      "resetting env. episode reward total was -17.0. running mean: -13.302945829653886\n",
      "resetting env. episode reward total was -14.0. running mean: -13.309916371357348\n",
      "resetting env. episode reward total was -16.0. running mean: -13.336817207643774\n",
      "resetting env. episode reward total was -13.0. running mean: -13.333449035567337\n",
      "resetting env. episode reward total was -17.0. running mean: -13.370114545211663\n",
      "resetting env. episode reward total was -11.0. running mean: -13.346413399759546\n",
      "resetting env. episode reward total was -15.0. running mean: -13.362949265761952\n",
      "resetting env. episode reward total was -9.0. running mean: -13.319319773104331\n",
      "resetting env. episode reward total was -15.0. running mean: -13.336126575373289\n",
      "resetting env. episode reward total was -13.0. running mean: -13.332765309619557\n",
      "resetting env. episode reward total was -14.0. running mean: -13.339437656523362\n",
      "resetting env. episode reward total was -16.0. running mean: -13.366043279958129\n",
      "resetting env. episode reward total was -11.0. running mean: -13.342382847158547\n",
      "resetting env. episode reward total was -11.0. running mean: -13.31895901868696\n",
      "resetting env. episode reward total was -13.0. running mean: -13.315769428500092\n",
      "resetting env. episode reward total was -18.0. running mean: -13.36261173421509\n",
      "resetting env. episode reward total was -21.0. running mean: -13.43898561687294\n",
      "resetting env. episode reward total was -16.0. running mean: -13.46459576070421\n",
      "resetting env. episode reward total was -15.0. running mean: -13.479949803097169\n",
      "resetting env. episode reward total was -18.0. running mean: -13.525150305066196\n",
      "resetting env. episode reward total was -18.0. running mean: -13.569898802015533\n",
      "resetting env. episode reward total was -15.0. running mean: -13.584199813995378\n",
      "resetting env. episode reward total was -18.0. running mean: -13.628357815855423\n",
      "resetting env. episode reward total was -9.0. running mean: -13.582074237696869\n",
      "resetting env. episode reward total was -13.0. running mean: -13.5762534953199\n",
      "resetting env. episode reward total was -16.0. running mean: -13.6004909603667\n",
      "resetting env. episode reward total was -14.0. running mean: -13.604486050763034\n",
      "resetting env. episode reward total was -13.0. running mean: -13.598441190255405\n",
      "resetting env. episode reward total was -13.0. running mean: -13.592456778352853\n",
      "resetting env. episode reward total was -16.0. running mean: -13.616532210569325\n",
      "resetting env. episode reward total was -14.0. running mean: -13.620366888463632\n",
      "resetting env. episode reward total was -19.0. running mean: -13.674163219578995\n",
      "resetting env. episode reward total was -21.0. running mean: -13.747421587383206\n",
      "resetting env. episode reward total was -11.0. running mean: -13.719947371509374\n",
      "resetting env. episode reward total was -16.0. running mean: -13.74274789779428\n",
      "resetting env. episode reward total was -11.0. running mean: -13.715320418816336\n",
      "resetting env. episode reward total was -14.0. running mean: -13.718167214628174\n",
      "resetting env. episode reward total was -18.0. running mean: -13.760985542481892\n",
      "resetting env. episode reward total was -9.0. running mean: -13.713375687057074\n",
      "resetting env. episode reward total was -17.0. running mean: -13.746241930186503\n",
      "resetting env. episode reward total was -19.0. running mean: -13.798779510884637\n",
      "resetting env. episode reward total was -11.0. running mean: -13.77079171577579\n",
      "resetting env. episode reward total was -19.0. running mean: -13.82308379861803\n",
      "resetting env. episode reward total was -16.0. running mean: -13.844852960631851\n",
      "resetting env. episode reward total was -19.0. running mean: -13.896404431025532\n",
      "resetting env. episode reward total was -14.0. running mean: -13.897440386715278\n",
      "resetting env. episode reward total was -11.0. running mean: -13.868465982848125\n",
      "resetting env. episode reward total was -18.0. running mean: -13.909781323019644\n",
      "resetting env. episode reward total was -15.0. running mean: -13.920683509789447\n",
      "resetting env. episode reward total was -17.0. running mean: -13.951476674691552\n",
      "resetting env. episode reward total was -16.0. running mean: -13.971961907944637\n",
      "resetting env. episode reward total was -12.0. running mean: -13.95224228886519\n",
      "resetting env. episode reward total was -17.0. running mean: -13.982719865976538\n",
      "resetting env. episode reward total was -13.0. running mean: -13.972892667316772\n",
      "resetting env. episode reward total was -13.0. running mean: -13.963163740643605\n",
      "resetting env. episode reward total was -18.0. running mean: -14.003532103237168\n",
      "resetting env. episode reward total was -16.0. running mean: -14.023496782204797\n",
      "resetting env. episode reward total was -16.0. running mean: -14.043261814382749\n",
      "resetting env. episode reward total was -15.0. running mean: -14.052829196238921\n",
      "resetting env. episode reward total was -13.0. running mean: -14.042300904276532\n",
      "resetting env. episode reward total was -13.0. running mean: -14.031877895233768\n",
      "resetting env. episode reward total was -12.0. running mean: -14.011559116281429\n",
      "resetting env. episode reward total was -17.0. running mean: -14.041443525118614\n",
      "resetting env. episode reward total was -17.0. running mean: -14.071029089867428\n",
      "resetting env. episode reward total was -15.0. running mean: -14.080318798968754\n",
      "resetting env. episode reward total was -15.0. running mean: -14.089515610979067\n",
      "resetting env. episode reward total was -14.0. running mean: -14.088620454869277\n",
      "resetting env. episode reward total was -17.0. running mean: -14.117734250320584\n",
      "resetting env. episode reward total was -11.0. running mean: -14.086556907817378\n",
      "resetting env. episode reward total was -14.0. running mean: -14.085691338739204\n",
      "resetting env. episode reward total was -15.0. running mean: -14.094834425351813\n",
      "resetting env. episode reward total was -15.0. running mean: -14.103886081098295\n",
      "resetting env. episode reward total was -11.0. running mean: -14.072847220287311\n",
      "resetting env. episode reward total was -15.0. running mean: -14.082118748084438\n",
      "resetting env. episode reward total was -14.0. running mean: -14.081297560603595\n",
      "resetting env. episode reward total was -19.0. running mean: -14.130484584997559\n",
      "resetting env. episode reward total was -9.0. running mean: -14.079179739147582\n",
      "resetting env. episode reward total was -13.0. running mean: -14.068387941756107\n",
      "resetting env. episode reward total was -11.0. running mean: -14.037704062338545\n",
      "resetting env. episode reward total was -15.0. running mean: -14.047327021715159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -21.0. running mean: -14.116853751498008\n",
      "resetting env. episode reward total was -15.0. running mean: -14.125685213983028\n",
      "resetting env. episode reward total was -17.0. running mean: -14.154428361843197\n",
      "resetting env. episode reward total was -17.0. running mean: -14.182884078224765\n",
      "resetting env. episode reward total was -15.0. running mean: -14.191055237442518\n",
      "resetting env. episode reward total was -19.0. running mean: -14.239144685068092\n",
      "resetting env. episode reward total was -13.0. running mean: -14.226753238217412\n",
      "resetting env. episode reward total was -17.0. running mean: -14.254485705835238\n",
      "resetting env. episode reward total was -9.0. running mean: -14.201940848776886\n",
      "resetting env. episode reward total was -14.0. running mean: -14.199921440289117\n",
      "resetting env. episode reward total was -11.0. running mean: -14.167922225886224\n",
      "resetting env. episode reward total was -15.0. running mean: -14.176243003627363\n",
      "resetting env. episode reward total was -12.0. running mean: -14.154480573591089\n",
      "resetting env. episode reward total was -13.0. running mean: -14.142935767855178\n",
      "resetting env. episode reward total was -14.0. running mean: -14.141506410176627\n",
      "resetting env. episode reward total was -15.0. running mean: -14.150091346074861\n",
      "resetting env. episode reward total was -11.0. running mean: -14.118590432614111\n",
      "resetting env. episode reward total was -15.0. running mean: -14.12740452828797\n",
      "resetting env. episode reward total was -11.0. running mean: -14.096130483005089\n",
      "resetting env. episode reward total was -18.0. running mean: -14.135169178175037\n",
      "resetting env. episode reward total was -13.0. running mean: -14.123817486393287\n",
      "resetting env. episode reward total was -16.0. running mean: -14.142579311529355\n",
      "resetting env. episode reward total was -17.0. running mean: -14.17115351841406\n",
      "resetting env. episode reward total was -13.0. running mean: -14.15944198322992\n",
      "resetting env. episode reward total was -7.0. running mean: -14.08784756339762\n",
      "resetting env. episode reward total was -8.0. running mean: -14.026969087763645\n",
      "resetting env. episode reward total was -13.0. running mean: -14.01669939688601\n",
      "resetting env. episode reward total was -17.0. running mean: -14.04653240291715\n",
      "resetting env. episode reward total was -8.0. running mean: -13.986067078887977\n",
      "resetting env. episode reward total was -19.0. running mean: -14.036206408099098\n",
      "resetting env. episode reward total was -6.0. running mean: -13.955844344018107\n",
      "resetting env. episode reward total was -11.0. running mean: -13.926285900577925\n",
      "resetting env. episode reward total was -13.0. running mean: -13.917023041572147\n",
      "resetting env. episode reward total was -13.0. running mean: -13.907852811156426\n",
      "resetting env. episode reward total was -11.0. running mean: -13.87877428304486\n",
      "resetting env. episode reward total was -15.0. running mean: -13.889986540214412\n",
      "resetting env. episode reward total was -7.0. running mean: -13.821086674812268\n",
      "resetting env. episode reward total was -14.0. running mean: -13.822875808064145\n",
      "resetting env. episode reward total was -13.0. running mean: -13.814647049983504\n",
      "resetting env. episode reward total was -12.0. running mean: -13.796500579483668\n",
      "resetting env. episode reward total was -13.0. running mean: -13.788535573688833\n",
      "resetting env. episode reward total was -14.0. running mean: -13.790650217951946\n",
      "resetting env. episode reward total was -14.0. running mean: -13.792743715772426\n",
      "resetting env. episode reward total was -15.0. running mean: -13.804816278614702\n",
      "resetting env. episode reward total was -15.0. running mean: -13.816768115828555\n",
      "resetting env. episode reward total was -15.0. running mean: -13.82860043467027\n",
      "resetting env. episode reward total was -19.0. running mean: -13.880314430323565\n",
      "resetting env. episode reward total was -11.0. running mean: -13.85151128602033\n",
      "resetting env. episode reward total was -7.0. running mean: -13.782996173160127\n",
      "resetting env. episode reward total was -11.0. running mean: -13.755166211428525\n",
      "resetting env. episode reward total was -19.0. running mean: -13.80761454931424\n",
      "resetting env. episode reward total was -16.0. running mean: -13.829538403821097\n",
      "resetting env. episode reward total was -17.0. running mean: -13.861243019782886\n",
      "resetting env. episode reward total was -13.0. running mean: -13.852630589585058\n",
      "resetting env. episode reward total was -14.0. running mean: -13.854104283689207\n",
      "resetting env. episode reward total was -15.0. running mean: -13.865563240852316\n",
      "resetting env. episode reward total was -11.0. running mean: -13.836907608443791\n",
      "resetting env. episode reward total was -2.0. running mean: -13.718538532359354\n",
      "resetting env. episode reward total was -10.0. running mean: -13.68135314703576\n",
      "resetting env. episode reward total was -13.0. running mean: -13.674539615565402\n",
      "resetting env. episode reward total was -10.0. running mean: -13.637794219409749\n",
      "resetting env. episode reward total was -15.0. running mean: -13.65141627721565\n",
      "resetting env. episode reward total was -19.0. running mean: -13.704902114443493\n",
      "resetting env. episode reward total was -14.0. running mean: -13.70785309329906\n",
      "resetting env. episode reward total was -7.0. running mean: -13.640774562366069\n",
      "resetting env. episode reward total was -11.0. running mean: -13.614366816742407\n",
      "resetting env. episode reward total was -11.0. running mean: -13.588223148574983\n",
      "resetting env. episode reward total was -10.0. running mean: -13.552340917089232\n",
      "resetting env. episode reward total was -17.0. running mean: -13.58681750791834\n",
      "resetting env. episode reward total was -11.0. running mean: -13.560949332839156\n",
      "resetting env. episode reward total was -17.0. running mean: -13.595339839510764\n",
      "resetting env. episode reward total was -9.0. running mean: -13.549386441115656\n",
      "resetting env. episode reward total was -15.0. running mean: -13.5638925767045\n",
      "resetting env. episode reward total was -14.0. running mean: -13.568253650937455\n",
      "resetting env. episode reward total was -11.0. running mean: -13.54257111442808\n",
      "resetting env. episode reward total was -19.0. running mean: -13.597145403283799\n",
      "resetting env. episode reward total was -19.0. running mean: -13.65117394925096\n",
      "resetting env. episode reward total was -14.0. running mean: -13.65466220975845\n",
      "resetting env. episode reward total was -20.0. running mean: -13.718115587660865\n",
      "resetting env. episode reward total was -13.0. running mean: -13.710934431784256\n",
      "resetting env. episode reward total was -15.0. running mean: -13.723825087466414\n",
      "resetting env. episode reward total was -11.0. running mean: -13.696586836591749\n",
      "resetting env. episode reward total was -16.0. running mean: -13.719620968225831\n",
      "resetting env. episode reward total was -7.0. running mean: -13.652424758543573\n",
      "resetting env. episode reward total was -15.0. running mean: -13.665900510958137\n",
      "resetting env. episode reward total was -11.0. running mean: -13.639241505848554\n",
      "resetting env. episode reward total was -4.0. running mean: -13.542849090790067\n",
      "resetting env. episode reward total was -9.0. running mean: -13.497420599882167\n",
      "resetting env. episode reward total was -9.0. running mean: -13.452446393883346\n",
      "resetting env. episode reward total was -16.0. running mean: -13.477921929944513\n",
      "resetting env. episode reward total was -11.0. running mean: -13.453142710645068\n",
      "resetting env. episode reward total was -13.0. running mean: -13.448611283538618\n",
      "resetting env. episode reward total was -5.0. running mean: -13.364125170703232\n",
      "resetting env. episode reward total was -9.0. running mean: -13.3204839189962\n",
      "resetting env. episode reward total was -17.0. running mean: -13.357279079806236\n",
      "resetting env. episode reward total was -10.0. running mean: -13.323706289008173\n",
      "resetting env. episode reward total was -11.0. running mean: -13.300469226118091\n",
      "resetting env. episode reward total was -15.0. running mean: -13.31746453385691\n",
      "resetting env. episode reward total was -15.0. running mean: -13.334289888518342\n",
      "resetting env. episode reward total was -16.0. running mean: -13.360946989633158\n",
      "resetting env. episode reward total was -10.0. running mean: -13.327337519736826\n",
      "resetting env. episode reward total was -15.0. running mean: -13.344064144539457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -12.0. running mean: -13.330623503094062\n",
      "resetting env. episode reward total was -11.0. running mean: -13.30731726806312\n",
      "resetting env. episode reward total was -7.0. running mean: -13.244244095382488\n",
      "resetting env. episode reward total was -12.0. running mean: -13.231801654428661\n",
      "resetting env. episode reward total was -8.0. running mean: -13.179483637884374\n",
      "resetting env. episode reward total was -6.0. running mean: -13.10768880150553\n",
      "resetting env. episode reward total was -11.0. running mean: -13.086611913490474\n",
      "resetting env. episode reward total was -13.0. running mean: -13.085745794355569\n",
      "resetting env. episode reward total was -6.0. running mean: -13.014888336412014\n",
      "resetting env. episode reward total was -10.0. running mean: -12.984739453047894\n",
      "resetting env. episode reward total was -19.0. running mean: -13.044892058517414\n",
      "resetting env. episode reward total was -9.0. running mean: -13.00444313793224\n",
      "resetting env. episode reward total was -5.0. running mean: -12.924398706552918\n",
      "resetting env. episode reward total was -15.0. running mean: -12.94515471948739\n",
      "resetting env. episode reward total was -10.0. running mean: -12.915703172292515\n",
      "resetting env. episode reward total was -13.0. running mean: -12.91654614056959\n",
      "resetting env. episode reward total was -15.0. running mean: -12.937380679163894\n",
      "resetting env. episode reward total was -15.0. running mean: -12.958006872372255\n",
      "resetting env. episode reward total was -12.0. running mean: -12.948426803648532\n",
      "resetting env. episode reward total was -11.0. running mean: -12.928942535612046\n",
      "resetting env. episode reward total was -14.0. running mean: -12.939653110255927\n",
      "resetting env. episode reward total was -16.0. running mean: -12.970256579153368\n",
      "resetting env. episode reward total was -14.0. running mean: -12.980554013361834\n",
      "resetting env. episode reward total was -19.0. running mean: -13.040748473228215\n",
      "resetting env. episode reward total was -8.0. running mean: -12.990340988495932\n",
      "resetting env. episode reward total was -13.0. running mean: -12.990437578610972\n",
      "resetting env. episode reward total was -15.0. running mean: -13.010533202824863\n",
      "resetting env. episode reward total was -16.0. running mean: -13.040427870796615\n",
      "resetting env. episode reward total was -9.0. running mean: -13.000023592088649\n",
      "resetting env. episode reward total was -9.0. running mean: -12.960023356167762\n",
      "resetting env. episode reward total was -15.0. running mean: -12.980423122606084\n",
      "resetting env. episode reward total was -8.0. running mean: -12.930618891380023\n",
      "resetting env. episode reward total was -14.0. running mean: -12.941312702466224\n",
      "resetting env. episode reward total was -15.0. running mean: -12.961899575441562\n",
      "resetting env. episode reward total was -13.0. running mean: -12.962280579687146\n",
      "resetting env. episode reward total was -17.0. running mean: -13.002657773890274\n",
      "resetting env. episode reward total was -16.0. running mean: -13.032631196151371\n",
      "resetting env. episode reward total was -15.0. running mean: -13.052304884189857\n",
      "resetting env. episode reward total was -2.0. running mean: -12.941781835347959\n",
      "resetting env. episode reward total was -13.0. running mean: -12.94236401699448\n",
      "resetting env. episode reward total was -6.0. running mean: -12.872940376824536\n",
      "resetting env. episode reward total was -15.0. running mean: -12.89421097305629\n",
      "resetting env. episode reward total was -8.0. running mean: -12.845268863325728\n",
      "resetting env. episode reward total was -16.0. running mean: -12.87681617469247\n",
      "resetting env. episode reward total was -13.0. running mean: -12.878048012945547\n",
      "resetting env. episode reward total was -10.0. running mean: -12.849267532816091\n",
      "resetting env. episode reward total was -17.0. running mean: -12.89077485748793\n",
      "resetting env. episode reward total was -14.0. running mean: -12.90186710891305\n",
      "resetting env. episode reward total was -15.0. running mean: -12.92284843782392\n",
      "resetting env. episode reward total was -3.0. running mean: -12.823619953445679\n",
      "resetting env. episode reward total was -14.0. running mean: -12.835383753911222\n",
      "resetting env. episode reward total was -15.0. running mean: -12.85702991637211\n",
      "resetting env. episode reward total was -8.0. running mean: -12.808459617208388\n",
      "resetting env. episode reward total was -10.0. running mean: -12.780375021036305\n",
      "resetting env. episode reward total was -13.0. running mean: -12.782571270825942\n",
      "resetting env. episode reward total was -6.0. running mean: -12.714745558117682\n",
      "resetting env. episode reward total was -9.0. running mean: -12.677598102536505\n",
      "resetting env. episode reward total was -9.0. running mean: -12.64082212151114\n",
      "resetting env. episode reward total was -16.0. running mean: -12.67441390029603\n",
      "resetting env. episode reward total was -14.0. running mean: -12.68766976129307\n",
      "resetting env. episode reward total was -13.0. running mean: -12.69079306368014\n",
      "resetting env. episode reward total was -15.0. running mean: -12.713885133043338\n",
      "resetting env. episode reward total was -9.0. running mean: -12.676746281712903\n",
      "resetting env. episode reward total was -17.0. running mean: -12.719978818895774\n",
      "resetting env. episode reward total was -17.0. running mean: -12.762779030706815\n",
      "resetting env. episode reward total was -17.0. running mean: -12.805151240399747\n",
      "resetting env. episode reward total was -12.0. running mean: -12.797099727995748\n",
      "resetting env. episode reward total was -11.0. running mean: -12.77912873071579\n",
      "resetting env. episode reward total was -13.0. running mean: -12.781337443408633\n",
      "resetting env. episode reward total was -7.0. running mean: -12.723524068974546\n",
      "resetting env. episode reward total was -8.0. running mean: -12.6762888282848\n",
      "resetting env. episode reward total was -13.0. running mean: -12.679525940001954\n",
      "resetting env. episode reward total was -1.0. running mean: -12.562730680601934\n",
      "resetting env. episode reward total was -11.0. running mean: -12.547103373795913\n",
      "resetting env. episode reward total was -13.0. running mean: -12.551632340057955\n",
      "resetting env. episode reward total was -10.0. running mean: -12.526116016657374\n",
      "resetting env. episode reward total was -15.0. running mean: -12.550854856490801\n",
      "resetting env. episode reward total was -10.0. running mean: -12.525346307925892\n",
      "resetting env. episode reward total was -12.0. running mean: -12.520092844846632\n",
      "resetting env. episode reward total was -12.0. running mean: -12.514891916398165\n",
      "resetting env. episode reward total was -15.0. running mean: -12.539742997234184\n",
      "resetting env. episode reward total was -10.0. running mean: -12.514345567261842\n",
      "resetting env. episode reward total was -10.0. running mean: -12.489202111589222\n",
      "resetting env. episode reward total was -15.0. running mean: -12.51431009047333\n",
      "resetting env. episode reward total was -14.0. running mean: -12.529166989568598\n",
      "resetting env. episode reward total was -15.0. running mean: -12.553875319672912\n",
      "resetting env. episode reward total was -5.0. running mean: -12.478336566476184\n",
      "resetting env. episode reward total was -5.0. running mean: -12.403553200811423\n",
      "resetting env. episode reward total was -11.0. running mean: -12.389517668803308\n",
      "resetting env. episode reward total was -9.0. running mean: -12.355622492115273\n",
      "resetting env. episode reward total was -7.0. running mean: -12.302066267194121\n",
      "resetting env. episode reward total was -9.0. running mean: -12.26904560452218\n",
      "resetting env. episode reward total was -7.0. running mean: -12.216355148476959\n",
      "resetting env. episode reward total was -16.0. running mean: -12.25419159699219\n",
      "resetting env. episode reward total was -2.0. running mean: -12.151649681022267\n",
      "resetting env. episode reward total was -14.0. running mean: -12.170133184212045\n",
      "resetting env. episode reward total was -13.0. running mean: -12.178431852369926\n",
      "resetting env. episode reward total was -15.0. running mean: -12.206647533846226\n",
      "resetting env. episode reward total was -13.0. running mean: -12.214581058507765\n",
      "resetting env. episode reward total was -15.0. running mean: -12.242435247922687\n",
      "resetting env. episode reward total was -15.0. running mean: -12.27001089544346\n",
      "resetting env. episode reward total was -2.0. running mean: -12.167310786489026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -10.0. running mean: -12.145637678624135\n",
      "resetting env. episode reward total was -15.0. running mean: -12.174181301837894\n",
      "resetting env. episode reward total was -9.0. running mean: -12.142439488819514\n",
      "resetting env. episode reward total was -19.0. running mean: -12.211015093931318\n",
      "resetting env. episode reward total was -11.0. running mean: -12.198904942992003\n",
      "resetting env. episode reward total was -6.0. running mean: -12.136915893562083\n",
      "resetting env. episode reward total was 1.0. running mean: -12.005546734626462\n",
      "resetting env. episode reward total was -14.0. running mean: -12.025491267280197\n",
      "resetting env. episode reward total was -17.0. running mean: -12.075236354607394\n",
      "resetting env. episode reward total was -5.0. running mean: -12.00448399106132\n",
      "resetting env. episode reward total was -17.0. running mean: -12.054439151150707\n",
      "resetting env. episode reward total was -4.0. running mean: -11.9738947596392\n",
      "resetting env. episode reward total was -6.0. running mean: -11.914155812042807\n",
      "resetting env. episode reward total was -13.0. running mean: -11.92501425392238\n",
      "resetting env. episode reward total was -16.0. running mean: -11.965764111383155\n",
      "resetting env. episode reward total was -7.0. running mean: -11.916106470269323\n",
      "resetting env. episode reward total was -11.0. running mean: -11.90694540556663\n",
      "resetting env. episode reward total was -14.0. running mean: -11.927875951510964\n",
      "resetting env. episode reward total was -16.0. running mean: -11.968597191995855\n",
      "resetting env. episode reward total was -12.0. running mean: -11.968911220075896\n",
      "resetting env. episode reward total was -15.0. running mean: -11.999222107875138\n",
      "resetting env. episode reward total was -12.0. running mean: -11.999229886796385\n",
      "resetting env. episode reward total was -13.0. running mean: -12.009237587928423\n",
      "resetting env. episode reward total was -12.0. running mean: -12.009145212049138\n",
      "resetting env. episode reward total was -16.0. running mean: -12.049053759928647\n",
      "resetting env. episode reward total was -7.0. running mean: -11.998563222329361\n",
      "resetting env. episode reward total was -15.0. running mean: -12.028577590106067\n",
      "resetting env. episode reward total was -14.0. running mean: -12.048291814205006\n",
      "resetting env. episode reward total was -19.0. running mean: -12.117808896062956\n",
      "resetting env. episode reward total was -2.0. running mean: -12.016630807102326\n",
      "resetting env. episode reward total was -10.0. running mean: -11.996464499031301\n",
      "resetting env. episode reward total was -9.0. running mean: -11.966499854040988\n",
      "resetting env. episode reward total was -8.0. running mean: -11.926834855500578\n",
      "resetting env. episode reward total was -11.0. running mean: -11.917566506945573\n",
      "resetting env. episode reward total was -14.0. running mean: -11.938390841876117\n",
      "resetting env. episode reward total was -10.0. running mean: -11.919006933457355\n",
      "resetting env. episode reward total was -6.0. running mean: -11.859816864122783\n",
      "resetting env. episode reward total was -11.0. running mean: -11.851218695481554\n",
      "resetting env. episode reward total was -11.0. running mean: -11.842706508526739\n",
      "resetting env. episode reward total was -12.0. running mean: -11.84427944344147\n",
      "resetting env. episode reward total was -11.0. running mean: -11.835836649007055\n",
      "resetting env. episode reward total was -14.0. running mean: -11.857478282516984\n",
      "resetting env. episode reward total was -15.0. running mean: -11.888903499691814\n",
      "resetting env. episode reward total was -9.0. running mean: -11.860014464694896\n",
      "resetting env. episode reward total was -2.0. running mean: -11.761414320047946\n",
      "resetting env. episode reward total was -12.0. running mean: -11.763800176847466\n",
      "resetting env. episode reward total was -13.0. running mean: -11.776162175078992\n",
      "resetting env. episode reward total was -7.0. running mean: -11.728400553328203\n",
      "resetting env. episode reward total was -17.0. running mean: -11.781116547794921\n",
      "resetting env. episode reward total was -13.0. running mean: -11.793305382316973\n",
      "resetting env. episode reward total was -1.0. running mean: -11.685372328493802\n",
      "resetting env. episode reward total was -12.0. running mean: -11.688518605208863\n",
      "resetting env. episode reward total was -13.0. running mean: -11.701633419156774\n",
      "resetting env. episode reward total was -9.0. running mean: -11.674617084965206\n",
      "resetting env. episode reward total was -11.0. running mean: -11.667870914115554\n",
      "resetting env. episode reward total was -13.0. running mean: -11.6811922049744\n",
      "resetting env. episode reward total was -4.0. running mean: -11.604380282924655\n",
      "resetting env. episode reward total was -9.0. running mean: -11.578336480095409\n",
      "resetting env. episode reward total was -15.0. running mean: -11.612553115294455\n",
      "resetting env. episode reward total was -8.0. running mean: -11.576427584141511\n",
      "resetting env. episode reward total was -13.0. running mean: -11.590663308300096\n",
      "resetting env. episode reward total was -3.0. running mean: -11.504756675217093\n",
      "resetting env. episode reward total was -13.0. running mean: -11.519709108464923\n",
      "resetting env. episode reward total was -12.0. running mean: -11.524512017380273\n",
      "resetting env. episode reward total was -16.0. running mean: -11.56926689720647\n",
      "resetting env. episode reward total was 2.0. running mean: -11.433574228234406\n",
      "resetting env. episode reward total was -13.0. running mean: -11.449238485952062\n",
      "resetting env. episode reward total was 2.0. running mean: -11.314746101092542\n",
      "resetting env. episode reward total was -6.0. running mean: -11.261598640081617\n",
      "resetting env. episode reward total was -7.0. running mean: -11.2189826536808\n",
      "resetting env. episode reward total was -2.0. running mean: -11.126792827143992\n",
      "resetting env. episode reward total was -15.0. running mean: -11.165524898872553\n",
      "resetting env. episode reward total was -10.0. running mean: -11.153869649883827\n",
      "resetting env. episode reward total was -7.0. running mean: -11.112330953384989\n",
      "resetting env. episode reward total was -19.0. running mean: -11.191207643851138\n",
      "resetting env. episode reward total was -11.0. running mean: -11.189295567412627\n",
      "resetting env. episode reward total was -7.0. running mean: -11.147402611738501\n",
      "resetting env. episode reward total was -4.0. running mean: -11.075928585621115\n",
      "resetting env. episode reward total was 1.0. running mean: -10.955169299764904\n",
      "resetting env. episode reward total was -9.0. running mean: -10.935617606767256\n",
      "resetting env. episode reward total was -11.0. running mean: -10.936261430699583\n",
      "resetting env. episode reward total was -4.0. running mean: -10.866898816392586\n",
      "resetting env. episode reward total was -12.0. running mean: -10.87822982822866\n",
      "resetting env. episode reward total was -11.0. running mean: -10.879447529946372\n",
      "resetting env. episode reward total was -10.0. running mean: -10.870653054646908\n",
      "resetting env. episode reward total was -10.0. running mean: -10.86194652410044\n",
      "resetting env. episode reward total was -10.0. running mean: -10.853327058859435\n",
      "resetting env. episode reward total was -16.0. running mean: -10.90479378827084\n",
      "resetting env. episode reward total was -6.0. running mean: -10.855745850388132\n",
      "resetting env. episode reward total was -10.0. running mean: -10.84718839188425\n",
      "resetting env. episode reward total was -10.0. running mean: -10.838716507965408\n",
      "resetting env. episode reward total was -11.0. running mean: -10.840329342885754\n",
      "resetting env. episode reward total was -15.0. running mean: -10.881926049456897\n",
      "resetting env. episode reward total was -9.0. running mean: -10.863106788962329\n",
      "resetting env. episode reward total was -12.0. running mean: -10.874475721072704\n",
      "resetting env. episode reward total was -5.0. running mean: -10.815730963861977\n",
      "resetting env. episode reward total was -3.0. running mean: -10.737573654223358\n",
      "resetting env. episode reward total was -15.0. running mean: -10.780197917681123\n",
      "resetting env. episode reward total was -9.0. running mean: -10.762395938504312\n",
      "resetting env. episode reward total was -8.0. running mean: -10.73477197911927\n",
      "resetting env. episode reward total was -11.0. running mean: -10.737424259328076\n",
      "resetting env. episode reward total was -15.0. running mean: -10.780050016734796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -11.0. running mean: -10.782249516567447\n",
      "resetting env. episode reward total was -13.0. running mean: -10.804427021401773\n",
      "resetting env. episode reward total was -12.0. running mean: -10.816382751187755\n",
      "resetting env. episode reward total was -7.0. running mean: -10.778218923675878\n",
      "resetting env. episode reward total was -13.0. running mean: -10.80043673443912\n",
      "resetting env. episode reward total was -8.0. running mean: -10.77243236709473\n",
      "resetting env. episode reward total was -2.0. running mean: -10.684708043423782\n",
      "resetting env. episode reward total was -7.0. running mean: -10.647860962989546\n",
      "resetting env. episode reward total was -7.0. running mean: -10.61138235335965\n",
      "resetting env. episode reward total was -14.0. running mean: -10.645268529826053\n",
      "resetting env. episode reward total was -7.0. running mean: -10.608815844527793\n",
      "resetting env. episode reward total was -13.0. running mean: -10.632727686082516\n",
      "resetting env. episode reward total was -7.0. running mean: -10.59640040922169\n",
      "resetting env. episode reward total was -11.0. running mean: -10.600436405129473\n",
      "resetting env. episode reward total was -15.0. running mean: -10.64443204107818\n",
      "resetting env. episode reward total was -6.0. running mean: -10.597987720667398\n",
      "resetting env. episode reward total was -8.0. running mean: -10.572007843460723\n",
      "resetting env. episode reward total was -15.0. running mean: -10.616287765026115\n",
      "resetting env. episode reward total was -13.0. running mean: -10.640124887375855\n",
      "resetting env. episode reward total was -13.0. running mean: -10.663723638502097\n",
      "resetting env. episode reward total was -13.0. running mean: -10.687086402117076\n",
      "resetting env. episode reward total was -8.0. running mean: -10.660215538095905\n",
      "resetting env. episode reward total was -18.0. running mean: -10.733613382714946\n",
      "resetting env. episode reward total was -15.0. running mean: -10.776277248887796\n",
      "resetting env. episode reward total was -15.0. running mean: -10.818514476398919\n",
      "resetting env. episode reward total was -11.0. running mean: -10.820329331634928\n",
      "resetting env. episode reward total was -7.0. running mean: -10.78212603831858\n",
      "resetting env. episode reward total was -15.0. running mean: -10.824304777935394\n",
      "resetting env. episode reward total was -10.0. running mean: -10.81606173015604\n",
      "resetting env. episode reward total was -3.0. running mean: -10.737901112854479\n",
      "resetting env. episode reward total was -13.0. running mean: -10.760522101725934\n",
      "resetting env. episode reward total was -4.0. running mean: -10.692916880708674\n",
      "resetting env. episode reward total was -8.0. running mean: -10.665987711901588\n",
      "resetting env. episode reward total was -9.0. running mean: -10.649327834782572\n",
      "resetting env. episode reward total was -15.0. running mean: -10.692834556434747\n",
      "resetting env. episode reward total was -1.0. running mean: -10.5959062108704\n",
      "resetting env. episode reward total was -6.0. running mean: -10.549947148761696\n",
      "resetting env. episode reward total was -10.0. running mean: -10.544447677274079\n",
      "resetting env. episode reward total was -17.0. running mean: -10.609003200501338\n",
      "resetting env. episode reward total was -14.0. running mean: -10.642913168496325\n",
      "resetting env. episode reward total was -10.0. running mean: -10.63648403681136\n",
      "resetting env. episode reward total was -9.0. running mean: -10.620119196443246\n",
      "resetting env. episode reward total was -6.0. running mean: -10.573918004478815\n",
      "resetting env. episode reward total was -10.0. running mean: -10.568178824434026\n",
      "resetting env. episode reward total was -1.0. running mean: -10.472497036189687\n",
      "resetting env. episode reward total was -9.0. running mean: -10.45777206582779\n",
      "resetting env. episode reward total was -10.0. running mean: -10.45319434516951\n",
      "resetting env. episode reward total was -16.0. running mean: -10.508662401717816\n",
      "resetting env. episode reward total was -9.0. running mean: -10.493575777700638\n",
      "resetting env. episode reward total was -10.0. running mean: -10.488640019923631\n",
      "resetting env. episode reward total was -8.0. running mean: -10.463753619724395\n",
      "resetting env. episode reward total was -12.0. running mean: -10.47911608352715\n",
      "resetting env. episode reward total was -17.0. running mean: -10.54432492269188\n",
      "resetting env. episode reward total was -9.0. running mean: -10.52888167346496\n",
      "resetting env. episode reward total was -13.0. running mean: -10.553592856730312\n",
      "resetting env. episode reward total was -13.0. running mean: -10.57805692816301\n",
      "resetting env. episode reward total was 1.0. running mean: -10.462276358881379\n",
      "resetting env. episode reward total was -7.0. running mean: -10.427653595292565\n",
      "resetting env. episode reward total was -11.0. running mean: -10.433377059339639\n",
      "resetting env. episode reward total was -12.0. running mean: -10.449043288746243\n",
      "resetting env. episode reward total was -12.0. running mean: -10.464552855858779\n",
      "resetting env. episode reward total was -10.0. running mean: -10.45990732730019\n",
      "resetting env. episode reward total was -7.0. running mean: -10.425308254027188\n",
      "resetting env. episode reward total was -11.0. running mean: -10.431055171486916\n",
      "resetting env. episode reward total was -12.0. running mean: -10.446744619772046\n",
      "resetting env. episode reward total was -6.0. running mean: -10.402277173574326\n",
      "resetting env. episode reward total was -10.0. running mean: -10.398254401838583\n",
      "resetting env. episode reward total was -12.0. running mean: -10.414271857820196\n",
      "resetting env. episode reward total was -14.0. running mean: -10.450129139241994\n",
      "resetting env. episode reward total was -14.0. running mean: -10.485627847849575\n",
      "resetting env. episode reward total was -17.0. running mean: -10.55077156937108\n",
      "resetting env. episode reward total was -9.0. running mean: -10.535263853677368\n",
      "resetting env. episode reward total was -6.0. running mean: -10.489911215140594\n",
      "resetting env. episode reward total was -9.0. running mean: -10.475012102989188\n",
      "resetting env. episode reward total was -15.0. running mean: -10.520261981959298\n",
      "resetting env. episode reward total was -13.0. running mean: -10.545059362139705\n",
      "resetting env. episode reward total was -15.0. running mean: -10.589608768518309\n",
      "resetting env. episode reward total was -5.0. running mean: -10.533712680833126\n",
      "resetting env. episode reward total was -9.0. running mean: -10.518375554024795\n",
      "resetting env. episode reward total was -14.0. running mean: -10.553191798484548\n",
      "resetting env. episode reward total was -10.0. running mean: -10.547659880499701\n",
      "resetting env. episode reward total was -15.0. running mean: -10.592183281694703\n",
      "resetting env. episode reward total was -9.0. running mean: -10.576261448877757\n",
      "resetting env. episode reward total was -9.0. running mean: -10.560498834388978\n",
      "resetting env. episode reward total was -15.0. running mean: -10.604893846045089\n",
      "resetting env. episode reward total was -14.0. running mean: -10.63884490758464\n",
      "resetting env. episode reward total was -9.0. running mean: -10.622456458508793\n",
      "resetting env. episode reward total was -15.0. running mean: -10.666231893923706\n",
      "resetting env. episode reward total was -13.0. running mean: -10.68956957498447\n",
      "resetting env. episode reward total was -13.0. running mean: -10.712673879234625\n",
      "resetting env. episode reward total was -9.0. running mean: -10.69554714044228\n",
      "resetting env. episode reward total was -1.0. running mean: -10.598591669037857\n",
      "resetting env. episode reward total was -7.0. running mean: -10.562605752347478\n",
      "resetting env. episode reward total was -12.0. running mean: -10.576979694824002\n",
      "resetting env. episode reward total was -15.0. running mean: -10.621209897875763\n",
      "resetting env. episode reward total was -12.0. running mean: -10.634997798897006\n",
      "resetting env. episode reward total was -9.0. running mean: -10.618647820908036\n",
      "resetting env. episode reward total was -9.0. running mean: -10.602461342698955\n",
      "resetting env. episode reward total was -17.0. running mean: -10.666436729271966\n",
      "resetting env. episode reward total was -11.0. running mean: -10.669772361979247\n",
      "resetting env. episode reward total was -15.0. running mean: -10.713074638359455\n",
      "resetting env. episode reward total was -13.0. running mean: -10.735943891975861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: -10.668584453056102\n",
      "resetting env. episode reward total was -9.0. running mean: -10.65189860852554\n",
      "resetting env. episode reward total was -9.0. running mean: -10.635379622440285\n",
      "resetting env. episode reward total was -6.0. running mean: -10.589025826215883\n",
      "resetting env. episode reward total was -9.0. running mean: -10.573135567953724\n",
      "resetting env. episode reward total was -8.0. running mean: -10.547404212274186\n",
      "resetting env. episode reward total was -15.0. running mean: -10.591930170151445\n",
      "resetting env. episode reward total was -9.0. running mean: -10.576010868449929\n",
      "resetting env. episode reward total was -11.0. running mean: -10.580250759765429\n",
      "resetting env. episode reward total was -8.0. running mean: -10.554448252167774\n",
      "resetting env. episode reward total was -12.0. running mean: -10.568903769646095\n",
      "resetting env. episode reward total was -6.0. running mean: -10.523214731949635\n",
      "resetting env. episode reward total was -8.0. running mean: -10.497982584630138\n",
      "resetting env. episode reward total was -7.0. running mean: -10.463002758783837\n",
      "resetting env. episode reward total was -11.0. running mean: -10.468372731195998\n",
      "resetting env. episode reward total was -7.0. running mean: -10.433689003884039\n",
      "resetting env. episode reward total was -1.0. running mean: -10.339352113845198\n",
      "resetting env. episode reward total was -10.0. running mean: -10.335958592706746\n",
      "resetting env. episode reward total was -13.0. running mean: -10.362599006779678\n",
      "resetting env. episode reward total was -9.0. running mean: -10.34897301671188\n",
      "resetting env. episode reward total was -3.0. running mean: -10.27548328654476\n",
      "resetting env. episode reward total was -10.0. running mean: -10.272728453679314\n",
      "resetting env. episode reward total was -16.0. running mean: -10.33000116914252\n",
      "resetting env. episode reward total was -9.0. running mean: -10.316701157451094\n",
      "resetting env. episode reward total was -7.0. running mean: -10.283534145876583\n",
      "resetting env. episode reward total was -9.0. running mean: -10.270698804417817\n",
      "resetting env. episode reward total was -9.0. running mean: -10.25799181637364\n",
      "resetting env. episode reward total was -12.0. running mean: -10.275411898209903\n",
      "resetting env. episode reward total was -13.0. running mean: -10.302657779227804\n",
      "resetting env. episode reward total was -11.0. running mean: -10.309631201435526\n",
      "resetting env. episode reward total was -8.0. running mean: -10.286534889421171\n",
      "resetting env. episode reward total was -9.0. running mean: -10.273669540526958\n",
      "resetting env. episode reward total was -6.0. running mean: -10.23093284512169\n",
      "resetting env. episode reward total was -12.0. running mean: -10.248623516670472\n",
      "resetting env. episode reward total was -13.0. running mean: -10.276137281503768\n",
      "resetting env. episode reward total was -16.0. running mean: -10.33337590868873\n",
      "resetting env. episode reward total was -11.0. running mean: -10.340042149601842\n",
      "resetting env. episode reward total was -17.0. running mean: -10.406641728105823\n",
      "resetting env. episode reward total was -16.0. running mean: -10.462575310824764\n",
      "resetting env. episode reward total was -13.0. running mean: -10.487949557716517\n",
      "resetting env. episode reward total was -17.0. running mean: -10.553070062139351\n",
      "resetting env. episode reward total was -12.0. running mean: -10.567539361517957\n",
      "resetting env. episode reward total was -16.0. running mean: -10.621863967902778\n",
      "resetting env. episode reward total was -15.0. running mean: -10.66564532822375\n",
      "resetting env. episode reward total was -9.0. running mean: -10.648988874941512\n",
      "resetting env. episode reward total was -15.0. running mean: -10.692498986192097\n",
      "resetting env. episode reward total was -12.0. running mean: -10.705573996330175\n",
      "resetting env. episode reward total was -9.0. running mean: -10.688518256366873\n",
      "resetting env. episode reward total was -9.0. running mean: -10.671633073803203\n",
      "resetting env. episode reward total was -9.0. running mean: -10.65491674306517\n",
      "resetting env. episode reward total was -15.0. running mean: -10.698367575634519\n",
      "resetting env. episode reward total was -11.0. running mean: -10.701383899878174\n",
      "resetting env. episode reward total was -10.0. running mean: -10.694370060879391\n",
      "resetting env. episode reward total was -13.0. running mean: -10.717426360270599\n",
      "resetting env. episode reward total was -11.0. running mean: -10.720252096667892\n",
      "resetting env. episode reward total was -7.0. running mean: -10.683049575701213\n",
      "resetting env. episode reward total was -1.0. running mean: -10.5862190799442\n",
      "resetting env. episode reward total was -14.0. running mean: -10.620356889144759\n",
      "resetting env. episode reward total was -7.0. running mean: -10.58415332025331\n",
      "resetting env. episode reward total was -1.0. running mean: -10.488311787050778\n",
      "resetting env. episode reward total was -12.0. running mean: -10.50342866918027\n",
      "resetting env. episode reward total was -10.0. running mean: -10.498394382488467\n",
      "resetting env. episode reward total was -7.0. running mean: -10.463410438663582\n",
      "resetting env. episode reward total was -8.0. running mean: -10.438776334276946\n",
      "resetting env. episode reward total was -7.0. running mean: -10.404388570934177\n",
      "resetting env. episode reward total was -6.0. running mean: -10.360344685224836\n",
      "resetting env. episode reward total was -12.0. running mean: -10.376741238372587\n",
      "resetting env. episode reward total was -11.0. running mean: -10.38297382598886\n",
      "resetting env. episode reward total was 1.0. running mean: -10.269144087728971\n",
      "resetting env. episode reward total was -7.0. running mean: -10.236452646851681\n",
      "resetting env. episode reward total was 1.0. running mean: -10.124088120383165\n",
      "resetting env. episode reward total was -13.0. running mean: -10.152847239179334\n",
      "resetting env. episode reward total was -13.0. running mean: -10.181318766787541\n",
      "resetting env. episode reward total was -8.0. running mean: -10.159505579119665\n",
      "resetting env. episode reward total was -8.0. running mean: -10.137910523328468\n",
      "resetting env. episode reward total was -6.0. running mean: -10.096531418095184\n",
      "resetting env. episode reward total was -9.0. running mean: -10.085566103914232\n",
      "resetting env. episode reward total was -1.0. running mean: -9.994710442875089\n",
      "resetting env. episode reward total was -10.0. running mean: -9.994763338446338\n",
      "resetting env. episode reward total was -9.0. running mean: -9.984815705061875\n",
      "resetting env. episode reward total was -15.0. running mean: -10.034967548011256\n",
      "resetting env. episode reward total was -13.0. running mean: -10.064617872531144\n",
      "resetting env. episode reward total was -10.0. running mean: -10.063971693805833\n",
      "resetting env. episode reward total was -9.0. running mean: -10.053331976867774\n",
      "resetting env. episode reward total was -12.0. running mean: -10.072798657099096\n",
      "resetting env. episode reward total was -15.0. running mean: -10.122070670528105\n",
      "resetting env. episode reward total was -6.0. running mean: -10.080849963822825\n",
      "resetting env. episode reward total was -8.0. running mean: -10.060041464184597\n",
      "resetting env. episode reward total was -1.0. running mean: -9.96944104954275\n",
      "resetting env. episode reward total was -11.0. running mean: -9.979746639047322\n",
      "resetting env. episode reward total was -5.0. running mean: -9.92994917265685\n",
      "resetting env. episode reward total was -9.0. running mean: -9.92064968093028\n",
      "resetting env. episode reward total was -2.0. running mean: -9.841443184120976\n",
      "resetting env. episode reward total was -10.0. running mean: -9.843028752279766\n",
      "resetting env. episode reward total was -11.0. running mean: -9.854598464756968\n",
      "resetting env. episode reward total was -9.0. running mean: -9.846052480109398\n",
      "resetting env. episode reward total was -10.0. running mean: -9.847591955308303\n",
      "resetting env. episode reward total was -9.0. running mean: -9.83911603575522\n",
      "resetting env. episode reward total was -6.0. running mean: -9.800724875397668\n",
      "resetting env. episode reward total was -10.0. running mean: -9.802717626643691\n",
      "resetting env. episode reward total was -6.0. running mean: -9.764690450377255\n",
      "resetting env. episode reward total was -8.0. running mean: -9.747043545873483\n",
      "resetting env. episode reward total was -12.0. running mean: -9.769573110414747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: -9.6418773793106\n",
      "resetting env. episode reward total was -11.0. running mean: -9.655458605517493\n",
      "resetting env. episode reward total was -13.0. running mean: -9.688904019462319\n",
      "resetting env. episode reward total was -8.0. running mean: -9.672014979267695\n",
      "resetting env. episode reward total was -11.0. running mean: -9.685294829475017\n",
      "resetting env. episode reward total was -5.0. running mean: -9.638441881180269\n",
      "resetting env. episode reward total was -4.0. running mean: -9.582057462368464\n",
      "resetting env. episode reward total was 1.0. running mean: -9.47623688774478\n",
      "resetting env. episode reward total was -6.0. running mean: -9.441474518867333\n",
      "resetting env. episode reward total was -12.0. running mean: -9.467059773678658\n",
      "resetting env. episode reward total was -9.0. running mean: -9.46238917594187\n",
      "resetting env. episode reward total was -1.0. running mean: -9.377765284182452\n",
      "resetting env. episode reward total was -7.0. running mean: -9.353987631340628\n",
      "resetting env. episode reward total was -16.0. running mean: -9.420447755027222\n",
      "resetting env. episode reward total was 1.0. running mean: -9.31624327747695\n",
      "resetting env. episode reward total was -12.0. running mean: -9.343080844702179\n",
      "resetting env. episode reward total was -7.0. running mean: -9.319650036255158\n",
      "resetting env. episode reward total was -3.0. running mean: -9.256453535892605\n",
      "resetting env. episode reward total was 1.0. running mean: -9.15388900053368\n",
      "resetting env. episode reward total was -11.0. running mean: -9.172350110528342\n",
      "resetting env. episode reward total was -13.0. running mean: -9.210626609423059\n",
      "resetting env. episode reward total was -14.0. running mean: -9.25852034332883\n",
      "resetting env. episode reward total was -8.0. running mean: -9.245935139895542\n",
      "resetting env. episode reward total was -7.0. running mean: -9.223475788496586\n",
      "resetting env. episode reward total was -7.0. running mean: -9.20124103061162\n",
      "resetting env. episode reward total was -8.0. running mean: -9.189228620305503\n",
      "resetting env. episode reward total was -11.0. running mean: -9.207336334102447\n",
      "resetting env. episode reward total was -5.0. running mean: -9.165262970761423\n",
      "resetting env. episode reward total was -15.0. running mean: -9.22361034105381\n",
      "resetting env. episode reward total was -10.0. running mean: -9.231374237643271\n",
      "resetting env. episode reward total was -5.0. running mean: -9.189060495266839\n",
      "resetting env. episode reward total was -8.0. running mean: -9.17716989031417\n",
      "resetting env. episode reward total was -15.0. running mean: -9.23539819141103\n",
      "resetting env. episode reward total was -11.0. running mean: -9.253044209496919\n",
      "resetting env. episode reward total was -9.0. running mean: -9.25051376740195\n",
      "resetting env. episode reward total was -14.0. running mean: -9.298008629727931\n",
      "resetting env. episode reward total was -6.0. running mean: -9.265028543430653\n",
      "resetting env. episode reward total was -7.0. running mean: -9.242378257996346\n",
      "resetting env. episode reward total was -6.0. running mean: -9.209954475416383\n",
      "resetting env. episode reward total was -5.0. running mean: -9.16785493066222\n",
      "resetting env. episode reward total was -8.0. running mean: -9.156176381355598\n",
      "resetting env. episode reward total was -5.0. running mean: -9.114614617542042\n",
      "resetting env. episode reward total was -11.0. running mean: -9.133468471366621\n",
      "resetting env. episode reward total was -10.0. running mean: -9.142133786652954\n",
      "resetting env. episode reward total was 2.0. running mean: -9.030712448786424\n",
      "resetting env. episode reward total was -8.0. running mean: -9.02040532429856\n",
      "resetting env. episode reward total was -9.0. running mean: -9.020201271055575\n",
      "resetting env. episode reward total was -6.0. running mean: -8.98999925834502\n",
      "resetting env. episode reward total was -9.0. running mean: -8.990099265761568\n",
      "resetting env. episode reward total was -14.0. running mean: -9.040198273103952\n",
      "resetting env. episode reward total was -10.0. running mean: -9.049796290372912\n",
      "resetting env. episode reward total was -7.0. running mean: -9.029298327469183\n",
      "resetting env. episode reward total was -13.0. running mean: -9.069005344194492\n",
      "resetting env. episode reward total was -5.0. running mean: -9.028315290752548\n",
      "resetting env. episode reward total was -17.0. running mean: -9.108032137845022\n",
      "resetting env. episode reward total was -15.0. running mean: -9.166951816466572\n",
      "resetting env. episode reward total was -11.0. running mean: -9.185282298301905\n",
      "resetting env. episode reward total was -12.0. running mean: -9.213429475318884\n",
      "resetting env. episode reward total was -11.0. running mean: -9.231295180565695\n",
      "resetting env. episode reward total was -11.0. running mean: -9.248982228760038\n",
      "resetting env. episode reward total was -10.0. running mean: -9.256492406472438\n",
      "resetting env. episode reward total was -13.0. running mean: -9.293927482407714\n",
      "resetting env. episode reward total was -18.0. running mean: -9.380988207583636\n",
      "resetting env. episode reward total was -13.0. running mean: -9.4171783255078\n",
      "resetting env. episode reward total was -15.0. running mean: -9.473006542252723\n",
      "resetting env. episode reward total was -7.0. running mean: -9.448276476830195\n",
      "resetting env. episode reward total was -13.0. running mean: -9.483793712061894\n",
      "resetting env. episode reward total was -13.0. running mean: -9.518955774941276\n",
      "resetting env. episode reward total was -12.0. running mean: -9.543766217191862\n",
      "resetting env. episode reward total was -11.0. running mean: -9.558328555019942\n",
      "resetting env. episode reward total was -16.0. running mean: -9.622745269469743\n",
      "resetting env. episode reward total was -11.0. running mean: -9.636517816775045\n",
      "resetting env. episode reward total was -5.0. running mean: -9.590152638607295\n",
      "resetting env. episode reward total was -14.0. running mean: -9.634251112221222\n",
      "resetting env. episode reward total was -10.0. running mean: -9.637908601099008\n",
      "resetting env. episode reward total was -13.0. running mean: -9.671529515088018\n",
      "resetting env. episode reward total was -13.0. running mean: -9.70481421993714\n",
      "resetting env. episode reward total was -9.0. running mean: -9.697766077737768\n",
      "resetting env. episode reward total was -14.0. running mean: -9.74078841696039\n",
      "resetting env. episode reward total was -12.0. running mean: -9.763380532790785\n",
      "resetting env. episode reward total was -8.0. running mean: -9.745746727462878\n",
      "resetting env. episode reward total was -11.0. running mean: -9.75828926018825\n",
      "resetting env. episode reward total was -15.0. running mean: -9.810706367586366\n",
      "resetting env. episode reward total was -9.0. running mean: -9.802599303910503\n",
      "resetting env. episode reward total was -7.0. running mean: -9.774573310871398\n",
      "resetting env. episode reward total was -9.0. running mean: -9.766827577762683\n",
      "resetting env. episode reward total was -17.0. running mean: -9.839159301985056\n",
      "resetting env. episode reward total was -14.0. running mean: -9.880767708965205\n",
      "resetting env. episode reward total was -8.0. running mean: -9.861960031875553\n",
      "resetting env. episode reward total was -13.0. running mean: -9.893340431556798\n",
      "resetting env. episode reward total was -11.0. running mean: -9.904407027241229\n",
      "resetting env. episode reward total was -10.0. running mean: -9.905362956968816\n",
      "resetting env. episode reward total was -10.0. running mean: -9.906309327399127\n",
      "resetting env. episode reward total was -9.0. running mean: -9.897246234125134\n",
      "resetting env. episode reward total was -17.0. running mean: -9.968273771783883\n",
      "resetting env. episode reward total was -15.0. running mean: -10.018591034066045\n",
      "resetting env. episode reward total was -9.0. running mean: -10.008405123725383\n",
      "resetting env. episode reward total was -8.0. running mean: -9.98832107248813\n",
      "resetting env. episode reward total was -2.0. running mean: -9.908437861763248\n",
      "resetting env. episode reward total was -9.0. running mean: -9.899353483145616\n",
      "resetting env. episode reward total was -9.0. running mean: -9.89035994831416\n",
      "resetting env. episode reward total was -15.0. running mean: -9.941456348831018\n",
      "resetting env. episode reward total was -12.0. running mean: -9.962041785342707\n",
      "resetting env. episode reward total was -6.0. running mean: -9.922421367489282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -16.0. running mean: -9.98319715381439\n",
      "resetting env. episode reward total was -12.0. running mean: -10.003365182276244\n",
      "resetting env. episode reward total was -8.0. running mean: -9.983331530453482\n",
      "resetting env. episode reward total was -15.0. running mean: -10.033498215148947\n",
      "resetting env. episode reward total was -7.0. running mean: -10.003163232997458\n",
      "resetting env. episode reward total was -12.0. running mean: -10.023131600667483\n",
      "resetting env. episode reward total was -7.0. running mean: -9.99290028466081\n",
      "resetting env. episode reward total was -10.0. running mean: -9.992971281814201\n",
      "resetting env. episode reward total was -13.0. running mean: -10.02304156899606\n",
      "resetting env. episode reward total was -9.0. running mean: -10.0128111533061\n",
      "resetting env. episode reward total was -11.0. running mean: -10.022683041773037\n",
      "resetting env. episode reward total was -5.0. running mean: -9.972456211355308\n",
      "resetting env. episode reward total was -14.0. running mean: -10.012731649241756\n",
      "resetting env. episode reward total was -11.0. running mean: -10.022604332749339\n",
      "resetting env. episode reward total was -13.0. running mean: -10.052378289421846\n",
      "resetting env. episode reward total was -6.0. running mean: -10.011854506527628\n",
      "resetting env. episode reward total was -5.0. running mean: -9.961735961462352\n",
      "resetting env. episode reward total was -8.0. running mean: -9.94211860184773\n",
      "resetting env. episode reward total was -7.0. running mean: -9.912697415829253\n",
      "resetting env. episode reward total was -13.0. running mean: -9.943570441670962\n",
      "resetting env. episode reward total was -13.0. running mean: -9.974134737254253\n",
      "resetting env. episode reward total was -8.0. running mean: -9.95439338988171\n",
      "resetting env. episode reward total was -13.0. running mean: -9.984849455982895\n",
      "resetting env. episode reward total was 7.0. running mean: -9.815000961423065\n",
      "resetting env. episode reward total was -13.0. running mean: -9.846850951808834\n",
      "resetting env. episode reward total was -3.0. running mean: -9.778382442290745\n",
      "resetting env. episode reward total was -9.0. running mean: -9.770598617867837\n",
      "resetting env. episode reward total was -8.0. running mean: -9.752892631689159\n",
      "resetting env. episode reward total was -9.0. running mean: -9.745363705372267\n",
      "resetting env. episode reward total was 2.0. running mean: -9.627910068318544\n",
      "resetting env. episode reward total was -1.0. running mean: -9.541630967635358\n",
      "resetting env. episode reward total was -11.0. running mean: -9.556214657959003\n",
      "resetting env. episode reward total was -12.0. running mean: -9.580652511379412\n",
      "resetting env. episode reward total was -5.0. running mean: -9.53484598626562\n",
      "resetting env. episode reward total was -13.0. running mean: -9.569497526402964\n",
      "resetting env. episode reward total was -7.0. running mean: -9.543802551138935\n",
      "resetting env. episode reward total was -6.0. running mean: -9.508364525627545\n",
      "resetting env. episode reward total was -13.0. running mean: -9.54328088037127\n",
      "resetting env. episode reward total was -13.0. running mean: -9.577848071567558\n",
      "resetting env. episode reward total was -15.0. running mean: -9.632069590851883\n",
      "resetting env. episode reward total was -12.0. running mean: -9.655748894943363\n",
      "resetting env. episode reward total was -15.0. running mean: -9.709191405993929\n",
      "resetting env. episode reward total was 8.0. running mean: -9.53209949193399\n",
      "resetting env. episode reward total was -12.0. running mean: -9.556778497014648\n",
      "resetting env. episode reward total was -13.0. running mean: -9.591210712044502\n",
      "resetting env. episode reward total was -11.0. running mean: -9.605298604924057\n",
      "resetting env. episode reward total was -3.0. running mean: -9.539245618874816\n",
      "resetting env. episode reward total was -12.0. running mean: -9.563853162686067\n",
      "resetting env. episode reward total was -11.0. running mean: -9.578214631059206\n",
      "resetting env. episode reward total was -5.0. running mean: -9.532432484748615\n",
      "resetting env. episode reward total was -14.0. running mean: -9.57710815990113\n",
      "resetting env. episode reward total was -10.0. running mean: -9.581337078302118\n",
      "resetting env. episode reward total was -14.0. running mean: -9.625523707519097\n",
      "resetting env. episode reward total was -10.0. running mean: -9.629268470443906\n",
      "resetting env. episode reward total was -8.0. running mean: -9.612975785739467\n",
      "resetting env. episode reward total was -6.0. running mean: -9.576846027882073\n",
      "resetting env. episode reward total was -2.0. running mean: -9.501077567603252\n",
      "resetting env. episode reward total was -10.0. running mean: -9.50606679192722\n",
      "resetting env. episode reward total was -3.0. running mean: -9.441006124007947\n",
      "resetting env. episode reward total was -13.0. running mean: -9.476596062767868\n",
      "resetting env. episode reward total was -17.0. running mean: -9.551830102140189\n",
      "resetting env. episode reward total was -21.0. running mean: -9.666311801118788\n",
      "resetting env. episode reward total was -8.0. running mean: -9.6496486831076\n",
      "resetting env. episode reward total was -13.0. running mean: -9.683152196276524\n",
      "resetting env. episode reward total was -14.0. running mean: -9.72632067431376\n",
      "resetting env. episode reward total was -9.0. running mean: -9.719057467570622\n",
      "resetting env. episode reward total was -14.0. running mean: -9.761866892894917\n",
      "resetting env. episode reward total was -4.0. running mean: -9.704248223965967\n",
      "resetting env. episode reward total was -9.0. running mean: -9.697205741726307\n",
      "resetting env. episode reward total was -6.0. running mean: -9.660233684309045\n",
      "resetting env. episode reward total was -9.0. running mean: -9.653631347465954\n",
      "resetting env. episode reward total was -2.0. running mean: -9.577095033991293\n",
      "resetting env. episode reward total was -7.0. running mean: -9.55132408365138\n",
      "resetting env. episode reward total was -1.0. running mean: -9.465810842814866\n",
      "resetting env. episode reward total was -11.0. running mean: -9.481152734386717\n",
      "resetting env. episode reward total was -6.0. running mean: -9.446341207042849\n",
      "resetting env. episode reward total was -11.0. running mean: -9.46187779497242\n",
      "resetting env. episode reward total was -13.0. running mean: -9.497259017022696\n",
      "resetting env. episode reward total was -10.0. running mean: -9.502286426852468\n",
      "resetting env. episode reward total was -11.0. running mean: -9.517263562583942\n",
      "resetting env. episode reward total was -13.0. running mean: -9.552090926958103\n",
      "resetting env. episode reward total was -4.0. running mean: -9.496570017688521\n",
      "resetting env. episode reward total was -15.0. running mean: -9.551604317511636\n",
      "resetting env. episode reward total was 1.0. running mean: -9.44608827433652\n",
      "resetting env. episode reward total was -15.0. running mean: -9.501627391593155\n",
      "resetting env. episode reward total was -15.0. running mean: -9.556611117677225\n",
      "resetting env. episode reward total was -5.0. running mean: -9.511045006500453\n",
      "resetting env. episode reward total was -5.0. running mean: -9.46593455643545\n",
      "resetting env. episode reward total was -10.0. running mean: -9.471275210871095\n",
      "resetting env. episode reward total was -18.0. running mean: -9.556562458762384\n",
      "resetting env. episode reward total was -17.0. running mean: -9.630996834174761\n",
      "resetting env. episode reward total was -8.0. running mean: -9.614686865833013\n",
      "resetting env. episode reward total was -4.0. running mean: -9.558539997174682\n",
      "resetting env. episode reward total was -6.0. running mean: -9.522954597202936\n",
      "resetting env. episode reward total was 1.0. running mean: -9.417725051230907\n",
      "resetting env. episode reward total was -6.0. running mean: -9.383547800718597\n",
      "resetting env. episode reward total was -12.0. running mean: -9.40971232271141\n",
      "resetting env. episode reward total was -9.0. running mean: -9.405615199484297\n",
      "resetting env. episode reward total was -11.0. running mean: -9.421559047489453\n",
      "resetting env. episode reward total was -11.0. running mean: -9.437343457014558\n",
      "resetting env. episode reward total was -5.0. running mean: -9.392970022444413\n",
      "resetting env. episode reward total was -3.0. running mean: -9.329040322219967\n",
      "resetting env. episode reward total was -18.0. running mean: -9.415749918997767\n",
      "resetting env. episode reward total was -15.0. running mean: -9.47159241980779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -9.446876495609711\n",
      "resetting env. episode reward total was -13.0. running mean: -9.482407730653614\n",
      "resetting env. episode reward total was -15.0. running mean: -9.53758365334708\n",
      "resetting env. episode reward total was -10.0. running mean: -9.542207816813608\n",
      "resetting env. episode reward total was -15.0. running mean: -9.596785738645472\n",
      "resetting env. episode reward total was -16.0. running mean: -9.660817881259018\n",
      "resetting env. episode reward total was -8.0. running mean: -9.644209702446428\n",
      "resetting env. episode reward total was -6.0. running mean: -9.607767605421964\n",
      "resetting env. episode reward total was -10.0. running mean: -9.611689929367744\n",
      "resetting env. episode reward total was -9.0. running mean: -9.605573030074066\n",
      "resetting env. episode reward total was -13.0. running mean: -9.639517299773326\n",
      "resetting env. episode reward total was -17.0. running mean: -9.713122126775593\n",
      "resetting env. episode reward total was -13.0. running mean: -9.745990905507838\n",
      "resetting env. episode reward total was -12.0. running mean: -9.768530996452759\n",
      "resetting env. episode reward total was -15.0. running mean: -9.820845686488232\n",
      "resetting env. episode reward total was -8.0. running mean: -9.80263722962335\n",
      "resetting env. episode reward total was -5.0. running mean: -9.754610857327117\n",
      "resetting env. episode reward total was 1.0. running mean: -9.647064748753847\n",
      "resetting env. episode reward total was -9.0. running mean: -9.640594101266307\n",
      "resetting env. episode reward total was -15.0. running mean: -9.694188160253645\n",
      "resetting env. episode reward total was -5.0. running mean: -9.64724627865111\n",
      "resetting env. episode reward total was -5.0. running mean: -9.6007738158646\n",
      "resetting env. episode reward total was -12.0. running mean: -9.624766077705953\n",
      "resetting env. episode reward total was -16.0. running mean: -9.688518416928893\n",
      "resetting env. episode reward total was -9.0. running mean: -9.681633232759605\n",
      "resetting env. episode reward total was -15.0. running mean: -9.734816900432008\n",
      "resetting env. episode reward total was -16.0. running mean: -9.797468731427688\n",
      "resetting env. episode reward total was -19.0. running mean: -9.88949404411341\n",
      "resetting env. episode reward total was -8.0. running mean: -9.870599103672276\n",
      "resetting env. episode reward total was -8.0. running mean: -9.851893112635553\n",
      "resetting env. episode reward total was -4.0. running mean: -9.793374181509197\n",
      "resetting env. episode reward total was -12.0. running mean: -9.815440439694104\n",
      "resetting env. episode reward total was -12.0. running mean: -9.837286035297161\n",
      "resetting env. episode reward total was -10.0. running mean: -9.838913174944189\n",
      "resetting env. episode reward total was -17.0. running mean: -9.910524043194746\n",
      "resetting env. episode reward total was -11.0. running mean: -9.921418802762798\n",
      "resetting env. episode reward total was -14.0. running mean: -9.96220461473517\n",
      "resetting env. episode reward total was -10.0. running mean: -9.962582568587818\n",
      "resetting env. episode reward total was -9.0. running mean: -9.95295674290194\n",
      "resetting env. episode reward total was -15.0. running mean: -10.00342717547292\n",
      "resetting env. episode reward total was 8.0. running mean: -9.82339290371819\n",
      "resetting env. episode reward total was -12.0. running mean: -9.845158974681008\n",
      "resetting env. episode reward total was -13.0. running mean: -9.876707384934198\n",
      "resetting env. episode reward total was -11.0. running mean: -9.887940311084856\n",
      "resetting env. episode reward total was -8.0. running mean: -9.869060907974008\n",
      "resetting env. episode reward total was -6.0. running mean: -9.830370298894268\n",
      "resetting env. episode reward total was -19.0. running mean: -9.922066595905324\n",
      "resetting env. episode reward total was -6.0. running mean: -9.88284592994627\n",
      "resetting env. episode reward total was -14.0. running mean: -9.924017470646808\n",
      "resetting env. episode reward total was -13.0. running mean: -9.95477729594034\n",
      "resetting env. episode reward total was -10.0. running mean: -9.955229522980936\n",
      "resetting env. episode reward total was -12.0. running mean: -9.975677227751126\n",
      "resetting env. episode reward total was -7.0. running mean: -9.945920455473615\n",
      "resetting env. episode reward total was 1.0. running mean: -9.836461250918878\n",
      "resetting env. episode reward total was -8.0. running mean: -9.81809663840969\n",
      "resetting env. episode reward total was -9.0. running mean: -9.809915672025593\n",
      "resetting env. episode reward total was -14.0. running mean: -9.851816515305337\n",
      "resetting env. episode reward total was -10.0. running mean: -9.853298350152283\n",
      "resetting env. episode reward total was -6.0. running mean: -9.81476536665076\n",
      "resetting env. episode reward total was -6.0. running mean: -9.776617712984253\n",
      "resetting env. episode reward total was -8.0. running mean: -9.75885153585441\n",
      "resetting env. episode reward total was -13.0. running mean: -9.791263020495867\n",
      "resetting env. episode reward total was -10.0. running mean: -9.793350390290907\n",
      "resetting env. episode reward total was -12.0. running mean: -9.815416886387997\n",
      "resetting env. episode reward total was -2.0. running mean: -9.737262717524116\n",
      "resetting env. episode reward total was -11.0. running mean: -9.749890090348874\n",
      "resetting env. episode reward total was -14.0. running mean: -9.792391189445386\n",
      "resetting env. episode reward total was -6.0. running mean: -9.754467277550932\n",
      "resetting env. episode reward total was -16.0. running mean: -9.816922604775423\n",
      "resetting env. episode reward total was -17.0. running mean: -9.888753378727667\n",
      "resetting env. episode reward total was -18.0. running mean: -9.96986584494039\n",
      "resetting env. episode reward total was -8.0. running mean: -9.950167186490987\n",
      "resetting env. episode reward total was -10.0. running mean: -9.950665514626076\n",
      "resetting env. episode reward total was 2.0. running mean: -9.831158859479816\n",
      "resetting env. episode reward total was -5.0. running mean: -9.782847270885018\n",
      "resetting env. episode reward total was -9.0. running mean: -9.775018798176168\n",
      "resetting env. episode reward total was -5.0. running mean: -9.727268610194407\n",
      "resetting env. episode reward total was -10.0. running mean: -9.729995924092464\n",
      "resetting env. episode reward total was -11.0. running mean: -9.742695964851539\n",
      "resetting env. episode reward total was -15.0. running mean: -9.795269005203023\n",
      "resetting env. episode reward total was -10.0. running mean: -9.797316315150992\n",
      "resetting env. episode reward total was -13.0. running mean: -9.829343151999483\n",
      "resetting env. episode reward total was -15.0. running mean: -9.881049720479488\n",
      "resetting env. episode reward total was -1.0. running mean: -9.792239223274693\n",
      "resetting env. episode reward total was -11.0. running mean: -9.804316831041946\n",
      "resetting env. episode reward total was -16.0. running mean: -9.866273662731526\n",
      "resetting env. episode reward total was -15.0. running mean: -9.917610926104212\n",
      "resetting env. episode reward total was -5.0. running mean: -9.86843481684317\n",
      "resetting env. episode reward total was -10.0. running mean: -9.869750468674738\n",
      "resetting env. episode reward total was -3.0. running mean: -9.80105296398799\n",
      "resetting env. episode reward total was -8.0. running mean: -9.78304243434811\n",
      "resetting env. episode reward total was -12.0. running mean: -9.805212010004627\n",
      "resetting env. episode reward total was 4.0. running mean: -9.667159889904582\n",
      "resetting env. episode reward total was -12.0. running mean: -9.690488291005535\n",
      "resetting env. episode reward total was -7.0. running mean: -9.66358340809548\n",
      "resetting env. episode reward total was -4.0. running mean: -9.606947574014525\n",
      "resetting env. episode reward total was -7.0. running mean: -9.580878098274379\n",
      "resetting env. episode reward total was -15.0. running mean: -9.635069317291636\n",
      "resetting env. episode reward total was -3.0. running mean: -9.56871862411872\n",
      "resetting env. episode reward total was 2.0. running mean: -9.453031437877533\n",
      "resetting env. episode reward total was -8.0. running mean: -9.438501123498757\n",
      "resetting env. episode reward total was 4.0. running mean: -9.30411611226377\n",
      "resetting env. episode reward total was -7.0. running mean: -9.281074951141132\n",
      "resetting env. episode reward total was -9.0. running mean: -9.278264201629721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: -9.225481559613423\n",
      "resetting env. episode reward total was -10.0. running mean: -9.233226744017287\n",
      "resetting env. episode reward total was -10.0. running mean: -9.240894476577115\n",
      "resetting env. episode reward total was 6.0. running mean: -9.088485531811342\n",
      "resetting env. episode reward total was 3.0. running mean: -8.967600676493229\n",
      "resetting env. episode reward total was -6.0. running mean: -8.937924669728297\n",
      "resetting env. episode reward total was -9.0. running mean: -8.938545423031014\n",
      "resetting env. episode reward total was -6.0. running mean: -8.909159968800704\n",
      "resetting env. episode reward total was -2.0. running mean: -8.840068369112696\n",
      "resetting env. episode reward total was -11.0. running mean: -8.861667685421569\n",
      "resetting env. episode reward total was 2.0. running mean: -8.753051008567354\n",
      "resetting env. episode reward total was 7.0. running mean: -8.59552049848168\n",
      "resetting env. episode reward total was -11.0. running mean: -8.619565293496862\n",
      "resetting env. episode reward total was -15.0. running mean: -8.683369640561894\n",
      "resetting env. episode reward total was -20.0. running mean: -8.796535944156274\n",
      "resetting env. episode reward total was -8.0. running mean: -8.78857058471471\n",
      "resetting env. episode reward total was -11.0. running mean: -8.810684878867562\n",
      "resetting env. episode reward total was 2.0. running mean: -8.702578030078886\n",
      "resetting env. episode reward total was 1.0. running mean: -8.605552249778098\n",
      "resetting env. episode reward total was -9.0. running mean: -8.609496727280316\n",
      "resetting env. episode reward total was -13.0. running mean: -8.653401760007513\n",
      "resetting env. episode reward total was -13.0. running mean: -8.69686774240744\n",
      "resetting env. episode reward total was -2.0. running mean: -8.629899064983364\n",
      "resetting env. episode reward total was -13.0. running mean: -8.673600074333532\n",
      "resetting env. episode reward total was -7.0. running mean: -8.656864073590196\n",
      "resetting env. episode reward total was 3.0. running mean: -8.540295432854295\n",
      "resetting env. episode reward total was -5.0. running mean: -8.504892478525752\n",
      "resetting env. episode reward total was -11.0. running mean: -8.529843553740495\n",
      "resetting env. episode reward total was -8.0. running mean: -8.52454511820309\n",
      "resetting env. episode reward total was -11.0. running mean: -8.549299667021058\n",
      "resetting env. episode reward total was -3.0. running mean: -8.493806670350848\n",
      "resetting env. episode reward total was -7.0. running mean: -8.47886860364734\n",
      "resetting env. episode reward total was -2.0. running mean: -8.414079917610866\n",
      "resetting env. episode reward total was -14.0. running mean: -8.469939118434759\n",
      "resetting env. episode reward total was -9.0. running mean: -8.475239727250411\n",
      "resetting env. episode reward total was -9.0. running mean: -8.480487329977906\n",
      "resetting env. episode reward total was -6.0. running mean: -8.455682456678128\n",
      "resetting env. episode reward total was -11.0. running mean: -8.481125632111345\n",
      "resetting env. episode reward total was -8.0. running mean: -8.476314375790231\n",
      "resetting env. episode reward total was -12.0. running mean: -8.511551232032328\n",
      "resetting env. episode reward total was 3.0. running mean: -8.396435719712006\n",
      "resetting env. episode reward total was -2.0. running mean: -8.332471362514886\n",
      "resetting env. episode reward total was -8.0. running mean: -8.329146648889736\n",
      "resetting env. episode reward total was -6.0. running mean: -8.305855182400839\n",
      "resetting env. episode reward total was -9.0. running mean: -8.31279663057683\n",
      "resetting env. episode reward total was -12.0. running mean: -8.34966866427106\n",
      "resetting env. episode reward total was -12.0. running mean: -8.386171977628349\n",
      "resetting env. episode reward total was -11.0. running mean: -8.412310257852065\n",
      "resetting env. episode reward total was -8.0. running mean: -8.408187155273545\n",
      "resetting env. episode reward total was -3.0. running mean: -8.35410528372081\n",
      "resetting env. episode reward total was 2.0. running mean: -8.250564230883601\n",
      "resetting env. episode reward total was -5.0. running mean: -8.218058588574765\n",
      "resetting env. episode reward total was 9.0. running mean: -8.045878002689017\n",
      "resetting env. episode reward total was 8.0. running mean: -7.885419222662127\n",
      "resetting env. episode reward total was -1.0. running mean: -7.816565030435505\n",
      "resetting env. episode reward total was 5.0. running mean: -7.68839938013115\n",
      "resetting env. episode reward total was -3.0. running mean: -7.641515386329838\n",
      "resetting env. episode reward total was -3.0. running mean: -7.59510023246654\n",
      "resetting env. episode reward total was 1.0. running mean: -7.509149230141874\n",
      "resetting env. episode reward total was -11.0. running mean: -7.544057737840456\n",
      "resetting env. episode reward total was -8.0. running mean: -7.548617160462051\n",
      "resetting env. episode reward total was -6.0. running mean: -7.53313098885743\n",
      "resetting env. episode reward total was -6.0. running mean: -7.517799678968855\n",
      "resetting env. episode reward total was -5.0. running mean: -7.492621682179166\n",
      "resetting env. episode reward total was 2.0. running mean: -7.3976954653573745\n",
      "resetting env. episode reward total was -11.0. running mean: -7.433718510703801\n",
      "resetting env. episode reward total was -11.0. running mean: -7.469381325596763\n",
      "resetting env. episode reward total was 6.0. running mean: -7.334687512340796\n",
      "resetting env. episode reward total was -12.0. running mean: -7.381340637217388\n",
      "resetting env. episode reward total was -2.0. running mean: -7.327527230845214\n",
      "resetting env. episode reward total was -6.0. running mean: -7.314251958536762\n",
      "resetting env. episode reward total was -4.0. running mean: -7.281109438951394\n",
      "resetting env. episode reward total was -12.0. running mean: -7.328298344561881\n",
      "resetting env. episode reward total was -8.0. running mean: -7.335015361116262\n",
      "resetting env. episode reward total was -7.0. running mean: -7.331665207505099\n",
      "resetting env. episode reward total was -11.0. running mean: -7.368348555430049\n",
      "resetting env. episode reward total was -13.0. running mean: -7.424665069875748\n",
      "resetting env. episode reward total was -5.0. running mean: -7.40041841917699\n",
      "resetting env. episode reward total was -2.0. running mean: -7.34641423498522\n",
      "resetting env. episode reward total was -1.0. running mean: -7.282950092635367\n",
      "resetting env. episode reward total was -3.0. running mean: -7.240120591709014\n",
      "resetting env. episode reward total was -14.0. running mean: -7.307719385791923\n",
      "resetting env. episode reward total was -9.0. running mean: -7.324642191934004\n",
      "resetting env. episode reward total was -5.0. running mean: -7.301395770014663\n",
      "resetting env. episode reward total was -11.0. running mean: -7.338381812314517\n",
      "resetting env. episode reward total was -3.0. running mean: -7.294997994191372\n",
      "resetting env. episode reward total was -7.0. running mean: -7.292048014249459\n",
      "resetting env. episode reward total was -9.0. running mean: -7.309127534106964\n",
      "resetting env. episode reward total was -17.0. running mean: -7.406036258765894\n",
      "resetting env. episode reward total was -6.0. running mean: -7.391975896178235\n",
      "resetting env. episode reward total was -7.0. running mean: -7.388056137216453\n",
      "resetting env. episode reward total was -12.0. running mean: -7.4341755758442885\n",
      "resetting env. episode reward total was -13.0. running mean: -7.489833820085845\n",
      "resetting env. episode reward total was -7.0. running mean: -7.484935481884987\n",
      "resetting env. episode reward total was -15.0. running mean: -7.560086127066137\n",
      "resetting env. episode reward total was -5.0. running mean: -7.5344852657954755\n",
      "resetting env. episode reward total was -11.0. running mean: -7.569140413137521\n",
      "resetting env. episode reward total was -11.0. running mean: -7.6034490090061455\n",
      "resetting env. episode reward total was -13.0. running mean: -7.657414518916084\n",
      "resetting env. episode reward total was -13.0. running mean: -7.710840373726922\n",
      "resetting env. episode reward total was -3.0. running mean: -7.663731969989653\n",
      "resetting env. episode reward total was -8.0. running mean: -7.667094650289757\n",
      "resetting env. episode reward total was -7.0. running mean: -7.66042370378686\n",
      "resetting env. episode reward total was -7.0. running mean: -7.653819466748991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -11.0. running mean: -7.687281272081501\n",
      "resetting env. episode reward total was -17.0. running mean: -7.780408459360686\n",
      "resetting env. episode reward total was -14.0. running mean: -7.842604374767078\n",
      "resetting env. episode reward total was -10.0. running mean: -7.864178331019407\n",
      "resetting env. episode reward total was -9.0. running mean: -7.875536547709213\n",
      "resetting env. episode reward total was -11.0. running mean: -7.9067811822321215\n",
      "resetting env. episode reward total was -8.0. running mean: -7.9077133704098\n",
      "resetting env. episode reward total was -11.0. running mean: -7.938636236705702\n",
      "resetting env. episode reward total was -11.0. running mean: -7.9692498743386455\n",
      "resetting env. episode reward total was -12.0. running mean: -8.009557375595259\n",
      "resetting env. episode reward total was -16.0. running mean: -8.089461801839306\n",
      "resetting env. episode reward total was -8.0. running mean: -8.088567183820913\n",
      "resetting env. episode reward total was -8.0. running mean: -8.087681511982705\n",
      "resetting env. episode reward total was -12.0. running mean: -8.126804696862877\n",
      "resetting env. episode reward total was -9.0. running mean: -8.135536649894247\n",
      "resetting env. episode reward total was -13.0. running mean: -8.184181283395306\n",
      "resetting env. episode reward total was -12.0. running mean: -8.222339470561352\n",
      "resetting env. episode reward total was -13.0. running mean: -8.27011607585574\n",
      "resetting env. episode reward total was -8.0. running mean: -8.267414915097183\n",
      "resetting env. episode reward total was -12.0. running mean: -8.30474076594621\n",
      "resetting env. episode reward total was -6.0. running mean: -8.281693358286748\n",
      "resetting env. episode reward total was 1.0. running mean: -8.188876424703881\n",
      "resetting env. episode reward total was -1.0. running mean: -8.116987660456843\n",
      "resetting env. episode reward total was -1.0. running mean: -8.045817783852275\n",
      "resetting env. episode reward total was -15.0. running mean: -8.115359606013753\n",
      "resetting env. episode reward total was -15.0. running mean: -8.184206009953616\n",
      "resetting env. episode reward total was -10.0. running mean: -8.20236394985408\n",
      "resetting env. episode reward total was -10.0. running mean: -8.220340310355539\n",
      "resetting env. episode reward total was -4.0. running mean: -8.178136907251982\n",
      "resetting env. episode reward total was -11.0. running mean: -8.206355538179462\n",
      "resetting env. episode reward total was -10.0. running mean: -8.224291982797666\n",
      "resetting env. episode reward total was -8.0. running mean: -8.22204906296969\n",
      "resetting env. episode reward total was -6.0. running mean: -8.199828572339994\n",
      "resetting env. episode reward total was -2.0. running mean: -8.137830286616595\n",
      "resetting env. episode reward total was -8.0. running mean: -8.136451983750428\n",
      "resetting env. episode reward total was -7.0. running mean: -8.125087463912925\n",
      "resetting env. episode reward total was 1.0. running mean: -8.033836589273795\n",
      "resetting env. episode reward total was -2.0. running mean: -7.973498223381057\n",
      "resetting env. episode reward total was -4.0. running mean: -7.933763241147246\n",
      "resetting env. episode reward total was -11.0. running mean: -7.964425608735774\n",
      "resetting env. episode reward total was -6.0. running mean: -7.944781352648416\n",
      "resetting env. episode reward total was -6.0. running mean: -7.925333539121931\n",
      "resetting env. episode reward total was -9.0. running mean: -7.936080203730712\n",
      "resetting env. episode reward total was -11.0. running mean: -7.966719401693405\n",
      "resetting env. episode reward total was -4.0. running mean: -7.927052207676471\n",
      "resetting env. episode reward total was -11.0. running mean: -7.957781685599707\n",
      "resetting env. episode reward total was -15.0. running mean: -8.02820386874371\n",
      "resetting env. episode reward total was -13.0. running mean: -8.077921830056273\n",
      "resetting env. episode reward total was -12.0. running mean: -8.117142611755709\n",
      "resetting env. episode reward total was -6.0. running mean: -8.095971185638152\n",
      "resetting env. episode reward total was -6.0. running mean: -8.075011473781771\n",
      "resetting env. episode reward total was -8.0. running mean: -8.074261359043954\n",
      "resetting env. episode reward total was -4.0. running mean: -8.033518745453513\n",
      "resetting env. episode reward total was -11.0. running mean: -8.063183557998977\n",
      "resetting env. episode reward total was -11.0. running mean: -8.092551722418987\n",
      "resetting env. episode reward total was -5.0. running mean: -8.061626205194798\n",
      "resetting env. episode reward total was -10.0. running mean: -8.08100994314285\n",
      "resetting env. episode reward total was -11.0. running mean: -8.110199843711422\n",
      "resetting env. episode reward total was -10.0. running mean: -8.129097845274307\n",
      "resetting env. episode reward total was -9.0. running mean: -8.137806866821563\n",
      "resetting env. episode reward total was -7.0. running mean: -8.126428798153349\n",
      "resetting env. episode reward total was -12.0. running mean: -8.165164510171815\n",
      "resetting env. episode reward total was -6.0. running mean: -8.143512865070097\n",
      "resetting env. episode reward total was -3.0. running mean: -8.092077736419395\n",
      "resetting env. episode reward total was -14.0. running mean: -8.151156959055202\n",
      "resetting env. episode reward total was -5.0. running mean: -8.119645389464651\n",
      "resetting env. episode reward total was -8.0. running mean: -8.118448935570004\n",
      "resetting env. episode reward total was -7.0. running mean: -8.107264446214305\n",
      "resetting env. episode reward total was 10.0. running mean: -7.926191801752163\n",
      "resetting env. episode reward total was -4.0. running mean: -7.886929883734641\n",
      "resetting env. episode reward total was 6.0. running mean: -7.748060584897296\n",
      "resetting env. episode reward total was -11.0. running mean: -7.780579979048323\n",
      "resetting env. episode reward total was 10.0. running mean: -7.60277417925784\n",
      "resetting env. episode reward total was -8.0. running mean: -7.606746437465262\n",
      "resetting env. episode reward total was -12.0. running mean: -7.650678973090609\n",
      "resetting env. episode reward total was -3.0. running mean: -7.604172183359704\n",
      "resetting env. episode reward total was -2.0. running mean: -7.548130461526106\n",
      "resetting env. episode reward total was -6.0. running mean: -7.5326491569108445\n",
      "resetting env. episode reward total was -8.0. running mean: -7.537322665341736\n",
      "resetting env. episode reward total was -4.0. running mean: -7.501949438688318\n",
      "resetting env. episode reward total was -19.0. running mean: -7.616929944301435\n",
      "resetting env. episode reward total was -5.0. running mean: -7.59076064485842\n",
      "resetting env. episode reward total was -11.0. running mean: -7.624853038409836\n",
      "resetting env. episode reward total was -13.0. running mean: -7.678604508025738\n",
      "resetting env. episode reward total was -4.0. running mean: -7.641818462945481\n",
      "resetting env. episode reward total was -6.0. running mean: -7.625400278316025\n",
      "resetting env. episode reward total was -9.0. running mean: -7.639146275532865\n",
      "resetting env. episode reward total was -14.0. running mean: -7.7027548127775365\n",
      "resetting env. episode reward total was -6.0. running mean: -7.685727264649761\n",
      "resetting env. episode reward total was 12.0. running mean: -7.488869992003263\n",
      "resetting env. episode reward total was -4.0. running mean: -7.45398129208323\n",
      "resetting env. episode reward total was -6.0. running mean: -7.439441479162397\n",
      "resetting env. episode reward total was -7.0. running mean: -7.435047064370774\n",
      "resetting env. episode reward total was -5.0. running mean: -7.4106965937270655\n",
      "resetting env. episode reward total was -9.0. running mean: -7.426589627789794\n",
      "resetting env. episode reward total was -8.0. running mean: -7.432323731511897\n",
      "resetting env. episode reward total was -6.0. running mean: -7.418000494196777\n",
      "resetting env. episode reward total was 1.0. running mean: -7.333820489254809\n",
      "resetting env. episode reward total was 6.0. running mean: -7.200482284362262\n",
      "resetting env. episode reward total was -4.0. running mean: -7.1684774615186395\n",
      "resetting env. episode reward total was -5.0. running mean: -7.146792686903453\n",
      "resetting env. episode reward total was -4.0. running mean: -7.115324760034418\n",
      "resetting env. episode reward total was -15.0. running mean: -7.194171512434074\n",
      "resetting env. episode reward total was 7.0. running mean: -7.0522297973097325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -10.0. running mean: -7.081707499336635\n",
      "resetting env. episode reward total was -17.0. running mean: -7.180890424343269\n",
      "resetting env. episode reward total was -5.0. running mean: -7.159081520099836\n",
      "resetting env. episode reward total was -12.0. running mean: -7.207490704898837\n",
      "resetting env. episode reward total was -16.0. running mean: -7.295415797849849\n",
      "resetting env. episode reward total was -5.0. running mean: -7.2724616398713495\n",
      "resetting env. episode reward total was -3.0. running mean: -7.229737023472636\n",
      "resetting env. episode reward total was -15.0. running mean: -7.3074396532379104\n",
      "resetting env. episode reward total was -8.0. running mean: -7.314365256705531\n",
      "resetting env. episode reward total was -4.0. running mean: -7.281221604138476\n",
      "resetting env. episode reward total was -9.0. running mean: -7.298409388097091\n",
      "resetting env. episode reward total was -9.0. running mean: -7.315425294216119\n",
      "resetting env. episode reward total was -4.0. running mean: -7.282271041273958\n",
      "resetting env. episode reward total was -8.0. running mean: -7.289448330861219\n",
      "resetting env. episode reward total was -13.0. running mean: -7.346553847552606\n",
      "resetting env. episode reward total was -1.0. running mean: -7.28308830907708\n",
      "resetting env. episode reward total was -1.0. running mean: -7.220257425986309\n",
      "resetting env. episode reward total was -11.0. running mean: -7.258054851726445\n",
      "resetting env. episode reward total was -9.0. running mean: -7.27547430320918\n",
      "resetting env. episode reward total was -5.0. running mean: -7.252719560177089\n",
      "resetting env. episode reward total was -2.0. running mean: -7.200192364575317\n",
      "resetting env. episode reward total was -3.0. running mean: -7.158190440929564\n",
      "resetting env. episode reward total was -7.0. running mean: -7.1566085365202685\n",
      "resetting env. episode reward total was -5.0. running mean: -7.135042451155066\n",
      "resetting env. episode reward total was -4.0. running mean: -7.103692026643515\n",
      "resetting env. episode reward total was -4.0. running mean: -7.07265510637708\n",
      "resetting env. episode reward total was -6.0. running mean: -7.061928555313308\n",
      "resetting env. episode reward total was 4.0. running mean: -6.951309269760175\n",
      "resetting env. episode reward total was 6.0. running mean: -6.8217961770625735\n",
      "resetting env. episode reward total was -9.0. running mean: -6.843578215291948\n",
      "resetting env. episode reward total was -8.0. running mean: -6.8551424331390285\n",
      "resetting env. episode reward total was -17.0. running mean: -6.956591008807638\n",
      "resetting env. episode reward total was -6.0. running mean: -6.9470250987195605\n",
      "resetting env. episode reward total was 2.0. running mean: -6.857554847732366\n",
      "resetting env. episode reward total was -6.0. running mean: -6.848979299255041\n",
      "resetting env. episode reward total was -5.0. running mean: -6.830489506262491\n",
      "resetting env. episode reward total was -4.0. running mean: -6.802184611199865\n",
      "resetting env. episode reward total was 6.0. running mean: -6.674162765087867\n",
      "resetting env. episode reward total was -2.0. running mean: -6.627421137436988\n",
      "resetting env. episode reward total was -6.0. running mean: -6.621146926062618\n",
      "resetting env. episode reward total was -5.0. running mean: -6.604935456801992\n",
      "resetting env. episode reward total was -1.0. running mean: -6.548886102233972\n",
      "resetting env. episode reward total was -8.0. running mean: -6.563397241211632\n",
      "resetting env. episode reward total was 4.0. running mean: -6.457763268799516\n",
      "resetting env. episode reward total was -11.0. running mean: -6.503185636111521\n",
      "resetting env. episode reward total was -11.0. running mean: -6.548153779750406\n",
      "resetting env. episode reward total was -9.0. running mean: -6.572672241952901\n",
      "resetting env. episode reward total was -7.0. running mean: -6.576945519533372\n",
      "resetting env. episode reward total was -12.0. running mean: -6.631176064338039\n",
      "resetting env. episode reward total was -8.0. running mean: -6.644864303694659\n",
      "resetting env. episode reward total was -12.0. running mean: -6.698415660657712\n",
      "resetting env. episode reward total was -13.0. running mean: -6.761431504051135\n",
      "resetting env. episode reward total was -12.0. running mean: -6.813817189010623\n",
      "resetting env. episode reward total was -15.0. running mean: -6.895679017120518\n",
      "resetting env. episode reward total was -9.0. running mean: -6.916722226949313\n",
      "resetting env. episode reward total was -13.0. running mean: -6.97755500467982\n",
      "resetting env. episode reward total was -6.0. running mean: -6.967779454633021\n",
      "resetting env. episode reward total was -11.0. running mean: -7.008101660086691\n",
      "resetting env. episode reward total was 2.0. running mean: -6.918020643485824\n",
      "resetting env. episode reward total was -13.0. running mean: -6.978840437050966\n",
      "resetting env. episode reward total was -9.0. running mean: -6.999052032680456\n",
      "resetting env. episode reward total was -15.0. running mean: -7.079061512353652\n",
      "resetting env. episode reward total was -10.0. running mean: -7.108270897230115\n",
      "resetting env. episode reward total was -8.0. running mean: -7.117188188257814\n",
      "resetting env. episode reward total was -11.0. running mean: -7.1560163063752364\n",
      "resetting env. episode reward total was -5.0. running mean: -7.134456143311484\n",
      "resetting env. episode reward total was -10.0. running mean: -7.163111581878368\n",
      "resetting env. episode reward total was -12.0. running mean: -7.211480466059585\n",
      "resetting env. episode reward total was -17.0. running mean: -7.309365661398989\n",
      "resetting env. episode reward total was -10.0. running mean: -7.336272004784998\n",
      "resetting env. episode reward total was -4.0. running mean: -7.302909284737148\n",
      "resetting env. episode reward total was -10.0. running mean: -7.329880191889776\n",
      "resetting env. episode reward total was -3.0. running mean: -7.286581389970879\n",
      "resetting env. episode reward total was -5.0. running mean: -7.26371557607117\n",
      "resetting env. episode reward total was -11.0. running mean: -7.301078420310458\n",
      "resetting env. episode reward total was -11.0. running mean: -7.338067636107354\n",
      "resetting env. episode reward total was -11.0. running mean: -7.37468695974628\n",
      "resetting env. episode reward total was -10.0. running mean: -7.400940090148817\n",
      "resetting env. episode reward total was -5.0. running mean: -7.376930689247328\n",
      "resetting env. episode reward total was -15.0. running mean: -7.453161382354855\n",
      "resetting env. episode reward total was -3.0. running mean: -7.4086297685313065\n",
      "resetting env. episode reward total was -13.0. running mean: -7.464543470845993\n",
      "resetting env. episode reward total was -11.0. running mean: -7.499898036137534\n",
      "resetting env. episode reward total was -9.0. running mean: -7.514899055776159\n",
      "resetting env. episode reward total was -11.0. running mean: -7.549750065218397\n",
      "resetting env. episode reward total was -11.0. running mean: -7.5842525645662136\n",
      "resetting env. episode reward total was 1.0. running mean: -7.498410038920552\n",
      "resetting env. episode reward total was -11.0. running mean: -7.533425938531346\n",
      "resetting env. episode reward total was 1.0. running mean: -7.4480916791460325\n",
      "resetting env. episode reward total was -8.0. running mean: -7.453610762354573\n",
      "resetting env. episode reward total was -1.0. running mean: -7.389074654731027\n",
      "resetting env. episode reward total was -11.0. running mean: -7.425183908183716\n",
      "resetting env. episode reward total was -7.0. running mean: -7.420932069101879\n",
      "resetting env. episode reward total was -16.0. running mean: -7.50672274841086\n",
      "resetting env. episode reward total was -5.0. running mean: -7.4816555209267515\n",
      "resetting env. episode reward total was -15.0. running mean: -7.556838965717485\n",
      "resetting env. episode reward total was -7.0. running mean: -7.55127057606031\n",
      "resetting env. episode reward total was -8.0. running mean: -7.555757870299707\n",
      "resetting env. episode reward total was -16.0. running mean: -7.6402002915967095\n",
      "resetting env. episode reward total was -9.0. running mean: -7.6537982886807425\n",
      "resetting env. episode reward total was -14.0. running mean: -7.717260305793935\n",
      "resetting env. episode reward total was -10.0. running mean: -7.740087702735995\n",
      "resetting env. episode reward total was -10.0. running mean: -7.762686825708634\n",
      "resetting env. episode reward total was -9.0. running mean: -7.775059957451548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -16.0. running mean: -7.857309357877033\n",
      "resetting env. episode reward total was -13.0. running mean: -7.908736264298263\n",
      "resetting env. episode reward total was -3.0. running mean: -7.85964890165528\n",
      "resetting env. episode reward total was -8.0. running mean: -7.861052412638728\n",
      "resetting env. episode reward total was -4.0. running mean: -7.822441888512341\n",
      "resetting env. episode reward total was -1.0. running mean: -7.754217469627217\n",
      "resetting env. episode reward total was -6.0. running mean: -7.7366752949309445\n",
      "resetting env. episode reward total was -15.0. running mean: -7.809308541981635\n",
      "resetting env. episode reward total was -8.0. running mean: -7.811215456561819\n",
      "resetting env. episode reward total was -6.0. running mean: -7.793103301996201\n",
      "resetting env. episode reward total was -8.0. running mean: -7.795172268976239\n",
      "resetting env. episode reward total was -18.0. running mean: -7.8972205462864755\n",
      "resetting env. episode reward total was -1.0. running mean: -7.8282483408236105\n",
      "resetting env. episode reward total was -9.0. running mean: -7.8399658574153746\n",
      "resetting env. episode reward total was -1.0. running mean: -7.771566198841221\n",
      "resetting env. episode reward total was -11.0. running mean: -7.803850536852809\n",
      "resetting env. episode reward total was -10.0. running mean: -7.825812031484281\n",
      "resetting env. episode reward total was -5.0. running mean: -7.797553911169438\n",
      "resetting env. episode reward total was -13.0. running mean: -7.849578372057744\n",
      "resetting env. episode reward total was -5.0. running mean: -7.821082588337166\n",
      "resetting env. episode reward total was -14.0. running mean: -7.882871762453794\n",
      "resetting env. episode reward total was 6.0. running mean: -7.744043044829256\n",
      "resetting env. episode reward total was -9.0. running mean: -7.756602614380964\n",
      "resetting env. episode reward total was -1.0. running mean: -7.689036588237154\n",
      "resetting env. episode reward total was -8.0. running mean: -7.692146222354783\n",
      "resetting env. episode reward total was -6.0. running mean: -7.6752247601312344\n",
      "resetting env. episode reward total was -10.0. running mean: -7.698472512529921\n",
      "resetting env. episode reward total was -11.0. running mean: -7.731487787404623\n",
      "resetting env. episode reward total was -1.0. running mean: -7.664172909530576\n",
      "resetting env. episode reward total was -15.0. running mean: -7.737531180435271\n",
      "resetting env. episode reward total was -9.0. running mean: -7.750155868630918\n",
      "resetting env. episode reward total was -12.0. running mean: -7.792654309944608\n",
      "resetting env. episode reward total was -8.0. running mean: -7.794727766845162\n",
      "resetting env. episode reward total was -1.0. running mean: -7.7267804891767105\n",
      "resetting env. episode reward total was -1.0. running mean: -7.659512684284943\n",
      "resetting env. episode reward total was -6.0. running mean: -7.642917557442093\n",
      "resetting env. episode reward total was -4.0. running mean: -7.606488381867672\n",
      "resetting env. episode reward total was -12.0. running mean: -7.650423498048996\n",
      "resetting env. episode reward total was -11.0. running mean: -7.683919263068506\n",
      "resetting env. episode reward total was -13.0. running mean: -7.737080070437821\n",
      "resetting env. episode reward total was -10.0. running mean: -7.759709269733442\n",
      "resetting env. episode reward total was -14.0. running mean: -7.822112177036107\n",
      "resetting env. episode reward total was -5.0. running mean: -7.793891055265746\n",
      "resetting env. episode reward total was -6.0. running mean: -7.775952144713088\n",
      "resetting env. episode reward total was 4.0. running mean: -7.658192623265957\n",
      "resetting env. episode reward total was -9.0. running mean: -7.671610697033297\n",
      "resetting env. episode reward total was -11.0. running mean: -7.704894590062964\n",
      "resetting env. episode reward total was -2.0. running mean: -7.647845644162334\n",
      "resetting env. episode reward total was -4.0. running mean: -7.611367187720711\n",
      "resetting env. episode reward total was -4.0. running mean: -7.575253515843504\n",
      "resetting env. episode reward total was -14.0. running mean: -7.639500980685068\n",
      "resetting env. episode reward total was -1.0. running mean: -7.573105970878217\n",
      "resetting env. episode reward total was -14.0. running mean: -7.6373749111694345\n",
      "resetting env. episode reward total was -8.0. running mean: -7.64100116205774\n",
      "resetting env. episode reward total was -7.0. running mean: -7.634591150437163\n",
      "resetting env. episode reward total was -1.0. running mean: -7.568245238932791\n",
      "resetting env. episode reward total was -7.0. running mean: -7.562562786543463\n",
      "resetting env. episode reward total was -6.0. running mean: -7.546937158678028\n",
      "resetting env. episode reward total was -4.0. running mean: -7.511467787091248\n",
      "resetting env. episode reward total was -14.0. running mean: -7.576353109220335\n",
      "resetting env. episode reward total was -6.0. running mean: -7.560589578128131\n",
      "resetting env. episode reward total was -9.0. running mean: -7.57498368234685\n",
      "resetting env. episode reward total was -15.0. running mean: -7.649233845523382\n",
      "resetting env. episode reward total was -13.0. running mean: -7.702741507068148\n",
      "resetting env. episode reward total was -12.0. running mean: -7.745714091997467\n",
      "resetting env. episode reward total was -8.0. running mean: -7.748256951077492\n",
      "resetting env. episode reward total was -1.0. running mean: -7.680774381566716\n",
      "resetting env. episode reward total was -5.0. running mean: -7.653966637751049\n",
      "resetting env. episode reward total was -6.0. running mean: -7.637426971373538\n",
      "resetting env. episode reward total was 5.0. running mean: -7.5110527016598025\n",
      "resetting env. episode reward total was -8.0. running mean: -7.515942174643205\n",
      "resetting env. episode reward total was -2.0. running mean: -7.4607827528967725\n",
      "resetting env. episode reward total was 3.0. running mean: -7.356174925367805\n",
      "resetting env. episode reward total was -4.0. running mean: -7.322613176114126\n",
      "resetting env. episode reward total was -13.0. running mean: -7.379387044352985\n",
      "resetting env. episode reward total was -6.0. running mean: -7.3655931739094544\n",
      "resetting env. episode reward total was 3.0. running mean: -7.26193724217036\n",
      "resetting env. episode reward total was -2.0. running mean: -7.209317869748656\n",
      "resetting env. episode reward total was -8.0. running mean: -7.217224691051169\n",
      "resetting env. episode reward total was -4.0. running mean: -7.185052444140657\n",
      "resetting env. episode reward total was -9.0. running mean: -7.203201919699251\n",
      "resetting env. episode reward total was -4.0. running mean: -7.171169900502258\n",
      "resetting env. episode reward total was -3.0. running mean: -7.129458201497236\n",
      "resetting env. episode reward total was -3.0. running mean: -7.088163619482264\n",
      "resetting env. episode reward total was -8.0. running mean: -7.097281983287441\n",
      "resetting env. episode reward total was -6.0. running mean: -7.086309163454566\n",
      "resetting env. episode reward total was -2.0. running mean: -7.0354460718200205\n",
      "resetting env. episode reward total was -2.0. running mean: -6.9850916111018195\n",
      "resetting env. episode reward total was -6.0. running mean: -6.975240694990801\n",
      "resetting env. episode reward total was 4.0. running mean: -6.865488288040893\n",
      "resetting env. episode reward total was -7.0. running mean: -6.8668334051604845\n",
      "resetting env. episode reward total was -9.0. running mean: -6.8881650711088795\n",
      "resetting env. episode reward total was -5.0. running mean: -6.869283420397791\n",
      "resetting env. episode reward total was -1.0. running mean: -6.810590586193812\n",
      "resetting env. episode reward total was 4.0. running mean: -6.702484680331874\n",
      "resetting env. episode reward total was -8.0. running mean: -6.715459833528555\n",
      "resetting env. episode reward total was -13.0. running mean: -6.778305235193269\n",
      "resetting env. episode reward total was -8.0. running mean: -6.790522182841336\n",
      "resetting env. episode reward total was 4.0. running mean: -6.682616961012923\n",
      "resetting env. episode reward total was 1.0. running mean: -6.605790791402794\n",
      "resetting env. episode reward total was -6.0. running mean: -6.599732883488765\n",
      "resetting env. episode reward total was -5.0. running mean: -6.583735554653877\n",
      "resetting env. episode reward total was -1.0. running mean: -6.527898199107338\n",
      "resetting env. episode reward total was 2.0. running mean: -6.442619217116265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: -6.278193024945103\n",
      "resetting env. episode reward total was 3.0. running mean: -6.1854110946956515\n",
      "resetting env. episode reward total was -9.0. running mean: -6.213556983748695\n",
      "resetting env. episode reward total was -9.0. running mean: -6.241421413911207\n",
      "resetting env. episode reward total was -3.0. running mean: -6.2090071997720955\n",
      "resetting env. episode reward total was -2.0. running mean: -6.166917127774374\n",
      "resetting env. episode reward total was -2.0. running mean: -6.125247956496629\n",
      "resetting env. episode reward total was -10.0. running mean: -6.163995476931663\n",
      "resetting env. episode reward total was -9.0. running mean: -6.192355522162346\n",
      "resetting env. episode reward total was -11.0. running mean: -6.240431966940723\n",
      "resetting env. episode reward total was -6.0. running mean: -6.238027647271315\n",
      "resetting env. episode reward total was -11.0. running mean: -6.2856473707986025\n",
      "resetting env. episode reward total was -2.0. running mean: -6.242790897090616\n",
      "resetting env. episode reward total was -14.0. running mean: -6.32036298811971\n",
      "resetting env. episode reward total was -6.0. running mean: -6.317159358238512\n",
      "resetting env. episode reward total was -14.0. running mean: -6.393987764656126\n",
      "resetting env. episode reward total was -12.0. running mean: -6.450047887009565\n",
      "resetting env. episode reward total was -6.0. running mean: -6.445547408139469\n",
      "resetting env. episode reward total was -5.0. running mean: -6.431091934058074\n",
      "resetting env. episode reward total was -7.0. running mean: -6.436781014717494\n",
      "resetting env. episode reward total was 4.0. running mean: -6.332413204570319\n",
      "resetting env. episode reward total was -3.0. running mean: -6.299089072524616\n",
      "resetting env. episode reward total was -5.0. running mean: -6.286098181799369\n",
      "resetting env. episode reward total was -7.0. running mean: -6.293237199981376\n",
      "resetting env. episode reward total was -6.0. running mean: -6.290304827981561\n",
      "resetting env. episode reward total was -3.0. running mean: -6.257401779701746\n",
      "resetting env. episode reward total was -12.0. running mean: -6.314827761904728\n",
      "resetting env. episode reward total was -17.0. running mean: -6.42167948428568\n",
      "resetting env. episode reward total was -5.0. running mean: -6.4074626894428235\n",
      "resetting env. episode reward total was -3.0. running mean: -6.373388062548395\n",
      "resetting env. episode reward total was 3.0. running mean: -6.279654181922911\n",
      "resetting env. episode reward total was -6.0. running mean: -6.276857640103682\n",
      "resetting env. episode reward total was -8.0. running mean: -6.2940890637026445\n",
      "resetting env. episode reward total was -14.0. running mean: -6.371148173065618\n",
      "resetting env. episode reward total was -8.0. running mean: -6.387436691334962\n",
      "resetting env. episode reward total was -8.0. running mean: -6.403562324421612\n",
      "resetting env. episode reward total was -12.0. running mean: -6.4595267011773965\n",
      "resetting env. episode reward total was 4.0. running mean: -6.354931434165622\n",
      "resetting env. episode reward total was -7.0. running mean: -6.361382119823967\n",
      "resetting env. episode reward total was 3.0. running mean: -6.267768298625727\n",
      "resetting env. episode reward total was -8.0. running mean: -6.2850906156394695\n",
      "resetting env. episode reward total was -11.0. running mean: -6.332239709483075\n",
      "resetting env. episode reward total was 10.0. running mean: -6.168917312388245\n",
      "resetting env. episode reward total was -8.0. running mean: -6.187228139264362\n",
      "resetting env. episode reward total was -1.0. running mean: -6.135355857871718\n",
      "resetting env. episode reward total was -9.0. running mean: -6.164002299293001\n",
      "resetting env. episode reward total was -7.0. running mean: -6.172362276300071\n",
      "resetting env. episode reward total was -9.0. running mean: -6.20063865353707\n",
      "resetting env. episode reward total was -15.0. running mean: -6.2886322670017\n",
      "resetting env. episode reward total was -3.0. running mean: -6.255745944331683\n",
      "resetting env. episode reward total was -9.0. running mean: -6.283188484888366\n",
      "resetting env. episode reward total was -9.0. running mean: -6.310356600039482\n",
      "resetting env. episode reward total was -7.0. running mean: -6.317253034039087\n",
      "resetting env. episode reward total was -14.0. running mean: -6.394080503698696\n",
      "resetting env. episode reward total was 4.0. running mean: -6.290139698661709\n",
      "resetting env. episode reward total was -7.0. running mean: -6.297238301675092\n",
      "resetting env. episode reward total was -10.0. running mean: -6.334265918658341\n",
      "resetting env. episode reward total was -9.0. running mean: -6.3609232594717575\n",
      "resetting env. episode reward total was -11.0. running mean: -6.4073140268770405\n",
      "resetting env. episode reward total was 6.0. running mean: -6.2832408866082705\n",
      "resetting env. episode reward total was -9.0. running mean: -6.310408477742188\n",
      "resetting env. episode reward total was 2.0. running mean: -6.227304392964767\n",
      "resetting env. episode reward total was 6.0. running mean: -6.105031349035119\n",
      "resetting env. episode reward total was -4.0. running mean: -6.0839810355447685\n",
      "resetting env. episode reward total was -4.0. running mean: -6.06314122518932\n",
      "resetting env. episode reward total was -6.0. running mean: -6.062509812937427\n",
      "resetting env. episode reward total was -14.0. running mean: -6.141884714808053\n",
      "resetting env. episode reward total was -7.0. running mean: -6.150465867659973\n",
      "resetting env. episode reward total was -1.0. running mean: -6.098961208983373\n",
      "resetting env. episode reward total was -6.0. running mean: -6.097971596893538\n",
      "resetting env. episode reward total was -4.0. running mean: -6.076991880924603\n",
      "resetting env. episode reward total was -7.0. running mean: -6.086221962115357\n",
      "resetting env. episode reward total was -7.0. running mean: -6.095359742494204\n",
      "resetting env. episode reward total was -7.0. running mean: -6.104406145069262\n",
      "resetting env. episode reward total was -5.0. running mean: -6.09336208361857\n",
      "resetting env. episode reward total was -14.0. running mean: -6.172428462782384\n",
      "resetting env. episode reward total was 2.0. running mean: -6.09070417815456\n",
      "resetting env. episode reward total was -14.0. running mean: -6.169797136373014\n",
      "resetting env. episode reward total was -3.0. running mean: -6.138099165009284\n",
      "resetting env. episode reward total was -6.0. running mean: -6.136718173359191\n",
      "resetting env. episode reward total was -9.0. running mean: -6.165350991625599\n",
      "resetting env. episode reward total was -9.0. running mean: -6.193697481709343\n",
      "resetting env. episode reward total was -8.0. running mean: -6.211760506892249\n",
      "resetting env. episode reward total was -7.0. running mean: -6.219642901823327\n",
      "resetting env. episode reward total was -8.0. running mean: -6.237446472805093\n",
      "resetting env. episode reward total was 3.0. running mean: -6.145072008077042\n",
      "resetting env. episode reward total was 13.0. running mean: -5.953621287996271\n",
      "resetting env. episode reward total was 1.0. running mean: -5.8840850751163085\n",
      "resetting env. episode reward total was -9.0. running mean: -5.9152442243651455\n",
      "resetting env. episode reward total was 8.0. running mean: -5.776091782121494\n",
      "resetting env. episode reward total was -7.0. running mean: -5.7883308643002795\n",
      "resetting env. episode reward total was -1.0. running mean: -5.740447555657276\n",
      "resetting env. episode reward total was -1.0. running mean: -5.693043080100703\n",
      "resetting env. episode reward total was -18.0. running mean: -5.816112649299696\n",
      "resetting env. episode reward total was 1.0. running mean: -5.7479515228067\n",
      "resetting env. episode reward total was -4.0. running mean: -5.730472007578633\n",
      "resetting env. episode reward total was -8.0. running mean: -5.753167287502846\n",
      "resetting env. episode reward total was -12.0. running mean: -5.815635614627817\n",
      "resetting env. episode reward total was -3.0. running mean: -5.7874792584815395\n",
      "resetting env. episode reward total was -10.0. running mean: -5.829604465896724\n",
      "resetting env. episode reward total was -8.0. running mean: -5.851308421237756\n",
      "resetting env. episode reward total was -2.0. running mean: -5.812795337025378\n",
      "resetting env. episode reward total was 5.0. running mean: -5.704667383655124\n",
      "resetting env. episode reward total was -5.0. running mean: -5.6976207098185725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -11.0. running mean: -5.750644502720387\n",
      "resetting env. episode reward total was -7.0. running mean: -5.763138057693184\n",
      "resetting env. episode reward total was -4.0. running mean: -5.745506677116253\n",
      "resetting env. episode reward total was -7.0. running mean: -5.75805161034509\n",
      "resetting env. episode reward total was -2.0. running mean: -5.720471094241638\n",
      "resetting env. episode reward total was -7.0. running mean: -5.733266383299222\n",
      "resetting env. episode reward total was -6.0. running mean: -5.73593371946623\n",
      "resetting env. episode reward total was -6.0. running mean: -5.738574382271567\n",
      "resetting env. episode reward total was -9.0. running mean: -5.7711886384488515\n",
      "resetting env. episode reward total was -11.0. running mean: -5.823476752064363\n",
      "resetting env. episode reward total was -7.0. running mean: -5.835241984543719\n",
      "resetting env. episode reward total was -11.0. running mean: -5.886889564698283\n",
      "resetting env. episode reward total was -10.0. running mean: -5.9280206690513\n",
      "resetting env. episode reward total was 3.0. running mean: -5.838740462360787\n",
      "resetting env. episode reward total was 4.0. running mean: -5.740353057737178\n",
      "resetting env. episode reward total was -1.0. running mean: -5.692949527159806\n",
      "resetting env. episode reward total was -12.0. running mean: -5.756020031888208\n",
      "resetting env. episode reward total was -5.0. running mean: -5.748459831569326\n",
      "resetting env. episode reward total was -12.0. running mean: -5.810975233253632\n",
      "resetting env. episode reward total was -2.0. running mean: -5.772865480921095\n",
      "resetting env. episode reward total was -10.0. running mean: -5.815136826111884\n",
      "resetting env. episode reward total was -10.0. running mean: -5.856985457850764\n",
      "resetting env. episode reward total was 1.0. running mean: -5.788415603272257\n",
      "resetting env. episode reward total was -4.0. running mean: -5.770531447239534\n",
      "resetting env. episode reward total was -13.0. running mean: -5.842826132767139\n",
      "resetting env. episode reward total was -9.0. running mean: -5.874397871439467\n",
      "resetting env. episode reward total was -8.0. running mean: -5.895653892725073\n",
      "resetting env. episode reward total was -8.0. running mean: -5.916697353797822\n",
      "resetting env. episode reward total was -6.0. running mean: -5.917530380259843\n",
      "resetting env. episode reward total was 1.0. running mean: -5.848355076457245\n",
      "resetting env. episode reward total was -4.0. running mean: -5.829871525692672\n",
      "resetting env. episode reward total was -2.0. running mean: -5.791572810435745\n",
      "resetting env. episode reward total was -5.0. running mean: -5.783657082331387\n",
      "resetting env. episode reward total was -13.0. running mean: -5.855820511508073\n",
      "resetting env. episode reward total was -3.0. running mean: -5.827262306392992\n",
      "resetting env. episode reward total was -15.0. running mean: -5.9189896833290625\n",
      "resetting env. episode reward total was -13.0. running mean: -5.989799786495772\n",
      "resetting env. episode reward total was -17.0. running mean: -6.099901788630814\n",
      "resetting env. episode reward total was -13.0. running mean: -6.168902770744506\n",
      "resetting env. episode reward total was -2.0. running mean: -6.12721374303706\n",
      "resetting env. episode reward total was -8.0. running mean: -6.145941605606689\n",
      "resetting env. episode reward total was -9.0. running mean: -6.174482189550622\n",
      "resetting env. episode reward total was 10.0. running mean: -6.012737367655116\n",
      "resetting env. episode reward total was 5.0. running mean: -5.902609993978564\n",
      "resetting env. episode reward total was -6.0. running mean: -5.903583894038778\n",
      "resetting env. episode reward total was -4.0. running mean: -5.88454805509839\n",
      "resetting env. episode reward total was -8.0. running mean: -5.905702574547407\n",
      "resetting env. episode reward total was -11.0. running mean: -5.956645548801933\n",
      "resetting env. episode reward total was -4.0. running mean: -5.937079093313914\n",
      "resetting env. episode reward total was -3.0. running mean: -5.907708302380775\n",
      "resetting env. episode reward total was -4.0. running mean: -5.888631219356967\n",
      "resetting env. episode reward total was -10.0. running mean: -5.929744907163397\n",
      "resetting env. episode reward total was -10.0. running mean: -5.970447458091763\n",
      "resetting env. episode reward total was -7.0. running mean: -5.980742983510845\n",
      "resetting env. episode reward total was -13.0. running mean: -6.050935553675737\n",
      "resetting env. episode reward total was 4.0. running mean: -5.95042619813898\n",
      "resetting env. episode reward total was 2.0. running mean: -5.870921936157591\n",
      "resetting env. episode reward total was 1.0. running mean: -5.8022127167960145\n",
      "resetting env. episode reward total was -3.0. running mean: -5.774190589628055\n",
      "resetting env. episode reward total was -9.0. running mean: -5.806448683731774\n",
      "resetting env. episode reward total was 8.0. running mean: -5.668384196894456\n",
      "resetting env. episode reward total was -6.0. running mean: -5.671700354925511\n",
      "resetting env. episode reward total was -16.0. running mean: -5.774983351376256\n",
      "resetting env. episode reward total was -7.0. running mean: -5.787233517862494\n",
      "resetting env. episode reward total was -8.0. running mean: -5.809361182683869\n",
      "resetting env. episode reward total was -10.0. running mean: -5.85126757085703\n",
      "resetting env. episode reward total was -5.0. running mean: -5.84275489514846\n",
      "resetting env. episode reward total was -1.0. running mean: -5.794327346196975\n",
      "resetting env. episode reward total was -3.0. running mean: -5.766384072735006\n",
      "resetting env. episode reward total was -1.0. running mean: -5.718720232007656\n",
      "resetting env. episode reward total was 3.0. running mean: -5.631533029687579\n",
      "resetting env. episode reward total was -6.0. running mean: -5.635217699390703\n",
      "resetting env. episode reward total was -11.0. running mean: -5.688865522396796\n",
      "resetting env. episode reward total was -11.0. running mean: -5.741976867172828\n",
      "resetting env. episode reward total was -4.0. running mean: -5.7245570985011\n",
      "resetting env. episode reward total was -13.0. running mean: -5.797311527516088\n",
      "resetting env. episode reward total was -7.0. running mean: -5.809338412240928\n",
      "resetting env. episode reward total was -1.0. running mean: -5.761245028118519\n",
      "resetting env. episode reward total was -5.0. running mean: -5.753632577837333\n",
      "resetting env. episode reward total was -11.0. running mean: -5.8060962520589605\n",
      "resetting env. episode reward total was -12.0. running mean: -5.868035289538371\n",
      "resetting env. episode reward total was -12.0. running mean: -5.929354936642987\n",
      "resetting env. episode reward total was -3.0. running mean: -5.9000613872765575\n",
      "resetting env. episode reward total was -17.0. running mean: -6.011060773403792\n",
      "resetting env. episode reward total was -15.0. running mean: -6.1009501656697545\n",
      "resetting env. episode reward total was -5.0. running mean: -6.0899406640130564\n",
      "resetting env. episode reward total was -6.0. running mean: -6.089041257372926\n",
      "resetting env. episode reward total was -5.0. running mean: -6.078150844799196\n",
      "resetting env. episode reward total was -2.0. running mean: -6.037369336351204\n",
      "resetting env. episode reward total was -7.0. running mean: -6.046995642987692\n",
      "resetting env. episode reward total was -8.0. running mean: -6.066525686557815\n",
      "resetting env. episode reward total was -7.0. running mean: -6.075860429692238\n",
      "resetting env. episode reward total was -14.0. running mean: -6.155101825395315\n",
      "resetting env. episode reward total was -14.0. running mean: -6.233550807141361\n",
      "resetting env. episode reward total was -12.0. running mean: -6.291215299069948\n",
      "resetting env. episode reward total was -1.0. running mean: -6.2383031460792475\n",
      "resetting env. episode reward total was -6.0. running mean: -6.235920114618454\n",
      "resetting env. episode reward total was -11.0. running mean: -6.28356091347227\n",
      "resetting env. episode reward total was -1.0. running mean: -6.230725304337547\n",
      "resetting env. episode reward total was -6.0. running mean: -6.228418051294171\n",
      "resetting env. episode reward total was -10.0. running mean: -6.266133870781229\n",
      "resetting env. episode reward total was -11.0. running mean: -6.313472532073417\n",
      "resetting env. episode reward total was -10.0. running mean: -6.350337806752683\n",
      "resetting env. episode reward total was -12.0. running mean: -6.406834428685157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -2.0. running mean: -6.362766084398305\n",
      "resetting env. episode reward total was -17.0. running mean: -6.4691384235543214\n",
      "resetting env. episode reward total was -16.0. running mean: -6.564447039318778\n",
      "resetting env. episode reward total was 4.0. running mean: -6.45880256892559\n",
      "resetting env. episode reward total was -12.0. running mean: -6.514214543236334\n",
      "resetting env. episode reward total was -13.0. running mean: -6.57907239780397\n",
      "resetting env. episode reward total was -13.0. running mean: -6.64328167382593\n",
      "resetting env. episode reward total was -12.0. running mean: -6.696848857087671\n",
      "resetting env. episode reward total was -1.0. running mean: -6.639880368516795\n",
      "resetting env. episode reward total was -6.0. running mean: -6.6334815648316265\n",
      "resetting env. episode reward total was -18.0. running mean: -6.74714674918331\n",
      "resetting env. episode reward total was -17.0. running mean: -6.849675281691477\n",
      "resetting env. episode reward total was -14.0. running mean: -6.921178528874561\n",
      "resetting env. episode reward total was 4.0. running mean: -6.811966743585816\n",
      "resetting env. episode reward total was -13.0. running mean: -6.873847076149958\n",
      "resetting env. episode reward total was -16.0. running mean: -6.965108605388458\n",
      "resetting env. episode reward total was -15.0. running mean: -7.045457519334574\n",
      "resetting env. episode reward total was -7.0. running mean: -7.0450029441412285\n",
      "resetting env. episode reward total was -13.0. running mean: -7.104552914699816\n",
      "resetting env. episode reward total was -7.0. running mean: -7.103507385552819\n",
      "resetting env. episode reward total was -13.0. running mean: -7.16247231169729\n",
      "resetting env. episode reward total was -12.0. running mean: -7.210847588580317\n",
      "resetting env. episode reward total was -13.0. running mean: -7.268739112694514\n",
      "resetting env. episode reward total was -9.0. running mean: -7.286051721567569\n",
      "resetting env. episode reward total was -18.0. running mean: -7.393191204351893\n",
      "resetting env. episode reward total was -11.0. running mean: -7.429259292308374\n",
      "resetting env. episode reward total was -13.0. running mean: -7.48496669938529\n",
      "resetting env. episode reward total was -15.0. running mean: -7.560117032391438\n",
      "resetting env. episode reward total was -10.0. running mean: -7.584515862067523\n",
      "resetting env. episode reward total was -11.0. running mean: -7.618670703446848\n",
      "resetting env. episode reward total was -13.0. running mean: -7.67248399641238\n",
      "resetting env. episode reward total was -15.0. running mean: -7.745759156448257\n",
      "resetting env. episode reward total was -13.0. running mean: -7.798301564883774\n",
      "resetting env. episode reward total was -7.0. running mean: -7.790318549234937\n",
      "resetting env. episode reward total was -11.0. running mean: -7.8224153637425875\n",
      "resetting env. episode reward total was -15.0. running mean: -7.894191210105162\n",
      "resetting env. episode reward total was -9.0. running mean: -7.90524929800411\n",
      "resetting env. episode reward total was -13.0. running mean: -7.956196805024068\n",
      "resetting env. episode reward total was -9.0. running mean: -7.966634836973827\n",
      "resetting env. episode reward total was -6.0. running mean: -7.946968488604089\n",
      "resetting env. episode reward total was -9.0. running mean: -7.957498803718048\n",
      "resetting env. episode reward total was -9.0. running mean: -7.967923815680868\n",
      "resetting env. episode reward total was -9.0. running mean: -7.978244577524059\n",
      "resetting env. episode reward total was -4.0. running mean: -7.938462131748818\n",
      "resetting env. episode reward total was -6.0. running mean: -7.91907751043133\n",
      "resetting env. episode reward total was -9.0. running mean: -7.929886735327016\n",
      "resetting env. episode reward total was -17.0. running mean: -8.020587867973745\n",
      "resetting env. episode reward total was -10.0. running mean: -8.040381989294008\n",
      "resetting env. episode reward total was -8.0. running mean: -8.039978169401069\n",
      "resetting env. episode reward total was 8.0. running mean: -7.879578387707058\n",
      "resetting env. episode reward total was -19.0. running mean: -7.990782603829988\n",
      "resetting env. episode reward total was -8.0. running mean: -7.990874777791688\n",
      "resetting env. episode reward total was -16.0. running mean: -8.070966030013771\n",
      "resetting env. episode reward total was -13.0. running mean: -8.120256369713633\n",
      "resetting env. episode reward total was -3.0. running mean: -8.069053806016496\n",
      "resetting env. episode reward total was -10.0. running mean: -8.088363267956332\n",
      "resetting env. episode reward total was -10.0. running mean: -8.107479635276768\n",
      "resetting env. episode reward total was -11.0. running mean: -8.136404838924\n",
      "resetting env. episode reward total was -12.0. running mean: -8.175040790534759\n",
      "resetting env. episode reward total was 7.0. running mean: -8.02329038262941\n",
      "resetting env. episode reward total was -1.0. running mean: -7.953057478803116\n",
      "resetting env. episode reward total was -8.0. running mean: -7.953526904015084\n",
      "resetting env. episode reward total was -5.0. running mean: -7.923991634974933\n",
      "resetting env. episode reward total was -13.0. running mean: -7.974751718625184\n",
      "resetting env. episode reward total was -3.0. running mean: -7.925004201438932\n",
      "resetting env. episode reward total was -10.0. running mean: -7.945754159424542\n",
      "resetting env. episode reward total was -2.0. running mean: -7.886296617830296\n",
      "resetting env. episode reward total was -11.0. running mean: -7.917433651651994\n",
      "resetting env. episode reward total was -13.0. running mean: -7.968259315135474\n",
      "resetting env. episode reward total was -3.0. running mean: -7.918576721984119\n",
      "resetting env. episode reward total was -1.0. running mean: -7.849390954764278\n",
      "resetting env. episode reward total was -10.0. running mean: -7.870897045216635\n",
      "resetting env. episode reward total was -9.0. running mean: -7.882188074764469\n",
      "resetting env. episode reward total was -11.0. running mean: -7.913366194016824\n",
      "resetting env. episode reward total was -9.0. running mean: -7.924232532076656\n",
      "resetting env. episode reward total was -7.0. running mean: -7.914990206755889\n",
      "resetting env. episode reward total was -2.0. running mean: -7.85584030468833\n",
      "resetting env. episode reward total was -12.0. running mean: -7.897281901641447\n",
      "resetting env. episode reward total was -3.0. running mean: -7.848309082625033\n",
      "resetting env. episode reward total was -7.0. running mean: -7.839825991798782\n",
      "resetting env. episode reward total was -9.0. running mean: -7.851427731880794\n",
      "resetting env. episode reward total was -10.0. running mean: -7.872913454561986\n",
      "resetting env. episode reward total was 3.0. running mean: -7.764184320016366\n",
      "resetting env. episode reward total was -6.0. running mean: -7.7465424768162015\n",
      "resetting env. episode reward total was -11.0. running mean: -7.77907705204804\n",
      "resetting env. episode reward total was -7.0. running mean: -7.771286281527559\n",
      "resetting env. episode reward total was 9.0. running mean: -7.603573418712284\n",
      "resetting env. episode reward total was -7.0. running mean: -7.597537684525162\n",
      "resetting env. episode reward total was -18.0. running mean: -7.70156230767991\n",
      "resetting env. episode reward total was -9.0. running mean: -7.7145466846031105\n",
      "resetting env. episode reward total was -13.0. running mean: -7.7674012177570795\n",
      "resetting env. episode reward total was -3.0. running mean: -7.719727205579509\n",
      "resetting env. episode reward total was -10.0. running mean: -7.742529933523714\n",
      "resetting env. episode reward total was -5.0. running mean: -7.715104634188476\n",
      "resetting env. episode reward total was -2.0. running mean: -7.657953587846591\n",
      "resetting env. episode reward total was -5.0. running mean: -7.631374051968125\n",
      "resetting env. episode reward total was 4.0. running mean: -7.515060311448444\n",
      "resetting env. episode reward total was -15.0. running mean: -7.58990970833396\n",
      "resetting env. episode reward total was -3.0. running mean: -7.544010611250621\n",
      "resetting env. episode reward total was -11.0. running mean: -7.578570505138115\n",
      "resetting env. episode reward total was -11.0. running mean: -7.612784800086734\n",
      "resetting env. episode reward total was -9.0. running mean: -7.626656952085867\n",
      "resetting env. episode reward total was -19.0. running mean: -7.740390382565009\n",
      "resetting env. episode reward total was -19.0. running mean: -7.852986478739359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -12.0. running mean: -7.894456613951966\n",
      "resetting env. episode reward total was -10.0. running mean: -7.915512047812445\n",
      "resetting env. episode reward total was -5.0. running mean: -7.886356927334321\n",
      "resetting env. episode reward total was -4.0. running mean: -7.847493358060977\n",
      "resetting env. episode reward total was -11.0. running mean: -7.879018424480368\n",
      "resetting env. episode reward total was -10.0. running mean: -7.900228240235563\n",
      "resetting env. episode reward total was -9.0. running mean: -7.911225957833207\n",
      "resetting env. episode reward total was 5.0. running mean: -7.782113698254875\n",
      "resetting env. episode reward total was -2.0. running mean: -7.724292561272326\n",
      "resetting env. episode reward total was -17.0. running mean: -7.817049635659602\n",
      "resetting env. episode reward total was -10.0. running mean: -7.838879139303006\n",
      "resetting env. episode reward total was -7.0. running mean: -7.830490347909976\n",
      "resetting env. episode reward total was -16.0. running mean: -7.912185444430876\n",
      "resetting env. episode reward total was -5.0. running mean: -7.883063589986567\n",
      "resetting env. episode reward total was -3.0. running mean: -7.834232954086701\n",
      "resetting env. episode reward total was -2.0. running mean: -7.775890624545834\n",
      "resetting env. episode reward total was -13.0. running mean: -7.828131718300376\n",
      "resetting env. episode reward total was -13.0. running mean: -7.879850401117372\n",
      "resetting env. episode reward total was -9.0. running mean: -7.891051897106197\n",
      "resetting env. episode reward total was -9.0. running mean: -7.902141378135135\n",
      "resetting env. episode reward total was -16.0. running mean: -7.983119964353784\n",
      "resetting env. episode reward total was -9.0. running mean: -7.993288764710246\n",
      "resetting env. episode reward total was -7.0. running mean: -7.983355877063143\n",
      "resetting env. episode reward total was -8.0. running mean: -7.983522318292512\n",
      "resetting env. episode reward total was -9.0. running mean: -7.993687095109586\n",
      "resetting env. episode reward total was -11.0. running mean: -8.02375022415849\n",
      "resetting env. episode reward total was -6.0. running mean: -8.003512721916906\n",
      "resetting env. episode reward total was 1.0. running mean: -7.913477594697737\n",
      "resetting env. episode reward total was 7.0. running mean: -7.764342818750759\n",
      "resetting env. episode reward total was -8.0. running mean: -7.766699390563251\n",
      "resetting env. episode reward total was -1.0. running mean: -7.699032396657619\n",
      "resetting env. episode reward total was -9.0. running mean: -7.712042072691042\n",
      "resetting env. episode reward total was -10.0. running mean: -7.7349216519641315\n",
      "resetting env. episode reward total was -9.0. running mean: -7.74757243544449\n",
      "resetting env. episode reward total was -11.0. running mean: -7.780096711090046\n",
      "resetting env. episode reward total was -12.0. running mean: -7.822295743979145\n",
      "resetting env. episode reward total was -6.0. running mean: -7.804072786539353\n",
      "resetting env. episode reward total was -10.0. running mean: -7.82603205867396\n",
      "resetting env. episode reward total was -12.0. running mean: -7.86777173808722\n",
      "resetting env. episode reward total was -3.0. running mean: -7.819094020706348\n",
      "resetting env. episode reward total was -15.0. running mean: -7.890903080499285\n",
      "resetting env. episode reward total was -16.0. running mean: -7.971994049694293\n",
      "resetting env. episode reward total was -10.0. running mean: -7.992274109197349\n",
      "resetting env. episode reward total was -3.0. running mean: -7.942351368105376\n",
      "resetting env. episode reward total was -17.0. running mean: -8.032927854424322\n",
      "resetting env. episode reward total was -4.0. running mean: -7.992598575880079\n",
      "resetting env. episode reward total was -8.0. running mean: -7.992672590121278\n",
      "resetting env. episode reward total was -1.0. running mean: -7.922745864220065\n",
      "resetting env. episode reward total was -13.0. running mean: -7.973518405577864\n",
      "resetting env. episode reward total was -6.0. running mean: -7.953783221522085\n",
      "resetting env. episode reward total was -1.0. running mean: -7.884245389306864\n",
      "resetting env. episode reward total was -4.0. running mean: -7.845402935413795\n",
      "resetting env. episode reward total was -11.0. running mean: -7.876948906059658\n",
      "resetting env. episode reward total was -13.0. running mean: -7.928179416999061\n",
      "resetting env. episode reward total was -1.0. running mean: -7.85889762282907\n",
      "resetting env. episode reward total was -7.0. running mean: -7.850308646600779\n",
      "resetting env. episode reward total was -15.0. running mean: -7.921805560134771\n",
      "resetting env. episode reward total was -13.0. running mean: -7.972587504533424\n",
      "resetting env. episode reward total was -7.0. running mean: -7.962861629488089\n",
      "resetting env. episode reward total was -8.0. running mean: -7.963233013193208\n",
      "resetting env. episode reward total was -2.0. running mean: -7.903600683061276\n",
      "resetting env. episode reward total was -7.0. running mean: -7.894564676230663\n",
      "resetting env. episode reward total was -14.0. running mean: -7.955619029468356\n",
      "resetting env. episode reward total was 3.0. running mean: -7.846062839173673\n",
      "resetting env. episode reward total was -8.0. running mean: -7.847602210781936\n",
      "resetting env. episode reward total was -14.0. running mean: -7.909126188674116\n",
      "resetting env. episode reward total was -17.0. running mean: -8.000034926787375\n",
      "resetting env. episode reward total was -11.0. running mean: -8.030034577519501\n",
      "resetting env. episode reward total was -2.0. running mean: -7.969734231744305\n",
      "resetting env. episode reward total was -8.0. running mean: -7.970036889426862\n",
      "resetting env. episode reward total was -9.0. running mean: -7.980336520532593\n",
      "resetting env. episode reward total was -5.0. running mean: -7.950533155327268\n",
      "resetting env. episode reward total was -10.0. running mean: -7.971027823773994\n",
      "resetting env. episode reward total was -7.0. running mean: -7.961317545536255\n",
      "resetting env. episode reward total was -17.0. running mean: -8.051704370080893\n",
      "resetting env. episode reward total was -6.0. running mean: -8.031187326380085\n",
      "resetting env. episode reward total was -7.0. running mean: -8.020875453116284\n",
      "resetting env. episode reward total was 4.0. running mean: -7.9006666985851215\n",
      "resetting env. episode reward total was -9.0. running mean: -7.91166003159927\n",
      "resetting env. episode reward total was -9.0. running mean: -7.922543431283278\n",
      "resetting env. episode reward total was -8.0. running mean: -7.923317996970445\n",
      "resetting env. episode reward total was -6.0. running mean: -7.90408481700074\n",
      "resetting env. episode reward total was 2.0. running mean: -7.805043968830733\n",
      "resetting env. episode reward total was -9.0. running mean: -7.816993529142426\n",
      "resetting env. episode reward total was -2.0. running mean: -7.758823593851001\n",
      "resetting env. episode reward total was -11.0. running mean: -7.791235357912491\n",
      "resetting env. episode reward total was -1.0. running mean: -7.723323004333366\n",
      "resetting env. episode reward total was -10.0. running mean: -7.7460897742900325\n",
      "resetting env. episode reward total was -2.0. running mean: -7.688628876547131\n",
      "resetting env. episode reward total was -11.0. running mean: -7.721742587781661\n",
      "resetting env. episode reward total was -6.0. running mean: -7.7045251619038435\n",
      "resetting env. episode reward total was 8.0. running mean: -7.547479910284805\n",
      "resetting env. episode reward total was -1.0. running mean: -7.482005111181957\n",
      "resetting env. episode reward total was -8.0. running mean: -7.4871850600701375\n",
      "resetting env. episode reward total was -8.0. running mean: -7.492313209469436\n",
      "resetting env. episode reward total was -1.0. running mean: -7.427390077374741\n",
      "resetting env. episode reward total was -12.0. running mean: -7.4731161766009935\n",
      "resetting env. episode reward total was -9.0. running mean: -7.488385014834983\n",
      "resetting env. episode reward total was -12.0. running mean: -7.5335011646866334\n",
      "resetting env. episode reward total was -9.0. running mean: -7.548166153039767\n",
      "resetting env. episode reward total was -8.0. running mean: -7.552684491509369\n",
      "resetting env. episode reward total was -13.0. running mean: -7.607157646594276\n",
      "resetting env. episode reward total was -14.0. running mean: -7.671086070128332\n",
      "resetting env. episode reward total was -7.0. running mean: -7.66437520942705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: -7.6677314573327795\n",
      "resetting env. episode reward total was -15.0. running mean: -7.741054142759452\n",
      "resetting env. episode reward total was -9.0. running mean: -7.7536436013318575\n",
      "resetting env. episode reward total was -12.0. running mean: -7.7961071653185385\n",
      "resetting env. episode reward total was -5.0. running mean: -7.768146093665353\n",
      "resetting env. episode reward total was -6.0. running mean: -7.750464632728699\n",
      "resetting env. episode reward total was -9.0. running mean: -7.762959986401412\n",
      "resetting env. episode reward total was -8.0. running mean: -7.765330386537397\n",
      "resetting env. episode reward total was -13.0. running mean: -7.817677082672023\n",
      "resetting env. episode reward total was -14.0. running mean: -7.879500311845302\n",
      "resetting env. episode reward total was -15.0. running mean: -7.950705308726849\n",
      "resetting env. episode reward total was -2.0. running mean: -7.89119825563958\n",
      "resetting env. episode reward total was -10.0. running mean: -7.9122862730831836\n",
      "resetting env. episode reward total was -9.0. running mean: -7.923163410352352\n",
      "resetting env. episode reward total was -9.0. running mean: -7.933931776248828\n",
      "resetting env. episode reward total was -5.0. running mean: -7.90459245848634\n",
      "resetting env. episode reward total was -9.0. running mean: -7.915546533901476\n",
      "resetting env. episode reward total was -13.0. running mean: -7.966391068562461\n",
      "resetting env. episode reward total was -8.0. running mean: -7.966727157876837\n",
      "resetting env. episode reward total was -8.0. running mean: -7.967059886298069\n",
      "resetting env. episode reward total was -12.0. running mean: -8.007389287435087\n",
      "resetting env. episode reward total was -10.0. running mean: -8.027315394560736\n",
      "resetting env. episode reward total was -12.0. running mean: -8.067042240615129\n",
      "resetting env. episode reward total was -13.0. running mean: -8.116371818208977\n",
      "resetting env. episode reward total was -15.0. running mean: -8.185208100026887\n",
      "resetting env. episode reward total was -13.0. running mean: -8.233356019026619\n",
      "resetting env. episode reward total was -16.0. running mean: -8.311022458836353\n",
      "resetting env. episode reward total was -4.0. running mean: -8.267912234247989\n",
      "resetting env. episode reward total was 1.0. running mean: -8.17523311190551\n",
      "resetting env. episode reward total was -3.0. running mean: -8.123480780786453\n",
      "resetting env. episode reward total was -11.0. running mean: -8.152245972978587\n",
      "resetting env. episode reward total was -8.0. running mean: -8.150723513248801\n",
      "resetting env. episode reward total was -14.0. running mean: -8.209216278116314\n",
      "resetting env. episode reward total was -13.0. running mean: -8.25712411533515\n",
      "resetting env. episode reward total was -11.0. running mean: -8.284552874181799\n",
      "resetting env. episode reward total was -10.0. running mean: -8.301707345439981\n",
      "resetting env. episode reward total was -10.0. running mean: -8.31869027198558\n",
      "resetting env. episode reward total was -11.0. running mean: -8.345503369265725\n",
      "resetting env. episode reward total was -16.0. running mean: -8.422048335573068\n",
      "resetting env. episode reward total was -4.0. running mean: -8.377827852217337\n",
      "resetting env. episode reward total was -6.0. running mean: -8.354049573695164\n",
      "resetting env. episode reward total was -13.0. running mean: -8.400509077958214\n",
      "resetting env. episode reward total was -9.0. running mean: -8.406503987178631\n",
      "resetting env. episode reward total was -8.0. running mean: -8.402438947306845\n",
      "resetting env. episode reward total was -13.0. running mean: -8.448414557833777\n",
      "resetting env. episode reward total was -11.0. running mean: -8.473930412255438\n",
      "resetting env. episode reward total was -18.0. running mean: -8.569191108132884\n",
      "resetting env. episode reward total was -15.0. running mean: -8.633499197051556\n",
      "resetting env. episode reward total was -11.0. running mean: -8.65716420508104\n",
      "resetting env. episode reward total was -13.0. running mean: -8.70059256303023\n",
      "resetting env. episode reward total was -15.0. running mean: -8.763586637399928\n",
      "resetting env. episode reward total was -11.0. running mean: -8.785950771025929\n",
      "resetting env. episode reward total was -11.0. running mean: -8.808091263315669\n",
      "resetting env. episode reward total was -4.0. running mean: -8.760010350682512\n",
      "resetting env. episode reward total was -13.0. running mean: -8.802410247175688\n",
      "resetting env. episode reward total was -14.0. running mean: -8.854386144703932\n",
      "resetting env. episode reward total was -8.0. running mean: -8.845842283256893\n",
      "resetting env. episode reward total was -5.0. running mean: -8.807383860424325\n",
      "resetting env. episode reward total was -10.0. running mean: -8.819310021820082\n",
      "resetting env. episode reward total was -13.0. running mean: -8.861116921601882\n",
      "resetting env. episode reward total was -8.0. running mean: -8.852505752385863\n",
      "resetting env. episode reward total was -8.0. running mean: -8.843980694862005\n",
      "resetting env. episode reward total was -11.0. running mean: -8.865540887913383\n",
      "resetting env. episode reward total was -5.0. running mean: -8.82688547903425\n",
      "resetting env. episode reward total was -11.0. running mean: -8.848616624243906\n",
      "resetting env. episode reward total was -12.0. running mean: -8.880130458001465\n",
      "resetting env. episode reward total was -1.0. running mean: -8.80132915342145\n",
      "resetting env. episode reward total was -7.0. running mean: -8.783315861887237\n",
      "resetting env. episode reward total was -17.0. running mean: -8.865482703268365\n",
      "resetting env. episode reward total was -9.0. running mean: -8.86682787623568\n",
      "resetting env. episode reward total was -10.0. running mean: -8.878159597473323\n",
      "resetting env. episode reward total was -17.0. running mean: -8.959378001498589\n",
      "resetting env. episode reward total was -14.0. running mean: -9.009784221483603\n",
      "resetting env. episode reward total was -7.0. running mean: -8.989686379268766\n",
      "resetting env. episode reward total was -10.0. running mean: -8.999789515476078\n",
      "resetting env. episode reward total was -10.0. running mean: -9.009791620321316\n",
      "resetting env. episode reward total was -13.0. running mean: -9.049693704118104\n",
      "resetting env. episode reward total was 2.0. running mean: -8.939196767076924\n",
      "resetting env. episode reward total was -15.0. running mean: -8.999804799406155\n",
      "resetting env. episode reward total was 7.0. running mean: -8.839806751412093\n",
      "resetting env. episode reward total was -5.0. running mean: -8.801408683897973\n",
      "resetting env. episode reward total was -8.0. running mean: -8.793394597058994\n",
      "resetting env. episode reward total was -12.0. running mean: -8.825460651088402\n",
      "resetting env. episode reward total was -6.0. running mean: -8.79720604457752\n",
      "resetting env. episode reward total was -11.0. running mean: -8.819233984131744\n",
      "resetting env. episode reward total was -11.0. running mean: -8.841041644290426\n",
      "resetting env. episode reward total was -10.0. running mean: -8.852631227847521\n",
      "resetting env. episode reward total was -9.0. running mean: -8.854104915569046\n",
      "resetting env. episode reward total was -4.0. running mean: -8.805563866413355\n",
      "resetting env. episode reward total was -1.0. running mean: -8.72750822774922\n",
      "resetting env. episode reward total was -11.0. running mean: -8.750233145471729\n",
      "resetting env. episode reward total was 5.0. running mean: -8.612730814017011\n",
      "resetting env. episode reward total was -9.0. running mean: -8.61660350587684\n",
      "resetting env. episode reward total was 2.0. running mean: -8.510437470818072\n",
      "resetting env. episode reward total was 6.0. running mean: -8.365333096109891\n",
      "resetting env. episode reward total was -12.0. running mean: -8.401679765148792\n",
      "resetting env. episode reward total was 4.0. running mean: -8.277662967497305\n",
      "resetting env. episode reward total was -9.0. running mean: -8.284886337822332\n",
      "resetting env. episode reward total was -3.0. running mean: -8.232037474444107\n",
      "resetting env. episode reward total was -1.0. running mean: -8.159717099699666\n",
      "resetting env. episode reward total was -9.0. running mean: -8.16811992870267\n",
      "resetting env. episode reward total was -11.0. running mean: -8.196438729415641\n",
      "resetting env. episode reward total was -7.0. running mean: -8.184474342121485\n",
      "resetting env. episode reward total was -8.0. running mean: -8.18262959870027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -2.0. running mean: -8.120803302713266\n",
      "resetting env. episode reward total was -11.0. running mean: -8.149595269686133\n",
      "resetting env. episode reward total was -15.0. running mean: -8.21809931698927\n",
      "resetting env. episode reward total was -7.0. running mean: -8.205918323819379\n",
      "resetting env. episode reward total was 4.0. running mean: -8.083859140581186\n",
      "resetting env. episode reward total was -5.0. running mean: -8.053020549175375\n",
      "resetting env. episode reward total was -9.0. running mean: -8.062490343683622\n",
      "resetting env. episode reward total was 2.0. running mean: -7.961865440246786\n",
      "resetting env. episode reward total was -9.0. running mean: -7.972246785844318\n",
      "resetting env. episode reward total was 9.0. running mean: -7.802524317985875\n",
      "resetting env. episode reward total was -7.0. running mean: -7.794499074806017\n",
      "resetting env. episode reward total was -11.0. running mean: -7.826554084057957\n",
      "resetting env. episode reward total was -15.0. running mean: -7.898288543217378\n",
      "resetting env. episode reward total was -11.0. running mean: -7.929305657785204\n",
      "resetting env. episode reward total was -8.0. running mean: -7.930012601207352\n",
      "resetting env. episode reward total was -10.0. running mean: -7.950712475195278\n",
      "resetting env. episode reward total was -1.0. running mean: -7.881205350443325\n",
      "resetting env. episode reward total was -7.0. running mean: -7.872393296938892\n",
      "resetting env. episode reward total was -3.0. running mean: -7.823669363969503\n",
      "resetting env. episode reward total was -12.0. running mean: -7.865432670329808\n",
      "resetting env. episode reward total was -7.0. running mean: -7.85677834362651\n",
      "resetting env. episode reward total was -7.0. running mean: -7.848210560190245\n",
      "resetting env. episode reward total was -4.0. running mean: -7.809728454588343\n",
      "resetting env. episode reward total was 2.0. running mean: -7.71163117004246\n",
      "resetting env. episode reward total was -8.0. running mean: -7.714514858342035\n",
      "resetting env. episode reward total was -4.0. running mean: -7.677369709758615\n",
      "resetting env. episode reward total was -9.0. running mean: -7.690596012661029\n",
      "resetting env. episode reward total was -7.0. running mean: -7.683690052534419\n",
      "resetting env. episode reward total was -9.0. running mean: -7.696853152009075\n",
      "resetting env. episode reward total was -5.0. running mean: -7.6698846204889835\n",
      "resetting env. episode reward total was -1.0. running mean: -7.603185774284094\n",
      "resetting env. episode reward total was 7.0. running mean: -7.457153916541253\n",
      "resetting env. episode reward total was -4.0. running mean: -7.42258237737584\n",
      "resetting env. episode reward total was 1.0. running mean: -7.338356553602082\n",
      "resetting env. episode reward total was 3.0. running mean: -7.23497298806606\n",
      "resetting env. episode reward total was -3.0. running mean: -7.1926232581853995\n",
      "resetting env. episode reward total was 4.0. running mean: -7.080697025603546\n",
      "resetting env. episode reward total was -1.0. running mean: -7.01989005534751\n",
      "resetting env. episode reward total was 5.0. running mean: -6.899691154794035\n",
      "resetting env. episode reward total was -11.0. running mean: -6.940694243246095\n",
      "resetting env. episode reward total was -2.0. running mean: -6.891287300813634\n",
      "resetting env. episode reward total was -2.0. running mean: -6.842374427805497\n",
      "resetting env. episode reward total was -5.0. running mean: -6.823950683527442\n",
      "resetting env. episode reward total was -6.0. running mean: -6.815711176692167\n",
      "resetting env. episode reward total was -8.0. running mean: -6.827554064925246\n",
      "resetting env. episode reward total was -9.0. running mean: -6.849278524275993\n",
      "resetting env. episode reward total was -11.0. running mean: -6.890785739033234\n",
      "resetting env. episode reward total was -4.0. running mean: -6.861877881642902\n",
      "resetting env. episode reward total was -5.0. running mean: -6.843259102826472\n",
      "resetting env. episode reward total was -5.0. running mean: -6.824826511798207\n",
      "resetting env. episode reward total was -5.0. running mean: -6.806578246680225\n",
      "resetting env. episode reward total was -7.0. running mean: -6.808512464213423\n",
      "resetting env. episode reward total was -7.0. running mean: -6.810427339571289\n",
      "resetting env. episode reward total was -7.0. running mean: -6.812323066175576\n",
      "resetting env. episode reward total was -1.0. running mean: -6.754199835513821\n",
      "resetting env. episode reward total was -7.0. running mean: -6.7566578371586825\n",
      "resetting env. episode reward total was 1.0. running mean: -6.679091258787095\n",
      "resetting env. episode reward total was -8.0. running mean: -6.692300346199224\n",
      "resetting env. episode reward total was 1.0. running mean: -6.615377342737232\n",
      "resetting env. episode reward total was -7.0. running mean: -6.61922356930986\n",
      "resetting env. episode reward total was -9.0. running mean: -6.643031333616761\n",
      "resetting env. episode reward total was -6.0. running mean: -6.636601020280593\n",
      "resetting env. episode reward total was -11.0. running mean: -6.680235010077787\n",
      "resetting env. episode reward total was -5.0. running mean: -6.663432659977009\n",
      "resetting env. episode reward total was -10.0. running mean: -6.696798333377239\n",
      "resetting env. episode reward total was -17.0. running mean: -6.799830350043466\n",
      "resetting env. episode reward total was -9.0. running mean: -6.821832046543031\n",
      "resetting env. episode reward total was -10.0. running mean: -6.853613726077601\n",
      "resetting env. episode reward total was -14.0. running mean: -6.925077588816825\n",
      "resetting env. episode reward total was -2.0. running mean: -6.875826812928656\n",
      "resetting env. episode reward total was 3.0. running mean: -6.777068544799369\n",
      "resetting env. episode reward total was -11.0. running mean: -6.819297859351376\n",
      "resetting env. episode reward total was 7.0. running mean: -6.681104880757862\n",
      "resetting env. episode reward total was -11.0. running mean: -6.724293831950283\n",
      "resetting env. episode reward total was -14.0. running mean: -6.79705089363078\n",
      "resetting env. episode reward total was -12.0. running mean: -6.849080384694472\n",
      "resetting env. episode reward total was -8.0. running mean: -6.860589580847527\n",
      "resetting env. episode reward total was -10.0. running mean: -6.891983685039051\n",
      "resetting env. episode reward total was -13.0. running mean: -6.95306384818866\n",
      "resetting env. episode reward total was -9.0. running mean: -6.9735332097067735\n",
      "resetting env. episode reward total was -11.0. running mean: -7.013797877609706\n",
      "resetting env. episode reward total was -8.0. running mean: -7.023659898833609\n",
      "resetting env. episode reward total was -11.0. running mean: -7.063423299845273\n",
      "resetting env. episode reward total was -4.0. running mean: -7.032789066846821\n",
      "resetting env. episode reward total was -8.0. running mean: -7.042461176178352\n",
      "resetting env. episode reward total was 6.0. running mean: -6.912036564416569\n",
      "resetting env. episode reward total was 4.0. running mean: -6.802916198772404\n",
      "resetting env. episode reward total was -13.0. running mean: -6.86488703678468\n",
      "resetting env. episode reward total was -2.0. running mean: -6.8162381664168326\n",
      "resetting env. episode reward total was -5.0. running mean: -6.798075784752664\n",
      "resetting env. episode reward total was -3.0. running mean: -6.760095026905137\n",
      "resetting env. episode reward total was -3.0. running mean: -6.722494076636086\n",
      "resetting env. episode reward total was -11.0. running mean: -6.765269135869725\n",
      "resetting env. episode reward total was -4.0. running mean: -6.737616444511028\n",
      "resetting env. episode reward total was -13.0. running mean: -6.800240280065918\n",
      "resetting env. episode reward total was -16.0. running mean: -6.892237877265258\n",
      "resetting env. episode reward total was -7.0. running mean: -6.893315498492606\n",
      "resetting env. episode reward total was -1.0. running mean: -6.83438234350768\n",
      "resetting env. episode reward total was -10.0. running mean: -6.866038520072602\n",
      "resetting env. episode reward total was -7.0. running mean: -6.867378134871877\n",
      "resetting env. episode reward total was -5.0. running mean: -6.848704353523158\n",
      "resetting env. episode reward total was -8.0. running mean: -6.8602173099879264\n",
      "resetting env. episode reward total was -9.0. running mean: -6.881615136888047\n",
      "resetting env. episode reward total was 1.0. running mean: -6.802798985519167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -11.0. running mean: -6.844770995663976\n",
      "resetting env. episode reward total was -13.0. running mean: -6.906323285707336\n",
      "resetting env. episode reward total was -6.0. running mean: -6.897260052850262\n",
      "resetting env. episode reward total was -18.0. running mean: -7.008287452321759\n",
      "resetting env. episode reward total was -12.0. running mean: -7.058204577798541\n",
      "resetting env. episode reward total was -9.0. running mean: -7.0776225320205555\n",
      "resetting env. episode reward total was -10.0. running mean: -7.10684630670035\n",
      "resetting env. episode reward total was -12.0. running mean: -7.155777843633346\n",
      "resetting env. episode reward total was -9.0. running mean: -7.174220065197012\n",
      "resetting env. episode reward total was -10.0. running mean: -7.202477864545042\n",
      "resetting env. episode reward total was -4.0. running mean: -7.170453085899592\n",
      "resetting env. episode reward total was -10.0. running mean: -7.198748555040595\n",
      "resetting env. episode reward total was -11.0. running mean: -7.236761069490189\n",
      "resetting env. episode reward total was -5.0. running mean: -7.214393458795287\n",
      "resetting env. episode reward total was -1.0. running mean: -7.152249524207334\n",
      "resetting env. episode reward total was -17.0. running mean: -7.250727028965261\n",
      "resetting env. episode reward total was -8.0. running mean: -7.258219758675608\n",
      "resetting env. episode reward total was -13.0. running mean: -7.3156375610888515\n",
      "resetting env. episode reward total was -12.0. running mean: -7.3624811854779635\n",
      "resetting env. episode reward total was -7.0. running mean: -7.358856373623184\n",
      "resetting env. episode reward total was -10.0. running mean: -7.385267809886952\n",
      "resetting env. episode reward total was -4.0. running mean: -7.351415131788082\n",
      "resetting env. episode reward total was -7.0. running mean: -7.347900980470201\n",
      "resetting env. episode reward total was -3.0. running mean: -7.3044219706655\n",
      "resetting env. episode reward total was -17.0. running mean: -7.4013777509588445\n",
      "resetting env. episode reward total was -15.0. running mean: -7.477363973449257\n",
      "resetting env. episode reward total was -3.0. running mean: -7.4325903337147645\n",
      "resetting env. episode reward total was -4.0. running mean: -7.398264430377617\n",
      "resetting env. episode reward total was -4.0. running mean: -7.364281786073841\n",
      "resetting env. episode reward total was 7.0. running mean: -7.220638968213102\n",
      "resetting env. episode reward total was -1.0. running mean: -7.15843257853097\n",
      "resetting env. episode reward total was -1.0. running mean: -7.0968482527456604\n",
      "resetting env. episode reward total was 1.0. running mean: -7.015879770218204\n",
      "resetting env. episode reward total was -10.0. running mean: -7.045720972516022\n",
      "resetting env. episode reward total was -17.0. running mean: -7.1452637627908615\n",
      "resetting env. episode reward total was -15.0. running mean: -7.223811125162953\n",
      "resetting env. episode reward total was 9.0. running mean: -7.061573013911324\n",
      "resetting env. episode reward total was -11.0. running mean: -7.10095728377221\n",
      "resetting env. episode reward total was -11.0. running mean: -7.139947710934488\n",
      "resetting env. episode reward total was -10.0. running mean: -7.168548233825143\n",
      "resetting env. episode reward total was -6.0. running mean: -7.156862751486891\n",
      "resetting env. episode reward total was -11.0. running mean: -7.1952941239720225\n",
      "resetting env. episode reward total was -1.0. running mean: -7.133341182732302\n",
      "resetting env. episode reward total was 2.0. running mean: -7.042007770904979\n",
      "resetting env. episode reward total was -5.0. running mean: -7.0215876931959285\n",
      "resetting env. episode reward total was -15.0. running mean: -7.10137181626397\n",
      "resetting env. episode reward total was -8.0. running mean: -7.11035809810133\n",
      "resetting env. episode reward total was 5.0. running mean: -6.989254517120317\n",
      "resetting env. episode reward total was -9.0. running mean: -7.009361971949113\n",
      "resetting env. episode reward total was 2.0. running mean: -6.919268352229623\n",
      "resetting env. episode reward total was 3.0. running mean: -6.820075668707326\n",
      "resetting env. episode reward total was -10.0. running mean: -6.851874912020253\n",
      "resetting env. episode reward total was -6.0. running mean: -6.84335616290005\n",
      "resetting env. episode reward total was 1.0. running mean: -6.764922601271049\n",
      "resetting env. episode reward total was -5.0. running mean: -6.747273375258339\n",
      "resetting env. episode reward total was -8.0. running mean: -6.759800641505755\n",
      "resetting env. episode reward total was -7.0. running mean: -6.7622026350906985\n",
      "resetting env. episode reward total was -13.0. running mean: -6.824580608739791\n",
      "resetting env. episode reward total was -8.0. running mean: -6.836334802652393\n",
      "resetting env. episode reward total was -13.0. running mean: -6.8979714546258695\n",
      "resetting env. episode reward total was -6.0. running mean: -6.88899174007961\n",
      "resetting env. episode reward total was -11.0. running mean: -6.9301018226788145\n",
      "resetting env. episode reward total was -9.0. running mean: -6.950800804452026\n",
      "resetting env. episode reward total was -5.0. running mean: -6.931292796407505\n",
      "resetting env. episode reward total was -8.0. running mean: -6.94197986844343\n",
      "resetting env. episode reward total was -17.0. running mean: -7.042560069758996\n",
      "resetting env. episode reward total was -9.0. running mean: -7.062134469061406\n",
      "resetting env. episode reward total was -13.0. running mean: -7.121513124370792\n",
      "resetting env. episode reward total was -14.0. running mean: -7.190297993127084\n",
      "resetting env. episode reward total was -15.0. running mean: -7.268395013195813\n",
      "resetting env. episode reward total was -15.0. running mean: -7.345711063063855\n",
      "resetting env. episode reward total was -10.0. running mean: -7.3722539524332165\n",
      "resetting env. episode reward total was -1.0. running mean: -7.308531412908884\n",
      "resetting env. episode reward total was 4.0. running mean: -7.1954460987797955\n",
      "resetting env. episode reward total was -11.0. running mean: -7.233491637791998\n",
      "resetting env. episode reward total was -13.0. running mean: -7.291156721414078\n",
      "resetting env. episode reward total was -12.0. running mean: -7.338245154199937\n",
      "resetting env. episode reward total was -9.0. running mean: -7.354862702657937\n",
      "resetting env. episode reward total was -10.0. running mean: -7.381314075631357\n",
      "resetting env. episode reward total was 5.0. running mean: -7.257500934875043\n",
      "resetting env. episode reward total was -17.0. running mean: -7.354925925526293\n",
      "resetting env. episode reward total was -17.0. running mean: -7.451376666271029\n",
      "resetting env. episode reward total was -8.0. running mean: -7.456862899608319\n",
      "resetting env. episode reward total was -1.0. running mean: -7.392294270612235\n",
      "resetting env. episode reward total was -13.0. running mean: -7.448371327906113\n",
      "resetting env. episode reward total was -8.0. running mean: -7.453887614627051\n",
      "resetting env. episode reward total was -7.0. running mean: -7.449348738480781\n",
      "resetting env. episode reward total was 5.0. running mean: -7.324855251095974\n",
      "resetting env. episode reward total was -5.0. running mean: -7.301606698585013\n",
      "resetting env. episode reward total was -12.0. running mean: -7.348590631599163\n",
      "resetting env. episode reward total was -10.0. running mean: -7.375104725283171\n",
      "resetting env. episode reward total was -14.0. running mean: -7.441353678030339\n",
      "resetting env. episode reward total was -10.0. running mean: -7.466940141250035\n",
      "resetting env. episode reward total was -16.0. running mean: -7.552270739837534\n",
      "resetting env. episode reward total was -11.0. running mean: -7.586748032439159\n",
      "resetting env. episode reward total was -6.0. running mean: -7.570880552114767\n",
      "resetting env. episode reward total was -9.0. running mean: -7.585171746593619\n",
      "resetting env. episode reward total was -13.0. running mean: -7.639320029127682\n",
      "resetting env. episode reward total was -3.0. running mean: -7.592926828836405\n",
      "resetting env. episode reward total was -11.0. running mean: -7.626997560548041\n",
      "resetting env. episode reward total was -2.0. running mean: -7.57072758494256\n",
      "resetting env. episode reward total was -6.0. running mean: -7.555020309093134\n",
      "resetting env. episode reward total was -6.0. running mean: -7.539470106002202\n",
      "resetting env. episode reward total was -7.0. running mean: -7.534075404942181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: -7.498734650892759\n",
      "resetting env. episode reward total was -13.0. running mean: -7.5537473043838315\n",
      "resetting env. episode reward total was -10.0. running mean: -7.578209831339993\n",
      "resetting env. episode reward total was -11.0. running mean: -7.612427733026593\n",
      "resetting env. episode reward total was -5.0. running mean: -7.586303455696326\n",
      "resetting env. episode reward total was -10.0. running mean: -7.610440421139362\n",
      "resetting env. episode reward total was -17.0. running mean: -7.704336016927968\n",
      "resetting env. episode reward total was 1.0. running mean: -7.617292656758688\n",
      "resetting env. episode reward total was -9.0. running mean: -7.631119730191101\n",
      "resetting env. episode reward total was -11.0. running mean: -7.66480853288919\n",
      "resetting env. episode reward total was -7.0. running mean: -7.658160447560299\n",
      "resetting env. episode reward total was -4.0. running mean: -7.621578843084696\n",
      "resetting env. episode reward total was -17.0. running mean: -7.7153630546538485\n",
      "resetting env. episode reward total was -3.0. running mean: -7.66820942410731\n",
      "resetting env. episode reward total was -5.0. running mean: -7.6415273298662365\n",
      "resetting env. episode reward total was -7.0. running mean: -7.635112056567574\n",
      "resetting env. episode reward total was -2.0. running mean: -7.578760936001898\n",
      "resetting env. episode reward total was -9.0. running mean: -7.592973326641879\n",
      "resetting env. episode reward total was -11.0. running mean: -7.62704359337546\n",
      "resetting env. episode reward total was -11.0. running mean: -7.660773157441706\n",
      "resetting env. episode reward total was -5.0. running mean: -7.634165425867288\n",
      "resetting env. episode reward total was -5.0. running mean: -7.607823771608615\n",
      "resetting env. episode reward total was -19.0. running mean: -7.72174553389253\n",
      "resetting env. episode reward total was -2.0. running mean: -7.664528078553603\n",
      "resetting env. episode reward total was -4.0. running mean: -7.627882797768067\n",
      "resetting env. episode reward total was -4.0. running mean: -7.591603969790387\n",
      "resetting env. episode reward total was -8.0. running mean: -7.595687930092483\n",
      "resetting env. episode reward total was -11.0. running mean: -7.629731050791558\n",
      "resetting env. episode reward total was -10.0. running mean: -7.653433740283642\n",
      "resetting env. episode reward total was -16.0. running mean: -7.736899402880805\n",
      "resetting env. episode reward total was -13.0. running mean: -7.789530408851997\n",
      "resetting env. episode reward total was -12.0. running mean: -7.8316351047634765\n",
      "resetting env. episode reward total was -12.0. running mean: -7.873318753715842\n",
      "resetting env. episode reward total was 4.0. running mean: -7.754585566178683\n",
      "resetting env. episode reward total was -17.0. running mean: -7.8470397105168965\n",
      "resetting env. episode reward total was -5.0. running mean: -7.818569313411727\n",
      "resetting env. episode reward total was -7.0. running mean: -7.81038362027761\n",
      "resetting env. episode reward total was 3.0. running mean: -7.702279784074833\n",
      "resetting env. episode reward total was -4.0. running mean: -7.665256986234085\n",
      "resetting env. episode reward total was -4.0. running mean: -7.628604416371744\n",
      "resetting env. episode reward total was -14.0. running mean: -7.692318372208026\n",
      "resetting env. episode reward total was -9.0. running mean: -7.705395188485946\n",
      "resetting env. episode reward total was 4.0. running mean: -7.588341236601087\n",
      "resetting env. episode reward total was -7.0. running mean: -7.582457824235076\n",
      "resetting env. episode reward total was -10.0. running mean: -7.606633245992725\n",
      "resetting env. episode reward total was -14.0. running mean: -7.670566913532798\n",
      "resetting env. episode reward total was -15.0. running mean: -7.74386124439747\n",
      "resetting env. episode reward total was -11.0. running mean: -7.776422631953496\n",
      "resetting env. episode reward total was -6.0. running mean: -7.758658405633961\n",
      "resetting env. episode reward total was -9.0. running mean: -7.771071821577621\n",
      "resetting env. episode reward total was -6.0. running mean: -7.753361103361844\n",
      "resetting env. episode reward total was -18.0. running mean: -7.855827492328226\n",
      "resetting env. episode reward total was -6.0. running mean: -7.837269217404943\n",
      "resetting env. episode reward total was -1.0. running mean: -7.768896525230893\n",
      "resetting env. episode reward total was -10.0. running mean: -7.7912075599785835\n",
      "resetting env. episode reward total was 4.0. running mean: -7.673295484378798\n",
      "resetting env. episode reward total was -9.0. running mean: -7.68656252953501\n",
      "resetting env. episode reward total was -5.0. running mean: -7.659696904239659\n",
      "resetting env. episode reward total was -5.0. running mean: -7.633099935197262\n",
      "resetting env. episode reward total was -13.0. running mean: -7.68676893584529\n",
      "resetting env. episode reward total was -5.0. running mean: -7.659901246486837\n",
      "resetting env. episode reward total was 2.0. running mean: -7.563302234021969\n",
      "resetting env. episode reward total was -13.0. running mean: -7.617669211681749\n",
      "resetting env. episode reward total was -5.0. running mean: -7.591492519564931\n",
      "resetting env. episode reward total was -15.0. running mean: -7.6655775943692825\n",
      "resetting env. episode reward total was -10.0. running mean: -7.688921818425589\n",
      "resetting env. episode reward total was -5.0. running mean: -7.662032600241333\n",
      "resetting env. episode reward total was -4.0. running mean: -7.625412274238919\n",
      "resetting env. episode reward total was -6.0. running mean: -7.60915815149653\n",
      "resetting env. episode reward total was -10.0. running mean: -7.6330665699815645\n",
      "resetting env. episode reward total was -4.0. running mean: -7.596735904281749\n",
      "resetting env. episode reward total was -1.0. running mean: -7.5307685452389315\n",
      "resetting env. episode reward total was -7.0. running mean: -7.525460859786542\n",
      "resetting env. episode reward total was -4.0. running mean: -7.490206251188677\n",
      "resetting env. episode reward total was -3.0. running mean: -7.44530418867679\n",
      "resetting env. episode reward total was -5.0. running mean: -7.420851146790022\n",
      "resetting env. episode reward total was -11.0. running mean: -7.456642635322122\n",
      "resetting env. episode reward total was -9.0. running mean: -7.4720762089689\n",
      "resetting env. episode reward total was -10.0. running mean: -7.497355446879211\n",
      "resetting env. episode reward total was -9.0. running mean: -7.512381892410418\n",
      "resetting env. episode reward total was -16.0. running mean: -7.597258073486314\n",
      "resetting env. episode reward total was -6.0. running mean: -7.581285492751451\n",
      "resetting env. episode reward total was -4.0. running mean: -7.545472637823936\n",
      "resetting env. episode reward total was -4.0. running mean: -7.510017911445697\n",
      "resetting env. episode reward total was -6.0. running mean: -7.494917732331239\n",
      "resetting env. episode reward total was -8.0. running mean: -7.499968555007927\n",
      "resetting env. episode reward total was -7.0. running mean: -7.494968869457848\n",
      "resetting env. episode reward total was -15.0. running mean: -7.5700191807632695\n",
      "resetting env. episode reward total was -8.0. running mean: -7.574318988955637\n",
      "resetting env. episode reward total was -13.0. running mean: -7.6285757990660805\n",
      "resetting env. episode reward total was -7.0. running mean: -7.62229004107542\n",
      "resetting env. episode reward total was -3.0. running mean: -7.576067140664666\n",
      "resetting env. episode reward total was -19.0. running mean: -7.69030646925802\n",
      "resetting env. episode reward total was -12.0. running mean: -7.73340340456544\n",
      "resetting env. episode reward total was -14.0. running mean: -7.796069370519785\n",
      "resetting env. episode reward total was -12.0. running mean: -7.838108676814587\n",
      "resetting env. episode reward total was -11.0. running mean: -7.869727590046441\n",
      "resetting env. episode reward total was -17.0. running mean: -7.961030314145977\n",
      "resetting env. episode reward total was -10.0. running mean: -7.981420011004516\n",
      "resetting env. episode reward total was -13.0. running mean: -8.031605810894472\n",
      "resetting env. episode reward total was 1.0. running mean: -7.9412897527855275\n",
      "resetting env. episode reward total was -10.0. running mean: -7.961876855257672\n",
      "resetting env. episode reward total was -6.0. running mean: -7.9422580867050945\n",
      "resetting env. episode reward total was -15.0. running mean: -8.012835505838042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: -7.972707150779662\n",
      "resetting env. episode reward total was -10.0. running mean: -7.992980079271865\n",
      "resetting env. episode reward total was -8.0. running mean: -7.993050278479147\n",
      "resetting env. episode reward total was -6.0. running mean: -7.973119775694355\n",
      "resetting env. episode reward total was -4.0. running mean: -7.933388577937411\n",
      "resetting env. episode reward total was -6.0. running mean: -7.914054692158036\n",
      "resetting env. episode reward total was -9.0. running mean: -7.924914145236455\n",
      "resetting env. episode reward total was 6.0. running mean: -7.785665003784091\n",
      "resetting env. episode reward total was -17.0. running mean: -7.87780835374625\n",
      "resetting env. episode reward total was -7.0. running mean: -7.869030270208787\n",
      "resetting env. episode reward total was -19.0. running mean: -7.9803399675066995\n",
      "resetting env. episode reward total was -5.0. running mean: -7.950536567831632\n",
      "resetting env. episode reward total was -7.0. running mean: -7.941031202153316\n",
      "resetting env. episode reward total was -12.0. running mean: -7.981620890131783\n",
      "resetting env. episode reward total was -1.0. running mean: -7.911804681230465\n",
      "resetting env. episode reward total was -8.0. running mean: -7.912686634418161\n",
      "resetting env. episode reward total was -8.0. running mean: -7.913559768073979\n",
      "resetting env. episode reward total was -11.0. running mean: -7.94442417039324\n",
      "resetting env. episode reward total was -13.0. running mean: -7.9949799286893075\n",
      "resetting env. episode reward total was -10.0. running mean: -8.015030129402415\n",
      "resetting env. episode reward total was 2.0. running mean: -7.914879828108392\n",
      "resetting env. episode reward total was 3.0. running mean: -7.8057310298273075\n",
      "resetting env. episode reward total was -5.0. running mean: -7.777673719529034\n",
      "resetting env. episode reward total was -11.0. running mean: -7.809896982333743\n",
      "resetting env. episode reward total was -6.0. running mean: -7.791798012510405\n",
      "resetting env. episode reward total was 2.0. running mean: -7.693880032385302\n",
      "resetting env. episode reward total was -5.0. running mean: -7.666941232061449\n",
      "resetting env. episode reward total was -1.0. running mean: -7.600271819740834\n",
      "resetting env. episode reward total was -9.0. running mean: -7.614269101543425\n",
      "resetting env. episode reward total was 9.0. running mean: -7.448126410527991\n",
      "resetting env. episode reward total was -6.0. running mean: -7.433645146422711\n",
      "resetting env. episode reward total was -9.0. running mean: -7.449308694958483\n",
      "resetting env. episode reward total was -9.0. running mean: -7.464815608008898\n",
      "resetting env. episode reward total was 4.0. running mean: -7.350167451928809\n",
      "resetting env. episode reward total was -19.0. running mean: -7.4666657774095215\n",
      "resetting env. episode reward total was -7.0. running mean: -7.4619991196354265\n",
      "resetting env. episode reward total was -7.0. running mean: -7.457379128439072\n",
      "resetting env. episode reward total was -11.0. running mean: -7.492805337154682\n",
      "resetting env. episode reward total was -11.0. running mean: -7.527877283783135\n",
      "resetting env. episode reward total was 7.0. running mean: -7.382598510945304\n",
      "resetting env. episode reward total was -3.0. running mean: -7.338772525835851\n",
      "resetting env. episode reward total was 9.0. running mean: -7.1753848005774925\n",
      "resetting env. episode reward total was -12.0. running mean: -7.2236309525717175\n",
      "resetting env. episode reward total was 3.0. running mean: -7.121394643046\n",
      "resetting env. episode reward total was -3.0. running mean: -7.08018069661554\n",
      "resetting env. episode reward total was -5.0. running mean: -7.059378889649384\n",
      "resetting env. episode reward total was -4.0. running mean: -7.0287851007528905\n",
      "resetting env. episode reward total was 2.0. running mean: -6.938497249745362\n",
      "resetting env. episode reward total was -7.0. running mean: -6.939112277247909\n",
      "resetting env. episode reward total was -12.0. running mean: -6.98972115447543\n",
      "resetting env. episode reward total was -5.0. running mean: -6.969823942930676\n",
      "resetting env. episode reward total was -2.0. running mean: -6.920125703501369\n",
      "resetting env. episode reward total was -2.0. running mean: -6.870924446466355\n",
      "resetting env. episode reward total was 4.0. running mean: -6.762215202001691\n",
      "resetting env. episode reward total was -6.0. running mean: -6.754593049981674\n",
      "resetting env. episode reward total was -3.0. running mean: -6.717047119481857\n",
      "resetting env. episode reward total was -4.0. running mean: -6.689876648287039\n",
      "resetting env. episode reward total was -11.0. running mean: -6.732977881804169\n",
      "resetting env. episode reward total was -9.0. running mean: -6.755648102986127\n",
      "resetting env. episode reward total was -8.0. running mean: -6.768091621956266\n",
      "resetting env. episode reward total was -5.0. running mean: -6.750410705736703\n",
      "resetting env. episode reward total was -7.0. running mean: -6.752906598679337\n",
      "resetting env. episode reward total was -10.0. running mean: -6.785377532692543\n",
      "resetting env. episode reward total was -11.0. running mean: -6.827523757365618\n",
      "resetting env. episode reward total was -9.0. running mean: -6.849248519791961\n",
      "resetting env. episode reward total was -10.0. running mean: -6.88075603459404\n",
      "resetting env. episode reward total was -13.0. running mean: -6.9419484742480995\n",
      "resetting env. episode reward total was -5.0. running mean: -6.922528989505619\n",
      "resetting env. episode reward total was -13.0. running mean: -6.983303699610563\n",
      "resetting env. episode reward total was -8.0. running mean: -6.993470662614457\n",
      "resetting env. episode reward total was -9.0. running mean: -7.013535955988313\n",
      "resetting env. episode reward total was -8.0. running mean: -7.02340059642843\n",
      "resetting env. episode reward total was 1.0. running mean: -6.943166590464146\n",
      "resetting env. episode reward total was -10.0. running mean: -6.973734924559504\n",
      "resetting env. episode reward total was -4.0. running mean: -6.943997575313909\n",
      "resetting env. episode reward total was -7.0. running mean: -6.9445575995607705\n",
      "resetting env. episode reward total was -8.0. running mean: -6.955112023565163\n",
      "resetting env. episode reward total was -16.0. running mean: -7.045560903329512\n",
      "resetting env. episode reward total was -2.0. running mean: -6.995105294296216\n",
      "resetting env. episode reward total was -1.0. running mean: -6.935154241353254\n",
      "resetting env. episode reward total was -10.0. running mean: -6.96580269893972\n",
      "resetting env. episode reward total was -11.0. running mean: -7.006144671950324\n",
      "resetting env. episode reward total was -5.0. running mean: -6.9860832252308205\n",
      "resetting env. episode reward total was -10.0. running mean: -7.016222392978512\n",
      "resetting env. episode reward total was 6.0. running mean: -6.8860601690487275\n",
      "resetting env. episode reward total was -6.0. running mean: -6.87719956735824\n",
      "resetting env. episode reward total was -1.0. running mean: -6.818427571684657\n",
      "resetting env. episode reward total was -9.0. running mean: -6.84024329596781\n",
      "resetting env. episode reward total was -9.0. running mean: -6.8618408630081325\n",
      "resetting env. episode reward total was -14.0. running mean: -6.9332224543780505\n",
      "resetting env. episode reward total was -7.0. running mean: -6.933890229834271\n",
      "resetting env. episode reward total was 7.0. running mean: -6.7945513275359275\n",
      "resetting env. episode reward total was -4.0. running mean: -6.7666058142605685\n",
      "resetting env. episode reward total was -1.0. running mean: -6.708939756117963\n",
      "resetting env. episode reward total was 4.0. running mean: -6.601850358556783\n",
      "resetting env. episode reward total was -12.0. running mean: -6.655831854971216\n",
      "resetting env. episode reward total was -11.0. running mean: -6.6992735364215035\n",
      "resetting env. episode reward total was -10.0. running mean: -6.732280801057288\n",
      "resetting env. episode reward total was -4.0. running mean: -6.704957993046715\n",
      "resetting env. episode reward total was -5.0. running mean: -6.687908413116248\n",
      "resetting env. episode reward total was -3.0. running mean: -6.651029328985086\n",
      "resetting env. episode reward total was -3.0. running mean: -6.614519035695235\n",
      "resetting env. episode reward total was -17.0. running mean: -6.718373845338283\n",
      "resetting env. episode reward total was -2.0. running mean: -6.671190106884899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -12.0. running mean: -6.724478205816051\n",
      "resetting env. episode reward total was -5.0. running mean: -6.70723342375789\n",
      "resetting env. episode reward total was 5.0. running mean: -6.590161089520311\n",
      "resetting env. episode reward total was -3.0. running mean: -6.5542594786251085\n",
      "resetting env. episode reward total was -8.0. running mean: -6.568716883838857\n",
      "resetting env. episode reward total was 4.0. running mean: -6.463029715000469\n",
      "resetting env. episode reward total was 2.0. running mean: -6.378399417850465\n",
      "resetting env. episode reward total was -5.0. running mean: -6.36461542367196\n",
      "resetting env. episode reward total was -1.0. running mean: -6.31096926943524\n",
      "resetting env. episode reward total was -7.0. running mean: -6.317859576740888\n",
      "resetting env. episode reward total was -3.0. running mean: -6.284680980973479\n",
      "resetting env. episode reward total was 6.0. running mean: -6.161834171163744\n",
      "resetting env. episode reward total was -2.0. running mean: -6.120215829452106\n",
      "resetting env. episode reward total was -3.0. running mean: -6.089013671157585\n",
      "resetting env. episode reward total was -11.0. running mean: -6.138123534446009\n",
      "resetting env. episode reward total was -7.0. running mean: -6.1467422991015495\n",
      "resetting env. episode reward total was -4.0. running mean: -6.125274876110534\n",
      "resetting env. episode reward total was -8.0. running mean: -6.144022127349428\n",
      "resetting env. episode reward total was -16.0. running mean: -6.242581906075935\n",
      "resetting env. episode reward total was 4.0. running mean: -6.140156087015175\n",
      "resetting env. episode reward total was -7.0. running mean: -6.148754526145023\n",
      "resetting env. episode reward total was -5.0. running mean: -6.137266980883572\n",
      "resetting env. episode reward total was 4.0. running mean: -6.0358943110747365\n",
      "resetting env. episode reward total was -11.0. running mean: -6.085535367963989\n",
      "resetting env. episode reward total was -12.0. running mean: -6.144680014284349\n",
      "resetting env. episode reward total was -4.0. running mean: -6.123233214141505\n",
      "resetting env. episode reward total was 3.0. running mean: -6.03200088200009\n",
      "resetting env. episode reward total was -7.0. running mean: -6.0416808731800895\n",
      "resetting env. episode reward total was 4.0. running mean: -5.941264064448289\n",
      "resetting env. episode reward total was -5.0. running mean: -5.931851423803805\n",
      "resetting env. episode reward total was -15.0. running mean: -6.022532909565768\n",
      "resetting env. episode reward total was 3.0. running mean: -5.93230758047011\n",
      "resetting env. episode reward total was -4.0. running mean: -5.912984504665409\n",
      "resetting env. episode reward total was -19.0. running mean: -6.043854659618755\n",
      "resetting env. episode reward total was -13.0. running mean: -6.113416113022567\n",
      "resetting env. episode reward total was -18.0. running mean: -6.232281951892341\n",
      "resetting env. episode reward total was -9.0. running mean: -6.259959132373417\n",
      "resetting env. episode reward total was -4.0. running mean: -6.237359541049683\n",
      "resetting env. episode reward total was -10.0. running mean: -6.274985945639186\n",
      "resetting env. episode reward total was -6.0. running mean: -6.272236086182794\n",
      "resetting env. episode reward total was 5.0. running mean: -6.1595137253209655\n",
      "resetting env. episode reward total was -5.0. running mean: -6.147918588067756\n",
      "resetting env. episode reward total was 1.0. running mean: -6.076439402187079\n",
      "resetting env. episode reward total was -8.0. running mean: -6.095675008165208\n",
      "resetting env. episode reward total was -12.0. running mean: -6.154718258083556\n",
      "resetting env. episode reward total was -10.0. running mean: -6.19317107550272\n",
      "resetting env. episode reward total was 2.0. running mean: -6.111239364747693\n",
      "resetting env. episode reward total was 2.0. running mean: -6.030126971100216\n",
      "resetting env. episode reward total was -2.0. running mean: -5.989825701389214\n",
      "resetting env. episode reward total was -11.0. running mean: -6.039927444375322\n",
      "resetting env. episode reward total was -4.0. running mean: -6.019528169931569\n",
      "resetting env. episode reward total was -13.0. running mean: -6.089332888232253\n",
      "resetting env. episode reward total was -8.0. running mean: -6.1084395593499305\n",
      "resetting env. episode reward total was -13.0. running mean: -6.177355163756431\n",
      "resetting env. episode reward total was 1.0. running mean: -6.105581612118867\n",
      "resetting env. episode reward total was -1.0. running mean: -6.0545257959976775\n",
      "resetting env. episode reward total was -10.0. running mean: -6.0939805380377\n",
      "resetting env. episode reward total was -11.0. running mean: -6.143040732657323\n",
      "resetting env. episode reward total was -1.0. running mean: -6.09161032533075\n",
      "resetting env. episode reward total was -5.0. running mean: -6.080694222077442\n",
      "resetting env. episode reward total was -9.0. running mean: -6.109887279856667\n",
      "resetting env. episode reward total was -15.0. running mean: -6.1987884070581005\n",
      "resetting env. episode reward total was -7.0. running mean: -6.206800522987519\n",
      "resetting env. episode reward total was 3.0. running mean: -6.114732517757644\n",
      "resetting env. episode reward total was -6.0. running mean: -6.113585192580067\n",
      "resetting env. episode reward total was -7.0. running mean: -6.122449340654267\n",
      "resetting env. episode reward total was -9.0. running mean: -6.1512248472477244\n",
      "resetting env. episode reward total was -11.0. running mean: -6.199712598775247\n",
      "resetting env. episode reward total was -13.0. running mean: -6.267715472787494\n",
      "resetting env. episode reward total was -7.0. running mean: -6.27503831805962\n",
      "resetting env. episode reward total was -11.0. running mean: -6.322287934879024\n",
      "resetting env. episode reward total was -11.0. running mean: -6.369065055530235\n",
      "resetting env. episode reward total was 4.0. running mean: -6.265374404974932\n",
      "resetting env. episode reward total was -7.0. running mean: -6.2727206609251835\n",
      "resetting env. episode reward total was 1.0. running mean: -6.199993454315932\n",
      "resetting env. episode reward total was 4.0. running mean: -6.097993519772772\n",
      "resetting env. episode reward total was -1.0. running mean: -6.047013584575044\n",
      "resetting env. episode reward total was -8.0. running mean: -6.066543448729294\n",
      "resetting env. episode reward total was -13.0. running mean: -6.135878014242001\n",
      "resetting env. episode reward total was -2.0. running mean: -6.094519234099581\n",
      "resetting env. episode reward total was -3.0. running mean: -6.063574041758585\n",
      "resetting env. episode reward total was -7.0. running mean: -6.072938301340999\n",
      "resetting env. episode reward total was -6.0. running mean: -6.072208918327589\n",
      "resetting env. episode reward total was 4.0. running mean: -5.971486829144313\n",
      "resetting env. episode reward total was -3.0. running mean: -5.94177196085287\n",
      "resetting env. episode reward total was -3.0. running mean: -5.9123542412443415\n",
      "resetting env. episode reward total was 3.0. running mean: -5.823230698831898\n",
      "resetting env. episode reward total was -6.0. running mean: -5.824998391843579\n",
      "resetting env. episode reward total was 5.0. running mean: -5.716748407925143\n",
      "resetting env. episode reward total was -1.0. running mean: -5.669580923845892\n",
      "resetting env. episode reward total was -11.0. running mean: -5.7228851146074335\n",
      "resetting env. episode reward total was -8.0. running mean: -5.745656263461359\n",
      "resetting env. episode reward total was -3.0. running mean: -5.718199700826745\n",
      "resetting env. episode reward total was -3.0. running mean: -5.691017703818478\n",
      "resetting env. episode reward total was -4.0. running mean: -5.6741075267802925\n",
      "resetting env. episode reward total was -8.0. running mean: -5.697366451512489\n",
      "resetting env. episode reward total was -9.0. running mean: -5.730392786997364\n",
      "resetting env. episode reward total was -9.0. running mean: -5.76308885912739\n",
      "resetting env. episode reward total was -11.0. running mean: -5.815457970536117\n",
      "resetting env. episode reward total was -15.0. running mean: -5.907303390830756\n",
      "resetting env. episode reward total was -12.0. running mean: -5.968230356922448\n",
      "resetting env. episode reward total was -10.0. running mean: -6.008548053353223\n",
      "resetting env. episode reward total was -13.0. running mean: -6.078462572819691\n",
      "resetting env. episode reward total was -10.0. running mean: -6.117677947091494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: -6.046501167620579\n",
      "resetting env. episode reward total was -6.0. running mean: -6.046036155944373\n",
      "resetting env. episode reward total was -11.0. running mean: -6.09557579438493\n",
      "resetting env. episode reward total was -11.0. running mean: -6.14462003644108\n",
      "resetting env. episode reward total was -10.0. running mean: -6.183173836076669\n",
      "resetting env. episode reward total was -7.0. running mean: -6.191342097715903\n",
      "resetting env. episode reward total was -13.0. running mean: -6.259428676738743\n",
      "resetting env. episode reward total was -4.0. running mean: -6.236834389971356\n",
      "resetting env. episode reward total was -6.0. running mean: -6.234466046071642\n",
      "resetting env. episode reward total was -9.0. running mean: -6.262121385610925\n",
      "resetting env. episode reward total was -13.0. running mean: -6.329500171754815\n",
      "resetting env. episode reward total was -11.0. running mean: -6.3762051700372675\n",
      "resetting env. episode reward total was -11.0. running mean: -6.422443118336895\n",
      "resetting env. episode reward total was -8.0. running mean: -6.438218687153526\n",
      "resetting env. episode reward total was -7.0. running mean: -6.443836500281991\n",
      "resetting env. episode reward total was -11.0. running mean: -6.489398135279171\n",
      "resetting env. episode reward total was -14.0. running mean: -6.5645041539263795\n",
      "resetting env. episode reward total was 1.0. running mean: -6.488859112387116\n",
      "resetting env. episode reward total was -10.0. running mean: -6.523970521263244\n",
      "resetting env. episode reward total was -7.0. running mean: -6.528730816050612\n",
      "resetting env. episode reward total was -11.0. running mean: -6.573443507890106\n",
      "resetting env. episode reward total was -13.0. running mean: -6.637709072811205\n",
      "resetting env. episode reward total was -17.0. running mean: -6.741331982083093\n",
      "resetting env. episode reward total was -12.0. running mean: -6.793918662262262\n",
      "resetting env. episode reward total was -16.0. running mean: -6.885979475639639\n",
      "resetting env. episode reward total was -5.0. running mean: -6.867119680883242\n",
      "resetting env. episode reward total was -8.0. running mean: -6.87844848407441\n",
      "resetting env. episode reward total was -7.0. running mean: -6.8796639992336655\n",
      "resetting env. episode reward total was -2.0. running mean: -6.830867359241329\n",
      "resetting env. episode reward total was -8.0. running mean: -6.842558685648916\n",
      "resetting env. episode reward total was -7.0. running mean: -6.844133098792427\n",
      "resetting env. episode reward total was -7.0. running mean: -6.845691767804503\n",
      "resetting env. episode reward total was 2.0. running mean: -6.7572348501264585\n",
      "resetting env. episode reward total was -7.0. running mean: -6.759662501625194\n",
      "resetting env. episode reward total was -3.0. running mean: -6.7220658766089425\n",
      "resetting env. episode reward total was -12.0. running mean: -6.774845217842853\n",
      "resetting env. episode reward total was 1.0. running mean: -6.6970967656644245\n",
      "resetting env. episode reward total was -15.0. running mean: -6.780125798007781\n",
      "resetting env. episode reward total was -3.0. running mean: -6.742324540027703\n",
      "resetting env. episode reward total was -13.0. running mean: -6.8049012946274265\n",
      "resetting env. episode reward total was -14.0. running mean: -6.876852281681152\n",
      "resetting env. episode reward total was -3.0. running mean: -6.83808375886434\n",
      "resetting env. episode reward total was 7.0. running mean: -6.699702921275697\n",
      "resetting env. episode reward total was -15.0. running mean: -6.78270589206294\n",
      "resetting env. episode reward total was -9.0. running mean: -6.80487883314231\n",
      "resetting env. episode reward total was -9.0. running mean: -6.826830044810887\n",
      "resetting env. episode reward total was -1.0. running mean: -6.768561744362778\n",
      "resetting env. episode reward total was -10.0. running mean: -6.8008761269191496\n",
      "resetting env. episode reward total was 10.0. running mean: -6.632867365649958\n",
      "resetting env. episode reward total was -9.0. running mean: -6.656538691993458\n",
      "resetting env. episode reward total was 5.0. running mean: -6.539973305073524\n",
      "resetting env. episode reward total was -6.0. running mean: -6.534573572022788\n",
      "resetting env. episode reward total was 2.0. running mean: -6.449227836302561\n",
      "resetting env. episode reward total was -8.0. running mean: -6.464735557939536\n",
      "resetting env. episode reward total was 2.0. running mean: -6.380088202360141\n",
      "resetting env. episode reward total was 7.0. running mean: -6.246287320336539\n",
      "resetting env. episode reward total was 8.0. running mean: -6.1038244471331735\n",
      "resetting env. episode reward total was -3.0. running mean: -6.072786202661842\n",
      "resetting env. episode reward total was -9.0. running mean: -6.102058340635224\n",
      "resetting env. episode reward total was -1.0. running mean: -6.051037757228871\n",
      "resetting env. episode reward total was -6.0. running mean: -6.0505273796565815\n",
      "resetting env. episode reward total was -13.0. running mean: -6.1200221058600155\n",
      "resetting env. episode reward total was -3.0. running mean: -6.0888218848014155\n",
      "resetting env. episode reward total was -9.0. running mean: -6.117933665953401\n",
      "resetting env. episode reward total was -4.0. running mean: -6.096754329293867\n",
      "resetting env. episode reward total was -6.0. running mean: -6.095786786000928\n",
      "resetting env. episode reward total was 2.0. running mean: -6.014828918140919\n",
      "resetting env. episode reward total was -9.0. running mean: -6.04468062895951\n",
      "resetting env. episode reward total was 5.0. running mean: -5.934233822669915\n",
      "resetting env. episode reward total was 9.0. running mean: -5.784891484443216\n",
      "resetting env. episode reward total was 2.0. running mean: -5.7070425695987845\n",
      "resetting env. episode reward total was -6.0. running mean: -5.709972143902796\n",
      "resetting env. episode reward total was -9.0. running mean: -5.742872422463768\n",
      "resetting env. episode reward total was -9.0. running mean: -5.775443698239131\n",
      "resetting env. episode reward total was -3.0. running mean: -5.747689261256739\n",
      "resetting env. episode reward total was -6.0. running mean: -5.7502123686441715\n",
      "resetting env. episode reward total was -11.0. running mean: -5.80271024495773\n",
      "resetting env. episode reward total was -7.0. running mean: -5.814683142508152\n",
      "resetting env. episode reward total was -11.0. running mean: -5.866536311083071\n",
      "resetting env. episode reward total was -12.0. running mean: -5.927870947972241\n",
      "resetting env. episode reward total was -15.0. running mean: -6.018592238492519\n",
      "resetting env. episode reward total was -5.0. running mean: -6.008406316107593\n",
      "resetting env. episode reward total was -11.0. running mean: -6.0583222529465175\n",
      "resetting env. episode reward total was -13.0. running mean: -6.127739030417052\n",
      "resetting env. episode reward total was -3.0. running mean: -6.0964616401128815\n",
      "resetting env. episode reward total was -11.0. running mean: -6.145497023711753\n",
      "resetting env. episode reward total was -5.0. running mean: -6.134042053474635\n",
      "resetting env. episode reward total was 2.0. running mean: -6.05270163293989\n",
      "resetting env. episode reward total was -13.0. running mean: -6.122174616610491\n",
      "resetting env. episode reward total was -7.0. running mean: -6.1309528704443865\n",
      "resetting env. episode reward total was -12.0. running mean: -6.189643341739942\n",
      "resetting env. episode reward total was -7.0. running mean: -6.197746908322543\n",
      "resetting env. episode reward total was 3.0. running mean: -6.105769439239317\n",
      "resetting env. episode reward total was -3.0. running mean: -6.074711744846924\n",
      "resetting env. episode reward total was -9.0. running mean: -6.1039646273984545\n",
      "resetting env. episode reward total was 4.0. running mean: -6.00292498112447\n",
      "resetting env. episode reward total was -1.0. running mean: -5.952895731313225\n",
      "resetting env. episode reward total was -7.0. running mean: -5.963366774000093\n",
      "resetting env. episode reward total was 4.0. running mean: -5.863733106260092\n",
      "resetting env. episode reward total was -7.0. running mean: -5.875095775197491\n",
      "resetting env. episode reward total was -3.0. running mean: -5.846344817445516\n",
      "resetting env. episode reward total was -18.0. running mean: -5.96788136927106\n",
      "resetting env. episode reward total was -5.0. running mean: -5.9582025555783495\n",
      "resetting env. episode reward total was 4.0. running mean: -5.8586205300225656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: -5.88003432472234\n",
      "resetting env. episode reward total was -14.0. running mean: -5.961233981475116\n",
      "resetting env. episode reward total was 7.0. running mean: -5.831621641660365\n",
      "resetting env. episode reward total was 3.0. running mean: -5.743305425243761\n",
      "resetting env. episode reward total was 9.0. running mean: -5.595872370991324\n",
      "resetting env. episode reward total was 6.0. running mean: -5.4799136472814105\n",
      "resetting env. episode reward total was 11.0. running mean: -5.315114510808596\n",
      "resetting env. episode reward total was -10.0. running mean: -5.361963365700509\n",
      "resetting env. episode reward total was -9.0. running mean: -5.398343732043504\n",
      "resetting env. episode reward total was 5.0. running mean: -5.294360294723069\n",
      "resetting env. episode reward total was -8.0. running mean: -5.3214166917758385\n",
      "resetting env. episode reward total was -15.0. running mean: -5.4182025248580805\n",
      "resetting env. episode reward total was -2.0. running mean: -5.384020499609499\n",
      "resetting env. episode reward total was -5.0. running mean: -5.380180294613404\n",
      "resetting env. episode reward total was -13.0. running mean: -5.4563784916672695\n",
      "resetting env. episode reward total was 5.0. running mean: -5.351814706750597\n",
      "resetting env. episode reward total was -7.0. running mean: -5.368296559683091\n",
      "resetting env. episode reward total was -1.0. running mean: -5.32461359408626\n",
      "resetting env. episode reward total was -6.0. running mean: -5.3313674581453965\n",
      "resetting env. episode reward total was -14.0. running mean: -5.418053783563942\n",
      "resetting env. episode reward total was -10.0. running mean: -5.463873245728302\n",
      "resetting env. episode reward total was -13.0. running mean: -5.539234513271019\n",
      "resetting env. episode reward total was -1.0. running mean: -5.4938421681383085\n",
      "resetting env. episode reward total was -9.0. running mean: -5.528903746456925\n",
      "resetting env. episode reward total was -11.0. running mean: -5.583614708992356\n",
      "resetting env. episode reward total was -1.0. running mean: -5.5377785619024325\n",
      "resetting env. episode reward total was -14.0. running mean: -5.622400776283408\n",
      "resetting env. episode reward total was -3.0. running mean: -5.596176768520574\n",
      "resetting env. episode reward total was -13.0. running mean: -5.670215000835368\n",
      "resetting env. episode reward total was 5.0. running mean: -5.563512850827014\n",
      "resetting env. episode reward total was -8.0. running mean: -5.587877722318744\n",
      "resetting env. episode reward total was -3.0. running mean: -5.5619989450955565\n",
      "resetting env. episode reward total was -18.0. running mean: -5.6863789556446\n",
      "resetting env. episode reward total was -1.0. running mean: -5.639515166088154\n",
      "resetting env. episode reward total was 4.0. running mean: -5.543120014427273\n",
      "resetting env. episode reward total was -5.0. running mean: -5.537688814282999\n",
      "resetting env. episode reward total was -14.0. running mean: -5.622311926140169\n",
      "resetting env. episode reward total was -3.0. running mean: -5.596088806878767\n",
      "resetting env. episode reward total was -10.0. running mean: -5.640127918809979\n",
      "resetting env. episode reward total was 3.0. running mean: -5.553726639621879\n",
      "resetting env. episode reward total was -8.0. running mean: -5.57818937322566\n",
      "resetting env. episode reward total was -18.0. running mean: -5.702407479493403\n",
      "resetting env. episode reward total was -10.0. running mean: -5.745383404698469\n",
      "resetting env. episode reward total was -2.0. running mean: -5.707929570651483\n",
      "resetting env. episode reward total was -9.0. running mean: -5.740850274944968\n",
      "resetting env. episode reward total was -13.0. running mean: -5.813441772195518\n",
      "resetting env. episode reward total was -13.0. running mean: -5.885307354473563\n",
      "resetting env. episode reward total was -1.0. running mean: -5.836454280928827\n",
      "resetting env. episode reward total was -13.0. running mean: -5.908089738119538\n",
      "resetting env. episode reward total was -10.0. running mean: -5.949008840738342\n",
      "resetting env. episode reward total was -5.0. running mean: -5.939518752330958\n",
      "resetting env. episode reward total was -8.0. running mean: -5.960123564807649\n",
      "resetting env. episode reward total was -16.0. running mean: -6.060522329159572\n",
      "resetting env. episode reward total was -8.0. running mean: -6.079917105867977\n",
      "resetting env. episode reward total was -8.0. running mean: -6.099117934809297\n",
      "resetting env. episode reward total was -7.0. running mean: -6.108126755461204\n",
      "resetting env. episode reward total was -7.0. running mean: -6.1170454879065925\n",
      "resetting env. episode reward total was 2.0. running mean: -6.035875033027527\n",
      "resetting env. episode reward total was -13.0. running mean: -6.105516282697252\n",
      "resetting env. episode reward total was -8.0. running mean: -6.124461119870279\n",
      "resetting env. episode reward total was -4.0. running mean: -6.103216508671577\n",
      "resetting env. episode reward total was -5.0. running mean: -6.092184343584861\n",
      "resetting env. episode reward total was -3.0. running mean: -6.061262500149012\n",
      "resetting env. episode reward total was 2.0. running mean: -5.980649875147522\n",
      "resetting env. episode reward total was -3.0. running mean: -5.950843376396047\n",
      "resetting env. episode reward total was -7.0. running mean: -5.961334942632086\n",
      "resetting env. episode reward total was -15.0. running mean: -6.051721593205765\n",
      "resetting env. episode reward total was -13.0. running mean: -6.121204377273707\n",
      "resetting env. episode reward total was -5.0. running mean: -6.10999233350097\n",
      "resetting env. episode reward total was -2.0. running mean: -6.06889241016596\n",
      "resetting env. episode reward total was -9.0. running mean: -6.0982034860643\n",
      "resetting env. episode reward total was -10.0. running mean: -6.137221451203656\n",
      "resetting env. episode reward total was -2.0. running mean: -6.095849236691619\n",
      "resetting env. episode reward total was -13.0. running mean: -6.164890744324702\n",
      "resetting env. episode reward total was -8.0. running mean: -6.1832418368814555\n",
      "resetting env. episode reward total was -5.0. running mean: -6.17140941851264\n",
      "resetting env. episode reward total was -4.0. running mean: -6.149695324327514\n",
      "resetting env. episode reward total was -1.0. running mean: -6.098198371084238\n",
      "resetting env. episode reward total was -3.0. running mean: -6.067216387373396\n",
      "resetting env. episode reward total was -3.0. running mean: -6.036544223499662\n",
      "resetting env. episode reward total was -4.0. running mean: -6.0161787812646645\n",
      "resetting env. episode reward total was -4.0. running mean: -5.9960169934520176\n",
      "resetting env. episode reward total was -7.0. running mean: -6.006056823517498\n",
      "resetting env. episode reward total was -3.0. running mean: -5.975996255282323\n",
      "resetting env. episode reward total was -11.0. running mean: -6.0262362927295\n",
      "resetting env. episode reward total was -8.0. running mean: -6.045973929802205\n",
      "resetting env. episode reward total was 1.0. running mean: -5.9755141905041835\n",
      "resetting env. episode reward total was -7.0. running mean: -5.985759048599142\n",
      "resetting env. episode reward total was -15.0. running mean: -6.075901458113151\n",
      "resetting env. episode reward total was -3.0. running mean: -6.045142443532019\n",
      "resetting env. episode reward total was -1.0. running mean: -5.994691019096699\n",
      "resetting env. episode reward total was -10.0. running mean: -6.034744108905731\n",
      "resetting env. episode reward total was 11.0. running mean: -5.864396667816674\n",
      "resetting env. episode reward total was -11.0. running mean: -5.915752701138508\n",
      "resetting env. episode reward total was -10.0. running mean: -5.956595174127122\n",
      "resetting env. episode reward total was -2.0. running mean: -5.91702922238585\n",
      "resetting env. episode reward total was -1.0. running mean: -5.867858930161991\n",
      "resetting env. episode reward total was -9.0. running mean: -5.8991803408603705\n",
      "resetting env. episode reward total was -4.0. running mean: -5.880188537451767\n",
      "resetting env. episode reward total was -7.0. running mean: -5.89138665207725\n",
      "resetting env. episode reward total was -13.0. running mean: -5.962472785556477\n",
      "resetting env. episode reward total was -1.0. running mean: -5.912848057700912\n",
      "resetting env. episode reward total was 3.0. running mean: -5.823719577123902\n",
      "resetting env. episode reward total was -11.0. running mean: -5.875482381352663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -13.0. running mean: -5.946727557539137\n",
      "resetting env. episode reward total was -13.0. running mean: -6.017260281963745\n",
      "resetting env. episode reward total was -1.0. running mean: -5.967087679144107\n",
      "resetting env. episode reward total was -9.0. running mean: -5.997416802352666\n",
      "resetting env. episode reward total was -13.0. running mean: -6.067442634329139\n",
      "resetting env. episode reward total was -11.0. running mean: -6.1167682079858485\n",
      "resetting env. episode reward total was 2.0. running mean: -6.03560052590599\n",
      "resetting env. episode reward total was -8.0. running mean: -6.05524452064693\n",
      "resetting env. episode reward total was -13.0. running mean: -6.124692075440461\n",
      "resetting env. episode reward total was -1.0. running mean: -6.0734451546860555\n",
      "resetting env. episode reward total was 2.0. running mean: -5.9927107031391955\n",
      "resetting env. episode reward total was -7.0. running mean: -6.002783596107804\n",
      "resetting env. episode reward total was -7.0. running mean: -6.012755760146726\n",
      "resetting env. episode reward total was 3.0. running mean: -5.922628202545258\n",
      "resetting env. episode reward total was -5.0. running mean: -5.913401920519806\n",
      "resetting env. episode reward total was -7.0. running mean: -5.924267901314608\n",
      "resetting env. episode reward total was 2.0. running mean: -5.845025222301462\n",
      "resetting env. episode reward total was -17.0. running mean: -5.956574970078448\n",
      "resetting env. episode reward total was -2.0. running mean: -5.917009220377663\n",
      "resetting env. episode reward total was 1.0. running mean: -5.847839128173886\n",
      "resetting env. episode reward total was -2.0. running mean: -5.809360736892147\n",
      "resetting env. episode reward total was -10.0. running mean: -5.851267129523225\n",
      "resetting env. episode reward total was -9.0. running mean: -5.882754458227993\n",
      "resetting env. episode reward total was -2.0. running mean: -5.843926913645713\n",
      "resetting env. episode reward total was -12.0. running mean: -5.905487644509256\n",
      "resetting env. episode reward total was 1.0. running mean: -5.836432768064164\n",
      "resetting env. episode reward total was -2.0. running mean: -5.798068440383521\n",
      "resetting env. episode reward total was 7.0. running mean: -5.670087755979686\n",
      "resetting env. episode reward total was -9.0. running mean: -5.703386878419889\n",
      "resetting env. episode reward total was -12.0. running mean: -5.76635300963569\n",
      "resetting env. episode reward total was -8.0. running mean: -5.788689479539333\n",
      "resetting env. episode reward total was -2.0. running mean: -5.75080258474394\n",
      "resetting env. episode reward total was -1.0. running mean: -5.7032945588965\n",
      "resetting env. episode reward total was -6.0. running mean: -5.706261613307535\n",
      "resetting env. episode reward total was -12.0. running mean: -5.76919899717446\n",
      "resetting env. episode reward total was -5.0. running mean: -5.761507007202715\n",
      "resetting env. episode reward total was -8.0. running mean: -5.783891937130687\n",
      "resetting env. episode reward total was -10.0. running mean: -5.82605301775938\n",
      "resetting env. episode reward total was -2.0. running mean: -5.787792487581785\n",
      "resetting env. episode reward total was -14.0. running mean: -5.869914562705967\n",
      "resetting env. episode reward total was -7.0. running mean: -5.8812154170789075\n",
      "resetting env. episode reward total was 5.0. running mean: -5.772403262908118\n",
      "resetting env. episode reward total was -4.0. running mean: -5.754679230279037\n",
      "resetting env. episode reward total was -4.0. running mean: -5.737132437976246\n",
      "resetting env. episode reward total was -6.0. running mean: -5.739761113596483\n",
      "resetting env. episode reward total was -9.0. running mean: -5.772363502460518\n",
      "resetting env. episode reward total was -6.0. running mean: -5.774639867435912\n",
      "resetting env. episode reward total was -10.0. running mean: -5.8168934687615526\n",
      "resetting env. episode reward total was -10.0. running mean: -5.858724534073937\n",
      "resetting env. episode reward total was -12.0. running mean: -5.920137288733198\n",
      "resetting env. episode reward total was -4.0. running mean: -5.900935915845865\n",
      "resetting env. episode reward total was -9.0. running mean: -5.931926556687406\n",
      "resetting env. episode reward total was -9.0. running mean: -5.962607291120532\n",
      "resetting env. episode reward total was -9.0. running mean: -5.9929812182093265\n",
      "resetting env. episode reward total was -6.0. running mean: -5.993051406027233\n",
      "resetting env. episode reward total was -14.0. running mean: -6.07312089196696\n",
      "resetting env. episode reward total was -4.0. running mean: -6.0523896830472905\n",
      "resetting env. episode reward total was -7.0. running mean: -6.061865786216818\n",
      "resetting env. episode reward total was -8.0. running mean: -6.08124712835465\n",
      "resetting env. episode reward total was -8.0. running mean: -6.100434657071103\n",
      "resetting env. episode reward total was -7.0. running mean: -6.109430310500392\n",
      "resetting env. episode reward total was 8.0. running mean: -5.968336007395388\n",
      "resetting env. episode reward total was -5.0. running mean: -5.958652647321434\n",
      "resetting env. episode reward total was 8.0. running mean: -5.819066120848219\n",
      "resetting env. episode reward total was -1.0. running mean: -5.770875459639736\n",
      "resetting env. episode reward total was -6.0. running mean: -5.773166705043338\n",
      "resetting env. episode reward total was -14.0. running mean: -5.855435037992905\n",
      "resetting env. episode reward total was 4.0. running mean: -5.756880687612975\n",
      "resetting env. episode reward total was -3.0. running mean: -5.729311880736845\n",
      "resetting env. episode reward total was 5.0. running mean: -5.622018761929477\n",
      "resetting env. episode reward total was -4.0. running mean: -5.605798574310182\n",
      "resetting env. episode reward total was -4.0. running mean: -5.5897405885670794\n",
      "resetting env. episode reward total was -9.0. running mean: -5.623843182681409\n",
      "resetting env. episode reward total was -15.0. running mean: -5.717604750854595\n",
      "resetting env. episode reward total was 2.0. running mean: -5.64042870334605\n",
      "resetting env. episode reward total was -11.0. running mean: -5.6940244163125895\n",
      "resetting env. episode reward total was -1.0. running mean: -5.647084172149463\n",
      "resetting env. episode reward total was -5.0. running mean: -5.640613330427969\n",
      "resetting env. episode reward total was -3.0. running mean: -5.614207197123689\n",
      "resetting env. episode reward total was -6.0. running mean: -5.618065125152452\n",
      "resetting env. episode reward total was -6.0. running mean: -5.621884473900927\n",
      "resetting env. episode reward total was -4.0. running mean: -5.605665629161917\n",
      "resetting env. episode reward total was -11.0. running mean: -5.6596089728702985\n",
      "resetting env. episode reward total was -7.0. running mean: -5.673012883141595\n",
      "resetting env. episode reward total was 3.0. running mean: -5.586282754310179\n",
      "resetting env. episode reward total was -6.0. running mean: -5.590419926767077\n",
      "resetting env. episode reward total was -15.0. running mean: -5.684515727499407\n",
      "resetting env. episode reward total was -13.0. running mean: -5.757670570224413\n",
      "resetting env. episode reward total was -6.0. running mean: -5.760093864522168\n",
      "resetting env. episode reward total was -7.0. running mean: -5.772492925876946\n",
      "resetting env. episode reward total was -9.0. running mean: -5.804767996618176\n",
      "resetting env. episode reward total was -10.0. running mean: -5.846720316651994\n",
      "resetting env. episode reward total was -10.0. running mean: -5.888253113485473\n",
      "resetting env. episode reward total was 4.0. running mean: -5.789370582350618\n",
      "resetting env. episode reward total was -4.0. running mean: -5.771476876527112\n",
      "resetting env. episode reward total was -6.0. running mean: -5.773762107761841\n",
      "resetting env. episode reward total was -3.0. running mean: -5.746024486684223\n",
      "resetting env. episode reward total was -9.0. running mean: -5.778564241817381\n",
      "resetting env. episode reward total was -9.0. running mean: -5.810778599399207\n",
      "resetting env. episode reward total was -11.0. running mean: -5.862670813405215\n",
      "resetting env. episode reward total was -3.0. running mean: -5.834044105271163\n",
      "resetting env. episode reward total was -8.0. running mean: -5.855703664218451\n",
      "resetting env. episode reward total was -9.0. running mean: -5.887146627576266\n",
      "resetting env. episode reward total was -9.0. running mean: -5.918275161300503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: -5.839092409687498\n",
      "resetting env. episode reward total was -10.0. running mean: -5.880701485590623\n",
      "resetting env. episode reward total was 8.0. running mean: -5.741894470734716\n",
      "resetting env. episode reward total was 4.0. running mean: -5.644475526027369\n",
      "resetting env. episode reward total was -13.0. running mean: -5.718030770767095\n",
      "resetting env. episode reward total was -3.0. running mean: -5.690850463059425\n",
      "resetting env. episode reward total was -10.0. running mean: -5.73394195842883\n",
      "resetting env. episode reward total was -12.0. running mean: -5.796602538844542\n",
      "resetting env. episode reward total was 2.0. running mean: -5.718636513456097\n",
      "resetting env. episode reward total was -7.0. running mean: -5.731450148321536\n",
      "resetting env. episode reward total was -10.0. running mean: -5.77413564683832\n",
      "resetting env. episode reward total was -6.0. running mean: -5.776394290369937\n",
      "resetting env. episode reward total was 8.0. running mean: -5.638630347466237\n",
      "resetting env. episode reward total was -2.0. running mean: -5.602244043991575\n",
      "resetting env. episode reward total was -9.0. running mean: -5.636221603551658\n",
      "resetting env. episode reward total was -8.0. running mean: -5.659859387516142\n",
      "resetting env. episode reward total was -7.0. running mean: -5.6732607936409805\n",
      "resetting env. episode reward total was 3.0. running mean: -5.58652818570457\n",
      "resetting env. episode reward total was -3.0. running mean: -5.560662903847525\n",
      "resetting env. episode reward total was 2.0. running mean: -5.4850562748090494\n",
      "resetting env. episode reward total was -12.0. running mean: -5.550205712060959\n",
      "resetting env. episode reward total was -4.0. running mean: -5.534703654940349\n",
      "resetting env. episode reward total was -3.0. running mean: -5.509356618390946\n",
      "resetting env. episode reward total was -9.0. running mean: -5.544263052207036\n",
      "resetting env. episode reward total was -1.0. running mean: -5.498820421684965\n",
      "resetting env. episode reward total was 1.0. running mean: -5.433832217468116\n",
      "resetting env. episode reward total was -12.0. running mean: -5.499493895293435\n",
      "resetting env. episode reward total was -4.0. running mean: -5.4844989563405\n",
      "resetting env. episode reward total was -6.0. running mean: -5.489653966777095\n",
      "resetting env. episode reward total was -3.0. running mean: -5.464757427109324\n",
      "resetting env. episode reward total was -4.0. running mean: -5.4501098528382315\n",
      "resetting env. episode reward total was -4.0. running mean: -5.4356087543098495\n",
      "resetting env. episode reward total was 4.0. running mean: -5.341252666766751\n",
      "resetting env. episode reward total was 2.0. running mean: -5.267840140099084\n",
      "resetting env. episode reward total was -6.0. running mean: -5.275161738698093\n",
      "resetting env. episode reward total was 5.0. running mean: -5.1724101213111116\n",
      "resetting env. episode reward total was -14.0. running mean: -5.260686020098\n",
      "resetting env. episode reward total was -12.0. running mean: -5.328079159897021\n",
      "resetting env. episode reward total was -13.0. running mean: -5.40479836829805\n",
      "resetting env. episode reward total was 10.0. running mean: -5.2507503846150705\n",
      "resetting env. episode reward total was 3.0. running mean: -5.168242880768919\n",
      "resetting env. episode reward total was 1.0. running mean: -5.10656045196123\n",
      "resetting env. episode reward total was -5.0. running mean: -5.1054948474416175\n",
      "resetting env. episode reward total was -7.0. running mean: -5.124439898967202\n",
      "resetting env. episode reward total was -3.0. running mean: -5.10319549997753\n",
      "resetting env. episode reward total was -2.0. running mean: -5.072163544977754\n",
      "resetting env. episode reward total was -11.0. running mean: -5.131441909527977\n",
      "resetting env. episode reward total was -6.0. running mean: -5.140127490432697\n",
      "resetting env. episode reward total was -13.0. running mean: -5.21872621552837\n",
      "resetting env. episode reward total was -2.0. running mean: -5.186538953373085\n",
      "resetting env. episode reward total was -11.0. running mean: -5.2446735638393545\n",
      "resetting env. episode reward total was 2.0. running mean: -5.172226828200961\n",
      "resetting env. episode reward total was -12.0. running mean: -5.240504559918952\n",
      "resetting env. episode reward total was -9.0. running mean: -5.278099514319762\n",
      "resetting env. episode reward total was -9.0. running mean: -5.315318519176564\n",
      "resetting env. episode reward total was -11.0. running mean: -5.372165333984799\n",
      "resetting env. episode reward total was -11.0. running mean: -5.428443680644951\n",
      "resetting env. episode reward total was 7.0. running mean: -5.304159243838501\n",
      "resetting env. episode reward total was -3.0. running mean: -5.281117651400116\n",
      "resetting env. episode reward total was -10.0. running mean: -5.328306474886115\n",
      "resetting env. episode reward total was -9.0. running mean: -5.365023410137254\n",
      "resetting env. episode reward total was -9.0. running mean: -5.401373176035881\n",
      "resetting env. episode reward total was -3.0. running mean: -5.377359444275522\n",
      "resetting env. episode reward total was -15.0. running mean: -5.473585849832768\n",
      "resetting env. episode reward total was -8.0. running mean: -5.49884999133444\n",
      "resetting env. episode reward total was -11.0. running mean: -5.553861491421096\n",
      "resetting env. episode reward total was 2.0. running mean: -5.478322876506885\n",
      "resetting env. episode reward total was -9.0. running mean: -5.513539647741816\n",
      "resetting env. episode reward total was -6.0. running mean: -5.518404251264398\n",
      "resetting env. episode reward total was -16.0. running mean: -5.623220208751754\n",
      "resetting env. episode reward total was -10.0. running mean: -5.666988006664236\n",
      "resetting env. episode reward total was 1.0. running mean: -5.600318126597594\n",
      "resetting env. episode reward total was -8.0. running mean: -5.624314945331618\n",
      "resetting env. episode reward total was -12.0. running mean: -5.688071795878302\n",
      "resetting env. episode reward total was -5.0. running mean: -5.681191077919519\n",
      "resetting env. episode reward total was -12.0. running mean: -5.744379167140324\n",
      "resetting env. episode reward total was -6.0. running mean: -5.7469353754689205\n",
      "resetting env. episode reward total was -5.0. running mean: -5.7394660217142315\n",
      "resetting env. episode reward total was -12.0. running mean: -5.802071361497089\n",
      "resetting env. episode reward total was -15.0. running mean: -5.894050647882119\n",
      "resetting env. episode reward total was 1.0. running mean: -5.8251101414032975\n",
      "resetting env. episode reward total was -1.0. running mean: -5.776859039989264\n",
      "resetting env. episode reward total was -16.0. running mean: -5.879090449589372\n",
      "resetting env. episode reward total was -10.0. running mean: -5.920299545093478\n",
      "resetting env. episode reward total was -13.0. running mean: -5.991096549642543\n",
      "resetting env. episode reward total was -5.0. running mean: -5.981185584146117\n",
      "resetting env. episode reward total was -9.0. running mean: -6.0113737283046556\n",
      "resetting env. episode reward total was -6.0. running mean: -6.011259991021609\n",
      "resetting env. episode reward total was -11.0. running mean: -6.061147391111393\n",
      "resetting env. episode reward total was 4.0. running mean: -5.960535917200279\n",
      "resetting env. episode reward total was -10.0. running mean: -6.000930558028276\n",
      "resetting env. episode reward total was -9.0. running mean: -6.030921252447993\n",
      "resetting env. episode reward total was -8.0. running mean: -6.0506120399235135\n",
      "resetting env. episode reward total was -7.0. running mean: -6.060105919524279\n",
      "resetting env. episode reward total was -11.0. running mean: -6.109504860329037\n",
      "resetting env. episode reward total was -7.0. running mean: -6.118409811725747\n",
      "resetting env. episode reward total was -8.0. running mean: -6.13722571360849\n",
      "resetting env. episode reward total was 4.0. running mean: -6.035853456472404\n",
      "resetting env. episode reward total was -5.0. running mean: -6.02549492190768\n",
      "resetting env. episode reward total was -2.0. running mean: -5.9852399726886025\n",
      "resetting env. episode reward total was -9.0. running mean: -6.015387572961716\n",
      "resetting env. episode reward total was -3.0. running mean: -5.985233697232099\n",
      "resetting env. episode reward total was -9.0. running mean: -6.015381360259777\n",
      "resetting env. episode reward total was -9.0. running mean: -6.04522754665718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: -5.974775271190608\n",
      "resetting env. episode reward total was -7.0. running mean: -5.985027518478702\n",
      "resetting env. episode reward total was 2.0. running mean: -5.905177243293916\n",
      "resetting env. episode reward total was -12.0. running mean: -5.966125470860977\n",
      "resetting env. episode reward total was -11.0. running mean: -6.016464216152367\n",
      "resetting env. episode reward total was -18.0. running mean: -6.1362995739908435\n",
      "resetting env. episode reward total was 3.0. running mean: -6.044936578250935\n",
      "resetting env. episode reward total was -2.0. running mean: -6.004487212468425\n",
      "resetting env. episode reward total was 1.0. running mean: -5.934442340343741\n",
      "resetting env. episode reward total was -17.0. running mean: -6.045097916940304\n",
      "resetting env. episode reward total was -10.0. running mean: -6.084646937770901\n",
      "resetting env. episode reward total was -9.0. running mean: -6.113800468393192\n",
      "resetting env. episode reward total was -8.0. running mean: -6.13266246370926\n",
      "resetting env. episode reward total was -8.0. running mean: -6.151335839072168\n",
      "resetting env. episode reward total was -4.0. running mean: -6.129822480681446\n",
      "resetting env. episode reward total was -4.0. running mean: -6.108524255874631\n",
      "resetting env. episode reward total was -1.0. running mean: -6.057439013315884\n",
      "resetting env. episode reward total was -3.0. running mean: -6.026864623182726\n",
      "resetting env. episode reward total was -3.0. running mean: -5.996595976950899\n",
      "resetting env. episode reward total was 2.0. running mean: -5.91663001718139\n",
      "resetting env. episode reward total was -7.0. running mean: -5.9274637170095765\n",
      "resetting env. episode reward total was 3.0. running mean: -5.838189079839481\n",
      "resetting env. episode reward total was -14.0. running mean: -5.9198071890410855\n",
      "resetting env. episode reward total was -5.0. running mean: -5.910609117150674\n",
      "resetting env. episode reward total was 1.0. running mean: -5.841503025979168\n",
      "resetting env. episode reward total was -4.0. running mean: -5.8230879957193755\n",
      "resetting env. episode reward total was -1.0. running mean: -5.774857115762181\n",
      "resetting env. episode reward total was -3.0. running mean: -5.7471085446045596\n",
      "resetting env. episode reward total was -7.0. running mean: -5.759637459158514\n",
      "resetting env. episode reward total was -10.0. running mean: -5.802041084566929\n",
      "resetting env. episode reward total was -15.0. running mean: -5.8940206737212595\n",
      "resetting env. episode reward total was -4.0. running mean: -5.875080466984047\n",
      "resetting env. episode reward total was -5.0. running mean: -5.866329662314206\n",
      "resetting env. episode reward total was -8.0. running mean: -5.8876663656910635\n",
      "resetting env. episode reward total was -9.0. running mean: -5.918789702034153\n",
      "resetting env. episode reward total was -8.0. running mean: -5.939601805013812\n",
      "resetting env. episode reward total was -4.0. running mean: -5.920205786963674\n",
      "resetting env. episode reward total was -9.0. running mean: -5.951003729094037\n",
      "resetting env. episode reward total was -14.0. running mean: -6.031493691803096\n",
      "resetting env. episode reward total was -10.0. running mean: -6.071178754885064\n",
      "resetting env. episode reward total was -15.0. running mean: -6.160466967336214\n",
      "resetting env. episode reward total was -15.0. running mean: -6.2488622976628525\n",
      "resetting env. episode reward total was -13.0. running mean: -6.316373674686224\n",
      "resetting env. episode reward total was -13.0. running mean: -6.383209937939362\n",
      "resetting env. episode reward total was -5.0. running mean: -6.369377838559968\n",
      "resetting env. episode reward total was -8.0. running mean: -6.385684060174369\n",
      "resetting env. episode reward total was -2.0. running mean: -6.341827219572624\n",
      "resetting env. episode reward total was 1.0. running mean: -6.268408947376899\n",
      "resetting env. episode reward total was -8.0. running mean: -6.28572485790313\n",
      "resetting env. episode reward total was -10.0. running mean: -6.322867609324098\n",
      "resetting env. episode reward total was -8.0. running mean: -6.339638933230857\n",
      "resetting env. episode reward total was -7.0. running mean: -6.346242543898549\n",
      "resetting env. episode reward total was -7.0. running mean: -6.352780118459563\n",
      "resetting env. episode reward total was -9.0. running mean: -6.379252317274967\n",
      "resetting env. episode reward total was -17.0. running mean: -6.485459794102217\n",
      "resetting env. episode reward total was -11.0. running mean: -6.530605196161195\n",
      "resetting env. episode reward total was -13.0. running mean: -6.595299144199583\n",
      "resetting env. episode reward total was -1.0. running mean: -6.539346152757586\n",
      "resetting env. episode reward total was -15.0. running mean: -6.623952691230011\n",
      "resetting env. episode reward total was -6.0. running mean: -6.617713164317711\n",
      "resetting env. episode reward total was -3.0. running mean: -6.581536032674534\n",
      "resetting env. episode reward total was -5.0. running mean: -6.565720672347789\n",
      "resetting env. episode reward total was -7.0. running mean: -6.570063465624311\n",
      "resetting env. episode reward total was -4.0. running mean: -6.544362830968068\n",
      "resetting env. episode reward total was -11.0. running mean: -6.588919202658388\n",
      "resetting env. episode reward total was -9.0. running mean: -6.613030010631803\n",
      "resetting env. episode reward total was -6.0. running mean: -6.606899710525485\n",
      "resetting env. episode reward total was -9.0. running mean: -6.63083071342023\n",
      "resetting env. episode reward total was 10.0. running mean: -6.464522406286028\n",
      "resetting env. episode reward total was -10.0. running mean: -6.499877182223167\n",
      "resetting env. episode reward total was -7.0. running mean: -6.504878410400935\n",
      "resetting env. episode reward total was 5.0. running mean: -6.389829626296926\n",
      "resetting env. episode reward total was 4.0. running mean: -6.285931330033956\n",
      "resetting env. episode reward total was -7.0. running mean: -6.293072016733617\n",
      "resetting env. episode reward total was -9.0. running mean: -6.32014129656628\n",
      "resetting env. episode reward total was -3.0. running mean: -6.286939883600618\n",
      "resetting env. episode reward total was -4.0. running mean: -6.264070484764612\n",
      "resetting env. episode reward total was -4.0. running mean: -6.241429779916966\n",
      "resetting env. episode reward total was -8.0. running mean: -6.259015482117796\n",
      "resetting env. episode reward total was -12.0. running mean: -6.316425327296618\n",
      "resetting env. episode reward total was -12.0. running mean: -6.3732610740236515\n",
      "resetting env. episode reward total was -4.0. running mean: -6.349528463283415\n",
      "resetting env. episode reward total was -14.0. running mean: -6.42603317865058\n",
      "resetting env. episode reward total was -6.0. running mean: -6.421772846864074\n",
      "resetting env. episode reward total was 2.0. running mean: -6.337555118395433\n",
      "resetting env. episode reward total was 4.0. running mean: -6.234179567211479\n",
      "resetting env. episode reward total was 11.0. running mean: -6.061837771539364\n",
      "resetting env. episode reward total was -5.0. running mean: -6.05121939382397\n",
      "resetting env. episode reward total was -8.0. running mean: -6.07070719988573\n",
      "resetting env. episode reward total was -5.0. running mean: -6.060000127886872\n",
      "resetting env. episode reward total was -1.0. running mean: -6.0094001266080035\n",
      "resetting env. episode reward total was -6.0. running mean: -6.009306125341923\n",
      "resetting env. episode reward total was -10.0. running mean: -6.049213064088503\n",
      "resetting env. episode reward total was -14.0. running mean: -6.128720933447618\n",
      "resetting env. episode reward total was -7.0. running mean: -6.1374337241131425\n",
      "resetting env. episode reward total was -7.0. running mean: -6.146059386872011\n",
      "resetting env. episode reward total was -5.0. running mean: -6.134598793003291\n",
      "resetting env. episode reward total was -4.0. running mean: -6.113252805073258\n",
      "resetting env. episode reward total was 1.0. running mean: -6.0421202770225255\n",
      "resetting env. episode reward total was -11.0. running mean: -6.0916990742523005\n",
      "resetting env. episode reward total was -15.0. running mean: -6.1807820835097775\n",
      "resetting env. episode reward total was -2.0. running mean: -6.1389742626746795\n",
      "resetting env. episode reward total was -6.0. running mean: -6.137584520047932\n",
      "resetting env. episode reward total was -10.0. running mean: -6.1762086748474525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -13.0. running mean: -6.2444465880989775\n",
      "resetting env. episode reward total was -8.0. running mean: -6.262002122217988\n",
      "resetting env. episode reward total was -8.0. running mean: -6.279382100995807\n",
      "resetting env. episode reward total was -9.0. running mean: -6.306588279985849\n",
      "resetting env. episode reward total was -11.0. running mean: -6.353522397185991\n",
      "resetting env. episode reward total was -10.0. running mean: -6.389987173214131\n",
      "resetting env. episode reward total was -16.0. running mean: -6.486087301481989\n",
      "resetting env. episode reward total was -1.0. running mean: -6.431226428467169\n",
      "resetting env. episode reward total was -5.0. running mean: -6.416914164182497\n",
      "resetting env. episode reward total was -12.0. running mean: -6.472745022540672\n",
      "resetting env. episode reward total was -6.0. running mean: -6.468017572315265\n",
      "resetting env. episode reward total was -5.0. running mean: -6.453337396592112\n",
      "resetting env. episode reward total was -11.0. running mean: -6.498804022626191\n",
      "resetting env. episode reward total was -7.0. running mean: -6.50381598239993\n",
      "resetting env. episode reward total was -6.0. running mean: -6.49877782257593\n",
      "resetting env. episode reward total was -13.0. running mean: -6.56379004435017\n",
      "resetting env. episode reward total was -7.0. running mean: -6.568152143906668\n",
      "resetting env. episode reward total was 2.0. running mean: -6.482470622467602\n",
      "resetting env. episode reward total was -2.0. running mean: -6.437645916242926\n",
      "resetting env. episode reward total was -8.0. running mean: -6.453269457080497\n",
      "resetting env. episode reward total was -8.0. running mean: -6.468736762509692\n",
      "resetting env. episode reward total was -13.0. running mean: -6.534049394884595\n",
      "resetting env. episode reward total was -8.0. running mean: -6.548708900935749\n",
      "resetting env. episode reward total was -11.0. running mean: -6.593221811926392\n",
      "resetting env. episode reward total was -2.0. running mean: -6.547289593807127\n",
      "resetting env. episode reward total was -1.0. running mean: -6.491816697869056\n",
      "resetting env. episode reward total was -7.0. running mean: -6.496898530890365\n",
      "resetting env. episode reward total was -7.0. running mean: -6.501929545581462\n",
      "resetting env. episode reward total was -2.0. running mean: -6.456910250125647\n",
      "resetting env. episode reward total was -6.0. running mean: -6.45234114762439\n",
      "resetting env. episode reward total was -3.0. running mean: -6.417817736148146\n",
      "resetting env. episode reward total was -5.0. running mean: -6.403639558786665\n",
      "resetting env. episode reward total was -8.0. running mean: -6.419603163198798\n",
      "resetting env. episode reward total was -11.0. running mean: -6.465407131566811\n",
      "resetting env. episode reward total was -11.0. running mean: -6.510753060251143\n",
      "resetting env. episode reward total was -6.0. running mean: -6.505645529648631\n",
      "resetting env. episode reward total was -9.0. running mean: -6.530589074352145\n",
      "resetting env. episode reward total was -6.0. running mean: -6.525283183608623\n",
      "resetting env. episode reward total was -3.0. running mean: -6.490030351772537\n",
      "resetting env. episode reward total was -4.0. running mean: -6.465130048254812\n",
      "resetting env. episode reward total was -11.0. running mean: -6.5104787477722645\n",
      "resetting env. episode reward total was -10.0. running mean: -6.545373960294541\n",
      "resetting env. episode reward total was -13.0. running mean: -6.6099202206915955\n",
      "resetting env. episode reward total was -7.0. running mean: -6.613821018484679\n",
      "resetting env. episode reward total was -12.0. running mean: -6.6676828082998325\n",
      "resetting env. episode reward total was -6.0. running mean: -6.661005980216833\n",
      "resetting env. episode reward total was -14.0. running mean: -6.734395920414665\n",
      "resetting env. episode reward total was -11.0. running mean: -6.7770519612105184\n",
      "resetting env. episode reward total was -7.0. running mean: -6.779281441598413\n",
      "resetting env. episode reward total was -5.0. running mean: -6.761488627182429\n",
      "resetting env. episode reward total was -7.0. running mean: -6.763873740910604\n",
      "resetting env. episode reward total was -9.0. running mean: -6.786235003501498\n",
      "resetting env. episode reward total was -7.0. running mean: -6.788372653466483\n",
      "resetting env. episode reward total was -5.0. running mean: -6.770488926931819\n",
      "resetting env. episode reward total was -10.0. running mean: -6.8027840376625\n",
      "resetting env. episode reward total was -13.0. running mean: -6.864756197285875\n",
      "resetting env. episode reward total was -10.0. running mean: -6.896108635313015\n",
      "resetting env. episode reward total was -7.0. running mean: -6.897147548959886\n",
      "resetting env. episode reward total was -11.0. running mean: -6.938176073470287\n",
      "resetting env. episode reward total was -4.0. running mean: -6.908794312735584\n",
      "resetting env. episode reward total was -9.0. running mean: -6.929706369608228\n",
      "resetting env. episode reward total was -10.0. running mean: -6.960409305912146\n",
      "resetting env. episode reward total was -6.0. running mean: -6.950805212853024\n",
      "resetting env. episode reward total was -1.0. running mean: -6.891297160724493\n",
      "resetting env. episode reward total was -11.0. running mean: -6.932384189117248\n",
      "resetting env. episode reward total was -7.0. running mean: -6.933060347226076\n",
      "resetting env. episode reward total was -5.0. running mean: -6.913729743753815\n",
      "resetting env. episode reward total was -7.0. running mean: -6.914592446316277\n",
      "resetting env. episode reward total was 12.0. running mean: -6.725446521853114\n",
      "resetting env. episode reward total was -2.0. running mean: -6.6781920566345825\n",
      "resetting env. episode reward total was -11.0. running mean: -6.721410136068237\n",
      "resetting env. episode reward total was 9.0. running mean: -6.564196034707555\n",
      "resetting env. episode reward total was -1.0. running mean: -6.508554074360479\n",
      "resetting env. episode reward total was 7.0. running mean: -6.373468533616873\n",
      "resetting env. episode reward total was -1.0. running mean: -6.319733848280705\n",
      "resetting env. episode reward total was -9.0. running mean: -6.346536509797898\n",
      "resetting env. episode reward total was -10.0. running mean: -6.383071144699918\n",
      "resetting env. episode reward total was -8.0. running mean: -6.399240433252919\n",
      "resetting env. episode reward total was -1.0. running mean: -6.345248028920389\n",
      "resetting env. episode reward total was -8.0. running mean: -6.361795548631186\n",
      "resetting env. episode reward total was -4.0. running mean: -6.338177593144874\n",
      "resetting env. episode reward total was 4.0. running mean: -6.234795817213425\n",
      "resetting env. episode reward total was -7.0. running mean: -6.242447859041291\n",
      "resetting env. episode reward total was -4.0. running mean: -6.220023380450878\n",
      "resetting env. episode reward total was 6.0. running mean: -6.09782314664637\n",
      "resetting env. episode reward total was -1.0. running mean: -6.046844915179905\n",
      "resetting env. episode reward total was -9.0. running mean: -6.076376466028106\n",
      "resetting env. episode reward total was -8.0. running mean: -6.095612701367824\n",
      "resetting env. episode reward total was -10.0. running mean: -6.134656574354145\n",
      "resetting env. episode reward total was -1.0. running mean: -6.083310008610604\n",
      "resetting env. episode reward total was -10.0. running mean: -6.122476908524497\n",
      "resetting env. episode reward total was -1.0. running mean: -6.071252139439252\n",
      "resetting env. episode reward total was -3.0. running mean: -6.04053961804486\n",
      "resetting env. episode reward total was -3.0. running mean: -6.010134221864411\n",
      "resetting env. episode reward total was -2.0. running mean: -5.970032879645767\n",
      "resetting env. episode reward total was -10.0. running mean: -6.010332550849308\n",
      "resetting env. episode reward total was -5.0. running mean: -6.000229225340815\n",
      "resetting env. episode reward total was 2.0. running mean: -5.920226933087408\n",
      "resetting env. episode reward total was 5.0. running mean: -5.811024663756534\n",
      "resetting env. episode reward total was -12.0. running mean: -5.8729144171189684\n",
      "resetting env. episode reward total was 1.0. running mean: -5.8041852729477785\n",
      "resetting env. episode reward total was 2.0. running mean: -5.7261434202183015\n",
      "resetting env. episode reward total was -4.0. running mean: -5.708881986016118\n",
      "resetting env. episode reward total was -11.0. running mean: -5.761793166155957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -5.774175234494398\n",
      "resetting env. episode reward total was -11.0. running mean: -5.826433482149454\n",
      "resetting env. episode reward total was -9.0. running mean: -5.85816914732796\n",
      "resetting env. episode reward total was -9.0. running mean: -5.88958745585468\n",
      "resetting env. episode reward total was -11.0. running mean: -5.940691581296133\n",
      "resetting env. episode reward total was -7.0. running mean: -5.951284665483172\n",
      "resetting env. episode reward total was -6.0. running mean: -5.95177181882834\n",
      "resetting env. episode reward total was -2.0. running mean: -5.912254100640056\n",
      "resetting env. episode reward total was -10.0. running mean: -5.953131559633655\n",
      "resetting env. episode reward total was -11.0. running mean: -6.003600244037319\n",
      "resetting env. episode reward total was -11.0. running mean: -6.053564241596946\n",
      "resetting env. episode reward total was 1.0. running mean: -5.983028599180977\n",
      "resetting env. episode reward total was 1.0. running mean: -5.913198313189167\n",
      "resetting env. episode reward total was -12.0. running mean: -5.974066330057275\n",
      "resetting env. episode reward total was -8.0. running mean: -5.994325666756703\n",
      "resetting env. episode reward total was -7.0. running mean: -6.0043824100891365\n",
      "resetting env. episode reward total was 2.0. running mean: -5.924338585988245\n",
      "resetting env. episode reward total was -7.0. running mean: -5.935095200128363\n",
      "resetting env. episode reward total was 4.0. running mean: -5.83574424812708\n",
      "resetting env. episode reward total was -6.0. running mean: -5.837386805645808\n",
      "resetting env. episode reward total was -9.0. running mean: -5.86901293758935\n",
      "resetting env. episode reward total was -9.0. running mean: -5.900322808213456\n",
      "resetting env. episode reward total was -13.0. running mean: -5.971319580131322\n",
      "resetting env. episode reward total was -9.0. running mean: -6.0016063843300085\n",
      "resetting env. episode reward total was -2.0. running mean: -5.961590320486708\n",
      "resetting env. episode reward total was -3.0. running mean: -5.9319744172818405\n",
      "resetting env. episode reward total was -10.0. running mean: -5.972654673109021\n",
      "resetting env. episode reward total was -2.0. running mean: -5.932928126377931\n",
      "resetting env. episode reward total was -11.0. running mean: -5.983598845114152\n",
      "resetting env. episode reward total was -9.0. running mean: -6.01376285666301\n",
      "resetting env. episode reward total was -9.0. running mean: -6.04362522809638\n",
      "resetting env. episode reward total was -3.0. running mean: -6.013188975815416\n",
      "resetting env. episode reward total was 7.0. running mean: -5.883057086057261\n",
      "resetting env. episode reward total was -6.0. running mean: -5.884226515196688\n",
      "resetting env. episode reward total was 5.0. running mean: -5.775384250044721\n",
      "resetting env. episode reward total was -3.0. running mean: -5.747630407544274\n",
      "resetting env. episode reward total was -6.0. running mean: -5.750154103468831\n",
      "resetting env. episode reward total was -9.0. running mean: -5.7826525624341425\n",
      "resetting env. episode reward total was -3.0. running mean: -5.754826036809801\n",
      "resetting env. episode reward total was -12.0. running mean: -5.817277776441703\n",
      "resetting env. episode reward total was 4.0. running mean: -5.7191049986772855\n",
      "resetting env. episode reward total was 4.0. running mean: -5.621913948690513\n",
      "resetting env. episode reward total was 10.0. running mean: -5.465694809203608\n",
      "resetting env. episode reward total was -5.0. running mean: -5.4610378611115715\n",
      "resetting env. episode reward total was 2.0. running mean: -5.386427482500456\n",
      "resetting env. episode reward total was -5.0. running mean: -5.382563207675451\n",
      "resetting env. episode reward total was 8.0. running mean: -5.248737575598697\n",
      "resetting env. episode reward total was -7.0. running mean: -5.26625019984271\n",
      "resetting env. episode reward total was -3.0. running mean: -5.243587697844283\n",
      "resetting env. episode reward total was -5.0. running mean: -5.24115182086584\n",
      "resetting env. episode reward total was -9.0. running mean: -5.278740302657181\n",
      "resetting env. episode reward total was -13.0. running mean: -5.355952899630609\n",
      "resetting env. episode reward total was 9.0. running mean: -5.212393370634303\n",
      "resetting env. episode reward total was -10.0. running mean: -5.26026943692796\n",
      "resetting env. episode reward total was -11.0. running mean: -5.31766674255868\n",
      "resetting env. episode reward total was -4.0. running mean: -5.304490075133094\n",
      "resetting env. episode reward total was -12.0. running mean: -5.371445174381763\n",
      "resetting env. episode reward total was -5.0. running mean: -5.367730722637945\n",
      "resetting env. episode reward total was -4.0. running mean: -5.354053415411565\n",
      "resetting env. episode reward total was -5.0. running mean: -5.350512881257449\n",
      "resetting env. episode reward total was -3.0. running mean: -5.327007752444875\n",
      "resetting env. episode reward total was -9.0. running mean: -5.363737674920427\n",
      "resetting env. episode reward total was -4.0. running mean: -5.350100298171222\n",
      "resetting env. episode reward total was -3.0. running mean: -5.32659929518951\n",
      "resetting env. episode reward total was -5.0. running mean: -5.323333302237614\n",
      "resetting env. episode reward total was -9.0. running mean: -5.360099969215238\n",
      "resetting env. episode reward total was -4.0. running mean: -5.346498969523085\n",
      "resetting env. episode reward total was -10.0. running mean: -5.393033979827854\n",
      "resetting env. episode reward total was -15.0. running mean: -5.489103640029576\n",
      "resetting env. episode reward total was -8.0. running mean: -5.5142126036292805\n",
      "resetting env. episode reward total was -9.0. running mean: -5.549070477592988\n",
      "resetting env. episode reward total was -7.0. running mean: -5.563579772817058\n",
      "resetting env. episode reward total was -10.0. running mean: -5.6079439750888875\n",
      "resetting env. episode reward total was 9.0. running mean: -5.461864535337999\n",
      "resetting env. episode reward total was 2.0. running mean: -5.387245889984619\n",
      "resetting env. episode reward total was -3.0. running mean: -5.363373431084773\n",
      "resetting env. episode reward total was -4.0. running mean: -5.349739696773925\n",
      "resetting env. episode reward total was -9.0. running mean: -5.386242299806185\n",
      "resetting env. episode reward total was -6.0. running mean: -5.392379876808123\n",
      "resetting env. episode reward total was -1.0. running mean: -5.348456078040042\n",
      "resetting env. episode reward total was -9.0. running mean: -5.384971517259641\n",
      "resetting env. episode reward total was -14.0. running mean: -5.471121802087044\n",
      "resetting env. episode reward total was -14.0. running mean: -5.556410584066173\n",
      "resetting env. episode reward total was -1.0. running mean: -5.510846478225511\n",
      "resetting env. episode reward total was -1.0. running mean: -5.465738013443255\n",
      "resetting env. episode reward total was 4.0. running mean: -5.371080633308822\n",
      "resetting env. episode reward total was 1.0. running mean: -5.307369826975735\n",
      "resetting env. episode reward total was -11.0. running mean: -5.364296128705978\n",
      "resetting env. episode reward total was -7.0. running mean: -5.380653167418918\n",
      "resetting env. episode reward total was -7.0. running mean: -5.39684663574473\n",
      "resetting env. episode reward total was -7.0. running mean: -5.412878169387283\n",
      "resetting env. episode reward total was -9.0. running mean: -5.44874938769341\n",
      "resetting env. episode reward total was -6.0. running mean: -5.454261893816476\n",
      "resetting env. episode reward total was -3.0. running mean: -5.429719274878312\n",
      "resetting env. episode reward total was -3.0. running mean: -5.405422082129529\n",
      "resetting env. episode reward total was -16.0. running mean: -5.5113678613082335\n",
      "resetting env. episode reward total was -7.0. running mean: -5.526254182695151\n",
      "resetting env. episode reward total was -1.0. running mean: -5.4809916408682\n",
      "resetting env. episode reward total was -3.0. running mean: -5.456181724459518\n",
      "resetting env. episode reward total was -9.0. running mean: -5.491619907214923\n",
      "resetting env. episode reward total was -8.0. running mean: -5.516703708142773\n",
      "resetting env. episode reward total was -5.0. running mean: -5.511536671061346\n",
      "resetting env. episode reward total was 8.0. running mean: -5.376421304350732\n",
      "resetting env. episode reward total was -7.0. running mean: -5.392657091307225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: -5.418730520394153\n",
      "resetting env. episode reward total was -2.0. running mean: -5.38454321519021\n",
      "resetting env. episode reward total was 1.0. running mean: -5.320697783038309\n",
      "resetting env. episode reward total was 6.0. running mean: -5.207490805207926\n",
      "resetting env. episode reward total was 4.0. running mean: -5.115415897155847\n",
      "resetting env. episode reward total was 3.0. running mean: -5.034261738184288\n",
      "resetting env. episode reward total was -2.0. running mean: -5.003919120802444\n",
      "resetting env. episode reward total was -2.0. running mean: -4.973879929594419\n",
      "resetting env. episode reward total was -3.0. running mean: -4.954141130298475\n",
      "resetting env. episode reward total was 4.0. running mean: -4.86459971899549\n",
      "resetting env. episode reward total was 5.0. running mean: -4.765953721805535\n",
      "resetting env. episode reward total was -11.0. running mean: -4.82829418458748\n",
      "resetting env. episode reward total was 3.0. running mean: -4.750011242741605\n",
      "resetting env. episode reward total was -5.0. running mean: -4.752511130314189\n",
      "resetting env. episode reward total was -7.0. running mean: -4.774986019011047\n",
      "resetting env. episode reward total was 5.0. running mean: -4.677236158820937\n",
      "resetting env. episode reward total was -11.0. running mean: -4.740463797232728\n",
      "resetting env. episode reward total was -2.0. running mean: -4.7130591592604\n",
      "resetting env. episode reward total was -9.0. running mean: -4.755928567667795\n",
      "resetting env. episode reward total was -7.0. running mean: -4.778369281991118\n",
      "resetting env. episode reward total was 12.0. running mean: -4.610585589171206\n",
      "resetting env. episode reward total was -7.0. running mean: -4.634479733279495\n",
      "resetting env. episode reward total was 6.0. running mean: -4.5281349359467\n",
      "resetting env. episode reward total was 10.0. running mean: -4.382853586587234\n",
      "resetting env. episode reward total was -8.0. running mean: -4.419025050721362\n",
      "resetting env. episode reward total was 5.0. running mean: -4.324834800214148\n",
      "resetting env. episode reward total was 10.0. running mean: -4.181586452212007\n",
      "resetting env. episode reward total was -6.0. running mean: -4.199770587689886\n",
      "resetting env. episode reward total was -7.0. running mean: -4.227772881812988\n",
      "resetting env. episode reward total was -6.0. running mean: -4.245495152994858\n",
      "resetting env. episode reward total was -10.0. running mean: -4.303040201464909\n",
      "resetting env. episode reward total was 11.0. running mean: -4.15000979945026\n",
      "resetting env. episode reward total was -3.0. running mean: -4.1385097014557575\n",
      "resetting env. episode reward total was 10.0. running mean: -3.9971246044412\n",
      "resetting env. episode reward total was 9.0. running mean: -3.8671533583967883\n",
      "resetting env. episode reward total was 4.0. running mean: -3.7884818248128203\n",
      "resetting env. episode reward total was -2.0. running mean: -3.770597006564692\n",
      "resetting env. episode reward total was 3.0. running mean: -3.7028910364990453\n",
      "resetting env. episode reward total was -4.0. running mean: -3.705862126134055\n",
      "resetting env. episode reward total was -5.0. running mean: -3.718803504872714\n",
      "resetting env. episode reward total was -4.0. running mean: -3.721615469823987\n",
      "resetting env. episode reward total was -9.0. running mean: -3.774399315125747\n",
      "resetting env. episode reward total was -7.0. running mean: -3.8066553219744894\n",
      "resetting env. episode reward total was 6.0. running mean: -3.7085887687547445\n",
      "resetting env. episode reward total was -2.0. running mean: -3.6915028810671973\n",
      "resetting env. episode reward total was 6.0. running mean: -3.594587852256525\n",
      "resetting env. episode reward total was -6.0. running mean: -3.61864197373396\n",
      "resetting env. episode reward total was -1.0. running mean: -3.59245555399662\n",
      "resetting env. episode reward total was -3.0. running mean: -3.5865309984566536\n",
      "resetting env. episode reward total was -7.0. running mean: -3.6206656884720867\n",
      "resetting env. episode reward total was -6.0. running mean: -3.644459031587366\n",
      "resetting env. episode reward total was -9.0. running mean: -3.698014441271492\n",
      "resetting env. episode reward total was 6.0. running mean: -3.601034296858777\n",
      "resetting env. episode reward total was -4.0. running mean: -3.605023953890189\n",
      "resetting env. episode reward total was -11.0. running mean: -3.678973714351287\n",
      "resetting env. episode reward total was -3.0. running mean: -3.672183977207774\n",
      "resetting env. episode reward total was -5.0. running mean: -3.685462137435696\n",
      "resetting env. episode reward total was -11.0. running mean: -3.758607516061339\n",
      "resetting env. episode reward total was -9.0. running mean: -3.8110214409007255\n",
      "resetting env. episode reward total was 7.0. running mean: -3.7029112264917186\n",
      "resetting env. episode reward total was -10.0. running mean: -3.7658821142268013\n",
      "resetting env. episode reward total was -12.0. running mean: -3.8482232930845335\n",
      "resetting env. episode reward total was -5.0. running mean: -3.859741060153688\n",
      "resetting env. episode reward total was -2.0. running mean: -3.841143649552151\n",
      "resetting env. episode reward total was -7.0. running mean: -3.8727322130566293\n",
      "resetting env. episode reward total was -9.0. running mean: -3.9240048909260627\n",
      "resetting env. episode reward total was -3.0. running mean: -3.914764842016802\n",
      "resetting env. episode reward total was -10.0. running mean: -3.975617193596634\n",
      "resetting env. episode reward total was -9.0. running mean: -4.025861021660668\n",
      "resetting env. episode reward total was -7.0. running mean: -4.055602411444061\n",
      "resetting env. episode reward total was -19.0. running mean: -4.205046387329621\n",
      "resetting env. episode reward total was -5.0. running mean: -4.212995923456325\n",
      "resetting env. episode reward total was -6.0. running mean: -4.230865964221762\n",
      "resetting env. episode reward total was -5.0. running mean: -4.238557304579544\n",
      "resetting env. episode reward total was -1.0. running mean: -4.206171731533749\n",
      "resetting env. episode reward total was -5.0. running mean: -4.214110014218411\n",
      "resetting env. episode reward total was 7.0. running mean: -4.1019689140762265\n",
      "resetting env. episode reward total was -10.0. running mean: -4.160949224935464\n",
      "resetting env. episode reward total was -8.0. running mean: -4.199339732686109\n",
      "resetting env. episode reward total was 1.0. running mean: -4.147346335359249\n",
      "resetting env. episode reward total was -4.0. running mean: -4.145872872005656\n",
      "resetting env. episode reward total was 6.0. running mean: -4.0444141432856\n",
      "resetting env. episode reward total was -11.0. running mean: -4.113970001852744\n",
      "resetting env. episode reward total was 7.0. running mean: -4.002830301834216\n",
      "resetting env. episode reward total was -7.0. running mean: -4.032801998815874\n",
      "resetting env. episode reward total was -7.0. running mean: -4.062473978827715\n",
      "resetting env. episode reward total was -5.0. running mean: -4.071849239039437\n",
      "resetting env. episode reward total was -12.0. running mean: -4.151130746649043\n",
      "resetting env. episode reward total was -17.0. running mean: -4.279619439182553\n",
      "resetting env. episode reward total was 10.0. running mean: -4.136823244790728\n",
      "resetting env. episode reward total was -7.0. running mean: -4.165455012342821\n",
      "resetting env. episode reward total was -8.0. running mean: -4.203800462219393\n",
      "resetting env. episode reward total was -12.0. running mean: -4.281762457597199\n",
      "resetting env. episode reward total was -12.0. running mean: -4.358944833021227\n",
      "resetting env. episode reward total was -5.0. running mean: -4.365355384691015\n",
      "resetting env. episode reward total was -12.0. running mean: -4.441701830844105\n",
      "resetting env. episode reward total was -7.0. running mean: -4.467284812535664\n",
      "resetting env. episode reward total was -1.0. running mean: -4.432611964410307\n",
      "resetting env. episode reward total was 2.0. running mean: -4.368285844766204\n",
      "resetting env. episode reward total was -9.0. running mean: -4.414602986318542\n",
      "resetting env. episode reward total was -10.0. running mean: -4.470456956455356\n",
      "resetting env. episode reward total was -3.0. running mean: -4.455752386890802\n",
      "resetting env. episode reward total was -10.0. running mean: -4.511194863021894\n",
      "resetting env. episode reward total was -6.0. running mean: -4.526082914391674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: -4.520822085247757\n",
      "resetting env. episode reward total was 4.0. running mean: -4.43561386439528\n",
      "resetting env. episode reward total was 6.0. running mean: -4.331257725751327\n",
      "resetting env. episode reward total was -6.0. running mean: -4.347945148493814\n",
      "resetting env. episode reward total was -4.0. running mean: -4.344465697008876\n",
      "resetting env. episode reward total was -6.0. running mean: -4.3610210400387865\n",
      "resetting env. episode reward total was 6.0. running mean: -4.257410829638399\n",
      "resetting env. episode reward total was -1.0. running mean: -4.224836721342014\n",
      "resetting env. episode reward total was -9.0. running mean: -4.272588354128594\n",
      "resetting env. episode reward total was -5.0. running mean: -4.279862470587307\n",
      "resetting env. episode reward total was 5.0. running mean: -4.187063845881434\n",
      "resetting env. episode reward total was -9.0. running mean: -4.23519320742262\n",
      "resetting env. episode reward total was -8.0. running mean: -4.272841275348394\n",
      "resetting env. episode reward total was -9.0. running mean: -4.32011286259491\n",
      "resetting env. episode reward total was -9.0. running mean: -4.366911733968961\n",
      "resetting env. episode reward total was -5.0. running mean: -4.3732426166292715\n",
      "resetting env. episode reward total was 1.0. running mean: -4.319510190462979\n",
      "resetting env. episode reward total was 7.0. running mean: -4.206315088558349\n",
      "resetting env. episode reward total was -4.0. running mean: -4.204251937672765\n",
      "resetting env. episode reward total was 4.0. running mean: -4.122209418296038\n",
      "resetting env. episode reward total was -7.0. running mean: -4.1509873241130775\n",
      "resetting env. episode reward total was -7.0. running mean: -4.179477450871947\n",
      "resetting env. episode reward total was -10.0. running mean: -4.237682676363227\n",
      "resetting env. episode reward total was -9.0. running mean: -4.285305849599594\n",
      "resetting env. episode reward total was 3.0. running mean: -4.2124527911035985\n",
      "resetting env. episode reward total was -6.0. running mean: -4.230328263192562\n",
      "resetting env. episode reward total was 3.0. running mean: -4.158024980560636\n",
      "resetting env. episode reward total was -7.0. running mean: -4.1864447307550305\n",
      "resetting env. episode reward total was -4.0. running mean: -4.18458028344748\n",
      "resetting env. episode reward total was -13.0. running mean: -4.272734480613005\n",
      "resetting env. episode reward total was -5.0. running mean: -4.2800071358068745\n",
      "resetting env. episode reward total was 8.0. running mean: -4.157207064448806\n",
      "resetting env. episode reward total was 1.0. running mean: -4.105634993804318\n",
      "resetting env. episode reward total was 6.0. running mean: -4.004578643866275\n",
      "resetting env. episode reward total was -12.0. running mean: -4.084532857427613\n",
      "resetting env. episode reward total was -9.0. running mean: -4.133687528853336\n",
      "resetting env. episode reward total was -9.0. running mean: -4.182350653564803\n",
      "resetting env. episode reward total was -5.0. running mean: -4.1905271470291545\n",
      "resetting env. episode reward total was 1.0. running mean: -4.138621875558863\n",
      "resetting env. episode reward total was -6.0. running mean: -4.157235656803274\n",
      "resetting env. episode reward total was -9.0. running mean: -4.2056633002352415\n",
      "resetting env. episode reward total was -9.0. running mean: -4.253606667232889\n",
      "resetting env. episode reward total was 2.0. running mean: -4.19107060056056\n",
      "resetting env. episode reward total was -3.0. running mean: -4.179159894554955\n",
      "resetting env. episode reward total was -2.0. running mean: -4.1573682956094045\n",
      "resetting env. episode reward total was -5.0. running mean: -4.16579461265331\n",
      "resetting env. episode reward total was -1.0. running mean: -4.134136666526777\n",
      "resetting env. episode reward total was -6.0. running mean: -4.152795299861508\n",
      "resetting env. episode reward total was 2.0. running mean: -4.091267346862893\n",
      "resetting env. episode reward total was 2.0. running mean: -4.030354673394265\n",
      "resetting env. episode reward total was 4.0. running mean: -3.950051126660322\n",
      "resetting env. episode reward total was -9.0. running mean: -4.000550615393719\n",
      "resetting env. episode reward total was -5.0. running mean: -4.010545109239781\n",
      "resetting env. episode reward total was -1.0. running mean: -3.9804396581473833\n",
      "resetting env. episode reward total was -7.0. running mean: -4.010635261565909\n",
      "resetting env. episode reward total was -4.0. running mean: -4.01052890895025\n",
      "resetting env. episode reward total was -10.0. running mean: -4.0704236198607475\n",
      "resetting env. episode reward total was -2.0. running mean: -4.04971938366214\n",
      "resetting env. episode reward total was -2.0. running mean: -4.029222189825518\n",
      "resetting env. episode reward total was 1.0. running mean: -3.9789299679272627\n",
      "resetting env. episode reward total was -8.0. running mean: -4.0191406682479895\n",
      "resetting env. episode reward total was -6.0. running mean: -4.038949261565509\n",
      "resetting env. episode reward total was -10.0. running mean: -4.098559768949854\n",
      "resetting env. episode reward total was -11.0. running mean: -4.167574171260355\n",
      "resetting env. episode reward total was -11.0. running mean: -4.235898429547752\n",
      "resetting env. episode reward total was 6.0. running mean: -4.133539445252275\n",
      "resetting env. episode reward total was 8.0. running mean: -4.012204050799752\n",
      "resetting env. episode reward total was -8.0. running mean: -4.052082010291754\n",
      "resetting env. episode reward total was -9.0. running mean: -4.101561190188836\n",
      "resetting env. episode reward total was -7.0. running mean: -4.130545578286948\n",
      "resetting env. episode reward total was -7.0. running mean: -4.1592401225040785\n",
      "resetting env. episode reward total was -7.0. running mean: -4.1876477212790375\n",
      "resetting env. episode reward total was 1.0. running mean: -4.135771244066247\n",
      "resetting env. episode reward total was -8.0. running mean: -4.174413531625585\n",
      "resetting env. episode reward total was -5.0. running mean: -4.182669396309329\n",
      "resetting env. episode reward total was -6.0. running mean: -4.200842702346235\n",
      "resetting env. episode reward total was 1.0. running mean: -4.148834275322773\n",
      "resetting env. episode reward total was 17.0. running mean: -3.9373459325695457\n",
      "resetting env. episode reward total was -3.0. running mean: -3.92797247324385\n",
      "resetting env. episode reward total was -5.0. running mean: -3.938692748511411\n",
      "resetting env. episode reward total was -9.0. running mean: -3.989305821026297\n",
      "resetting env. episode reward total was -6.0. running mean: -4.009412762816034\n",
      "resetting env. episode reward total was -7.0. running mean: -4.039318635187874\n",
      "resetting env. episode reward total was -4.0. running mean: -4.038925448835995\n",
      "resetting env. episode reward total was -5.0. running mean: -4.048536194347635\n",
      "resetting env. episode reward total was -7.0. running mean: -4.078050832404159\n",
      "resetting env. episode reward total was -11.0. running mean: -4.147270324080118\n",
      "resetting env. episode reward total was -1.0. running mean: -4.1157976208393166\n",
      "resetting env. episode reward total was -1.0. running mean: -4.084639644630923\n",
      "resetting env. episode reward total was -5.0. running mean: -4.093793248184614\n",
      "resetting env. episode reward total was -4.0. running mean: -4.092855315702768\n",
      "resetting env. episode reward total was 4.0. running mean: -4.01192676254574\n",
      "resetting env. episode reward total was -9.0. running mean: -4.0618074949202825\n",
      "resetting env. episode reward total was -5.0. running mean: -4.07118941997108\n",
      "resetting env. episode reward total was 3.0. running mean: -4.000477525771369\n",
      "resetting env. episode reward total was -7.0. running mean: -4.030472750513655\n",
      "resetting env. episode reward total was -6.0. running mean: -4.050168023008519\n",
      "resetting env. episode reward total was -5.0. running mean: -4.059666342778433\n",
      "resetting env. episode reward total was 11.0. running mean: -3.9090696793506488\n",
      "resetting env. episode reward total was -7.0. running mean: -3.939978982557142\n",
      "resetting env. episode reward total was -4.0. running mean: -3.9405791927315703\n",
      "resetting env. episode reward total was -3.0. running mean: -3.9311734008042545\n",
      "resetting env. episode reward total was -4.0. running mean: -3.931861666796212\n",
      "resetting env. episode reward total was -9.0. running mean: -3.9825430501282497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -6.0. running mean: -4.002717619626967\n",
      "resetting env. episode reward total was -7.0. running mean: -4.032690443430697\n",
      "resetting env. episode reward total was -6.0. running mean: -4.05236353899639\n",
      "resetting env. episode reward total was -8.0. running mean: -4.091839903606426\n",
      "resetting env. episode reward total was 4.0. running mean: -4.010921504570362\n",
      "resetting env. episode reward total was -14.0. running mean: -4.110812289524659\n",
      "resetting env. episode reward total was 1.0. running mean: -4.0597041666294125\n",
      "resetting env. episode reward total was -3.0. running mean: -4.049107124963118\n",
      "resetting env. episode reward total was -1.0. running mean: -4.018616053713487\n",
      "resetting env. episode reward total was -5.0. running mean: -4.028429893176352\n",
      "resetting env. episode reward total was -2.0. running mean: -4.008145594244588\n",
      "resetting env. episode reward total was 6.0. running mean: -3.9080641383021417\n",
      "resetting env. episode reward total was -2.0. running mean: -3.88898349691912\n",
      "resetting env. episode reward total was -3.0. running mean: -3.8800936619499287\n",
      "resetting env. episode reward total was -3.0. running mean: -3.871292725330429\n",
      "resetting env. episode reward total was 1.0. running mean: -3.822579798077125\n",
      "resetting env. episode reward total was -12.0. running mean: -3.9043540000963537\n",
      "resetting env. episode reward total was 7.0. running mean: -3.7953104600953904\n",
      "resetting env. episode reward total was -5.0. running mean: -3.807357355494436\n",
      "resetting env. episode reward total was -12.0. running mean: -3.889283781939492\n",
      "resetting env. episode reward total was 4.0. running mean: -3.810390944120097\n",
      "resetting env. episode reward total was -8.0. running mean: -3.852287034678896\n",
      "resetting env. episode reward total was -12.0. running mean: -3.9337641643321075\n",
      "resetting env. episode reward total was -7.0. running mean: -3.964426522688786\n",
      "resetting env. episode reward total was -3.0. running mean: -3.954782257461898\n",
      "resetting env. episode reward total was -1.0. running mean: -3.9252344348872787\n",
      "resetting env. episode reward total was -3.0. running mean: -3.9159820905384057\n",
      "resetting env. episode reward total was -8.0. running mean: -3.9568222696330215\n",
      "resetting env. episode reward total was -5.0. running mean: -3.967254046936691\n",
      "resetting env. episode reward total was -8.0. running mean: -4.007581506467324\n",
      "resetting env. episode reward total was 4.0. running mean: -3.9275056914026507\n",
      "resetting env. episode reward total was -14.0. running mean: -4.028230634488624\n",
      "resetting env. episode reward total was -5.0. running mean: -4.037948328143738\n",
      "resetting env. episode reward total was -1.0. running mean: -4.007568844862301\n",
      "resetting env. episode reward total was -8.0. running mean: -4.047493156413678\n",
      "resetting env. episode reward total was 4.0. running mean: -3.967018224849541\n",
      "resetting env. episode reward total was 8.0. running mean: -3.8473480426010456\n",
      "resetting env. episode reward total was -9.0. running mean: -3.898874562175035\n",
      "resetting env. episode reward total was -1.0. running mean: -3.8698858165532846\n",
      "resetting env. episode reward total was -5.0. running mean: -3.8811869583877514\n",
      "resetting env. episode reward total was -6.0. running mean: -3.9023750888038737\n",
      "resetting env. episode reward total was -2.0. running mean: -3.883351337915835\n",
      "resetting env. episode reward total was -5.0. running mean: -3.8945178245366767\n",
      "resetting env. episode reward total was -5.0. running mean: -3.9055726462913096\n",
      "resetting env. episode reward total was -4.0. running mean: -3.9065169198283964\n",
      "resetting env. episode reward total was 10.0. running mean: -3.767451750630112\n",
      "resetting env. episode reward total was -10.0. running mean: -3.829777233123811\n",
      "resetting env. episode reward total was 2.0. running mean: -3.771479460792573\n",
      "resetting env. episode reward total was 5.0. running mean: -3.683764666184647\n",
      "resetting env. episode reward total was -1.0. running mean: -3.6569270195228003\n",
      "resetting env. episode reward total was -5.0. running mean: -3.670357749327572\n",
      "resetting env. episode reward total was -1.0. running mean: -3.6436541718342963\n",
      "resetting env. episode reward total was -4.0. running mean: -3.647217630115953\n",
      "resetting env. episode reward total was -12.0. running mean: -3.7307454538147935\n",
      "resetting env. episode reward total was -3.0. running mean: -3.7234379992766455\n",
      "resetting env. episode reward total was -6.0. running mean: -3.7462036192838792\n",
      "resetting env. episode reward total was -6.0. running mean: -3.7687415830910407\n",
      "resetting env. episode reward total was -16.0. running mean: -3.89105416726013\n",
      "resetting env. episode reward total was -1.0. running mean: -3.8621436255875286\n",
      "resetting env. episode reward total was 2.0. running mean: -3.803522189331653\n",
      "resetting env. episode reward total was 1.0. running mean: -3.755486967438337\n",
      "resetting env. episode reward total was -11.0. running mean: -3.8279320977639535\n",
      "resetting env. episode reward total was 1.0. running mean: -3.779652776786314\n",
      "resetting env. episode reward total was -4.0. running mean: -3.7818562490184506\n",
      "resetting env. episode reward total was -5.0. running mean: -3.794037686528266\n",
      "resetting env. episode reward total was 1.0. running mean: -3.7460973096629835\n",
      "resetting env. episode reward total was -2.0. running mean: -3.7286363365663537\n",
      "resetting env. episode reward total was -3.0. running mean: -3.72134997320069\n",
      "resetting env. episode reward total was -1.0. running mean: -3.694136473468683\n",
      "resetting env. episode reward total was -5.0. running mean: -3.7071951087339956\n",
      "resetting env. episode reward total was -2.0. running mean: -3.6901231576466555\n",
      "resetting env. episode reward total was 3.0. running mean: -3.623221926070189\n",
      "resetting env. episode reward total was -3.0. running mean: -3.6169897068094867\n",
      "resetting env. episode reward total was 8.0. running mean: -3.5008198097413916\n",
      "resetting env. episode reward total was 6.0. running mean: -3.4058116116439776\n",
      "resetting env. episode reward total was -9.0. running mean: -3.4617534955275375\n",
      "resetting env. episode reward total was -1.0. running mean: -3.437135960572262\n",
      "resetting env. episode reward total was -8.0. running mean: -3.482764600966539\n",
      "resetting env. episode reward total was -3.0. running mean: -3.4779369549568737\n",
      "resetting env. episode reward total was -5.0. running mean: -3.493157585407305\n",
      "resetting env. episode reward total was 1.0. running mean: -3.448226009553232\n",
      "resetting env. episode reward total was -9.0. running mean: -3.5037437494576995\n",
      "resetting env. episode reward total was -3.0. running mean: -3.4987063119631223\n",
      "resetting env. episode reward total was -1.0. running mean: -3.4737192488434907\n",
      "resetting env. episode reward total was 2.0. running mean: -3.418982056355056\n",
      "resetting env. episode reward total was 5.0. running mean: -3.3347922357915056\n",
      "resetting env. episode reward total was 1.0. running mean: -3.291444313433591\n",
      "resetting env. episode reward total was -9.0. running mean: -3.348529870299255\n",
      "resetting env. episode reward total was -6.0. running mean: -3.3750445715962623\n",
      "resetting env. episode reward total was 2.0. running mean: -3.3212941258802995\n",
      "resetting env. episode reward total was -3.0. running mean: -3.318081184621496\n",
      "resetting env. episode reward total was -11.0. running mean: -3.394900372775281\n",
      "resetting env. episode reward total was -3.0. running mean: -3.390951369047528\n",
      "resetting env. episode reward total was -2.0. running mean: -3.3770418553570525\n",
      "resetting env. episode reward total was 2.0. running mean: -3.323271436803482\n",
      "resetting env. episode reward total was -1.0. running mean: -3.300038722435447\n",
      "resetting env. episode reward total was -6.0. running mean: -3.3270383352110926\n",
      "resetting env. episode reward total was -5.0. running mean: -3.3437679518589816\n",
      "resetting env. episode reward total was 2.0. running mean: -3.2903302723403915\n",
      "resetting env. episode reward total was 6.0. running mean: -3.1974269696169877\n",
      "resetting env. episode reward total was -11.0. running mean: -3.275452699920818\n",
      "resetting env. episode reward total was -9.0. running mean: -3.3326981729216096\n",
      "resetting env. episode reward total was -1.0. running mean: -3.309371191192393\n",
      "resetting env. episode reward total was 7.0. running mean: -3.206277479280469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: -3.1142147044876642\n",
      "resetting env. episode reward total was 11.0. running mean: -2.9730725574427876\n",
      "resetting env. episode reward total was 2.0. running mean: -2.9233418318683597\n",
      "resetting env. episode reward total was 11.0. running mean: -2.784108413549676\n",
      "resetting env. episode reward total was -1.0. running mean: -2.766267329414179\n",
      "resetting env. episode reward total was -7.0. running mean: -2.8086046561200373\n",
      "resetting env. episode reward total was -9.0. running mean: -2.870518609558837\n",
      "resetting env. episode reward total was -7.0. running mean: -2.9118134234632485\n",
      "resetting env. episode reward total was 2.0. running mean: -2.8626952892286157\n",
      "resetting env. episode reward total was -11.0. running mean: -2.9440683363363296\n",
      "resetting env. episode reward total was -9.0. running mean: -3.004627652972966\n",
      "resetting env. episode reward total was -2.0. running mean: -2.9945813764432363\n",
      "resetting env. episode reward total was 5.0. running mean: -2.914635562678804\n",
      "resetting env. episode reward total was -5.0. running mean: -2.935489207052016\n",
      "resetting env. episode reward total was 9.0. running mean: -2.816134314981496\n",
      "resetting env. episode reward total was -1.0. running mean: -2.7979729718316806\n",
      "resetting env. episode reward total was -9.0. running mean: -2.859993242113364\n",
      "resetting env. episode reward total was -1.0. running mean: -2.84139330969223\n",
      "resetting env. episode reward total was -8.0. running mean: -2.892979376595308\n",
      "resetting env. episode reward total was 7.0. running mean: -2.794049582829355\n",
      "resetting env. episode reward total was -4.0. running mean: -2.806109087001061\n",
      "resetting env. episode reward total was -1.0. running mean: -2.7880479961310503\n",
      "resetting env. episode reward total was -5.0. running mean: -2.8101675161697397\n",
      "resetting env. episode reward total was -3.0. running mean: -2.812065841008042\n",
      "resetting env. episode reward total was -7.0. running mean: -2.853945182597961\n",
      "resetting env. episode reward total was -7.0. running mean: -2.8954057307719814\n",
      "resetting env. episode reward total was -16.0. running mean: -3.0264516734642615\n",
      "resetting env. episode reward total was 2.0. running mean: -2.976187156729619\n",
      "resetting env. episode reward total was -6.0. running mean: -3.0064252851623228\n",
      "resetting env. episode reward total was 7.0. running mean: -2.9063610323107\n",
      "resetting env. episode reward total was 13.0. running mean: -2.747297421987593\n",
      "resetting env. episode reward total was -9.0. running mean: -2.809824447767717\n",
      "resetting env. episode reward total was 5.0. running mean: -2.73172620329004\n",
      "resetting env. episode reward total was -3.0. running mean: -2.7344089412571395\n",
      "resetting env. episode reward total was -6.0. running mean: -2.767064851844568\n",
      "resetting env. episode reward total was -16.0. running mean: -2.8993942033261226\n",
      "resetting env. episode reward total was -5.0. running mean: -2.920400261292861\n",
      "resetting env. episode reward total was 4.0. running mean: -2.8511962586799324\n",
      "resetting env. episode reward total was -7.0. running mean: -2.8926842960931327\n",
      "resetting env. episode reward total was -14.0. running mean: -3.0037574531322013\n",
      "resetting env. episode reward total was 6.0. running mean: -2.913719878600879\n",
      "resetting env. episode reward total was 2.0. running mean: -2.86458267981487\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8459368530167213\n",
      "resetting env. episode reward total was -13.0. running mean: -2.947477484486554\n",
      "resetting env. episode reward total was 2.0. running mean: -2.8980027096416885\n",
      "resetting env. episode reward total was -9.0. running mean: -2.9590226825452715\n",
      "resetting env. episode reward total was -3.0. running mean: -2.9594324557198184\n",
      "resetting env. episode reward total was -5.0. running mean: -2.97983813116262\n",
      "resetting env. episode reward total was -13.0. running mean: -3.0800397498509935\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0992393523524835\n",
      "resetting env. episode reward total was -5.0. running mean: -3.1182469588289585\n",
      "resetting env. episode reward total was -11.0. running mean: -3.197064489240669\n",
      "resetting env. episode reward total was -7.0. running mean: -3.235093844348262\n",
      "resetting env. episode reward total was -5.0. running mean: -3.252742905904779\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2902154768457312\n",
      "resetting env. episode reward total was 5.0. running mean: -3.2073133220772743\n",
      "resetting env. episode reward total was -5.0. running mean: -3.2252401888565014\n",
      "resetting env. episode reward total was -12.0. running mean: -3.3129877869679363\n",
      "resetting env. episode reward total was -3.0. running mean: -3.3098579090982567\n",
      "resetting env. episode reward total was -1.0. running mean: -3.286759330007274\n",
      "resetting env. episode reward total was -7.0. running mean: -3.323891736707201\n",
      "resetting env. episode reward total was -13.0. running mean: -3.420652819340129\n",
      "resetting env. episode reward total was -4.0. running mean: -3.426446291146728\n",
      "resetting env. episode reward total was -2.0. running mean: -3.4121818282352607\n",
      "resetting env. episode reward total was -10.0. running mean: -3.478060009952908\n",
      "resetting env. episode reward total was -3.0. running mean: -3.4732794098533786\n",
      "resetting env. episode reward total was -4.0. running mean: -3.4785466157548446\n",
      "resetting env. episode reward total was 10.0. running mean: -3.343761149597296\n",
      "resetting env. episode reward total was 5.0. running mean: -3.260323538101323\n",
      "resetting env. episode reward total was -2.0. running mean: -3.24772030272031\n",
      "resetting env. episode reward total was 1.0. running mean: -3.205243099693107\n",
      "resetting env. episode reward total was 5.0. running mean: -3.123190668696176\n",
      "resetting env. episode reward total was -1.0. running mean: -3.1019587620092137\n",
      "resetting env. episode reward total was -4.0. running mean: -3.1109391743891215\n",
      "resetting env. episode reward total was -8.0. running mean: -3.15982978264523\n",
      "resetting env. episode reward total was 5.0. running mean: -3.078231484818778\n",
      "resetting env. episode reward total was 2.0. running mean: -3.0274491699705903\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0471746782708844\n",
      "resetting env. episode reward total was -13.0. running mean: -3.1467029314881754\n",
      "resetting env. episode reward total was 6.0. running mean: -3.0552359021732935\n",
      "resetting env. episode reward total was -9.0. running mean: -3.1146835431515605\n",
      "resetting env. episode reward total was -10.0. running mean: -3.183536707720045\n",
      "resetting env. episode reward total was 5.0. running mean: -3.1017013406428444\n",
      "resetting env. episode reward total was 6.0. running mean: -3.010684327236416\n",
      "resetting env. episode reward total was -1.0. running mean: -2.9905774839640515\n",
      "resetting env. episode reward total was -4.0. running mean: -3.000671709124411\n",
      "resetting env. episode reward total was -8.0. running mean: -3.050664992033167\n",
      "resetting env. episode reward total was -4.0. running mean: -3.0601583421128353\n",
      "resetting env. episode reward total was -5.0. running mean: -3.079556758691707\n",
      "resetting env. episode reward total was -10.0. running mean: -3.14876119110479\n",
      "resetting env. episode reward total was 5.0. running mean: -3.0672735791937424\n",
      "resetting env. episode reward total was -3.0. running mean: -3.0666008434018046\n",
      "resetting env. episode reward total was -3.0. running mean: -3.0659348349677864\n",
      "resetting env. episode reward total was -7.0. running mean: -3.1052754866181083\n",
      "resetting env. episode reward total was -2.0. running mean: -3.0942227317519273\n",
      "resetting env. episode reward total was -13.0. running mean: -3.1932805044344077\n",
      "resetting env. episode reward total was 1.0. running mean: -3.151347699390064\n",
      "resetting env. episode reward total was -3.0. running mean: -3.149834222396163\n",
      "resetting env. episode reward total was -13.0. running mean: -3.2483358801722013\n",
      "resetting env. episode reward total was -3.0. running mean: -3.245852521370479\n",
      "resetting env. episode reward total was -5.0. running mean: -3.263393996156774\n",
      "resetting env. episode reward total was -11.0. running mean: -3.340760056195206\n",
      "resetting env. episode reward total was -3.0. running mean: -3.337352455633254\n",
      "resetting env. episode reward total was -15.0. running mean: -3.453978931076921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -6.0. running mean: -3.479439141766152\n",
      "resetting env. episode reward total was 7.0. running mean: -3.3746447503484904\n",
      "resetting env. episode reward total was -7.0. running mean: -3.4108983028450055\n",
      "resetting env. episode reward total was -9.0. running mean: -3.4667893198165554\n",
      "resetting env. episode reward total was -5.0. running mean: -3.4821214266183897\n",
      "resetting env. episode reward total was -7.0. running mean: -3.5173002123522057\n",
      "resetting env. episode reward total was 6.0. running mean: -3.4221272102286835\n",
      "resetting env. episode reward total was -11.0. running mean: -3.4979059381263964\n",
      "resetting env. episode reward total was -8.0. running mean: -3.5429268787451327\n",
      "resetting env. episode reward total was 4.0. running mean: -3.467497609957681\n",
      "resetting env. episode reward total was -5.0. running mean: -3.482822633858104\n",
      "resetting env. episode reward total was -3.0. running mean: -3.477994407519523\n",
      "resetting env. episode reward total was -10.0. running mean: -3.5432144634443277\n",
      "resetting env. episode reward total was 4.0. running mean: -3.4677823188098844\n",
      "resetting env. episode reward total was -7.0. running mean: -3.5031044956217854\n",
      "resetting env. episode reward total was -6.0. running mean: -3.5280734506655675\n",
      "resetting env. episode reward total was -13.0. running mean: -3.6227927161589117\n",
      "resetting env. episode reward total was -6.0. running mean: -3.6465647889973227\n",
      "resetting env. episode reward total was -5.0. running mean: -3.660099141107349\n",
      "resetting env. episode reward total was -12.0. running mean: -3.7434981496962756\n",
      "resetting env. episode reward total was -2.0. running mean: -3.7260631681993126\n",
      "resetting env. episode reward total was -2.0. running mean: -3.7088025365173194\n",
      "resetting env. episode reward total was -1.0. running mean: -3.681714511152146\n",
      "resetting env. episode reward total was -3.0. running mean: -3.674897366040624\n",
      "resetting env. episode reward total was -1.0. running mean: -3.6481483923802176\n",
      "resetting env. episode reward total was -5.0. running mean: -3.6616669084564153\n",
      "resetting env. episode reward total was -15.0. running mean: -3.775050239371851\n",
      "resetting env. episode reward total was -18.0. running mean: -3.9172997369781326\n",
      "resetting env. episode reward total was -10.0. running mean: -3.9781267396083515\n",
      "resetting env. episode reward total was 3.0. running mean: -3.908345472212268\n",
      "resetting env. episode reward total was -6.0. running mean: -3.9292620174901454\n",
      "resetting env. episode reward total was -3.0. running mean: -3.919969397315244\n",
      "resetting env. episode reward total was -17.0. running mean: -4.050769703342092\n",
      "resetting env. episode reward total was -12.0. running mean: -4.130262006308671\n",
      "resetting env. episode reward total was -1.0. running mean: -4.098959386245584\n",
      "resetting env. episode reward total was -16.0. running mean: -4.217969792383128\n",
      "resetting env. episode reward total was -5.0. running mean: -4.225790094459296\n",
      "resetting env. episode reward total was -9.0. running mean: -4.273532193514703\n",
      "resetting env. episode reward total was -13.0. running mean: -4.360796871579556\n",
      "resetting env. episode reward total was -11.0. running mean: -4.427188902863761\n",
      "resetting env. episode reward total was -6.0. running mean: -4.442917013835123\n",
      "resetting env. episode reward total was -14.0. running mean: -4.538487843696771\n",
      "resetting env. episode reward total was -11.0. running mean: -4.6031029652598034\n",
      "resetting env. episode reward total was 3.0. running mean: -4.527071935607205\n",
      "resetting env. episode reward total was -4.0. running mean: -4.521801216251133\n",
      "resetting env. episode reward total was -1.0. running mean: -4.486583204088622\n",
      "resetting env. episode reward total was -5.0. running mean: -4.491717372047735\n",
      "resetting env. episode reward total was -6.0. running mean: -4.506800198327258\n",
      "resetting env. episode reward total was -11.0. running mean: -4.571732196343985\n",
      "resetting env. episode reward total was -5.0. running mean: -4.5760148743805455\n",
      "resetting env. episode reward total was -4.0. running mean: -4.57025472563674\n",
      "resetting env. episode reward total was -10.0. running mean: -4.624552178380372\n",
      "resetting env. episode reward total was -8.0. running mean: -4.658306656596569\n",
      "resetting env. episode reward total was -3.0. running mean: -4.641723590030603\n",
      "resetting env. episode reward total was 3.0. running mean: -4.565306354130296\n",
      "resetting env. episode reward total was -6.0. running mean: -4.579653290588993\n",
      "resetting env. episode reward total was -5.0. running mean: -4.583856757683103\n",
      "resetting env. episode reward total was -15.0. running mean: -4.6880181901062725\n",
      "resetting env. episode reward total was -11.0. running mean: -4.75113800820521\n",
      "resetting env. episode reward total was -14.0. running mean: -4.8436266281231575\n",
      "resetting env. episode reward total was 1.0. running mean: -4.785190361841926\n",
      "resetting env. episode reward total was -6.0. running mean: -4.797338458223506\n",
      "resetting env. episode reward total was -7.0. running mean: -4.819365073641271\n",
      "resetting env. episode reward total was -5.0. running mean: -4.821171422904858\n",
      "resetting env. episode reward total was -14.0. running mean: -4.9129597086758094\n",
      "resetting env. episode reward total was -15.0. running mean: -5.013830111589051\n",
      "resetting env. episode reward total was -11.0. running mean: -5.073691810473161\n",
      "resetting env. episode reward total was -13.0. running mean: -5.152954892368429\n",
      "resetting env. episode reward total was -8.0. running mean: -5.181425343444745\n",
      "resetting env. episode reward total was -7.0. running mean: -5.199611090010297\n",
      "resetting env. episode reward total was -9.0. running mean: -5.237614979110194\n",
      "resetting env. episode reward total was -9.0. running mean: -5.2752388293190915\n",
      "resetting env. episode reward total was -13.0. running mean: -5.3524864410259\n",
      "resetting env. episode reward total was -8.0. running mean: -5.378961576615641\n",
      "resetting env. episode reward total was -3.0. running mean: -5.355171960849485\n",
      "resetting env. episode reward total was -6.0. running mean: -5.361620241240989\n",
      "resetting env. episode reward total was -7.0. running mean: -5.378004038828579\n",
      "resetting env. episode reward total was -9.0. running mean: -5.414223998440293\n",
      "resetting env. episode reward total was -8.0. running mean: -5.44008175845589\n",
      "resetting env. episode reward total was -8.0. running mean: -5.465680940871331\n",
      "resetting env. episode reward total was 2.0. running mean: -5.391024131462618\n",
      "resetting env. episode reward total was -12.0. running mean: -5.457113890147992\n",
      "resetting env. episode reward total was -8.0. running mean: -5.482542751246513\n",
      "resetting env. episode reward total was -8.0. running mean: -5.507717323734047\n",
      "resetting env. episode reward total was -1.0. running mean: -5.462640150496706\n",
      "resetting env. episode reward total was -13.0. running mean: -5.538013748991739\n",
      "resetting env. episode reward total was 8.0. running mean: -5.402633611501821\n",
      "resetting env. episode reward total was 3.0. running mean: -5.318607275386803\n",
      "resetting env. episode reward total was -9.0. running mean: -5.355421202632935\n",
      "resetting env. episode reward total was -2.0. running mean: -5.321866990606606\n",
      "resetting env. episode reward total was -1.0. running mean: -5.2786483207005395\n",
      "resetting env. episode reward total was 4.0. running mean: -5.185861837493534\n",
      "resetting env. episode reward total was -8.0. running mean: -5.214003219118599\n",
      "resetting env. episode reward total was -7.0. running mean: -5.231863186927413\n",
      "resetting env. episode reward total was -7.0. running mean: -5.249544555058139\n",
      "resetting env. episode reward total was -7.0. running mean: -5.267049109507558\n",
      "resetting env. episode reward total was -5.0. running mean: -5.264378618412482\n",
      "resetting env. episode reward total was -12.0. running mean: -5.331734832228357\n",
      "resetting env. episode reward total was 7.0. running mean: -5.208417483906073\n",
      "resetting env. episode reward total was -11.0. running mean: -5.266333309067013\n",
      "resetting env. episode reward total was -5.0. running mean: -5.263669975976343\n",
      "resetting env. episode reward total was -7.0. running mean: -5.281033276216579\n",
      "resetting env. episode reward total was -2.0. running mean: -5.248222943454413\n",
      "resetting env. episode reward total was -1.0. running mean: -5.205740714019869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -9.0. running mean: -5.24368330687967\n",
      "resetting env. episode reward total was -5.0. running mean: -5.2412464738108735\n",
      "resetting env. episode reward total was -9.0. running mean: -5.278834009072765\n",
      "resetting env. episode reward total was -1.0. running mean: -5.236045668982037\n",
      "resetting env. episode reward total was 1.0. running mean: -5.173685212292217\n",
      "resetting env. episode reward total was -5.0. running mean: -5.171948360169294\n",
      "resetting env. episode reward total was -11.0. running mean: -5.230228876567601\n",
      "resetting env. episode reward total was -11.0. running mean: -5.287926587801925\n",
      "resetting env. episode reward total was -3.0. running mean: -5.265047321923906\n",
      "resetting env. episode reward total was -11.0. running mean: -5.322396848704668\n",
      "resetting env. episode reward total was -10.0. running mean: -5.36917288021762\n",
      "resetting env. episode reward total was -2.0. running mean: -5.335481151415443\n",
      "resetting env. episode reward total was -13.0. running mean: -5.412126339901289\n",
      "resetting env. episode reward total was 11.0. running mean: -5.248005076502276\n",
      "resetting env. episode reward total was -4.0. running mean: -5.235525025737253\n",
      "resetting env. episode reward total was -4.0. running mean: -5.223169775479881\n",
      "resetting env. episode reward total was -4.0. running mean: -5.210938077725082\n",
      "resetting env. episode reward total was -3.0. running mean: -5.188828696947831\n",
      "resetting env. episode reward total was -11.0. running mean: -5.246940409978353\n",
      "resetting env. episode reward total was 3.0. running mean: -5.164471005878569\n",
      "resetting env. episode reward total was 4.0. running mean: -5.072826295819784\n",
      "resetting env. episode reward total was 13.0. running mean: -4.892098032861586\n",
      "resetting env. episode reward total was 2.0. running mean: -4.823177052532971\n",
      "resetting env. episode reward total was 5.0. running mean: -4.724945282007641\n",
      "resetting env. episode reward total was -3.0. running mean: -4.707695829187565\n",
      "resetting env. episode reward total was -9.0. running mean: -4.750618870895689\n",
      "resetting env. episode reward total was 2.0. running mean: -4.683112682186732\n",
      "resetting env. episode reward total was -5.0. running mean: -4.6862815553648645\n",
      "resetting env. episode reward total was 8.0. running mean: -4.559418739811216\n",
      "resetting env. episode reward total was -12.0. running mean: -4.633824552413103\n",
      "resetting env. episode reward total was -2.0. running mean: -4.607486306888972\n",
      "resetting env. episode reward total was -11.0. running mean: -4.671411443820082\n",
      "resetting env. episode reward total was -3.0. running mean: -4.654697329381881\n",
      "resetting env. episode reward total was -10.0. running mean: -4.708150356088062\n",
      "resetting env. episode reward total was -3.0. running mean: -4.691068852527182\n",
      "resetting env. episode reward total was -1.0. running mean: -4.65415816400191\n",
      "resetting env. episode reward total was -7.0. running mean: -4.677616582361891\n",
      "resetting env. episode reward total was -7.0. running mean: -4.700840416538272\n",
      "resetting env. episode reward total was -9.0. running mean: -4.743832012372889\n",
      "resetting env. episode reward total was -6.0. running mean: -4.756393692249159\n",
      "resetting env. episode reward total was 2.0. running mean: -4.688829755326668\n",
      "resetting env. episode reward total was 4.0. running mean: -4.6019414577734015\n",
      "resetting env. episode reward total was 2.0. running mean: -4.535922043195668\n",
      "resetting env. episode reward total was -11.0. running mean: -4.600562822763711\n",
      "resetting env. episode reward total was -7.0. running mean: -4.624557194536075\n",
      "resetting env. episode reward total was -13.0. running mean: -4.708311622590713\n",
      "resetting env. episode reward total was -8.0. running mean: -4.7412285063648065\n",
      "resetting env. episode reward total was 4.0. running mean: -4.653816221301159\n",
      "resetting env. episode reward total was -1.0. running mean: -4.617278059088147\n",
      "resetting env. episode reward total was -12.0. running mean: -4.6911052784972656\n",
      "resetting env. episode reward total was -19.0. running mean: -4.834194225712293\n",
      "resetting env. episode reward total was -11.0. running mean: -4.895852283455171\n",
      "resetting env. episode reward total was 2.0. running mean: -4.82689376062062\n",
      "resetting env. episode reward total was -15.0. running mean: -4.928624823014414\n",
      "resetting env. episode reward total was -6.0. running mean: -4.939338574784269\n",
      "resetting env. episode reward total was -6.0. running mean: -4.949945189036426\n",
      "resetting env. episode reward total was -3.0. running mean: -4.930445737146062\n",
      "resetting env. episode reward total was 4.0. running mean: -4.841141279774601\n",
      "resetting env. episode reward total was -13.0. running mean: -4.922729866976855\n",
      "resetting env. episode reward total was -5.0. running mean: -4.923502568307087\n",
      "resetting env. episode reward total was -11.0. running mean: -4.984267542624016\n",
      "resetting env. episode reward total was -10.0. running mean: -5.034424867197775\n",
      "resetting env. episode reward total was -5.0. running mean: -5.034080618525797\n",
      "resetting env. episode reward total was -8.0. running mean: -5.063739812340539\n",
      "resetting env. episode reward total was -7.0. running mean: -5.083102414217134\n",
      "resetting env. episode reward total was 8.0. running mean: -4.952271390074962\n",
      "resetting env. episode reward total was -10.0. running mean: -5.002748676174212\n",
      "resetting env. episode reward total was 1.0. running mean: -4.94272118941247\n",
      "resetting env. episode reward total was 4.0. running mean: -4.853293977518345\n",
      "resetting env. episode reward total was 4.0. running mean: -4.7647610377431615\n",
      "resetting env. episode reward total was 1.0. running mean: -4.70711342736573\n",
      "resetting env. episode reward total was -7.0. running mean: -4.730042293092073\n",
      "resetting env. episode reward total was -13.0. running mean: -4.812741870161153\n",
      "resetting env. episode reward total was -10.0. running mean: -4.864614451459541\n",
      "resetting env. episode reward total was -11.0. running mean: -4.925968306944946\n",
      "resetting env. episode reward total was -1.0. running mean: -4.886708623875497\n",
      "resetting env. episode reward total was -11.0. running mean: -4.947841537636742\n",
      "resetting env. episode reward total was 1.0. running mean: -4.888363122260374\n",
      "resetting env. episode reward total was -10.0. running mean: -4.93947949103777\n",
      "resetting env. episode reward total was 3.0. running mean: -4.860084696127392\n",
      "resetting env. episode reward total was -5.0. running mean: -4.861483849166118\n",
      "resetting env. episode reward total was -9.0. running mean: -4.902869010674456\n",
      "resetting env. episode reward total was 1.0. running mean: -4.843840320567711\n",
      "resetting env. episode reward total was 8.0. running mean: -4.715401917362034\n",
      "resetting env. episode reward total was -9.0. running mean: -4.758247898188414\n",
      "resetting env. episode reward total was -12.0. running mean: -4.83066541920653\n",
      "resetting env. episode reward total was -8.0. running mean: -4.862358765014465\n",
      "resetting env. episode reward total was -13.0. running mean: -4.94373517736432\n",
      "resetting env. episode reward total was -11.0. running mean: -5.004297825590677\n",
      "resetting env. episode reward total was 8.0. running mean: -4.87425484733477\n",
      "resetting env. episode reward total was -1.0. running mean: -4.835512298861422\n",
      "resetting env. episode reward total was -7.0. running mean: -4.857157175872809\n",
      "resetting env. episode reward total was 3.0. running mean: -4.77858560411408\n",
      "resetting env. episode reward total was -10.0. running mean: -4.8307997480729385\n",
      "resetting env. episode reward total was -10.0. running mean: -4.882491750592209\n",
      "resetting env. episode reward total was -9.0. running mean: -4.923666833086286\n",
      "resetting env. episode reward total was -3.0. running mean: -4.904430164755423\n",
      "resetting env. episode reward total was -7.0. running mean: -4.925385863107869\n",
      "resetting env. episode reward total was -13.0. running mean: -5.0061320044767905\n",
      "resetting env. episode reward total was -5.0. running mean: -5.006070684432022\n",
      "resetting env. episode reward total was -5.0. running mean: -5.006009977587702\n",
      "resetting env. episode reward total was -6.0. running mean: -5.015949877811825\n",
      "resetting env. episode reward total was -12.0. running mean: -5.085790379033707\n",
      "resetting env. episode reward total was -5.0. running mean: -5.084932475243369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -15.0. running mean: -5.184083150490936\n",
      "resetting env. episode reward total was -15.0. running mean: -5.282242318986027\n",
      "resetting env. episode reward total was -3.0. running mean: -5.259419895796167\n",
      "resetting env. episode reward total was -5.0. running mean: -5.256825696838205\n",
      "resetting env. episode reward total was -6.0. running mean: -5.264257439869822\n",
      "resetting env. episode reward total was -9.0. running mean: -5.301614865471124\n",
      "resetting env. episode reward total was -3.0. running mean: -5.278598716816413\n",
      "resetting env. episode reward total was -1.0. running mean: -5.235812729648249\n",
      "resetting env. episode reward total was -6.0. running mean: -5.243454602351766\n",
      "resetting env. episode reward total was -7.0. running mean: -5.261020056328248\n",
      "resetting env. episode reward total was -9.0. running mean: -5.298409855764965\n",
      "resetting env. episode reward total was -11.0. running mean: -5.355425757207316\n",
      "resetting env. episode reward total was -6.0. running mean: -5.361871499635242\n",
      "resetting env. episode reward total was -9.0. running mean: -5.39825278463889\n",
      "resetting env. episode reward total was -14.0. running mean: -5.484270256792501\n",
      "resetting env. episode reward total was 6.0. running mean: -5.3694275542245755\n",
      "resetting env. episode reward total was -5.0. running mean: -5.365733278682329\n",
      "resetting env. episode reward total was -10.0. running mean: -5.412075945895506\n",
      "resetting env. episode reward total was 3.0. running mean: -5.32795518643655\n",
      "resetting env. episode reward total was 8.0. running mean: -5.194675634572184\n",
      "resetting env. episode reward total was -9.0. running mean: -5.232728878226462\n",
      "resetting env. episode reward total was -1.0. running mean: -5.190401589444197\n",
      "resetting env. episode reward total was -7.0. running mean: -5.208497573549756\n",
      "resetting env. episode reward total was -13.0. running mean: -5.286412597814258\n",
      "resetting env. episode reward total was -6.0. running mean: -5.2935484718361145\n",
      "resetting env. episode reward total was 1.0. running mean: -5.230612987117754\n",
      "resetting env. episode reward total was 1.0. running mean: -5.168306857246576\n",
      "resetting env. episode reward total was -1.0. running mean: -5.12662378867411\n",
      "resetting env. episode reward total was -15.0. running mean: -5.225357550787369\n",
      "resetting env. episode reward total was -7.0. running mean: -5.243103975279496\n",
      "resetting env. episode reward total was -10.0. running mean: -5.2906729355267\n",
      "resetting env. episode reward total was -11.0. running mean: -5.347766206171434\n",
      "resetting env. episode reward total was -12.0. running mean: -5.414288544109719\n",
      "resetting env. episode reward total was -6.0. running mean: -5.420145658668622\n",
      "resetting env. episode reward total was -10.0. running mean: -5.465944202081935\n",
      "resetting env. episode reward total was 9.0. running mean: -5.321284760061116\n",
      "resetting env. episode reward total was -11.0. running mean: -5.378071912460505\n",
      "resetting env. episode reward total was -6.0. running mean: -5.3842911933358995\n",
      "resetting env. episode reward total was -7.0. running mean: -5.40044828140254\n",
      "resetting env. episode reward total was -14.0. running mean: -5.486443798588515\n",
      "resetting env. episode reward total was -7.0. running mean: -5.50157936060263\n",
      "resetting env. episode reward total was -1.0. running mean: -5.4565635669966035\n",
      "resetting env. episode reward total was -9.0. running mean: -5.491997931326638\n",
      "resetting env. episode reward total was -1.0. running mean: -5.4470779520133705\n",
      "resetting env. episode reward total was -10.0. running mean: -5.492607172493236\n",
      "resetting env. episode reward total was 12.0. running mean: -5.317681100768303\n",
      "resetting env. episode reward total was -7.0. running mean: -5.334504289760621\n",
      "resetting env. episode reward total was -1.0. running mean: -5.291159246863014\n",
      "resetting env. episode reward total was 4.0. running mean: -5.198247654394383\n",
      "resetting env. episode reward total was -9.0. running mean: -5.23626517785044\n",
      "resetting env. episode reward total was -6.0. running mean: -5.243902526071935\n",
      "resetting env. episode reward total was -6.0. running mean: -5.251463500811215\n",
      "resetting env. episode reward total was 3.0. running mean: -5.168948865803102\n",
      "resetting env. episode reward total was -11.0. running mean: -5.227259377145072\n",
      "resetting env. episode reward total was -1.0. running mean: -5.1849867833736205\n",
      "resetting env. episode reward total was -6.0. running mean: -5.193136915539884\n",
      "resetting env. episode reward total was -3.0. running mean: -5.171205546384485\n",
      "resetting env. episode reward total was 10.0. running mean: -5.01949349092064\n",
      "resetting env. episode reward total was -2.0. running mean: -4.989298556011433\n",
      "resetting env. episode reward total was -6.0. running mean: -4.9994055704513185\n",
      "resetting env. episode reward total was -13.0. running mean: -5.0794115147468055\n",
      "resetting env. episode reward total was -7.0. running mean: -5.098617399599338\n",
      "resetting env. episode reward total was 4.0. running mean: -5.007631225603344\n",
      "resetting env. episode reward total was 7.0. running mean: -4.88755491334731\n",
      "resetting env. episode reward total was 1.0. running mean: -4.828679364213837\n",
      "resetting env. episode reward total was -15.0. running mean: -4.930392570571699\n",
      "resetting env. episode reward total was -5.0. running mean: -4.931088644865982\n",
      "resetting env. episode reward total was -11.0. running mean: -4.991777758417323\n",
      "resetting env. episode reward total was -9.0. running mean: -5.031859980833149\n",
      "resetting env. episode reward total was -11.0. running mean: -5.091541381024817\n",
      "resetting env. episode reward total was -7.0. running mean: -5.1106259672145695\n",
      "resetting env. episode reward total was -5.0. running mean: -5.1095197075424235\n",
      "resetting env. episode reward total was -10.0. running mean: -5.158424510466999\n",
      "resetting env. episode reward total was -10.0. running mean: -5.206840265362328\n",
      "resetting env. episode reward total was -14.0. running mean: -5.294771862708704\n",
      "resetting env. episode reward total was 1.0. running mean: -5.231824144081617\n",
      "resetting env. episode reward total was -3.0. running mean: -5.209505902640801\n",
      "resetting env. episode reward total was -3.0. running mean: -5.187410843614393\n",
      "resetting env. episode reward total was -17.0. running mean: -5.305536735178249\n",
      "resetting env. episode reward total was 2.0. running mean: -5.232481367826467\n",
      "resetting env. episode reward total was -8.0. running mean: -5.260156554148202\n",
      "resetting env. episode reward total was -16.0. running mean: -5.36755498860672\n",
      "resetting env. episode reward total was -2.0. running mean: -5.333879438720652\n",
      "resetting env. episode reward total was 2.0. running mean: -5.260540644333446\n",
      "resetting env. episode reward total was -3.0. running mean: -5.237935237890111\n",
      "resetting env. episode reward total was 1.0. running mean: -5.17555588551121\n",
      "resetting env. episode reward total was -9.0. running mean: -5.213800326656098\n",
      "resetting env. episode reward total was -10.0. running mean: -5.261662323389537\n",
      "resetting env. episode reward total was -5.0. running mean: -5.259045700155641\n",
      "resetting env. episode reward total was -3.0. running mean: -5.236455243154086\n",
      "resetting env. episode reward total was -9.0. running mean: -5.274090690722544\n",
      "resetting env. episode reward total was 6.0. running mean: -5.161349783815319\n",
      "resetting env. episode reward total was -5.0. running mean: -5.159736285977165\n",
      "resetting env. episode reward total was -3.0. running mean: -5.138138923117394\n",
      "resetting env. episode reward total was -8.0. running mean: -5.16675753388622\n",
      "resetting env. episode reward total was -5.0. running mean: -5.165089958547358\n",
      "resetting env. episode reward total was 3.0. running mean: -5.0834390589618845\n",
      "resetting env. episode reward total was -1.0. running mean: -5.042604668372266\n",
      "resetting env. episode reward total was -9.0. running mean: -5.082178621688543\n",
      "resetting env. episode reward total was -9.0. running mean: -5.121356835471658\n",
      "resetting env. episode reward total was -4.0. running mean: -5.110143267116941\n",
      "resetting env. episode reward total was -7.0. running mean: -5.129041834445772\n",
      "resetting env. episode reward total was 1.0. running mean: -5.067751416101315\n",
      "resetting env. episode reward total was -9.0. running mean: -5.107073901940301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: -5.026003162920897\n",
      "resetting env. episode reward total was -12.0. running mean: -5.095743131291688\n",
      "resetting env. episode reward total was 8.0. running mean: -4.964785699978771\n",
      "resetting env. episode reward total was -2.0. running mean: -4.935137842978983\n",
      "resetting env. episode reward total was -5.0. running mean: -4.935786464549193\n",
      "resetting env. episode reward total was -1.0. running mean: -4.896428599903701\n",
      "resetting env. episode reward total was -7.0. running mean: -4.917464313904665\n",
      "resetting env. episode reward total was 10.0. running mean: -4.768289670765618\n",
      "resetting env. episode reward total was -9.0. running mean: -4.810606774057962\n",
      "resetting env. episode reward total was -12.0. running mean: -4.882500706317382\n",
      "resetting env. episode reward total was -3.0. running mean: -4.863675699254208\n",
      "resetting env. episode reward total was 4.0. running mean: -4.7750389422616655\n",
      "resetting env. episode reward total was -7.0. running mean: -4.797288552839049\n",
      "resetting env. episode reward total was -3.0. running mean: -4.779315667310659\n",
      "resetting env. episode reward total was 5.0. running mean: -4.681522510637552\n",
      "resetting env. episode reward total was 2.0. running mean: -4.614707285531177\n",
      "resetting env. episode reward total was -2.0. running mean: -4.588560212675865\n",
      "resetting env. episode reward total was -5.0. running mean: -4.592674610549106\n",
      "resetting env. episode reward total was 2.0. running mean: -4.526747864443616\n",
      "resetting env. episode reward total was -7.0. running mean: -4.55148038579918\n",
      "resetting env. episode reward total was -4.0. running mean: -4.545965581941188\n",
      "resetting env. episode reward total was -4.0. running mean: -4.540505926121776\n",
      "resetting env. episode reward total was 8.0. running mean: -4.415100866860558\n",
      "resetting env. episode reward total was 3.0. running mean: -4.340949858191952\n",
      "resetting env. episode reward total was -13.0. running mean: -4.427540359610033\n",
      "resetting env. episode reward total was -4.0. running mean: -4.4232649560139325\n",
      "resetting env. episode reward total was 1.0. running mean: -4.369032306453794\n",
      "resetting env. episode reward total was -3.0. running mean: -4.355341983389256\n",
      "resetting env. episode reward total was -5.0. running mean: -4.361788563555364\n",
      "resetting env. episode reward total was -8.0. running mean: -4.39817067791981\n",
      "resetting env. episode reward total was -4.0. running mean: -4.394188971140612\n",
      "resetting env. episode reward total was -7.0. running mean: -4.420247081429206\n",
      "resetting env. episode reward total was -5.0. running mean: -4.426044610614914\n",
      "resetting env. episode reward total was -5.0. running mean: -4.431784164508765\n",
      "resetting env. episode reward total was 7.0. running mean: -4.317466322863678\n",
      "resetting env. episode reward total was 2.0. running mean: -4.254291659635041\n",
      "resetting env. episode reward total was 10.0. running mean: -4.111748743038691\n",
      "resetting env. episode reward total was 2.0. running mean: -4.050631255608305\n",
      "resetting env. episode reward total was -4.0. running mean: -4.050124943052222\n",
      "resetting env. episode reward total was -11.0. running mean: -4.1196236936217\n",
      "resetting env. episode reward total was -4.0. running mean: -4.118427456685484\n",
      "resetting env. episode reward total was -8.0. running mean: -4.157243182118629\n",
      "resetting env. episode reward total was -3.0. running mean: -4.145670750297443\n",
      "resetting env. episode reward total was -6.0. running mean: -4.164214042794468\n",
      "resetting env. episode reward total was -7.0. running mean: -4.192571902366524\n",
      "resetting env. episode reward total was -5.0. running mean: -4.200646183342858\n",
      "resetting env. episode reward total was -12.0. running mean: -4.278639721509429\n",
      "resetting env. episode reward total was -7.0. running mean: -4.305853324294335\n",
      "resetting env. episode reward total was -11.0. running mean: -4.372794791051392\n",
      "resetting env. episode reward total was -7.0. running mean: -4.399066843140878\n",
      "resetting env. episode reward total was -1.0. running mean: -4.365076174709469\n",
      "resetting env. episode reward total was 1.0. running mean: -4.311425412962374\n",
      "resetting env. episode reward total was 4.0. running mean: -4.22831115883275\n",
      "resetting env. episode reward total was -14.0. running mean: -4.326028047244423\n",
      "resetting env. episode reward total was -3.0. running mean: -4.312767766771978\n",
      "resetting env. episode reward total was -12.0. running mean: -4.389640089104259\n",
      "resetting env. episode reward total was -6.0. running mean: -4.405743688213216\n",
      "resetting env. episode reward total was 3.0. running mean: -4.331686251331084\n",
      "resetting env. episode reward total was 2.0. running mean: -4.268369388817774\n",
      "resetting env. episode reward total was -6.0. running mean: -4.2856856949295965\n",
      "resetting env. episode reward total was -7.0. running mean: -4.312828837980301\n",
      "resetting env. episode reward total was -5.0. running mean: -4.319700549600498\n",
      "resetting env. episode reward total was 1.0. running mean: -4.266503544104493\n",
      "resetting env. episode reward total was 7.0. running mean: -4.153838508663448\n",
      "resetting env. episode reward total was -7.0. running mean: -4.182300123576813\n",
      "resetting env. episode reward total was -1.0. running mean: -4.150477122341045\n",
      "resetting env. episode reward total was -1.0. running mean: -4.118972351117635\n",
      "resetting env. episode reward total was -2.0. running mean: -4.097782627606458\n",
      "resetting env. episode reward total was -5.0. running mean: -4.1068048013303935\n",
      "resetting env. episode reward total was -9.0. running mean: -4.15573675331709\n",
      "resetting env. episode reward total was -13.0. running mean: -4.2441793857839185\n",
      "resetting env. episode reward total was 3.0. running mean: -4.171737591926079\n",
      "resetting env. episode reward total was 5.0. running mean: -4.080020216006819\n",
      "resetting env. episode reward total was -13.0. running mean: -4.169220013846751\n",
      "resetting env. episode reward total was 2.0. running mean: -4.107527813708283\n",
      "resetting env. episode reward total was -4.0. running mean: -4.106452535571201\n",
      "resetting env. episode reward total was -9.0. running mean: -4.155388010215488\n",
      "resetting env. episode reward total was -4.0. running mean: -4.153834130113333\n",
      "resetting env. episode reward total was -9.0. running mean: -4.2022957888122\n",
      "resetting env. episode reward total was -2.0. running mean: -4.1802728309240775\n",
      "resetting env. episode reward total was -15.0. running mean: -4.288470102614837\n",
      "resetting env. episode reward total was -11.0. running mean: -4.355585401588689\n",
      "resetting env. episode reward total was 1.0. running mean: -4.302029547572802\n",
      "resetting env. episode reward total was -15.0. running mean: -4.409009252097075\n",
      "resetting env. episode reward total was 1.0. running mean: -4.354919159576104\n",
      "resetting env. episode reward total was -9.0. running mean: -4.401369967980343\n",
      "resetting env. episode reward total was -4.0. running mean: -4.397356268300539\n",
      "resetting env. episode reward total was -11.0. running mean: -4.463382705617534\n",
      "resetting env. episode reward total was -2.0. running mean: -4.438748878561358\n",
      "resetting env. episode reward total was 2.0. running mean: -4.374361389775745\n",
      "resetting env. episode reward total was -5.0. running mean: -4.380617775877988\n",
      "resetting env. episode reward total was -5.0. running mean: -4.386811598119207\n",
      "resetting env. episode reward total was -5.0. running mean: -4.392943482138015\n",
      "resetting env. episode reward total was -7.0. running mean: -4.419014047316635\n",
      "resetting env. episode reward total was -9.0. running mean: -4.464823906843468\n",
      "resetting env. episode reward total was -2.0. running mean: -4.440175667775033\n",
      "resetting env. episode reward total was -10.0. running mean: -4.495773911097282\n",
      "resetting env. episode reward total was -10.0. running mean: -4.550816171986309\n",
      "resetting env. episode reward total was -10.0. running mean: -4.605308010266445\n",
      "resetting env. episode reward total was -9.0. running mean: -4.649254930163781\n",
      "resetting env. episode reward total was -13.0. running mean: -4.732762380862143\n",
      "resetting env. episode reward total was 10.0. running mean: -4.585434757053521\n",
      "resetting env. episode reward total was -6.0. running mean: -4.599580409482986\n",
      "resetting env. episode reward total was -7.0. running mean: -4.623584605388156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -4.647348759334275\n",
      "resetting env. episode reward total was -10.0. running mean: -4.700875271740932\n",
      "resetting env. episode reward total was -13.0. running mean: -4.783866519023523\n",
      "resetting env. episode reward total was -4.0. running mean: -4.776027853833288\n",
      "resetting env. episode reward total was -11.0. running mean: -4.838267575294955\n",
      "resetting env. episode reward total was -11.0. running mean: -4.8998848995420055\n",
      "resetting env. episode reward total was -14.0. running mean: -4.990886050546585\n",
      "resetting env. episode reward total was -9.0. running mean: -5.030977190041119\n",
      "resetting env. episode reward total was -9.0. running mean: -5.070667418140707\n",
      "resetting env. episode reward total was -2.0. running mean: -5.039960743959299\n",
      "resetting env. episode reward total was -7.0. running mean: -5.059561136519706\n",
      "resetting env. episode reward total was -9.0. running mean: -5.098965525154509\n",
      "resetting env. episode reward total was -13.0. running mean: -5.177975869902964\n",
      "resetting env. episode reward total was -3.0. running mean: -5.1561961112039345\n",
      "resetting env. episode reward total was -5.0. running mean: -5.154634150091895\n",
      "resetting env. episode reward total was -1.0. running mean: -5.113087808590976\n",
      "resetting env. episode reward total was -6.0. running mean: -5.121956930505066\n",
      "resetting env. episode reward total was -1.0. running mean: -5.080737361200015\n",
      "resetting env. episode reward total was -8.0. running mean: -5.109929987588015\n",
      "resetting env. episode reward total was -10.0. running mean: -5.158830687712134\n",
      "resetting env. episode reward total was -6.0. running mean: -5.167242380835012\n",
      "resetting env. episode reward total was -17.0. running mean: -5.285569957026662\n",
      "resetting env. episode reward total was -7.0. running mean: -5.302714257456396\n",
      "resetting env. episode reward total was -3.0. running mean: -5.279687114881832\n",
      "resetting env. episode reward total was -7.0. running mean: -5.296890243733014\n",
      "resetting env. episode reward total was -12.0. running mean: -5.363921341295684\n",
      "resetting env. episode reward total was -13.0. running mean: -5.4402821278827265\n",
      "resetting env. episode reward total was -1.0. running mean: -5.395879306603899\n",
      "resetting env. episode reward total was -13.0. running mean: -5.471920513537859\n",
      "resetting env. episode reward total was -15.0. running mean: -5.567201308402481\n",
      "resetting env. episode reward total was 2.0. running mean: -5.491529295318457\n",
      "resetting env. episode reward total was -5.0. running mean: -5.486614002365272\n",
      "resetting env. episode reward total was -11.0. running mean: -5.541747862341619\n",
      "resetting env. episode reward total was -8.0. running mean: -5.566330383718204\n",
      "resetting env. episode reward total was -8.0. running mean: -5.590667079881022\n",
      "resetting env. episode reward total was -15.0. running mean: -5.6847604090822115\n",
      "resetting env. episode reward total was -11.0. running mean: -5.73791280499139\n",
      "resetting env. episode reward total was -2.0. running mean: -5.700533676941475\n",
      "resetting env. episode reward total was -9.0. running mean: -5.73352834017206\n",
      "resetting env. episode reward total was -8.0. running mean: -5.756193056770339\n",
      "resetting env. episode reward total was -1.0. running mean: -5.7086311262026355\n",
      "resetting env. episode reward total was -13.0. running mean: -5.781544814940609\n",
      "resetting env. episode reward total was -10.0. running mean: -5.823729366791202\n",
      "resetting env. episode reward total was -10.0. running mean: -5.865492073123289\n",
      "resetting env. episode reward total was -6.0. running mean: -5.866837152392056\n",
      "resetting env. episode reward total was -14.0. running mean: -5.9481687808681345\n",
      "resetting env. episode reward total was -6.0. running mean: -5.948687093059453\n",
      "resetting env. episode reward total was -11.0. running mean: -5.9992002221288585\n",
      "resetting env. episode reward total was -3.0. running mean: -5.9692082199075704\n",
      "resetting env. episode reward total was -7.0. running mean: -5.979516137708495\n",
      "resetting env. episode reward total was -9.0. running mean: -6.009720976331409\n",
      "resetting env. episode reward total was -3.0. running mean: -5.979623766568095\n",
      "resetting env. episode reward total was 3.0. running mean: -5.889827528902414\n",
      "resetting env. episode reward total was -3.0. running mean: -5.8609292536133895\n",
      "resetting env. episode reward total was -3.0. running mean: -5.832319961077256\n",
      "resetting env. episode reward total was 2.0. running mean: -5.7539967614664835\n",
      "resetting env. episode reward total was -7.0. running mean: -5.766456793851819\n",
      "resetting env. episode reward total was -11.0. running mean: -5.818792225913301\n",
      "resetting env. episode reward total was 2.0. running mean: -5.740604303654168\n",
      "resetting env. episode reward total was -10.0. running mean: -5.783198260617626\n",
      "resetting env. episode reward total was -4.0. running mean: -5.76536627801145\n",
      "resetting env. episode reward total was -12.0. running mean: -5.827712615231335\n",
      "resetting env. episode reward total was -1.0. running mean: -5.779435489079021\n",
      "resetting env. episode reward total was -11.0. running mean: -5.8316411341882315\n",
      "resetting env. episode reward total was 1.0. running mean: -5.76332472284635\n",
      "resetting env. episode reward total was 2.0. running mean: -5.685691475617887\n",
      "resetting env. episode reward total was -9.0. running mean: -5.7188345608617075\n",
      "resetting env. episode reward total was -5.0. running mean: -5.71164621525309\n",
      "resetting env. episode reward total was 8.0. running mean: -5.574529753100559\n",
      "resetting env. episode reward total was -7.0. running mean: -5.588784455569553\n",
      "resetting env. episode reward total was -11.0. running mean: -5.642896611013858\n",
      "resetting env. episode reward total was -5.0. running mean: -5.6364676449037185\n",
      "resetting env. episode reward total was 1.0. running mean: -5.570102968454681\n",
      "resetting env. episode reward total was -9.0. running mean: -5.604401938770134\n",
      "resetting env. episode reward total was -2.0. running mean: -5.568357919382432\n",
      "resetting env. episode reward total was -8.0. running mean: -5.592674340188608\n",
      "resetting env. episode reward total was -6.0. running mean: -5.596747596786721\n",
      "resetting env. episode reward total was -4.0. running mean: -5.580780120818853\n",
      "resetting env. episode reward total was -4.0. running mean: -5.564972319610665\n",
      "resetting env. episode reward total was -16.0. running mean: -5.669322596414559\n",
      "resetting env. episode reward total was -14.0. running mean: -5.752629370450413\n",
      "resetting env. episode reward total was -4.0. running mean: -5.735103076745909\n",
      "resetting env. episode reward total was -9.0. running mean: -5.767752045978449\n",
      "resetting env. episode reward total was 6.0. running mean: -5.650074525518665\n",
      "resetting env. episode reward total was 2.0. running mean: -5.573573780263478\n",
      "resetting env. episode reward total was -7.0. running mean: -5.587838042460844\n",
      "resetting env. episode reward total was 3.0. running mean: -5.501959662036236\n",
      "resetting env. episode reward total was 1.0. running mean: -5.4369400654158735\n",
      "resetting env. episode reward total was -6.0. running mean: -5.442570664761714\n",
      "resetting env. episode reward total was -2.0. running mean: -5.408144958114097\n",
      "resetting env. episode reward total was -5.0. running mean: -5.404063508532955\n",
      "resetting env. episode reward total was -8.0. running mean: -5.4300228734476255\n",
      "resetting env. episode reward total was -10.0. running mean: -5.475722644713149\n",
      "resetting env. episode reward total was -8.0. running mean: -5.500965418266017\n",
      "resetting env. episode reward total was -15.0. running mean: -5.5959557640833575\n",
      "resetting env. episode reward total was -19.0. running mean: -5.7240962443780985\n",
      "resetting env. episode reward total was -10.0. running mean: -5.766855281934317\n",
      "resetting env. episode reward total was -12.0. running mean: -5.829186729114975\n",
      "resetting env. episode reward total was -6.0. running mean: -5.8308948618238245\n",
      "resetting env. episode reward total was -12.0. running mean: -5.892585913205586\n",
      "resetting env. episode reward total was -2.0. running mean: -5.85366005407353\n",
      "resetting env. episode reward total was -10.0. running mean: -5.895123453532794\n",
      "resetting env. episode reward total was -11.0. running mean: -5.946172218997467\n",
      "resetting env. episode reward total was -11.0. running mean: -5.996710496807492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: -5.9467433918394175\n",
      "resetting env. episode reward total was -1.0. running mean: -5.897275957921023\n",
      "resetting env. episode reward total was -1.0. running mean: -5.848303198341813\n",
      "resetting env. episode reward total was -3.0. running mean: -5.819820166358395\n",
      "resetting env. episode reward total was -11.0. running mean: -5.871621964694811\n",
      "resetting env. episode reward total was -9.0. running mean: -5.902905745047863\n",
      "resetting env. episode reward total was -2.0. running mean: -5.863876687597384\n",
      "resetting env. episode reward total was 1.0. running mean: -5.79523792072141\n",
      "resetting env. episode reward total was -9.0. running mean: -5.827285541514196\n",
      "resetting env. episode reward total was -4.0. running mean: -5.809012686099054\n",
      "resetting env. episode reward total was -10.0. running mean: -5.850922559238063\n",
      "resetting env. episode reward total was -5.0. running mean: -5.842413333645682\n",
      "resetting env. episode reward total was -11.0. running mean: -5.893989200309226\n",
      "resetting env. episode reward total was 3.0. running mean: -5.805049308306133\n",
      "resetting env. episode reward total was -12.0. running mean: -5.866998815223072\n",
      "resetting env. episode reward total was 5.0. running mean: -5.758328827070842\n",
      "resetting env. episode reward total was 4.0. running mean: -5.660745538800133\n",
      "resetting env. episode reward total was 6.0. running mean: -5.544138083412132\n",
      "resetting env. episode reward total was -10.0. running mean: -5.58869670257801\n",
      "resetting env. episode reward total was -3.0. running mean: -5.5628097355522295\n",
      "resetting env. episode reward total was -5.0. running mean: -5.557181638196707\n",
      "resetting env. episode reward total was -14.0. running mean: -5.64160982181474\n",
      "resetting env. episode reward total was -10.0. running mean: -5.6851937235965915\n",
      "resetting env. episode reward total was -9.0. running mean: -5.718341786360625\n",
      "resetting env. episode reward total was 2.0. running mean: -5.6411583684970195\n",
      "resetting env. episode reward total was -7.0. running mean: -5.654746784812049\n",
      "resetting env. episode reward total was -9.0. running mean: -5.688199316963929\n",
      "resetting env. episode reward total was 1.0. running mean: -5.6213173237942895\n",
      "resetting env. episode reward total was 3.0. running mean: -5.5351041505563465\n",
      "resetting env. episode reward total was 9.0. running mean: -5.389753109050783\n",
      "resetting env. episode reward total was -3.0. running mean: -5.365855577960276\n",
      "resetting env. episode reward total was -2.0. running mean: -5.332197022180672\n",
      "resetting env. episode reward total was -16.0. running mean: -5.438875051958866\n",
      "resetting env. episode reward total was -7.0. running mean: -5.454486301439277\n",
      "resetting env. episode reward total was -2.0. running mean: -5.419941438424884\n",
      "resetting env. episode reward total was -11.0. running mean: -5.475742024040635\n",
      "resetting env. episode reward total was -11.0. running mean: -5.530984603800229\n",
      "resetting env. episode reward total was -9.0. running mean: -5.565674757762226\n",
      "resetting env. episode reward total was -6.0. running mean: -5.5700180101846035\n",
      "resetting env. episode reward total was -1.0. running mean: -5.524317830082757\n",
      "resetting env. episode reward total was -8.0. running mean: -5.54907465178193\n",
      "resetting env. episode reward total was -3.0. running mean: -5.523583905264111\n",
      "resetting env. episode reward total was -13.0. running mean: -5.59834806621147\n",
      "resetting env. episode reward total was -8.0. running mean: -5.622364585549355\n",
      "resetting env. episode reward total was -9.0. running mean: -5.656140939693861\n",
      "resetting env. episode reward total was -5.0. running mean: -5.649579530296922\n",
      "resetting env. episode reward total was -2.0. running mean: -5.613083734993952\n",
      "resetting env. episode reward total was -2.0. running mean: -5.576952897644013\n",
      "resetting env. episode reward total was -1.0. running mean: -5.531183368667572\n",
      "resetting env. episode reward total was -3.0. running mean: -5.505871534980897\n",
      "resetting env. episode reward total was -16.0. running mean: -5.610812819631088\n",
      "resetting env. episode reward total was -7.0. running mean: -5.624704691434777\n",
      "resetting env. episode reward total was -15.0. running mean: -5.71845764452043\n",
      "resetting env. episode reward total was -4.0. running mean: -5.701273068075226\n",
      "resetting env. episode reward total was -10.0. running mean: -5.744260337394473\n",
      "resetting env. episode reward total was -19.0. running mean: -5.876817734020529\n",
      "resetting env. episode reward total was -1.0. running mean: -5.828049556680323\n",
      "resetting env. episode reward total was -14.0. running mean: -5.909769061113519\n",
      "resetting env. episode reward total was -7.0. running mean: -5.920671370502385\n",
      "resetting env. episode reward total was -6.0. running mean: -5.921464656797361\n",
      "resetting env. episode reward total was -14.0. running mean: -6.002250010229387\n",
      "resetting env. episode reward total was -3.0. running mean: -5.972227510127094\n",
      "resetting env. episode reward total was 2.0. running mean: -5.892505235025823\n",
      "resetting env. episode reward total was -12.0. running mean: -5.953580182675564\n",
      "resetting env. episode reward total was -9.0. running mean: -5.984044380848808\n",
      "resetting env. episode reward total was -5.0. running mean: -5.97420393704032\n",
      "resetting env. episode reward total was 6.0. running mean: -5.854461897669918\n",
      "resetting env. episode reward total was 2.0. running mean: -5.7759172786932185\n",
      "resetting env. episode reward total was -6.0. running mean: -5.778158105906286\n",
      "resetting env. episode reward total was 1.0. running mean: -5.710376524847224\n",
      "resetting env. episode reward total was -5.0. running mean: -5.703272759598751\n",
      "resetting env. episode reward total was -7.0. running mean: -5.716240032002764\n",
      "resetting env. episode reward total was -11.0. running mean: -5.769077631682737\n",
      "resetting env. episode reward total was -11.0. running mean: -5.821386855365909\n",
      "resetting env. episode reward total was -9.0. running mean: -5.8531729868122495\n",
      "resetting env. episode reward total was -11.0. running mean: -5.904641256944127\n",
      "resetting env. episode reward total was 3.0. running mean: -5.815594844374686\n",
      "resetting env. episode reward total was 1.0. running mean: -5.747438895930939\n",
      "resetting env. episode reward total was 2.0. running mean: -5.66996450697163\n",
      "resetting env. episode reward total was -3.0. running mean: -5.643264861901915\n",
      "resetting env. episode reward total was -6.0. running mean: -5.646832213282895\n",
      "resetting env. episode reward total was -3.0. running mean: -5.620363891150067\n",
      "resetting env. episode reward total was -10.0. running mean: -5.664160252238566\n",
      "resetting env. episode reward total was -13.0. running mean: -5.73751864971618\n",
      "resetting env. episode reward total was -6.0. running mean: -5.740143463219018\n",
      "resetting env. episode reward total was 1.0. running mean: -5.6727420285868275\n",
      "resetting env. episode reward total was -11.0. running mean: -5.726014608300959\n",
      "resetting env. episode reward total was -6.0. running mean: -5.728754462217949\n",
      "resetting env. episode reward total was -6.0. running mean: -5.731466917595768\n",
      "resetting env. episode reward total was -3.0. running mean: -5.704152248419811\n",
      "resetting env. episode reward total was -8.0. running mean: -5.727110725935613\n",
      "resetting env. episode reward total was 3.0. running mean: -5.639839618676256\n",
      "resetting env. episode reward total was 9.0. running mean: -5.493441222489494\n",
      "resetting env. episode reward total was -10.0. running mean: -5.5385068102645985\n",
      "resetting env. episode reward total was -10.0. running mean: -5.583121742161952\n",
      "resetting env. episode reward total was -9.0. running mean: -5.617290524740332\n",
      "resetting env. episode reward total was -2.0. running mean: -5.581117619492928\n",
      "resetting env. episode reward total was -7.0. running mean: -5.595306443297999\n",
      "resetting env. episode reward total was -11.0. running mean: -5.649353378865019\n",
      "resetting env. episode reward total was 2.0. running mean: -5.572859845076369\n",
      "resetting env. episode reward total was 1.0. running mean: -5.5071312466256055\n",
      "resetting env. episode reward total was -8.0. running mean: -5.532059934159349\n",
      "resetting env. episode reward total was 5.0. running mean: -5.426739334817756\n",
      "resetting env. episode reward total was -7.0. running mean: -5.442471941469579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: -5.358047222054883\n",
      "resetting env. episode reward total was -2.0. running mean: -5.324466749834333\n",
      "resetting env. episode reward total was -8.0. running mean: -5.35122208233599\n",
      "resetting env. episode reward total was -17.0. running mean: -5.46770986151263\n",
      "resetting env. episode reward total was 5.0. running mean: -5.363032762897504\n",
      "resetting env. episode reward total was -6.0. running mean: -5.369402435268529\n",
      "resetting env. episode reward total was -10.0. running mean: -5.415708410915843\n",
      "resetting env. episode reward total was 8.0. running mean: -5.281551326806684\n",
      "resetting env. episode reward total was -3.0. running mean: -5.2587358135386175\n",
      "resetting env. episode reward total was -1.0. running mean: -5.216148455403231\n",
      "resetting env. episode reward total was -9.0. running mean: -5.253986970849199\n",
      "resetting env. episode reward total was -11.0. running mean: -5.311447101140707\n",
      "resetting env. episode reward total was -5.0. running mean: -5.308332630129299\n",
      "resetting env. episode reward total was -3.0. running mean: -5.285249303828007\n",
      "resetting env. episode reward total was 2.0. running mean: -5.212396810789727\n",
      "resetting env. episode reward total was -11.0. running mean: -5.27027284268183\n",
      "resetting env. episode reward total was -6.0. running mean: -5.2775701142550115\n",
      "resetting env. episode reward total was 4.0. running mean: -5.184794413112462\n",
      "resetting env. episode reward total was -7.0. running mean: -5.202946468981337\n",
      "resetting env. episode reward total was 2.0. running mean: -5.130917004291524\n",
      "resetting env. episode reward total was -10.0. running mean: -5.179607834248608\n",
      "resetting env. episode reward total was 3.0. running mean: -5.097811755906122\n",
      "resetting env. episode reward total was 3.0. running mean: -5.016833638347061\n",
      "resetting env. episode reward total was -2.0. running mean: -4.98666530196359\n",
      "resetting env. episode reward total was -7.0. running mean: -5.0067986489439535\n",
      "resetting env. episode reward total was 7.0. running mean: -4.8867306624545135\n",
      "resetting env. episode reward total was -3.0. running mean: -4.867863355829969\n",
      "resetting env. episode reward total was -7.0. running mean: -4.889184722271669\n",
      "resetting env. episode reward total was -6.0. running mean: -4.900292875048952\n",
      "resetting env. episode reward total was -8.0. running mean: -4.931289946298462\n",
      "resetting env. episode reward total was -13.0. running mean: -5.011977046835478\n",
      "resetting env. episode reward total was -3.0. running mean: -4.991857276367123\n",
      "resetting env. episode reward total was -8.0. running mean: -5.021938703603452\n",
      "resetting env. episode reward total was -5.0. running mean: -5.021719316567418\n",
      "resetting env. episode reward total was 4.0. running mean: -4.931502123401743\n",
      "resetting env. episode reward total was -2.0. running mean: -4.9021871021677255\n",
      "resetting env. episode reward total was 1.0. running mean: -4.843165231146048\n",
      "resetting env. episode reward total was 6.0. running mean: -4.734733578834588\n",
      "resetting env. episode reward total was -9.0. running mean: -4.777386243046242\n",
      "resetting env. episode reward total was 7.0. running mean: -4.659612380615779\n",
      "resetting env. episode reward total was -15.0. running mean: -4.763016256809622\n",
      "resetting env. episode reward total was -1.0. running mean: -4.725386094241525\n",
      "resetting env. episode reward total was -9.0. running mean: -4.768132233299109\n",
      "resetting env. episode reward total was -5.0. running mean: -4.770450910966118\n",
      "resetting env. episode reward total was -10.0. running mean: -4.822746401856456\n",
      "resetting env. episode reward total was -10.0. running mean: -4.874518937837891\n",
      "resetting env. episode reward total was -11.0. running mean: -4.935773748459512\n",
      "resetting env. episode reward total was -7.0. running mean: -4.956416010974918\n",
      "resetting env. episode reward total was -14.0. running mean: -5.046851850865168\n",
      "resetting env. episode reward total was -11.0. running mean: -5.106383332356517\n",
      "resetting env. episode reward total was 3.0. running mean: -5.0253194990329515\n",
      "resetting env. episode reward total was -3.0. running mean: -5.005066304042622\n",
      "resetting env. episode reward total was -11.0. running mean: -5.065015641002196\n",
      "resetting env. episode reward total was -3.0. running mean: -5.044365484592174\n",
      "resetting env. episode reward total was -2.0. running mean: -5.013921829746252\n",
      "resetting env. episode reward total was 8.0. running mean: -4.8837826114487894\n",
      "resetting env. episode reward total was 2.0. running mean: -4.814944785334302\n",
      "resetting env. episode reward total was 1.0. running mean: -4.756795337480959\n",
      "resetting env. episode reward total was -3.0. running mean: -4.73922738410615\n",
      "resetting env. episode reward total was 5.0. running mean: -4.641835110265089\n",
      "resetting env. episode reward total was -3.0. running mean: -4.625416759162438\n",
      "resetting env. episode reward total was -9.0. running mean: -4.669162591570814\n",
      "resetting env. episode reward total was -6.0. running mean: -4.682470965655106\n",
      "resetting env. episode reward total was 5.0. running mean: -4.5856462559985545\n",
      "resetting env. episode reward total was -5.0. running mean: -4.589789793438569\n",
      "resetting env. episode reward total was -15.0. running mean: -4.6938918955041835\n",
      "resetting env. episode reward total was -1.0. running mean: -4.6569529765491415\n",
      "resetting env. episode reward total was -4.0. running mean: -4.65038344678365\n",
      "resetting env. episode reward total was -1.0. running mean: -4.613879612315813\n",
      "resetting env. episode reward total was -5.0. running mean: -4.617740816192654\n",
      "resetting env. episode reward total was 3.0. running mean: -4.5415634080307274\n",
      "resetting env. episode reward total was 5.0. running mean: -4.44614777395042\n",
      "resetting env. episode reward total was 6.0. running mean: -4.341686296210916\n",
      "resetting env. episode reward total was -2.0. running mean: -4.3182694332488065\n",
      "resetting env. episode reward total was -12.0. running mean: -4.395086738916318\n",
      "resetting env. episode reward total was 5.0. running mean: -4.301135871527156\n",
      "resetting env. episode reward total was -7.0. running mean: -4.328124512811884\n",
      "resetting env. episode reward total was -12.0. running mean: -4.404843267683765\n",
      "resetting env. episode reward total was 4.0. running mean: -4.320794835006928\n",
      "resetting env. episode reward total was -1.0. running mean: -4.287586886656858\n",
      "resetting env. episode reward total was -3.0. running mean: -4.27471101779029\n",
      "resetting env. episode reward total was -4.0. running mean: -4.271963907612387\n",
      "resetting env. episode reward total was -9.0. running mean: -4.319244268536264\n",
      "resetting env. episode reward total was -5.0. running mean: -4.326051825850901\n",
      "resetting env. episode reward total was -10.0. running mean: -4.382791307592392\n",
      "resetting env. episode reward total was -12.0. running mean: -4.458963394516468\n",
      "resetting env. episode reward total was -10.0. running mean: -4.514373760571303\n",
      "resetting env. episode reward total was -13.0. running mean: -4.59923002296559\n",
      "resetting env. episode reward total was -7.0. running mean: -4.623237722735934\n",
      "resetting env. episode reward total was -9.0. running mean: -4.667005345508574\n",
      "resetting env. episode reward total was 8.0. running mean: -4.540335292053489\n",
      "resetting env. episode reward total was -4.0. running mean: -4.534931939132954\n",
      "resetting env. episode reward total was -6.0. running mean: -4.549582619741624\n",
      "resetting env. episode reward total was -3.0. running mean: -4.534086793544208\n",
      "resetting env. episode reward total was -7.0. running mean: -4.558745925608767\n",
      "resetting env. episode reward total was -4.0. running mean: -4.553158466352679\n",
      "resetting env. episode reward total was 3.0. running mean: -4.477626881689152\n",
      "resetting env. episode reward total was -7.0. running mean: -4.502850612872261\n",
      "resetting env. episode reward total was 2.0. running mean: -4.437822106743539\n",
      "resetting env. episode reward total was -2.0. running mean: -4.413443885676103\n",
      "resetting env. episode reward total was -7.0. running mean: -4.439309446819342\n",
      "resetting env. episode reward total was -12.0. running mean: -4.514916352351149\n",
      "resetting env. episode reward total was -12.0. running mean: -4.589767188827637\n",
      "resetting env. episode reward total was 12.0. running mean: -4.4238695169393605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -15.0. running mean: -4.529630821769967\n",
      "resetting env. episode reward total was 1.0. running mean: -4.474334513552267\n",
      "resetting env. episode reward total was -6.0. running mean: -4.489591168416744\n",
      "resetting env. episode reward total was -3.0. running mean: -4.474695256732577\n",
      "resetting env. episode reward total was -1.0. running mean: -4.439948304165251\n",
      "resetting env. episode reward total was -10.0. running mean: -4.495548821123599\n",
      "resetting env. episode reward total was 6.0. running mean: -4.390593332912363\n",
      "resetting env. episode reward total was -3.0. running mean: -4.37668739958324\n",
      "resetting env. episode reward total was -3.0. running mean: -4.362920525587407\n",
      "resetting env. episode reward total was 2.0. running mean: -4.299291320331534\n",
      "resetting env. episode reward total was 3.0. running mean: -4.226298407128218\n",
      "resetting env. episode reward total was -9.0. running mean: -4.274035423056936\n",
      "resetting env. episode reward total was -7.0. running mean: -4.3012950688263665\n",
      "resetting env. episode reward total was 2.0. running mean: -4.238282118138104\n",
      "resetting env. episode reward total was 9.0. running mean: -4.105899296956722\n",
      "resetting env. episode reward total was -5.0. running mean: -4.114840303987155\n",
      "resetting env. episode reward total was -8.0. running mean: -4.153691900947283\n",
      "resetting env. episode reward total was -9.0. running mean: -4.20215498193781\n",
      "resetting env. episode reward total was -7.0. running mean: -4.230133432118432\n",
      "resetting env. episode reward total was -4.0. running mean: -4.227832097797248\n",
      "resetting env. episode reward total was 2.0. running mean: -4.165553776819276\n",
      "resetting env. episode reward total was -6.0. running mean: -4.183898239051082\n",
      "resetting env. episode reward total was -8.0. running mean: -4.222059256660572\n",
      "resetting env. episode reward total was 7.0. running mean: -4.1098386640939655\n",
      "resetting env. episode reward total was -5.0. running mean: -4.118740277453026\n",
      "resetting env. episode reward total was 2.0. running mean: -4.057552874678496\n",
      "resetting env. episode reward total was 3.0. running mean: -3.9869773459317117\n",
      "resetting env. episode reward total was 5.0. running mean: -3.897107572472395\n",
      "resetting env. episode reward total was -5.0. running mean: -3.908136496747671\n",
      "resetting env. episode reward total was 7.0. running mean: -3.7990551317801944\n",
      "resetting env. episode reward total was 2.0. running mean: -3.7410645804623925\n",
      "resetting env. episode reward total was -4.0. running mean: -3.7436539346577686\n",
      "resetting env. episode reward total was -16.0. running mean: -3.866217395311191\n",
      "resetting env. episode reward total was 1.0. running mean: -3.8175552213580795\n",
      "resetting env. episode reward total was -6.0. running mean: -3.8393796691444986\n",
      "resetting env. episode reward total was 2.0. running mean: -3.7809858724530536\n",
      "resetting env. episode reward total was 1.0. running mean: -3.7331760137285235\n",
      "resetting env. episode reward total was 10.0. running mean: -3.5958442535912383\n",
      "resetting env. episode reward total was -4.0. running mean: -3.599885811055326\n",
      "resetting env. episode reward total was -4.0. running mean: -3.6038869529447726\n",
      "resetting env. episode reward total was 10.0. running mean: -3.467848083415325\n",
      "resetting env. episode reward total was -7.0. running mean: -3.5031696025811714\n",
      "resetting env. episode reward total was 4.0. running mean: -3.4281379065553597\n",
      "resetting env. episode reward total was -5.0. running mean: -3.443856527489806\n",
      "resetting env. episode reward total was 1.0. running mean: -3.399417962214908\n",
      "resetting env. episode reward total was -1.0. running mean: -3.3754237825927587\n",
      "resetting env. episode reward total was -13.0. running mean: -3.471669544766831\n",
      "resetting env. episode reward total was 9.0. running mean: -3.346952849319163\n",
      "resetting env. episode reward total was -1.0. running mean: -3.323483320825971\n",
      "resetting env. episode reward total was 8.0. running mean: -3.210248487617711\n",
      "resetting env. episode reward total was 4.0. running mean: -3.138146002741534\n",
      "resetting env. episode reward total was -7.0. running mean: -3.1767645427141185\n",
      "resetting env. episode reward total was -1.0. running mean: -3.154996897286977\n",
      "resetting env. episode reward total was -10.0. running mean: -3.223446928314107\n",
      "resetting env. episode reward total was -1.0. running mean: -3.2012124590309656\n",
      "resetting env. episode reward total was -13.0. running mean: -3.299200334440656\n",
      "resetting env. episode reward total was -1.0. running mean: -3.276208331096249\n",
      "resetting env. episode reward total was 5.0. running mean: -3.1934462477852867\n",
      "resetting env. episode reward total was 3.0. running mean: -3.131511785307434\n",
      "resetting env. episode reward total was 5.0. running mean: -3.05019666745436\n",
      "resetting env. episode reward total was -7.0. running mean: -3.089694700779816\n",
      "resetting env. episode reward total was -6.0. running mean: -3.118797753772018\n",
      "resetting env. episode reward total was -5.0. running mean: -3.1376097762342976\n",
      "resetting env. episode reward total was -2.0. running mean: -3.1262336784719547\n",
      "resetting env. episode reward total was -18.0. running mean: -3.2749713416872352\n",
      "resetting env. episode reward total was 7.0. running mean: -3.1722216282703632\n",
      "resetting env. episode reward total was 3.0. running mean: -3.11049941198766\n",
      "resetting env. episode reward total was -9.0. running mean: -3.169394417867783\n",
      "resetting env. episode reward total was 11.0. running mean: -3.0277004736891056\n",
      "resetting env. episode reward total was -7.0. running mean: -3.067423468952214\n",
      "resetting env. episode reward total was 7.0. running mean: -2.966749234262692\n",
      "resetting env. episode reward total was 10.0. running mean: -2.837081741920065\n",
      "resetting env. episode reward total was 1.0. running mean: -2.7987109245008646\n",
      "resetting env. episode reward total was 9.0. running mean: -2.680723815255856\n",
      "resetting env. episode reward total was 4.0. running mean: -2.6139165771032977\n",
      "resetting env. episode reward total was -9.0. running mean: -2.6777774113322645\n",
      "resetting env. episode reward total was -1.0. running mean: -2.6609996372189415\n",
      "resetting env. episode reward total was -3.0. running mean: -2.664389640846752\n",
      "resetting env. episode reward total was -8.0. running mean: -2.7177457444382846\n",
      "resetting env. episode reward total was -10.0. running mean: -2.790568286993902\n",
      "resetting env. episode reward total was 2.0. running mean: -2.742662604123963\n",
      "resetting env. episode reward total was 10.0. running mean: -2.6152359780827235\n",
      "resetting env. episode reward total was -5.0. running mean: -2.639083618301896\n",
      "resetting env. episode reward total was 11.0. running mean: -2.5026927821188774\n",
      "resetting env. episode reward total was -1.0. running mean: -2.4876658542976884\n",
      "resetting env. episode reward total was 7.0. running mean: -2.3927891957547116\n",
      "resetting env. episode reward total was -5.0. running mean: -2.4188613037971645\n",
      "resetting env. episode reward total was 3.0. running mean: -2.364672690759193\n",
      "resetting env. episode reward total was 1.0. running mean: -2.3310259638516015\n",
      "resetting env. episode reward total was -5.0. running mean: -2.3577157042130854\n",
      "resetting env. episode reward total was -6.0. running mean: -2.3941385471709546\n",
      "resetting env. episode reward total was 2.0. running mean: -2.350197161699245\n",
      "resetting env. episode reward total was -7.0. running mean: -2.3966951900822524\n",
      "resetting env. episode reward total was 4.0. running mean: -2.3327282381814296\n",
      "resetting env. episode reward total was -3.0. running mean: -2.339400955799615\n",
      "resetting env. episode reward total was -7.0. running mean: -2.3860069462416185\n",
      "resetting env. episode reward total was -11.0. running mean: -2.472146876779202\n",
      "resetting env. episode reward total was -1.0. running mean: -2.4574254080114097\n",
      "resetting env. episode reward total was 7.0. running mean: -2.3628511539312957\n",
      "resetting env. episode reward total was -1.0. running mean: -2.3492226423919824\n",
      "resetting env. episode reward total was 2.0. running mean: -2.3057304159680627\n",
      "resetting env. episode reward total was 8.0. running mean: -2.202673111808382\n",
      "resetting env. episode reward total was -16.0. running mean: -2.3406463806902984\n",
      "resetting env. episode reward total was -4.0. running mean: -2.3572399168833953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: -2.253667517714561\n",
      "resetting env. episode reward total was -3.0. running mean: -2.2611308425374155\n",
      "resetting env. episode reward total was -1.0. running mean: -2.248519534112041\n",
      "resetting env. episode reward total was 12.0. running mean: -2.106034338770921\n",
      "resetting env. episode reward total was -2.0. running mean: -2.1049739953832116\n",
      "resetting env. episode reward total was 1.0. running mean: -2.0739242554293797\n",
      "resetting env. episode reward total was 5.0. running mean: -2.003185012875086\n",
      "resetting env. episode reward total was 1.0. running mean: -1.9731531627463352\n",
      "resetting env. episode reward total was -11.0. running mean: -2.063421631118872\n",
      "resetting env. episode reward total was 3.0. running mean: -2.012787414807683\n",
      "resetting env. episode reward total was -3.0. running mean: -2.0226595406596064\n",
      "resetting env. episode reward total was 9.0. running mean: -1.9124329452530102\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9033086158004802\n",
      "resetting env. episode reward total was 12.0. running mean: -1.7642755296424752\n",
      "resetting env. episode reward total was -1.0. running mean: -1.7566327743460506\n",
      "resetting env. episode reward total was -1.0. running mean: -1.74906644660259\n",
      "resetting env. episode reward total was 1.0. running mean: -1.721575782136564\n",
      "resetting env. episode reward total was 5.0. running mean: -1.6543600243151984\n",
      "resetting env. episode reward total was 6.0. running mean: -1.5778164240720463\n",
      "resetting env. episode reward total was -10.0. running mean: -1.662038259831326\n",
      "resetting env. episode reward total was 1.0. running mean: -1.6354178772330126\n",
      "resetting env. episode reward total was 3.0. running mean: -1.5890636984606825\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6231730614760758\n",
      "resetting env. episode reward total was 7.0. running mean: -1.536941330861315\n",
      "resetting env. episode reward total was 3.0. running mean: -1.4915719175527018\n",
      "resetting env. episode reward total was -1.0. running mean: -1.4866561983771749\n",
      "resetting env. episode reward total was 2.0. running mean: -1.451789636393403\n",
      "resetting env. episode reward total was 2.0. running mean: -1.417271740029469\n",
      "resetting env. episode reward total was -5.0. running mean: -1.4530990226291742\n",
      "resetting env. episode reward total was 5.0. running mean: -1.3885680324028824\n",
      "resetting env. episode reward total was 4.0. running mean: -1.3346823520788536\n",
      "resetting env. episode reward total was 1.0. running mean: -1.311335528558065\n",
      "resetting env. episode reward total was 11.0. running mean: -1.1882221732724843\n",
      "resetting env. episode reward total was -2.0. running mean: -1.1963399515397595\n",
      "resetting env. episode reward total was 11.0. running mean: -1.0743765520243618\n",
      "resetting env. episode reward total was 3.0. running mean: -1.0336327865041182\n",
      "resetting env. episode reward total was 2.0. running mean: -1.003296458639077\n",
      "resetting env. episode reward total was -8.0. running mean: -1.0732634940526862\n",
      "resetting env. episode reward total was 4.0. running mean: -1.0225308591121594\n",
      "resetting env. episode reward total was -8.0. running mean: -1.0923055505210377\n",
      "resetting env. episode reward total was -2.0. running mean: -1.1013824950158273\n",
      "resetting env. episode reward total was -6.0. running mean: -1.150368670065669\n",
      "resetting env. episode reward total was -9.0. running mean: -1.2288649833650125\n",
      "resetting env. episode reward total was 4.0. running mean: -1.1765763335313624\n",
      "resetting env. episode reward total was 1.0. running mean: -1.1548105701960487\n",
      "resetting env. episode reward total was 15.0. running mean: -0.9932624644940883\n",
      "resetting env. episode reward total was 2.0. running mean: -0.9633298398491473\n",
      "resetting env. episode reward total was 4.0. running mean: -0.9136965414506558\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8845595760361492\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8557139802757877\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9171568404730299\n",
      "resetting env. episode reward total was -2.0. running mean: -0.9279852720682996\n",
      "resetting env. episode reward total was -2.0. running mean: -0.9387054193476166\n",
      "resetting env. episode reward total was 10.0. running mean: -0.8293183651541405\n",
      "resetting env. episode reward total was -2.0. running mean: -0.8410251815025991\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8426149296875731\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8641887803906975\n",
      "resetting env. episode reward total was 1.0. running mean: -0.8455468925867905\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8470914236609226\n",
      "resetting env. episode reward total was 8.0. running mean: -0.7586205094243134\n",
      "resetting env. episode reward total was -3.0. running mean: -0.7810343043300703\n",
      "resetting env. episode reward total was -8.0. running mean: -0.8532239612867695\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9146917216739017\n",
      "resetting env. episode reward total was -14.0. running mean: -1.0455448044571627\n",
      "resetting env. episode reward total was -7.0. running mean: -1.1050893564125912\n",
      "resetting env. episode reward total was 3.0. running mean: -1.0640384628484651\n",
      "resetting env. episode reward total was -7.0. running mean: -1.1233980782199806\n",
      "resetting env. episode reward total was -1.0. running mean: -1.122164097437781\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1409424564634032\n",
      "resetting env. episode reward total was -3.0. running mean: -1.159533031898769\n",
      "resetting env. episode reward total was -11.0. running mean: -1.2579377015797815\n",
      "resetting env. episode reward total was 4.0. running mean: -1.2053583245639836\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2033047413183438\n",
      "resetting env. episode reward total was -8.0. running mean: -1.2712716939051605\n",
      "resetting env. episode reward total was -3.0. running mean: -1.288558976966109\n",
      "resetting env. episode reward total was -2.0. running mean: -1.2956733871964479\n",
      "resetting env. episode reward total was 6.0. running mean: -1.2227166533244833\n",
      "resetting env. episode reward total was -5.0. running mean: -1.2604894867912386\n",
      "resetting env. episode reward total was -4.0. running mean: -1.2878845919233262\n",
      "resetting env. episode reward total was 1.0. running mean: -1.2650057460040929\n",
      "resetting env. episode reward total was -8.0. running mean: -1.332355688544052\n",
      "resetting env. episode reward total was 1.0. running mean: -1.3090321316586113\n",
      "resetting env. episode reward total was 8.0. running mean: -1.2159418103420252\n",
      "resetting env. episode reward total was 6.0. running mean: -1.1437823922386048\n",
      "resetting env. episode reward total was 1.0. running mean: -1.1223445683162188\n",
      "resetting env. episode reward total was -14.0. running mean: -1.2511211226330565\n",
      "resetting env. episode reward total was 6.0. running mean: -1.1786099114067259\n",
      "resetting env. episode reward total was 8.0. running mean: -1.0868238122926586\n",
      "resetting env. episode reward total was 2.0. running mean: -1.055955574169732\n",
      "resetting env. episode reward total was -7.0. running mean: -1.1153960184280347\n",
      "resetting env. episode reward total was 5.0. running mean: -1.0542420582437544\n",
      "resetting env. episode reward total was 3.0. running mean: -1.0136996376613168\n",
      "resetting env. episode reward total was -3.0. running mean: -1.0335626412847037\n",
      "resetting env. episode reward total was 10.0. running mean: -0.9232270148718565\n",
      "resetting env. episode reward total was -6.0. running mean: -0.9739947447231381\n",
      "resetting env. episode reward total was 2.0. running mean: -0.9442547972759067\n",
      "resetting env. episode reward total was 6.0. running mean: -0.8748122493031476\n",
      "resetting env. episode reward total was -9.0. running mean: -0.9560641268101161\n",
      "resetting env. episode reward total was 7.0. running mean: -0.8765034855420148\n",
      "resetting env. episode reward total was 5.0. running mean: -0.8177384506865947\n",
      "resetting env. episode reward total was -4.0. running mean: -0.8495610661797287\n",
      "resetting env. episode reward total was 7.0. running mean: -0.7710654555179315\n",
      "resetting env. episode reward total was 4.0. running mean: -0.7233548009627522\n",
      "resetting env. episode reward total was -5.0. running mean: -0.7661212529531247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: -0.8084600404235935\n",
      "resetting env. episode reward total was 12.0. running mean: -0.6803754400193576\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7435716856191641\n",
      "resetting env. episode reward total was 6.0. running mean: -0.6761359687629724\n",
      "resetting env. episode reward total was -9.0. running mean: -0.7593746090753427\n",
      "resetting env. episode reward total was 11.0. running mean: -0.6417808629845893\n",
      "resetting env. episode reward total was -11.0. running mean: -0.7453630543547434\n",
      "resetting env. episode reward total was 5.0. running mean: -0.6879094238111959\n",
      "resetting env. episode reward total was -7.0. running mean: -0.751030329573084\n",
      "resetting env. episode reward total was 13.0. running mean: -0.6135200262773531\n",
      "resetting env. episode reward total was 4.0. running mean: -0.5673848260145795\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5717109777544337\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6159938679768894\n",
      "resetting env. episode reward total was -6.0. running mean: -0.6698339292971205\n",
      "resetting env. episode reward total was -5.0. running mean: -0.7131355900041493\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7760042341041078\n",
      "resetting env. episode reward total was 3.0. running mean: -0.7382441917630667\n",
      "resetting env. episode reward total was -3.0. running mean: -0.760861749845436\n",
      "resetting env. episode reward total was 4.0. running mean: -0.7132531323469816\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7761206010235118\n",
      "resetting env. episode reward total was -7.0. running mean: -0.8383593950132766\n",
      "resetting env. episode reward total was -4.0. running mean: -0.8699758010631439\n",
      "resetting env. episode reward total was -5.0. running mean: -0.9112760430525124\n",
      "resetting env. episode reward total was -5.0. running mean: -0.9521632826219874\n",
      "resetting env. episode reward total was 1.0. running mean: -0.9326416497957675\n",
      "resetting env. episode reward total was 6.0. running mean: -0.8633152332978098\n",
      "resetting env. episode reward total was 6.0. running mean: -0.7946820809648316\n",
      "resetting env. episode reward total was 13.0. running mean: -0.6567352601551832\n",
      "resetting env. episode reward total was -5.0. running mean: -0.7001679075536315\n",
      "resetting env. episode reward total was -1.0. running mean: -0.7031662284780952\n",
      "resetting env. episode reward total was -8.0. running mean: -0.7761345661933142\n",
      "resetting env. episode reward total was 2.0. running mean: -0.7483732205313811\n",
      "resetting env. episode reward total was -10.0. running mean: -0.8408894883260672\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8624805934428066\n",
      "resetting env. episode reward total was -4.0. running mean: -0.8938557875083786\n",
      "resetting env. episode reward total was -9.0. running mean: -0.9749172296332947\n",
      "resetting env. episode reward total was 6.0. running mean: -0.9051680573369618\n",
      "resetting env. episode reward total was 10.0. running mean: -0.7961163767635923\n",
      "resetting env. episode reward total was -13.0. running mean: -0.9181552129959564\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8889736608659968\n",
      "resetting env. episode reward total was 8.0. running mean: -0.8000839242573369\n",
      "resetting env. episode reward total was -4.0. running mean: -0.8320830850147636\n",
      "resetting env. episode reward total was 5.0. running mean: -0.7737622541646159\n",
      "resetting env. episode reward total was -2.0. running mean: -0.7860246316229698\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8281643853067401\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8498827414536727\n",
      "resetting env. episode reward total was -11.0. running mean: -0.9513839140391359\n",
      "resetting env. episode reward total was 3.0. running mean: -0.9118700748987445\n",
      "resetting env. episode reward total was -19.0. running mean: -1.092751374149757\n",
      "resetting env. episode reward total was -5.0. running mean: -1.1318238604082596\n",
      "resetting env. episode reward total was -9.0. running mean: -1.210505621804177\n",
      "resetting env. episode reward total was -3.0. running mean: -1.2284005655861352\n",
      "resetting env. episode reward total was 5.0. running mean: -1.1661165599302739\n",
      "resetting env. episode reward total was -7.0. running mean: -1.224455394330971\n",
      "resetting env. episode reward total was -11.0. running mean: -1.3222108403876613\n",
      "resetting env. episode reward total was -12.0. running mean: -1.4289887319837846\n",
      "resetting env. episode reward total was -17.0. running mean: -1.5846988446639467\n",
      "resetting env. episode reward total was -1.0. running mean: -1.5788518562173073\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6130633376551342\n",
      "resetting env. episode reward total was -10.0. running mean: -1.696932704278583\n",
      "resetting env. episode reward total was -15.0. running mean: -1.829963377235797\n",
      "resetting env. episode reward total was 4.0. running mean: -1.771663743463439\n",
      "resetting env. episode reward total was -4.0. running mean: -1.7939471060288046\n",
      "resetting env. episode reward total was 3.0. running mean: -1.7460076349685165\n",
      "resetting env. episode reward total was 3.0. running mean: -1.6985475586188312\n",
      "resetting env. episode reward total was 2.0. running mean: -1.661562083032643\n",
      "resetting env. episode reward total was -4.0. running mean: -1.6849464622023165\n",
      "resetting env. episode reward total was -9.0. running mean: -1.7580969975802934\n",
      "resetting env. episode reward total was -7.0. running mean: -1.8105160276044905\n",
      "resetting env. episode reward total was 2.0. running mean: -1.7724108673284455\n",
      "resetting env. episode reward total was -13.0. running mean: -1.8846867586551612\n",
      "resetting env. episode reward total was -16.0. running mean: -2.0258398910686095\n",
      "resetting env. episode reward total was -8.0. running mean: -2.0855814921579237\n",
      "resetting env. episode reward total was -11.0. running mean: -2.1747256772363444\n",
      "resetting env. episode reward total was 3.0. running mean: -2.122978420463981\n",
      "resetting env. episode reward total was -4.0. running mean: -2.1417486362593414\n",
      "resetting env. episode reward total was 4.0. running mean: -2.080331149896748\n",
      "resetting env. episode reward total was -2.0. running mean: -2.0795278383977807\n",
      "resetting env. episode reward total was -8.0. running mean: -2.138732560013803\n",
      "resetting env. episode reward total was 3.0. running mean: -2.087345234413665\n",
      "resetting env. episode reward total was -11.0. running mean: -2.176471782069528\n",
      "resetting env. episode reward total was -1.0. running mean: -2.1647070642488324\n",
      "resetting env. episode reward total was -14.0. running mean: -2.283059993606344\n",
      "resetting env. episode reward total was -8.0. running mean: -2.3402293936702807\n",
      "resetting env. episode reward total was 9.0. running mean: -2.226827099733578\n",
      "resetting env. episode reward total was -1.0. running mean: -2.214558828736242\n",
      "resetting env. episode reward total was 7.0. running mean: -2.12241324044888\n",
      "resetting env. episode reward total was -11.0. running mean: -2.211189108044391\n",
      "resetting env. episode reward total was -3.0. running mean: -2.2190772169639468\n",
      "resetting env. episode reward total was -9.0. running mean: -2.286886444794307\n",
      "resetting env. episode reward total was -9.0. running mean: -2.354017580346364\n",
      "resetting env. episode reward total was 6.0. running mean: -2.2704774045429006\n",
      "resetting env. episode reward total was -2.0. running mean: -2.2677726304974715\n",
      "resetting env. episode reward total was -14.0. running mean: -2.385094904192497\n",
      "resetting env. episode reward total was 2.0. running mean: -2.341243955150572\n",
      "resetting env. episode reward total was -10.0. running mean: -2.417831515599066\n",
      "resetting env. episode reward total was -15.0. running mean: -2.5436532004430754\n",
      "resetting env. episode reward total was 3.0. running mean: -2.488216668438645\n",
      "resetting env. episode reward total was -5.0. running mean: -2.513334501754258\n",
      "resetting env. episode reward total was -10.0. running mean: -2.588201156736716\n",
      "resetting env. episode reward total was -10.0. running mean: -2.6623191451693486\n",
      "resetting env. episode reward total was -7.0. running mean: -2.705695953717655\n",
      "resetting env. episode reward total was -11.0. running mean: -2.788638994180478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: -2.790752604238673\n",
      "resetting env. episode reward total was -8.0. running mean: -2.8428450781962864\n",
      "resetting env. episode reward total was -5.0. running mean: -2.8644166274143235\n",
      "resetting env. episode reward total was 9.0. running mean: -2.7457724611401804\n",
      "resetting env. episode reward total was -2.0. running mean: -2.7383147365287788\n",
      "resetting env. episode reward total was -19.0. running mean: -2.900931589163491\n",
      "resetting env. episode reward total was -3.0. running mean: -2.9019222732718557\n",
      "resetting env. episode reward total was 6.0. running mean: -2.8129030505391373\n",
      "resetting env. episode reward total was -8.0. running mean: -2.864774020033746\n",
      "resetting env. episode reward total was -7.0. running mean: -2.9061262798334084\n",
      "resetting env. episode reward total was -6.0. running mean: -2.9370650170350743\n",
      "resetting env. episode reward total was -8.0. running mean: -2.987694366864724\n",
      "resetting env. episode reward total was -11.0. running mean: -3.067817423196076\n",
      "resetting env. episode reward total was 2.0. running mean: -3.0171392489641153\n",
      "resetting env. episode reward total was 5.0. running mean: -2.936967856474474\n",
      "resetting env. episode reward total was 5.0. running mean: -2.8575981779097295\n",
      "resetting env. episode reward total was -6.0. running mean: -2.8890221961306324\n",
      "resetting env. episode reward total was -14.0. running mean: -3.000131974169326\n",
      "resetting env. episode reward total was -13.0. running mean: -3.1001306544276326\n",
      "resetting env. episode reward total was 1.0. running mean: -3.0591293478833563\n",
      "resetting env. episode reward total was -3.0. running mean: -3.0585380544045226\n",
      "resetting env. episode reward total was -11.0. running mean: -3.137952673860477\n",
      "resetting env. episode reward total was -16.0. running mean: -3.266573147121872\n",
      "resetting env. episode reward total was -1.0. running mean: -3.243907415650653\n",
      "resetting env. episode reward total was -3.0. running mean: -3.2414683414941465\n",
      "resetting env. episode reward total was -8.0. running mean: -3.289053658079205\n",
      "resetting env. episode reward total was -1.0. running mean: -3.266163121498413\n",
      "resetting env. episode reward total was -3.0. running mean: -3.2635014902834283\n",
      "resetting env. episode reward total was -7.0. running mean: -3.3008664753805936\n",
      "resetting env. episode reward total was -9.0. running mean: -3.3578578106267876\n",
      "resetting env. episode reward total was -4.0. running mean: -3.3642792325205195\n",
      "resetting env. episode reward total was -5.0. running mean: -3.380636440195314\n",
      "resetting env. episode reward total was -11.0. running mean: -3.4568300757933605\n",
      "resetting env. episode reward total was -13.0. running mean: -3.5522617750354266\n",
      "resetting env. episode reward total was -9.0. running mean: -3.606739157285072\n",
      "resetting env. episode reward total was -15.0. running mean: -3.7206717657122215\n",
      "resetting env. episode reward total was -12.0. running mean: -3.803465048055099\n",
      "resetting env. episode reward total was -13.0. running mean: -3.895430397574548\n",
      "resetting env. episode reward total was -10.0. running mean: -3.956476093598803\n",
      "resetting env. episode reward total was -4.0. running mean: -3.956911332662815\n",
      "resetting env. episode reward total was -10.0. running mean: -4.017342219336187\n",
      "resetting env. episode reward total was -1.0. running mean: -3.9871687971428247\n",
      "resetting env. episode reward total was -15.0. running mean: -4.097297109171397\n",
      "resetting env. episode reward total was 7.0. running mean: -3.986324138079683\n",
      "resetting env. episode reward total was 1.0. running mean: -3.9364608966988865\n",
      "resetting env. episode reward total was -16.0. running mean: -4.0570962877318975\n",
      "resetting env. episode reward total was -4.0. running mean: -4.0565253248545785\n",
      "resetting env. episode reward total was -4.0. running mean: -4.055960071606033\n",
      "resetting env. episode reward total was -9.0. running mean: -4.105400470889973\n",
      "resetting env. episode reward total was 3.0. running mean: -4.034346466181073\n",
      "resetting env. episode reward total was -8.0. running mean: -4.074003001519261\n",
      "resetting env. episode reward total was -5.0. running mean: -4.083262971504069\n",
      "resetting env. episode reward total was -11.0. running mean: -4.152430341789028\n",
      "resetting env. episode reward total was -9.0. running mean: -4.200906038371137\n",
      "resetting env. episode reward total was 4.0. running mean: -4.118896977987426\n",
      "resetting env. episode reward total was -11.0. running mean: -4.187708008207552\n",
      "resetting env. episode reward total was -3.0. running mean: -4.175830928125476\n",
      "resetting env. episode reward total was -11.0. running mean: -4.244072618844222\n",
      "resetting env. episode reward total was -5.0. running mean: -4.25163189265578\n",
      "resetting env. episode reward total was 5.0. running mean: -4.159115573729222\n",
      "resetting env. episode reward total was -4.0. running mean: -4.15752441799193\n",
      "resetting env. episode reward total was -10.0. running mean: -4.21594917381201\n",
      "resetting env. episode reward total was -6.0. running mean: -4.23378968207389\n",
      "resetting env. episode reward total was -3.0. running mean: -4.221451785253151\n",
      "resetting env. episode reward total was -3.0. running mean: -4.209237267400619\n",
      "resetting env. episode reward total was -5.0. running mean: -4.217144894726612\n",
      "resetting env. episode reward total was -15.0. running mean: -4.324973445779347\n",
      "resetting env. episode reward total was -11.0. running mean: -4.3917237113215535\n",
      "resetting env. episode reward total was -4.0. running mean: -4.387806474208338\n",
      "resetting env. episode reward total was -5.0. running mean: -4.3939284094662545\n",
      "resetting env. episode reward total was -10.0. running mean: -4.449989125371592\n",
      "resetting env. episode reward total was -5.0. running mean: -4.455489234117875\n",
      "resetting env. episode reward total was 3.0. running mean: -4.380934341776697\n",
      "resetting env. episode reward total was -5.0. running mean: -4.38712499835893\n",
      "resetting env. episode reward total was -5.0. running mean: -4.39325374837534\n",
      "resetting env. episode reward total was -15.0. running mean: -4.499321210891587\n",
      "resetting env. episode reward total was 1.0. running mean: -4.444327998782671\n",
      "resetting env. episode reward total was -1.0. running mean: -4.409884718794844\n",
      "resetting env. episode reward total was -3.0. running mean: -4.395785871606896\n",
      "resetting env. episode reward total was -5.0. running mean: -4.401828012890827\n",
      "resetting env. episode reward total was -9.0. running mean: -4.447809732761919\n",
      "resetting env. episode reward total was -9.0. running mean: -4.493331635434299\n",
      "resetting env. episode reward total was 6.0. running mean: -4.388398319079957\n",
      "resetting env. episode reward total was -8.0. running mean: -4.424514335889157\n",
      "resetting env. episode reward total was 6.0. running mean: -4.320269192530265\n",
      "resetting env. episode reward total was 9.0. running mean: -4.1870665006049625\n",
      "resetting env. episode reward total was -2.0. running mean: -4.1651958355989125\n",
      "resetting env. episode reward total was 6.0. running mean: -4.063543877242924\n",
      "resetting env. episode reward total was 2.0. running mean: -4.002908438470495\n",
      "resetting env. episode reward total was -3.0. running mean: -3.99287935408579\n",
      "resetting env. episode reward total was 3.0. running mean: -3.922950560544932\n",
      "resetting env. episode reward total was -6.0. running mean: -3.9437210549394828\n",
      "resetting env. episode reward total was -11.0. running mean: -4.014283844390088\n",
      "resetting env. episode reward total was -7.0. running mean: -4.044141005946187\n",
      "resetting env. episode reward total was 2.0. running mean: -3.983699595886725\n",
      "resetting env. episode reward total was -9.0. running mean: -4.033862599927858\n",
      "resetting env. episode reward total was 3.0. running mean: -3.9635239739285795\n",
      "resetting env. episode reward total was -6.0. running mean: -3.9838887341892937\n",
      "resetting env. episode reward total was -7.0. running mean: -4.014049846847401\n",
      "resetting env. episode reward total was 9.0. running mean: -3.883909348378927\n",
      "resetting env. episode reward total was 16.0. running mean: -3.6850702548951375\n",
      "resetting env. episode reward total was -1.0. running mean: -3.658219552346186\n",
      "resetting env. episode reward total was -3.0. running mean: -3.651637356822724\n",
      "resetting env. episode reward total was 7.0. running mean: -3.5451209832544968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -11.0. running mean: -3.619669773421952\n",
      "resetting env. episode reward total was -13.0. running mean: -3.713473075687732\n",
      "resetting env. episode reward total was 6.0. running mean: -3.616338344930855\n",
      "resetting env. episode reward total was 10.0. running mean: -3.4801749614815463\n",
      "resetting env. episode reward total was 9.0. running mean: -3.355373211866731\n",
      "resetting env. episode reward total was -7.0. running mean: -3.3918194797480634\n",
      "resetting env. episode reward total was 4.0. running mean: -3.3179012849505827\n",
      "resetting env. episode reward total was -1.0. running mean: -3.2947222721010765\n",
      "resetting env. episode reward total was -11.0. running mean: -3.371775049380066\n",
      "resetting env. episode reward total was -3.0. running mean: -3.368057298886265\n",
      "resetting env. episode reward total was -7.0. running mean: -3.4043767258974023\n",
      "resetting env. episode reward total was 8.0. running mean: -3.290332958638428\n",
      "resetting env. episode reward total was -1.0. running mean: -3.2674296290520437\n",
      "resetting env. episode reward total was -6.0. running mean: -3.294755332761523\n",
      "resetting env. episode reward total was -3.0. running mean: -3.2918077794339076\n",
      "resetting env. episode reward total was 10.0. running mean: -3.1588897016395685\n",
      "resetting env. episode reward total was -8.0. running mean: -3.207300804623173\n",
      "resetting env. episode reward total was -1.0. running mean: -3.185227796576941\n",
      "resetting env. episode reward total was -10.0. running mean: -3.253375518611172\n",
      "resetting env. episode reward total was -13.0. running mean: -3.35084176342506\n",
      "resetting env. episode reward total was -9.0. running mean: -3.4073333457908093\n",
      "resetting env. episode reward total was -4.0. running mean: -3.413260012332901\n",
      "resetting env. episode reward total was -11.0. running mean: -3.489127412209572\n",
      "resetting env. episode reward total was -3.0. running mean: -3.4842361380874762\n",
      "resetting env. episode reward total was 8.0. running mean: -3.3693937767066013\n",
      "resetting env. episode reward total was -9.0. running mean: -3.425699838939535\n",
      "resetting env. episode reward total was -13.0. running mean: -3.5214428405501397\n",
      "resetting env. episode reward total was 2.0. running mean: -3.466228412144638\n",
      "resetting env. episode reward total was 8.0. running mean: -3.3515661280231916\n",
      "resetting env. episode reward total was 6.0. running mean: -3.2580504667429597\n",
      "resetting env. episode reward total was 5.0. running mean: -3.1754699620755305\n",
      "resetting env. episode reward total was -6.0. running mean: -3.203715262454775\n",
      "resetting env. episode reward total was 4.0. running mean: -3.131678109830227\n",
      "resetting env. episode reward total was -6.0. running mean: -3.1603613287319248\n",
      "resetting env. episode reward total was -12.0. running mean: -3.2487577154446057\n",
      "resetting env. episode reward total was 9.0. running mean: -3.1262701382901597\n",
      "resetting env. episode reward total was -2.0. running mean: -3.1150074369072582\n",
      "resetting env. episode reward total was -2.0. running mean: -3.103857362538186\n",
      "resetting env. episode reward total was -13.0. running mean: -3.2028187889128037\n",
      "resetting env. episode reward total was 1.0. running mean: -3.1607906010236757\n",
      "resetting env. episode reward total was 14.0. running mean: -2.989182695013439\n",
      "resetting env. episode reward total was -11.0. running mean: -3.0692908680633044\n",
      "resetting env. episode reward total was -8.0. running mean: -3.1185979593826714\n",
      "resetting env. episode reward total was -4.0. running mean: -3.1274119797888447\n",
      "resetting env. episode reward total was 7.0. running mean: -3.0261378599909565\n",
      "resetting env. episode reward total was 5.0. running mean: -2.945876481391047\n",
      "resetting env. episode reward total was 2.0. running mean: -2.8964177165771368\n",
      "resetting env. episode reward total was -12.0. running mean: -2.9874535394113653\n",
      "resetting env. episode reward total was 7.0. running mean: -2.8875790040172515\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8687032139770787\n",
      "resetting env. episode reward total was -2.0. running mean: -2.8600161818373078\n",
      "resetting env. episode reward total was -4.0. running mean: -2.871416020018935\n",
      "resetting env. episode reward total was -12.0. running mean: -2.9627018598187456\n",
      "resetting env. episode reward total was -6.0. running mean: -2.993074841220558\n",
      "resetting env. episode reward total was 5.0. running mean: -2.9131440928083525\n",
      "resetting env. episode reward total was 4.0. running mean: -2.844012651880269\n",
      "resetting env. episode reward total was -13.0. running mean: -2.945572525361466\n",
      "resetting env. episode reward total was 3.0. running mean: -2.886116800107852\n",
      "resetting env. episode reward total was -7.0. running mean: -2.9272556321067733\n",
      "resetting env. episode reward total was -1.0. running mean: -2.9079830757857055\n",
      "resetting env. episode reward total was 1.0. running mean: -2.8689032450278487\n",
      "resetting env. episode reward total was -13.0. running mean: -2.97021421257757\n",
      "resetting env. episode reward total was 1.0. running mean: -2.9305120704517944\n",
      "resetting env. episode reward total was -16.0. running mean: -3.0612069497472767\n",
      "resetting env. episode reward total was -8.0. running mean: -3.110594880249804\n",
      "resetting env. episode reward total was -10.0. running mean: -3.179488931447306\n",
      "resetting env. episode reward total was -9.0. running mean: -3.2376940421328326\n",
      "resetting env. episode reward total was -15.0. running mean: -3.355317101711504\n",
      "resetting env. episode reward total was -14.0. running mean: -3.461763930694389\n",
      "resetting env. episode reward total was -15.0. running mean: -3.577146291387445\n",
      "resetting env. episode reward total was -12.0. running mean: -3.661374828473571\n",
      "resetting env. episode reward total was -11.0. running mean: -3.734761080188835\n",
      "resetting env. episode reward total was -8.0. running mean: -3.7774134693869468\n",
      "resetting env. episode reward total was -9.0. running mean: -3.829639334693077\n",
      "resetting env. episode reward total was -5.0. running mean: -3.841342941346146\n",
      "resetting env. episode reward total was -13.0. running mean: -3.9329295119326844\n",
      "resetting env. episode reward total was -9.0. running mean: -3.9836002168133575\n",
      "resetting env. episode reward total was -8.0. running mean: -4.023764214645224\n",
      "resetting env. episode reward total was -4.0. running mean: -4.023526572498771\n",
      "resetting env. episode reward total was -4.0. running mean: -4.023291306773784\n",
      "resetting env. episode reward total was -3.0. running mean: -4.013058393706046\n",
      "resetting env. episode reward total was -1.0. running mean: -3.982927809768985\n",
      "resetting env. episode reward total was -13.0. running mean: -4.073098531671295\n",
      "resetting env. episode reward total was 5.0. running mean: -3.982367546354583\n",
      "resetting env. episode reward total was -3.0. running mean: -3.972543870891037\n",
      "resetting env. episode reward total was -9.0. running mean: -4.0228184321821265\n",
      "resetting env. episode reward total was -1.0. running mean: -3.992590247860305\n",
      "resetting env. episode reward total was -4.0. running mean: -3.992664345381702\n",
      "resetting env. episode reward total was -7.0. running mean: -4.022737701927885\n",
      "resetting env. episode reward total was -4.0. running mean: -4.022510324908606\n",
      "resetting env. episode reward total was -7.0. running mean: -4.05228522165952\n",
      "resetting env. episode reward total was -2.0. running mean: -4.031762369442925\n",
      "resetting env. episode reward total was -5.0. running mean: -4.041444745748495\n",
      "resetting env. episode reward total was -7.0. running mean: -4.071030298291011\n",
      "resetting env. episode reward total was -11.0. running mean: -4.140319995308101\n",
      "resetting env. episode reward total was -10.0. running mean: -4.19891679535502\n",
      "resetting env. episode reward total was -10.0. running mean: -4.256927627401469\n",
      "resetting env. episode reward total was -11.0. running mean: -4.324358351127454\n",
      "resetting env. episode reward total was -4.0. running mean: -4.32111476761618\n",
      "resetting env. episode reward total was -3.0. running mean: -4.307903619940019\n",
      "resetting env. episode reward total was -7.0. running mean: -4.334824583740619\n",
      "resetting env. episode reward total was -7.0. running mean: -4.361476337903213\n",
      "resetting env. episode reward total was -9.0. running mean: -4.407861574524181\n",
      "resetting env. episode reward total was -16.0. running mean: -4.523782958778939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: -4.428545129191149\n",
      "resetting env. episode reward total was -8.0. running mean: -4.464259677899237\n",
      "resetting env. episode reward total was -6.0. running mean: -4.479617081120245\n",
      "resetting env. episode reward total was -8.0. running mean: -4.514820910309043\n",
      "resetting env. episode reward total was -5.0. running mean: -4.519672701205952\n",
      "resetting env. episode reward total was -2.0. running mean: -4.494475974193892\n",
      "resetting env. episode reward total was -5.0. running mean: -4.499531214451953\n",
      "resetting env. episode reward total was -3.0. running mean: -4.484535902307434\n",
      "resetting env. episode reward total was -2.0. running mean: -4.45969054328436\n",
      "resetting env. episode reward total was -12.0. running mean: -4.535093637851516\n",
      "resetting env. episode reward total was -1.0. running mean: -4.499742701473001\n",
      "resetting env. episode reward total was 2.0. running mean: -4.434745274458272\n",
      "resetting env. episode reward total was -9.0. running mean: -4.480397821713689\n",
      "resetting env. episode reward total was -8.0. running mean: -4.515593843496553\n",
      "resetting env. episode reward total was 2.0. running mean: -4.450437905061587\n",
      "resetting env. episode reward total was -8.0. running mean: -4.485933526010972\n",
      "resetting env. episode reward total was -6.0. running mean: -4.501074190750861\n",
      "resetting env. episode reward total was -8.0. running mean: -4.536063448843353\n",
      "resetting env. episode reward total was -14.0. running mean: -4.630702814354919\n",
      "resetting env. episode reward total was -2.0. running mean: -4.604395786211369\n",
      "resetting env. episode reward total was -7.0. running mean: -4.628351828349255\n",
      "resetting env. episode reward total was -3.0. running mean: -4.612068310065763\n",
      "resetting env. episode reward total was -15.0. running mean: -4.7159476269651055\n",
      "resetting env. episode reward total was -1.0. running mean: -4.678788150695454\n",
      "resetting env. episode reward total was -19.0. running mean: -4.8220002691885\n",
      "resetting env. episode reward total was -1.0. running mean: -4.783780266496615\n",
      "resetting env. episode reward total was -5.0. running mean: -4.785942463831649\n",
      "resetting env. episode reward total was -6.0. running mean: -4.798083039193332\n",
      "resetting env. episode reward total was -12.0. running mean: -4.8701022088013985\n",
      "resetting env. episode reward total was -7.0. running mean: -4.891401186713384\n",
      "resetting env. episode reward total was -2.0. running mean: -4.86248717484625\n",
      "resetting env. episode reward total was -17.0. running mean: -4.983862303097787\n",
      "resetting env. episode reward total was -4.0. running mean: -4.974023680066809\n",
      "resetting env. episode reward total was -9.0. running mean: -5.014283443266141\n",
      "resetting env. episode reward total was 10.0. running mean: -4.8641406088334795\n",
      "resetting env. episode reward total was -5.0. running mean: -4.865499202745145\n",
      "resetting env. episode reward total was -4.0. running mean: -4.856844210717694\n",
      "resetting env. episode reward total was -1.0. running mean: -4.818275768610516\n",
      "resetting env. episode reward total was 9.0. running mean: -4.680093010924411\n",
      "resetting env. episode reward total was -5.0. running mean: -4.683292080815167\n",
      "resetting env. episode reward total was -7.0. running mean: -4.706459160007015\n",
      "resetting env. episode reward total was -11.0. running mean: -4.769394568406946\n",
      "resetting env. episode reward total was -9.0. running mean: -4.811700622722876\n",
      "resetting env. episode reward total was -3.0. running mean: -4.793583616495647\n",
      "resetting env. episode reward total was -10.0. running mean: -4.84564778033069\n",
      "resetting env. episode reward total was -10.0. running mean: -4.897191302527383\n",
      "resetting env. episode reward total was -5.0. running mean: -4.898219389502109\n",
      "resetting env. episode reward total was -7.0. running mean: -4.919237195607088\n",
      "resetting env. episode reward total was -7.0. running mean: -4.940044823651017\n",
      "resetting env. episode reward total was -10.0. running mean: -4.990644375414506\n",
      "resetting env. episode reward total was -10.0. running mean: -5.04073793166036\n",
      "resetting env. episode reward total was -12.0. running mean: -5.110330552343757\n",
      "resetting env. episode reward total was -5.0. running mean: -5.109227246820319\n",
      "resetting env. episode reward total was -13.0. running mean: -5.188134974352115\n",
      "resetting env. episode reward total was -9.0. running mean: -5.226253624608594\n",
      "resetting env. episode reward total was -15.0. running mean: -5.323991088362509\n",
      "resetting env. episode reward total was 6.0. running mean: -5.210751177478884\n",
      "resetting env. episode reward total was -7.0. running mean: -5.228643665704095\n",
      "resetting env. episode reward total was -16.0. running mean: -5.336357229047055\n",
      "resetting env. episode reward total was -11.0. running mean: -5.392993656756585\n",
      "resetting env. episode reward total was -16.0. running mean: -5.499063720189019\n",
      "resetting env. episode reward total was -5.0. running mean: -5.4940730829871285\n",
      "resetting env. episode reward total was -3.0. running mean: -5.469132352157257\n",
      "resetting env. episode reward total was -1.0. running mean: -5.424441028635685\n",
      "resetting env. episode reward total was -10.0. running mean: -5.470196618349328\n",
      "resetting env. episode reward total was -9.0. running mean: -5.505494652165834\n",
      "resetting env. episode reward total was -10.0. running mean: -5.550439705644175\n",
      "resetting env. episode reward total was -12.0. running mean: -5.614935308587733\n",
      "resetting env. episode reward total was -5.0. running mean: -5.6087859555018555\n",
      "resetting env. episode reward total was -7.0. running mean: -5.622698095946837\n",
      "resetting env. episode reward total was -6.0. running mean: -5.6264711149873685\n",
      "resetting env. episode reward total was -14.0. running mean: -5.7102064038374944\n",
      "resetting env. episode reward total was -9.0. running mean: -5.743104339799119\n",
      "resetting env. episode reward total was -10.0. running mean: -5.785673296401128\n",
      "resetting env. episode reward total was -18.0. running mean: -5.907816563437116\n",
      "resetting env. episode reward total was -5.0. running mean: -5.898738397802744\n",
      "resetting env. episode reward total was -1.0. running mean: -5.849751013824717\n",
      "resetting env. episode reward total was -13.0. running mean: -5.9212535036864695\n",
      "resetting env. episode reward total was -1.0. running mean: -5.872040968649604\n",
      "resetting env. episode reward total was -7.0. running mean: -5.883320558963108\n",
      "resetting env. episode reward total was -9.0. running mean: -5.9144873533734765\n",
      "resetting env. episode reward total was -11.0. running mean: -5.965342479839742\n",
      "resetting env. episode reward total was -2.0. running mean: -5.925689055041344\n",
      "resetting env. episode reward total was -4.0. running mean: -5.906432164490931\n",
      "resetting env. episode reward total was 8.0. running mean: -5.7673678428460216\n",
      "resetting env. episode reward total was 6.0. running mean: -5.649694164417562\n",
      "resetting env. episode reward total was 12.0. running mean: -5.473197222773385\n",
      "resetting env. episode reward total was -3.0. running mean: -5.4484652505456515\n",
      "resetting env. episode reward total was 3.0. running mean: -5.363980598040195\n",
      "resetting env. episode reward total was 2.0. running mean: -5.290340792059793\n",
      "resetting env. episode reward total was -1.0. running mean: -5.247437384139195\n",
      "resetting env. episode reward total was 5.0. running mean: -5.144963010297803\n",
      "resetting env. episode reward total was 5.0. running mean: -5.043513380194826\n",
      "resetting env. episode reward total was -12.0. running mean: -5.1130782463928774\n",
      "resetting env. episode reward total was -3.0. running mean: -5.091947463928949\n",
      "resetting env. episode reward total was -13.0. running mean: -5.17102798928966\n",
      "resetting env. episode reward total was 3.0. running mean: -5.089317709396763\n",
      "resetting env. episode reward total was 12.0. running mean: -4.9184245323027955\n",
      "resetting env. episode reward total was 6.0. running mean: -4.809240286979768\n",
      "resetting env. episode reward total was -8.0. running mean: -4.84114788410997\n",
      "resetting env. episode reward total was -1.0. running mean: -4.80273640526887\n",
      "resetting env. episode reward total was 3.0. running mean: -4.724709041216181\n",
      "resetting env. episode reward total was 6.0. running mean: -4.61746195080402\n",
      "resetting env. episode reward total was -1.0. running mean: -4.58128733129598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: -4.44547445798302\n",
      "resetting env. episode reward total was -10.0. running mean: -4.501019713403189\n",
      "resetting env. episode reward total was -1.0. running mean: -4.466009516269157\n",
      "resetting env. episode reward total was -7.0. running mean: -4.491349421106466\n",
      "resetting env. episode reward total was -3.0. running mean: -4.476435926895402\n",
      "resetting env. episode reward total was 1.0. running mean: -4.421671567626448\n",
      "resetting env. episode reward total was -9.0. running mean: -4.467454851950183\n",
      "resetting env. episode reward total was -4.0. running mean: -4.462780303430682\n",
      "resetting env. episode reward total was -9.0. running mean: -4.508152500396375\n",
      "resetting env. episode reward total was -5.0. running mean: -4.513070975392411\n",
      "resetting env. episode reward total was -5.0. running mean: -4.517940265638487\n",
      "resetting env. episode reward total was -2.0. running mean: -4.492760862982101\n",
      "resetting env. episode reward total was -19.0. running mean: -4.637833254352281\n",
      "resetting env. episode reward total was -6.0. running mean: -4.6514549218087575\n",
      "resetting env. episode reward total was -13.0. running mean: -4.73494037259067\n",
      "resetting env. episode reward total was -5.0. running mean: -4.7375909688647635\n",
      "resetting env. episode reward total was -9.0. running mean: -4.780215059176116\n",
      "resetting env. episode reward total was -4.0. running mean: -4.7724129085843545\n",
      "resetting env. episode reward total was -8.0. running mean: -4.804688779498511\n",
      "resetting env. episode reward total was -7.0. running mean: -4.826641891703526\n",
      "resetting env. episode reward total was -9.0. running mean: -4.86837547278649\n",
      "resetting env. episode reward total was 2.0. running mean: -4.799691718058626\n",
      "resetting env. episode reward total was -1.0. running mean: -4.76169480087804\n",
      "resetting env. episode reward total was -13.0. running mean: -4.844077852869259\n",
      "resetting env. episode reward total was -9.0. running mean: -4.885637074340567\n",
      "resetting env. episode reward total was -8.0. running mean: -4.916780703597161\n",
      "resetting env. episode reward total was -11.0. running mean: -4.977612896561189\n",
      "resetting env. episode reward total was -7.0. running mean: -4.997836767595578\n",
      "resetting env. episode reward total was -3.0. running mean: -4.977858399919622\n",
      "resetting env. episode reward total was -6.0. running mean: -4.988079815920425\n",
      "resetting env. episode reward total was -7.0. running mean: -5.008199017761221\n",
      "resetting env. episode reward total was -5.0. running mean: -5.008117027583609\n",
      "resetting env. episode reward total was -8.0. running mean: -5.038035857307773\n",
      "resetting env. episode reward total was -5.0. running mean: -5.037655498734695\n",
      "resetting env. episode reward total was -4.0. running mean: -5.027278943747349\n",
      "resetting env. episode reward total was -13.0. running mean: -5.107006154309875\n",
      "resetting env. episode reward total was -9.0. running mean: -5.145936092766776\n",
      "resetting env. episode reward total was -5.0. running mean: -5.1444767318391085\n",
      "resetting env. episode reward total was -6.0. running mean: -5.153031964520717\n",
      "resetting env. episode reward total was -16.0. running mean: -5.26150164487551\n",
      "resetting env. episode reward total was -9.0. running mean: -5.298886628426755\n",
      "resetting env. episode reward total was -5.0. running mean: -5.295897762142487\n",
      "resetting env. episode reward total was -7.0. running mean: -5.312938784521062\n",
      "resetting env. episode reward total was -10.0. running mean: -5.3598093966758515\n",
      "resetting env. episode reward total was -4.0. running mean: -5.346211302709093\n",
      "resetting env. episode reward total was -9.0. running mean: -5.382749189682001\n",
      "resetting env. episode reward total was -11.0. running mean: -5.438921697785181\n",
      "resetting env. episode reward total was -3.0. running mean: -5.414532480807329\n",
      "resetting env. episode reward total was -11.0. running mean: -5.470387155999257\n",
      "resetting env. episode reward total was 6.0. running mean: -5.355683284439264\n",
      "resetting env. episode reward total was 4.0. running mean: -5.262126451594871\n",
      "resetting env. episode reward total was -17.0. running mean: -5.379505187078922\n",
      "resetting env. episode reward total was -3.0. running mean: -5.355710135208133\n",
      "resetting env. episode reward total was -10.0. running mean: -5.4021530338560515\n",
      "resetting env. episode reward total was 1.0. running mean: -5.338131503517491\n",
      "resetting env. episode reward total was 5.0. running mean: -5.234750188482317\n",
      "resetting env. episode reward total was 10.0. running mean: -5.082402686597494\n",
      "resetting env. episode reward total was -8.0. running mean: -5.111578659731519\n",
      "resetting env. episode reward total was -9.0. running mean: -5.150462873134203\n",
      "resetting env. episode reward total was -8.0. running mean: -5.178958244402861\n",
      "resetting env. episode reward total was -17.0. running mean: -5.297168661958833\n",
      "resetting env. episode reward total was -5.0. running mean: -5.294196975339244\n",
      "resetting env. episode reward total was -11.0. running mean: -5.351255005585852\n",
      "resetting env. episode reward total was -7.0. running mean: -5.367742455529994\n",
      "resetting env. episode reward total was 3.0. running mean: -5.284065030974694\n",
      "resetting env. episode reward total was -13.0. running mean: -5.361224380664947\n",
      "resetting env. episode reward total was -10.0. running mean: -5.407612136858297\n",
      "resetting env. episode reward total was -9.0. running mean: -5.443536015489713\n",
      "resetting env. episode reward total was -2.0. running mean: -5.409100655334816\n",
      "resetting env. episode reward total was -13.0. running mean: -5.4850096487814675\n",
      "resetting env. episode reward total was -5.0. running mean: -5.480159552293652\n",
      "resetting env. episode reward total was -5.0. running mean: -5.475357956770716\n",
      "resetting env. episode reward total was -3.0. running mean: -5.450604377203009\n",
      "resetting env. episode reward total was -8.0. running mean: -5.476098333430978\n",
      "resetting env. episode reward total was -7.0. running mean: -5.491337350096669\n",
      "resetting env. episode reward total was -3.0. running mean: -5.466423976595702\n",
      "resetting env. episode reward total was -2.0. running mean: -5.431759736829744\n",
      "resetting env. episode reward total was -7.0. running mean: -5.447442139461447\n",
      "resetting env. episode reward total was -3.0. running mean: -5.422967718066833\n",
      "resetting env. episode reward total was -5.0. running mean: -5.418738040886165\n",
      "resetting env. episode reward total was -6.0. running mean: -5.424550660477303\n",
      "resetting env. episode reward total was -7.0. running mean: -5.44030515387253\n",
      "resetting env. episode reward total was 7.0. running mean: -5.315902102333805\n",
      "resetting env. episode reward total was 2.0. running mean: -5.242743081310468\n",
      "resetting env. episode reward total was -8.0. running mean: -5.270315650497363\n",
      "resetting env. episode reward total was -14.0. running mean: -5.357612493992389\n",
      "resetting env. episode reward total was -8.0. running mean: -5.384036369052465\n",
      "resetting env. episode reward total was -14.0. running mean: -5.47019600536194\n",
      "resetting env. episode reward total was 1.0. running mean: -5.405494045308321\n",
      "resetting env. episode reward total was -11.0. running mean: -5.461439104855238\n",
      "resetting env. episode reward total was -2.0. running mean: -5.426824713806685\n",
      "resetting env. episode reward total was 1.0. running mean: -5.362556466668618\n",
      "resetting env. episode reward total was 5.0. running mean: -5.258930902001932\n",
      "resetting env. episode reward total was -9.0. running mean: -5.296341592981912\n",
      "resetting env. episode reward total was -13.0. running mean: -5.373378177052093\n",
      "resetting env. episode reward total was -3.0. running mean: -5.349644395281572\n",
      "resetting env. episode reward total was 2.0. running mean: -5.276147951328757\n",
      "resetting env. episode reward total was -3.0. running mean: -5.253386471815469\n",
      "resetting env. episode reward total was -5.0. running mean: -5.250852607097315\n",
      "resetting env. episode reward total was 9.0. running mean: -5.108344081026342\n",
      "resetting env. episode reward total was -5.0. running mean: -5.1072606402160785\n",
      "resetting env. episode reward total was 5.0. running mean: -5.006188033813918\n",
      "resetting env. episode reward total was -5.0. running mean: -5.006126153475778\n",
      "resetting env. episode reward total was -18.0. running mean: -5.13606489194102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -2.0. running mean: -5.104704243021609\n",
      "resetting env. episode reward total was -3.0. running mean: -5.083657200591393\n",
      "resetting env. episode reward total was -9.0. running mean: -5.122820628585479\n",
      "resetting env. episode reward total was 1.0. running mean: -5.061592422299624\n",
      "resetting env. episode reward total was -1.0. running mean: -5.020976498076627\n",
      "resetting env. episode reward total was -6.0. running mean: -5.03076673309586\n",
      "resetting env. episode reward total was 7.0. running mean: -4.910459065764901\n",
      "resetting env. episode reward total was -6.0. running mean: -4.921354475107252\n",
      "resetting env. episode reward total was -8.0. running mean: -4.95214093035618\n",
      "resetting env. episode reward total was -8.0. running mean: -4.982619521052618\n",
      "resetting env. episode reward total was -3.0. running mean: -4.9627933258420915\n",
      "resetting env. episode reward total was -11.0. running mean: -5.023165392583671\n",
      "resetting env. episode reward total was -8.0. running mean: -5.052933738657834\n",
      "resetting env. episode reward total was 2.0. running mean: -4.982404401271256\n",
      "resetting env. episode reward total was -9.0. running mean: -5.022580357258543\n",
      "resetting env. episode reward total was 1.0. running mean: -4.962354553685958\n",
      "resetting env. episode reward total was -11.0. running mean: -5.022731008149099\n",
      "resetting env. episode reward total was 3.0. running mean: -4.942503698067608\n",
      "resetting env. episode reward total was -15.0. running mean: -5.043078661086932\n",
      "resetting env. episode reward total was -11.0. running mean: -5.102647874476063\n",
      "resetting env. episode reward total was -13.0. running mean: -5.181621395731303\n",
      "resetting env. episode reward total was 6.0. running mean: -5.06980518177399\n",
      "resetting env. episode reward total was -5.0. running mean: -5.06910712995625\n",
      "resetting env. episode reward total was -6.0. running mean: -5.078416058656687\n",
      "resetting env. episode reward total was -15.0. running mean: -5.17763189807012\n",
      "resetting env. episode reward total was -12.0. running mean: -5.245855579089419\n",
      "resetting env. episode reward total was -3.0. running mean: -5.223397023298525\n",
      "resetting env. episode reward total was -10.0. running mean: -5.271163053065539\n",
      "resetting env. episode reward total was 4.0. running mean: -5.178451422534883\n",
      "resetting env. episode reward total was -6.0. running mean: -5.186666908309534\n",
      "resetting env. episode reward total was -7.0. running mean: -5.204800239226439\n",
      "resetting env. episode reward total was -8.0. running mean: -5.232752236834175\n",
      "resetting env. episode reward total was -10.0. running mean: -5.280424714465833\n",
      "resetting env. episode reward total was -5.0. running mean: -5.277620467321174\n",
      "resetting env. episode reward total was -15.0. running mean: -5.374844262647963\n",
      "resetting env. episode reward total was -15.0. running mean: -5.471095820021484\n",
      "resetting env. episode reward total was -9.0. running mean: -5.506384861821268\n",
      "resetting env. episode reward total was -7.0. running mean: -5.521321013203056\n",
      "resetting env. episode reward total was -9.0. running mean: -5.556107803071026\n",
      "resetting env. episode reward total was -5.0. running mean: -5.5505467250403155\n",
      "resetting env. episode reward total was -10.0. running mean: -5.595041257789912\n",
      "resetting env. episode reward total was -3.0. running mean: -5.569090845212013\n",
      "resetting env. episode reward total was -7.0. running mean: -5.583399936759894\n",
      "resetting env. episode reward total was 8.0. running mean: -5.447565937392294\n",
      "resetting env. episode reward total was -2.0. running mean: -5.413090278018371\n",
      "resetting env. episode reward total was 2.0. running mean: -5.338959375238188\n",
      "resetting env. episode reward total was -8.0. running mean: -5.3655697814858065\n",
      "resetting env. episode reward total was -6.0. running mean: -5.371914083670948\n",
      "resetting env. episode reward total was -9.0. running mean: -5.408194942834238\n",
      "resetting env. episode reward total was -7.0. running mean: -5.424112993405896\n",
      "resetting env. episode reward total was -9.0. running mean: -5.459871863471837\n",
      "resetting env. episode reward total was -1.0. running mean: -5.415273144837118\n",
      "resetting env. episode reward total was -6.0. running mean: -5.4211204133887465\n",
      "resetting env. episode reward total was 8.0. running mean: -5.286909209254859\n",
      "resetting env. episode reward total was -9.0. running mean: -5.32404011716231\n",
      "resetting env. episode reward total was -11.0. running mean: -5.380799715990688\n",
      "resetting env. episode reward total was -7.0. running mean: -5.396991718830781\n",
      "resetting env. episode reward total was -7.0. running mean: -5.413021801642474\n",
      "resetting env. episode reward total was -10.0. running mean: -5.458891583626048\n",
      "resetting env. episode reward total was -10.0. running mean: -5.504302667789787\n",
      "resetting env. episode reward total was 3.0. running mean: -5.419259641111889\n",
      "resetting env. episode reward total was -13.0. running mean: -5.49506704470077\n",
      "resetting env. episode reward total was -11.0. running mean: -5.550116374253762\n",
      "resetting env. episode reward total was -9.0. running mean: -5.584615210511225\n",
      "resetting env. episode reward total was -9.0. running mean: -5.618769058406112\n",
      "resetting env. episode reward total was -5.0. running mean: -5.612581367822051\n",
      "resetting env. episode reward total was -3.0. running mean: -5.58645555414383\n",
      "resetting env. episode reward total was 3.0. running mean: -5.500590998602392\n",
      "resetting env. episode reward total was 3.0. running mean: -5.415585088616368\n",
      "resetting env. episode reward total was 6.0. running mean: -5.301429237730204\n",
      "resetting env. episode reward total was -9.0. running mean: -5.338414945352902\n",
      "resetting env. episode reward total was -13.0. running mean: -5.415030795899373\n",
      "resetting env. episode reward total was -13.0. running mean: -5.490880487940379\n",
      "resetting env. episode reward total was -9.0. running mean: -5.525971683060975\n",
      "resetting env. episode reward total was -5.0. running mean: -5.520711966230365\n",
      "resetting env. episode reward total was -3.0. running mean: -5.495504846568062\n",
      "resetting env. episode reward total was -5.0. running mean: -5.490549798102381\n",
      "resetting env. episode reward total was -1.0. running mean: -5.445644300121357\n",
      "resetting env. episode reward total was 2.0. running mean: -5.371187857120144\n",
      "resetting env. episode reward total was -8.0. running mean: -5.397475978548942\n",
      "resetting env. episode reward total was -8.0. running mean: -5.423501218763453\n",
      "resetting env. episode reward total was -1.0. running mean: -5.379266206575818\n",
      "resetting env. episode reward total was -1.0. running mean: -5.33547354451006\n",
      "resetting env. episode reward total was 7.0. running mean: -5.212118809064958\n",
      "resetting env. episode reward total was -7.0. running mean: -5.229997620974309\n",
      "resetting env. episode reward total was -5.0. running mean: -5.227697644764566\n",
      "resetting env. episode reward total was -11.0. running mean: -5.285420668316921\n",
      "resetting env. episode reward total was -5.0. running mean: -5.282566461633752\n",
      "resetting env. episode reward total was -4.0. running mean: -5.269740797017414\n",
      "resetting env. episode reward total was 3.0. running mean: -5.18704338904724\n",
      "resetting env. episode reward total was 7.0. running mean: -5.0651729551567675\n",
      "resetting env. episode reward total was -6.0. running mean: -5.074521225605199\n",
      "resetting env. episode reward total was -15.0. running mean: -5.173776013349148\n",
      "resetting env. episode reward total was 8.0. running mean: -5.042038253215656\n",
      "resetting env. episode reward total was -9.0. running mean: -5.081617870683499\n",
      "resetting env. episode reward total was -5.0. running mean: -5.080801691976664\n",
      "resetting env. episode reward total was -9.0. running mean: -5.119993675056897\n",
      "resetting env. episode reward total was -12.0. running mean: -5.188793738306328\n",
      "resetting env. episode reward total was -7.0. running mean: -5.2069058009232645\n",
      "resetting env. episode reward total was -3.0. running mean: -5.184836742914032\n",
      "resetting env. episode reward total was -5.0. running mean: -5.182988375484892\n",
      "resetting env. episode reward total was 6.0. running mean: -5.071158491730044\n",
      "resetting env. episode reward total was -13.0. running mean: -5.150446906812744\n",
      "resetting env. episode reward total was -6.0. running mean: -5.158942437744615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: -5.077353013367169\n",
      "resetting env. episode reward total was -13.0. running mean: -5.1565794832334975\n",
      "resetting env. episode reward total was -7.0. running mean: -5.175013688401163\n",
      "resetting env. episode reward total was -11.0. running mean: -5.233263551517151\n",
      "resetting env. episode reward total was -13.0. running mean: -5.310930916001979\n",
      "resetting env. episode reward total was 6.0. running mean: -5.19782160684196\n",
      "resetting env. episode reward total was -9.0. running mean: -5.235843390773541\n",
      "resetting env. episode reward total was -4.0. running mean: -5.223484956865805\n",
      "resetting env. episode reward total was -1.0. running mean: -5.181250107297147\n",
      "resetting env. episode reward total was -17.0. running mean: -5.299437606224175\n",
      "resetting env. episode reward total was -9.0. running mean: -5.336443230161933\n",
      "resetting env. episode reward total was -6.0. running mean: -5.343078797860313\n",
      "resetting env. episode reward total was -8.0. running mean: -5.36964800988171\n",
      "resetting env. episode reward total was -14.0. running mean: -5.455951529782893\n",
      "resetting env. episode reward total was -7.0. running mean: -5.4713920144850645\n",
      "resetting env. episode reward total was -3.0. running mean: -5.446678094340214\n",
      "resetting env. episode reward total was 5.0. running mean: -5.342211313396812\n",
      "resetting env. episode reward total was -11.0. running mean: -5.398789200262844\n",
      "resetting env. episode reward total was 8.0. running mean: -5.264801308260216\n",
      "resetting env. episode reward total was 5.0. running mean: -5.162153295177614\n",
      "resetting env. episode reward total was 7.0. running mean: -5.040531762225838\n",
      "resetting env. episode reward total was -5.0. running mean: -5.040126444603579\n",
      "resetting env. episode reward total was -3.0. running mean: -5.019725180157543\n",
      "resetting env. episode reward total was 1.0. running mean: -4.959527928355968\n",
      "resetting env. episode reward total was -1.0. running mean: -4.919932649072408\n",
      "resetting env. episode reward total was -1.0. running mean: -4.880733322581683\n",
      "resetting env. episode reward total was -7.0. running mean: -4.901925989355867\n",
      "resetting env. episode reward total was 4.0. running mean: -4.812906729462308\n",
      "resetting env. episode reward total was 4.0. running mean: -4.724777662167685\n",
      "resetting env. episode reward total was -11.0. running mean: -4.787529885546008\n",
      "resetting env. episode reward total was -12.0. running mean: -4.8596545866905485\n",
      "resetting env. episode reward total was -9.0. running mean: -4.901058040823643\n",
      "resetting env. episode reward total was 3.0. running mean: -4.822047460415407\n",
      "resetting env. episode reward total was 1.0. running mean: -4.763826985811253\n",
      "resetting env. episode reward total was 5.0. running mean: -4.66618871595314\n",
      "resetting env. episode reward total was -1.0. running mean: -4.629526828793609\n",
      "resetting env. episode reward total was -3.0. running mean: -4.613231560505673\n",
      "resetting env. episode reward total was 6.0. running mean: -4.507099244900616\n",
      "resetting env. episode reward total was 10.0. running mean: -4.36202825245161\n",
      "resetting env. episode reward total was 1.0. running mean: -4.308407969927094\n",
      "resetting env. episode reward total was 6.0. running mean: -4.205323890227824\n",
      "resetting env. episode reward total was -6.0. running mean: -4.223270651325545\n",
      "resetting env. episode reward total was -11.0. running mean: -4.29103794481229\n",
      "resetting env. episode reward total was -3.0. running mean: -4.2781275653641675\n",
      "resetting env. episode reward total was -8.0. running mean: -4.315346289710526\n",
      "resetting env. episode reward total was 5.0. running mean: -4.222192826813421\n",
      "resetting env. episode reward total was 3.0. running mean: -4.149970898545287\n",
      "resetting env. episode reward total was -4.0. running mean: -4.148471189559834\n",
      "resetting env. episode reward total was -7.0. running mean: -4.1769864776642365\n",
      "resetting env. episode reward total was -7.0. running mean: -4.205216612887594\n",
      "resetting env. episode reward total was -5.0. running mean: -4.213164446758718\n",
      "resetting env. episode reward total was -5.0. running mean: -4.2210328022911305\n",
      "resetting env. episode reward total was -13.0. running mean: -4.3088224742682195\n",
      "resetting env. episode reward total was -10.0. running mean: -4.365734249525537\n",
      "resetting env. episode reward total was -7.0. running mean: -4.392076907030281\n",
      "resetting env. episode reward total was 4.0. running mean: -4.308156137959979\n",
      "resetting env. episode reward total was 4.0. running mean: -4.225074576580379\n",
      "resetting env. episode reward total was 4.0. running mean: -4.142823830814575\n",
      "resetting env. episode reward total was -1.0. running mean: -4.11139559250643\n",
      "resetting env. episode reward total was 1.0. running mean: -4.060281636581365\n",
      "resetting env. episode reward total was -3.0. running mean: -4.049678820215552\n",
      "resetting env. episode reward total was 3.0. running mean: -3.9791820320133966\n",
      "resetting env. episode reward total was -7.0. running mean: -4.009390211693263\n",
      "resetting env. episode reward total was -5.0. running mean: -4.01929630957633\n",
      "resetting env. episode reward total was 6.0. running mean: -3.9191033464805662\n",
      "resetting env. episode reward total was -4.0. running mean: -3.9199123130157605\n",
      "resetting env. episode reward total was -3.0. running mean: -3.9107131898856027\n",
      "resetting env. episode reward total was -11.0. running mean: -3.9816060579867467\n",
      "resetting env. episode reward total was 7.0. running mean: -3.8717899974068795\n",
      "resetting env. episode reward total was -7.0. running mean: -3.9030720974328106\n",
      "resetting env. episode reward total was 1.0. running mean: -3.8540413764584827\n",
      "resetting env. episode reward total was 6.0. running mean: -3.7555009626938975\n",
      "resetting env. episode reward total was -7.0. running mean: -3.7879459530669584\n",
      "resetting env. episode reward total was -9.0. running mean: -3.8400664935362885\n",
      "resetting env. episode reward total was -14.0. running mean: -3.9416658286009256\n",
      "resetting env. episode reward total was -9.0. running mean: -3.992249170314916\n",
      "resetting env. episode reward total was -3.0. running mean: -3.982326678611767\n",
      "resetting env. episode reward total was -8.0. running mean: -4.022503411825649\n",
      "resetting env. episode reward total was -5.0. running mean: -4.032278377707392\n",
      "resetting env. episode reward total was -7.0. running mean: -4.0619555939303185\n",
      "resetting env. episode reward total was -14.0. running mean: -4.161336037991015\n",
      "resetting env. episode reward total was 2.0. running mean: -4.099722677611106\n",
      "resetting env. episode reward total was -6.0. running mean: -4.118725450834995\n",
      "resetting env. episode reward total was -4.0. running mean: -4.117538196326644\n",
      "resetting env. episode reward total was -7.0. running mean: -4.146362814363378\n",
      "resetting env. episode reward total was -2.0. running mean: -4.124899186219744\n",
      "resetting env. episode reward total was -15.0. running mean: -4.233650194357547\n",
      "resetting env. episode reward total was 6.0. running mean: -4.131313692413972\n",
      "resetting env. episode reward total was -8.0. running mean: -4.170000555489832\n",
      "resetting env. episode reward total was -10.0. running mean: -4.228300549934933\n",
      "resetting env. episode reward total was -17.0. running mean: -4.356017544435583\n",
      "resetting env. episode reward total was -8.0. running mean: -4.392457368991227\n",
      "resetting env. episode reward total was -2.0. running mean: -4.368532795301315\n",
      "resetting env. episode reward total was 1.0. running mean: -4.314847467348302\n",
      "resetting env. episode reward total was -13.0. running mean: -4.4016989926748185\n",
      "resetting env. episode reward total was -11.0. running mean: -4.46768200274807\n",
      "resetting env. episode reward total was -11.0. running mean: -4.53300518272059\n",
      "resetting env. episode reward total was -4.0. running mean: -4.5276751308933845\n",
      "resetting env. episode reward total was -15.0. running mean: -4.632398379584451\n",
      "resetting env. episode reward total was -3.0. running mean: -4.616074395788607\n",
      "resetting env. episode reward total was -6.0. running mean: -4.62991365183072\n",
      "resetting env. episode reward total was -16.0. running mean: -4.743614515312413\n",
      "resetting env. episode reward total was -1.0. running mean: -4.7061783701592885\n",
      "resetting env. episode reward total was -8.0. running mean: -4.739116586457696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -2.0. running mean: -4.711725420593118\n",
      "resetting env. episode reward total was -5.0. running mean: -4.714608166387187\n",
      "resetting env. episode reward total was -9.0. running mean: -4.757462084723315\n",
      "resetting env. episode reward total was -2.0. running mean: -4.729887463876081\n",
      "resetting env. episode reward total was -1.0. running mean: -4.69258858923732\n",
      "resetting env. episode reward total was -8.0. running mean: -4.7256627033449465\n",
      "resetting env. episode reward total was -9.0. running mean: -4.768406076311497\n",
      "resetting env. episode reward total was -8.0. running mean: -4.8007220155483825\n",
      "resetting env. episode reward total was 7.0. running mean: -4.682714795392898\n",
      "resetting env. episode reward total was -11.0. running mean: -4.74588764743897\n",
      "resetting env. episode reward total was -7.0. running mean: -4.76842877096458\n",
      "resetting env. episode reward total was -8.0. running mean: -4.800744483254935\n",
      "resetting env. episode reward total was -8.0. running mean: -4.832737038422385\n",
      "resetting env. episode reward total was 2.0. running mean: -4.764409668038161\n",
      "resetting env. episode reward total was -3.0. running mean: -4.74676557135778\n",
      "resetting env. episode reward total was -14.0. running mean: -4.8392979156442015\n",
      "resetting env. episode reward total was -6.0. running mean: -4.850904936487759\n",
      "resetting env. episode reward total was 7.0. running mean: -4.732395887122881\n",
      "resetting env. episode reward total was -8.0. running mean: -4.765071928251652\n",
      "resetting env. episode reward total was -6.0. running mean: -4.777421208969136\n",
      "resetting env. episode reward total was -11.0. running mean: -4.839646996879445\n",
      "resetting env. episode reward total was 3.0. running mean: -4.76125052691065\n",
      "resetting env. episode reward total was -7.0. running mean: -4.7836380216415435\n",
      "resetting env. episode reward total was -15.0. running mean: -4.885801641425128\n",
      "resetting env. episode reward total was -9.0. running mean: -4.9269436250108765\n",
      "resetting env. episode reward total was -9.0. running mean: -4.967674188760768\n",
      "resetting env. episode reward total was -1.0. running mean: -4.927997446873159\n",
      "resetting env. episode reward total was -9.0. running mean: -4.968717472404427\n",
      "resetting env. episode reward total was -8.0. running mean: -4.999030297680383\n",
      "resetting env. episode reward total was -4.0. running mean: -4.989039994703579\n",
      "resetting env. episode reward total was -17.0. running mean: -5.109149594756543\n",
      "resetting env. episode reward total was -14.0. running mean: -5.1980580988089775\n",
      "resetting env. episode reward total was -17.0. running mean: -5.316077517820887\n",
      "resetting env. episode reward total was -5.0. running mean: -5.312916742642678\n",
      "resetting env. episode reward total was -6.0. running mean: -5.319787575216251\n",
      "resetting env. episode reward total was -12.0. running mean: -5.386589699464089\n",
      "resetting env. episode reward total was -10.0. running mean: -5.4327238024694475\n",
      "resetting env. episode reward total was -7.0. running mean: -5.448396564444753\n",
      "resetting env. episode reward total was -16.0. running mean: -5.553912598800306\n",
      "resetting env. episode reward total was -2.0. running mean: -5.518373472812303\n",
      "resetting env. episode reward total was -14.0. running mean: -5.603189738084179\n",
      "resetting env. episode reward total was -7.0. running mean: -5.617157840703338\n",
      "resetting env. episode reward total was -7.0. running mean: -5.630986262296305\n",
      "resetting env. episode reward total was -2.0. running mean: -5.594676399673341\n",
      "resetting env. episode reward total was -15.0. running mean: -5.688729635676609\n",
      "resetting env. episode reward total was -6.0. running mean: -5.691842339319842\n",
      "resetting env. episode reward total was -7.0. running mean: -5.704923915926644\n",
      "resetting env. episode reward total was -15.0. running mean: -5.7978746767673774\n",
      "resetting env. episode reward total was -11.0. running mean: -5.849895929999704\n",
      "resetting env. episode reward total was -13.0. running mean: -5.921396970699707\n",
      "resetting env. episode reward total was -8.0. running mean: -5.94218300099271\n",
      "resetting env. episode reward total was -7.0. running mean: -5.952761170982783\n",
      "resetting env. episode reward total was -12.0. running mean: -6.0132335592729556\n",
      "resetting env. episode reward total was -10.0. running mean: -6.053101223680225\n",
      "resetting env. episode reward total was -11.0. running mean: -6.102570211443424\n",
      "resetting env. episode reward total was -10.0. running mean: -6.141544509328989\n",
      "resetting env. episode reward total was -8.0. running mean: -6.1601290642357\n",
      "resetting env. episode reward total was -15.0. running mean: -6.248527773593343\n",
      "resetting env. episode reward total was -12.0. running mean: -6.30604249585741\n",
      "resetting env. episode reward total was -11.0. running mean: -6.352982070898836\n",
      "resetting env. episode reward total was 7.0. running mean: -6.219452250189847\n",
      "resetting env. episode reward total was -8.0. running mean: -6.237257727687949\n",
      "resetting env. episode reward total was -12.0. running mean: -6.294885150411069\n",
      "resetting env. episode reward total was -3.0. running mean: -6.261936298906959\n",
      "resetting env. episode reward total was -9.0. running mean: -6.289316935917889\n",
      "resetting env. episode reward total was -17.0. running mean: -6.39642376655871\n",
      "resetting env. episode reward total was -19.0. running mean: -6.5224595288931235\n",
      "resetting env. episode reward total was -8.0. running mean: -6.537234933604192\n",
      "resetting env. episode reward total was -15.0. running mean: -6.62186258426815\n",
      "resetting env. episode reward total was -9.0. running mean: -6.6456439584254685\n",
      "resetting env. episode reward total was -6.0. running mean: -6.639187518841213\n",
      "resetting env. episode reward total was -13.0. running mean: -6.702795643652801\n",
      "resetting env. episode reward total was -5.0. running mean: -6.6857676872162735\n",
      "resetting env. episode reward total was -1.0. running mean: -6.628910010344111\n",
      "resetting env. episode reward total was -5.0. running mean: -6.612620910240669\n",
      "resetting env. episode reward total was 2.0. running mean: -6.526494701138263\n",
      "resetting env. episode reward total was -7.0. running mean: -6.53122975412688\n",
      "resetting env. episode reward total was 1.0. running mean: -6.4559174565856114\n",
      "resetting env. episode reward total was -12.0. running mean: -6.5113582820197555\n",
      "resetting env. episode reward total was -6.0. running mean: -6.5062446991995575\n",
      "resetting env. episode reward total was -10.0. running mean: -6.5411822522075616\n",
      "resetting env. episode reward total was 1.0. running mean: -6.465770429685486\n",
      "resetting env. episode reward total was -10.0. running mean: -6.501112725388631\n",
      "resetting env. episode reward total was -1.0. running mean: -6.446101598134744\n",
      "resetting env. episode reward total was -5.0. running mean: -6.431640582153396\n",
      "resetting env. episode reward total was 3.0. running mean: -6.337324176331862\n",
      "resetting env. episode reward total was -6.0. running mean: -6.333950934568542\n",
      "resetting env. episode reward total was -6.0. running mean: -6.330611425222856\n",
      "resetting env. episode reward total was -2.0. running mean: -6.287305310970627\n",
      "resetting env. episode reward total was -16.0. running mean: -6.3844322578609205\n",
      "resetting env. episode reward total was -11.0. running mean: -6.430587935282311\n",
      "resetting env. episode reward total was -7.0. running mean: -6.436282055929488\n",
      "resetting env. episode reward total was 2.0. running mean: -6.351919235370193\n",
      "resetting env. episode reward total was -13.0. running mean: -6.418400043016491\n",
      "resetting env. episode reward total was -1.0. running mean: -6.3642160425863255\n",
      "resetting env. episode reward total was 8.0. running mean: -6.220573882160462\n",
      "resetting env. episode reward total was -14.0. running mean: -6.298368143338857\n",
      "resetting env. episode reward total was 1.0. running mean: -6.225384461905469\n",
      "resetting env. episode reward total was -7.0. running mean: -6.233130617286414\n",
      "resetting env. episode reward total was -8.0. running mean: -6.25079931111355\n",
      "resetting env. episode reward total was -1.0. running mean: -6.198291318002414\n",
      "resetting env. episode reward total was -7.0. running mean: -6.20630840482239\n",
      "resetting env. episode reward total was -8.0. running mean: -6.224245320774166\n",
      "resetting env. episode reward total was -14.0. running mean: -6.302002867566424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -10.0. running mean: -6.338982838890759\n",
      "resetting env. episode reward total was -16.0. running mean: -6.435593010501852\n",
      "resetting env. episode reward total was -12.0. running mean: -6.491237080396833\n",
      "resetting env. episode reward total was -1.0. running mean: -6.436324709592864\n",
      "resetting env. episode reward total was -5.0. running mean: -6.4219614624969354\n",
      "resetting env. episode reward total was -3.0. running mean: -6.3877418478719665\n",
      "resetting env. episode reward total was -10.0. running mean: -6.423864429393246\n",
      "resetting env. episode reward total was -11.0. running mean: -6.469625785099314\n",
      "resetting env. episode reward total was -10.0. running mean: -6.50492952724832\n",
      "resetting env. episode reward total was 1.0. running mean: -6.4298802319758375\n",
      "resetting env. episode reward total was -2.0. running mean: -6.385581429656079\n",
      "resetting env. episode reward total was -6.0. running mean: -6.381725615359517\n",
      "resetting env. episode reward total was -1.0. running mean: -6.327908359205922\n",
      "resetting env. episode reward total was -8.0. running mean: -6.344629275613863\n",
      "resetting env. episode reward total was -8.0. running mean: -6.361182982857724\n",
      "resetting env. episode reward total was -3.0. running mean: -6.327571153029147\n",
      "resetting env. episode reward total was -9.0. running mean: -6.354295441498856\n",
      "resetting env. episode reward total was -4.0. running mean: -6.330752487083867\n",
      "resetting env. episode reward total was -1.0. running mean: -6.277444962213028\n",
      "resetting env. episode reward total was -12.0. running mean: -6.334670512590898\n",
      "resetting env. episode reward total was 6.0. running mean: -6.211323807464989\n",
      "resetting env. episode reward total was 1.0. running mean: -6.13921056939034\n",
      "resetting env. episode reward total was -3.0. running mean: -6.107818463696437\n",
      "resetting env. episode reward total was 1.0. running mean: -6.036740279059472\n",
      "resetting env. episode reward total was -9.0. running mean: -6.066372876268877\n",
      "resetting env. episode reward total was -3.0. running mean: -6.035709147506188\n",
      "resetting env. episode reward total was -1.0. running mean: -5.985352056031126\n",
      "resetting env. episode reward total was -1.0. running mean: -5.935498535470814\n",
      "resetting env. episode reward total was -5.0. running mean: -5.926143550116106\n",
      "resetting env. episode reward total was -15.0. running mean: -6.016882114614946\n",
      "resetting env. episode reward total was -3.0. running mean: -5.986713293468797\n",
      "resetting env. episode reward total was -7.0. running mean: -5.996846160534109\n",
      "resetting env. episode reward total was -12.0. running mean: -6.056877698928768\n",
      "resetting env. episode reward total was 4.0. running mean: -5.95630892193948\n",
      "resetting env. episode reward total was -4.0. running mean: -5.936745832720085\n",
      "resetting env. episode reward total was -15.0. running mean: -6.027378374392884\n",
      "resetting env. episode reward total was -6.0. running mean: -6.027104590648955\n",
      "resetting env. episode reward total was -7.0. running mean: -6.036833544742466\n",
      "resetting env. episode reward total was 3.0. running mean: -5.946465209295041\n",
      "resetting env. episode reward total was -2.0. running mean: -5.90700055720209\n",
      "resetting env. episode reward total was 1.0. running mean: -5.837930551630069\n",
      "resetting env. episode reward total was -3.0. running mean: -5.809551246113768\n",
      "resetting env. episode reward total was -10.0. running mean: -5.851455733652631\n",
      "resetting env. episode reward total was -6.0. running mean: -5.852941176316104\n",
      "resetting env. episode reward total was 9.0. running mean: -5.704411764552943\n",
      "resetting env. episode reward total was -2.0. running mean: -5.6673676469074135\n",
      "resetting env. episode reward total was -9.0. running mean: -5.700693970438339\n",
      "resetting env. episode reward total was 10.0. running mean: -5.543687030733956\n",
      "resetting env. episode reward total was -8.0. running mean: -5.568250160426617\n",
      "resetting env. episode reward total was -4.0. running mean: -5.55256765882235\n",
      "resetting env. episode reward total was -9.0. running mean: -5.587041982234126\n",
      "resetting env. episode reward total was -1.0. running mean: -5.541171562411785\n",
      "resetting env. episode reward total was 6.0. running mean: -5.425759846787668\n",
      "resetting env. episode reward total was -6.0. running mean: -5.431502248319791\n",
      "resetting env. episode reward total was 5.0. running mean: -5.327187225836592\n",
      "resetting env. episode reward total was 4.0. running mean: -5.233915353578227\n",
      "resetting env. episode reward total was -1.0. running mean: -5.191576200042444\n",
      "resetting env. episode reward total was -2.0. running mean: -5.159660438042019\n",
      "resetting env. episode reward total was -6.0. running mean: -5.1680638336615985\n",
      "resetting env. episode reward total was -11.0. running mean: -5.226383195324983\n",
      "resetting env. episode reward total was -4.0. running mean: -5.214119363371733\n",
      "resetting env. episode reward total was -5.0. running mean: -5.211978169738015\n",
      "resetting env. episode reward total was -13.0. running mean: -5.289858388040635\n",
      "resetting env. episode reward total was -9.0. running mean: -5.326959804160229\n",
      "resetting env. episode reward total was -17.0. running mean: -5.443690206118626\n",
      "resetting env. episode reward total was -4.0. running mean: -5.42925330405744\n",
      "resetting env. episode reward total was -9.0. running mean: -5.464960771016865\n",
      "resetting env. episode reward total was 3.0. running mean: -5.380311163306696\n",
      "resetting env. episode reward total was 4.0. running mean: -5.286508051673629\n",
      "resetting env. episode reward total was -10.0. running mean: -5.333642971156893\n",
      "resetting env. episode reward total was -10.0. running mean: -5.380306541445323\n",
      "resetting env. episode reward total was 3.0. running mean: -5.296503476030869\n",
      "resetting env. episode reward total was 7.0. running mean: -5.17353844127056\n",
      "resetting env. episode reward total was -3.0. running mean: -5.151803056857855\n",
      "resetting env. episode reward total was -9.0. running mean: -5.190285026289276\n",
      "resetting env. episode reward total was 5.0. running mean: -5.088382176026383\n",
      "resetting env. episode reward total was -5.0. running mean: -5.087498354266119\n",
      "resetting env. episode reward total was -9.0. running mean: -5.126623370723458\n",
      "resetting env. episode reward total was -4.0. running mean: -5.115357137016223\n",
      "resetting env. episode reward total was -10.0. running mean: -5.16420356564606\n",
      "resetting env. episode reward total was -9.0. running mean: -5.202561529989599\n",
      "resetting env. episode reward total was 2.0. running mean: -5.130535914689704\n",
      "resetting env. episode reward total was -9.0. running mean: -5.169230555542806\n",
      "resetting env. episode reward total was -6.0. running mean: -5.177538249987378\n",
      "resetting env. episode reward total was -9.0. running mean: -5.215762867487504\n",
      "resetting env. episode reward total was -7.0. running mean: -5.233605238812629\n",
      "resetting env. episode reward total was -8.0. running mean: -5.261269186424503\n",
      "resetting env. episode reward total was -11.0. running mean: -5.318656494560258\n",
      "resetting env. episode reward total was -7.0. running mean: -5.335469929614656\n",
      "resetting env. episode reward total was -9.0. running mean: -5.372115230318509\n",
      "resetting env. episode reward total was -7.0. running mean: -5.388394078015324\n",
      "resetting env. episode reward total was -12.0. running mean: -5.454510137235171\n",
      "resetting env. episode reward total was -14.0. running mean: -5.539965035862819\n",
      "resetting env. episode reward total was -7.0. running mean: -5.554565385504191\n",
      "resetting env. episode reward total was 1.0. running mean: -5.48901973164915\n",
      "resetting env. episode reward total was -5.0. running mean: -5.484129534332658\n",
      "resetting env. episode reward total was -8.0. running mean: -5.509288238989332\n",
      "resetting env. episode reward total was -13.0. running mean: -5.584195356599438\n",
      "resetting env. episode reward total was -5.0. running mean: -5.578353403033444\n",
      "resetting env. episode reward total was -17.0. running mean: -5.692569869003109\n",
      "resetting env. episode reward total was -7.0. running mean: -5.705644170313079\n",
      "resetting env. episode reward total was -8.0. running mean: -5.728587728609948\n",
      "resetting env. episode reward total was -10.0. running mean: -5.771301851323848\n",
      "resetting env. episode reward total was 6.0. running mean: -5.65358883281061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -5.667052944482504\n",
      "resetting env. episode reward total was -6.0. running mean: -5.670382415037678\n",
      "resetting env. episode reward total was 4.0. running mean: -5.573678590887301\n",
      "resetting env. episode reward total was 3.0. running mean: -5.487941804978428\n",
      "resetting env. episode reward total was -7.0. running mean: -5.503062386928644\n",
      "resetting env. episode reward total was -1.0. running mean: -5.458031763059357\n",
      "resetting env. episode reward total was 1.0. running mean: -5.393451445428764\n",
      "resetting env. episode reward total was 2.0. running mean: -5.319516930974476\n",
      "resetting env. episode reward total was -5.0. running mean: -5.316321761664732\n",
      "resetting env. episode reward total was -11.0. running mean: -5.373158544048085\n",
      "resetting env. episode reward total was -4.0. running mean: -5.359426958607604\n",
      "resetting env. episode reward total was -8.0. running mean: -5.385832689021528\n",
      "resetting env. episode reward total was -11.0. running mean: -5.441974362131313\n",
      "resetting env. episode reward total was -4.0. running mean: -5.427554618509999\n",
      "resetting env. episode reward total was 2.0. running mean: -5.3532790723248995\n",
      "resetting env. episode reward total was -10.0. running mean: -5.39974628160165\n",
      "resetting env. episode reward total was 2.0. running mean: -5.325748818785634\n",
      "resetting env. episode reward total was -11.0. running mean: -5.3824913305977775\n",
      "resetting env. episode reward total was -3.0. running mean: -5.3586664172918\n",
      "resetting env. episode reward total was -5.0. running mean: -5.355079753118882\n",
      "resetting env. episode reward total was 6.0. running mean: -5.241528955587693\n",
      "resetting env. episode reward total was -6.0. running mean: -5.249113666031816\n",
      "resetting env. episode reward total was -4.0. running mean: -5.236622529371497\n",
      "resetting env. episode reward total was 6.0. running mean: -5.124256304077782\n",
      "resetting env. episode reward total was -1.0. running mean: -5.083013741037004\n",
      "resetting env. episode reward total was -6.0. running mean: -5.092183603626634\n",
      "resetting env. episode reward total was 2.0. running mean: -5.021261767590368\n",
      "resetting env. episode reward total was -7.0. running mean: -5.041049149914465\n",
      "resetting env. episode reward total was -7.0. running mean: -5.0606386584153205\n",
      "resetting env. episode reward total was -6.0. running mean: -5.070032271831167\n",
      "resetting env. episode reward total was -1.0. running mean: -5.029331949112855\n",
      "resetting env. episode reward total was -1.0. running mean: -4.989038629621726\n",
      "resetting env. episode reward total was -5.0. running mean: -4.989148243325508\n",
      "resetting env. episode reward total was -6.0. running mean: -4.999256760892253\n",
      "resetting env. episode reward total was 2.0. running mean: -4.9292641932833305\n",
      "resetting env. episode reward total was -10.0. running mean: -4.979971551350497\n",
      "resetting env. episode reward total was 7.0. running mean: -4.860171835836992\n",
      "resetting env. episode reward total was -3.0. running mean: -4.841570117478622\n",
      "resetting env. episode reward total was -3.0. running mean: -4.8231544163038365\n",
      "resetting env. episode reward total was -13.0. running mean: -4.904922872140798\n",
      "resetting env. episode reward total was 5.0. running mean: -4.80587364341939\n",
      "resetting env. episode reward total was 6.0. running mean: -4.697814906985196\n",
      "resetting env. episode reward total was -6.0. running mean: -4.710836757915344\n",
      "resetting env. episode reward total was -9.0. running mean: -4.753728390336191\n",
      "resetting env. episode reward total was -4.0. running mean: -4.746191106432828\n",
      "resetting env. episode reward total was -5.0. running mean: -4.7487291953685\n",
      "resetting env. episode reward total was 1.0. running mean: -4.691241903414816\n",
      "resetting env. episode reward total was -3.0. running mean: -4.674329484380667\n",
      "resetting env. episode reward total was -9.0. running mean: -4.717586189536861\n",
      "resetting env. episode reward total was -7.0. running mean: -4.740410327641492\n",
      "resetting env. episode reward total was -6.0. running mean: -4.753006224365077\n",
      "resetting env. episode reward total was -9.0. running mean: -4.7954761621214255\n",
      "resetting env. episode reward total was -6.0. running mean: -4.807521400500211\n",
      "resetting env. episode reward total was -2.0. running mean: -4.779446186495209\n",
      "resetting env. episode reward total was -9.0. running mean: -4.821651724630256\n",
      "resetting env. episode reward total was -6.0. running mean: -4.833435207383953\n",
      "resetting env. episode reward total was -11.0. running mean: -4.895100855310114\n",
      "resetting env. episode reward total was 9.0. running mean: -4.756149846757013\n",
      "resetting env. episode reward total was -9.0. running mean: -4.798588348289442\n",
      "resetting env. episode reward total was -11.0. running mean: -4.860602464806548\n",
      "resetting env. episode reward total was -11.0. running mean: -4.921996440158483\n",
      "resetting env. episode reward total was -7.0. running mean: -4.942776475756898\n",
      "resetting env. episode reward total was -11.0. running mean: -5.0033487109993295\n",
      "resetting env. episode reward total was 6.0. running mean: -4.893315223889337\n",
      "resetting env. episode reward total was -13.0. running mean: -4.974382071650443\n",
      "resetting env. episode reward total was -14.0. running mean: -5.064638250933938\n",
      "resetting env. episode reward total was -13.0. running mean: -5.143991868424599\n",
      "resetting env. episode reward total was -9.0. running mean: -5.182551949740352\n",
      "resetting env. episode reward total was -9.0. running mean: -5.220726430242949\n",
      "resetting env. episode reward total was -9.0. running mean: -5.258519165940519\n",
      "resetting env. episode reward total was -7.0. running mean: -5.275933974281114\n",
      "resetting env. episode reward total was -3.0. running mean: -5.253174634538303\n",
      "resetting env. episode reward total was -19.0. running mean: -5.390642888192921\n",
      "resetting env. episode reward total was -15.0. running mean: -5.4867364593109915\n",
      "resetting env. episode reward total was -10.0. running mean: -5.531869094717881\n",
      "resetting env. episode reward total was -11.0. running mean: -5.586550403770702\n",
      "resetting env. episode reward total was -14.0. running mean: -5.670684899732994\n",
      "resetting env. episode reward total was -4.0. running mean: -5.653978050735664\n",
      "resetting env. episode reward total was -14.0. running mean: -5.737438270228307\n",
      "resetting env. episode reward total was -5.0. running mean: -5.730063887526024\n",
      "resetting env. episode reward total was -4.0. running mean: -5.712763248650764\n",
      "resetting env. episode reward total was -9.0. running mean: -5.745635616164256\n",
      "resetting env. episode reward total was -9.0. running mean: -5.778179260002613\n",
      "resetting env. episode reward total was -6.0. running mean: -5.780397467402587\n",
      "resetting env. episode reward total was -8.0. running mean: -5.802593492728561\n",
      "resetting env. episode reward total was -10.0. running mean: -5.844567557801275\n",
      "resetting env. episode reward total was -1.0. running mean: -5.796121882223262\n",
      "resetting env. episode reward total was -9.0. running mean: -5.828160663401029\n",
      "resetting env. episode reward total was -7.0. running mean: -5.8398790567670185\n",
      "resetting env. episode reward total was -10.0. running mean: -5.881480266199348\n",
      "resetting env. episode reward total was -8.0. running mean: -5.902665463537354\n",
      "resetting env. episode reward total was -11.0. running mean: -5.953638808901981\n",
      "resetting env. episode reward total was -11.0. running mean: -6.004102420812961\n",
      "resetting env. episode reward total was -8.0. running mean: -6.024061396604831\n",
      "resetting env. episode reward total was -5.0. running mean: -6.013820782638783\n",
      "resetting env. episode reward total was -1.0. running mean: -5.963682574812395\n",
      "resetting env. episode reward total was -8.0. running mean: -5.984045749064271\n",
      "resetting env. episode reward total was -6.0. running mean: -5.984205291573628\n",
      "resetting env. episode reward total was -11.0. running mean: -6.034363238657892\n",
      "resetting env. episode reward total was -2.0. running mean: -5.994019606271312\n",
      "resetting env. episode reward total was -12.0. running mean: -6.054079410208599\n",
      "resetting env. episode reward total was -6.0. running mean: -6.053538616106513\n",
      "resetting env. episode reward total was -12.0. running mean: -6.1130032299454475\n",
      "resetting env. episode reward total was -11.0. running mean: -6.161873197645994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -14.0. running mean: -6.240254465669533\n",
      "resetting env. episode reward total was -9.0. running mean: -6.267851921012838\n",
      "resetting env. episode reward total was -2.0. running mean: -6.225173401802709\n",
      "resetting env. episode reward total was -7.0. running mean: -6.232921667784682\n",
      "resetting env. episode reward total was -9.0. running mean: -6.2605924511068345\n",
      "resetting env. episode reward total was -14.0. running mean: -6.337986526595766\n",
      "resetting env. episode reward total was -8.0. running mean: -6.354606661329808\n",
      "resetting env. episode reward total was -5.0. running mean: -6.3410605947165095\n",
      "resetting env. episode reward total was 1.0. running mean: -6.267649988769344\n",
      "resetting env. episode reward total was -7.0. running mean: -6.274973488881651\n",
      "resetting env. episode reward total was -10.0. running mean: -6.312223753992834\n",
      "resetting env. episode reward total was -7.0. running mean: -6.319101516452906\n",
      "resetting env. episode reward total was -3.0. running mean: -6.285910501288377\n",
      "resetting env. episode reward total was -16.0. running mean: -6.383051396275493\n",
      "resetting env. episode reward total was -6.0. running mean: -6.379220882312738\n",
      "resetting env. episode reward total was -7.0. running mean: -6.385428673489611\n",
      "resetting env. episode reward total was -11.0. running mean: -6.431574386754715\n",
      "resetting env. episode reward total was -5.0. running mean: -6.417258642887168\n",
      "resetting env. episode reward total was -11.0. running mean: -6.463086056458296\n",
      "resetting env. episode reward total was -9.0. running mean: -6.488455195893713\n",
      "resetting env. episode reward total was -8.0. running mean: -6.503570643934776\n",
      "resetting env. episode reward total was -2.0. running mean: -6.458534937495427\n",
      "resetting env. episode reward total was -10.0. running mean: -6.493949588120473\n",
      "resetting env. episode reward total was -2.0. running mean: -6.449010092239268\n",
      "resetting env. episode reward total was -8.0. running mean: -6.464519991316876\n",
      "resetting env. episode reward total was 2.0. running mean: -6.379874791403707\n",
      "resetting env. episode reward total was -19.0. running mean: -6.506076043489671\n",
      "resetting env. episode reward total was -14.0. running mean: -6.581015283054773\n",
      "resetting env. episode reward total was -6.0. running mean: -6.575205130224225\n",
      "resetting env. episode reward total was -1.0. running mean: -6.519453078921982\n",
      "resetting env. episode reward total was 1.0. running mean: -6.444258548132763\n",
      "resetting env. episode reward total was -2.0. running mean: -6.399815962651434\n",
      "resetting env. episode reward total was -4.0. running mean: -6.37581780302492\n",
      "resetting env. episode reward total was 3.0. running mean: -6.2820596249946705\n",
      "resetting env. episode reward total was -3.0. running mean: -6.249239028744724\n",
      "resetting env. episode reward total was -9.0. running mean: -6.2767466384572765\n",
      "resetting env. episode reward total was -11.0. running mean: -6.323979172072704\n",
      "resetting env. episode reward total was -7.0. running mean: -6.330739380351977\n",
      "resetting env. episode reward total was -11.0. running mean: -6.377431986548458\n",
      "resetting env. episode reward total was -13.0. running mean: -6.443657666682973\n",
      "resetting env. episode reward total was -4.0. running mean: -6.419221090016143\n",
      "resetting env. episode reward total was -2.0. running mean: -6.375028879115981\n",
      "resetting env. episode reward total was -5.0. running mean: -6.3612785903248215\n",
      "resetting env. episode reward total was 1.0. running mean: -6.287665804421573\n",
      "resetting env. episode reward total was -10.0. running mean: -6.324789146377357\n",
      "resetting env. episode reward total was -10.0. running mean: -6.3615412549135835\n",
      "resetting env. episode reward total was 1.0. running mean: -6.287925842364448\n",
      "resetting env. episode reward total was -3.0. running mean: -6.255046583940803\n",
      "resetting env. episode reward total was -6.0. running mean: -6.252496118101395\n",
      "resetting env. episode reward total was 2.0. running mean: -6.169971156920382\n",
      "resetting env. episode reward total was 6.0. running mean: -6.048271445351179\n",
      "resetting env. episode reward total was -2.0. running mean: -6.0077887308976665\n",
      "resetting env. episode reward total was -3.0. running mean: -5.97771084358869\n",
      "resetting env. episode reward total was -9.0. running mean: -6.007933735152802\n",
      "resetting env. episode reward total was -9.0. running mean: -6.037854397801274\n",
      "resetting env. episode reward total was -2.0. running mean: -5.997475853823261\n",
      "resetting env. episode reward total was -5.0. running mean: -5.987501095285028\n",
      "resetting env. episode reward total was -1.0. running mean: -5.9376260843321775\n",
      "resetting env. episode reward total was -5.0. running mean: -5.928249823488856\n",
      "resetting env. episode reward total was -1.0. running mean: -5.878967325253967\n",
      "resetting env. episode reward total was 6.0. running mean: -5.760177652001428\n",
      "resetting env. episode reward total was -8.0. running mean: -5.782575875481413\n",
      "resetting env. episode reward total was -12.0. running mean: -5.844750116726599\n",
      "resetting env. episode reward total was -11.0. running mean: -5.896302615559334\n",
      "resetting env. episode reward total was 2.0. running mean: -5.8173395894037405\n",
      "resetting env. episode reward total was 11.0. running mean: -5.649166193509703\n",
      "resetting env. episode reward total was -8.0. running mean: -5.672674531574605\n",
      "resetting env. episode reward total was -7.0. running mean: -5.685947786258859\n",
      "resetting env. episode reward total was 7.0. running mean: -5.55908830839627\n",
      "resetting env. episode reward total was -4.0. running mean: -5.5434974253123075\n",
      "resetting env. episode reward total was 4.0. running mean: -5.448062451059184\n",
      "resetting env. episode reward total was 2.0. running mean: -5.373581826548593\n",
      "resetting env. episode reward total was -7.0. running mean: -5.389846008283107\n",
      "resetting env. episode reward total was -7.0. running mean: -5.405947548200277\n",
      "resetting env. episode reward total was -12.0. running mean: -5.471888072718274\n",
      "resetting env. episode reward total was -7.0. running mean: -5.487169191991091\n",
      "resetting env. episode reward total was -5.0. running mean: -5.48229750007118\n",
      "resetting env. episode reward total was -5.0. running mean: -5.477474525070468\n",
      "resetting env. episode reward total was 5.0. running mean: -5.372699779819763\n",
      "resetting env. episode reward total was -3.0. running mean: -5.348972782021566\n",
      "resetting env. episode reward total was -9.0. running mean: -5.38548305420135\n",
      "resetting env. episode reward total was -1.0. running mean: -5.341628223659336\n",
      "resetting env. episode reward total was 5.0. running mean: -5.238211941422743\n",
      "resetting env. episode reward total was -7.0. running mean: -5.255829822008516\n",
      "resetting env. episode reward total was -5.0. running mean: -5.25327152378843\n",
      "resetting env. episode reward total was -7.0. running mean: -5.270738808550546\n",
      "resetting env. episode reward total was -8.0. running mean: -5.2980314204650405\n",
      "resetting env. episode reward total was 4.0. running mean: -5.20505110626039\n",
      "resetting env. episode reward total was -4.0. running mean: -5.193000595197786\n",
      "resetting env. episode reward total was 2.0. running mean: -5.121070589245808\n",
      "resetting env. episode reward total was -8.0. running mean: -5.14985988335335\n",
      "resetting env. episode reward total was -4.0. running mean: -5.138361284519816\n",
      "resetting env. episode reward total was -12.0. running mean: -5.206977671674618\n",
      "resetting env. episode reward total was -6.0. running mean: -5.2149078949578715\n",
      "resetting env. episode reward total was 9.0. running mean: -5.072758816008293\n",
      "resetting env. episode reward total was -12.0. running mean: -5.142031227848211\n",
      "resetting env. episode reward total was 4.0. running mean: -5.050610915569728\n",
      "resetting env. episode reward total was 2.0. running mean: -4.980104806414031\n",
      "resetting env. episode reward total was 2.0. running mean: -4.910303758349891\n",
      "resetting env. episode reward total was -5.0. running mean: -4.911200720766392\n",
      "resetting env. episode reward total was -3.0. running mean: -4.892088713558729\n",
      "resetting env. episode reward total was -4.0. running mean: -4.883167826423142\n",
      "resetting env. episode reward total was 12.0. running mean: -4.71433614815891\n",
      "resetting env. episode reward total was -3.0. running mean: -4.697192786677322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: -4.530220858810549\n",
      "resetting env. episode reward total was -8.0. running mean: -4.5649186502224435\n",
      "resetting env. episode reward total was -12.0. running mean: -4.639269463720219\n",
      "resetting env. episode reward total was -9.0. running mean: -4.682876769083017\n",
      "resetting env. episode reward total was 5.0. running mean: -4.586048001392187\n",
      "resetting env. episode reward total was -2.0. running mean: -4.560187521378264\n",
      "resetting env. episode reward total was -6.0. running mean: -4.574585646164481\n",
      "resetting env. episode reward total was -7.0. running mean: -4.598839789702836\n",
      "resetting env. episode reward total was -1.0. running mean: -4.562851391805808\n",
      "resetting env. episode reward total was 3.0. running mean: -4.487222877887749\n",
      "resetting env. episode reward total was 9.0. running mean: -4.352350649108872\n",
      "resetting env. episode reward total was -7.0. running mean: -4.378827142617784\n",
      "resetting env. episode reward total was -3.0. running mean: -4.365038871191606\n",
      "resetting env. episode reward total was 6.0. running mean: -4.26138848247969\n",
      "resetting env. episode reward total was -8.0. running mean: -4.2987745976548934\n",
      "resetting env. episode reward total was -1.0. running mean: -4.265786851678344\n",
      "resetting env. episode reward total was 3.0. running mean: -4.193128983161561\n",
      "resetting env. episode reward total was -7.0. running mean: -4.2211976933299455\n",
      "resetting env. episode reward total was -8.0. running mean: -4.258985716396646\n",
      "resetting env. episode reward total was -6.0. running mean: -4.276395859232679\n",
      "resetting env. episode reward total was -6.0. running mean: -4.293631900640351\n",
      "resetting env. episode reward total was -9.0. running mean: -4.340695581633947\n",
      "resetting env. episode reward total was -2.0. running mean: -4.317288625817607\n",
      "resetting env. episode reward total was -8.0. running mean: -4.354115739559431\n",
      "resetting env. episode reward total was -5.0. running mean: -4.360574582163836\n",
      "resetting env. episode reward total was -5.0. running mean: -4.366968836342197\n",
      "resetting env. episode reward total was 10.0. running mean: -4.223299147978776\n",
      "resetting env. episode reward total was 7.0. running mean: -4.111066156498988\n",
      "resetting env. episode reward total was -5.0. running mean: -4.119955494933998\n",
      "resetting env. episode reward total was 5.0. running mean: -4.028755939984658\n",
      "resetting env. episode reward total was -5.0. running mean: -4.038468380584812\n",
      "resetting env. episode reward total was -14.0. running mean: -4.138083696778963\n",
      "resetting env. episode reward total was 5.0. running mean: -4.046702859811174\n",
      "resetting env. episode reward total was 4.0. running mean: -3.966235831213062\n",
      "resetting env. episode reward total was -5.0. running mean: -3.9765734729009314\n",
      "resetting env. episode reward total was -1.0. running mean: -3.946807738171922\n",
      "resetting env. episode reward total was 6.0. running mean: -3.847339660790203\n",
      "resetting env. episode reward total was -5.0. running mean: -3.8588662641823004\n",
      "resetting env. episode reward total was 3.0. running mean: -3.7902776015404775\n",
      "resetting env. episode reward total was -13.0. running mean: -3.8823748255250727\n",
      "resetting env. episode reward total was 8.0. running mean: -3.7635510772698217\n",
      "resetting env. episode reward total was -4.0. running mean: -3.7659155664971236\n",
      "resetting env. episode reward total was -11.0. running mean: -3.838256410832152\n",
      "resetting env. episode reward total was 7.0. running mean: -3.7298738467238306\n",
      "resetting env. episode reward total was 4.0. running mean: -3.6525751082565923\n",
      "resetting env. episode reward total was 4.0. running mean: -3.576049357174026\n",
      "resetting env. episode reward total was -7.0. running mean: -3.610288863602286\n",
      "resetting env. episode reward total was -9.0. running mean: -3.6641859749662626\n",
      "resetting env. episode reward total was 3.0. running mean: -3.5975441152166003\n",
      "resetting env. episode reward total was -14.0. running mean: -3.7015686740644345\n",
      "resetting env. episode reward total was -14.0. running mean: -3.80455298732379\n",
      "resetting env. episode reward total was 3.0. running mean: -3.736507457450552\n",
      "resetting env. episode reward total was 8.0. running mean: -3.6191423828760465\n",
      "resetting env. episode reward total was -2.0. running mean: -3.602950959047286\n",
      "resetting env. episode reward total was -7.0. running mean: -3.6369214494568127\n",
      "resetting env. episode reward total was -6.0. running mean: -3.660552234962245\n",
      "resetting env. episode reward total was -6.0. running mean: -3.6839467126126224\n",
      "resetting env. episode reward total was 8.0. running mean: -3.567107245486496\n",
      "resetting env. episode reward total was -2.0. running mean: -3.551436173031631\n",
      "resetting env. episode reward total was -13.0. running mean: -3.6459218113013145\n",
      "resetting env. episode reward total was -5.0. running mean: -3.659462593188301\n",
      "resetting env. episode reward total was -3.0. running mean: -3.6528679672564177\n",
      "resetting env. episode reward total was 2.0. running mean: -3.5963392875838536\n",
      "resetting env. episode reward total was -1.0. running mean: -3.5703758947080146\n",
      "resetting env. episode reward total was -13.0. running mean: -3.6646721357609344\n",
      "resetting env. episode reward total was 3.0. running mean: -3.5980254144033252\n",
      "resetting env. episode reward total was -5.0. running mean: -3.612045160259292\n",
      "resetting env. episode reward total was 8.0. running mean: -3.4959247086566987\n",
      "resetting env. episode reward total was -3.0. running mean: -3.4909654615701315\n",
      "resetting env. episode reward total was -1.0. running mean: -3.46605580695443\n",
      "resetting env. episode reward total was -4.0. running mean: -3.4713952488848854\n",
      "resetting env. episode reward total was 4.0. running mean: -3.3966812963960367\n",
      "resetting env. episode reward total was -5.0. running mean: -3.412714483432076\n",
      "resetting env. episode reward total was 3.0. running mean: -3.3485873385977554\n",
      "resetting env. episode reward total was 7.0. running mean: -3.245101465211778\n",
      "resetting env. episode reward total was -13.0. running mean: -3.34265045055966\n",
      "resetting env. episode reward total was 1.0. running mean: -3.2992239460540635\n",
      "resetting env. episode reward total was -5.0. running mean: -3.3162317065935225\n",
      "resetting env. episode reward total was -9.0. running mean: -3.373069389527587\n",
      "resetting env. episode reward total was 2.0. running mean: -3.3193386956323114\n",
      "resetting env. episode reward total was 12.0. running mean: -3.166145308675988\n",
      "resetting env. episode reward total was -5.0. running mean: -3.184483855589228\n",
      "resetting env. episode reward total was -12.0. running mean: -3.272639017033336\n",
      "resetting env. episode reward total was -10.0. running mean: -3.339912626863003\n",
      "resetting env. episode reward total was -9.0. running mean: -3.3965135005943727\n",
      "resetting env. episode reward total was -2.0. running mean: -3.382548365588429\n",
      "resetting env. episode reward total was 2.0. running mean: -3.3287228819325447\n",
      "resetting env. episode reward total was 4.0. running mean: -3.2554356531132194\n",
      "resetting env. episode reward total was 2.0. running mean: -3.202881296582087\n",
      "resetting env. episode reward total was -9.0. running mean: -3.260852483616266\n",
      "resetting env. episode reward total was 1.0. running mean: -3.2182439587801035\n",
      "resetting env. episode reward total was -6.0. running mean: -3.2460615191923026\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2836009040003793\n",
      "resetting env. episode reward total was -5.0. running mean: -3.300764894960375\n",
      "resetting env. episode reward total was 2.0. running mean: -3.2477572460107713\n",
      "resetting env. episode reward total was 3.0. running mean: -3.1852796735506637\n",
      "resetting env. episode reward total was 6.0. running mean: -3.093426876815157\n",
      "resetting env. episode reward total was 1.0. running mean: -3.0524926080470056\n",
      "resetting env. episode reward total was -15.0. running mean: -3.1719676819665352\n",
      "resetting env. episode reward total was 1.0. running mean: -3.13024800514687\n",
      "resetting env. episode reward total was -7.0. running mean: -3.1689455250954013\n",
      "resetting env. episode reward total was -6.0. running mean: -3.1972560698444474\n",
      "resetting env. episode reward total was -2.0. running mean: -3.185283509146003\n",
      "resetting env. episode reward total was -1.0. running mean: -3.1634306740545424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: -3.171796367313997\n",
      "resetting env. episode reward total was -1.0. running mean: -3.150078403640857\n",
      "resetting env. episode reward total was 10.0. running mean: -3.0185776196044483\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0383918434084034\n",
      "resetting env. episode reward total was -2.0. running mean: -3.0280079249743195\n",
      "resetting env. episode reward total was -1.0. running mean: -3.007727845724576\n",
      "resetting env. episode reward total was 4.0. running mean: -2.9376505672673305\n",
      "resetting env. episode reward total was -15.0. running mean: -3.0582740615946573\n",
      "resetting env. episode reward total was 1.0. running mean: -3.017691320978711\n",
      "resetting env. episode reward total was 12.0. running mean: -2.8675144077689234\n",
      "resetting env. episode reward total was -11.0. running mean: -2.948839263691234\n",
      "resetting env. episode reward total was -4.0. running mean: -2.9593508710543217\n",
      "resetting env. episode reward total was 10.0. running mean: -2.8297573623437784\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8114597887203403\n",
      "resetting env. episode reward total was -11.0. running mean: -2.893345190833137\n",
      "resetting env. episode reward total was -4.0. running mean: -2.9044117389248054\n",
      "resetting env. episode reward total was -2.0. running mean: -2.8953676215355575\n",
      "resetting env. episode reward total was -11.0. running mean: -2.9764139453202016\n",
      "resetting env. episode reward total was -2.0. running mean: -2.9666498058669997\n",
      "resetting env. episode reward total was -11.0. running mean: -3.0469833078083295\n",
      "resetting env. episode reward total was -5.0. running mean: -3.066513474730246\n",
      "resetting env. episode reward total was -8.0. running mean: -3.1158483399829433\n",
      "resetting env. episode reward total was -6.0. running mean: -3.144689856583114\n",
      "resetting env. episode reward total was -15.0. running mean: -3.2632429580172824\n",
      "resetting env. episode reward total was -10.0. running mean: -3.3306105284371097\n",
      "resetting env. episode reward total was -8.0. running mean: -3.3773044231527387\n",
      "resetting env. episode reward total was 2.0. running mean: -3.3235313789212113\n",
      "resetting env. episode reward total was 6.0. running mean: -3.230296065131999\n",
      "resetting env. episode reward total was -11.0. running mean: -3.307993104480679\n",
      "resetting env. episode reward total was -17.0. running mean: -3.444913173435872\n",
      "resetting env. episode reward total was 4.0. running mean: -3.370464041701513\n",
      "resetting env. episode reward total was -11.0. running mean: -3.4467594012844978\n",
      "resetting env. episode reward total was -5.0. running mean: -3.4622918072716526\n",
      "resetting env. episode reward total was -3.0. running mean: -3.457668889198936\n",
      "resetting env. episode reward total was -7.0. running mean: -3.4930922003069464\n",
      "resetting env. episode reward total was -14.0. running mean: -3.598161278303877\n",
      "resetting env. episode reward total was -11.0. running mean: -3.672179665520838\n",
      "resetting env. episode reward total was -11.0. running mean: -3.7454578688656293\n",
      "resetting env. episode reward total was -11.0. running mean: -3.8180032901769727\n",
      "resetting env. episode reward total was -15.0. running mean: -3.9298232572752028\n",
      "resetting env. episode reward total was -2.0. running mean: -3.9105250247024506\n",
      "resetting env. episode reward total was -5.0. running mean: -3.9214197744554258\n",
      "resetting env. episode reward total was -9.0. running mean: -3.9722055767108713\n",
      "resetting env. episode reward total was 3.0. running mean: -3.9024835209437625\n",
      "resetting env. episode reward total was 4.0. running mean: -3.823458685734325\n",
      "resetting env. episode reward total was -1.0. running mean: -3.7952240988769814\n",
      "resetting env. episode reward total was -7.0. running mean: -3.8272718578882112\n",
      "resetting env. episode reward total was -4.0. running mean: -3.828999139309329\n",
      "resetting env. episode reward total was -5.0. running mean: -3.8407091479162356\n",
      "resetting env. episode reward total was 12.0. running mean: -3.682302056437073\n",
      "resetting env. episode reward total was -1.0. running mean: -3.6554790358727023\n",
      "resetting env. episode reward total was -6.0. running mean: -3.6789242455139752\n",
      "resetting env. episode reward total was -8.0. running mean: -3.7221350030588356\n",
      "resetting env. episode reward total was 3.0. running mean: -3.6549136530282476\n",
      "resetting env. episode reward total was -1.0. running mean: -3.6283645164979648\n",
      "resetting env. episode reward total was -4.0. running mean: -3.632080871332985\n",
      "resetting env. episode reward total was -7.0. running mean: -3.665760062619655\n",
      "resetting env. episode reward total was -1.0. running mean: -3.639102461993458\n",
      "resetting env. episode reward total was 10.0. running mean: -3.5027114373735233\n",
      "resetting env. episode reward total was 6.0. running mean: -3.407684322999788\n",
      "resetting env. episode reward total was -5.0. running mean: -3.4236074797697897\n",
      "resetting env. episode reward total was -7.0. running mean: -3.459371404972092\n",
      "resetting env. episode reward total was -9.0. running mean: -3.514777690922371\n",
      "resetting env. episode reward total was -5.0. running mean: -3.529629914013147\n",
      "resetting env. episode reward total was -8.0. running mean: -3.5743336148730154\n",
      "resetting env. episode reward total was -9.0. running mean: -3.628590278724285\n",
      "resetting env. episode reward total was -11.0. running mean: -3.7023043759370418\n",
      "resetting env. episode reward total was -3.0. running mean: -3.695281332177671\n",
      "resetting env. episode reward total was -4.0. running mean: -3.6983285188558943\n",
      "resetting env. episode reward total was -7.0. running mean: -3.7313452336673354\n",
      "resetting env. episode reward total was -12.0. running mean: -3.814031781330662\n",
      "resetting env. episode reward total was 6.0. running mean: -3.715891463517355\n",
      "resetting env. episode reward total was -2.0. running mean: -3.6987325488821816\n",
      "resetting env. episode reward total was -7.0. running mean: -3.7317452233933595\n",
      "resetting env. episode reward total was -5.0. running mean: -3.7444277711594256\n",
      "resetting env. episode reward total was -3.0. running mean: -3.736983493447831\n",
      "resetting env. episode reward total was 1.0. running mean: -3.6896136585133528\n",
      "resetting env. episode reward total was 1.0. running mean: -3.6427175219282195\n",
      "resetting env. episode reward total was -9.0. running mean: -3.696290346708937\n",
      "resetting env. episode reward total was -5.0. running mean: -3.7093274432418473\n",
      "resetting env. episode reward total was -9.0. running mean: -3.7622341688094285\n",
      "resetting env. episode reward total was -2.0. running mean: -3.744611827121334\n",
      "resetting env. episode reward total was 1.0. running mean: -3.697165708850121\n",
      "resetting env. episode reward total was -11.0. running mean: -3.7701940517616195\n",
      "resetting env. episode reward total was -1.0. running mean: -3.742492111244003\n",
      "resetting env. episode reward total was -7.0. running mean: -3.7750671901315624\n",
      "resetting env. episode reward total was -3.0. running mean: -3.7673165182302464\n",
      "resetting env. episode reward total was 5.0. running mean: -3.679643353047944\n",
      "resetting env. episode reward total was 1.0. running mean: -3.632846919517465\n",
      "resetting env. episode reward total was 5.0. running mean: -3.5465184503222904\n",
      "resetting env. episode reward total was -5.0. running mean: -3.5610532658190674\n",
      "resetting env. episode reward total was 4.0. running mean: -3.485442733160877\n",
      "resetting env. episode reward total was 3.0. running mean: -3.420588305829268\n",
      "resetting env. episode reward total was -1.0. running mean: -3.396382422770975\n",
      "resetting env. episode reward total was 9.0. running mean: -3.2724185985432657\n",
      "resetting env. episode reward total was 11.0. running mean: -3.129694412557833\n",
      "resetting env. episode reward total was -6.0. running mean: -3.1583974684322547\n",
      "resetting env. episode reward total was 4.0. running mean: -3.086813493747932\n",
      "resetting env. episode reward total was -10.0. running mean: -3.155945358810453\n",
      "resetting env. episode reward total was -1.0. running mean: -3.134385905222348\n",
      "resetting env. episode reward total was 3.0. running mean: -3.0730420461701247\n",
      "resetting env. episode reward total was -2.0. running mean: -3.0623116257084235\n",
      "resetting env. episode reward total was 4.0. running mean: -2.9916885094513392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -3.031771624356826\n",
      "resetting env. episode reward total was -11.0. running mean: -3.1114539081132575\n",
      "resetting env. episode reward total was 6.0. running mean: -3.0203393690321247\n",
      "resetting env. episode reward total was -17.0. running mean: -3.1601359753418032\n",
      "resetting env. episode reward total was -8.0. running mean: -3.2085346155883854\n",
      "resetting env. episode reward total was -8.0. running mean: -3.2564492694325016\n",
      "resetting env. episode reward total was -1.0. running mean: -3.233884776738176\n",
      "resetting env. episode reward total was 2.0. running mean: -3.1815459289707944\n",
      "resetting env. episode reward total was -1.0. running mean: -3.159730469681086\n",
      "resetting env. episode reward total was 2.0. running mean: -3.108133164984275\n",
      "resetting env. episode reward total was -7.0. running mean: -3.1470518333344324\n",
      "resetting env. episode reward total was 3.0. running mean: -3.0855813150010882\n",
      "resetting env. episode reward total was 3.0. running mean: -3.0247255018510777\n",
      "resetting env. episode reward total was 8.0. running mean: -2.9144782468325667\n",
      "resetting env. episode reward total was 6.0. running mean: -2.825333464364241\n",
      "resetting env. episode reward total was 1.0. running mean: -2.7870801297205987\n",
      "resetting env. episode reward total was -6.0. running mean: -2.819209328423393\n",
      "resetting env. episode reward total was -2.0. running mean: -2.811017235139159\n",
      "resetting env. episode reward total was 11.0. running mean: -2.6729070627877674\n",
      "resetting env. episode reward total was 1.0. running mean: -2.63617799215989\n",
      "resetting env. episode reward total was -2.0. running mean: -2.629816212238291\n",
      "resetting env. episode reward total was 6.0. running mean: -2.543518050115908\n",
      "resetting env. episode reward total was 1.0. running mean: -2.508082869614749\n",
      "resetting env. episode reward total was -13.0. running mean: -2.613002040918601\n",
      "resetting env. episode reward total was -4.0. running mean: -2.626872020509415\n",
      "resetting env. episode reward total was -13.0. running mean: -2.730603300304321\n",
      "resetting env. episode reward total was 5.0. running mean: -2.653297267301278\n",
      "resetting env. episode reward total was 10.0. running mean: -2.526764294628265\n",
      "resetting env. episode reward total was -9.0. running mean: -2.591496651681982\n",
      "resetting env. episode reward total was 4.0. running mean: -2.5255816851651622\n",
      "resetting env. episode reward total was 2.0. running mean: -2.4803258683135105\n",
      "resetting env. episode reward total was -4.0. running mean: -2.4955226096303753\n",
      "resetting env. episode reward total was -3.0. running mean: -2.5005673835340714\n",
      "resetting env. episode reward total was -6.0. running mean: -2.535561709698731\n",
      "resetting env. episode reward total was -3.0. running mean: -2.540206092601743\n",
      "resetting env. episode reward total was -3.0. running mean: -2.5448040316757257\n",
      "resetting env. episode reward total was -8.0. running mean: -2.5993559913589683\n",
      "resetting env. episode reward total was 2.0. running mean: -2.5533624314453784\n",
      "resetting env. episode reward total was 9.0. running mean: -2.437828807130925\n",
      "resetting env. episode reward total was -6.0. running mean: -2.4734505190596154\n",
      "resetting env. episode reward total was -2.0. running mean: -2.4687160138690194\n",
      "resetting env. episode reward total was -13.0. running mean: -2.574028853730329\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5982885651930254\n",
      "resetting env. episode reward total was -5.0. running mean: -2.622305679541095\n",
      "resetting env. episode reward total was -7.0. running mean: -2.6660826227456838\n",
      "resetting env. episode reward total was -8.0. running mean: -2.719421796518227\n",
      "resetting env. episode reward total was -4.0. running mean: -2.7322275785530445\n",
      "resetting env. episode reward total was 7.0. running mean: -2.6349053027675144\n",
      "resetting env. episode reward total was -2.0. running mean: -2.628556249739839\n",
      "resetting env. episode reward total was 2.0. running mean: -2.5822706872424406\n",
      "resetting env. episode reward total was -6.0. running mean: -2.6164479803700162\n",
      "resetting env. episode reward total was 6.0. running mean: -2.530283500566316\n",
      "resetting env. episode reward total was 4.0. running mean: -2.4649806655606525\n",
      "resetting env. episode reward total was 3.0. running mean: -2.4103308589050463\n",
      "resetting env. episode reward total was -2.0. running mean: -2.4062275503159958\n",
      "resetting env. episode reward total was -2.0. running mean: -2.4021652748128357\n",
      "resetting env. episode reward total was 7.0. running mean: -2.3081436220647076\n",
      "resetting env. episode reward total was -5.0. running mean: -2.3350621858440603\n",
      "resetting env. episode reward total was 4.0. running mean: -2.27171156398562\n",
      "resetting env. episode reward total was 2.0. running mean: -2.2289944483457638\n",
      "resetting env. episode reward total was 3.0. running mean: -2.1767045038623065\n",
      "resetting env. episode reward total was -7.0. running mean: -2.224937458823683\n",
      "resetting env. episode reward total was 3.0. running mean: -2.1726880842354466\n",
      "resetting env. episode reward total was 5.0. running mean: -2.1009612033930924\n",
      "resetting env. episode reward total was -2.0. running mean: -2.0999515913591615\n",
      "resetting env. episode reward total was -1.0. running mean: -2.0889520754455697\n",
      "resetting env. episode reward total was -8.0. running mean: -2.148062554691114\n",
      "resetting env. episode reward total was 3.0. running mean: -2.096581929144203\n",
      "resetting env. episode reward total was 3.0. running mean: -2.045616109852761\n",
      "resetting env. episode reward total was -7.0. running mean: -2.095159948754233\n",
      "resetting env. episode reward total was 4.0. running mean: -2.0342083492666907\n",
      "resetting env. episode reward total was 2.0. running mean: -1.9938662657740238\n",
      "resetting env. episode reward total was 4.0. running mean: -1.9339276031162835\n",
      "resetting env. episode reward total was -7.0. running mean: -1.9845883270851208\n",
      "resetting env. episode reward total was -2.0. running mean: -1.9847424438142696\n",
      "resetting env. episode reward total was -2.0. running mean: -1.9848950193761268\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9950460691823655\n",
      "resetting env. episode reward total was -6.0. running mean: -2.0350956084905416\n",
      "resetting env. episode reward total was -6.0. running mean: -2.074744652405636\n",
      "resetting env. episode reward total was -6.0. running mean: -2.1139972058815797\n",
      "resetting env. episode reward total was -7.0. running mean: -2.1628572338227636\n",
      "resetting env. episode reward total was 8.0. running mean: -2.061228661484536\n",
      "resetting env. episode reward total was -5.0. running mean: -2.09061637486969\n",
      "resetting env. episode reward total was -7.0. running mean: -2.139710211120993\n",
      "resetting env. episode reward total was -9.0. running mean: -2.208313109009783\n",
      "resetting env. episode reward total was 2.0. running mean: -2.166229977919685\n",
      "resetting env. episode reward total was -15.0. running mean: -2.294567678140488\n",
      "resetting env. episode reward total was -3.0. running mean: -2.301622001359083\n",
      "resetting env. episode reward total was 7.0. running mean: -2.2086057813454922\n",
      "resetting env. episode reward total was 1.0. running mean: -2.1765197235320377\n",
      "resetting env. episode reward total was -3.0. running mean: -2.184754526296717\n",
      "resetting env. episode reward total was 2.0. running mean: -2.1429069810337498\n",
      "resetting env. episode reward total was -7.0. running mean: -2.191477911223412\n",
      "resetting env. episode reward total was 3.0. running mean: -2.1395631321111783\n",
      "resetting env. episode reward total was 3.0. running mean: -2.0881675007900666\n",
      "resetting env. episode reward total was 6.0. running mean: -2.0072858257821657\n",
      "resetting env. episode reward total was -12.0. running mean: -2.1072129675243443\n",
      "resetting env. episode reward total was -8.0. running mean: -2.1661408378491007\n",
      "resetting env. episode reward total was -2.0. running mean: -2.16447942947061\n",
      "resetting env. episode reward total was 10.0. running mean: -2.0428346351759035\n",
      "resetting env. episode reward total was -6.0. running mean: -2.0824062888241444\n",
      "resetting env. episode reward total was 2.0. running mean: -2.041582225935903\n",
      "resetting env. episode reward total was -5.0. running mean: -2.0711664036765436\n",
      "resetting env. episode reward total was 8.0. running mean: -1.970454739639778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: -1.8907501922433803\n",
      "resetting env. episode reward total was 5.0. running mean: -1.8218426903209464\n",
      "resetting env. episode reward total was 14.0. running mean: -1.663624263417737\n",
      "resetting env. episode reward total was 10.0. running mean: -1.5469880207835596\n",
      "resetting env. episode reward total was 11.0. running mean: -1.4215181405757238\n",
      "resetting env. episode reward total was 2.0. running mean: -1.3873029591699666\n",
      "resetting env. episode reward total was 3.0. running mean: -1.3434299295782668\n",
      "resetting env. episode reward total was -1.0. running mean: -1.339995630282484\n",
      "resetting env. episode reward total was 7.0. running mean: -1.256595673979659\n",
      "resetting env. episode reward total was -6.0. running mean: -1.3040297172398625\n",
      "resetting env. episode reward total was -1.0. running mean: -1.3009894200674639\n",
      "resetting env. episode reward total was 4.0. running mean: -1.2479795258667892\n",
      "resetting env. episode reward total was -9.0. running mean: -1.3254997306081213\n",
      "resetting env. episode reward total was 3.0. running mean: -1.2822447333020401\n",
      "resetting env. episode reward total was -9.0. running mean: -1.3594222859690197\n",
      "resetting env. episode reward total was -8.0. running mean: -1.4258280631093296\n",
      "resetting env. episode reward total was 2.0. running mean: -1.3915697824782363\n",
      "resetting env. episode reward total was -11.0. running mean: -1.487654084653454\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5027775438069195\n",
      "resetting env. episode reward total was 3.0. running mean: -1.4577497683688503\n",
      "resetting env. episode reward total was -2.0. running mean: -1.4631722706851618\n",
      "resetting env. episode reward total was 3.0. running mean: -1.4185405479783102\n",
      "resetting env. episode reward total was 5.0. running mean: -1.354355142498527\n",
      "resetting env. episode reward total was -14.0. running mean: -1.4808115910735418\n",
      "resetting env. episode reward total was -5.0. running mean: -1.5160034751628064\n",
      "resetting env. episode reward total was 2.0. running mean: -1.4808434404111783\n",
      "resetting env. episode reward total was -5.0. running mean: -1.5160350060070666\n",
      "resetting env. episode reward total was -5.0. running mean: -1.550874655946996\n",
      "resetting env. episode reward total was -10.0. running mean: -1.6353659093875261\n",
      "resetting env. episode reward total was -9.0. running mean: -1.709012250293651\n",
      "resetting env. episode reward total was 14.0. running mean: -1.5519221277907143\n",
      "resetting env. episode reward total was -15.0. running mean: -1.686402906512807\n",
      "resetting env. episode reward total was 6.0. running mean: -1.6095388774476789\n",
      "resetting env. episode reward total was -1.0. running mean: -1.603443488673202\n",
      "resetting env. episode reward total was -7.0. running mean: -1.65740905378647\n",
      "resetting env. episode reward total was -4.0. running mean: -1.6808349632486055\n",
      "resetting env. episode reward total was 5.0. running mean: -1.6140266136161194\n",
      "resetting env. episode reward total was 1.0. running mean: -1.5878863474799583\n",
      "resetting env. episode reward total was -8.0. running mean: -1.6520074840051588\n",
      "resetting env. episode reward total was 3.0. running mean: -1.6054874091651072\n",
      "resetting env. episode reward total was -6.0. running mean: -1.6494325350734562\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6829382097227217\n",
      "resetting env. episode reward total was -7.0. running mean: -1.7361088276254946\n",
      "resetting env. episode reward total was 2.0. running mean: -1.6987477393492396\n",
      "resetting env. episode reward total was -3.0. running mean: -1.7117602619557473\n",
      "resetting env. episode reward total was -10.0. running mean: -1.79464265933619\n",
      "resetting env. episode reward total was 4.0. running mean: -1.736696232742828\n",
      "resetting env. episode reward total was -1.0. running mean: -1.7293292704153995\n",
      "resetting env. episode reward total was 1.0. running mean: -1.7020359777112455\n",
      "resetting env. episode reward total was -8.0. running mean: -1.7650156179341332\n",
      "resetting env. episode reward total was 3.0. running mean: -1.7173654617547918\n",
      "resetting env. episode reward total was 11.0. running mean: -1.5901918071372438\n",
      "resetting env. episode reward total was -1.0. running mean: -1.5842898890658714\n",
      "resetting env. episode reward total was -11.0. running mean: -1.6784469901752128\n",
      "resetting env. episode reward total was 2.0. running mean: -1.6416625202734607\n",
      "resetting env. episode reward total was -13.0. running mean: -1.755245895070726\n",
      "resetting env. episode reward total was 4.0. running mean: -1.6976934361200187\n",
      "resetting env. episode reward total was -3.0. running mean: -1.7107165017588184\n",
      "resetting env. episode reward total was 5.0. running mean: -1.64360933674123\n",
      "resetting env. episode reward total was 8.0. running mean: -1.5471732433738177\n",
      "resetting env. episode reward total was -2.0. running mean: -1.5517015109400796\n",
      "resetting env. episode reward total was 7.0. running mean: -1.4661844958306787\n",
      "resetting env. episode reward total was -5.0. running mean: -1.501522650872372\n",
      "resetting env. episode reward total was -4.0. running mean: -1.5265074243636483\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5412423501200119\n",
      "resetting env. episode reward total was -6.0. running mean: -1.5858299266188118\n",
      "resetting env. episode reward total was 11.0. running mean: -1.4599716273526235\n",
      "resetting env. episode reward total was -9.0. running mean: -1.5353719110790973\n",
      "resetting env. episode reward total was 2.0. running mean: -1.5000181919683062\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5150180100486232\n",
      "resetting env. episode reward total was 1.0. running mean: -1.489867829948137\n",
      "resetting env. episode reward total was -5.0. running mean: -1.5249691516486557\n",
      "resetting env. episode reward total was -15.0. running mean: -1.659719460132169\n",
      "resetting env. episode reward total was -13.0. running mean: -1.7731222655308474\n",
      "resetting env. episode reward total was -16.0. running mean: -1.9153910428755387\n",
      "resetting env. episode reward total was 2.0. running mean: -1.8762371324467833\n",
      "resetting env. episode reward total was -5.0. running mean: -1.9074747611223155\n",
      "resetting env. episode reward total was -2.0. running mean: -1.9084000135110923\n",
      "resetting env. episode reward total was -6.0. running mean: -1.9493160133759815\n",
      "resetting env. episode reward total was -2.0. running mean: -1.9498228532422217\n",
      "resetting env. episode reward total was 7.0. running mean: -1.8603246247097993\n",
      "resetting env. episode reward total was -10.0. running mean: -1.9417213784627014\n",
      "resetting env. episode reward total was 5.0. running mean: -1.8723041646780743\n",
      "resetting env. episode reward total was -4.0. running mean: -1.8935811230312936\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9046453118009807\n",
      "resetting env. episode reward total was -1.0. running mean: -1.8955988586829708\n",
      "resetting env. episode reward total was 4.0. running mean: -1.836642870096141\n",
      "resetting env. episode reward total was -10.0. running mean: -1.9182764413951796\n",
      "resetting env. episode reward total was -7.0. running mean: -1.969093676981228\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9594027402114156\n",
      "resetting env. episode reward total was -7.0. running mean: -2.0098087128093014\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9997106256812083\n",
      "resetting env. episode reward total was -10.0. running mean: -2.0797135194243963\n",
      "resetting env. episode reward total was -9.0. running mean: -2.148916384230152\n",
      "resetting env. episode reward total was -2.0. running mean: -2.1474272203878506\n",
      "resetting env. episode reward total was -5.0. running mean: -2.175952948183972\n",
      "resetting env. episode reward total was -14.0. running mean: -2.2941934187021324\n",
      "resetting env. episode reward total was -7.0. running mean: -2.341251484515111\n",
      "resetting env. episode reward total was -9.0. running mean: -2.40783896966996\n",
      "resetting env. episode reward total was 4.0. running mean: -2.34376057997326\n",
      "resetting env. episode reward total was -15.0. running mean: -2.4703229741735275\n",
      "resetting env. episode reward total was -6.0. running mean: -2.5056197444317925\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5305635469874743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: -2.5352579115175993\n",
      "resetting env. episode reward total was -8.0. running mean: -2.5899053324024233\n",
      "resetting env. episode reward total was -8.0. running mean: -2.644006279078399\n",
      "resetting env. episode reward total was -3.0. running mean: -2.647566216287615\n",
      "resetting env. episode reward total was -6.0. running mean: -2.6810905541247387\n",
      "resetting env. episode reward total was 4.0. running mean: -2.614279648583491\n",
      "resetting env. episode reward total was 9.0. running mean: -2.4981368520976566\n",
      "resetting env. episode reward total was -12.0. running mean: -2.59315548357668\n",
      "resetting env. episode reward total was 5.0. running mean: -2.517223928740913\n",
      "resetting env. episode reward total was -5.0. running mean: -2.542051689453504\n",
      "resetting env. episode reward total was 8.0. running mean: -2.4366311725589687\n",
      "resetting env. episode reward total was 8.0. running mean: -2.3322648608333787\n",
      "resetting env. episode reward total was 1.0. running mean: -2.298942212225045\n",
      "resetting env. episode reward total was -3.0. running mean: -2.3059527901027943\n",
      "resetting env. episode reward total was -13.0. running mean: -2.412893262201766\n",
      "resetting env. episode reward total was 3.0. running mean: -2.3587643295797487\n",
      "resetting env. episode reward total was -4.0. running mean: -2.375176686283951\n",
      "resetting env. episode reward total was -12.0. running mean: -2.4714249194211115\n",
      "resetting env. episode reward total was -4.0. running mean: -2.4867106702269006\n",
      "resetting env. episode reward total was 6.0. running mean: -2.4018435635246314\n",
      "resetting env. episode reward total was 3.0. running mean: -2.347825127889385\n",
      "resetting env. episode reward total was -17.0. running mean: -2.494346876610491\n",
      "resetting env. episode reward total was -4.0. running mean: -2.509403407844386\n",
      "resetting env. episode reward total was -3.0. running mean: -2.514309373765942\n",
      "resetting env. episode reward total was -12.0. running mean: -2.609166280028283\n",
      "resetting env. episode reward total was -15.0. running mean: -2.733074617228\n",
      "resetting env. episode reward total was -10.0. running mean: -2.80574387105572\n",
      "resetting env. episode reward total was 5.0. running mean: -2.727686432345163\n",
      "resetting env. episode reward total was -10.0. running mean: -2.8004095680217116\n",
      "resetting env. episode reward total was 5.0. running mean: -2.7224054723414945\n",
      "resetting env. episode reward total was -4.0. running mean: -2.7351814176180795\n",
      "resetting env. episode reward total was 1.0. running mean: -2.697829603441899\n",
      "resetting env. episode reward total was -8.0. running mean: -2.7508513074074803\n",
      "resetting env. episode reward total was -6.0. running mean: -2.7833427943334055\n",
      "resetting env. episode reward total was -11.0. running mean: -2.8655093663900715\n",
      "resetting env. episode reward total was -10.0. running mean: -2.936854272726171\n",
      "resetting env. episode reward total was -1.0. running mean: -2.917485729998909\n",
      "resetting env. episode reward total was -6.0. running mean: -2.94831087269892\n",
      "resetting env. episode reward total was -7.0. running mean: -2.9888277639719307\n",
      "resetting env. episode reward total was -7.0. running mean: -3.028939486332211\n",
      "resetting env. episode reward total was -1.0. running mean: -3.0086500914688887\n",
      "resetting env. episode reward total was -6.0. running mean: -3.0385635905541997\n",
      "resetting env. episode reward total was -9.0. running mean: -3.0981779546486576\n",
      "resetting env. episode reward total was -1.0. running mean: -3.077196175102171\n",
      "resetting env. episode reward total was -5.0. running mean: -3.096424213351149\n",
      "resetting env. episode reward total was -7.0. running mean: -3.1354599712176374\n",
      "resetting env. episode reward total was -10.0. running mean: -3.2041053715054613\n",
      "resetting env. episode reward total was -3.0. running mean: -3.2020643177904065\n",
      "resetting env. episode reward total was 6.0. running mean: -3.1100436746125024\n",
      "resetting env. episode reward total was -1.0. running mean: -3.0889432378663773\n",
      "resetting env. episode reward total was -10.0. running mean: -3.1580538054877136\n",
      "resetting env. episode reward total was -9.0. running mean: -3.2164732674328365\n",
      "resetting env. episode reward total was 1.0. running mean: -3.1743085347585085\n",
      "resetting env. episode reward total was -10.0. running mean: -3.2425654494109235\n",
      "resetting env. episode reward total was -12.0. running mean: -3.3301397949168146\n",
      "resetting env. episode reward total was -3.0. running mean: -3.3268383969676463\n",
      "resetting env. episode reward total was 7.0. running mean: -3.22357001299797\n",
      "resetting env. episode reward total was -8.0. running mean: -3.27133431286799\n",
      "resetting env. episode reward total was -3.0. running mean: -3.26862096973931\n",
      "resetting env. episode reward total was -18.0. running mean: -3.415934760041917\n",
      "resetting env. episode reward total was -8.0. running mean: -3.4617754124414977\n",
      "resetting env. episode reward total was -10.0. running mean: -3.527157658317083\n",
      "resetting env. episode reward total was 1.0. running mean: -3.4818860817339123\n",
      "resetting env. episode reward total was -7.0. running mean: -3.517067220916573\n",
      "resetting env. episode reward total was -11.0. running mean: -3.5918965487074073\n",
      "resetting env. episode reward total was -1.0. running mean: -3.565977583220333\n",
      "resetting env. episode reward total was -1.0. running mean: -3.5403178073881296\n",
      "resetting env. episode reward total was 2.0. running mean: -3.484914629314248\n",
      "resetting env. episode reward total was 9.0. running mean: -3.360065483021106\n",
      "resetting env. episode reward total was -9.0. running mean: -3.4164648281908945\n",
      "resetting env. episode reward total was 7.0. running mean: -3.3123001799089855\n",
      "resetting env. episode reward total was -9.0. running mean: -3.3691771781098954\n",
      "resetting env. episode reward total was -9.0. running mean: -3.425485406328796\n",
      "resetting env. episode reward total was -1.0. running mean: -3.401230552265508\n",
      "resetting env. episode reward total was -6.0. running mean: -3.4272182467428527\n",
      "resetting env. episode reward total was -4.0. running mean: -3.4329460642754244\n",
      "resetting env. episode reward total was -6.0. running mean: -3.45861660363267\n",
      "resetting env. episode reward total was 1.0. running mean: -3.4140304375963435\n",
      "resetting env. episode reward total was 6.0. running mean: -3.31989013322038\n",
      "resetting env. episode reward total was 8.0. running mean: -3.206691231888176\n",
      "resetting env. episode reward total was 4.0. running mean: -3.134624319569294\n",
      "resetting env. episode reward total was -1.0. running mean: -3.113278076373601\n",
      "resetting env. episode reward total was -4.0. running mean: -3.122145295609865\n",
      "resetting env. episode reward total was -8.0. running mean: -3.1709238426537665\n",
      "resetting env. episode reward total was -6.0. running mean: -3.1992146042272287\n",
      "resetting env. episode reward total was 8.0. running mean: -3.0872224581849563\n",
      "resetting env. episode reward total was 4.0. running mean: -3.0163502336031067\n",
      "resetting env. episode reward total was -10.0. running mean: -3.086186731267076\n",
      "resetting env. episode reward total was -5.0. running mean: -3.105324863954405\n",
      "resetting env. episode reward total was 16.0. running mean: -2.9142716153148607\n",
      "resetting env. episode reward total was -6.0. running mean: -2.945128899161712\n",
      "resetting env. episode reward total was -11.0. running mean: -3.025677610170095\n",
      "resetting env. episode reward total was 3.0. running mean: -2.965420834068394\n",
      "resetting env. episode reward total was -7.0. running mean: -3.0057666257277096\n",
      "resetting env. episode reward total was 6.0. running mean: -2.9157089594704324\n",
      "resetting env. episode reward total was -4.0. running mean: -2.9265518698757282\n",
      "resetting env. episode reward total was -1.0. running mean: -2.9072863511769707\n",
      "resetting env. episode reward total was -4.0. running mean: -2.918213487665201\n",
      "resetting env. episode reward total was 5.0. running mean: -2.839031352788549\n",
      "resetting env. episode reward total was -7.0. running mean: -2.8806410392606634\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8618346288680567\n",
      "resetting env. episode reward total was -3.0. running mean: -2.863216282579376\n",
      "resetting env. episode reward total was -5.0. running mean: -2.884584119753582\n",
      "resetting env. episode reward total was -7.0. running mean: -2.925738278556046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: -2.9364808957704858\n",
      "resetting env. episode reward total was -1.0. running mean: -2.9171160868127806\n",
      "resetting env. episode reward total was 6.0. running mean: -2.8279449259446525\n",
      "resetting env. episode reward total was -1.0. running mean: -2.809665476685206\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8115688219183537\n",
      "resetting env. episode reward total was 6.0. running mean: -2.72345313369917\n",
      "resetting env. episode reward total was 1.0. running mean: -2.6862186023621786\n",
      "resetting env. episode reward total was -1.0. running mean: -2.6693564163385566\n",
      "resetting env. episode reward total was -4.0. running mean: -2.682662852175171\n",
      "resetting env. episode reward total was -10.0. running mean: -2.7558362236534193\n",
      "resetting env. episode reward total was 7.0. running mean: -2.6582778614168854\n",
      "resetting env. episode reward total was -5.0. running mean: -2.681695082802716\n",
      "resetting env. episode reward total was -1.0. running mean: -2.664878131974689\n",
      "resetting env. episode reward total was -3.0. running mean: -2.6682293506549417\n",
      "resetting env. episode reward total was 3.0. running mean: -2.6115470571483925\n",
      "resetting env. episode reward total was -2.0. running mean: -2.6054315865769087\n",
      "resetting env. episode reward total was -9.0. running mean: -2.6693772707111396\n",
      "resetting env. episode reward total was 5.0. running mean: -2.5926834980040283\n",
      "resetting env. episode reward total was -10.0. running mean: -2.666756663023988\n",
      "resetting env. episode reward total was 7.0. running mean: -2.5700890963937484\n",
      "resetting env. episode reward total was -1.0. running mean: -2.554388205429811\n",
      "resetting env. episode reward total was 8.0. running mean: -2.448844323375513\n",
      "resetting env. episode reward total was -1.0. running mean: -2.4343558801417573\n",
      "resetting env. episode reward total was 3.0. running mean: -2.38001232134034\n",
      "resetting env. episode reward total was -5.0. running mean: -2.406212198126936\n",
      "resetting env. episode reward total was 1.0. running mean: -2.372150076145667\n",
      "resetting env. episode reward total was -1.0. running mean: -2.35842857538421\n",
      "resetting env. episode reward total was 1.0. running mean: -2.3248442896303683\n",
      "resetting env. episode reward total was 9.0. running mean: -2.2115958467340646\n",
      "resetting env. episode reward total was 6.0. running mean: -2.129479888266724\n",
      "resetting env. episode reward total was 6.0. running mean: -2.0481850893840567\n",
      "resetting env. episode reward total was 7.0. running mean: -1.9577032384902162\n",
      "resetting env. episode reward total was -12.0. running mean: -2.058126206105314\n",
      "resetting env. episode reward total was -12.0. running mean: -2.1575449440442607\n",
      "resetting env. episode reward total was -6.0. running mean: -2.195969494603818\n",
      "resetting env. episode reward total was 3.0. running mean: -2.14400979965778\n",
      "resetting env. episode reward total was -11.0. running mean: -2.2325697016612023\n",
      "resetting env. episode reward total was -1.0. running mean: -2.22024400464459\n",
      "resetting env. episode reward total was -12.0. running mean: -2.3180415645981443\n",
      "resetting env. episode reward total was -5.0. running mean: -2.3448611489521625\n",
      "resetting env. episode reward total was -3.0. running mean: -2.3514125374626405\n",
      "resetting env. episode reward total was 2.0. running mean: -2.307898412088014\n",
      "resetting env. episode reward total was -9.0. running mean: -2.3748194279671337\n",
      "resetting env. episode reward total was -1.0. running mean: -2.361071233687462\n",
      "resetting env. episode reward total was -3.0. running mean: -2.3674605213505875\n",
      "resetting env. episode reward total was -5.0. running mean: -2.3937859161370816\n",
      "resetting env. episode reward total was 5.0. running mean: -2.3198480569757107\n",
      "resetting env. episode reward total was -12.0. running mean: -2.4166495764059537\n",
      "resetting env. episode reward total was -9.0. running mean: -2.482483080641894\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5076582498354747\n",
      "resetting env. episode reward total was 3.0. running mean: -2.45258166733712\n",
      "resetting env. episode reward total was -5.0. running mean: -2.4780558506637487\n",
      "resetting env. episode reward total was -8.0. running mean: -2.533275292157111\n",
      "resetting env. episode reward total was -10.0. running mean: -2.60794253923554\n",
      "resetting env. episode reward total was 7.0. running mean: -2.511863113843185\n",
      "resetting env. episode reward total was 3.0. running mean: -2.4567444827047535\n",
      "resetting env. episode reward total was -12.0. running mean: -2.5521770378777062\n",
      "resetting env. episode reward total was 3.0. running mean: -2.4966552674989293\n",
      "resetting env. episode reward total was 11.0. running mean: -2.36168871482394\n",
      "resetting env. episode reward total was 1.0. running mean: -2.328071827675701\n",
      "resetting env. episode reward total was -9.0. running mean: -2.394791109398944\n",
      "resetting env. episode reward total was 6.0. running mean: -2.3108431983049544\n",
      "resetting env. episode reward total was 8.0. running mean: -2.207734766321905\n",
      "resetting env. episode reward total was -6.0. running mean: -2.245657418658686\n",
      "resetting env. episode reward total was -8.0. running mean: -2.3032008444720993\n",
      "resetting env. episode reward total was -13.0. running mean: -2.410168836027378\n",
      "resetting env. episode reward total was -1.0. running mean: -2.3960671476671043\n",
      "resetting env. episode reward total was -5.0. running mean: -2.422106476190433\n",
      "resetting env. episode reward total was 4.0. running mean: -2.3578854114285286\n",
      "resetting env. episode reward total was 4.0. running mean: -2.2943065573142434\n",
      "resetting env. episode reward total was 1.0. running mean: -2.261363491741101\n",
      "resetting env. episode reward total was 10.0. running mean: -2.13874985682369\n",
      "resetting env. episode reward total was 1.0. running mean: -2.1073623582554535\n",
      "resetting env. episode reward total was -9.0. running mean: -2.176288734672899\n",
      "resetting env. episode reward total was 9.0. running mean: -2.0645258473261703\n",
      "resetting env. episode reward total was 6.0. running mean: -1.9838805888529083\n",
      "resetting env. episode reward total was -14.0. running mean: -2.104041782964379\n",
      "resetting env. episode reward total was -7.0. running mean: -2.153001365134735\n",
      "resetting env. episode reward total was 1.0. running mean: -2.121471351483388\n",
      "resetting env. episode reward total was 5.0. running mean: -2.050256637968554\n",
      "resetting env. episode reward total was -8.0. running mean: -2.1097540715888687\n",
      "resetting env. episode reward total was -2.0. running mean: -2.10865653087298\n",
      "resetting env. episode reward total was -7.0. running mean: -2.15756996556425\n",
      "resetting env. episode reward total was -8.0. running mean: -2.2159942659086074\n",
      "resetting env. episode reward total was 7.0. running mean: -2.1238343232495214\n",
      "resetting env. episode reward total was -6.0. running mean: -2.1625959800170262\n",
      "resetting env. episode reward total was -12.0. running mean: -2.260970020216856\n",
      "resetting env. episode reward total was -11.0. running mean: -2.348360320014687\n",
      "resetting env. episode reward total was 7.0. running mean: -2.2548767168145405\n",
      "resetting env. episode reward total was -5.0. running mean: -2.282327949646395\n",
      "resetting env. episode reward total was -7.0. running mean: -2.3295046701499307\n",
      "resetting env. episode reward total was -5.0. running mean: -2.3562096234484313\n",
      "resetting env. episode reward total was -1.0. running mean: -2.3426475272139466\n",
      "resetting env. episode reward total was -13.0. running mean: -2.449221051941807\n",
      "resetting env. episode reward total was 3.0. running mean: -2.394728841422389\n",
      "resetting env. episode reward total was -1.0. running mean: -2.380781553008165\n",
      "resetting env. episode reward total was 3.0. running mean: -2.3269737374780832\n",
      "resetting env. episode reward total was 4.0. running mean: -2.2637040001033024\n",
      "resetting env. episode reward total was 1.0. running mean: -2.2310669601022695\n",
      "resetting env. episode reward total was 10.0. running mean: -2.1087562905012467\n",
      "resetting env. episode reward total was -4.0. running mean: -2.1276687275962343\n",
      "resetting env. episode reward total was -6.0. running mean: -2.166392040320272\n",
      "resetting env. episode reward total was 4.0. running mean: -2.1047281199170693\n",
      "resetting env. episode reward total was 1.0. running mean: -2.0736808387178987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -10.0. running mean: -2.15294403033072\n",
      "resetting env. episode reward total was 1.0. running mean: -2.121414590027413\n",
      "resetting env. episode reward total was -5.0. running mean: -2.1502004441271385\n",
      "resetting env. episode reward total was 1.0. running mean: -2.1186984396858675\n",
      "resetting env. episode reward total was -1.0. running mean: -2.1075114552890084\n",
      "resetting env. episode reward total was 10.0. running mean: -1.9864363407361183\n",
      "resetting env. episode reward total was -10.0. running mean: -2.066571977328757\n",
      "resetting env. episode reward total was -8.0. running mean: -2.1259062575554695\n",
      "resetting env. episode reward total was -2.0. running mean: -2.124647194979915\n",
      "resetting env. episode reward total was 4.0. running mean: -2.0634007230301155\n",
      "resetting env. episode reward total was 8.0. running mean: -1.9627667157998143\n",
      "resetting env. episode reward total was -9.0. running mean: -2.033139048641816\n",
      "resetting env. episode reward total was 1.0. running mean: -2.0028076581553984\n",
      "resetting env. episode reward total was 7.0. running mean: -1.9127795815738444\n",
      "resetting env. episode reward total was -1.0. running mean: -1.903651785758106\n",
      "resetting env. episode reward total was -4.0. running mean: -1.9246152679005248\n",
      "resetting env. episode reward total was 6.0. running mean: -1.8453691152215195\n",
      "resetting env. episode reward total was -8.0. running mean: -1.9069154240693043\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9178462698286112\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9286678071303252\n",
      "resetting env. episode reward total was 9.0. running mean: -1.8193811290590218\n",
      "resetting env. episode reward total was 4.0. running mean: -1.7611873177684316\n",
      "resetting env. episode reward total was 9.0. running mean: -1.6535754445907471\n",
      "resetting env. episode reward total was -13.0. running mean: -1.7670396901448395\n",
      "resetting env. episode reward total was 7.0. running mean: -1.679369293243391\n",
      "resetting env. episode reward total was 1.0. running mean: -1.652575600310957\n",
      "resetting env. episode reward total was 1.0. running mean: -1.6260498443078475\n",
      "resetting env. episode reward total was -12.0. running mean: -1.729789345864769\n",
      "resetting env. episode reward total was 8.0. running mean: -1.6324914524061214\n",
      "resetting env. episode reward total was -9.0. running mean: -1.7061665378820603\n",
      "resetting env. episode reward total was 12.0. running mean: -1.5691048725032397\n",
      "resetting env. episode reward total was 3.0. running mean: -1.5234138237782073\n",
      "resetting env. episode reward total was 3.0. running mean: -1.4781796855404252\n",
      "resetting env. episode reward total was 10.0. running mean: -1.3633978886850209\n",
      "resetting env. episode reward total was -9.0. running mean: -1.4397639097981707\n",
      "resetting env. episode reward total was -7.0. running mean: -1.4953662707001891\n",
      "resetting env. episode reward total was 5.0. running mean: -1.4304126079931871\n",
      "resetting env. episode reward total was -5.0. running mean: -1.4661084819132553\n",
      "resetting env. episode reward total was -6.0. running mean: -1.5114473970941227\n",
      "resetting env. episode reward total was -10.0. running mean: -1.5963329231231815\n",
      "resetting env. episode reward total was -1.0. running mean: -1.5903695938919498\n",
      "resetting env. episode reward total was 8.0. running mean: -1.49446589795303\n",
      "resetting env. episode reward total was 4.0. running mean: -1.4395212389734997\n",
      "resetting env. episode reward total was 1.0. running mean: -1.4151260265837646\n",
      "resetting env. episode reward total was 2.0. running mean: -1.380974766317927\n",
      "resetting env. episode reward total was -6.0. running mean: -1.4271650186547478\n",
      "resetting env. episode reward total was 2.0. running mean: -1.3928933684682003\n",
      "resetting env. episode reward total was 5.0. running mean: -1.3289644347835183\n",
      "resetting env. episode reward total was 1.0. running mean: -1.3056747904356831\n",
      "resetting env. episode reward total was -3.0. running mean: -1.3226180425313263\n",
      "resetting env. episode reward total was 2.0. running mean: -1.289391862106013\n",
      "resetting env. episode reward total was 7.0. running mean: -1.2064979434849528\n",
      "resetting env. episode reward total was -4.0. running mean: -1.2344329640501033\n",
      "resetting env. episode reward total was 3.0. running mean: -1.1920886344096022\n",
      "resetting env. episode reward total was 5.0. running mean: -1.1301677480655061\n",
      "resetting env. episode reward total was -8.0. running mean: -1.198866070584851\n",
      "resetting env. episode reward total was 8.0. running mean: -1.1068774098790024\n",
      "resetting env. episode reward total was -2.0. running mean: -1.1158086357802124\n",
      "resetting env. episode reward total was 5.0. running mean: -1.05465054942241\n",
      "resetting env. episode reward total was 5.0. running mean: -0.9941040439281859\n",
      "resetting env. episode reward total was -5.0. running mean: -1.034163003488904\n",
      "resetting env. episode reward total was -7.0. running mean: -1.093821373454015\n",
      "resetting env. episode reward total was -13.0. running mean: -1.2128831597194747\n",
      "resetting env. episode reward total was -3.0. running mean: -1.23075432812228\n",
      "resetting env. episode reward total was -2.0. running mean: -1.2384467848410572\n",
      "resetting env. episode reward total was 6.0. running mean: -1.1660623169926465\n",
      "resetting env. episode reward total was 10.0. running mean: -1.0544016938227199\n",
      "resetting env. episode reward total was -8.0. running mean: -1.1238576768844928\n",
      "resetting env. episode reward total was 7.0. running mean: -1.0426191001156477\n",
      "resetting env. episode reward total was -7.0. running mean: -1.1021929091144913\n",
      "resetting env. episode reward total was -14.0. running mean: -1.2311709800233466\n",
      "resetting env. episode reward total was 1.0. running mean: -1.2088592702231131\n",
      "resetting env. episode reward total was 7.0. running mean: -1.126770677520882\n",
      "resetting env. episode reward total was -8.0. running mean: -1.1955029707456732\n",
      "resetting env. episode reward total was 2.0. running mean: -1.1635479410382166\n",
      "resetting env. episode reward total was -1.0. running mean: -1.1619124616278345\n",
      "resetting env. episode reward total was -2.0. running mean: -1.170293337011556\n",
      "resetting env. episode reward total was -4.0. running mean: -1.1985904036414405\n",
      "resetting env. episode reward total was 3.0. running mean: -1.1566044996050262\n",
      "resetting env. episode reward total was -15.0. running mean: -1.295038454608976\n",
      "resetting env. episode reward total was 1.0. running mean: -1.272088070062886\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2693671893622571\n",
      "resetting env. episode reward total was -3.0. running mean: -1.2866735174686346\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2838067822939483\n",
      "resetting env. episode reward total was -6.0. running mean: -1.330968714471009\n",
      "resetting env. episode reward total was 2.0. running mean: -1.297659027326299\n",
      "resetting env. episode reward total was -4.0. running mean: -1.324682437053036\n",
      "resetting env. episode reward total was -5.0. running mean: -1.3614356126825056\n",
      "resetting env. episode reward total was -11.0. running mean: -1.4578212565556805\n",
      "resetting env. episode reward total was 3.0. running mean: -1.4132430439901236\n",
      "resetting env. episode reward total was -3.0. running mean: -1.4291106135502223\n",
      "resetting env. episode reward total was -12.0. running mean: -1.5348195074147202\n",
      "resetting env. episode reward total was -9.0. running mean: -1.609471312340573\n",
      "resetting env. episode reward total was 8.0. running mean: -1.5133765992171673\n",
      "resetting env. episode reward total was -9.0. running mean: -1.5882428332249956\n",
      "resetting env. episode reward total was 2.0. running mean: -1.5523604048927455\n",
      "resetting env. episode reward total was -4.0. running mean: -1.576836800843818\n",
      "resetting env. episode reward total was -5.0. running mean: -1.61106843283538\n",
      "resetting env. episode reward total was 9.0. running mean: -1.504957748507026\n",
      "resetting env. episode reward total was -1.0. running mean: -1.4999081710219557\n",
      "resetting env. episode reward total was -9.0. running mean: -1.5749090893117363\n",
      "resetting env. episode reward total was 8.0. running mean: -1.479159998418619\n",
      "resetting env. episode reward total was -4.0. running mean: -1.504368398434433\n",
      "resetting env. episode reward total was 11.0. running mean: -1.3793247144500884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: -1.2855314673055875\n",
      "resetting env. episode reward total was -9.0. running mean: -1.3626761526325317\n",
      "resetting env. episode reward total was -12.0. running mean: -1.4690493911062066\n",
      "resetting env. episode reward total was -5.0. running mean: -1.5043588971951445\n",
      "resetting env. episode reward total was -6.0. running mean: -1.5493153082231932\n",
      "resetting env. episode reward total was -4.0. running mean: -1.5738221551409612\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6080839335895516\n",
      "resetting env. episode reward total was -6.0. running mean: -1.652003094253656\n",
      "resetting env. episode reward total was -11.0. running mean: -1.7454830633111196\n",
      "resetting env. episode reward total was -5.0. running mean: -1.7780282326780084\n",
      "resetting env. episode reward total was 9.0. running mean: -1.6702479503512282\n",
      "resetting env. episode reward total was -1.0. running mean: -1.663545470847716\n",
      "resetting env. episode reward total was -13.0. running mean: -1.7769100161392388\n",
      "resetting env. episode reward total was 2.0. running mean: -1.7391409159778464\n",
      "resetting env. episode reward total was 1.0. running mean: -1.711749506818068\n",
      "resetting env. episode reward total was 1.0. running mean: -1.6846320117498872\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6977856916323883\n",
      "resetting env. episode reward total was 4.0. running mean: -1.6408078347160644\n",
      "resetting env. episode reward total was 3.0. running mean: -1.5943997563689036\n",
      "resetting env. episode reward total was -2.0. running mean: -1.5984557588052146\n",
      "resetting env. episode reward total was -11.0. running mean: -1.6924712012171625\n",
      "resetting env. episode reward total was 8.0. running mean: -1.5955464892049909\n",
      "resetting env. episode reward total was 4.0. running mean: -1.539591024312941\n",
      "resetting env. episode reward total was -5.0. running mean: -1.5741951140698116\n",
      "resetting env. episode reward total was 4.0. running mean: -1.5184531629291134\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5332686312998223\n",
      "resetting env. episode reward total was 2.0. running mean: -1.497935944986824\n",
      "resetting env. episode reward total was -4.0. running mean: -1.5229565855369558\n",
      "resetting env. episode reward total was -4.0. running mean: -1.5477270196815862\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5622497494847705\n",
      "resetting env. episode reward total was -6.0. running mean: -1.6066272519899227\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6405609794700236\n",
      "resetting env. episode reward total was -1.0. running mean: -1.6341553696753233\n",
      "resetting env. episode reward total was 8.0. running mean: -1.53781381597857\n",
      "resetting env. episode reward total was 2.0. running mean: -1.5024356778187842\n",
      "resetting env. episode reward total was -4.0. running mean: -1.5274113210405964\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5421372078301905\n",
      "resetting env. episode reward total was 6.0. running mean: -1.4667158357518886\n",
      "resetting env. episode reward total was 7.0. running mean: -1.3820486773943697\n",
      "resetting env. episode reward total was -13.0. running mean: -1.4982281906204258\n",
      "resetting env. episode reward total was -1.0. running mean: -1.4932459087142216\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5083134496270794\n",
      "resetting env. episode reward total was 5.0. running mean: -1.4432303151308086\n",
      "resetting env. episode reward total was -9.0. running mean: -1.5187980119795006\n",
      "resetting env. episode reward total was 8.0. running mean: -1.4236100318597056\n",
      "resetting env. episode reward total was -9.0. running mean: -1.4993739315411085\n",
      "resetting env. episode reward total was 1.0. running mean: -1.4743801922256974\n",
      "resetting env. episode reward total was 3.0. running mean: -1.4296363903034404\n",
      "resetting env. episode reward total was 2.0. running mean: -1.3953400264004059\n",
      "resetting env. episode reward total was 9.0. running mean: -1.2913866261364018\n",
      "resetting env. episode reward total was -6.0. running mean: -1.3384727598750379\n",
      "resetting env. episode reward total was 1.0. running mean: -1.3150880322762875\n",
      "resetting env. episode reward total was 3.0. running mean: -1.2719371519535245\n",
      "resetting env. episode reward total was -5.0. running mean: -1.3092177804339893\n",
      "resetting env. episode reward total was -8.0. running mean: -1.3761256026296496\n",
      "resetting env. episode reward total was -2.0. running mean: -1.382364346603353\n",
      "resetting env. episode reward total was 11.0. running mean: -1.2585407031373195\n",
      "resetting env. episode reward total was 2.0. running mean: -1.2259552961059463\n",
      "resetting env. episode reward total was 2.0. running mean: -1.193695743144887\n",
      "resetting env. episode reward total was -7.0. running mean: -1.251758785713438\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2492411978563036\n",
      "resetting env. episode reward total was -4.0. running mean: -1.2767487858777407\n",
      "resetting env. episode reward total was 7.0. running mean: -1.1939812980189632\n",
      "resetting env. episode reward total was -3.0. running mean: -1.2120414850387737\n",
      "resetting env. episode reward total was 8.0. running mean: -1.119921070188386\n",
      "resetting env. episode reward total was 5.0. running mean: -1.058721859486502\n",
      "resetting env. episode reward total was -2.0. running mean: -1.068134640891637\n",
      "resetting env. episode reward total was 7.0. running mean: -0.9874532944827206\n",
      "resetting env. episode reward total was 5.0. running mean: -0.9275787615378933\n",
      "resetting env. episode reward total was 10.0. running mean: -0.8183029739225144\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8201199441832893\n",
      "resetting env. episode reward total was 15.0. running mean: -0.6619187447414563\n",
      "resetting env. episode reward total was 8.0. running mean: -0.5752995572940418\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5995465617211014\n",
      "resetting env. episode reward total was 6.0. running mean: -0.5335510961038905\n",
      "resetting env. episode reward total was 9.0. running mean: -0.43821558514285164\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4638334292914231\n",
      "resetting env. episode reward total was 9.0. running mean: -0.3691950949985089\n",
      "resetting env. episode reward total was -4.0. running mean: -0.4055031440485238\n",
      "resetting env. episode reward total was -7.0. running mean: -0.47144811260803854\n",
      "resetting env. episode reward total was -2.0. running mean: -0.48673363148195814\n",
      "resetting env. episode reward total was -1.0. running mean: -0.4918662951671386\n",
      "resetting env. episode reward total was 9.0. running mean: -0.39694763221546725\n",
      "resetting env. episode reward total was -11.0. running mean: -0.5029781558933126\n",
      "resetting env. episode reward total was 4.0. running mean: -0.4579483743343795\n",
      "resetting env. episode reward total was -1.0. running mean: -0.4633688905910357\n",
      "resetting env. episode reward total was 5.0. running mean: -0.40873520168512534\n",
      "resetting env. episode reward total was 8.0. running mean: -0.3246478496682741\n",
      "resetting env. episode reward total was 3.0. running mean: -0.2914013711715914\n",
      "resetting env. episode reward total was 8.0. running mean: -0.20848735745987546\n",
      "resetting env. episode reward total was 5.0. running mean: -0.15640248388527672\n",
      "resetting env. episode reward total was -3.0. running mean: -0.18483845904642396\n",
      "resetting env. episode reward total was 1.0. running mean: -0.1729900744559597\n",
      "resetting env. episode reward total was -15.0. running mean: -0.32126017371140014\n",
      "resetting env. episode reward total was 11.0. running mean: -0.20804757197428614\n",
      "resetting env. episode reward total was 4.0. running mean: -0.16596709625454326\n",
      "resetting env. episode reward total was -7.0. running mean: -0.23430742529199783\n",
      "resetting env. episode reward total was 3.0. running mean: -0.20196435103907784\n",
      "resetting env. episode reward total was 8.0. running mean: -0.11994470752868706\n",
      "resetting env. episode reward total was -9.0. running mean: -0.2087452604534002\n",
      "resetting env. episode reward total was -1.0. running mean: -0.2166578078488662\n",
      "resetting env. episode reward total was 1.0. running mean: -0.20449122977037754\n",
      "resetting env. episode reward total was 6.0. running mean: -0.14244631747267375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: -0.111021854297947\n",
      "resetting env. episode reward total was -4.0. running mean: -0.14991163575496752\n",
      "resetting env. episode reward total was 14.0. running mean: -0.008412519397417828\n",
      "resetting env. episode reward total was -3.0. running mean: -0.03832839420344365\n",
      "resetting env. episode reward total was 7.0. running mean: 0.03205488973859079\n",
      "resetting env. episode reward total was -9.0. running mean: -0.05826565915879511\n",
      "resetting env. episode reward total was 2.0. running mean: -0.03768300256720716\n",
      "resetting env. episode reward total was -10.0. running mean: -0.1373061725415351\n",
      "resetting env. episode reward total was -1.0. running mean: -0.14593311081611976\n",
      "resetting env. episode reward total was 3.0. running mean: -0.11447377970795855\n",
      "resetting env. episode reward total was -2.0. running mean: -0.13332904191087896\n",
      "resetting env. episode reward total was -1.0. running mean: -0.14199575149177018\n",
      "resetting env. episode reward total was 7.0. running mean: -0.07057579397685249\n",
      "resetting env. episode reward total was -6.0. running mean: -0.12987003603708397\n",
      "resetting env. episode reward total was 5.0. running mean: -0.07857133567671314\n",
      "resetting env. episode reward total was 4.0. running mean: -0.037785622319946\n",
      "resetting env. episode reward total was 10.0. running mean: 0.06259223390325347\n",
      "resetting env. episode reward total was 2.0. running mean: 0.08196631156422093\n",
      "resetting env. episode reward total was -4.0. running mean: 0.04114664844857872\n",
      "resetting env. episode reward total was 4.0. running mean: 0.08073518196409293\n",
      "resetting env. episode reward total was 2.0. running mean: 0.099927830144452\n",
      "resetting env. episode reward total was 2.0. running mean: 0.11892855184300749\n",
      "resetting env. episode reward total was 3.0. running mean: 0.1477392663245774\n",
      "resetting env. episode reward total was -3.0. running mean: 0.11626187366133162\n",
      "resetting env. episode reward total was -4.0. running mean: 0.0750992549247183\n",
      "resetting env. episode reward total was -3.0. running mean: 0.044348262375471126\n",
      "resetting env. episode reward total was -3.0. running mean: 0.013904779751716417\n",
      "resetting env. episode reward total was -2.0. running mean: -0.006234268045800748\n",
      "resetting env. episode reward total was -3.0. running mean: -0.036171925365342736\n",
      "resetting env. episode reward total was -9.0. running mean: -0.1258102061116893\n",
      "resetting env. episode reward total was 2.0. running mean: -0.1045521040505724\n",
      "resetting env. episode reward total was -6.0. running mean: -0.16350658301006665\n",
      "resetting env. episode reward total was 7.0. running mean: -0.09187151717996597\n",
      "resetting env. episode reward total was -6.0. running mean: -0.1509528020081663\n",
      "resetting env. episode reward total was -11.0. running mean: -0.25944327398808464\n",
      "resetting env. episode reward total was 2.0. running mean: -0.2368488412482038\n",
      "resetting env. episode reward total was 1.0. running mean: -0.22448035283572174\n",
      "resetting env. episode reward total was -2.0. running mean: -0.24223554930736452\n",
      "resetting env. episode reward total was -1.0. running mean: -0.24981319381429087\n",
      "resetting env. episode reward total was -4.0. running mean: -0.28731506187614797\n",
      "resetting env. episode reward total was 2.0. running mean: -0.2644419112573865\n",
      "resetting env. episode reward total was -8.0. running mean: -0.34179749214481264\n",
      "resetting env. episode reward total was -4.0. running mean: -0.3783795172233645\n",
      "resetting env. episode reward total was -1.0. running mean: -0.38459572205113085\n",
      "resetting env. episode reward total was -3.0. running mean: -0.41074976483061953\n",
      "resetting env. episode reward total was -9.0. running mean: -0.4966422671823133\n",
      "resetting env. episode reward total was 3.0. running mean: -0.46167584451049015\n",
      "resetting env. episode reward total was 13.0. running mean: -0.32705908606538525\n",
      "resetting env. episode reward total was -5.0. running mean: -0.3737884952047314\n",
      "resetting env. episode reward total was 1.0. running mean: -0.3600506102526841\n",
      "resetting env. episode reward total was -8.0. running mean: -0.4364501041501573\n",
      "resetting env. episode reward total was -7.0. running mean: -0.5020856031086557\n",
      "resetting env. episode reward total was -13.0. running mean: -0.6270647470775692\n",
      "resetting env. episode reward total was -11.0. running mean: -0.7307940996067935\n",
      "resetting env. episode reward total was -5.0. running mean: -0.7734861586107257\n",
      "resetting env. episode reward total was -2.0. running mean: -0.7857512970246184\n",
      "resetting env. episode reward total was 3.0. running mean: -0.7478937840543722\n",
      "resetting env. episode reward total was -7.0. running mean: -0.8104148462138285\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8523106977516903\n",
      "resetting env. episode reward total was 10.0. running mean: -0.7437875907741734\n",
      "resetting env. episode reward total was -9.0. running mean: -0.8263497148664317\n",
      "resetting env. episode reward total was 4.0. running mean: -0.7780862177177673\n",
      "resetting env. episode reward total was -1.0. running mean: -0.7803053555405897\n",
      "resetting env. episode reward total was -11.0. running mean: -0.8825023019851838\n",
      "resetting env. episode reward total was -6.0. running mean: -0.9336772789653318\n",
      "resetting env. episode reward total was 3.0. running mean: -0.8943405061756785\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8653971011139217\n",
      "resetting env. episode reward total was 5.0. running mean: -0.8067431301027824\n",
      "resetting env. episode reward total was -13.0. running mean: -0.9286756988017546\n",
      "resetting env. episode reward total was -5.0. running mean: -0.9693889418137371\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9696950523955997\n",
      "resetting env. episode reward total was -5.0. running mean: -1.0099981018716437\n",
      "resetting env. episode reward total was 3.0. running mean: -0.9698981208529273\n",
      "resetting env. episode reward total was 4.0. running mean: -0.9201991396443979\n",
      "resetting env. episode reward total was 1.0. running mean: -0.900997148247954\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8519871767654744\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8934673049978197\n",
      "resetting env. episode reward total was -5.0. running mean: -0.9345326319478415\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9351873056283632\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9358354325720796\n",
      "resetting env. episode reward total was 8.0. running mean: -0.8464770782463588\n",
      "resetting env. episode reward total was -4.0. running mean: -0.8780123074638952\n",
      "resetting env. episode reward total was 14.0. running mean: -0.7292321843892563\n",
      "resetting env. episode reward total was 5.0. running mean: -0.6719398625453636\n",
      "resetting env. episode reward total was -3.0. running mean: -0.69522046391991\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6982682592807109\n",
      "resetting env. episode reward total was -2.0. running mean: -0.7112855766879038\n",
      "resetting env. episode reward total was -4.0. running mean: -0.7441727209210248\n",
      "resetting env. episode reward total was -11.0. running mean: -0.8467309937118146\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8682636837746964\n",
      "resetting env. episode reward total was 7.0. running mean: -0.7895810469369495\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8316852364675801\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8533683841029043\n",
      "resetting env. episode reward total was -9.0. running mean: -0.9348347002618752\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9954863532592564\n",
      "resetting env. episode reward total was 1.0. running mean: -0.9755314897266638\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9757761748293972\n",
      "resetting env. episode reward total was -2.0. running mean: -0.9860184130811032\n",
      "resetting env. episode reward total was 5.0. running mean: -0.9261582289502921\n",
      "resetting env. episode reward total was -11.0. running mean: -1.0268966466607892\n",
      "resetting env. episode reward total was -12.0. running mean: -1.1366276801941813\n",
      "resetting env. episode reward total was 5.0. running mean: -1.0752614033922394\n",
      "resetting env. episode reward total was 3.0. running mean: -1.034508789358317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: -0.9841637014647338\n",
      "resetting env. episode reward total was 15.0. running mean: -0.8243220644500864\n",
      "resetting env. episode reward total was 4.0. running mean: -0.7760788438055854\n",
      "resetting env. episode reward total was -9.0. running mean: -0.8583180553675296\n",
      "resetting env. episode reward total was -9.0. running mean: -0.9397348748138542\n",
      "resetting env. episode reward total was -9.0. running mean: -1.0203375260657157\n",
      "resetting env. episode reward total was -5.0. running mean: -1.0601341508050586\n",
      "resetting env. episode reward total was 1.0. running mean: -1.039532809297008\n",
      "resetting env. episode reward total was 4.0. running mean: -0.9891374812040379\n",
      "resetting env. episode reward total was 2.0. running mean: -0.9592461063919975\n",
      "resetting env. episode reward total was -8.0. running mean: -1.0296536453280776\n",
      "resetting env. episode reward total was 1.0. running mean: -1.0093571088747968\n",
      "resetting env. episode reward total was 3.0. running mean: -0.9692635377860488\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9695709024081883\n",
      "resetting env. episode reward total was 2.0. running mean: -0.9398751933841064\n",
      "resetting env. episode reward total was -7.0. running mean: -1.0004764414502654\n",
      "resetting env. episode reward total was -3.0. running mean: -1.0204716770357627\n",
      "resetting env. episode reward total was -7.0. running mean: -1.0802669602654051\n",
      "resetting env. episode reward total was -3.0. running mean: -1.0994642906627512\n",
      "resetting env. episode reward total was -5.0. running mean: -1.1384696477561238\n",
      "resetting env. episode reward total was -10.0. running mean: -1.2270849512785627\n",
      "resetting env. episode reward total was -7.0. running mean: -1.284814101765777\n",
      "resetting env. episode reward total was 9.0. running mean: -1.1819659607481192\n",
      "resetting env. episode reward total was -15.0. running mean: -1.320146301140638\n",
      "resetting env. episode reward total was -9.0. running mean: -1.3969448381292318\n",
      "resetting env. episode reward total was 3.0. running mean: -1.3529753897479393\n",
      "resetting env. episode reward total was -11.0. running mean: -1.44944563585046\n",
      "resetting env. episode reward total was 9.0. running mean: -1.3449511794919553\n",
      "resetting env. episode reward total was 4.0. running mean: -1.2915016676970357\n",
      "resetting env. episode reward total was -8.0. running mean: -1.3585866510200655\n",
      "resetting env. episode reward total was -9.0. running mean: -1.435000784509865\n",
      "resetting env. episode reward total was -7.0. running mean: -1.4906507766647663\n",
      "resetting env. episode reward total was -11.0. running mean: -1.5857442688981187\n",
      "resetting env. episode reward total was 4.0. running mean: -1.5298868262091374\n",
      "resetting env. episode reward total was -10.0. running mean: -1.6145879579470461\n",
      "resetting env. episode reward total was 1.0. running mean: -1.5884420783675757\n",
      "resetting env. episode reward total was -10.0. running mean: -1.6725576575839\n",
      "resetting env. episode reward total was 5.0. running mean: -1.605832081008061\n",
      "resetting env. episode reward total was -2.0. running mean: -1.6097737601979805\n",
      "resetting env. episode reward total was -9.0. running mean: -1.6836760225960008\n",
      "resetting env. episode reward total was 5.0. running mean: -1.6168392623700407\n",
      "resetting env. episode reward total was 6.0. running mean: -1.5406708697463403\n",
      "resetting env. episode reward total was -1.0. running mean: -1.5352641610488769\n",
      "resetting env. episode reward total was -2.0. running mean: -1.539911519438388\n",
      "resetting env. episode reward total was -2.0. running mean: -1.5445124042440042\n",
      "resetting env. episode reward total was -6.0. running mean: -1.5890672802015642\n",
      "resetting env. episode reward total was 4.0. running mean: -1.5331766073995485\n",
      "resetting env. episode reward total was -5.0. running mean: -1.567844841325553\n",
      "resetting env. episode reward total was 3.0. running mean: -1.5221663929122975\n",
      "resetting env. episode reward total was -5.0. running mean: -1.5569447289831746\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5713752816933428\n",
      "resetting env. episode reward total was -4.0. running mean: -1.5956615288764093\n",
      "resetting env. episode reward total was -8.0. running mean: -1.6597049135876454\n",
      "resetting env. episode reward total was 6.0. running mean: -1.5831078644517689\n",
      "resetting env. episode reward total was 2.0. running mean: -1.5472767858072511\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5618040179491786\n",
      "resetting env. episode reward total was -5.0. running mean: -1.5961859777696867\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6102241179919898\n",
      "resetting env. episode reward total was 5.0. running mean: -1.54412187681207\n",
      "resetting env. episode reward total was 4.0. running mean: -1.4886806580439491\n",
      "resetting env. episode reward total was 5.0. running mean: -1.4237938514635096\n",
      "resetting env. episode reward total was -6.0. running mean: -1.4695559129488744\n",
      "resetting env. episode reward total was -5.0. running mean: -1.5048603538193857\n",
      "resetting env. episode reward total was -1.0. running mean: -1.4998117502811918\n",
      "resetting env. episode reward total was 6.0. running mean: -1.4248136327783798\n",
      "resetting env. episode reward total was -7.0. running mean: -1.480565496450596\n",
      "resetting env. episode reward total was -6.0. running mean: -1.5257598414860902\n",
      "resetting env. episode reward total was 9.0. running mean: -1.4205022430712293\n",
      "resetting env. episode reward total was -2.0. running mean: -1.4262972206405171\n",
      "resetting env. episode reward total was 13.0. running mean: -1.2820342484341118\n",
      "resetting env. episode reward total was 8.0. running mean: -1.1892139059497706\n",
      "resetting env. episode reward total was 5.0. running mean: -1.1273217668902729\n",
      "resetting env. episode reward total was -5.0. running mean: -1.1660485492213701\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1843880637291564\n",
      "resetting env. episode reward total was 3.0. running mean: -1.1425441830918648\n",
      "resetting env. episode reward total was 5.0. running mean: -1.081118741260946\n",
      "resetting env. episode reward total was -4.0. running mean: -1.1103075538483365\n",
      "resetting env. episode reward total was 2.0. running mean: -1.079204478309853\n",
      "resetting env. episode reward total was -4.0. running mean: -1.1084124335267547\n",
      "resetting env. episode reward total was -1.0. running mean: -1.1073283091914872\n",
      "resetting env. episode reward total was -11.0. running mean: -1.2062550260995724\n",
      "resetting env. episode reward total was -2.0. running mean: -1.2141924758385767\n",
      "resetting env. episode reward total was -10.0. running mean: -1.302050551080191\n",
      "resetting env. episode reward total was 2.0. running mean: -1.269030045569389\n",
      "resetting env. episode reward total was -3.0. running mean: -1.286339745113695\n",
      "resetting env. episode reward total was -3.0. running mean: -1.3034763476625582\n",
      "resetting env. episode reward total was -2.0. running mean: -1.3104415841859325\n",
      "resetting env. episode reward total was -10.0. running mean: -1.3973371683440732\n",
      "resetting env. episode reward total was -11.0. running mean: -1.4933637966606326\n",
      "resetting env. episode reward total was -6.0. running mean: -1.5384301586940263\n",
      "resetting env. episode reward total was 4.0. running mean: -1.483045857107086\n",
      "resetting env. episode reward total was -14.0. running mean: -1.6082153985360153\n",
      "resetting env. episode reward total was -3.0. running mean: -1.622133244550655\n",
      "resetting env. episode reward total was 3.0. running mean: -1.5759119121051486\n",
      "resetting env. episode reward total was 1.0. running mean: -1.550152792984097\n",
      "resetting env. episode reward total was -5.0. running mean: -1.5846512650542561\n",
      "resetting env. episode reward total was -6.0. running mean: -1.6288047524037137\n",
      "resetting env. episode reward total was -6.0. running mean: -1.6725167048796765\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6857915378308799\n",
      "resetting env. episode reward total was 1.0. running mean: -1.658933622452571\n",
      "resetting env. episode reward total was 3.0. running mean: -1.6123442862280453\n",
      "resetting env. episode reward total was -6.0. running mean: -1.6562208433657648\n",
      "resetting env. episode reward total was -10.0. running mean: -1.7396586349321073\n",
      "resetting env. episode reward total was 5.0. running mean: -1.6722620485827862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: -1.6855394280969582\n",
      "resetting env. episode reward total was 12.0. running mean: -1.5486840338159888\n",
      "resetting env. episode reward total was -7.0. running mean: -1.603197193477829\n",
      "resetting env. episode reward total was -2.0. running mean: -1.6071652215430507\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6210935693276203\n",
      "resetting env. episode reward total was 3.0. running mean: -1.574882633634344\n",
      "resetting env. episode reward total was 4.0. running mean: -1.5191338072980005\n",
      "resetting env. episode reward total was -7.0. running mean: -1.5739424692250206\n",
      "resetting env. episode reward total was -1.0. running mean: -1.5682030445327704\n",
      "resetting env. episode reward total was -12.0. running mean: -1.6725210140874425\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6857958039465681\n",
      "resetting env. episode reward total was -8.0. running mean: -1.7489378459071026\n",
      "resetting env. episode reward total was -1.0. running mean: -1.7414484674480315\n",
      "resetting env. episode reward total was 2.0. running mean: -1.7040339827735511\n",
      "resetting env. episode reward total was -6.0. running mean: -1.7469936429458157\n",
      "resetting env. episode reward total was -6.0. running mean: -1.7895237065163576\n",
      "resetting env. episode reward total was -4.0. running mean: -1.8116284694511942\n",
      "resetting env. episode reward total was -8.0. running mean: -1.8735121847566822\n",
      "resetting env. episode reward total was -10.0. running mean: -1.9547770629091155\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9452292922800243\n",
      "resetting env. episode reward total was 2.0. running mean: -1.905776999357224\n",
      "resetting env. episode reward total was 7.0. running mean: -1.8167192293636516\n",
      "resetting env. episode reward total was -1.0. running mean: -1.808552037070015\n",
      "resetting env. episode reward total was -2.0. running mean: -1.8104665166993148\n",
      "resetting env. episode reward total was -9.0. running mean: -1.8823618515323217\n",
      "resetting env. episode reward total was 8.0. running mean: -1.7835382330169984\n",
      "resetting env. episode reward total was 1.0. running mean: -1.7557028506868284\n",
      "resetting env. episode reward total was 11.0. running mean: -1.62814582217996\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6618643639581605\n",
      "resetting env. episode reward total was -1.0. running mean: -1.6552457203185789\n",
      "resetting env. episode reward total was -4.0. running mean: -1.678693263115393\n",
      "resetting env. episode reward total was -3.0. running mean: -1.691906330484239\n",
      "resetting env. episode reward total was -9.0. running mean: -1.7649872671793967\n",
      "resetting env. episode reward total was -10.0. running mean: -1.8473373945076028\n",
      "resetting env. episode reward total was -6.0. running mean: -1.888864020562527\n",
      "resetting env. episode reward total was 1.0. running mean: -1.8599753803569017\n",
      "resetting env. episode reward total was -13.0. running mean: -1.9713756265533329\n",
      "resetting env. episode reward total was 2.0. running mean: -1.9316618702877995\n",
      "resetting env. episode reward total was 9.0. running mean: -1.8223452515849214\n",
      "resetting env. episode reward total was -6.0. running mean: -1.8641217990690722\n",
      "resetting env. episode reward total was -2.0. running mean: -1.8654805810783814\n",
      "resetting env. episode reward total was -8.0. running mean: -1.9268257752675977\n",
      "resetting env. episode reward total was -14.0. running mean: -2.047557517514922\n",
      "resetting env. episode reward total was 2.0. running mean: -2.0070819423397728\n",
      "resetting env. episode reward total was 1.0. running mean: -1.977011122916375\n",
      "resetting env. episode reward total was -11.0. running mean: -2.0672410116872113\n",
      "resetting env. episode reward total was -5.0. running mean: -2.096568601570339\n",
      "resetting env. episode reward total was 1.0. running mean: -2.065602915554636\n",
      "resetting env. episode reward total was 9.0. running mean: -1.9549468863990895\n",
      "resetting env. episode reward total was -9.0. running mean: -2.0253974175350984\n",
      "resetting env. episode reward total was -9.0. running mean: -2.0951434433597473\n",
      "resetting env. episode reward total was -11.0. running mean: -2.1841920089261495\n",
      "resetting env. episode reward total was -3.0. running mean: -2.192350088836888\n",
      "resetting env. episode reward total was -7.0. running mean: -2.240426587948519\n",
      "resetting env. episode reward total was -7.0. running mean: -2.2880223220690334\n",
      "resetting env. episode reward total was 6.0. running mean: -2.2051420988483432\n",
      "resetting env. episode reward total was -9.0. running mean: -2.2730906778598596\n",
      "resetting env. episode reward total was -11.0. running mean: -2.360359771081261\n",
      "resetting env. episode reward total was -2.0. running mean: -2.3567561733704485\n",
      "resetting env. episode reward total was -4.0. running mean: -2.373188611636744\n",
      "resetting env. episode reward total was -11.0. running mean: -2.4594567255203765\n",
      "resetting env. episode reward total was -9.0. running mean: -2.5248621582651727\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5496135366825206\n",
      "resetting env. episode reward total was 2.0. running mean: -2.5041174013156953\n",
      "resetting env. episode reward total was -10.0. running mean: -2.5790762273025383\n",
      "resetting env. episode reward total was 4.0. running mean: -2.513285465029513\n",
      "resetting env. episode reward total was 3.0. running mean: -2.458152610379218\n",
      "resetting env. episode reward total was -8.0. running mean: -2.513571084275426\n",
      "resetting env. episode reward total was -10.0. running mean: -2.588435373432672\n",
      "resetting env. episode reward total was -5.0. running mean: -2.612551019698345\n",
      "resetting env. episode reward total was -9.0. running mean: -2.6764255095013616\n",
      "resetting env. episode reward total was 1.0. running mean: -2.6396612544063482\n",
      "resetting env. episode reward total was 6.0. running mean: -2.5532646418622846\n",
      "resetting env. episode reward total was 4.0. running mean: -2.487731995443662\n",
      "resetting env. episode reward total was 9.0. running mean: -2.3728546754892252\n",
      "resetting env. episode reward total was -1.0. running mean: -2.359126128734333\n",
      "resetting env. episode reward total was -3.0. running mean: -2.365534867446989\n",
      "resetting env. episode reward total was 9.0. running mean: -2.2518795187725194\n",
      "resetting env. episode reward total was -1.0. running mean: -2.239360723584794\n",
      "resetting env. episode reward total was -5.0. running mean: -2.2669671163489458\n",
      "resetting env. episode reward total was -2.0. running mean: -2.2642974451854565\n",
      "resetting env. episode reward total was -9.0. running mean: -2.3316544707336018\n",
      "resetting env. episode reward total was -9.0. running mean: -2.3983379260262656\n",
      "resetting env. episode reward total was -3.0. running mean: -2.404354546766003\n",
      "resetting env. episode reward total was -4.0. running mean: -2.4203110012983426\n",
      "resetting env. episode reward total was -11.0. running mean: -2.506107891285359\n",
      "resetting env. episode reward total was 2.0. running mean: -2.4610468123725053\n",
      "resetting env. episode reward total was 3.0. running mean: -2.4064363442487804\n",
      "resetting env. episode reward total was -5.0. running mean: -2.4323719808062925\n",
      "resetting env. episode reward total was 7.0. running mean: -2.33804826099823\n",
      "resetting env. episode reward total was -3.0. running mean: -2.3446677783882475\n",
      "resetting env. episode reward total was -3.0. running mean: -2.3512211006043646\n",
      "resetting env. episode reward total was 2.0. running mean: -2.307708889598321\n",
      "resetting env. episode reward total was -5.0. running mean: -2.3346318007023377\n",
      "resetting env. episode reward total was -4.0. running mean: -2.3512854826953142\n",
      "resetting env. episode reward total was -9.0. running mean: -2.417772627868361\n",
      "resetting env. episode reward total was -6.0. running mean: -2.4535949015896774\n",
      "resetting env. episode reward total was -6.0. running mean: -2.4890589525737807\n",
      "resetting env. episode reward total was 1.0. running mean: -2.4541683630480433\n",
      "resetting env. episode reward total was 7.0. running mean: -2.359626679417563\n",
      "resetting env. episode reward total was -12.0. running mean: -2.4560304126233876\n",
      "resetting env. episode reward total was -2.0. running mean: -2.4514701084971535\n",
      "resetting env. episode reward total was -17.0. running mean: -2.596955407412182\n",
      "resetting env. episode reward total was -11.0. running mean: -2.68098585333806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -11.0. running mean: -2.7641759948046793\n",
      "resetting env. episode reward total was -7.0. running mean: -2.8065342348566324\n",
      "resetting env. episode reward total was -4.0. running mean: -2.8184688925080663\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8202842035829856\n",
      "resetting env. episode reward total was -14.0. running mean: -2.932081361547156\n",
      "resetting env. episode reward total was -9.0. running mean: -2.992760547931684\n",
      "resetting env. episode reward total was 1.0. running mean: -2.9528329424523676\n",
      "resetting env. episode reward total was 4.0. running mean: -2.883304613027844\n",
      "resetting env. episode reward total was -9.0. running mean: -2.9444715668975654\n",
      "resetting env. episode reward total was -5.0. running mean: -2.9650268512285893\n",
      "resetting env. episode reward total was -3.0. running mean: -2.965376582716303\n",
      "resetting env. episode reward total was 5.0. running mean: -2.8857228168891402\n",
      "resetting env. episode reward total was -7.0. running mean: -2.926865588720249\n",
      "resetting env. episode reward total was -9.0. running mean: -2.9875969328330463\n",
      "resetting env. episode reward total was -11.0. running mean: -3.0677209635047156\n",
      "resetting env. episode reward total was -7.0. running mean: -3.107043753869668\n",
      "resetting env. episode reward total was 1.0. running mean: -3.0659733163309717\n",
      "resetting env. episode reward total was -5.0. running mean: -3.085313583167662\n",
      "resetting env. episode reward total was -10.0. running mean: -3.1544604473359854\n",
      "resetting env. episode reward total was 1.0. running mean: -3.1129158428626256\n",
      "resetting env. episode reward total was 6.0. running mean: -3.0217866844339993\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0415688175896594\n",
      "resetting env. episode reward total was -11.0. running mean: -3.1211531294137624\n",
      "resetting env. episode reward total was 1.0. running mean: -3.079941598119625\n",
      "resetting env. episode reward total was -4.0. running mean: -3.089142182138429\n",
      "resetting env. episode reward total was 1.0. running mean: -3.048250760317045\n",
      "resetting env. episode reward total was -3.0. running mean: -3.0477682527138743\n",
      "resetting env. episode reward total was -4.0. running mean: -3.0572905701867357\n",
      "resetting env. episode reward total was -5.0. running mean: -3.076717664484868\n",
      "resetting env. episode reward total was 5.0. running mean: -2.9959504878400196\n",
      "resetting env. episode reward total was -12.0. running mean: -3.0859909829616194\n",
      "resetting env. episode reward total was -2.0. running mean: -3.0751310731320034\n",
      "resetting env. episode reward total was 2.0. running mean: -3.024379762400683\n",
      "resetting env. episode reward total was -10.0. running mean: -3.0941359647766764\n",
      "resetting env. episode reward total was -10.0. running mean: -3.1631946051289095\n",
      "resetting env. episode reward total was 5.0. running mean: -3.0815626590776204\n",
      "resetting env. episode reward total was 3.0. running mean: -3.0207470324868444\n",
      "resetting env. episode reward total was -2.0. running mean: -3.010539562161976\n",
      "resetting env. episode reward total was -3.0. running mean: -3.0104341665403562\n",
      "resetting env. episode reward total was -2.0. running mean: -3.0003298248749526\n",
      "resetting env. episode reward total was -11.0. running mean: -3.080326526626203\n",
      "resetting env. episode reward total was 5.0. running mean: -2.999523261359941\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0195280287463415\n",
      "resetting env. episode reward total was -10.0. running mean: -3.089332748458878\n",
      "resetting env. episode reward total was -6.0. running mean: -3.1184394209742896\n",
      "resetting env. episode reward total was 2.0. running mean: -3.067255026764547\n",
      "resetting env. episode reward total was -6.0. running mean: -3.096582476496901\n",
      "resetting env. episode reward total was 1.0. running mean: -3.0556166517319325\n",
      "resetting env. episode reward total was -13.0. running mean: -3.155060485214613\n",
      "resetting env. episode reward total was -7.0. running mean: -3.1935098803624666\n",
      "resetting env. episode reward total was -14.0. running mean: -3.301574781558842\n",
      "resetting env. episode reward total was 2.0. running mean: -3.2485590337432537\n",
      "resetting env. episode reward total was -9.0. running mean: -3.306073443405821\n",
      "resetting env. episode reward total was -6.0. running mean: -3.3330127089717627\n",
      "resetting env. episode reward total was -9.0. running mean: -3.389682581882045\n",
      "resetting env. episode reward total was -11.0. running mean: -3.4657857560632244\n",
      "resetting env. episode reward total was -4.0. running mean: -3.471127898502592\n",
      "resetting env. episode reward total was 10.0. running mean: -3.336416619517566\n",
      "resetting env. episode reward total was 2.0. running mean: -3.2830524533223904\n",
      "resetting env. episode reward total was 3.0. running mean: -3.2202219287891665\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2580197095012746\n",
      "resetting env. episode reward total was 2.0. running mean: -3.205439512406262\n",
      "resetting env. episode reward total was -11.0. running mean: -3.283385117282199\n",
      "resetting env. episode reward total was 6.0. running mean: -3.190551266109377\n",
      "resetting env. episode reward total was 3.0. running mean: -3.1286457534482834\n",
      "resetting env. episode reward total was 5.0. running mean: -3.0473592959138007\n",
      "resetting env. episode reward total was -3.0. running mean: -3.0468857029546625\n",
      "resetting env. episode reward total was -10.0. running mean: -3.116416845925116\n",
      "resetting env. episode reward total was -11.0. running mean: -3.1952526774658643\n",
      "resetting env. episode reward total was -5.0. running mean: -3.2133001506912056\n",
      "resetting env. episode reward total was 4.0. running mean: -3.1411671491842936\n",
      "resetting env. episode reward total was 3.0. running mean: -3.079755477692451\n",
      "resetting env. episode reward total was -8.0. running mean: -3.1289579229155264\n",
      "resetting env. episode reward total was -7.0. running mean: -3.167668343686371\n",
      "resetting env. episode reward total was 3.0. running mean: -3.1059916602495075\n",
      "resetting env. episode reward total was -6.0. running mean: -3.1349317436470123\n",
      "resetting env. episode reward total was -7.0. running mean: -3.173582426210542\n",
      "resetting env. episode reward total was -11.0. running mean: -3.2518466019484364\n",
      "resetting env. episode reward total was -5.0. running mean: -3.269328135928952\n",
      "resetting env. episode reward total was 4.0. running mean: -3.196634854569662\n",
      "resetting env. episode reward total was 8.0. running mean: -3.0846685060239656\n",
      "resetting env. episode reward total was -13.0. running mean: -3.183821820963726\n",
      "resetting env. episode reward total was -2.0. running mean: -3.1719836027540884\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2102637667265475\n",
      "resetting env. episode reward total was 5.0. running mean: -3.1281611290592823\n",
      "resetting env. episode reward total was 2.0. running mean: -3.0768795177686896\n",
      "resetting env. episode reward total was 7.0. running mean: -2.976110722591003\n",
      "resetting env. episode reward total was -17.0. running mean: -3.1163496153650927\n",
      "resetting env. episode reward total was 2.0. running mean: -3.065186119211442\n",
      "resetting env. episode reward total was -10.0. running mean: -3.1345342580193276\n",
      "resetting env. episode reward total was 3.0. running mean: -3.0731889154391343\n",
      "resetting env. episode reward total was -5.0. running mean: -3.092457026284743\n",
      "resetting env. episode reward total was -6.0. running mean: -3.1215324560218956\n",
      "resetting env. episode reward total was 4.0. running mean: -3.0503171314616764\n",
      "resetting env. episode reward total was -1.0. running mean: -3.0298139601470595\n",
      "resetting env. episode reward total was -5.0. running mean: -3.049515820545589\n",
      "resetting env. episode reward total was -4.0. running mean: -3.059020662340133\n",
      "resetting env. episode reward total was -1.0. running mean: -3.0384304557167314\n",
      "resetting env. episode reward total was -9.0. running mean: -3.098046151159564\n",
      "resetting env. episode reward total was -5.0. running mean: -3.1170656896479683\n",
      "resetting env. episode reward total was 2.0. running mean: -3.0658950327514884\n",
      "resetting env. episode reward total was 6.0. running mean: -2.9752360824239736\n",
      "resetting env. episode reward total was -1.0. running mean: -2.955483721599734\n",
      "resetting env. episode reward total was -12.0. running mean: -3.0459288843837364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: -2.9454695955398993\n",
      "resetting env. episode reward total was -3.0. running mean: -2.9460148995845\n",
      "resetting env. episode reward total was -2.0. running mean: -2.9365547505886553\n",
      "resetting env. episode reward total was -1.0. running mean: -2.9171892030827684\n",
      "resetting env. episode reward total was -3.0. running mean: -2.9180173110519405\n",
      "resetting env. episode reward total was 7.0. running mean: -2.818837137941421\n",
      "resetting env. episode reward total was -8.0. running mean: -2.870648766562007\n",
      "resetting env. episode reward total was -6.0. running mean: -2.901942278896387\n",
      "resetting env. episode reward total was 1.0. running mean: -2.8629228561074234\n",
      "resetting env. episode reward total was 2.0. running mean: -2.8142936275463493\n",
      "resetting env. episode reward total was -11.0. running mean: -2.8961506912708854\n",
      "resetting env. episode reward total was -7.0. running mean: -2.9371891843581763\n",
      "resetting env. episode reward total was 8.0. running mean: -2.8278172925145943\n",
      "resetting env. episode reward total was 6.0. running mean: -2.7395391195894483\n",
      "resetting env. episode reward total was -6.0. running mean: -2.7721437283935537\n",
      "resetting env. episode reward total was -8.0. running mean: -2.8244222911096184\n",
      "resetting env. episode reward total was -11.0. running mean: -2.906178068198522\n",
      "resetting env. episode reward total was -5.0. running mean: -2.9271162875165366\n",
      "resetting env. episode reward total was -7.0. running mean: -2.967845124641371\n",
      "resetting env. episode reward total was 4.0. running mean: -2.8981666733949574\n",
      "resetting env. episode reward total was -11.0. running mean: -2.9791850066610075\n",
      "resetting env. episode reward total was 2.0. running mean: -2.9293931565943976\n",
      "resetting env. episode reward total was -9.0. running mean: -2.9900992250284535\n",
      "resetting env. episode reward total was -9.0. running mean: -3.0501982327781687\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0696962504503866\n",
      "resetting env. episode reward total was -4.0. running mean: -3.0789992879458827\n",
      "resetting env. episode reward total was -2.0. running mean: -3.0682092950664237\n",
      "resetting env. episode reward total was -6.0. running mean: -3.0975272021157596\n",
      "resetting env. episode reward total was -4.0. running mean: -3.106551930094602\n",
      "resetting env. episode reward total was -5.0. running mean: -3.1254864107936555\n",
      "resetting env. episode reward total was -7.0. running mean: -3.164231546685719\n",
      "resetting env. episode reward total was -3.0. running mean: -3.1625892312188615\n",
      "resetting env. episode reward total was 5.0. running mean: -3.080963338906673\n",
      "resetting env. episode reward total was -5.0. running mean: -3.1001537055176063\n",
      "resetting env. episode reward total was -4.0. running mean: -3.10915216846243\n",
      "resetting env. episode reward total was 8.0. running mean: -2.9980606467778057\n",
      "resetting env. episode reward total was 12.0. running mean: -2.8480800403100277\n",
      "resetting env. episode reward total was -7.0. running mean: -2.8895992399069272\n",
      "resetting env. episode reward total was -11.0. running mean: -2.9707032475078576\n",
      "resetting env. episode reward total was -12.0. running mean: -3.060996215032779\n",
      "resetting env. episode reward total was 1.0. running mean: -3.020386252882451\n",
      "resetting env. episode reward total was -14.0. running mean: -3.1301823903536268\n",
      "resetting env. episode reward total was -1.0. running mean: -3.1088805664500905\n",
      "resetting env. episode reward total was 6.0. running mean: -3.0177917607855895\n",
      "resetting env. episode reward total was 9.0. running mean: -2.8976138431777336\n",
      "resetting env. episode reward total was 1.0. running mean: -2.8586377047459566\n",
      "resetting env. episode reward total was 7.0. running mean: -2.760051327698497\n",
      "resetting env. episode reward total was 5.0. running mean: -2.6824508144215122\n",
      "resetting env. episode reward total was -5.0. running mean: -2.705626306277297\n",
      "resetting env. episode reward total was 7.0. running mean: -2.6085700432145242\n",
      "resetting env. episode reward total was -1.0. running mean: -2.5924843427823787\n",
      "resetting env. episode reward total was -10.0. running mean: -2.666559499354555\n",
      "resetting env. episode reward total was -10.0. running mean: -2.7398939043610095\n",
      "resetting env. episode reward total was -10.0. running mean: -2.8124949653173994\n",
      "resetting env. episode reward total was 5.0. running mean: -2.7343700156642257\n",
      "resetting env. episode reward total was -5.0. running mean: -2.7570263155075834\n",
      "resetting env. episode reward total was -4.0. running mean: -2.7694560523525076\n",
      "resetting env. episode reward total was -11.0. running mean: -2.851761491828982\n",
      "resetting env. episode reward total was -5.0. running mean: -2.873243876910692\n",
      "resetting env. episode reward total was 2.0. running mean: -2.824511438141585\n",
      "resetting env. episode reward total was 9.0. running mean: -2.706266323760169\n",
      "resetting env. episode reward total was 10.0. running mean: -2.5792036605225674\n",
      "resetting env. episode reward total was -9.0. running mean: -2.6434116239173417\n",
      "resetting env. episode reward total was 4.0. running mean: -2.5769775076781682\n",
      "resetting env. episode reward total was 3.0. running mean: -2.5212077326013866\n",
      "resetting env. episode reward total was -6.0. running mean: -2.555995655275373\n",
      "resetting env. episode reward total was 2.0. running mean: -2.510435698722619\n",
      "resetting env. episode reward total was -11.0. running mean: -2.5953313417353927\n",
      "resetting env. episode reward total was -7.0. running mean: -2.639378028318039\n",
      "resetting env. episode reward total was -2.0. running mean: -2.6329842480348584\n",
      "resetting env. episode reward total was -7.0. running mean: -2.6766544055545096\n",
      "resetting env. episode reward total was -9.0. running mean: -2.7398878614989646\n",
      "resetting env. episode reward total was -1.0. running mean: -2.722488982883975\n",
      "resetting env. episode reward total was -3.0. running mean: -2.725264093055135\n",
      "resetting env. episode reward total was -7.0. running mean: -2.768011452124583\n",
      "resetting env. episode reward total was 4.0. running mean: -2.700331337603337\n",
      "resetting env. episode reward total was -1.0. running mean: -2.6833280242273037\n",
      "resetting env. episode reward total was -3.0. running mean: -2.68649474398503\n",
      "resetting env. episode reward total was 8.0. running mean: -2.5796297965451798\n",
      "resetting env. episode reward total was -1.0. running mean: -2.5638334985797275\n",
      "resetting env. episode reward total was 6.0. running mean: -2.4781951635939303\n",
      "resetting env. episode reward total was 8.0. running mean: -2.373413211957991\n",
      "resetting env. episode reward total was 4.0. running mean: -2.309679079838411\n",
      "resetting env. episode reward total was 7.0. running mean: -2.216582289040027\n",
      "resetting env. episode reward total was 7.0. running mean: -2.1244164661496265\n",
      "resetting env. episode reward total was -2.0. running mean: -2.1231723014881303\n",
      "resetting env. episode reward total was -3.0. running mean: -2.1319405784732486\n",
      "resetting env. episode reward total was 12.0. running mean: -1.990621172688516\n",
      "resetting env. episode reward total was 7.0. running mean: -1.9007149609616307\n",
      "resetting env. episode reward total was -12.0. running mean: -2.0017078113520146\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9516907332384943\n",
      "resetting env. episode reward total was -4.0. running mean: -1.9721738259061095\n",
      "resetting env. episode reward total was -5.0. running mean: -2.002452087647048\n",
      "resetting env. episode reward total was -8.0. running mean: -2.0624275667705776\n",
      "resetting env. episode reward total was -2.0. running mean: -2.061803291102872\n",
      "resetting env. episode reward total was -2.0. running mean: -2.061185258191843\n",
      "resetting env. episode reward total was 6.0. running mean: -1.9805734056099245\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9307676715538251\n",
      "resetting env. episode reward total was -4.0. running mean: -1.951459994838287\n",
      "resetting env. episode reward total was -9.0. running mean: -2.021945394889904\n",
      "resetting env. episode reward total was -5.0. running mean: -2.051725940941005\n",
      "resetting env. episode reward total was -3.0. running mean: -2.061208681531595\n",
      "resetting env. episode reward total was 4.0. running mean: -2.0005965947162787\n",
      "resetting env. episode reward total was 3.0. running mean: -1.950590628769116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: -1.9810847224814248\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9312738752566105\n",
      "resetting env. episode reward total was -4.0. running mean: -1.9519611365040443\n",
      "resetting env. episode reward total was -13.0. running mean: -2.062441525139004\n",
      "resetting env. episode reward total was 3.0. running mean: -2.0118171098876143\n",
      "resetting env. episode reward total was -8.0. running mean: -2.071698938788738\n",
      "resetting env. episode reward total was 7.0. running mean: -1.9809819494008505\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9711721299068419\n",
      "resetting env. episode reward total was -7.0. running mean: -2.021460408607773\n",
      "resetting env. episode reward total was -3.0. running mean: -2.0312458045216952\n",
      "resetting env. episode reward total was -8.0. running mean: -2.0909333464764783\n",
      "resetting env. episode reward total was -3.0. running mean: -2.1000240130117134\n",
      "resetting env. episode reward total was -1.0. running mean: -2.089023772881596\n",
      "resetting env. episode reward total was -7.0. running mean: -2.13813353515278\n",
      "resetting env. episode reward total was 5.0. running mean: -2.0667521998012526\n",
      "resetting env. episode reward total was -3.0. running mean: -2.07608467780324\n",
      "resetting env. episode reward total was -3.0. running mean: -2.0853238310252076\n",
      "resetting env. episode reward total was -3.0. running mean: -2.094470592714955\n",
      "resetting env. episode reward total was -8.0. running mean: -2.1535258867878055\n",
      "resetting env. episode reward total was -5.0. running mean: -2.1819906279199275\n",
      "resetting env. episode reward total was 1.0. running mean: -2.150170721640728\n",
      "resetting env. episode reward total was -7.0. running mean: -2.1986690144243206\n",
      "resetting env. episode reward total was 2.0. running mean: -2.1566823242800774\n",
      "resetting env. episode reward total was -6.0. running mean: -2.1951155010372765\n",
      "resetting env. episode reward total was 3.0. running mean: -2.143164346026904\n",
      "resetting env. episode reward total was 4.0. running mean: -2.081732702566635\n",
      "resetting env. episode reward total was -9.0. running mean: -2.1509153755409685\n",
      "resetting env. episode reward total was 2.0. running mean: -2.1094062217855587\n",
      "resetting env. episode reward total was -7.0. running mean: -2.158312159567703\n",
      "resetting env. episode reward total was -1.0. running mean: -2.1467290379720256\n",
      "resetting env. episode reward total was 1.0. running mean: -2.1152617475923057\n",
      "resetting env. episode reward total was 4.0. running mean: -2.0541091301163825\n",
      "resetting env. episode reward total was -8.0. running mean: -2.113568038815219\n",
      "resetting env. episode reward total was -5.0. running mean: -2.1424323584270666\n",
      "resetting env. episode reward total was -1.0. running mean: -2.1310080348427958\n",
      "resetting env. episode reward total was -7.0. running mean: -2.1796979544943675\n",
      "resetting env. episode reward total was -6.0. running mean: -2.217900974949424\n",
      "resetting env. episode reward total was -5.0. running mean: -2.24572196519993\n",
      "resetting env. episode reward total was -4.0. running mean: -2.2632647455479304\n",
      "resetting env. episode reward total was -3.0. running mean: -2.270632098092451\n",
      "resetting env. episode reward total was -8.0. running mean: -2.3279257771115267\n",
      "resetting env. episode reward total was -5.0. running mean: -2.3546465193404114\n",
      "resetting env. episode reward total was -7.0. running mean: -2.401100054147007\n",
      "resetting env. episode reward total was -2.0. running mean: -2.3970890536055367\n",
      "resetting env. episode reward total was 3.0. running mean: -2.3431181630694815\n",
      "resetting env. episode reward total was -16.0. running mean: -2.4796869814387867\n",
      "resetting env. episode reward total was -3.0. running mean: -2.4848901116243987\n",
      "resetting env. episode reward total was -7.0. running mean: -2.5300412105081547\n",
      "resetting env. episode reward total was 2.0. running mean: -2.484740798403073\n",
      "resetting env. episode reward total was -6.0. running mean: -2.519893390419042\n",
      "resetting env. episode reward total was -11.0. running mean: -2.6046944565148515\n",
      "resetting env. episode reward total was 7.0. running mean: -2.5086475119497034\n",
      "resetting env. episode reward total was 2.0. running mean: -2.4635610368302063\n",
      "resetting env. episode reward total was -7.0. running mean: -2.508925426461904\n",
      "resetting env. episode reward total was -3.0. running mean: -2.513836172197285\n",
      "resetting env. episode reward total was -8.0. running mean: -2.568697810475312\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5930108323705587\n",
      "resetting env. episode reward total was -4.0. running mean: -2.607080724046853\n",
      "resetting env. episode reward total was -9.0. running mean: -2.6710099168063843\n",
      "resetting env. episode reward total was -9.0. running mean: -2.73429981763832\n",
      "resetting env. episode reward total was -9.0. running mean: -2.7969568194619367\n",
      "resetting env. episode reward total was -5.0. running mean: -2.818987251267317\n",
      "resetting env. episode reward total was 6.0. running mean: -2.730797378754644\n",
      "resetting env. episode reward total was 7.0. running mean: -2.6334894049670976\n",
      "resetting env. episode reward total was -3.0. running mean: -2.6371545109174264\n",
      "resetting env. episode reward total was 2.0. running mean: -2.590782965808252\n",
      "resetting env. episode reward total was -8.0. running mean: -2.6448751361501697\n",
      "resetting env. episode reward total was -10.0. running mean: -2.718426384788668\n",
      "resetting env. episode reward total was -3.0. running mean: -2.721242120940781\n",
      "resetting env. episode reward total was 2.0. running mean: -2.6740296997313733\n",
      "resetting env. episode reward total was -5.0. running mean: -2.6972894027340595\n",
      "resetting env. episode reward total was 8.0. running mean: -2.5903165087067186\n",
      "resetting env. episode reward total was -2.0. running mean: -2.5844133436196515\n",
      "resetting env. episode reward total was -9.0. running mean: -2.648569210183455\n",
      "resetting env. episode reward total was -1.0. running mean: -2.63208351808162\n",
      "resetting env. episode reward total was 6.0. running mean: -2.5457626829008038\n",
      "resetting env. episode reward total was 1.0. running mean: -2.510305056071796\n",
      "resetting env. episode reward total was -1.0. running mean: -2.4952020055110777\n",
      "resetting env. episode reward total was -2.0. running mean: -2.490249985455967\n",
      "resetting env. episode reward total was -4.0. running mean: -2.5053474856014075\n",
      "resetting env. episode reward total was 8.0. running mean: -2.400294010745393\n",
      "resetting env. episode reward total was -2.0. running mean: -2.3962910706379392\n",
      "resetting env. episode reward total was -9.0. running mean: -2.46232815993156\n",
      "resetting env. episode reward total was 7.0. running mean: -2.3677048783322445\n",
      "resetting env. episode reward total was -4.0. running mean: -2.384027829548922\n",
      "resetting env. episode reward total was -2.0. running mean: -2.380187551253433\n",
      "resetting env. episode reward total was 3.0. running mean: -2.326385675740899\n",
      "resetting env. episode reward total was 6.0. running mean: -2.24312181898349\n",
      "resetting env. episode reward total was -15.0. running mean: -2.370690600793655\n",
      "resetting env. episode reward total was -13.0. running mean: -2.4769836947857184\n",
      "resetting env. episode reward total was 2.0. running mean: -2.432213857837861\n",
      "resetting env. episode reward total was -13.0. running mean: -2.5378917192594823\n",
      "resetting env. episode reward total was -7.0. running mean: -2.5825128020668875\n",
      "resetting env. episode reward total was -10.0. running mean: -2.6566876740462186\n",
      "resetting env. episode reward total was -13.0. running mean: -2.760120797305756\n",
      "resetting env. episode reward total was 5.0. running mean: -2.6825195893326987\n",
      "resetting env. episode reward total was -11.0. running mean: -2.7656943934393716\n",
      "resetting env. episode reward total was -6.0. running mean: -2.798037449504978\n",
      "resetting env. episode reward total was -8.0. running mean: -2.850057075009928\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8515565042598285\n",
      "resetting env. episode reward total was -1.0. running mean: -2.83304093921723\n",
      "resetting env. episode reward total was -9.0. running mean: -2.894710529825058\n",
      "resetting env. episode reward total was -15.0. running mean: -3.0157634245268072\n",
      "resetting env. episode reward total was -2.0. running mean: -3.005605790281539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: -2.9855497323787232\n",
      "resetting env. episode reward total was -11.0. running mean: -3.0656942350549357\n",
      "resetting env. episode reward total was 1.0. running mean: -3.0250372927043867\n",
      "resetting env. episode reward total was -6.0. running mean: -3.0547869197773427\n",
      "resetting env. episode reward total was -10.0. running mean: -3.124239050579569\n",
      "resetting env. episode reward total was -6.0. running mean: -3.1529966600737733\n",
      "resetting env. episode reward total was -8.0. running mean: -3.201466693473036\n",
      "resetting env. episode reward total was -8.0. running mean: -3.2494520265383056\n",
      "resetting env. episode reward total was -13.0. running mean: -3.3469575062729224\n",
      "resetting env. episode reward total was -7.0. running mean: -3.383487931210193\n",
      "resetting env. episode reward total was -4.0. running mean: -3.389653051898091\n",
      "resetting env. episode reward total was -4.0. running mean: -3.39575652137911\n",
      "resetting env. episode reward total was -3.0. running mean: -3.3917989561653186\n",
      "resetting env. episode reward total was -7.0. running mean: -3.427880966603665\n",
      "resetting env. episode reward total was 7.0. running mean: -3.323602156937629\n",
      "resetting env. episode reward total was -3.0. running mean: -3.3203661353682525\n",
      "resetting env. episode reward total was -4.0. running mean: -3.32716247401457\n",
      "resetting env. episode reward total was 9.0. running mean: -3.2038908492744245\n",
      "resetting env. episode reward total was 3.0. running mean: -3.1418519407816805\n",
      "resetting env. episode reward total was -7.0. running mean: -3.1804334213738636\n",
      "resetting env. episode reward total was -4.0. running mean: -3.188629087160125\n",
      "resetting env. episode reward total was 2.0. running mean: -3.136742796288524\n",
      "resetting env. episode reward total was 8.0. running mean: -3.025375368325639\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0451216146423823\n",
      "resetting env. episode reward total was 10.0. running mean: -2.9146703984959585\n",
      "resetting env. episode reward total was -9.0. running mean: -2.975523694510999\n",
      "resetting env. episode reward total was -7.0. running mean: -3.0157684575658887\n",
      "resetting env. episode reward total was 1.0. running mean: -2.97561077299023\n",
      "resetting env. episode reward total was 9.0. running mean: -2.855854665260328\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8572961186077244\n",
      "resetting env. episode reward total was 2.0. running mean: -2.808723157421647\n",
      "resetting env. episode reward total was 6.0. running mean: -2.7206359258474304\n",
      "resetting env. episode reward total was -4.0. running mean: -2.7334295665889563\n",
      "resetting env. episode reward total was -1.0. running mean: -2.7160952709230664\n",
      "resetting env. episode reward total was 6.0. running mean: -2.628934318213836\n",
      "resetting env. episode reward total was -3.0. running mean: -2.632644975031697\n",
      "resetting env. episode reward total was -6.0. running mean: -2.66631852528138\n",
      "resetting env. episode reward total was 6.0. running mean: -2.5796553400285664\n",
      "resetting env. episode reward total was -2.0. running mean: -2.5738587866282807\n",
      "resetting env. episode reward total was -3.0. running mean: -2.5781201987619977\n",
      "resetting env. episode reward total was -10.0. running mean: -2.652338996774378\n",
      "resetting env. episode reward total was -2.0. running mean: -2.645815606806634\n",
      "resetting env. episode reward total was -2.0. running mean: -2.6393574507385678\n",
      "resetting env. episode reward total was -3.0. running mean: -2.642963876231182\n",
      "resetting env. episode reward total was -3.0. running mean: -2.64653423746887\n",
      "resetting env. episode reward total was -1.0. running mean: -2.630068895094181\n",
      "resetting env. episode reward total was -9.0. running mean: -2.6937682061432393\n",
      "resetting env. episode reward total was 3.0. running mean: -2.636830524081807\n",
      "resetting env. episode reward total was -3.0. running mean: -2.6404622188409888\n",
      "resetting env. episode reward total was -11.0. running mean: -2.7240575966525786\n",
      "resetting env. episode reward total was -9.0. running mean: -2.7868170206860525\n",
      "resetting env. episode reward total was -3.0. running mean: -2.788948850479192\n",
      "resetting env. episode reward total was -2.0. running mean: -2.7810593619744\n",
      "resetting env. episode reward total was -1.0. running mean: -2.763248768354656\n",
      "resetting env. episode reward total was -13.0. running mean: -2.865616280671109\n",
      "resetting env. episode reward total was -7.0. running mean: -2.906960117864398\n",
      "resetting env. episode reward total was -4.0. running mean: -2.917890516685754\n",
      "resetting env. episode reward total was -3.0. running mean: -2.9187116115188965\n",
      "resetting env. episode reward total was -6.0. running mean: -2.9495244954037076\n",
      "resetting env. episode reward total was -10.0. running mean: -3.020029250449671\n",
      "resetting env. episode reward total was -1.0. running mean: -2.999828957945174\n",
      "resetting env. episode reward total was 10.0. running mean: -2.8698306683657218\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8711323616820645\n",
      "resetting env. episode reward total was 4.0. running mean: -2.8024210380652437\n",
      "resetting env. episode reward total was 1.0. running mean: -2.7643968276845916\n",
      "resetting env. episode reward total was -7.0. running mean: -2.8067528594077453\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8086853308136677\n",
      "resetting env. episode reward total was -1.0. running mean: -2.790598477505531\n",
      "resetting env. episode reward total was -7.0. running mean: -2.8326924927304753\n",
      "resetting env. episode reward total was 1.0. running mean: -2.7943655678031707\n",
      "resetting env. episode reward total was -8.0. running mean: -2.846421912125139\n",
      "resetting env. episode reward total was -12.0. running mean: -2.9379576930038875\n",
      "resetting env. episode reward total was -11.0. running mean: -3.0185781160738485\n",
      "resetting env. episode reward total was -4.0. running mean: -3.02839233491311\n",
      "resetting env. episode reward total was 5.0. running mean: -2.948108411563979\n",
      "resetting env. episode reward total was -1.0. running mean: -2.9286273274483388\n",
      "resetting env. episode reward total was 2.0. running mean: -2.8793410541738553\n",
      "resetting env. episode reward total was -9.0. running mean: -2.9405476436321165\n",
      "resetting env. episode reward total was -4.0. running mean: -2.9511421671957954\n",
      "resetting env. episode reward total was -2.0. running mean: -2.9416307455238373\n",
      "resetting env. episode reward total was -4.0. running mean: -2.952214438068599\n",
      "resetting env. episode reward total was -5.0. running mean: -2.9726922936879125\n",
      "resetting env. episode reward total was -5.0. running mean: -2.9929653707510333\n",
      "resetting env. episode reward total was -4.0. running mean: -3.003035717043523\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0230053598730873\n",
      "resetting env. episode reward total was -4.0. running mean: -3.0327753062743565\n",
      "resetting env. episode reward total was -5.0. running mean: -3.052447553211613\n",
      "resetting env. episode reward total was -11.0. running mean: -3.1319230776794966\n",
      "resetting env. episode reward total was 2.0. running mean: -3.0806038469027017\n",
      "resetting env. episode reward total was -9.0. running mean: -3.1397978084336744\n",
      "resetting env. episode reward total was -2.0. running mean: -3.1283998303493377\n",
      "resetting env. episode reward total was -5.0. running mean: -3.147115832045844\n",
      "resetting env. episode reward total was -1.0. running mean: -3.1256446737253856\n",
      "resetting env. episode reward total was -8.0. running mean: -3.174388226988132\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2126443447182504\n",
      "resetting env. episode reward total was -4.0. running mean: -3.220517901271068\n",
      "resetting env. episode reward total was -8.0. running mean: -3.2683127222583575\n",
      "resetting env. episode reward total was 5.0. running mean: -3.185629595035774\n",
      "resetting env. episode reward total was -3.0. running mean: -3.183773299085416\n",
      "resetting env. episode reward total was -12.0. running mean: -3.271935566094562\n",
      "resetting env. episode reward total was 3.0. running mean: -3.2092162104336164\n",
      "resetting env. episode reward total was -7.0. running mean: -3.24712404832928\n",
      "resetting env. episode reward total was -7.0. running mean: -3.284652807845987\n",
      "resetting env. episode reward total was 5.0. running mean: -3.2018062797675273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: -3.139788216969852\n",
      "resetting env. episode reward total was -2.0. running mean: -3.1283903348001534\n",
      "resetting env. episode reward total was -11.0. running mean: -3.207106431452152\n",
      "resetting env. episode reward total was -6.0. running mean: -3.2350353671376304\n",
      "resetting env. episode reward total was -1.0. running mean: -3.212685013466254\n",
      "resetting env. episode reward total was -3.0. running mean: -3.210558163331591\n",
      "resetting env. episode reward total was -5.0. running mean: -3.228452581698275\n",
      "resetting env. episode reward total was -14.0. running mean: -3.3361680558812927\n",
      "resetting env. episode reward total was -10.0. running mean: -3.4028063753224798\n",
      "resetting env. episode reward total was -8.0. running mean: -3.448778311569255\n",
      "resetting env. episode reward total was -1.0. running mean: -3.4242905284535623\n",
      "resetting env. episode reward total was -8.0. running mean: -3.4700476231690267\n",
      "resetting env. episode reward total was 2.0. running mean: -3.415347146937336\n",
      "resetting env. episode reward total was -9.0. running mean: -3.471193675467963\n",
      "resetting env. episode reward total was -6.0. running mean: -3.496481738713283\n",
      "resetting env. episode reward total was 7.0. running mean: -3.3915169213261507\n",
      "resetting env. episode reward total was -5.0. running mean: -3.407601752112889\n",
      "resetting env. episode reward total was 7.0. running mean: -3.3035257345917604\n",
      "resetting env. episode reward total was -1.0. running mean: -3.2804904772458423\n",
      "resetting env. episode reward total was -1.0. running mean: -3.2576855724733838\n",
      "resetting env. episode reward total was -5.0. running mean: -3.2751087167486497\n",
      "resetting env. episode reward total was -2.0. running mean: -3.2623576295811634\n",
      "resetting env. episode reward total was -5.0. running mean: -3.2797340532853516\n",
      "resetting env. episode reward total was -4.0. running mean: -3.286936712752498\n",
      "resetting env. episode reward total was -6.0. running mean: -3.314067345624973\n",
      "resetting env. episode reward total was 6.0. running mean: -3.2209266721687233\n",
      "resetting env. episode reward total was -2.0. running mean: -3.208717405447036\n",
      "resetting env. episode reward total was -8.0. running mean: -3.2566302313925655\n",
      "resetting env. episode reward total was -2.0. running mean: -3.24406392907864\n",
      "resetting env. episode reward total was 4.0. running mean: -3.1716232897878536\n",
      "resetting env. episode reward total was -4.0. running mean: -3.179907056889975\n",
      "resetting env. episode reward total was -6.0. running mean: -3.208107986321075\n",
      "resetting env. episode reward total was -1.0. running mean: -3.186026906457864\n",
      "resetting env. episode reward total was -11.0. running mean: -3.264166637393285\n",
      "resetting env. episode reward total was 3.0. running mean: -3.2015249710193525\n",
      "resetting env. episode reward total was -4.0. running mean: -3.209509721309159\n",
      "resetting env. episode reward total was 1.0. running mean: -3.167414624096067\n",
      "resetting env. episode reward total was -9.0. running mean: -3.225740477855106\n",
      "resetting env. episode reward total was 5.0. running mean: -3.1434830730765553\n",
      "resetting env. episode reward total was -1.0. running mean: -3.1220482423457896\n",
      "resetting env. episode reward total was 1.0. running mean: -3.080827759922332\n",
      "resetting env. episode reward total was -9.0. running mean: -3.1400194823231082\n",
      "resetting env. episode reward total was -5.0. running mean: -3.158619287499877\n",
      "resetting env. episode reward total was -1.0. running mean: -3.137033094624878\n",
      "resetting env. episode reward total was -2.0. running mean: -3.125662763678629\n",
      "resetting env. episode reward total was -10.0. running mean: -3.1944061360418425\n",
      "resetting env. episode reward total was -3.0. running mean: -3.192462074681424\n",
      "resetting env. episode reward total was -5.0. running mean: -3.2105374539346094\n",
      "resetting env. episode reward total was -9.0. running mean: -3.268432079395263\n",
      "resetting env. episode reward total was 5.0. running mean: -3.1857477586013108\n",
      "resetting env. episode reward total was 4.0. running mean: -3.1138902810152977\n",
      "resetting env. episode reward total was 1.0. running mean: -3.0727513782051448\n",
      "resetting env. episode reward total was -6.0. running mean: -3.1020238644230935\n",
      "resetting env. episode reward total was 9.0. running mean: -2.981003625778863\n",
      "resetting env. episode reward total was -13.0. running mean: -3.081193589521074\n",
      "resetting env. episode reward total was 1.0. running mean: -3.0403816536258637\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0599778370896047\n",
      "resetting env. episode reward total was 1.0. running mean: -3.0193780587187087\n",
      "resetting env. episode reward total was 1.0. running mean: -2.979184278131522\n",
      "resetting env. episode reward total was -4.0. running mean: -2.9893924353502066\n",
      "resetting env. episode reward total was -7.0. running mean: -3.0294985109967043\n",
      "resetting env. episode reward total was 3.0. running mean: -2.9692035258867375\n",
      "resetting env. episode reward total was 2.0. running mean: -2.9195114906278703\n",
      "resetting env. episode reward total was -15.0. running mean: -3.0403163757215914\n",
      "resetting env. episode reward total was -8.0. running mean: -3.0899132119643755\n",
      "resetting env. episode reward total was -2.0. running mean: -3.0790140798447316\n",
      "resetting env. episode reward total was -14.0. running mean: -3.1882239390462845\n",
      "resetting env. episode reward total was -1.0. running mean: -3.1663416996558214\n",
      "resetting env. episode reward total was 5.0. running mean: -3.0846782826592634\n",
      "resetting env. episode reward total was -4.0. running mean: -3.0938314998326706\n",
      "resetting env. episode reward total was -3.0. running mean: -3.0928931848343435\n",
      "resetting env. episode reward total was -3.0. running mean: -3.0919642529859996\n",
      "resetting env. episode reward total was 7.0. running mean: -2.99104461045614\n",
      "resetting env. episode reward total was -10.0. running mean: -3.0611341643515786\n",
      "resetting env. episode reward total was -6.0. running mean: -3.090522822708063\n",
      "resetting env. episode reward total was 1.0. running mean: -3.0496175944809827\n",
      "resetting env. episode reward total was 3.0. running mean: -2.989121418536173\n",
      "resetting env. episode reward total was 1.0. running mean: -2.949230204350812\n",
      "resetting env. episode reward total was -4.0. running mean: -2.9597379023073036\n",
      "resetting env. episode reward total was 10.0. running mean: -2.8301405232842303\n",
      "resetting env. episode reward total was -12.0. running mean: -2.921839118051388\n",
      "resetting env. episode reward total was -10.0. running mean: -2.992620726870874\n",
      "resetting env. episode reward total was -5.0. running mean: -3.012694519602165\n",
      "resetting env. episode reward total was -7.0. running mean: -3.0525675744061433\n",
      "resetting env. episode reward total was -4.0. running mean: -3.062041898662082\n",
      "resetting env. episode reward total was 6.0. running mean: -2.971421479675461\n",
      "resetting env. episode reward total was -3.0. running mean: -2.971707264878706\n",
      "resetting env. episode reward total was 2.0. running mean: -2.9219901922299187\n",
      "resetting env. episode reward total was 2.0. running mean: -2.8727702903076193\n",
      "resetting env. episode reward total was -10.0. running mean: -2.9440425874045433\n",
      "resetting env. episode reward total was -6.0. running mean: -2.974602161530498\n",
      "resetting env. episode reward total was -5.0. running mean: -2.9948561399151927\n",
      "resetting env. episode reward total was -16.0. running mean: -3.1249075785160407\n",
      "resetting env. episode reward total was 4.0. running mean: -3.0536585027308805\n",
      "resetting env. episode reward total was -8.0. running mean: -3.1031219177035716\n",
      "resetting env. episode reward total was 12.0. running mean: -2.952090698526536\n",
      "resetting env. episode reward total was -7.0. running mean: -2.9925697915412703\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0126440936258576\n",
      "resetting env. episode reward total was -10.0. running mean: -3.082517652689599\n",
      "resetting env. episode reward total was -1.0. running mean: -3.061692476162703\n",
      "resetting env. episode reward total was 1.0. running mean: -3.021075551401076\n",
      "resetting env. episode reward total was 1.0. running mean: -2.9808647958870655\n",
      "resetting env. episode reward total was 2.0. running mean: -2.931056147928195\n",
      "resetting env. episode reward total was -11.0. running mean: -3.011745586448913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: -2.951628130584424\n",
      "resetting env. episode reward total was 1.0. running mean: -2.9121118492785802\n",
      "resetting env. episode reward total was -11.0. running mean: -2.9929907307857944\n",
      "resetting env. episode reward total was -2.0. running mean: -2.9830608234779366\n",
      "resetting env. episode reward total was -9.0. running mean: -3.043230215243157\n",
      "resetting env. episode reward total was 3.0. running mean: -2.9827979130907254\n",
      "resetting env. episode reward total was 8.0. running mean: -2.8729699339598183\n",
      "resetting env. episode reward total was -6.0. running mean: -2.9042402346202203\n",
      "resetting env. episode reward total was 3.0. running mean: -2.8451978322740183\n",
      "resetting env. episode reward total was 5.0. running mean: -2.7667458539512784\n",
      "resetting env. episode reward total was -9.0. running mean: -2.8290783954117655\n",
      "resetting env. episode reward total was -12.0. running mean: -2.920787611457648\n",
      "resetting env. episode reward total was -7.0. running mean: -2.9615797353430713\n",
      "resetting env. episode reward total was -13.0. running mean: -3.0619639379896406\n",
      "resetting env. episode reward total was -7.0. running mean: -3.101344298609744\n",
      "resetting env. episode reward total was -11.0. running mean: -3.1803308556236467\n",
      "resetting env. episode reward total was -8.0. running mean: -3.22852754706741\n",
      "resetting env. episode reward total was 2.0. running mean: -3.176242271596736\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2144798488807687\n",
      "resetting env. episode reward total was -5.0. running mean: -3.232335050391961\n",
      "resetting env. episode reward total was -10.0. running mean: -3.3000116998880413\n",
      "resetting env. episode reward total was -11.0. running mean: -3.377011582889161\n",
      "resetting env. episode reward total was -12.0. running mean: -3.4632414670602696\n",
      "resetting env. episode reward total was -11.0. running mean: -3.538609052389667\n",
      "resetting env. episode reward total was -10.0. running mean: -3.6032229618657703\n",
      "resetting env. episode reward total was -12.0. running mean: -3.6871907322471125\n",
      "resetting env. episode reward total was -7.0. running mean: -3.7203188249246413\n",
      "resetting env. episode reward total was -7.0. running mean: -3.753115636675395\n",
      "resetting env. episode reward total was -6.0. running mean: -3.7755844803086407\n",
      "resetting env. episode reward total was 4.0. running mean: -3.6978286355055543\n",
      "resetting env. episode reward total was -1.0. running mean: -3.6708503491504985\n",
      "resetting env. episode reward total was -5.0. running mean: -3.6841418456589934\n",
      "resetting env. episode reward total was -3.0. running mean: -3.677300427202403\n",
      "resetting env. episode reward total was -5.0. running mean: -3.6905274229303786\n",
      "resetting env. episode reward total was -6.0. running mean: -3.713622148701075\n",
      "resetting env. episode reward total was -3.0. running mean: -3.706485927214064\n",
      "resetting env. episode reward total was -6.0. running mean: -3.7294210679419235\n",
      "resetting env. episode reward total was -3.0. running mean: -3.722126857262504\n",
      "resetting env. episode reward total was -6.0. running mean: -3.7449055886898788\n",
      "resetting env. episode reward total was -3.0. running mean: -3.73745653280298\n",
      "resetting env. episode reward total was -11.0. running mean: -3.8100819674749498\n",
      "resetting env. episode reward total was -1.0. running mean: -3.7819811478002\n",
      "resetting env. episode reward total was -2.0. running mean: -3.764161336322198\n",
      "resetting env. episode reward total was -6.0. running mean: -3.7865197229589764\n",
      "resetting env. episode reward total was 5.0. running mean: -3.698654525729387\n",
      "resetting env. episode reward total was -9.0. running mean: -3.751667980472093\n",
      "resetting env. episode reward total was -5.0. running mean: -3.764151300667372\n",
      "resetting env. episode reward total was 12.0. running mean: -3.606509787660698\n",
      "resetting env. episode reward total was -1.0. running mean: -3.5804446897840907\n",
      "resetting env. episode reward total was 5.0. running mean: -3.4946402428862497\n",
      "resetting env. episode reward total was -7.0. running mean: -3.529693840457387\n",
      "resetting env. episode reward total was -2.0. running mean: -3.5143969020528134\n",
      "resetting env. episode reward total was -11.0. running mean: -3.5892529330322853\n",
      "resetting env. episode reward total was -9.0. running mean: -3.6433604037019625\n",
      "resetting env. episode reward total was -1.0. running mean: -3.6169267996649426\n",
      "resetting env. episode reward total was -7.0. running mean: -3.650757531668293\n",
      "resetting env. episode reward total was -1.0. running mean: -3.6242499563516097\n",
      "resetting env. episode reward total was 6.0. running mean: -3.5280074567880937\n",
      "resetting env. episode reward total was 1.0. running mean: -3.482727382220213\n",
      "resetting env. episode reward total was 1.0. running mean: -3.437900108398011\n",
      "resetting env. episode reward total was 5.0. running mean: -3.353521107314031\n",
      "resetting env. episode reward total was -7.0. running mean: -3.3899858962408906\n",
      "resetting env. episode reward total was -1.0. running mean: -3.3660860372784813\n",
      "resetting env. episode reward total was -3.0. running mean: -3.3624251769056963\n",
      "resetting env. episode reward total was -6.0. running mean: -3.3888009251366396\n",
      "resetting env. episode reward total was 7.0. running mean: -3.2849129158852732\n",
      "resetting env. episode reward total was 4.0. running mean: -3.2120637867264206\n",
      "resetting env. episode reward total was -8.0. running mean: -3.2599431488591564\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2973437173705644\n",
      "resetting env. episode reward total was 9.0. running mean: -3.1743702801968587\n",
      "resetting env. episode reward total was -12.0. running mean: -3.26262657739489\n",
      "resetting env. episode reward total was 12.0. running mean: -3.110000311620941\n",
      "resetting env. episode reward total was 5.0. running mean: -3.0289003085047317\n",
      "resetting env. episode reward total was -4.0. running mean: -3.038611305419684\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0582251923654873\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0776429404418324\n",
      "resetting env. episode reward total was 4.0. running mean: -3.006866511037414\n",
      "resetting env. episode reward total was -3.0. running mean: -3.0067978459270397\n",
      "resetting env. episode reward total was 4.0. running mean: -2.9367298674677693\n",
      "resetting env. episode reward total was 2.0. running mean: -2.8873625687930917\n",
      "resetting env. episode reward total was 3.0. running mean: -2.828488943105161\n",
      "resetting env. episode reward total was 12.0. running mean: -2.6802040536741094\n",
      "resetting env. episode reward total was -3.0. running mean: -2.683402013137368\n",
      "resetting env. episode reward total was -6.0. running mean: -2.7165679930059943\n",
      "resetting env. episode reward total was 3.0. running mean: -2.6594023130759346\n",
      "resetting env. episode reward total was 7.0. running mean: -2.5628082899451754\n",
      "resetting env. episode reward total was 7.0. running mean: -2.4671802070457236\n",
      "resetting env. episode reward total was -12.0. running mean: -2.5625084049752664\n",
      "resetting env. episode reward total was -1.0. running mean: -2.5468833209255135\n",
      "resetting env. episode reward total was 9.0. running mean: -2.4314144877162587\n",
      "resetting env. episode reward total was 9.0. running mean: -2.317100342839096\n",
      "resetting env. episode reward total was -13.0. running mean: -2.423929339410705\n",
      "resetting env. episode reward total was -5.0. running mean: -2.449690046016598\n",
      "resetting env. episode reward total was 3.0. running mean: -2.395193145556432\n",
      "resetting env. episode reward total was -4.0. running mean: -2.4112412141008677\n",
      "resetting env. episode reward total was -11.0. running mean: -2.497128801959859\n",
      "resetting env. episode reward total was -16.0. running mean: -2.6321575139402604\n",
      "resetting env. episode reward total was -14.0. running mean: -2.745835938800858\n",
      "resetting env. episode reward total was -10.0. running mean: -2.8183775794128496\n",
      "resetting env. episode reward total was -4.0. running mean: -2.8301938036187213\n",
      "resetting env. episode reward total was 5.0. running mean: -2.751891865582534\n",
      "resetting env. episode reward total was -7.0. running mean: -2.7943729469267087\n",
      "resetting env. episode reward total was -4.0. running mean: -2.8064292174574414\n",
      "resetting env. episode reward total was -9.0. running mean: -2.868364925282867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: -2.919681276030038\n",
      "resetting env. episode reward total was -12.0. running mean: -3.0104844632697376\n",
      "resetting env. episode reward total was -4.0. running mean: -3.0203796186370404\n",
      "resetting env. episode reward total was 1.0. running mean: -2.9801758224506703\n",
      "resetting env. episode reward total was -1.0. running mean: -2.9603740642261633\n",
      "resetting env. episode reward total was -7.0. running mean: -3.0007703235839016\n",
      "resetting env. episode reward total was 3.0. running mean: -2.9407626203480626\n",
      "resetting env. episode reward total was 4.0. running mean: -2.871354994144582\n",
      "resetting env. episode reward total was -5.0. running mean: -2.892641444203136\n",
      "resetting env. episode reward total was -7.0. running mean: -2.933715029761104\n",
      "resetting env. episode reward total was -6.0. running mean: -2.964377879463493\n",
      "resetting env. episode reward total was -9.0. running mean: -3.0247341006688577\n",
      "resetting env. episode reward total was -7.0. running mean: -3.0644867596621688\n",
      "resetting env. episode reward total was 1.0. running mean: -3.023841892065547\n",
      "resetting env. episode reward total was -1.0. running mean: -3.0036034731448913\n",
      "resetting env. episode reward total was -4.0. running mean: -3.0135674384134425\n",
      "resetting env. episode reward total was -11.0. running mean: -3.093431764029308\n",
      "resetting env. episode reward total was -9.0. running mean: -3.152497446389015\n",
      "resetting env. episode reward total was 4.0. running mean: -3.080972471925125\n",
      "resetting env. episode reward total was 10.0. running mean: -2.9501627472058733\n",
      "resetting env. episode reward total was 4.0. running mean: -2.8806611197338143\n",
      "resetting env. episode reward total was -1.0. running mean: -2.861854508536476\n",
      "resetting env. episode reward total was 11.0. running mean: -2.7232359634511116\n",
      "resetting env. episode reward total was -10.0. running mean: -2.7960036038166005\n",
      "resetting env. episode reward total was 8.0. running mean: -2.6880435677784345\n",
      "resetting env. episode reward total was -8.0. running mean: -2.74116313210065\n",
      "resetting env. episode reward total was -8.0. running mean: -2.793751500779644\n",
      "resetting env. episode reward total was 9.0. running mean: -2.6758139857718475\n",
      "resetting env. episode reward total was -4.0. running mean: -2.689055845914129\n",
      "resetting env. episode reward total was 11.0. running mean: -2.552165287454988\n",
      "resetting env. episode reward total was 9.0. running mean: -2.436643634580438\n",
      "resetting env. episode reward total was 6.0. running mean: -2.3522771982346335\n",
      "resetting env. episode reward total was -1.0. running mean: -2.338754426252287\n",
      "resetting env. episode reward total was 8.0. running mean: -2.235366881989764\n",
      "resetting env. episode reward total was 3.0. running mean: -2.1830132131698665\n",
      "resetting env. episode reward total was -10.0. running mean: -2.261183081038168\n",
      "resetting env. episode reward total was 10.0. running mean: -2.1385712502277863\n",
      "resetting env. episode reward total was -11.0. running mean: -2.227185537725508\n",
      "resetting env. episode reward total was -7.0. running mean: -2.2749136823482528\n",
      "resetting env. episode reward total was -5.0. running mean: -2.30216454552477\n",
      "resetting env. episode reward total was -5.0. running mean: -2.329142900069522\n",
      "resetting env. episode reward total was -5.0. running mean: -2.3558514710688265\n",
      "resetting env. episode reward total was 1.0. running mean: -2.3222929563581385\n",
      "resetting env. episode reward total was -4.0. running mean: -2.3390700267945572\n",
      "resetting env. episode reward total was -2.0. running mean: -2.335679326526612\n",
      "resetting env. episode reward total was 4.0. running mean: -2.2723225332613457\n",
      "resetting env. episode reward total was -7.0. running mean: -2.319599307928732\n",
      "resetting env. episode reward total was -6.0. running mean: -2.3564033148494445\n",
      "resetting env. episode reward total was 6.0. running mean: -2.27283928170095\n",
      "resetting env. episode reward total was 2.0. running mean: -2.2301108888839405\n",
      "resetting env. episode reward total was -2.0. running mean: -2.227809779995101\n",
      "resetting env. episode reward total was -6.0. running mean: -2.2655316821951503\n",
      "resetting env. episode reward total was 1.0. running mean: -2.232876365373199\n",
      "resetting env. episode reward total was 6.0. running mean: -2.1505476017194667\n",
      "resetting env. episode reward total was -8.0. running mean: -2.209042125702272\n",
      "resetting env. episode reward total was 5.0. running mean: -2.1369517044452495\n",
      "resetting env. episode reward total was 16.0. running mean: -1.955582187400797\n",
      "resetting env. episode reward total was 4.0. running mean: -1.896026365526789\n",
      "resetting env. episode reward total was 3.0. running mean: -1.847066101871521\n",
      "resetting env. episode reward total was -7.0. running mean: -1.8985954408528058\n",
      "resetting env. episode reward total was -2.0. running mean: -1.8996094864442779\n",
      "resetting env. episode reward total was 6.0. running mean: -1.820613391579835\n",
      "resetting env. episode reward total was -9.0. running mean: -1.8924072576640367\n",
      "resetting env. episode reward total was 2.0. running mean: -1.8534831850873963\n",
      "resetting env. episode reward total was -9.0. running mean: -1.9249483532365224\n",
      "resetting env. episode reward total was -1.0. running mean: -1.915698869704157\n",
      "resetting env. episode reward total was 6.0. running mean: -1.8365418810071155\n",
      "resetting env. episode reward total was -5.0. running mean: -1.8681764621970443\n",
      "resetting env. episode reward total was 4.0. running mean: -1.8094946975750739\n",
      "resetting env. episode reward total was -2.0. running mean: -1.8113997505993231\n",
      "resetting env. episode reward total was -3.0. running mean: -1.82328575309333\n",
      "resetting env. episode reward total was -5.0. running mean: -1.8550528955623966\n",
      "resetting env. episode reward total was -9.0. running mean: -1.9265023666067727\n",
      "resetting env. episode reward total was -6.0. running mean: -1.967237342940705\n",
      "resetting env. episode reward total was -4.0. running mean: -1.987564969511298\n",
      "resetting env. episode reward total was -15.0. running mean: -2.117689319816185\n",
      "resetting env. episode reward total was 10.0. running mean: -1.9965124266180232\n",
      "resetting env. episode reward total was 5.0. running mean: -1.926547302351843\n",
      "resetting env. episode reward total was 14.0. running mean: -1.7672818293283243\n",
      "resetting env. episode reward total was 4.0. running mean: -1.709609011035041\n",
      "resetting env. episode reward total was 5.0. running mean: -1.6425129209246905\n",
      "resetting env. episode reward total was -8.0. running mean: -1.7060877917154436\n",
      "resetting env. episode reward total was -3.0. running mean: -1.7190269137982892\n",
      "resetting env. episode reward total was -8.0. running mean: -1.7818366446603064\n",
      "resetting env. episode reward total was 2.0. running mean: -1.7440182782137033\n",
      "resetting env. episode reward total was 2.0. running mean: -1.7065780954315661\n",
      "resetting env. episode reward total was -15.0. running mean: -1.8395123144772503\n",
      "resetting env. episode reward total was 8.0. running mean: -1.7411171913324777\n",
      "resetting env. episode reward total was -6.0. running mean: -1.783706019419153\n",
      "resetting env. episode reward total was 7.0. running mean: -1.6958689592249614\n",
      "resetting env. episode reward total was -11.0. running mean: -1.788910269632712\n",
      "resetting env. episode reward total was -3.0. running mean: -1.801021166936385\n",
      "resetting env. episode reward total was -5.0. running mean: -1.833010955267021\n",
      "resetting env. episode reward total was 7.0. running mean: -1.7446808457143508\n",
      "resetting env. episode reward total was -4.0. running mean: -1.7672340372572073\n",
      "resetting env. episode reward total was 2.0. running mean: -1.7295616968846352\n",
      "resetting env. episode reward total was -8.0. running mean: -1.792266079915789\n",
      "resetting env. episode reward total was 10.0. running mean: -1.674343419116631\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6875999849254648\n",
      "resetting env. episode reward total was -3.0. running mean: -1.7007239850762101\n",
      "resetting env. episode reward total was 7.0. running mean: -1.613716745225448\n",
      "resetting env. episode reward total was 9.0. running mean: -1.5075795777731933\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5225037819954614\n",
      "resetting env. episode reward total was -6.0. running mean: -1.567278744175507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: -1.5016059567337519\n",
      "resetting env. episode reward total was -8.0. running mean: -1.5665898971664145\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5809239981947503\n",
      "resetting env. episode reward total was 6.0. running mean: -1.5051147582128026\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5200636106306746\n",
      "resetting env. episode reward total was 4.0. running mean: -1.4648629745243678\n",
      "resetting env. episode reward total was -11.0. running mean: -1.5602143447791241\n",
      "resetting env. episode reward total was -2.0. running mean: -1.5646122013313328\n",
      "resetting env. episode reward total was -9.0. running mean: -1.6389660793180196\n",
      "resetting env. episode reward total was 5.0. running mean: -1.5725764185248394\n",
      "resetting env. episode reward total was -1.0. running mean: -1.566850654339591\n",
      "resetting env. episode reward total was -8.0. running mean: -1.6311821477961952\n",
      "resetting env. episode reward total was -8.0. running mean: -1.6948703263182332\n",
      "resetting env. episode reward total was -11.0. running mean: -1.787921623055051\n",
      "resetting env. episode reward total was -4.0. running mean: -1.8100424068245005\n",
      "resetting env. episode reward total was -9.0. running mean: -1.8819419827562556\n",
      "resetting env. episode reward total was 2.0. running mean: -1.843122562928693\n",
      "resetting env. episode reward total was -5.0. running mean: -1.874691337299406\n",
      "resetting env. episode reward total was 4.0. running mean: -1.815944423926412\n",
      "resetting env. episode reward total was -1.0. running mean: -1.807784979687148\n",
      "resetting env. episode reward total was -5.0. running mean: -1.8397071298902765\n",
      "resetting env. episode reward total was -9.0. running mean: -1.9113100585913738\n",
      "resetting env. episode reward total was 3.0. running mean: -1.86219695800546\n",
      "resetting env. episode reward total was -16.0. running mean: -2.0035749884254055\n",
      "resetting env. episode reward total was 8.0. running mean: -1.9035392385411514\n",
      "resetting env. episode reward total was -13.0. running mean: -2.0145038461557396\n",
      "resetting env. episode reward total was -1.0. running mean: -2.004358807694182\n",
      "resetting env. episode reward total was -7.0. running mean: -2.0543152196172403\n",
      "resetting env. episode reward total was -2.0. running mean: -2.0537720674210678\n",
      "resetting env. episode reward total was 7.0. running mean: -1.9632343467468572\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9736020032793886\n",
      "resetting env. episode reward total was -7.0. running mean: -2.0238659832465946\n",
      "resetting env. episode reward total was -12.0. running mean: -2.1236273234141287\n",
      "resetting env. episode reward total was -9.0. running mean: -2.1923910501799875\n",
      "resetting env. episode reward total was -11.0. running mean: -2.2804671396781875\n",
      "resetting env. episode reward total was 5.0. running mean: -2.2076624682814057\n",
      "resetting env. episode reward total was -9.0. running mean: -2.2755858435985914\n",
      "resetting env. episode reward total was -1.0. running mean: -2.2628299851626053\n",
      "resetting env. episode reward total was 2.0. running mean: -2.220201685310979\n",
      "resetting env. episode reward total was -6.0. running mean: -2.2579996684578694\n",
      "resetting env. episode reward total was 3.0. running mean: -2.205419671773291\n",
      "resetting env. episode reward total was -11.0. running mean: -2.2933654750555577\n",
      "resetting env. episode reward total was -4.0. running mean: -2.310431820305002\n",
      "resetting env. episode reward total was -11.0. running mean: -2.397327502101952\n",
      "resetting env. episode reward total was 8.0. running mean: -2.293354227080932\n",
      "resetting env. episode reward total was 8.0. running mean: -2.190420684810123\n",
      "resetting env. episode reward total was 3.0. running mean: -2.1385164779620216\n",
      "resetting env. episode reward total was -7.0. running mean: -2.1871313131824013\n",
      "resetting env. episode reward total was -1.0. running mean: -2.175260000050577\n",
      "resetting env. episode reward total was 4.0. running mean: -2.113507400050071\n",
      "resetting env. episode reward total was 5.0. running mean: -2.0423723260495708\n",
      "resetting env. episode reward total was 6.0. running mean: -1.9619486027890751\n",
      "resetting env. episode reward total was 2.0. running mean: -1.9223291167611842\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9331058255935725\n",
      "resetting env. episode reward total was 7.0. running mean: -1.8437747673376366\n",
      "resetting env. episode reward total was 14.0. running mean: -1.68533701966426\n",
      "resetting env. episode reward total was 1.0. running mean: -1.6584836494676174\n",
      "resetting env. episode reward total was -6.0. running mean: -1.7018988129729413\n",
      "resetting env. episode reward total was -9.0. running mean: -1.774879824843212\n",
      "resetting env. episode reward total was -6.0. running mean: -1.81713102659478\n",
      "resetting env. episode reward total was 3.0. running mean: -1.7689597163288322\n",
      "resetting env. episode reward total was 7.0. running mean: -1.6812701191655437\n",
      "resetting env. episode reward total was 7.0. running mean: -1.5944574179738882\n",
      "resetting env. episode reward total was 6.0. running mean: -1.5185128437941493\n",
      "resetting env. episode reward total was -3.0. running mean: -1.533327715356208\n",
      "resetting env. episode reward total was 7.0. running mean: -1.4479944382026457\n",
      "resetting env. episode reward total was -3.0. running mean: -1.4635144938206193\n",
      "resetting env. episode reward total was -1.0. running mean: -1.458879348882413\n",
      "resetting env. episode reward total was -6.0. running mean: -1.5042905553935888\n",
      "resetting env. episode reward total was -4.0. running mean: -1.529247649839653\n",
      "resetting env. episode reward total was -7.0. running mean: -1.5839551733412565\n",
      "resetting env. episode reward total was 8.0. running mean: -1.4881156216078437\n",
      "resetting env. episode reward total was -10.0. running mean: -1.5732344653917654\n",
      "resetting env. episode reward total was -4.0. running mean: -1.5975021207378477\n",
      "resetting env. episode reward total was -4.0. running mean: -1.6215270995304691\n",
      "resetting env. episode reward total was -2.0. running mean: -1.6253118285351644\n",
      "resetting env. episode reward total was -2.0. running mean: -1.6290587102498129\n",
      "resetting env. episode reward total was 5.0. running mean: -1.5627681231473147\n",
      "resetting env. episode reward total was -11.0. running mean: -1.6571404419158418\n",
      "resetting env. episode reward total was -1.0. running mean: -1.6505690374966833\n",
      "resetting env. episode reward total was -7.0. running mean: -1.7040633471217166\n",
      "resetting env. episode reward total was -11.0. running mean: -1.7970227136504995\n",
      "resetting env. episode reward total was -7.0. running mean: -1.8490524865139946\n",
      "resetting env. episode reward total was 3.0. running mean: -1.8005619616488546\n",
      "resetting env. episode reward total was -2.0. running mean: -1.802556342032366\n",
      "resetting env. episode reward total was 4.0. running mean: -1.7445307786120423\n",
      "resetting env. episode reward total was -5.0. running mean: -1.7770854708259218\n",
      "resetting env. episode reward total was -7.0. running mean: -1.8293146161176626\n",
      "resetting env. episode reward total was -11.0. running mean: -1.921021469956486\n",
      "resetting env. episode reward total was -6.0. running mean: -1.9618112552569211\n",
      "resetting env. episode reward total was 7.0. running mean: -1.8721931427043519\n",
      "resetting env. episode reward total was -9.0. running mean: -1.9434712112773085\n",
      "resetting env. episode reward total was -13.0. running mean: -2.0540364991645355\n",
      "resetting env. episode reward total was 5.0. running mean: -1.98349613417289\n",
      "resetting env. episode reward total was 4.0. running mean: -1.923661172831161\n",
      "resetting env. episode reward total was -5.0. running mean: -1.9544245611028495\n",
      "resetting env. episode reward total was -15.0. running mean: -2.084880315491821\n",
      "resetting env. episode reward total was -7.0. running mean: -2.134031512336903\n",
      "resetting env. episode reward total was 5.0. running mean: -2.062691197213534\n",
      "resetting env. episode reward total was 1.0. running mean: -2.032064285241399\n",
      "resetting env. episode reward total was -2.0. running mean: -2.031743642388985\n",
      "resetting env. episode reward total was -3.0. running mean: -2.041426205965095\n",
      "resetting env. episode reward total was -8.0. running mean: -2.101011943905444\n",
      "resetting env. episode reward total was -14.0. running mean: -2.2200018244663897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: -2.2478018062217258\n",
      "resetting env. episode reward total was -2.0. running mean: -2.2453237881595083\n",
      "resetting env. episode reward total was 9.0. running mean: -2.1328705502779135\n",
      "resetting env. episode reward total was -12.0. running mean: -2.2315418447751343\n",
      "resetting env. episode reward total was -3.0. running mean: -2.2392264263273827\n",
      "resetting env. episode reward total was -8.0. running mean: -2.296834162064109\n",
      "resetting env. episode reward total was 6.0. running mean: -2.2138658204434676\n",
      "resetting env. episode reward total was -6.0. running mean: -2.251727162239033\n",
      "resetting env. episode reward total was -10.0. running mean: -2.3292098906166427\n",
      "resetting env. episode reward total was -1.0. running mean: -2.315917791710476\n",
      "resetting env. episode reward total was -12.0. running mean: -2.4127586137933714\n",
      "resetting env. episode reward total was 9.0. running mean: -2.298631027655438\n",
      "resetting env. episode reward total was -2.0. running mean: -2.2956447173788836\n",
      "resetting env. episode reward total was -6.0. running mean: -2.332688270205095\n",
      "resetting env. episode reward total was -8.0. running mean: -2.389361387503044\n",
      "resetting env. episode reward total was -7.0. running mean: -2.4354677736280133\n",
      "resetting env. episode reward total was -5.0. running mean: -2.461113095891733\n",
      "resetting env. episode reward total was 2.0. running mean: -2.4165019649328157\n",
      "resetting env. episode reward total was 1.0. running mean: -2.3823369452834875\n",
      "resetting env. episode reward total was 3.0. running mean: -2.328513575830653\n",
      "resetting env. episode reward total was -5.0. running mean: -2.3552284400723464\n",
      "resetting env. episode reward total was 5.0. running mean: -2.281676155671623\n",
      "resetting env. episode reward total was -5.0. running mean: -2.308859394114907\n",
      "resetting env. episode reward total was -7.0. running mean: -2.3557708001737576\n",
      "resetting env. episode reward total was -2.0. running mean: -2.35221309217202\n",
      "resetting env. episode reward total was -5.0. running mean: -2.3786909612502996\n",
      "resetting env. episode reward total was -3.0. running mean: -2.3849040516377964\n",
      "resetting env. episode reward total was -7.0. running mean: -2.431055011121418\n",
      "resetting env. episode reward total was -5.0. running mean: -2.456744461010204\n",
      "resetting env. episode reward total was 8.0. running mean: -2.352177016400102\n",
      "resetting env. episode reward total was -7.0. running mean: -2.3986552462361006\n",
      "resetting env. episode reward total was 7.0. running mean: -2.3046686937737397\n",
      "resetting env. episode reward total was -6.0. running mean: -2.3416220068360025\n",
      "resetting env. episode reward total was -9.0. running mean: -2.4082057867676423\n",
      "resetting env. episode reward total was -9.0. running mean: -2.474123728899966\n",
      "resetting env. episode reward total was -6.0. running mean: -2.509382491610966\n",
      "resetting env. episode reward total was -12.0. running mean: -2.6042886666948566\n",
      "resetting env. episode reward total was -3.0. running mean: -2.6082457800279077\n",
      "resetting env. episode reward total was 7.0. running mean: -2.5121633222276287\n",
      "resetting env. episode reward total was -8.0. running mean: -2.5670416890053525\n",
      "resetting env. episode reward total was -10.0. running mean: -2.641371272115299\n",
      "resetting env. episode reward total was 3.0. running mean: -2.5849575593941463\n",
      "resetting env. episode reward total was -10.0. running mean: -2.659107983800205\n",
      "resetting env. episode reward total was -9.0. running mean: -2.7225169039622026\n",
      "resetting env. episode reward total was -3.0. running mean: -2.7252917349225805\n",
      "resetting env. episode reward total was -12.0. running mean: -2.818038817573355\n",
      "resetting env. episode reward total was -11.0. running mean: -2.899858429397621\n",
      "resetting env. episode reward total was -5.0. running mean: -2.9208598451036445\n",
      "resetting env. episode reward total was -3.0. running mean: -2.921651246652608\n",
      "resetting env. episode reward total was 5.0. running mean: -2.842434734186082\n",
      "resetting env. episode reward total was -2.0. running mean: -2.8340103868442212\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8356702829757787\n",
      "resetting env. episode reward total was -5.0. running mean: -2.8573135801460205\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8387404443445603\n",
      "resetting env. episode reward total was 9.0. running mean: -2.7203530399011147\n",
      "resetting env. episode reward total was -3.0. running mean: -2.7231495095021034\n",
      "resetting env. episode reward total was -2.0. running mean: -2.7159180144070825\n",
      "resetting env. episode reward total was 10.0. running mean: -2.5887588342630115\n",
      "resetting env. episode reward total was 9.0. running mean: -2.4728712459203814\n",
      "resetting env. episode reward total was 3.0. running mean: -2.418142533461178\n",
      "resetting env. episode reward total was -8.0. running mean: -2.473961108126566\n",
      "resetting env. episode reward total was -4.0. running mean: -2.4892214970453\n",
      "resetting env. episode reward total was 2.0. running mean: -2.4443292820748472\n",
      "resetting env. episode reward total was 10.0. running mean: -2.319885989254099\n",
      "resetting env. episode reward total was 8.0. running mean: -2.2166871293615578\n",
      "resetting env. episode reward total was 5.0. running mean: -2.1445202580679426\n",
      "resetting env. episode reward total was 1.0. running mean: -2.1130750554872635\n",
      "resetting env. episode reward total was 5.0. running mean: -2.041944304932391\n",
      "resetting env. episode reward total was 2.0. running mean: -2.001524861883067\n",
      "resetting env. episode reward total was -6.0. running mean: -2.0415096132642363\n",
      "resetting env. episode reward total was -1.0. running mean: -2.0310945171315935\n",
      "resetting env. episode reward total was -1.0. running mean: -2.020783571960277\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9705757362406742\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9208699788782675\n",
      "resetting env. episode reward total was -9.0. running mean: -1.991661279089485\n",
      "resetting env. episode reward total was 8.0. running mean: -1.89174466629859\n",
      "resetting env. episode reward total was 8.0. running mean: -1.7928272196356039\n",
      "resetting env. episode reward total was 9.0. running mean: -1.6848989474392477\n",
      "resetting env. episode reward total was -13.0. running mean: -1.7980499579648552\n",
      "resetting env. episode reward total was -8.0. running mean: -1.8600694583852067\n",
      "resetting env. episode reward total was -2.0. running mean: -1.8614687638013545\n",
      "resetting env. episode reward total was -7.0. running mean: -1.912854076163341\n",
      "resetting env. episode reward total was -7.0. running mean: -1.9637255354017076\n",
      "resetting env. episode reward total was 9.0. running mean: -1.8540882800476903\n",
      "resetting env. episode reward total was -6.0. running mean: -1.8955473972472134\n",
      "resetting env. episode reward total was -10.0. running mean: -1.9765919232747413\n",
      "resetting env. episode reward total was 12.0. running mean: -1.8368260040419937\n",
      "resetting env. episode reward total was 8.0. running mean: -1.7384577440015736\n",
      "resetting env. episode reward total was 8.0. running mean: -1.6410731665615579\n",
      "resetting env. episode reward total was 8.0. running mean: -1.5446624348959421\n",
      "resetting env. episode reward total was 12.0. running mean: -1.4092158105469825\n",
      "resetting env. episode reward total was -7.0. running mean: -1.4651236524415128\n",
      "resetting env. episode reward total was 4.0. running mean: -1.4104724159170976\n",
      "resetting env. episode reward total was 2.0. running mean: -1.3763676917579266\n",
      "resetting env. episode reward total was 3.0. running mean: -1.3326040148403473\n",
      "resetting env. episode reward total was -7.0. running mean: -1.389277974691944\n",
      "resetting env. episode reward total was 4.0. running mean: -1.3353851949450244\n",
      "resetting env. episode reward total was 9.0. running mean: -1.232031342995574\n",
      "resetting env. episode reward total was 6.0. running mean: -1.1597110295656183\n",
      "resetting env. episode reward total was -5.0. running mean: -1.1981139192699621\n",
      "resetting env. episode reward total was -3.0. running mean: -1.2161327800772626\n",
      "resetting env. episode reward total was 12.0. running mean: -1.08397145227649\n",
      "resetting env. episode reward total was 8.0. running mean: -0.9931317377537251\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9932004203761878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: -0.973268416172426\n",
      "resetting env. episode reward total was 2.0. running mean: -0.9435357320107017\n",
      "resetting env. episode reward total was 14.0. running mean: -0.7941003746905947\n",
      "resetting env. episode reward total was -1.0. running mean: -0.7961593709436887\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8481977772342517\n",
      "resetting env. episode reward total was 6.0. running mean: -0.7797157994619093\n",
      "resetting env. episode reward total was -1.0. running mean: -0.7819186414672902\n",
      "resetting env. episode reward total was 4.0. running mean: -0.7340994550526172\n",
      "resetting env. episode reward total was 8.0. running mean: -0.6467584605020911\n",
      "resetting env. episode reward total was -10.0. running mean: -0.7402908758970701\n",
      "resetting env. episode reward total was 2.0. running mean: -0.7128879671380993\n",
      "resetting env. episode reward total was 1.0. running mean: -0.6957590874667183\n",
      "resetting env. episode reward total was 8.0. running mean: -0.6088014965920512\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6527134816261307\n",
      "resetting env. episode reward total was 14.0. running mean: -0.5061863468098694\n",
      "resetting env. episode reward total was 2.0. running mean: -0.4811244833417707\n",
      "resetting env. episode reward total was -3.0. running mean: -0.506313238508353\n",
      "resetting env. episode reward total was 5.0. running mean: -0.4512501061232695\n",
      "resetting env. episode reward total was 6.0. running mean: -0.3867376050620368\n",
      "resetting env. episode reward total was 7.0. running mean: -0.3128702290114164\n",
      "resetting env. episode reward total was -4.0. running mean: -0.3497415267213022\n",
      "resetting env. episode reward total was -3.0. running mean: -0.3762441114540892\n",
      "resetting env. episode reward total was 6.0. running mean: -0.3124816703395483\n",
      "resetting env. episode reward total was -5.0. running mean: -0.35935685363615283\n",
      "resetting env. episode reward total was 4.0. running mean: -0.3157632850997913\n",
      "resetting env. episode reward total was -1.0. running mean: -0.3226056522487934\n",
      "resetting env. episode reward total was 3.0. running mean: -0.28937959572630545\n",
      "resetting env. episode reward total was -5.0. running mean: -0.33648579976904236\n",
      "resetting env. episode reward total was 11.0. running mean: -0.22312094177135194\n",
      "resetting env. episode reward total was 6.0. running mean: -0.16088973235363843\n",
      "resetting env. episode reward total was 5.0. running mean: -0.10928083503010204\n",
      "resetting env. episode reward total was 13.0. running mean: 0.02181197332019899\n",
      "resetting env. episode reward total was 5.0. running mean: 0.071593853586997\n",
      "resetting env. episode reward total was 7.0. running mean: 0.14087791505112704\n",
      "resetting env. episode reward total was -9.0. running mean: 0.049469135900615774\n",
      "resetting env. episode reward total was 11.0. running mean: 0.1589744445416096\n",
      "resetting env. episode reward total was -1.0. running mean: 0.1473847000961935\n",
      "resetting env. episode reward total was -5.0. running mean: 0.09591085309523158\n",
      "resetting env. episode reward total was 3.0. running mean: 0.12495174456427927\n",
      "resetting env. episode reward total was 6.0. running mean: 0.18370222711863649\n",
      "resetting env. episode reward total was -10.0. running mean: 0.08186520484745011\n",
      "resetting env. episode reward total was 3.0. running mean: 0.1110465527989756\n",
      "resetting env. episode reward total was -2.0. running mean: 0.08993608727098584\n",
      "resetting env. episode reward total was 4.0. running mean: 0.12903672639827599\n",
      "resetting env. episode reward total was -8.0. running mean: 0.04774635913429322\n",
      "resetting env. episode reward total was 3.0. running mean: 0.07726889554295029\n",
      "resetting env. episode reward total was -1.0. running mean: 0.06649620658752078\n",
      "resetting env. episode reward total was -8.0. running mean: -0.01416875547835443\n",
      "resetting env. episode reward total was 8.0. running mean: 0.06597293207642911\n",
      "resetting env. episode reward total was 8.0. running mean: 0.14531320275566484\n",
      "resetting env. episode reward total was 1.0. running mean: 0.1538600707281082\n",
      "resetting env. episode reward total was 6.0. running mean: 0.2123214700208271\n",
      "resetting env. episode reward total was 7.0. running mean: 0.2801982553206188\n",
      "resetting env. episode reward total was 2.0. running mean: 0.29739627276741265\n",
      "resetting env. episode reward total was 8.0. running mean: 0.3744223100397385\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3406780869393411\n",
      "resetting env. episode reward total was 6.0. running mean: 0.3972713060699477\n",
      "resetting env. episode reward total was -1.0. running mean: 0.38329859300924823\n",
      "resetting env. episode reward total was -1.0. running mean: 0.36946560707915577\n",
      "resetting env. episode reward total was 6.0. running mean: 0.4257709510083642\n",
      "resetting env. episode reward total was 6.0. running mean: 0.48151324149828056\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5566981090832978\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6011311279924648\n",
      "resetting env. episode reward total was 11.0. running mean: 0.7051198167125402\n",
      "resetting env. episode reward total was 2.0. running mean: 0.7180686185454148\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6808879323599606\n",
      "resetting env. episode reward total was -5.0. running mean: 0.6240790530363609\n",
      "resetting env. episode reward total was 1.0. running mean: 0.6278382625059973\n",
      "resetting env. episode reward total was 11.0. running mean: 0.7315598798809373\n",
      "resetting env. episode reward total was 9.0. running mean: 0.8142442810821279\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9061018382713065\n",
      "resetting env. episode reward total was 12.0. running mean: 1.0170408198885934\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0568704116897074\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0663017075728103\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1256386904970823\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1543823035921115\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1328384805561904\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1115100957506285\n",
      "resetting env. episode reward total was -2.0. running mean: 1.0803949947931222\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9795910448451909\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0097951343967388\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9296971830527714\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9904002112222436\n",
      "resetting env. episode reward total was -6.0. running mean: 0.9204962091100213\n",
      "resetting env. episode reward total was -3.0. running mean: 0.881291247018921\n",
      "resetting env. episode reward total was -4.0. running mean: 0.8324783345487318\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9241535512032444\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9049120156912119\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9658628955342998\n",
      "resetting env. episode reward total was -6.0. running mean: 0.8962042665789569\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9672422239131673\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9675698016740356\n",
      "resetting env. episode reward total was -11.0. running mean: 0.8478941036572952\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8594151626207223\n",
      "resetting env. episode reward total was 16.0. running mean: 1.010821010994515\n",
      "resetting env. episode reward total was 10.0. running mean: 1.10071280088457\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1597056728757242\n",
      "resetting env. episode reward total was 11.0. running mean: 1.258108616146967\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2755275299854973\n",
      "resetting env. episode reward total was -6.0. running mean: 1.2027722546856423\n",
      "resetting env. episode reward total was 2.0. running mean: 1.210744532138786\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2486370868173982\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2661507159492242\n",
      "resetting env. episode reward total was -3.0. running mean: 1.223489208789732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: 1.1612543167018345\n",
      "resetting env. episode reward total was -1.0. running mean: 1.139641773534816\n",
      "resetting env. episode reward total was -9.0. running mean: 1.0382453557994678\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0678629022414732\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0271842732190584\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9269124304868678\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9476433061819991\n",
      "resetting env. episode reward total was -12.0. running mean: 0.8181668731201791\n",
      "resetting env. episode reward total was 9.0. running mean: 0.8999852043889772\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8609853523450874\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8923754988216366\n",
      "resetting env. episode reward total was -4.0. running mean: 0.8434517438334201\n",
      "resetting env. episode reward total was -6.0. running mean: 0.7750172263950859\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7572670541311349\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6796943835898235\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7228974397539253\n",
      "resetting env. episode reward total was -3.0. running mean: 0.685668465356386\n",
      "resetting env. episode reward total was 10.0. running mean: 0.7788117807028222\n",
      "resetting env. episode reward total was 1.0. running mean: 0.781023662895794\n",
      "resetting env. episode reward total was 2.0. running mean: 0.793213426266836\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8452812920041677\n",
      "resetting env. episode reward total was -5.0. running mean: 0.786828479084126\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7489601942932848\n",
      "resetting env. episode reward total was -8.0. running mean: 0.661470592350352\n",
      "resetting env. episode reward total was 9.0. running mean: 0.7448558864268484\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8174073275625798\n",
      "resetting env. episode reward total was 7.0. running mean: 0.8792332542869541\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8904409217440845\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8715365125266437\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8928211474013772\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9838929359273634\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9640540065680897\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9044134665024087\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8053693318373847\n",
      "resetting env. episode reward total was 15.0. running mean: 0.9473156385190109\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8478424821338209\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8493640573124827\n",
      "resetting env. episode reward total was -8.0. running mean: 0.7608704167393578\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8032617125719643\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7452290954462446\n",
      "resetting env. episode reward total was -5.0. running mean: 0.6877768044917821\n",
      "resetting env. episode reward total was -10.0. running mean: 0.5808990364468644\n",
      "resetting env. episode reward total was -11.0. running mean: 0.4650900460823957\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5004391456215718\n",
      "resetting env. episode reward total was 3.0. running mean: 0.525434754165356\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5601804066237025\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5845786025574655\n",
      "resetting env. episode reward total was 7.0. running mean: 0.6487328165318909\n",
      "resetting env. episode reward total was 9.0. running mean: 0.7322454883665719\n",
      "resetting env. episode reward total was 3.0. running mean: 0.7549230334829062\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7173738031480772\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7602000651165964\n",
      "resetting env. episode reward total was 10.0. running mean: 0.8525980644654304\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8640720838207762\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8954313629825684\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9564770493527428\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9669122788592154\n",
      "resetting env. episode reward total was 9.0. running mean: 1.0472431560706232\n",
      "resetting env. episode reward total was 6.0. running mean: 1.096770724509917\n",
      "resetting env. episode reward total was -7.0. running mean: 1.0158030172648178\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0156449870921695\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9654885372212478\n",
      "resetting env. episode reward total was -13.0. running mean: 0.8258336518490353\n",
      "resetting env. episode reward total was 1.0. running mean: 0.827575315330545\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8392995621772396\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8509065665554671\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8823975008899125\n",
      "resetting env. episode reward total was -11.0. running mean: 0.7635735258810135\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7259377906222033\n",
      "resetting env. episode reward total was 13.0. running mean: 0.8486784127159813\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9001916285888214\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8411897123029332\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8727778151799038\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8440500370281048\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7856095366578236\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7477534412912453\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7902759068783329\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8023731478095496\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8443494163314541\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8759059221681396\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9171468629464582\n",
      "resetting env. episode reward total was -8.0. running mean: 0.8279753943169936\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8696956403738237\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8909986839700855\n",
      "resetting env. episode reward total was -13.0. running mean: 0.7520886971303846\n",
      "resetting env. episode reward total was 1.0. running mean: 0.7545678101590808\n",
      "resetting env. episode reward total was -1.0. running mean: 0.73702213205749\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7796519107369152\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7618553916295461\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7342368377132505\n",
      "resetting env. episode reward total was 3.0. running mean: 0.756894469336118\n",
      "resetting env. episode reward total was -8.0. running mean: 0.6693255246427569\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5926322693963293\n",
      "resetting env. episode reward total was -1.0. running mean: 0.576705946702366\n",
      "resetting env. episode reward total was -8.0. running mean: 0.49093888723534224\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4760294983629888\n",
      "resetting env. episode reward total was 14.0. running mean: 0.611269203379359\n",
      "resetting env. episode reward total was 11.0. running mean: 0.7151565113455653\n",
      "resetting env. episode reward total was -5.0. running mean: 0.6580049462321097\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6414248967697885\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6750106478020906\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6582605413240697\n",
      "resetting env. episode reward total was 8.0. running mean: 0.731677935910829\n",
      "resetting env. episode reward total was -6.0. running mean: 0.6643611565517207\n",
      "resetting env. episode reward total was -2.0. running mean: 0.6377175449862035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 0.6713403695363415\n",
      "resetting env. episode reward total was -7.0. running mean: 0.594626965840978\n",
      "resetting env. episode reward total was 11.0. running mean: 0.6986806961825681\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6616938892207423\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5850769503285349\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5592261808252496\n",
      "resetting env. episode reward total was -14.0. running mean: 0.4136339190169971\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5194975798268271\n",
      "resetting env. episode reward total was -3.0. running mean: 0.48430260402855874\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4994595779882732\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5744649822083904\n",
      "resetting env. episode reward total was 11.0. running mean: 0.6787203323863065\n",
      "resetting env. episode reward total was 8.0. running mean: 0.7519331290624434\n",
      "resetting env. episode reward total was 5.0. running mean: 0.794413797771819\n",
      "resetting env. episode reward total was -11.0. running mean: 0.6764696597941008\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7197049631961598\n",
      "resetting env. episode reward total was 7.0. running mean: 0.7825079135641984\n",
      "resetting env. episode reward total was 9.0. running mean: 0.8646828344285563\n",
      "resetting env. episode reward total was -4.0. running mean: 0.8160360060842707\n",
      "resetting env. episode reward total was -7.0. running mean: 0.7378756460234279\n",
      "resetting env. episode reward total was 4.0. running mean: 0.7704968895631936\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7327919206675616\n",
      "resetting env. episode reward total was 13.0. running mean: 0.855464001460886\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8569093614462772\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8183402678318143\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8001568651534962\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8721552965019611\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9434337435369414\n",
      "resetting env. episode reward total was 11.0. running mean: 1.043999406101572\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0035594120405562\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9435238179201506\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9840885797409491\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9842476939435396\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9344052170041042\n",
      "resetting env. episode reward total was -5.0. running mean: 0.875061164834063\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9263105531857223\n",
      "resetting env. episode reward total was -1.0. running mean: 0.907047447653865\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8679769731773264\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8992972034455531\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8003042314110975\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7423011890969865\n",
      "resetting env. episode reward total was -9.0. running mean: 0.6448781772060167\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6284293954339565\n",
      "resetting env. episode reward total was 7.0. running mean: 0.6921451014796169\n",
      "resetting env. episode reward total was -9.0. running mean: 0.5952236504648208\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6392714139601726\n",
      "resetting env. episode reward total was -6.0. running mean: 0.5728786998205708\n",
      "resetting env. episode reward total was 9.0. running mean: 0.6571499128223651\n",
      "resetting env. episode reward total was 7.0. running mean: 0.7205784136941416\n",
      "resetting env. episode reward total was 1.0. running mean: 0.7233726295572002\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7761389032616282\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8083775142290119\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8102937390867219\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8321908016958547\n",
      "resetting env. episode reward total was -7.0. running mean: 0.7538688936788962\n",
      "resetting env. episode reward total was -8.0. running mean: 0.6663302047421072\n",
      "resetting env. episode reward total was 12.0. running mean: 0.7796669026946862\n",
      "resetting env. episode reward total was -4.0. running mean: 0.7318702336677393\n",
      "resetting env. episode reward total was -9.0. running mean: 0.6345515313310619\n",
      "resetting env. episode reward total was -4.0. running mean: 0.5882060160177512\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5623239558575737\n",
      "resetting env. episode reward total was 5.0. running mean: 0.606700716298998\n",
      "resetting env. episode reward total was -3.0. running mean: 0.570633709136008\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5749273720446479\n",
      "resetting env. episode reward total was 8.0. running mean: 0.6491780983242014\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6726863173409594\n",
      "resetting env. episode reward total was 1.0. running mean: 0.6759594541675498\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5991998596258743\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5732078610296155\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5774757824193194\n",
      "resetting env. episode reward total was 6.0. running mean: 0.6317010245951262\n",
      "resetting env. episode reward total was 6.0. running mean: 0.685384014349175\n",
      "resetting env. episode reward total was 4.0. running mean: 0.7185301742056832\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7613448724636264\n",
      "resetting env. episode reward total was -7.0. running mean: 0.68373142373899\n",
      "resetting env. episode reward total was 9.0. running mean: 0.7668941095016001\n",
      "resetting env. episode reward total was -8.0. running mean: 0.6792251684065841\n",
      "resetting env. episode reward total was 3.0. running mean: 0.7024329167225183\n",
      "resetting env. episode reward total was -6.0. running mean: 0.6354085875552931\n",
      "resetting env. episode reward total was 10.0. running mean: 0.7290545016797401\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6517639566629427\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6152463170963133\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6490938539253501\n",
      "resetting env. episode reward total was 1.0. running mean: 0.6526029153860966\n",
      "resetting env. episode reward total was -8.0. running mean: 0.5660768862322356\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5704161173699133\n",
      "resetting env. episode reward total was -11.0. running mean: 0.4547119561962142\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5401648366342521\n",
      "resetting env. episode reward total was -10.0. running mean: 0.4347631882679096\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5204155563852305\n",
      "resetting env. episode reward total was -3.0. running mean: 0.48521140082137815\n",
      "resetting env. episode reward total was -8.0. running mean: 0.40035928681316435\n",
      "resetting env. episode reward total was 3.0. running mean: 0.4263556939450327\n",
      "resetting env. episode reward total was 10.0. running mean: 0.5220921370055823\n",
      "resetting env. episode reward total was -4.0. running mean: 0.47687121563552654\n",
      "resetting env. episode reward total was 1.0. running mean: 0.4821025034791713\n",
      "resetting env. episode reward total was -8.0. running mean: 0.39728147844437955\n",
      "resetting env. episode reward total was 4.0. running mean: 0.43330866365993576\n",
      "resetting env. episode reward total was -7.0. running mean: 0.3589755770233364\n",
      "resetting env. episode reward total was -7.0. running mean: 0.285385821253103\n",
      "resetting env. episode reward total was 5.0. running mean: 0.332531963040572\n",
      "resetting env. episode reward total was -5.0. running mean: 0.27920664341016627\n",
      "resetting env. episode reward total was 11.0. running mean: 0.38641457697606457\n",
      "resetting env. episode reward total was 13.0. running mean: 0.512550431206304\n",
      "resetting env. episode reward total was -5.0. running mean: 0.4574249268942409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 0.4928506776252985\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4779221708490455\n",
      "resetting env. episode reward total was -10.0. running mean: 0.373142949140555\n",
      "resetting env. episode reward total was -11.0. running mean: 0.2594115196491495\n",
      "resetting env. episode reward total was -2.0. running mean: 0.236817404452658\n",
      "resetting env. episode reward total was 7.0. running mean: 0.30444923040813143\n",
      "resetting env. episode reward total was 9.0. running mean: 0.3914047381040501\n",
      "resetting env. episode reward total was -4.0. running mean: 0.3474906907230096\n",
      "resetting env. episode reward total was -5.0. running mean: 0.2940157838157795\n",
      "resetting env. episode reward total was 11.0. running mean: 0.40107562597762164\n",
      "resetting env. episode reward total was -8.0. running mean: 0.3170648697178454\n",
      "resetting env. episode reward total was -4.0. running mean: 0.27389422102066696\n",
      "resetting env. episode reward total was -1.0. running mean: 0.2611552788104603\n",
      "resetting env. episode reward total was 9.0. running mean: 0.3485437260223557\n",
      "resetting env. episode reward total was -10.0. running mean: 0.24505828876213218\n",
      "resetting env. episode reward total was -2.0. running mean: 0.22260770587451087\n",
      "resetting env. episode reward total was -10.0. running mean: 0.12038162881576575\n",
      "resetting env. episode reward total was -7.0. running mean: 0.049177812527608084\n",
      "resetting env. episode reward total was 4.0. running mean: 0.088686034402332\n",
      "resetting env. episode reward total was -11.0. running mean: -0.02220082594169133\n",
      "resetting env. episode reward total was 10.0. running mean: 0.07802118231772559\n",
      "resetting env. episode reward total was 11.0. running mean: 0.18724097049454835\n",
      "resetting env. episode reward total was -3.0. running mean: 0.15536856078960287\n",
      "resetting env. episode reward total was -4.0. running mean: 0.11381487518170683\n",
      "resetting env. episode reward total was -7.0. running mean: 0.04267672642988975\n",
      "resetting env. episode reward total was 2.0. running mean: 0.062249959165590854\n",
      "resetting env. episode reward total was -2.0. running mean: 0.04162745957393495\n",
      "resetting env. episode reward total was -2.0. running mean: 0.0212111849781956\n",
      "resetting env. episode reward total was 7.0. running mean: 0.09099907312841365\n",
      "resetting env. episode reward total was -2.0. running mean: 0.0700890823971295\n",
      "resetting env. episode reward total was -9.0. running mean: -0.02061180842684178\n",
      "resetting env. episode reward total was -2.0. running mean: -0.04040569034257337\n",
      "resetting env. episode reward total was 6.0. running mean: 0.019998366560852368\n",
      "resetting env. episode reward total was 6.0. running mean: 0.07979838289524384\n",
      "resetting env. episode reward total was 3.0. running mean: 0.1090003990662914\n",
      "resetting env. episode reward total was -6.0. running mean: 0.047910395075628484\n",
      "resetting env. episode reward total was -10.0. running mean: -0.05256870887512781\n",
      "resetting env. episode reward total was -14.0. running mean: -0.19204302178637656\n",
      "resetting env. episode reward total was 1.0. running mean: -0.1801225915685128\n",
      "resetting env. episode reward total was 7.0. running mean: -0.10832136565282766\n",
      "resetting env. episode reward total was 4.0. running mean: -0.06723815199629937\n",
      "resetting env. episode reward total was -6.0. running mean: -0.12656577047633638\n",
      "resetting env. episode reward total was -3.0. running mean: -0.15530011277157302\n",
      "resetting env. episode reward total was 8.0. running mean: -0.07374711164385729\n",
      "resetting env. episode reward total was 6.0. running mean: -0.013009640527418723\n",
      "resetting env. episode reward total was -11.0. running mean: -0.12287954412214454\n",
      "resetting env. episode reward total was 2.0. running mean: -0.10165074868092308\n",
      "resetting env. episode reward total was -7.0. running mean: -0.17063424119411386\n",
      "resetting env. episode reward total was -1.0. running mean: -0.17892789878217272\n",
      "resetting env. episode reward total was -2.0. running mean: -0.197138619794351\n",
      "resetting env. episode reward total was 4.0. running mean: -0.15516723359640747\n",
      "resetting env. episode reward total was -13.0. running mean: -0.2836155612604434\n",
      "resetting env. episode reward total was -1.0. running mean: -0.290779405647839\n",
      "resetting env. episode reward total was -8.0. running mean: -0.3678716115913606\n",
      "resetting env. episode reward total was -7.0. running mean: -0.43419289547544704\n",
      "resetting env. episode reward total was 2.0. running mean: -0.40985096652069253\n",
      "resetting env. episode reward total was -11.0. running mean: -0.5157524568554857\n",
      "resetting env. episode reward total was -8.0. running mean: -0.5905949322869307\n",
      "resetting env. episode reward total was 7.0. running mean: -0.5146889829640613\n",
      "resetting env. episode reward total was -12.0. running mean: -0.6295420931344207\n",
      "resetting env. episode reward total was -3.0. running mean: -0.6532466722030765\n",
      "resetting env. episode reward total was -14.0. running mean: -0.7867142054810458\n",
      "resetting env. episode reward total was -9.0. running mean: -0.8688470634262353\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9301585927919729\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9308570068640531\n",
      "resetting env. episode reward total was -13.0. running mean: -1.0515484367954127\n",
      "resetting env. episode reward total was -7.0. running mean: -1.1110329524274585\n",
      "resetting env. episode reward total was -4.0. running mean: -1.139922622903184\n",
      "resetting env. episode reward total was -5.0. running mean: -1.1785233966741522\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1967381627074107\n",
      "resetting env. episode reward total was -4.0. running mean: -1.2247707810803365\n",
      "resetting env. episode reward total was -2.0. running mean: -1.2325230732695331\n",
      "resetting env. episode reward total was -5.0. running mean: -1.2701978425368379\n",
      "resetting env. episode reward total was -13.0. running mean: -1.3874958641114694\n",
      "resetting env. episode reward total was -9.0. running mean: -1.4636209054703548\n",
      "resetting env. episode reward total was -5.0. running mean: -1.4989846964156512\n",
      "resetting env. episode reward total was -8.0. running mean: -1.5639948494514948\n",
      "resetting env. episode reward total was -4.0. running mean: -1.58835490095698\n",
      "resetting env. episode reward total was -9.0. running mean: -1.6624713519474101\n",
      "resetting env. episode reward total was -1.0. running mean: -1.655846638427936\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6892881720436568\n",
      "resetting env. episode reward total was -9.0. running mean: -1.7623952903232203\n",
      "resetting env. episode reward total was -1.0. running mean: -1.754771337419988\n",
      "resetting env. episode reward total was 10.0. running mean: -1.637223624045788\n",
      "resetting env. episode reward total was -9.0. running mean: -1.7108513878053302\n",
      "resetting env. episode reward total was -8.0. running mean: -1.773742873927277\n",
      "resetting env. episode reward total was -5.0. running mean: -1.806005445188004\n",
      "resetting env. episode reward total was -1.0. running mean: -1.797945390736124\n",
      "resetting env. episode reward total was -1.0. running mean: -1.7899659368287628\n",
      "resetting env. episode reward total was -5.0. running mean: -1.8220662774604752\n",
      "resetting env. episode reward total was -5.0. running mean: -1.8538456146858704\n",
      "resetting env. episode reward total was -9.0. running mean: -1.9253071585390118\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9360540869536218\n",
      "resetting env. episode reward total was -5.0. running mean: -1.9666935460840855\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9170266106232445\n",
      "resetting env. episode reward total was -3.0. running mean: -1.927856344517012\n",
      "resetting env. episode reward total was -11.0. running mean: -2.018577781071842\n",
      "resetting env. episode reward total was -8.0. running mean: -2.0783920032611234\n",
      "resetting env. episode reward total was 4.0. running mean: -2.017608083228512\n",
      "resetting env. episode reward total was -14.0. running mean: -2.137432002396227\n",
      "resetting env. episode reward total was -8.0. running mean: -2.196057682372265\n",
      "resetting env. episode reward total was -2.0. running mean: -2.1940971055485425\n",
      "resetting env. episode reward total was -6.0. running mean: -2.232156134493057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: -2.249834573148126\n",
      "resetting env. episode reward total was -16.0. running mean: -2.387336227416645\n",
      "resetting env. episode reward total was 3.0. running mean: -2.333462865142479\n",
      "resetting env. episode reward total was 4.0. running mean: -2.270128236491054\n",
      "resetting env. episode reward total was -11.0. running mean: -2.3574269541261432\n",
      "resetting env. episode reward total was 4.0. running mean: -2.293852684584882\n",
      "resetting env. episode reward total was -1.0. running mean: -2.280914157739033\n",
      "resetting env. episode reward total was -7.0. running mean: -2.3281050161616426\n",
      "resetting env. episode reward total was -7.0. running mean: -2.374823966000026\n",
      "resetting env. episode reward total was -4.0. running mean: -2.3910757263400257\n",
      "resetting env. episode reward total was -9.0. running mean: -2.4571649690766253\n",
      "resetting env. episode reward total was -9.0. running mean: -2.5225933193858587\n",
      "resetting env. episode reward total was -1.0. running mean: -2.507367386192\n",
      "resetting env. episode reward total was -9.0. running mean: -2.57229371233008\n",
      "resetting env. episode reward total was 10.0. running mean: -2.446570775206779\n",
      "resetting env. episode reward total was -4.0. running mean: -2.4621050674547114\n",
      "resetting env. episode reward total was -10.0. running mean: -2.5374840167801644\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5621091766123625\n",
      "resetting env. episode reward total was 4.0. running mean: -2.4964880848462387\n",
      "resetting env. episode reward total was 6.0. running mean: -2.4115232039977763\n",
      "resetting env. episode reward total was -1.0. running mean: -2.3974079719577985\n",
      "resetting env. episode reward total was 1.0. running mean: -2.3634338922382208\n",
      "resetting env. episode reward total was -9.0. running mean: -2.4297995533158385\n",
      "resetting env. episode reward total was -1.0. running mean: -2.41550155778268\n",
      "resetting env. episode reward total was -7.0. running mean: -2.461346542204853\n",
      "resetting env. episode reward total was -6.0. running mean: -2.4967330767828044\n",
      "resetting env. episode reward total was -13.0. running mean: -2.6017657460149763\n",
      "resetting env. episode reward total was -3.0. running mean: -2.6057480885548263\n",
      "resetting env. episode reward total was -2.0. running mean: -2.599690607669278\n",
      "resetting env. episode reward total was -4.0. running mean: -2.613693701592585\n",
      "resetting env. episode reward total was -5.0. running mean: -2.637556764576659\n",
      "resetting env. episode reward total was -13.0. running mean: -2.741181196930892\n",
      "resetting env. episode reward total was 10.0. running mean: -2.613769384961583\n",
      "resetting env. episode reward total was 5.0. running mean: -2.5376316911119674\n",
      "resetting env. episode reward total was 6.0. running mean: -2.4522553742008477\n",
      "resetting env. episode reward total was 7.0. running mean: -2.3577328204588395\n",
      "resetting env. episode reward total was -13.0. running mean: -2.464155492254251\n",
      "resetting env. episode reward total was 1.0. running mean: -2.4295139373317087\n",
      "resetting env. episode reward total was 2.0. running mean: -2.3852187979583914\n",
      "resetting env. episode reward total was 7.0. running mean: -2.2913666099788075\n",
      "resetting env. episode reward total was -6.0. running mean: -2.3284529438790194\n",
      "resetting env. episode reward total was -11.0. running mean: -2.4151684144402292\n",
      "resetting env. episode reward total was 3.0. running mean: -2.361016730295827\n",
      "resetting env. episode reward total was -7.0. running mean: -2.4074065629928687\n",
      "resetting env. episode reward total was 2.0. running mean: -2.36333249736294\n",
      "resetting env. episode reward total was -4.0. running mean: -2.3796991723893104\n",
      "resetting env. episode reward total was 8.0. running mean: -2.275902180665417\n",
      "resetting env. episode reward total was -3.0. running mean: -2.283143158858763\n",
      "resetting env. episode reward total was -3.0. running mean: -2.290311727270175\n",
      "resetting env. episode reward total was 8.0. running mean: -2.1874086099974734\n",
      "resetting env. episode reward total was -8.0. running mean: -2.245534523897499\n",
      "resetting env. episode reward total was 11.0. running mean: -2.113079178658524\n",
      "resetting env. episode reward total was -1.0. running mean: -2.1019483868719386\n",
      "resetting env. episode reward total was -6.0. running mean: -2.1409289030032195\n",
      "resetting env. episode reward total was -5.0. running mean: -2.169519613973187\n",
      "resetting env. episode reward total was 3.0. running mean: -2.1178244178334555\n",
      "resetting env. episode reward total was -3.0. running mean: -2.126646173655121\n",
      "resetting env. episode reward total was 1.0. running mean: -2.0953797119185698\n",
      "resetting env. episode reward total was 7.0. running mean: -2.004425914799384\n",
      "resetting env. episode reward total was -4.0. running mean: -2.02438165565139\n",
      "resetting env. episode reward total was -4.0. running mean: -2.0441378390948763\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9936964607039276\n",
      "resetting env. episode reward total was 4.0. running mean: -1.9337594960968882\n",
      "resetting env. episode reward total was 6.0. running mean: -1.8544219011359193\n",
      "resetting env. episode reward total was 2.0. running mean: -1.8158776821245601\n",
      "resetting env. episode reward total was 4.0. running mean: -1.7577189053033144\n",
      "resetting env. episode reward total was 9.0. running mean: -1.6501417162502812\n",
      "resetting env. episode reward total was 3.0. running mean: -1.6036402990877783\n",
      "resetting env. episode reward total was -7.0. running mean: -1.6576038960969006\n",
      "resetting env. episode reward total was -4.0. running mean: -1.6810278571359316\n",
      "resetting env. episode reward total was 1.0. running mean: -1.6542175785645723\n",
      "resetting env. episode reward total was 9.0. running mean: -1.5476754027789266\n",
      "resetting env. episode reward total was 6.0. running mean: -1.4721986487511372\n",
      "resetting env. episode reward total was -9.0. running mean: -1.5474766622636258\n",
      "resetting env. episode reward total was 13.0. running mean: -1.4020018956409896\n",
      "resetting env. episode reward total was -1.0. running mean: -1.3979818766845797\n",
      "resetting env. episode reward total was 2.0. running mean: -1.3640020579177339\n",
      "resetting env. episode reward total was 6.0. running mean: -1.2903620373385565\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2874584169651708\n",
      "resetting env. episode reward total was -2.0. running mean: -1.294583832795519\n",
      "resetting env. episode reward total was -2.0. running mean: -1.3016379944675638\n",
      "resetting env. episode reward total was 5.0. running mean: -1.238621614522888\n",
      "resetting env. episode reward total was 6.0. running mean: -1.1662353983776592\n",
      "resetting env. episode reward total was -8.0. running mean: -1.2345730443938827\n",
      "resetting env. episode reward total was 12.0. running mean: -1.1022273139499439\n",
      "resetting env. episode reward total was 2.0. running mean: -1.0712050408104443\n",
      "resetting env. episode reward total was 1.0. running mean: -1.05049299040234\n",
      "resetting env. episode reward total was -11.0. running mean: -1.1499880604983166\n",
      "resetting env. episode reward total was -8.0. running mean: -1.2184881798933336\n",
      "resetting env. episode reward total was -6.0. running mean: -1.2663032980944002\n",
      "resetting env. episode reward total was -6.0. running mean: -1.3136402651134562\n",
      "resetting env. episode reward total was 14.0. running mean: -1.1605038624623218\n",
      "resetting env. episode reward total was 4.0. running mean: -1.1088988238376987\n",
      "resetting env. episode reward total was 8.0. running mean: -1.0178098355993217\n",
      "resetting env. episode reward total was -11.0. running mean: -1.1176317372433286\n",
      "resetting env. episode reward total was 8.0. running mean: -1.0264554198708953\n",
      "resetting env. episode reward total was 6.0. running mean: -0.9561908656721863\n",
      "resetting env. episode reward total was 5.0. running mean: -0.8966289570154643\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8476626674453096\n",
      "resetting env. episode reward total was 9.0. running mean: -0.7491860407708565\n",
      "resetting env. episode reward total was -9.0. running mean: -0.8316941803631479\n",
      "resetting env. episode reward total was 7.0. running mean: -0.7533772385595163\n",
      "resetting env. episode reward total was -1.0. running mean: -0.7558434661739212\n",
      "resetting env. episode reward total was 1.0. running mean: -0.7382850315121819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: -0.7409021811970601\n",
      "resetting env. episode reward total was -3.0. running mean: -0.7634931593850895\n",
      "resetting env. episode reward total was 3.0. running mean: -0.7258582277912387\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7885996455133262\n",
      "resetting env. episode reward total was -1.0. running mean: -0.790713649058193\n",
      "resetting env. episode reward total was -1.0. running mean: -0.792806512567611\n",
      "resetting env. episode reward total was -1.0. running mean: -0.7948784474419349\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8369296629675156\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8585603663378405\n",
      "resetting env. episode reward total was 11.0. running mean: -0.739974762674462\n",
      "resetting env. episode reward total was -9.0. running mean: -0.8225750150477174\n",
      "resetting env. episode reward total was -7.0. running mean: -0.8843492648972402\n",
      "resetting env. episode reward total was 10.0. running mean: -0.7755057722482678\n",
      "resetting env. episode reward total was 5.0. running mean: -0.7177507145257851\n",
      "resetting env. episode reward total was 6.0. running mean: -0.6505732073805273\n",
      "resetting env. episode reward total was -9.0. running mean: -0.734067475306722\n",
      "resetting env. episode reward total was -11.0. running mean: -0.8367268005536548\n",
      "resetting env. episode reward total was 11.0. running mean: -0.7183595325481182\n",
      "resetting env. episode reward total was -7.0. running mean: -0.781175937222637\n",
      "resetting env. episode reward total was -2.0. running mean: -0.7933641778504107\n",
      "resetting env. episode reward total was 7.0. running mean: -0.7154305360719067\n",
      "resetting env. episode reward total was 5.0. running mean: -0.6582762307111876\n",
      "resetting env. episode reward total was 11.0. running mean: -0.5416934684040757\n",
      "resetting env. episode reward total was 6.0. running mean: -0.4762765337200349\n",
      "resetting env. episode reward total was 5.0. running mean: -0.42151376838283455\n",
      "resetting env. episode reward total was 1.0. running mean: -0.4072986306990062\n",
      "resetting env. episode reward total was -5.0. running mean: -0.4532256443920161\n",
      "resetting env. episode reward total was 8.0. running mean: -0.3686933879480959\n",
      "resetting env. episode reward total was -3.0. running mean: -0.395006454068615\n",
      "resetting env. episode reward total was 4.0. running mean: -0.3510563895279289\n",
      "resetting env. episode reward total was -1.0. running mean: -0.3575458256326496\n",
      "resetting env. episode reward total was -7.0. running mean: -0.4239703673763231\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3897306637025598\n",
      "resetting env. episode reward total was 11.0. running mean: -0.27583335706553425\n",
      "resetting env. episode reward total was 3.0. running mean: -0.2430750234948789\n",
      "resetting env. episode reward total was 2.0. running mean: -0.2206442732599301\n",
      "resetting env. episode reward total was -6.0. running mean: -0.27843783052733084\n",
      "resetting env. episode reward total was -3.0. running mean: -0.30565345222205753\n",
      "resetting env. episode reward total was 3.0. running mean: -0.27259691769983696\n",
      "resetting env. episode reward total was 1.0. running mean: -0.2598709485228386\n",
      "resetting env. episode reward total was -1.0. running mean: -0.2672722390376102\n",
      "resetting env. episode reward total was -6.0. running mean: -0.32459951664723413\n",
      "resetting env. episode reward total was 1.0. running mean: -0.3113535214807618\n",
      "resetting env. episode reward total was -9.0. running mean: -0.39823998626595414\n",
      "resetting env. episode reward total was 14.0. running mean: -0.2542575864032946\n",
      "resetting env. episode reward total was 2.0. running mean: -0.23171501053926166\n",
      "resetting env. episode reward total was 6.0. running mean: -0.16939786043386904\n",
      "resetting env. episode reward total was -5.0. running mean: -0.21770388182953032\n",
      "resetting env. episode reward total was -1.0. running mean: -0.22552684301123502\n",
      "resetting env. episode reward total was 5.0. running mean: -0.1732715745811227\n",
      "resetting env. episode reward total was 1.0. running mean: -0.16153885883531144\n",
      "resetting env. episode reward total was -13.0. running mean: -0.2899234702469583\n",
      "resetting env. episode reward total was 4.0. running mean: -0.24702423554448869\n",
      "resetting env. episode reward total was 4.0. running mean: -0.2045539931890438\n",
      "resetting env. episode reward total was 10.0. running mean: -0.10250845325715335\n",
      "resetting env. episode reward total was 3.0. running mean: -0.07148336872458182\n",
      "resetting env. episode reward total was 3.0. running mean: -0.040768535037336004\n",
      "resetting env. episode reward total was 7.0. running mean: 0.029639150313037363\n",
      "resetting env. episode reward total was -9.0. running mean: -0.06065724119009301\n",
      "resetting env. episode reward total was 2.0. running mean: -0.04005066877819208\n",
      "resetting env. episode reward total was 5.0. running mean: 0.010349837909589849\n",
      "resetting env. episode reward total was 5.0. running mean: 0.06024633953049395\n",
      "resetting env. episode reward total was 9.0. running mean: 0.149643876135189\n",
      "resetting env. episode reward total was -8.0. running mean: 0.06814743737383712\n",
      "resetting env. episode reward total was -1.0. running mean: 0.05746596300009874\n",
      "resetting env. episode reward total was 6.0. running mean: 0.11689130337009776\n",
      "resetting env. episode reward total was 2.0. running mean: 0.13572239033639677\n",
      "resetting env. episode reward total was -3.0. running mean: 0.10436516643303281\n",
      "resetting env. episode reward total was 7.0. running mean: 0.1733215147687025\n",
      "resetting env. episode reward total was 10.0. running mean: 0.2715882996210155\n",
      "resetting env. episode reward total was -1.0. running mean: 0.2588724166248053\n",
      "resetting env. episode reward total was 3.0. running mean: 0.2862836924585572\n",
      "resetting env. episode reward total was 6.0. running mean: 0.34342085553397167\n",
      "resetting env. episode reward total was 5.0. running mean: 0.38998664697863195\n",
      "resetting env. episode reward total was 6.0. running mean: 0.4460867805088456\n",
      "resetting env. episode reward total was 5.0. running mean: 0.4916259127037571\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5967096535767196\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6207425570409524\n",
      "resetting env. episode reward total was -11.0. running mean: 0.5045351314705429\n",
      "resetting env. episode reward total was 10.0. running mean: 0.5994897801558374\n",
      "resetting env. episode reward total was -4.0. running mean: 0.553494882354279\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5379599335307362\n",
      "resetting env. episode reward total was 7.0. running mean: 0.6025803341954288\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6365545308534746\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6201889855449398\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6039870956894904\n",
      "resetting env. episode reward total was -8.0. running mean: 0.5179472247325955\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5927677524852695\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5668400749604168\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5311716742108126\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5658599574687044\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5102013578940173\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5950993443150772\n",
      "resetting env. episode reward total was -14.0. running mean: 0.4491483508719264\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5046568673632071\n",
      "resetting env. episode reward total was -7.0. running mean: 0.42961029868957507\n",
      "resetting env. episode reward total was -8.0. running mean: 0.3453141957026793\n",
      "resetting env. episode reward total was 6.0. running mean: 0.4018610537456525\n",
      "resetting env. episode reward total was 4.0. running mean: 0.437842443208196\n",
      "resetting env. episode reward total was 15.0. running mean: 0.583464018776114\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5576293785883528\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5320530848024693\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5867325539544446\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5608652284149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 0.6052565761307511\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6492040103694436\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6927119702657493\n",
      "resetting env. episode reward total was 4.0. running mean: 0.7257848505630918\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7085270020574609\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7514417320368864\n",
      "resetting env. episode reward total was 7.0. running mean: 0.8139273147165176\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8557880415693524\n",
      "resetting env. episode reward total was -4.0. running mean: 0.8072301611536589\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8491578595421223\n",
      "resetting env. episode reward total was 6.0. running mean: 0.900666280946701\n",
      "resetting env. episode reward total was 3.0. running mean: 0.921659618137234\n",
      "resetting env. episode reward total was 13.0. running mean: 1.0424430219558616\n",
      "resetting env. episode reward total was 1.0. running mean: 1.042018591736303\n",
      "resetting env. episode reward total was 7.0. running mean: 1.10159840581894\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0605824217607507\n",
      "resetting env. episode reward total was 6.0. running mean: 1.1099765975431433\n",
      "resetting env. episode reward total was -5.0. running mean: 1.0488768315677117\n",
      "resetting env. episode reward total was -8.0. running mean: 0.9583880632520346\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0188041826195142\n",
      "resetting env. episode reward total was 5.0. running mean: 1.058616140793319\n",
      "resetting env. episode reward total was 8.0. running mean: 1.1280299793853859\n",
      "resetting env. episode reward total was 6.0. running mean: 1.176749679591532\n",
      "resetting env. episode reward total was -6.0. running mean: 1.1049821827956166\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0639323609676603\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0432930373579836\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0428601069844037\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0924315059145597\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0915071908554141\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0505921189468599\n",
      "resetting env. episode reward total was -2.0. running mean: 1.0200861977573912\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0698853357798173\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0291864824220192\n",
      "resetting env. episode reward total was 4.0. running mean: 1.058894617597799\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0683056714218209\n",
      "resetting env. episode reward total was -10.0. running mean: 0.9576226147076027\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9280463885605267\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9987659246749213\n",
      "resetting env. episode reward total was -4.0. running mean: 0.948778265428172\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9492904827738903\n",
      "resetting env. episode reward total was -6.0. running mean: 0.8797975779461513\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9609996021666898\n",
      "resetting env. episode reward total was 5.0. running mean: 1.001389606145023\n",
      "resetting env. episode reward total was -10.0. running mean: 0.8913757100835727\n",
      "resetting env. episode reward total was 12.0. running mean: 1.002461952982737\n",
      "resetting env. episode reward total was 12.0. running mean: 1.1124373334529096\n",
      "resetting env. episode reward total was -9.0. running mean: 1.0113129601183803\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9511998305171965\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0116878322120244\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9815709538899042\n",
      "resetting env. episode reward total was -3.0. running mean: 0.9417552443510051\n",
      "resetting env. episode reward total was -3.0. running mean: 0.902337691907495\n",
      "resetting env. episode reward total was 11.0. running mean: 1.00331431498842\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0332811718385357\n",
      "resetting env. episode reward total was -2.0. running mean: 1.0029483601201503\n",
      "resetting env. episode reward total was 8.0. running mean: 1.0729188765189488\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1321896877537594\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0908677908762217\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0899591129674595\n",
      "resetting env. episode reward total was 8.0. running mean: 1.159059521837785\n",
      "resetting env. episode reward total was -6.0. running mean: 1.087468926619407\n",
      "resetting env. episode reward total was 10.0. running mean: 1.176594237353213\n",
      "resetting env. episode reward total was -9.0. running mean: 1.0748282949796808\n",
      "resetting env. episode reward total was -4.0. running mean: 1.0240800120298839\n",
      "resetting env. episode reward total was 3.0. running mean: 1.043839211909585\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0634008197904892\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0827668115925844\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0919391434766585\n",
      "resetting env. episode reward total was 9.0. running mean: 1.1710197520418921\n",
      "resetting env. episode reward total was -1.0. running mean: 1.149309554521473\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1078164589762582\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0667382943864956\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0760709114426306\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0853102023282042\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0844571003049222\n",
      "resetting env. episode reward total was 2.0. running mean: 1.093612529301873\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0926764040088544\n",
      "resetting env. episode reward total was 3.0. running mean: 1.1117496399687659\n",
      "resetting env. episode reward total was 8.0. running mean: 1.1806321435690783\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2088258221333876\n",
      "resetting env. episode reward total was -13.0. running mean: 1.0667375639120538\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0960701882729333\n",
      "resetting env. episode reward total was 7.0. running mean: 1.155109486390204\n",
      "resetting env. episode reward total was 3.0. running mean: 1.173558391526302\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1518228076110388\n",
      "resetting env. episode reward total was 5.0. running mean: 1.1903045795349285\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2184015337395793\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1762175184021835\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2544553432181618\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3219107897859803\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3586916818881205\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3651047650692394\n",
      "resetting env. episode reward total was -8.0. running mean: 1.271453717418547\n",
      "resetting env. episode reward total was -10.0. running mean: 1.1587391802443614\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1871517884419178\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1652802705574987\n",
      "resetting env. episode reward total was -16.0. running mean: 0.9936274678519238\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9736911931734046\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9839542812416705\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9541147384292538\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9345735910449612\n",
      "resetting env. episode reward total was -6.0. running mean: 0.8652278551345116\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8765755765831665\n",
      "resetting env. episode reward total was -4.0. running mean: 0.8278098208173348\n",
      "resetting env. episode reward total was -9.0. running mean: 0.7295317226091614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 0.8022364053830697\n",
      "resetting env. episode reward total was 5.0. running mean: 0.844214041329239\n",
      "resetting env. episode reward total was -11.0. running mean: 0.7257719009159467\n",
      "resetting env. episode reward total was -11.0. running mean: 0.6085141819067872\n",
      "resetting env. episode reward total was 11.0. running mean: 0.7124290400877193\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7653047496868421\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7276517021899737\n",
      "resetting env. episode reward total was -15.0. running mean: 0.5703751851680738\n",
      "resetting env. episode reward total was -4.0. running mean: 0.5246714333163931\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5794247189832291\n",
      "resetting env. episode reward total was 2.0. running mean: 0.5936304717933968\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6276941670754629\n",
      "resetting env. episode reward total was -13.0. running mean: 0.4914172254047082\n",
      "resetting env. episode reward total was -10.0. running mean: 0.38650305315066114\n",
      "resetting env. episode reward total was -6.0. running mean: 0.32263802261915453\n",
      "resetting env. episode reward total was -8.0. running mean: 0.23941164239296298\n",
      "resetting env. episode reward total was -9.0. running mean: 0.14701752596903334\n",
      "resetting env. episode reward total was -9.0. running mean: 0.055547350709342996\n",
      "resetting env. episode reward total was -1.0. running mean: 0.044991877202249564\n",
      "resetting env. episode reward total was -6.0. running mean: -0.015458041569772929\n",
      "resetting env. episode reward total was 11.0. running mean: 0.0946965388459248\n",
      "resetting env. episode reward total was 9.0. running mean: 0.18374957345746556\n",
      "resetting env. episode reward total was 5.0. running mean: 0.2319120777228909\n",
      "resetting env. episode reward total was -6.0. running mean: 0.169592956945662\n",
      "resetting env. episode reward total was -3.0. running mean: 0.13789702737620538\n",
      "resetting env. episode reward total was -3.0. running mean: 0.10651805710244333\n",
      "resetting env. episode reward total was 4.0. running mean: 0.1454528765314189\n",
      "resetting env. episode reward total was -7.0. running mean: 0.0739983477661047\n",
      "resetting env. episode reward total was -1.0. running mean: 0.06325836428844366\n",
      "resetting env. episode reward total was 6.0. running mean: 0.12262578064555922\n",
      "resetting env. episode reward total was -8.0. running mean: 0.04139952283910363\n",
      "resetting env. episode reward total was -9.0. running mean: -0.049014472389287404\n",
      "resetting env. episode reward total was 5.0. running mean: 0.0014756723346054726\n",
      "resetting env. episode reward total was 1.0. running mean: 0.011460915611259418\n",
      "resetting env. episode reward total was -5.0. running mean: -0.03865369354485318\n",
      "resetting env. episode reward total was 3.0. running mean: -0.00826715660940465\n",
      "resetting env. episode reward total was -11.0. running mean: -0.11818448504331061\n",
      "resetting env. episode reward total was -2.0. running mean: -0.1370026401928775\n",
      "resetting env. episode reward total was -6.0. running mean: -0.19563261379094873\n",
      "resetting env. episode reward total was -6.0. running mean: -0.25367628765303923\n",
      "resetting env. episode reward total was 2.0. running mean: -0.23113952477650887\n",
      "resetting env. episode reward total was 2.0. running mean: -0.2088281295287438\n",
      "resetting env. episode reward total was 2.0. running mean: -0.18673984823345638\n",
      "resetting env. episode reward total was 6.0. running mean: -0.12487244975112183\n",
      "resetting env. episode reward total was 9.0. running mean: -0.03362372525361061\n",
      "resetting env. episode reward total was -1.0. running mean: -0.04328748800107451\n",
      "resetting env. episode reward total was 14.0. running mean: 0.09714538687893626\n",
      "resetting env. episode reward total was 5.0. running mean: 0.14617393301014692\n",
      "resetting env. episode reward total was -5.0. running mean: 0.09471219368004545\n",
      "resetting env. episode reward total was -3.0. running mean: 0.063765071743245\n",
      "resetting env. episode reward total was -5.0. running mean: 0.013127421025812547\n",
      "resetting env. episode reward total was -5.0. running mean: -0.03700385318444558\n",
      "resetting env. episode reward total was -1.0. running mean: -0.04663381465260113\n",
      "resetting env. episode reward total was -3.0. running mean: -0.07616747650607511\n",
      "resetting env. episode reward total was -7.0. running mean: -0.14540580174101436\n",
      "resetting env. episode reward total was 2.0. running mean: -0.12395174372360422\n",
      "resetting env. episode reward total was -9.0. running mean: -0.21271222628636816\n",
      "resetting env. episode reward total was 7.0. running mean: -0.14058510402350446\n",
      "resetting env. episode reward total was -1.0. running mean: -0.14917925298326942\n",
      "resetting env. episode reward total was 7.0. running mean: -0.07768746045343672\n",
      "resetting env. episode reward total was 15.0. running mean: 0.07308941415109764\n",
      "resetting env. episode reward total was 10.0. running mean: 0.17235852000958668\n",
      "resetting env. episode reward total was -3.0. running mean: 0.14063493480949082\n",
      "resetting env. episode reward total was -2.0. running mean: 0.1192285854613959\n",
      "resetting env. episode reward total was 2.0. running mean: 0.13803629960678193\n",
      "resetting env. episode reward total was -5.0. running mean: 0.08665593661071412\n",
      "resetting env. episode reward total was 6.0. running mean: 0.14578937724460697\n",
      "resetting env. episode reward total was 6.0. running mean: 0.2043314834721609\n",
      "resetting env. episode reward total was 1.0. running mean: 0.2122881686374393\n",
      "resetting env. episode reward total was -3.0. running mean: 0.1801652869510649\n",
      "resetting env. episode reward total was 6.0. running mean: 0.23836363408155425\n",
      "resetting env. episode reward total was 7.0. running mean: 0.3059799977407387\n",
      "resetting env. episode reward total was 4.0. running mean: 0.34292019776333127\n",
      "resetting env. episode reward total was -9.0. running mean: 0.24949099578569797\n",
      "resetting env. episode reward total was -3.0. running mean: 0.216996085827841\n",
      "resetting env. episode reward total was -3.0. running mean: 0.18482612496956258\n",
      "resetting env. episode reward total was 15.0. running mean: 0.33297786371986693\n",
      "resetting env. episode reward total was -12.0. running mean: 0.20964808508266825\n",
      "resetting env. episode reward total was -8.0. running mean: 0.1275516042318416\n",
      "resetting env. episode reward total was -3.0. running mean: 0.09627608818952316\n",
      "resetting env. episode reward total was -8.0. running mean: 0.015313327307627925\n",
      "resetting env. episode reward total was 9.0. running mean: 0.10516019403455164\n",
      "resetting env. episode reward total was -2.0. running mean: 0.08410859209420611\n",
      "resetting env. episode reward total was 4.0. running mean: 0.12326750617326404\n",
      "resetting env. episode reward total was -5.0. running mean: 0.0720348311115314\n",
      "resetting env. episode reward total was -9.0. running mean: -0.018685517199583904\n",
      "resetting env. episode reward total was 4.0. running mean: 0.021501337972411938\n",
      "resetting env. episode reward total was 3.0. running mean: 0.05128632459268782\n",
      "resetting env. episode reward total was -11.0. running mean: -0.05922653865323906\n",
      "resetting env. episode reward total was -8.0. running mean: -0.1386342732667067\n",
      "resetting env. episode reward total was -3.0. running mean: -0.1672479305340396\n",
      "resetting env. episode reward total was -9.0. running mean: -0.2555754512286992\n",
      "resetting env. episode reward total was -4.0. running mean: -0.29301969671641215\n",
      "resetting env. episode reward total was -10.0. running mean: -0.390089499749248\n",
      "resetting env. episode reward total was -1.0. running mean: -0.39618860475175555\n",
      "resetting env. episode reward total was -5.0. running mean: -0.44222671870423796\n",
      "resetting env. episode reward total was -4.0. running mean: -0.4778044515171956\n",
      "resetting env. episode reward total was 12.0. running mean: -0.35302640700202365\n",
      "resetting env. episode reward total was -5.0. running mean: -0.3994961429320034\n",
      "resetting env. episode reward total was 2.0. running mean: -0.37550118150268336\n",
      "resetting env. episode reward total was 9.0. running mean: -0.28174616968765653\n",
      "resetting env. episode reward total was 13.0. running mean: -0.14892870799077995\n",
      "resetting env. episode reward total was 3.0. running mean: -0.11743942091087214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: -0.19626502670176343\n",
      "resetting env. episode reward total was 7.0. running mean: -0.12430237643474579\n",
      "resetting env. episode reward total was 3.0. running mean: -0.09305935267039833\n",
      "resetting env. episode reward total was 3.0. running mean: -0.062128759143694354\n",
      "resetting env. episode reward total was 9.0. running mean: 0.02849252844774259\n",
      "resetting env. episode reward total was 10.0. running mean: 0.12820760316326518\n",
      "resetting env. episode reward total was 9.0. running mean: 0.21692552713163252\n",
      "resetting env. episode reward total was -1.0. running mean: 0.20475627186031617\n",
      "resetting env. episode reward total was -5.0. running mean: 0.15270870914171303\n",
      "resetting env. episode reward total was 7.0. running mean: 0.2211816220502959\n",
      "resetting env. episode reward total was 3.0. running mean: 0.24896980582979295\n",
      "resetting env. episode reward total was 2.0. running mean: 0.266480107771495\n",
      "resetting env. episode reward total was 5.0. running mean: 0.31381530669378005\n",
      "resetting env. episode reward total was 2.0. running mean: 0.33067715362684225\n",
      "resetting env. episode reward total was -3.0. running mean: 0.29737038209057387\n",
      "resetting env. episode reward total was 1.0. running mean: 0.30439667826966815\n",
      "resetting env. episode reward total was 11.0. running mean: 0.41135271148697145\n",
      "resetting env. episode reward total was 9.0. running mean: 0.4972391843721017\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4822667925283807\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5574441246030969\n",
      "resetting env. episode reward total was 6.0. running mean: 0.6118696833570658\n",
      "resetting env. episode reward total was 9.0. running mean: 0.6957509865234951\n",
      "resetting env. episode reward total was -2.0. running mean: 0.6687934766582602\n",
      "resetting env. episode reward total was -5.0. running mean: 0.6121055418916775\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6559844864727608\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5994246416080331\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5234303951919528\n",
      "resetting env. episode reward total was -9.0. running mean: 0.4281960912400333\n",
      "resetting env. episode reward total was -1.0. running mean: 0.41391413032763297\n",
      "resetting env. episode reward total was 1.0. running mean: 0.41977498902435667\n",
      "resetting env. episode reward total was 6.0. running mean: 0.4755772391341131\n",
      "resetting env. episode reward total was -6.0. running mean: 0.410821466742772\n",
      "resetting env. episode reward total was -10.0. running mean: 0.3067132520753443\n",
      "resetting env. episode reward total was -6.0. running mean: 0.2436461195545908\n",
      "resetting env. episode reward total was 4.0. running mean: 0.2812096583590449\n",
      "resetting env. episode reward total was 11.0. running mean: 0.3883975617754544\n",
      "resetting env. episode reward total was 5.0. running mean: 0.43451358615769986\n",
      "resetting env. episode reward total was -2.0. running mean: 0.41016845029612287\n",
      "resetting env. episode reward total was -7.0. running mean: 0.33606676579316164\n",
      "resetting env. episode reward total was 4.0. running mean: 0.37270609813523\n",
      "resetting env. episode reward total was -3.0. running mean: 0.33897903715387767\n",
      "resetting env. episode reward total was 8.0. running mean: 0.4155892467823389\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4014333543145155\n",
      "resetting env. episode reward total was 9.0. running mean: 0.48741902077137034\n",
      "resetting env. episode reward total was 7.0. running mean: 0.5525448305636567\n",
      "resetting env. episode reward total was -2.0. running mean: 0.52701938225802\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5117491884354398\n",
      "resetting env. episode reward total was 5.0. running mean: 0.5566316965510855\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6010653795855746\n",
      "resetting env. episode reward total was 6.0. running mean: 0.6550547257897188\n",
      "resetting env. episode reward total was -8.0. running mean: 0.5685041785318217\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5428191367465034\n",
      "resetting env. episode reward total was -7.0. running mean: 0.4673909453790383\n",
      "resetting env. episode reward total was 13.0. running mean: 0.5927170359252479\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6367898655659955\n",
      "resetting env. episode reward total was 9.0. running mean: 0.7204219669103354\n",
      "resetting env. episode reward total was 1.0. running mean: 0.7232177472412321\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6459855697688197\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5895257140711314\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6136304569304201\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5974941523611158\n",
      "resetting env. episode reward total was -8.0. running mean: 0.5115192108375047\n",
      "resetting env. episode reward total was -8.0. running mean: 0.42640401872912964\n",
      "resetting env. episode reward total was 3.0. running mean: 0.4521399785418383\n",
      "resetting env. episode reward total was 3.0. running mean: 0.4776185787564199\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5028423929688557\n",
      "resetting env. episode reward total was -4.0. running mean: 0.45781396903916716\n",
      "resetting env. episode reward total was -4.0. running mean: 0.4132358293487755\n",
      "resetting env. episode reward total was -2.0. running mean: 0.38910347105528775\n",
      "resetting env. episode reward total was -6.0. running mean: 0.3252124363447349\n",
      "resetting env. episode reward total was 6.0. running mean: 0.38196031198128755\n",
      "resetting env. episode reward total was -12.0. running mean: 0.25814070886147467\n",
      "resetting env. episode reward total was 10.0. running mean: 0.3555593017728599\n",
      "resetting env. episode reward total was 1.0. running mean: 0.36200370875513127\n",
      "resetting env. episode reward total was 7.0. running mean: 0.42838367166757996\n",
      "resetting env. episode reward total was -5.0. running mean: 0.37409983495090415\n",
      "resetting env. episode reward total was -2.0. running mean: 0.3503588366013951\n",
      "resetting env. episode reward total was 1.0. running mean: 0.3568552482353812\n",
      "resetting env. episode reward total was 7.0. running mean: 0.42328669575302735\n",
      "resetting env. episode reward total was 3.0. running mean: 0.44905382879549705\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5045632905075421\n",
      "resetting env. episode reward total was -2.0. running mean: 0.4795176576024667\n",
      "resetting env. episode reward total was 9.0. running mean: 0.564722481026442\n",
      "resetting env. episode reward total was 9.0. running mean: 0.6490752562161775\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6125845036540156\n",
      "resetting env. episode reward total was 7.0. running mean: 0.6764586586174755\n",
      "resetting env. episode reward total was -9.0. running mean: 0.5796940720313007\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6238971313109878\n",
      "resetting env. episode reward total was 6.0. running mean: 0.6776581599978779\n",
      "resetting env. episode reward total was 1.0. running mean: 0.6808815783978992\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7340727626139203\n",
      "resetting env. episode reward total was -2.0. running mean: 0.706732034987781\n",
      "resetting env. episode reward total was 9.0. running mean: 0.7896647146379032\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8117680674915242\n",
      "resetting env. episode reward total was -11.0. running mean: 0.693650386816609\n",
      "resetting env. episode reward total was 3.0. running mean: 0.7167138829484428\n",
      "resetting env. episode reward total was -2.0. running mean: 0.6895467441189584\n",
      "resetting env. episode reward total was -2.0. running mean: 0.6626512766777688\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7060247639109911\n",
      "resetting env. episode reward total was 2.0. running mean: 0.7189645162718812\n",
      "resetting env. episode reward total was -11.0. running mean: 0.6017748711091624\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6157571223980708\n",
      "resetting env. episode reward total was 8.0. running mean: 0.68959955117409\n",
      "resetting env. episode reward total was -2.0. running mean: 0.6627035556623491\n",
      "resetting env. episode reward total was 7.0. running mean: 0.7260765201057255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 0.7988157549046683\n",
      "resetting env. episode reward total was -10.0. running mean: 0.6908275973556216\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6139193213820653\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5977801281682447\n",
      "resetting env. episode reward total was 10.0. running mean: 0.6918023268865622\n",
      "resetting env. episode reward total was 14.0. running mean: 0.8248843036176966\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8266354605815196\n",
      "resetting env. episode reward total was 12.0. running mean: 0.9383691059757044\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9889854149159474\n",
      "resetting env. episode reward total was -11.0. running mean: 0.869095560766788\n",
      "resetting env. episode reward total was 4.0. running mean: 0.9004046051591201\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9214005591075289\n",
      "resetting env. episode reward total was -7.0. running mean: 0.8421865535164537\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8737646879812891\n",
      "resetting env. episode reward total was -8.0. running mean: 0.7850270411014763\n",
      "resetting env. episode reward total was 1.0. running mean: 0.7871767706904615\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7693050029835569\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8116119529537213\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7934958334241842\n",
      "resetting env. episode reward total was 9.0. running mean: 0.8755608750899423\n",
      "resetting env. episode reward total was -6.0. running mean: 0.8068052663390428\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7687372136756524\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7510498415388959\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7335393431235069\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7062039496922717\n",
      "resetting env. episode reward total was 8.0. running mean: 0.779141910195349\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8013504910933955\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8333369861824615\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7750036163206369\n",
      "resetting env. episode reward total was -10.0. running mean: 0.6672535801574305\n",
      "resetting env. episode reward total was 4.0. running mean: 0.7005810443558562\n",
      "resetting env. episode reward total was 10.0. running mean: 0.7935752339122977\n",
      "resetting env. episode reward total was -11.0. running mean: 0.6756394815731747\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6588830867574429\n",
      "resetting env. episode reward total was -5.0. running mean: 0.6022942558898684\n",
      "resetting env. episode reward total was 13.0. running mean: 0.7262713133309697\n",
      "resetting env. episode reward total was -7.0. running mean: 0.64900860019766\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6825185141956834\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6956933290537266\n",
      "resetting env. episode reward total was 7.0. running mean: 0.7587363957631894\n",
      "resetting env. episode reward total was 2.0. running mean: 0.7711490318055575\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7434375414875019\n",
      "resetting env. episode reward total was 7.0. running mean: 0.8060031660726268\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8379431344119005\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8395637030677815\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9011680660371038\n",
      "resetting env. episode reward total was 4.0. running mean: 0.9321563853767327\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9128348215229654\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8137064733077357\n",
      "resetting env. episode reward total was 9.0. running mean: 0.8955694085746583\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9566137144889117\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9770475773440227\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9972771015705825\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9773043305548766\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0175312872493278\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9873559743768345\n",
      "resetting env. episode reward total was 8.0. running mean: 1.0574824146330661\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0569075904867355\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9563385145818682\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9667751294360496\n",
      "resetting env. episode reward total was 7.0. running mean: 1.027107378141689\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9468363043602721\n",
      "resetting env. episode reward total was -7.0. running mean: 0.8673679413166693\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8486942619035026\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8802073192844676\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9614052460916229\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0017911936307067\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0517732816943997\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0312555488774557\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0709429933886812\n",
      "resetting env. episode reward total was 8.0. running mean: 1.1402335634547944\n",
      "resetting env. episode reward total was 5.0. running mean: 1.1788312278202466\n",
      "resetting env. episode reward total was 8.0. running mean: 1.2470429155420442\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2745724863866237\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3218267615227575\n",
      "resetting env. episode reward total was 1.0. running mean: 1.31860849390753\n",
      "resetting env. episode reward total was 12.0. running mean: 1.4254224089684548\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4611681848787703\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3965565030299825\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3725909379996826\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3688650286196857\n",
      "resetting env. episode reward total was 9.0. running mean: 1.445176378333489\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4007246145501542\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4267173684046526\n",
      "resetting env. episode reward total was -3.0. running mean: 1.382450194720606\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3486256927734\n",
      "resetting env. episode reward total was 8.0. running mean: 1.415139435845666\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4109880414872094\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3868781610723373\n",
      "resetting env. episode reward total was -8.0. running mean: 1.2930093794616138\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3600792856669977\n",
      "resetting env. episode reward total was -9.0. running mean: 1.2564784928103276\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2839137078822245\n",
      "resetting env. episode reward total was -15.0. running mean: 1.1210745708034022\n",
      "resetting env. episode reward total was -9.0. running mean: 1.0198638250953682\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9896651868444144\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8897685349759703\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8508708496262105\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8823621411299485\n",
      "resetting env. episode reward total was 7.0. running mean: 0.943538519718649\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9641031345214626\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9344621031762479\n",
      "resetting env. episode reward total was -12.0. running mean: 0.8051174821444854\n",
      "resetting env. episode reward total was 12.0. running mean: 0.9170663073230405\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9178956442498101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: 0.918716687807312\n",
      "resetting env. episode reward total was -10.0. running mean: 0.8095295209292389\n",
      "resetting env. episode reward total was -4.0. running mean: 0.7614342257199465\n",
      "resetting env. episode reward total was 11.0. running mean: 0.863819883462747\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9151816846281196\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9960298677818383\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0260695691040198\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9458088734129795\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8863507846788496\n",
      "resetting env. episode reward total was -4.0. running mean: 0.8374872768320611\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8691124040637406\n",
      "resetting env. episode reward total was -6.0. running mean: 0.8004212800231032\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7824170672228722\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8245928965506435\n",
      "resetting env. episode reward total was -11.0. running mean: 0.706346967585137\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6692834979092857\n",
      "resetting env. episode reward total was -8.0. running mean: 0.5825906629301928\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5467647563008908\n",
      "resetting env. episode reward total was 5.0. running mean: 0.591297108737882\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6053841376505031\n",
      "resetting env. episode reward total was -9.0. running mean: 0.5093302962739982\n",
      "resetting env. episode reward total was -7.0. running mean: 0.43423699331125815\n",
      "resetting env. episode reward total was -8.0. running mean: 0.34989462337814553\n",
      "resetting env. episode reward total was 3.0. running mean: 0.37639567714436406\n",
      "resetting env. episode reward total was 2.0. running mean: 0.39263172037292043\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3587054031691912\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3051183491374993\n",
      "resetting env. episode reward total was -7.0. running mean: 0.23206716564612428\n",
      "resetting env. episode reward total was 12.0. running mean: 0.34974649398966307\n",
      "resetting env. episode reward total was -2.0. running mean: 0.32624902904976644\n",
      "resetting env. episode reward total was -9.0. running mean: 0.23298653875926875\n",
      "resetting env. episode reward total was 6.0. running mean: 0.29065667337167606\n",
      "resetting env. episode reward total was -8.0. running mean: 0.2077501066379593\n",
      "resetting env. episode reward total was -9.0. running mean: 0.11567260557157968\n",
      "resetting env. episode reward total was -7.0. running mean: 0.044515879515863874\n",
      "resetting env. episode reward total was 1.0. running mean: 0.054070720720705234\n",
      "resetting env. episode reward total was -10.0. running mean: -0.04646998648650182\n",
      "resetting env. episode reward total was -11.0. running mean: -0.15600528662163682\n",
      "resetting env. episode reward total was 7.0. running mean: -0.08444523375542043\n",
      "resetting env. episode reward total was 7.0. running mean: -0.01360078141786622\n",
      "resetting env. episode reward total was -7.0. running mean: -0.08346477360368756\n",
      "resetting env. episode reward total was -3.0. running mean: -0.11263012586765069\n",
      "resetting env. episode reward total was -5.0. running mean: -0.16150382460897417\n",
      "resetting env. episode reward total was 3.0. running mean: -0.12988878636288442\n",
      "resetting env. episode reward total was -12.0. running mean: -0.24858989849925558\n",
      "resetting env. episode reward total was -7.0. running mean: -0.31610399951426305\n",
      "resetting env. episode reward total was -4.0. running mean: -0.3529429595191204\n",
      "resetting env. episode reward total was 7.0. running mean: -0.2794135299239292\n",
      "resetting env. episode reward total was -5.0. running mean: -0.3266193946246899\n",
      "resetting env. episode reward total was -3.0. running mean: -0.353353200678443\n",
      "resetting env. episode reward total was 2.0. running mean: -0.3298196686716586\n",
      "resetting env. episode reward total was -2.0. running mean: -0.346521471984942\n",
      "resetting env. episode reward total was 2.0. running mean: -0.3230562572650926\n",
      "resetting env. episode reward total was 9.0. running mean: -0.22982569469244166\n",
      "resetting env. episode reward total was -9.0. running mean: -0.3175274377455172\n",
      "resetting env. episode reward total was 1.0. running mean: -0.30435216336806203\n",
      "resetting env. episode reward total was 4.0. running mean: -0.26130864173438145\n",
      "resetting env. episode reward total was -10.0. running mean: -0.3586955553170377\n",
      "resetting env. episode reward total was -4.0. running mean: -0.39510859976386725\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3611575137662286\n",
      "resetting env. episode reward total was 10.0. running mean: -0.25754593862856634\n",
      "resetting env. episode reward total was 12.0. running mean: -0.13497047924228067\n",
      "resetting env. episode reward total was -8.0. running mean: -0.2136207744498579\n",
      "resetting env. episode reward total was 11.0. running mean: -0.10148456670535931\n",
      "resetting env. episode reward total was 12.0. running mean: 0.019530278961694278\n",
      "resetting env. episode reward total was 3.0. running mean: 0.049334976172077334\n",
      "resetting env. episode reward total was 4.0. running mean: 0.08884162641035656\n",
      "resetting env. episode reward total was -5.0. running mean: 0.037953210146253\n",
      "resetting env. episode reward total was -7.0. running mean: -0.03242632195520954\n",
      "resetting env. episode reward total was -5.0. running mean: -0.08210205873565744\n",
      "resetting env. episode reward total was -9.0. running mean: -0.17128103814830087\n",
      "resetting env. episode reward total was -7.0. running mean: -0.23956822776681785\n",
      "resetting env. episode reward total was 10.0. running mean: -0.13717254548914967\n",
      "resetting env. episode reward total was -6.0. running mean: -0.19580082003425817\n",
      "resetting env. episode reward total was 5.0. running mean: -0.14384281183391556\n",
      "resetting env. episode reward total was -11.0. running mean: -0.2524043837155764\n",
      "resetting env. episode reward total was -7.0. running mean: -0.3198803398784206\n",
      "resetting env. episode reward total was -7.0. running mean: -0.38668153647963643\n",
      "resetting env. episode reward total was 12.0. running mean: -0.26281472111484006\n",
      "resetting env. episode reward total was -6.0. running mean: -0.32018657390369165\n",
      "resetting env. episode reward total was -1.0. running mean: -0.32698470816465475\n",
      "resetting env. episode reward total was -2.0. running mean: -0.3437148610830082\n",
      "resetting env. episode reward total was -5.0. running mean: -0.3902777124721781\n",
      "resetting env. episode reward total was -11.0. running mean: -0.4963749353474563\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5214111859939817\n",
      "resetting env. episode reward total was 5.0. running mean: -0.46619707413404193\n",
      "resetting env. episode reward total was -12.0. running mean: -0.5815351033927014\n",
      "resetting env. episode reward total was -12.0. running mean: -0.6957197523587744\n",
      "resetting env. episode reward total was -2.0. running mean: -0.7087625548351867\n",
      "resetting env. episode reward total was 1.0. running mean: -0.6916749292868348\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7547581799939664\n",
      "resetting env. episode reward total was -8.0. running mean: -0.8272105981940268\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8789384922120864\n",
      "resetting env. episode reward total was -8.0. running mean: -0.9501491072899655\n",
      "resetting env. episode reward total was 2.0. running mean: -0.9206476162170658\n",
      "resetting env. episode reward total was -5.0. running mean: -0.9614411400548952\n",
      "resetting env. episode reward total was -12.0. running mean: -1.0718267286543464\n",
      "resetting env. episode reward total was 2.0. running mean: -1.0411084613678028\n",
      "resetting env. episode reward total was -11.0. running mean: -1.1406973767541249\n",
      "resetting env. episode reward total was 5.0. running mean: -1.0792904029865835\n",
      "resetting env. episode reward total was -9.0. running mean: -1.1584974989567178\n",
      "resetting env. episode reward total was 8.0. running mean: -1.0669125239671506\n",
      "resetting env. episode reward total was -9.0. running mean: -1.1462433987274792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: -1.1447809647402043\n",
      "resetting env. episode reward total was -15.0. running mean: -1.2833331550928022\n",
      "resetting env. episode reward total was -3.0. running mean: -1.300499823541874\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2974948253064553\n",
      "resetting env. episode reward total was -3.0. running mean: -1.3145198770533908\n",
      "resetting env. episode reward total was -6.0. running mean: -1.3613746782828569\n",
      "resetting env. episode reward total was -4.0. running mean: -1.3877609315000283\n",
      "resetting env. episode reward total was -10.0. running mean: -1.473883322185028\n",
      "resetting env. episode reward total was -5.0. running mean: -1.5091444889631778\n",
      "resetting env. episode reward total was -13.0. running mean: -1.6240530440735461\n",
      "resetting env. episode reward total was -6.0. running mean: -1.6678125136328108\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6811343884964827\n",
      "resetting env. episode reward total was -2.0. running mean: -1.6843230446115178\n",
      "resetting env. episode reward total was 4.0. running mean: -1.6274798141654025\n",
      "resetting env. episode reward total was 2.0. running mean: -1.5912050160237485\n",
      "resetting env. episode reward total was -6.0. running mean: -1.6352929658635111\n",
      "resetting env. episode reward total was -1.0. running mean: -1.628940036204876\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6426506358428272\n",
      "resetting env. episode reward total was -1.0. running mean: -1.6362241294843989\n",
      "resetting env. episode reward total was 3.0. running mean: -1.5898618881895548\n",
      "resetting env. episode reward total was 1.0. running mean: -1.5639632693076593\n",
      "resetting env. episode reward total was -8.0. running mean: -1.6283236366145828\n",
      "resetting env. episode reward total was -11.0. running mean: -1.722040400248437\n",
      "resetting env. episode reward total was 1.0. running mean: -1.6948199962459527\n",
      "resetting env. episode reward total was -1.0. running mean: -1.6878717962834933\n",
      "resetting env. episode reward total was -6.0. running mean: -1.7309930783206584\n",
      "resetting env. episode reward total was 1.0. running mean: -1.7036831475374519\n",
      "resetting env. episode reward total was -9.0. running mean: -1.7766463160620773\n",
      "resetting env. episode reward total was -1.0. running mean: -1.7688798529014567\n",
      "resetting env. episode reward total was -1.0. running mean: -1.761191054372442\n",
      "resetting env. episode reward total was -5.0. running mean: -1.7935791438287176\n",
      "resetting env. episode reward total was 10.0. running mean: -1.6756433523904304\n",
      "resetting env. episode reward total was 7.0. running mean: -1.588886918866526\n",
      "resetting env. episode reward total was -9.0. running mean: -1.662998049677861\n",
      "resetting env. episode reward total was -4.0. running mean: -1.6863680691810823\n",
      "resetting env. episode reward total was 1.0. running mean: -1.6595043884892715\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6929093446043788\n",
      "resetting env. episode reward total was 1.0. running mean: -1.665980251158335\n",
      "resetting env. episode reward total was 6.0. running mean: -1.5893204486467516\n",
      "resetting env. episode reward total was -10.0. running mean: -1.6734272441602842\n",
      "resetting env. episode reward total was -10.0. running mean: -1.7566929717186814\n",
      "resetting env. episode reward total was -11.0. running mean: -1.8491260420014948\n",
      "resetting env. episode reward total was 2.0. running mean: -1.8106347815814798\n",
      "resetting env. episode reward total was -11.0. running mean: -1.9025284337656652\n",
      "resetting env. episode reward total was -5.0. running mean: -1.9335031494280086\n",
      "resetting env. episode reward total was 2.0. running mean: -1.8941681179337284\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9052264367543912\n",
      "resetting env. episode reward total was 3.0. running mean: -1.8561741723868472\n",
      "resetting env. episode reward total was -5.0. running mean: -1.8876124306629787\n",
      "resetting env. episode reward total was 5.0. running mean: -1.8187363063563489\n",
      "resetting env. episode reward total was 2.0. running mean: -1.7805489432927852\n",
      "resetting env. episode reward total was 9.0. running mean: -1.6727434538598573\n",
      "resetting env. episode reward total was -7.0. running mean: -1.7260160193212588\n",
      "resetting env. episode reward total was -2.0. running mean: -1.7287558591280463\n",
      "resetting env. episode reward total was 12.0. running mean: -1.591468300536766\n",
      "resetting env. episode reward total was 12.0. running mean: -1.4555536175313986\n",
      "resetting env. episode reward total was 8.0. running mean: -1.3609980813560845\n",
      "resetting env. episode reward total was 7.0. running mean: -1.2773881005425236\n",
      "resetting env. episode reward total was -3.0. running mean: -1.2946142195370984\n",
      "resetting env. episode reward total was 1.0. running mean: -1.2716680773417275\n",
      "resetting env. episode reward total was -5.0. running mean: -1.3089513965683102\n",
      "resetting env. episode reward total was 5.0. running mean: -1.245861882602627\n",
      "resetting env. episode reward total was 6.0. running mean: -1.1734032637766008\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1916692311388348\n",
      "resetting env. episode reward total was 2.0. running mean: -1.1597525388274466\n",
      "resetting env. episode reward total was -7.0. running mean: -1.218155013439172\n",
      "resetting env. episode reward total was 10.0. running mean: -1.1059734633047802\n",
      "resetting env. episode reward total was 5.0. running mean: -1.0449137286717323\n",
      "resetting env. episode reward total was -1.0. running mean: -1.044464591385015\n",
      "resetting env. episode reward total was 5.0. running mean: -0.9840199454711649\n",
      "resetting env. episode reward total was 13.0. running mean: -0.8441797460164532\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8857379485562887\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8368805690707258\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8785117633800186\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8497266457462184\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8712293792887562\n",
      "resetting env. episode reward total was 8.0. running mean: -0.7825170854958687\n",
      "resetting env. episode reward total was -6.0. running mean: -0.83469191464091\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8563449954945009\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8577815455395559\n",
      "resetting env. episode reward total was -10.0. running mean: -0.9492037300841603\n",
      "resetting env. episode reward total was -3.0. running mean: -0.9697116927833187\n",
      "resetting env. episode reward total was 7.0. running mean: -0.8900145758554856\n",
      "resetting env. episode reward total was 8.0. running mean: -0.8011144300969307\n",
      "resetting env. episode reward total was 1.0. running mean: -0.7831032857959614\n",
      "resetting env. episode reward total was -8.0. running mean: -0.8552722529380018\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8767195304086218\n",
      "resetting env. episode reward total was -10.0. running mean: -0.9679523351045356\n",
      "resetting env. episode reward total was 4.0. running mean: -0.9182728117534902\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8690900836359552\n",
      "resetting env. episode reward total was 11.0. running mean: -0.7503991827995956\n",
      "resetting env. episode reward total was -13.0. running mean: -0.8728951909715996\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9341662390618837\n",
      "resetting env. episode reward total was -4.0. running mean: -0.9648245766712649\n",
      "resetting env. episode reward total was 5.0. running mean: -0.9051763309045522\n",
      "resetting env. episode reward total was -6.0. running mean: -0.9561245675955066\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9565633219195515\n",
      "resetting env. episode reward total was 11.0. running mean: -0.836997688700356\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8786277118133524\n",
      "resetting env. episode reward total was 8.0. running mean: -0.789841434695219\n",
      "resetting env. episode reward total was -4.0. running mean: -0.8219430203482668\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8237235901447841\n",
      "resetting env. episode reward total was 1.0. running mean: -0.8054863542433363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -11.0. running mean: -0.9074314907009029\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8583571757938938\n",
      "resetting env. episode reward total was 12.0. running mean: -0.7297736040359549\n",
      "resetting env. episode reward total was 1.0. running mean: -0.7124758679955954\n",
      "resetting env. episode reward total was 9.0. running mean: -0.6153511093156394\n",
      "resetting env. episode reward total was 5.0. running mean: -0.5591975982224829\n",
      "resetting env. episode reward total was -11.0. running mean: -0.6636056222402581\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7269695660178555\n",
      "resetting env. episode reward total was -7.0. running mean: -0.789699870357677\n",
      "resetting env. episode reward total was -9.0. running mean: -0.8718028716541002\n",
      "resetting env. episode reward total was 10.0. running mean: -0.7630848429375592\n",
      "resetting env. episode reward total was -10.0. running mean: -0.8554539945081836\n",
      "resetting env. episode reward total was 6.0. running mean: -0.7868994545631018\n",
      "resetting env. episode reward total was 11.0. running mean: -0.6690304600174708\n",
      "resetting env. episode reward total was -13.0. running mean: -0.7923401554172961\n",
      "resetting env. episode reward total was -15.0. running mean: -0.9344167538631232\n",
      "resetting env. episode reward total was 5.0. running mean: -0.8750725863244919\n",
      "resetting env. episode reward total was -1.0. running mean: -0.876321860461247\n",
      "resetting env. episode reward total was -11.0. running mean: -0.9775586418566345\n",
      "resetting env. episode reward total was -2.0. running mean: -0.9877830554380682\n",
      "resetting env. episode reward total was -3.0. running mean: -1.0079052248836875\n",
      "resetting env. episode reward total was -2.0. running mean: -1.0178261726348505\n",
      "resetting env. episode reward total was -7.0. running mean: -1.077647910908502\n",
      "resetting env. episode reward total was -1.0. running mean: -1.076871431799417\n",
      "resetting env. episode reward total was -10.0. running mean: -1.166102717481423\n",
      "resetting env. episode reward total was 7.0. running mean: -1.0844416903066085\n",
      "resetting env. episode reward total was -13.0. running mean: -1.2035972734035423\n",
      "resetting env. episode reward total was 7.0. running mean: -1.1215613006695069\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1403456876628117\n",
      "resetting env. episode reward total was 2.0. running mean: -1.1089422307861836\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1278528084783217\n",
      "resetting env. episode reward total was 4.0. running mean: -1.0765742803935385\n",
      "resetting env. episode reward total was 1.0. running mean: -1.0558085375896031\n",
      "resetting env. episode reward total was -4.0. running mean: -1.0852504522137072\n",
      "resetting env. episode reward total was 2.0. running mean: -1.0543979476915701\n",
      "resetting env. episode reward total was -7.0. running mean: -1.1138539682146544\n",
      "resetting env. episode reward total was 6.0. running mean: -1.0427154285325078\n",
      "resetting env. episode reward total was -2.0. running mean: -1.0522882742471826\n",
      "resetting env. episode reward total was -10.0. running mean: -1.1417653915047108\n",
      "resetting env. episode reward total was -5.0. running mean: -1.1803477375896638\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1985442602137673\n",
      "resetting env. episode reward total was 1.0. running mean: -1.1765588176116295\n",
      "resetting env. episode reward total was -12.0. running mean: -1.2847932294355133\n",
      "resetting env. episode reward total was -2.0. running mean: -1.2919452971411582\n",
      "resetting env. episode reward total was -3.0. running mean: -1.3090258441697467\n",
      "resetting env. episode reward total was -7.0. running mean: -1.3659355857280493\n",
      "resetting env. episode reward total was 7.0. running mean: -1.2822762298707688\n",
      "resetting env. episode reward total was 8.0. running mean: -1.1894534675720612\n",
      "resetting env. episode reward total was 11.0. running mean: -1.0675589328963404\n",
      "resetting env. episode reward total was -3.0. running mean: -1.086883343567377\n",
      "resetting env. episode reward total was 1.0. running mean: -1.0660145101317033\n",
      "resetting env. episode reward total was 7.0. running mean: -0.9853543650303862\n",
      "resetting env. episode reward total was -6.0. running mean: -1.0355008213800823\n",
      "resetting env. episode reward total was -3.0. running mean: -1.0551458131662814\n",
      "resetting env. episode reward total was 1.0. running mean: -1.0345943550346186\n",
      "resetting env. episode reward total was 1.0. running mean: -1.0142484114842725\n",
      "resetting env. episode reward total was -3.0. running mean: -1.0341059273694297\n",
      "resetting env. episode reward total was -7.0. running mean: -1.0937648680957355\n",
      "resetting env. episode reward total was -12.0. running mean: -1.202827219414778\n",
      "resetting env. episode reward total was -7.0. running mean: -1.2607989472206302\n",
      "resetting env. episode reward total was 5.0. running mean: -1.198190957748424\n",
      "resetting env. episode reward total was 7.0. running mean: -1.1162090481709397\n",
      "resetting env. episode reward total was 6.0. running mean: -1.0450469576892303\n",
      "resetting env. episode reward total was -7.0. running mean: -1.104596488112338\n",
      "resetting env. episode reward total was -1.0. running mean: -1.1035505232312146\n",
      "resetting env. episode reward total was 6.0. running mean: -1.0325150179989024\n",
      "resetting env. episode reward total was 8.0. running mean: -0.9421898678189135\n",
      "resetting env. episode reward total was -4.0. running mean: -0.9727679691407244\n",
      "resetting env. episode reward total was 1.0. running mean: -0.9530402894493172\n",
      "resetting env. episode reward total was -9.0. running mean: -1.033509886554824\n",
      "resetting env. episode reward total was -3.0. running mean: -1.0531747876892759\n",
      "resetting env. episode reward total was -9.0. running mean: -1.1326430398123832\n",
      "resetting env. episode reward total was 5.0. running mean: -1.0713166094142594\n",
      "resetting env. episode reward total was 7.0. running mean: -0.9906034433201167\n",
      "resetting env. episode reward total was 7.0. running mean: -0.9106974088869155\n",
      "resetting env. episode reward total was -8.0. running mean: -0.9815904347980463\n",
      "resetting env. episode reward total was 5.0. running mean: -0.9217745304500657\n",
      "resetting env. episode reward total was 6.0. running mean: -0.8525567851455651\n",
      "resetting env. episode reward total was 8.0. running mean: -0.7640312172941095\n",
      "resetting env. episode reward total was -1.0. running mean: -0.7663909051211684\n",
      "resetting env. episode reward total was 6.0. running mean: -0.6987269960699567\n",
      "resetting env. episode reward total was 4.0. running mean: -0.6517397261092571\n",
      "resetting env. episode reward total was 8.0. running mean: -0.5652223288481646\n",
      "resetting env. episode reward total was 3.0. running mean: -0.5295701055596829\n",
      "resetting env. episode reward total was 3.0. running mean: -0.494274404504086\n",
      "resetting env. episode reward total was 5.0. running mean: -0.43933166045904515\n",
      "resetting env. episode reward total was -5.0. running mean: -0.48493834385445467\n",
      "resetting env. episode reward total was -2.0. running mean: -0.5000889604159101\n",
      "resetting env. episode reward total was -1.0. running mean: -0.505088070811751\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5100371901036335\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5149368182025972\n",
      "resetting env. episode reward total was -5.0. running mean: -0.5597874500205713\n",
      "resetting env. episode reward total was 11.0. running mean: -0.44418957552036553\n",
      "resetting env. episode reward total was -1.0. running mean: -0.4497476797651619\n",
      "resetting env. episode reward total was 7.0. running mean: -0.37525020296751027\n",
      "resetting env. episode reward total was 6.0. running mean: -0.3114977009378352\n",
      "resetting env. episode reward total was -10.0. running mean: -0.40838272392845687\n",
      "resetting env. episode reward total was -8.0. running mean: -0.4842988966891723\n",
      "resetting env. episode reward total was -1.0. running mean: -0.4894559077222806\n",
      "resetting env. episode reward total was 11.0. running mean: -0.3745613486450578\n",
      "resetting env. episode reward total was -5.0. running mean: -0.4208157351586072\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4466075778070211\n",
      "resetting env. episode reward total was -2.0. running mean: -0.4621415020289509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: -0.49752008700866135\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5225448861385747\n",
      "resetting env. episode reward total was 2.0. running mean: -0.49731943727718897\n",
      "resetting env. episode reward total was 10.0. running mean: -0.3923462429044171\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3584227804753729\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3248385526706191\n",
      "resetting env. episode reward total was -4.0. running mean: -0.3615901671439129\n",
      "resetting env. episode reward total was 11.0. running mean: -0.24797426547247375\n",
      "resetting env. episode reward total was -7.0. running mean: -0.31549452281774903\n",
      "resetting env. episode reward total was -7.0. running mean: -0.38233957758957154\n",
      "resetting env. episode reward total was -1.0. running mean: -0.3885161818136758\n",
      "resetting env. episode reward total was -4.0. running mean: -0.42463101999553904\n",
      "resetting env. episode reward total was 12.0. running mean: -0.3003847097955836\n",
      "resetting env. episode reward total was 12.0. running mean: -0.17738086269762782\n",
      "resetting env. episode reward total was -8.0. running mean: -0.25560705407065154\n",
      "resetting env. episode reward total was -9.0. running mean: -0.343050983529945\n",
      "resetting env. episode reward total was 4.0. running mean: -0.29962047369464556\n",
      "resetting env. episode reward total was -9.0. running mean: -0.3866242689576991\n",
      "resetting env. episode reward total was 2.0. running mean: -0.3627580262681221\n",
      "resetting env. episode reward total was 1.0. running mean: -0.34913044600544085\n",
      "resetting env. episode reward total was -11.0. running mean: -0.45563914154538643\n",
      "resetting env. episode reward total was 4.0. running mean: -0.41108275012993256\n",
      "resetting env. episode reward total was -7.0. running mean: -0.47697192262863325\n",
      "resetting env. episode reward total was 4.0. running mean: -0.43220220340234694\n",
      "resetting env. episode reward total was -4.0. running mean: -0.46788018136832343\n",
      "resetting env. episode reward total was 13.0. running mean: -0.3332013795546402\n",
      "resetting env. episode reward total was -8.0. running mean: -0.4098693657590938\n",
      "resetting env. episode reward total was -8.0. running mean: -0.4857706721015028\n",
      "resetting env. episode reward total was -5.0. running mean: -0.5309129653804878\n",
      "resetting env. episode reward total was 10.0. running mean: -0.4256038357266829\n",
      "resetting env. episode reward total was -2.0. running mean: -0.4413477973694161\n",
      "resetting env. episode reward total was 12.0. running mean: -0.3169343193957219\n",
      "resetting env. episode reward total was 6.0. running mean: -0.2537649762017647\n",
      "resetting env. episode reward total was -5.0. running mean: -0.30122732643974703\n",
      "resetting env. episode reward total was 7.0. running mean: -0.22821505317534957\n",
      "resetting env. episode reward total was 9.0. running mean: -0.1359329026435961\n",
      "resetting env. episode reward total was 6.0. running mean: -0.07457357361716013\n",
      "resetting env. episode reward total was -3.0. running mean: -0.10382783788098852\n",
      "resetting env. episode reward total was 3.0. running mean: -0.07278955950217864\n",
      "resetting env. episode reward total was -13.0. running mean: -0.20206166390715685\n",
      "resetting env. episode reward total was -12.0. running mean: -0.32004104726808524\n",
      "resetting env. episode reward total was 7.0. running mean: -0.24684063679540436\n",
      "resetting env. episode reward total was -1.0. running mean: -0.25437223042745033\n",
      "resetting env. episode reward total was -8.0. running mean: -0.3318285081231758\n",
      "resetting env. episode reward total was 2.0. running mean: -0.30851022304194403\n",
      "resetting env. episode reward total was -3.0. running mean: -0.33542512081152454\n",
      "resetting env. episode reward total was -7.0. running mean: -0.4020708696034093\n",
      "resetting env. episode reward total was -3.0. running mean: -0.42805016090737524\n",
      "resetting env. episode reward total was 5.0. running mean: -0.37376965929830147\n",
      "resetting env. episode reward total was 9.0. running mean: -0.2800319627053185\n",
      "resetting env. episode reward total was 3.0. running mean: -0.2472316430782653\n",
      "resetting env. episode reward total was 7.0. running mean: -0.17475932664748264\n",
      "resetting env. episode reward total was -5.0. running mean: -0.22301173338100783\n",
      "resetting env. episode reward total was -10.0. running mean: -0.3207816160471978\n",
      "resetting env. episode reward total was -8.0. running mean: -0.3975737998867258\n",
      "resetting env. episode reward total was 1.0. running mean: -0.38359806188785855\n",
      "resetting env. episode reward total was -13.0. running mean: -0.50976208126898\n",
      "resetting env. episode reward total was 12.0. running mean: -0.3846644604562902\n",
      "resetting env. episode reward total was -7.0. running mean: -0.4508178158517273\n",
      "resetting env. episode reward total was -1.0. running mean: -0.45630963769321004\n",
      "resetting env. episode reward total was -7.0. running mean: -0.521746541316278\n",
      "resetting env. episode reward total was -9.0. running mean: -0.6065290759031151\n",
      "resetting env. episode reward total was -4.0. running mean: -0.640463785144084\n",
      "resetting env. episode reward total was -3.0. running mean: -0.6640591472926431\n",
      "resetting env. episode reward total was -5.0. running mean: -0.7074185558197168\n",
      "resetting env. episode reward total was 5.0. running mean: -0.6503443702615196\n",
      "resetting env. episode reward total was -4.0. running mean: -0.6838409265589044\n",
      "resetting env. episode reward total was 10.0. running mean: -0.5770025172933153\n",
      "resetting env. episode reward total was 5.0. running mean: -0.5212324921203821\n",
      "resetting env. episode reward total was 8.0. running mean: -0.4360201671991783\n",
      "resetting env. episode reward total was 1.0. running mean: -0.4216599655271865\n",
      "resetting env. episode reward total was 7.0. running mean: -0.3474433658719146\n",
      "resetting env. episode reward total was -1.0. running mean: -0.3539689322131955\n",
      "resetting env. episode reward total was -1.0. running mean: -0.36042924289106354\n",
      "resetting env. episode reward total was -5.0. running mean: -0.4068249504621529\n",
      "resetting env. episode reward total was 3.0. running mean: -0.37275670095753133\n",
      "resetting env. episode reward total was 4.0. running mean: -0.329029133947956\n",
      "resetting env. episode reward total was -7.0. running mean: -0.39573884260847647\n",
      "resetting env. episode reward total was -1.0. running mean: -0.4017814541823917\n",
      "resetting env. episode reward total was -8.0. running mean: -0.4777636396405678\n",
      "resetting env. episode reward total was -1.0. running mean: -0.48298600324416213\n",
      "resetting env. episode reward total was 1.0. running mean: -0.4681561432117205\n",
      "resetting env. episode reward total was 9.0. running mean: -0.37347458177960324\n",
      "resetting env. episode reward total was 8.0. running mean: -0.2897398359618072\n",
      "resetting env. episode reward total was 9.0. running mean: -0.19684243760218914\n",
      "resetting env. episode reward total was 5.0. running mean: -0.14487401322616722\n",
      "resetting env. episode reward total was 1.0. running mean: -0.13342527309390553\n",
      "resetting env. episode reward total was 7.0. running mean: -0.06209102036296646\n",
      "resetting env. episode reward total was 6.0. running mean: -0.0014701101593367974\n",
      "resetting env. episode reward total was 10.0. running mean: 0.09854459094225658\n",
      "resetting env. episode reward total was 10.0. running mean: 0.197559145032834\n",
      "resetting env. episode reward total was 14.0. running mean: 0.3355835535825057\n",
      "resetting env. episode reward total was 1.0. running mean: 0.3422277180466806\n",
      "resetting env. episode reward total was -13.0. running mean: 0.20880544086621383\n",
      "resetting env. episode reward total was -1.0. running mean: 0.19671738645755169\n",
      "resetting env. episode reward total was 6.0. running mean: 0.25475021259297614\n",
      "resetting env. episode reward total was 7.0. running mean: 0.3222027104670464\n",
      "resetting env. episode reward total was -6.0. running mean: 0.25898068336237595\n",
      "resetting env. episode reward total was -12.0. running mean: 0.1363908765287522\n",
      "resetting env. episode reward total was -3.0. running mean: 0.10502696776346468\n",
      "resetting env. episode reward total was 10.0. running mean: 0.20397669808583002\n",
      "resetting env. episode reward total was 12.0. running mean: 0.3219369311049717\n",
      "resetting env. episode reward total was 13.0. running mean: 0.44871756179392197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 0.49423038617598275\n",
      "resetting env. episode reward total was -4.0. running mean: 0.44928808231422296\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4647952014910807\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5501472494761699\n",
      "resetting env. episode reward total was -7.0. running mean: 0.47464577698140814\n",
      "resetting env. episode reward total was -9.0. running mean: 0.37989931921159403\n",
      "resetting env. episode reward total was -1.0. running mean: 0.36610032601947806\n",
      "resetting env. episode reward total was -3.0. running mean: 0.33243932275928323\n",
      "resetting env. episode reward total was 2.0. running mean: 0.34911492953169043\n",
      "resetting env. episode reward total was 10.0. running mean: 0.4456237802363735\n",
      "resetting env. episode reward total was -8.0. running mean: 0.3611675424340097\n",
      "resetting env. episode reward total was 1.0. running mean: 0.36755586700966963\n",
      "resetting env. episode reward total was 9.0. running mean: 0.45388030833957294\n",
      "resetting env. episode reward total was 7.0. running mean: 0.5193415052561772\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5241480902036154\n",
      "resetting env. episode reward total was 10.0. running mean: 0.6189066093015793\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6327175432085634\n",
      "resetting env. episode reward total was 9.0. running mean: 0.7163903677764778\n",
      "resetting env. episode reward total was 6.0. running mean: 0.769226464098713\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8215341994577259\n",
      "resetting env. episode reward total was 15.0. running mean: 0.9633188574631486\n",
      "resetting env. episode reward total was -8.0. running mean: 0.8736856688885172\n",
      "resetting env. episode reward total was -2.0. running mean: 0.844948812199632\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8764993240776358\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8577343308368593\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8291569875284908\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8408654176532059\n",
      "resetting env. episode reward total was 16.0. running mean: 0.9924567634766739\n",
      "resetting env. episode reward total was 12.0. running mean: 1.1025321958419072\n",
      "resetting env. episode reward total was 9.0. running mean: 1.1815068738834882\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2296918051446533\n",
      "resetting env. episode reward total was 7.0. running mean: 1.2873948870932068\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3345209382222747\n",
      "resetting env. episode reward total was 4.0. running mean: 1.361175728840052\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3575639715516514\n",
      "resetting env. episode reward total was 7.0. running mean: 1.413988331836135\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4298484485177736\n",
      "resetting env. episode reward total was 3.0. running mean: 1.445549964032596\n",
      "resetting env. episode reward total was 14.0. running mean: 1.57109446439227\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5053835197483472\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5303296845508638\n",
      "resetting env. episode reward total was -3.0. running mean: 1.485026387705355\n",
      "resetting env. episode reward total was 14.0. running mean: 1.6101761238283014\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5840743625900184\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5782336189641182\n",
      "resetting env. episode reward total was 6.0. running mean: 1.622451282774477\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6262267699467323\n",
      "resetting env. episode reward total was -10.0. running mean: 1.509964502247265\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5548648572247923\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6193162086525443\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5831230465660189\n",
      "resetting env. episode reward total was 11.0. running mean: 1.6772918161003587\n",
      "resetting env. episode reward total was 5.0. running mean: 1.710518897939355\n",
      "resetting env. episode reward total was -4.0. running mean: 1.6534137089599614\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6468795718703617\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6404107761516582\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6540066683901415\n",
      "resetting env. episode reward total was 5.0. running mean: 1.68746660170624\n",
      "resetting env. episode reward total was -13.0. running mean: 1.5405919356891777\n",
      "resetting env. episode reward total was 10.0. running mean: 1.625186016332286\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5689341561689631\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5232448146072735\n",
      "resetting env. episode reward total was -4.0. running mean: 1.4680123664612006\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4033322427965886\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3392989203686227\n",
      "resetting env. episode reward total was 11.0. running mean: 1.4359059311649367\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3715468718532873\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3278314031347545\n",
      "resetting env. episode reward total was -8.0. running mean: 1.2345530891034069\n",
      "resetting env. episode reward total was 11.0. running mean: 1.332207558212373\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3888854826302492\n",
      "resetting env. episode reward total was 9.0. running mean: 1.4649966278039468\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5503466615259074\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5948431949106483\n",
      "resetting env. episode reward total was -10.0. running mean: 1.4788947629615417\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4841058153319262\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4592647571786068\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4346721096068207\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4303253885107525\n",
      "resetting env. episode reward total was 5.0. running mean: 1.466022134625645\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5513619132793885\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6258482941465948\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6795898112051288\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6527939130930775\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6862659739621468\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7494033142225254\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6819092810803\n",
      "resetting env. episode reward total was -5.0. running mean: 1.615090188269497\n",
      "resetting env. episode reward total was 11.0. running mean: 1.708939286386802\n",
      "resetting env. episode reward total was 3.0. running mean: 1.721849893522934\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7246313945877048\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7573850806418276\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7498112298354094\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6823131175370551\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6054899863616845\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6294350864980676\n",
      "resetting env. episode reward total was -9.0. running mean: 1.5231407356330868\n",
      "resetting env. episode reward total was 2.0. running mean: 1.527909328276756\n",
      "resetting env. episode reward total was -7.0. running mean: 1.4426302349939883\n",
      "resetting env. episode reward total was -4.0. running mean: 1.3882039326440485\n",
      "resetting env. episode reward total was -7.0. running mean: 1.304321893317608\n",
      "resetting env. episode reward total was -3.0. running mean: 1.2612786743844318\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2686658876405874\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3059792287641816\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3429194364765398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 1.3894902421117745\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4255953396906569\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3913393862937502\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3874259924308128\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3535517325065045\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3500162151814394\n",
      "resetting env. episode reward total was -1.0. running mean: 1.326516053029625\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3632508924993287\n",
      "resetting env. episode reward total was 10.0. running mean: 1.4496183835743355\n",
      "resetting env. episode reward total was -8.0. running mean: 1.355122199738592\n",
      "resetting env. episode reward total was -8.0. running mean: 1.261570977741206\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2889552679637941\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3160657152841562\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3729050581313147\n",
      "resetting env. episode reward total was 3.0. running mean: 1.3891760075500015\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3252842474745015\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3520314049997564\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2885110909497588\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3256259800402612\n",
      "resetting env. episode reward total was 10.0. running mean: 1.4123697202398586\n",
      "resetting env. episode reward total was 1.0. running mean: 1.40824602303746\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4341635628070855\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4298219271790147\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3855237079072245\n",
      "resetting env. episode reward total was -3.0. running mean: 1.341668470828152\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3982517861198707\n",
      "resetting env. episode reward total was 4.0. running mean: 1.424269268258672\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4700265755760853\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5353263098203245\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5099730467221213\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5648733162549002\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5692245830923512\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5735323372614278\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5177970138888135\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4526190437499253\n",
      "resetting env. episode reward total was 6.0. running mean: 1.498092853312426\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5231119247793017\n",
      "resetting env. episode reward total was 9.0. running mean: 1.5978808055315088\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6119019974761937\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5857829775014316\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5399251477264173\n",
      "resetting env. episode reward total was -5.0. running mean: 1.474525896249153\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4097806372866615\n",
      "resetting env. episode reward total was 9.0. running mean: 1.4856828309137948\n",
      "resetting env. episode reward total was 5.0. running mean: 1.520826002604657\n",
      "resetting env. episode reward total was -7.0. running mean: 1.4356177425786103\n",
      "resetting env. episode reward total was -9.0. running mean: 1.3312615651528241\n",
      "resetting env. episode reward total was 3.0. running mean: 1.347948949501296\n",
      "resetting env. episode reward total was 4.0. running mean: 1.374469460006283\n",
      "resetting env. episode reward total was 10.0. running mean: 1.4607247654062203\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5161175177521582\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5209563425746366\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4757467791488903\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4709893113574013\n",
      "resetting env. episode reward total was -2.0. running mean: 1.4362794182438272\n",
      "resetting env. episode reward total was -1.0. running mean: 1.411916624061389\n",
      "resetting env. episode reward total was -5.0. running mean: 1.347797457820775\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3443194832425673\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3208762884101417\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3276675255260404\n",
      "resetting env. episode reward total was 12.0. running mean: 1.43439085027078\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4600469417680724\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4554464723503917\n",
      "resetting env. episode reward total was 8.0. running mean: 1.520892007626888\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6056830875506192\n",
      "resetting env. episode reward total was -11.0. running mean: 1.4796262566751128\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4848299941083618\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4999816941672781\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5149818772256054\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5998320584533494\n",
      "resetting env. episode reward total was -8.0. running mean: 1.5038337378688158\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5187954004901276\n",
      "resetting env. episode reward total was -7.0. running mean: 1.4336074464852262\n",
      "resetting env. episode reward total was 8.0. running mean: 1.499271372020374\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4542786583001703\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5197358717171687\n",
      "resetting env. episode reward total was -4.0. running mean: 1.464538512999997\n",
      "resetting env. episode reward total was -5.0. running mean: 1.399893127869997\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4458941965912973\n",
      "resetting env. episode reward total was -2.0. running mean: 1.4114352546253843\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3873209020791304\n",
      "resetting env. episode reward total was -5.0. running mean: 1.323447693058339\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3002132161277555\n",
      "resetting env. episode reward total was 7.0. running mean: 1.357211083966478\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2936389731268132\n",
      "resetting env. episode reward total was 9.0. running mean: 1.370702583395545\n",
      "resetting env. episode reward total was -6.0. running mean: 1.2969955575615895\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2340256019859734\n",
      "resetting env. episode reward total was -7.0. running mean: 1.1516853459661136\n",
      "resetting env. episode reward total was -5.0. running mean: 1.0901684925064523\n",
      "resetting env. episode reward total was -5.0. running mean: 1.0292668075813878\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0789741395055739\n",
      "resetting env. episode reward total was -15.0. running mean: 0.9181843981105181\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9390025541294129\n",
      "resetting env. episode reward total was -6.0. running mean: 0.8696125285881189\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9109164033022378\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8918072392692153\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9328891668765232\n",
      "resetting env. episode reward total was -8.0. running mean: 0.843560275207758\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8751246724556805\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8463734257311236\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8079096914738123\n",
      "resetting env. episode reward total was -6.0. running mean: 0.7398305945590742\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7124322886134834\n",
      "resetting env. episode reward total was -11.0. running mean: 0.5953079657273486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: 0.559354886070075\n",
      "resetting env. episode reward total was -11.0. running mean: 0.4437613372093743\n",
      "resetting env. episode reward total was -6.0. running mean: 0.3793237238372805\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3455304865989077\n",
      "resetting env. episode reward total was 7.0. running mean: 0.4120751817329186\n",
      "resetting env. episode reward total was 5.0. running mean: 0.45795442991558943\n",
      "resetting env. episode reward total was -15.0. running mean: 0.30337488561643355\n",
      "resetting env. episode reward total was -3.0. running mean: 0.27034113676026916\n",
      "resetting env. episode reward total was -10.0. running mean: 0.16763772539266644\n",
      "resetting env. episode reward total was -1.0. running mean: 0.15596134813873977\n",
      "resetting env. episode reward total was 4.0. running mean: 0.1944017346573524\n",
      "resetting env. episode reward total was 11.0. running mean: 0.30245771731077886\n",
      "resetting env. episode reward total was -11.0. running mean: 0.1894331401376711\n",
      "resetting env. episode reward total was -9.0. running mean: 0.09753880873629439\n",
      "resetting env. episode reward total was -2.0. running mean: 0.07656342064893144\n",
      "resetting env. episode reward total was -9.0. running mean: -0.014202213557557866\n",
      "resetting env. episode reward total was -9.0. running mean: -0.10406019142198228\n",
      "resetting env. episode reward total was 5.0. running mean: -0.05301958950776245\n",
      "resetting env. episode reward total was -5.0. running mean: -0.10248939361268483\n",
      "resetting env. episode reward total was -5.0. running mean: -0.15146449967655798\n",
      "resetting env. episode reward total was 7.0. running mean: -0.0799498546797924\n",
      "resetting env. episode reward total was 6.0. running mean: -0.019150356132994484\n",
      "resetting env. episode reward total was -11.0. running mean: -0.12895885257166453\n",
      "resetting env. episode reward total was 1.0. running mean: -0.1176692640459479\n",
      "resetting env. episode reward total was -7.0. running mean: -0.18649257140548842\n",
      "resetting env. episode reward total was -9.0. running mean: -0.2746276456914335\n",
      "resetting env. episode reward total was -11.0. running mean: -0.38188136923451915\n",
      "resetting env. episode reward total was 11.0. running mean: -0.26806255554217395\n",
      "resetting env. episode reward total was -2.0. running mean: -0.2853819299867522\n",
      "resetting env. episode reward total was -2.0. running mean: -0.30252811068688473\n",
      "resetting env. episode reward total was -1.0. running mean: -0.3095028295800159\n",
      "resetting env. episode reward total was 10.0. running mean: -0.20640780128421574\n",
      "resetting env. episode reward total was 4.0. running mean: -0.16434372327137356\n",
      "resetting env. episode reward total was 5.0. running mean: -0.11270028603865982\n",
      "resetting env. episode reward total was 10.0. running mean: -0.01157328317827322\n",
      "resetting env. episode reward total was -2.0. running mean: -0.03145755034649049\n",
      "resetting env. episode reward total was -4.0. running mean: -0.07114297484302559\n",
      "resetting env. episode reward total was -10.0. running mean: -0.17043154509459535\n",
      "resetting env. episode reward total was 4.0. running mean: -0.12872722964364938\n",
      "resetting env. episode reward total was -7.0. running mean: -0.1974399573472129\n",
      "resetting env. episode reward total was -3.0. running mean: -0.22546555777374078\n",
      "resetting env. episode reward total was -7.0. running mean: -0.2932109021960034\n",
      "resetting env. episode reward total was 13.0. running mean: -0.1602787931740433\n",
      "resetting env. episode reward total was -7.0. running mean: -0.2286760052423029\n",
      "resetting env. episode reward total was 8.0. running mean: -0.14638924518987984\n",
      "resetting env. episode reward total was -7.0. running mean: -0.21492535273798105\n",
      "resetting env. episode reward total was -7.0. running mean: -0.2827760992106012\n",
      "resetting env. episode reward total was -8.0. running mean: -0.3599483382184952\n",
      "resetting env. episode reward total was -1.0. running mean: -0.36634885483631024\n",
      "resetting env. episode reward total was 6.0. running mean: -0.3026853662879471\n",
      "resetting env. episode reward total was 1.0. running mean: -0.28965851262506764\n",
      "resetting env. episode reward total was -8.0. running mean: -0.366761927498817\n",
      "resetting env. episode reward total was -3.0. running mean: -0.39309430822382885\n",
      "resetting env. episode reward total was 7.0. running mean: -0.31916336514159055\n",
      "resetting env. episode reward total was 6.0. running mean: -0.25597173149017466\n",
      "resetting env. episode reward total was -4.0. running mean: -0.2934120141752729\n",
      "resetting env. episode reward total was 1.0. running mean: -0.2804778940335202\n",
      "resetting env. episode reward total was -7.0. running mean: -0.347673115093185\n",
      "resetting env. episode reward total was -5.0. running mean: -0.39419638394225315\n",
      "resetting env. episode reward total was 2.0. running mean: -0.3702544201028306\n",
      "resetting env. episode reward total was -1.0. running mean: -0.3765518759018023\n",
      "resetting env. episode reward total was -10.0. running mean: -0.4727863571427843\n",
      "resetting env. episode reward total was -2.0. running mean: -0.48805849357135644\n",
      "resetting env. episode reward total was 13.0. running mean: -0.35317790863564286\n",
      "resetting env. episode reward total was -3.0. running mean: -0.37964612954928645\n",
      "resetting env. episode reward total was -8.0. running mean: -0.4558496682537936\n",
      "resetting env. episode reward total was -11.0. running mean: -0.5612911715712556\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5456782598555431\n",
      "resetting env. episode reward total was -7.0. running mean: -0.6102214772569876\n",
      "resetting env. episode reward total was -9.0. running mean: -0.6941192624844177\n",
      "resetting env. episode reward total was -10.0. running mean: -0.7871780698595735\n",
      "resetting env. episode reward total was -11.0. running mean: -0.8893062891609778\n",
      "resetting env. episode reward total was -13.0. running mean: -1.010413226269368\n",
      "resetting env. episode reward total was -7.0. running mean: -1.0703090940066742\n",
      "resetting env. episode reward total was -9.0. running mean: -1.1496060030666075\n",
      "resetting env. episode reward total was -1.0. running mean: -1.1481099430359414\n",
      "resetting env. episode reward total was -6.0. running mean: -1.196628843605582\n",
      "resetting env. episode reward total was -5.0. running mean: -1.2346625551695263\n",
      "resetting env. episode reward total was -17.0. running mean: -1.392315929617831\n",
      "resetting env. episode reward total was -9.0. running mean: -1.4683927703216526\n",
      "resetting env. episode reward total was -7.0. running mean: -1.5237088426184362\n",
      "resetting env. episode reward total was -19.0. running mean: -1.6984717541922518\n",
      "resetting env. episode reward total was -8.0. running mean: -1.7614870366503295\n",
      "resetting env. episode reward total was 1.0. running mean: -1.7338721662838261\n",
      "resetting env. episode reward total was 5.0. running mean: -1.6665334446209878\n",
      "resetting env. episode reward total was -6.0. running mean: -1.709868110174778\n",
      "resetting env. episode reward total was 1.0. running mean: -1.6827694290730302\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6959417347822998\n",
      "resetting env. episode reward total was -1.0. running mean: -1.688982317434477\n",
      "resetting env. episode reward total was -13.0. running mean: -1.802092494260132\n",
      "resetting env. episode reward total was 1.0. running mean: -1.7740715693175306\n",
      "resetting env. episode reward total was 5.0. running mean: -1.7063308536243553\n",
      "resetting env. episode reward total was -5.0. running mean: -1.7392675450881119\n",
      "resetting env. episode reward total was 10.0. running mean: -1.6218748696372307\n",
      "resetting env. episode reward total was -2.0. running mean: -1.6256561209408584\n",
      "resetting env. episode reward total was -7.0. running mean: -1.67939955973145\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6926055641341355\n",
      "resetting env. episode reward total was -11.0. running mean: -1.7856795084927943\n",
      "resetting env. episode reward total was -7.0. running mean: -1.8378227134078664\n",
      "resetting env. episode reward total was -9.0. running mean: -1.9094444862737878\n",
      "resetting env. episode reward total was -7.0. running mean: -1.96035004141105\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9707465409969396\n",
      "resetting env. episode reward total was -5.0. running mean: -2.00103907558697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -2.0510286848311003\n",
      "resetting env. episode reward total was -5.0. running mean: -2.080518397982789\n",
      "resetting env. episode reward total was 1.0. running mean: -2.0497132140029612\n",
      "resetting env. episode reward total was 2.0. running mean: -2.0092160818629314\n",
      "resetting env. episode reward total was -9.0. running mean: -2.079123921044302\n",
      "resetting env. episode reward total was -7.0. running mean: -2.128332681833859\n",
      "resetting env. episode reward total was 5.0. running mean: -2.0570493550155207\n",
      "resetting env. episode reward total was -11.0. running mean: -2.1464788614653654\n",
      "resetting env. episode reward total was -8.0. running mean: -2.205014072850712\n",
      "resetting env. episode reward total was -15.0. running mean: -2.3329639321222047\n",
      "resetting env. episode reward total was -1.0. running mean: -2.3196342928009823\n",
      "resetting env. episode reward total was -7.0. running mean: -2.366437949872972\n",
      "resetting env. episode reward total was -4.0. running mean: -2.3827735703742423\n",
      "resetting env. episode reward total was -1.0. running mean: -2.3689458346704995\n",
      "resetting env. episode reward total was -7.0. running mean: -2.415256376323794\n",
      "resetting env. episode reward total was -11.0. running mean: -2.5011038125605562\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5260927744349506\n",
      "resetting env. episode reward total was -8.0. running mean: -2.580831846690601\n",
      "resetting env. episode reward total was -12.0. running mean: -2.675023528223695\n",
      "resetting env. episode reward total was 2.0. running mean: -2.628273292941458\n",
      "resetting env. episode reward total was -3.0. running mean: -2.631990560012043\n",
      "resetting env. episode reward total was -1.0. running mean: -2.615670654411922\n",
      "resetting env. episode reward total was -14.0. running mean: -2.729513947867803\n",
      "resetting env. episode reward total was 13.0. running mean: -2.5722188083891253\n",
      "resetting env. episode reward total was -7.0. running mean: -2.616496620305234\n",
      "resetting env. episode reward total was -6.0. running mean: -2.6503316541021817\n",
      "resetting env. episode reward total was 3.0. running mean: -2.59382833756116\n",
      "resetting env. episode reward total was -5.0. running mean: -2.6178900541855485\n",
      "resetting env. episode reward total was 5.0. running mean: -2.541711153643693\n",
      "resetting env. episode reward total was -1.0. running mean: -2.526294042107256\n",
      "resetting env. episode reward total was -8.0. running mean: -2.5810311016861833\n",
      "resetting env. episode reward total was -12.0. running mean: -2.6752207906693215\n",
      "resetting env. episode reward total was -2.0. running mean: -2.668468582762628\n",
      "resetting env. episode reward total was 6.0. running mean: -2.581783896935002\n",
      "resetting env. episode reward total was 2.0. running mean: -2.535966057965652\n",
      "resetting env. episode reward total was 8.0. running mean: -2.4306063973859953\n",
      "resetting env. episode reward total was 4.0. running mean: -2.366300333412135\n",
      "resetting env. episode reward total was -1.0. running mean: -2.3526373300780135\n",
      "resetting env. episode reward total was -7.0. running mean: -2.3991109567772333\n",
      "resetting env. episode reward total was -6.0. running mean: -2.435119847209461\n",
      "resetting env. episode reward total was -7.0. running mean: -2.4807686487373664\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5059609622499925\n",
      "resetting env. episode reward total was 7.0. running mean: -2.410901352627493\n",
      "resetting env. episode reward total was -2.0. running mean: -2.406792339101218\n",
      "resetting env. episode reward total was -4.0. running mean: -2.422724415710206\n",
      "resetting env. episode reward total was -13.0. running mean: -2.528497171553104\n",
      "resetting env. episode reward total was 3.0. running mean: -2.473212199837573\n",
      "resetting env. episode reward total was -11.0. running mean: -2.558480077839197\n",
      "resetting env. episode reward total was 2.0. running mean: -2.5128952770608053\n",
      "resetting env. episode reward total was 2.0. running mean: -2.467766324290197\n",
      "resetting env. episode reward total was 3.0. running mean: -2.4130886610472952\n",
      "resetting env. episode reward total was 12.0. running mean: -2.268957774436822\n",
      "resetting env. episode reward total was -9.0. running mean: -2.336268196692454\n",
      "resetting env. episode reward total was 3.0. running mean: -2.2829055147255297\n",
      "resetting env. episode reward total was 2.0. running mean: -2.2400764595782743\n",
      "resetting env. episode reward total was 4.0. running mean: -2.1776756949824914\n",
      "resetting env. episode reward total was -6.0. running mean: -2.2158989380326664\n",
      "resetting env. episode reward total was -6.0. running mean: -2.2537399486523397\n",
      "resetting env. episode reward total was 9.0. running mean: -2.1412025491658166\n",
      "resetting env. episode reward total was 10.0. running mean: -2.0197905236741582\n",
      "resetting env. episode reward total was 4.0. running mean: -1.9595926184374166\n",
      "resetting env. episode reward total was -7.0. running mean: -2.0099966922530426\n",
      "resetting env. episode reward total was 10.0. running mean: -1.8898967253305121\n",
      "resetting env. episode reward total was 7.0. running mean: -1.800997758077207\n",
      "resetting env. episode reward total was -10.0. running mean: -1.882987780496435\n",
      "resetting env. episode reward total was -10.0. running mean: -1.9641579026914708\n",
      "resetting env. episode reward total was -4.0. running mean: -1.9845163236645562\n",
      "resetting env. episode reward total was 5.0. running mean: -1.9146711604279105\n",
      "resetting env. episode reward total was 6.0. running mean: -1.8355244488236313\n",
      "resetting env. episode reward total was -6.0. running mean: -1.8771692043353951\n",
      "resetting env. episode reward total was -11.0. running mean: -1.9683975122920412\n",
      "resetting env. episode reward total was -2.0. running mean: -1.9687135371691207\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9190264017974294\n",
      "resetting env. episode reward total was -3.0. running mean: -1.929836137779455\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9205377764016605\n",
      "resetting env. episode reward total was -13.0. running mean: -2.0313323986376437\n",
      "resetting env. episode reward total was -8.0. running mean: -2.091019074651267\n",
      "resetting env. episode reward total was -5.0. running mean: -2.1201088839047544\n",
      "resetting env. episode reward total was -7.0. running mean: -2.1689077950657065\n",
      "resetting env. episode reward total was -3.0. running mean: -2.1772187171150494\n",
      "resetting env. episode reward total was 5.0. running mean: -2.105446529943899\n",
      "resetting env. episode reward total was 1.0. running mean: -2.0743920646444605\n",
      "resetting env. episode reward total was -11.0. running mean: -2.1636481439980155\n",
      "resetting env. episode reward total was -9.0. running mean: -2.232011662558035\n",
      "resetting env. episode reward total was -5.0. running mean: -2.2596915459324545\n",
      "resetting env. episode reward total was -12.0. running mean: -2.35709463047313\n",
      "resetting env. episode reward total was 9.0. running mean: -2.243523684168399\n",
      "resetting env. episode reward total was 3.0. running mean: -2.1910884473267154\n",
      "resetting env. episode reward total was -1.0. running mean: -2.179177562853448\n",
      "resetting env. episode reward total was 7.0. running mean: -2.0873857872249135\n",
      "resetting env. episode reward total was -9.0. running mean: -2.1565119293526642\n",
      "resetting env. episode reward total was 5.0. running mean: -2.084946810059138\n",
      "resetting env. episode reward total was -1.0. running mean: -2.0740973419585464\n",
      "resetting env. episode reward total was 1.0. running mean: -2.0433563685389613\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9929228048535716\n",
      "resetting env. episode reward total was -4.0. running mean: -2.012993576805036\n",
      "resetting env. episode reward total was -9.0. running mean: -2.0828636410369854\n",
      "resetting env. episode reward total was 4.0. running mean: -2.0220350046266153\n",
      "resetting env. episode reward total was -11.0. running mean: -2.111814654580349\n",
      "resetting env. episode reward total was 10.0. running mean: -1.9906965080345453\n",
      "resetting env. episode reward total was -5.0. running mean: -2.0207895429542\n",
      "resetting env. episode reward total was -7.0. running mean: -2.0705816475246577\n",
      "resetting env. episode reward total was -2.0. running mean: -2.069875831049411\n",
      "resetting env. episode reward total was 1.0. running mean: -2.039177072738917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: -2.048785302011528\n",
      "resetting env. episode reward total was 10.0. running mean: -1.9282974489914126\n",
      "resetting env. episode reward total was 8.0. running mean: -1.8290144745014985\n",
      "resetting env. episode reward total was 8.0. running mean: -1.7307243297564834\n",
      "resetting env. episode reward total was 9.0. running mean: -1.6234170864589184\n",
      "resetting env. episode reward total was 4.0. running mean: -1.567182915594329\n",
      "resetting env. episode reward total was -3.0. running mean: -1.581511086438386\n",
      "resetting env. episode reward total was -7.0. running mean: -1.6356959755740021\n",
      "resetting env. episode reward total was 2.0. running mean: -1.599339015818262\n",
      "resetting env. episode reward total was -1.0. running mean: -1.5933456256600795\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6074121694034786\n",
      "resetting env. episode reward total was -10.0. running mean: -1.691338047709444\n",
      "resetting env. episode reward total was 2.0. running mean: -1.6544246672323495\n",
      "resetting env. episode reward total was 8.0. running mean: -1.5578804205600258\n",
      "resetting env. episode reward total was -1.0. running mean: -1.5523016163544257\n",
      "resetting env. episode reward total was -9.0. running mean: -1.6267786001908815\n",
      "resetting env. episode reward total was -6.0. running mean: -1.6705108141889726\n",
      "resetting env. episode reward total was -5.0. running mean: -1.703805706047083\n",
      "resetting env. episode reward total was 6.0. running mean: -1.626767648986612\n",
      "resetting env. episode reward total was -10.0. running mean: -1.710499972496746\n",
      "resetting env. episode reward total was -7.0. running mean: -1.7633949727717786\n",
      "resetting env. episode reward total was -4.0. running mean: -1.7857610230440608\n",
      "resetting env. episode reward total was 4.0. running mean: -1.7279034128136201\n",
      "resetting env. episode reward total was -10.0. running mean: -1.810624378685484\n",
      "resetting env. episode reward total was -1.0. running mean: -1.8025181348986292\n",
      "resetting env. episode reward total was -5.0. running mean: -1.834492953549643\n",
      "resetting env. episode reward total was -3.0. running mean: -1.8461480240141466\n",
      "resetting env. episode reward total was -12.0. running mean: -1.947686543774005\n",
      "resetting env. episode reward total was -9.0. running mean: -2.018209678336265\n",
      "resetting env. episode reward total was -9.0. running mean: -2.0880275815529026\n",
      "resetting env. episode reward total was -6.0. running mean: -2.1271473057373735\n",
      "resetting env. episode reward total was -5.0. running mean: -2.1558758326799996\n",
      "resetting env. episode reward total was -15.0. running mean: -2.2843170743531993\n",
      "resetting env. episode reward total was -7.0. running mean: -2.331473903609667\n",
      "resetting env. episode reward total was 4.0. running mean: -2.26815916457357\n",
      "resetting env. episode reward total was 1.0. running mean: -2.2354775729278344\n",
      "resetting env. episode reward total was 2.0. running mean: -2.193122797198556\n",
      "resetting env. episode reward total was -9.0. running mean: -2.26119156922657\n",
      "resetting env. episode reward total was 5.0. running mean: -2.1885796535343047\n",
      "resetting env. episode reward total was 2.0. running mean: -2.1466938569989615\n",
      "resetting env. episode reward total was -3.0. running mean: -2.155226918428972\n",
      "resetting env. episode reward total was -3.0. running mean: -2.163674649244682\n",
      "resetting env. episode reward total was -8.0. running mean: -2.222037902752235\n",
      "resetting env. episode reward total was -11.0. running mean: -2.3098175237247127\n",
      "resetting env. episode reward total was 4.0. running mean: -2.2467193484874657\n",
      "resetting env. episode reward total was -1.0. running mean: -2.234252155002591\n",
      "resetting env. episode reward total was -17.0. running mean: -2.381909633452565\n",
      "resetting env. episode reward total was -7.0. running mean: -2.428090537118039\n",
      "resetting env. episode reward total was 3.0. running mean: -2.373809631746859\n",
      "resetting env. episode reward total was -1.0. running mean: -2.36007153542939\n",
      "resetting env. episode reward total was -2.0. running mean: -2.356470820075096\n",
      "resetting env. episode reward total was -4.0. running mean: -2.3729061118743453\n",
      "resetting env. episode reward total was -13.0. running mean: -2.479177050755602\n",
      "resetting env. episode reward total was -15.0. running mean: -2.604385280248046\n",
      "resetting env. episode reward total was -2.0. running mean: -2.598341427445565\n",
      "resetting env. episode reward total was -10.0. running mean: -2.6723580131711095\n",
      "resetting env. episode reward total was 2.0. running mean: -2.6256344330393984\n",
      "resetting env. episode reward total was -11.0. running mean: -2.709378088709004\n",
      "resetting env. episode reward total was -10.0. running mean: -2.7822843078219144\n",
      "resetting env. episode reward total was 4.0. running mean: -2.714461464743695\n",
      "resetting env. episode reward total was 3.0. running mean: -2.6573168500962585\n",
      "resetting env. episode reward total was -9.0. running mean: -2.720743681595296\n",
      "resetting env. episode reward total was 3.0. running mean: -2.663536244779343\n",
      "resetting env. episode reward total was 3.0. running mean: -2.60690088233155\n",
      "resetting env. episode reward total was -1.0. running mean: -2.5908318735082343\n",
      "resetting env. episode reward total was -9.0. running mean: -2.654923554773152\n",
      "resetting env. episode reward total was -8.0. running mean: -2.7083743192254204\n",
      "resetting env. episode reward total was 2.0. running mean: -2.661290576033166\n",
      "resetting env. episode reward total was 2.0. running mean: -2.6146776702728345\n",
      "resetting env. episode reward total was -9.0. running mean: -2.6785308935701058\n",
      "resetting env. episode reward total was -13.0. running mean: -2.7817455846344044\n",
      "resetting env. episode reward total was -2.0. running mean: -2.7739281287880604\n",
      "resetting env. episode reward total was -14.0. running mean: -2.88618884750018\n",
      "resetting env. episode reward total was 8.0. running mean: -2.777326959025178\n",
      "resetting env. episode reward total was -12.0. running mean: -2.8695536894349263\n",
      "resetting env. episode reward total was -12.0. running mean: -2.960858152540577\n",
      "resetting env. episode reward total was -8.0. running mean: -3.0112495710151714\n",
      "resetting env. episode reward total was -15.0. running mean: -3.1311370753050194\n",
      "resetting env. episode reward total was -3.0. running mean: -3.129825704551969\n",
      "resetting env. episode reward total was -5.0. running mean: -3.1485274475064493\n",
      "resetting env. episode reward total was -4.0. running mean: -3.157042173031385\n",
      "resetting env. episode reward total was -12.0. running mean: -3.2454717513010714\n",
      "resetting env. episode reward total was -2.0. running mean: -3.2330170337880606\n",
      "resetting env. episode reward total was -10.0. running mean: -3.30068686345018\n",
      "resetting env. episode reward total was -7.0. running mean: -3.337679994815678\n",
      "resetting env. episode reward total was -14.0. running mean: -3.4443031948675213\n",
      "resetting env. episode reward total was 5.0. running mean: -3.3598601629188463\n",
      "resetting env. episode reward total was 2.0. running mean: -3.3062615612896575\n",
      "resetting env. episode reward total was 10.0. running mean: -3.1731989456767606\n",
      "resetting env. episode reward total was -6.0. running mean: -3.201466956219993\n",
      "resetting env. episode reward total was -10.0. running mean: -3.269452286657793\n",
      "resetting env. episode reward total was 3.0. running mean: -3.2067577637912152\n",
      "resetting env. episode reward total was 5.0. running mean: -3.124690186153303\n",
      "resetting env. episode reward total was -12.0. running mean: -3.2134432842917704\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2513088514488526\n",
      "resetting env. episode reward total was -9.0. running mean: -3.308795762934364\n",
      "resetting env. episode reward total was -9.0. running mean: -3.3657078053050205\n",
      "resetting env. episode reward total was 6.0. running mean: -3.2720507272519703\n",
      "resetting env. episode reward total was -10.0. running mean: -3.3393302199794506\n",
      "resetting env. episode reward total was -10.0. running mean: -3.405936917779656\n",
      "resetting env. episode reward total was -5.0. running mean: -3.4218775486018593\n",
      "resetting env. episode reward total was -6.0. running mean: -3.447658773115841\n",
      "resetting env. episode reward total was -1.0. running mean: -3.423182185384682\n",
      "resetting env. episode reward total was -4.0. running mean: -3.428950363530835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -13.0. running mean: -3.5246608598955267\n",
      "resetting env. episode reward total was 1.0. running mean: -3.479414251296572\n",
      "resetting env. episode reward total was -6.0. running mean: -3.504620108783606\n",
      "resetting env. episode reward total was -10.0. running mean: -3.56957390769577\n",
      "resetting env. episode reward total was -7.0. running mean: -3.603878168618812\n",
      "resetting env. episode reward total was -13.0. running mean: -3.697839386932624\n",
      "resetting env. episode reward total was -2.0. running mean: -3.6808609930632974\n",
      "resetting env. episode reward total was 6.0. running mean: -3.5840523831326645\n",
      "resetting env. episode reward total was 8.0. running mean: -3.468211859301338\n",
      "resetting env. episode reward total was -11.0. running mean: -3.5435297407083244\n",
      "resetting env. episode reward total was -17.0. running mean: -3.6780944433012412\n",
      "resetting env. episode reward total was -10.0. running mean: -3.741313498868229\n",
      "resetting env. episode reward total was -11.0. running mean: -3.8139003638795463\n",
      "resetting env. episode reward total was -7.0. running mean: -3.8457613602407505\n",
      "resetting env. episode reward total was -9.0. running mean: -3.8973037466383427\n",
      "resetting env. episode reward total was -17.0. running mean: -4.02833070917196\n",
      "resetting env. episode reward total was -11.0. running mean: -4.09804740208024\n",
      "resetting env. episode reward total was -13.0. running mean: -4.187066928059438\n",
      "resetting env. episode reward total was -14.0. running mean: -4.285196258778843\n",
      "resetting env. episode reward total was -15.0. running mean: -4.392344296191054\n",
      "resetting env. episode reward total was -15.0. running mean: -4.4984208532291445\n",
      "resetting env. episode reward total was -10.0. running mean: -4.553436644696853\n",
      "resetting env. episode reward total was -10.0. running mean: -4.607902278249884\n",
      "resetting env. episode reward total was -10.0. running mean: -4.661823255467384\n",
      "resetting env. episode reward total was -10.0. running mean: -4.71520502291271\n",
      "resetting env. episode reward total was -5.0. running mean: -4.718052972683583\n",
      "resetting env. episode reward total was -18.0. running mean: -4.850872442956747\n",
      "resetting env. episode reward total was -6.0. running mean: -4.862363718527178\n",
      "resetting env. episode reward total was 1.0. running mean: -4.803740081341907\n",
      "resetting env. episode reward total was -7.0. running mean: -4.825702680528488\n",
      "resetting env. episode reward total was -12.0. running mean: -4.897445653723204\n",
      "resetting env. episode reward total was -12.0. running mean: -4.968471197185972\n",
      "resetting env. episode reward total was -13.0. running mean: -5.048786485214111\n",
      "resetting env. episode reward total was -7.0. running mean: -5.06829862036197\n",
      "resetting env. episode reward total was -14.0. running mean: -5.157615634158351\n",
      "resetting env. episode reward total was -3.0. running mean: -5.136039477816767\n",
      "resetting env. episode reward total was -1.0. running mean: -5.094679083038599\n",
      "resetting env. episode reward total was -11.0. running mean: -5.153732292208214\n",
      "resetting env. episode reward total was -9.0. running mean: -5.192194969286131\n",
      "resetting env. episode reward total was -9.0. running mean: -5.23027301959327\n",
      "resetting env. episode reward total was -7.0. running mean: -5.247970289397337\n",
      "resetting env. episode reward total was -11.0. running mean: -5.305490586503364\n",
      "resetting env. episode reward total was -9.0. running mean: -5.34243568063833\n",
      "resetting env. episode reward total was -5.0. running mean: -5.339011323831946\n",
      "resetting env. episode reward total was -15.0. running mean: -5.435621210593627\n",
      "resetting env. episode reward total was 10.0. running mean: -5.281264998487691\n",
      "resetting env. episode reward total was -14.0. running mean: -5.368452348502814\n",
      "resetting env. episode reward total was -11.0. running mean: -5.424767825017786\n",
      "resetting env. episode reward total was -2.0. running mean: -5.390520146767607\n",
      "resetting env. episode reward total was -10.0. running mean: -5.436614945299931\n",
      "resetting env. episode reward total was -7.0. running mean: -5.452248795846932\n",
      "resetting env. episode reward total was -11.0. running mean: -5.507726307888463\n",
      "resetting env. episode reward total was -16.0. running mean: -5.6126490448095785\n",
      "resetting env. episode reward total was -16.0. running mean: -5.716522554361482\n",
      "resetting env. episode reward total was -7.0. running mean: -5.729357328817867\n",
      "resetting env. episode reward total was -10.0. running mean: -5.772063755529689\n",
      "resetting env. episode reward total was -8.0. running mean: -5.794343117974392\n",
      "resetting env. episode reward total was -9.0. running mean: -5.826399686794647\n",
      "resetting env. episode reward total was -12.0. running mean: -5.888135689926701\n",
      "resetting env. episode reward total was -14.0. running mean: -5.9692543330274335\n",
      "resetting env. episode reward total was -5.0. running mean: -5.959561789697159\n",
      "resetting env. episode reward total was -14.0. running mean: -6.039966171800187\n",
      "resetting env. episode reward total was -19.0. running mean: -6.169566510082186\n",
      "resetting env. episode reward total was -10.0. running mean: -6.207870844981364\n",
      "resetting env. episode reward total was -9.0. running mean: -6.23579213653155\n",
      "resetting env. episode reward total was -8.0. running mean: -6.2534342151662345\n",
      "resetting env. episode reward total was -1.0. running mean: -6.200899873014572\n",
      "resetting env. episode reward total was -7.0. running mean: -6.208890874284426\n",
      "resetting env. episode reward total was -1.0. running mean: -6.1568019655415815\n",
      "resetting env. episode reward total was -8.0. running mean: -6.175233945886165\n",
      "resetting env. episode reward total was -9.0. running mean: -6.203481606427304\n",
      "resetting env. episode reward total was -3.0. running mean: -6.1714467903630315\n",
      "resetting env. episode reward total was -5.0. running mean: -6.1597323224594005\n",
      "resetting env. episode reward total was -4.0. running mean: -6.138134999234807\n",
      "resetting env. episode reward total was 7.0. running mean: -6.006753649242459\n",
      "resetting env. episode reward total was -17.0. running mean: -6.116686112750034\n",
      "resetting env. episode reward total was -8.0. running mean: -6.135519251622534\n",
      "resetting env. episode reward total was -7.0. running mean: -6.144164059106309\n",
      "resetting env. episode reward total was 1.0. running mean: -6.072722418515246\n",
      "resetting env. episode reward total was -7.0. running mean: -6.081995194330094\n",
      "resetting env. episode reward total was -1.0. running mean: -6.0311752423867935\n",
      "resetting env. episode reward total was -8.0. running mean: -6.050863489962926\n",
      "resetting env. episode reward total was -4.0. running mean: -6.030354855063297\n",
      "resetting env. episode reward total was -2.0. running mean: -5.9900513065126635\n",
      "resetting env. episode reward total was -5.0. running mean: -5.980150793447536\n",
      "resetting env. episode reward total was -14.0. running mean: -6.060349285513061\n",
      "resetting env. episode reward total was -7.0. running mean: -6.069745792657931\n",
      "resetting env. episode reward total was -9.0. running mean: -6.099048334731351\n",
      "resetting env. episode reward total was -3.0. running mean: -6.0680578513840375\n",
      "resetting env. episode reward total was -8.0. running mean: -6.087377272870198\n",
      "resetting env. episode reward total was 9.0. running mean: -5.936503500141495\n",
      "resetting env. episode reward total was -1.0. running mean: -5.88713846514008\n",
      "resetting env. episode reward total was -11.0. running mean: -5.9382670804886795\n",
      "resetting env. episode reward total was 8.0. running mean: -5.798884409683793\n",
      "resetting env. episode reward total was 5.0. running mean: -5.690895565586955\n",
      "resetting env. episode reward total was 2.0. running mean: -5.613986609931086\n",
      "resetting env. episode reward total was -10.0. running mean: -5.657846743831774\n",
      "resetting env. episode reward total was -4.0. running mean: -5.641268276393457\n",
      "resetting env. episode reward total was -3.0. running mean: -5.614855593629523\n",
      "resetting env. episode reward total was -9.0. running mean: -5.648707037693227\n",
      "resetting env. episode reward total was 9.0. running mean: -5.502219967316295\n",
      "resetting env. episode reward total was -7.0. running mean: -5.5171977676431325\n",
      "resetting env. episode reward total was -9.0. running mean: -5.552025789966701\n",
      "resetting env. episode reward total was -5.0. running mean: -5.546505532067034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: -5.371040476746363\n",
      "resetting env. episode reward total was 11.0. running mean: -5.207330071978899\n",
      "resetting env. episode reward total was 4.0. running mean: -5.11525677125911\n",
      "resetting env. episode reward total was -8.0. running mean: -5.14410420354652\n",
      "resetting env. episode reward total was -11.0. running mean: -5.202663161511055\n",
      "resetting env. episode reward total was -2.0. running mean: -5.170636529895943\n",
      "resetting env. episode reward total was -7.0. running mean: -5.188930164596984\n",
      "resetting env. episode reward total was -13.0. running mean: -5.267040862951014\n",
      "resetting env. episode reward total was 9.0. running mean: -5.124370454321505\n",
      "resetting env. episode reward total was 5.0. running mean: -5.02312674977829\n",
      "resetting env. episode reward total was -5.0. running mean: -5.022895482280506\n",
      "resetting env. episode reward total was -1.0. running mean: -4.982666527457701\n",
      "resetting env. episode reward total was 3.0. running mean: -4.902839862183123\n",
      "resetting env. episode reward total was -2.0. running mean: -4.8738114635612915\n",
      "resetting env. episode reward total was -5.0. running mean: -4.875073348925678\n",
      "resetting env. episode reward total was -7.0. running mean: -4.896322615436421\n",
      "resetting env. episode reward total was -11.0. running mean: -4.9573593892820575\n",
      "resetting env. episode reward total was -5.0. running mean: -4.957785795389237\n",
      "resetting env. episode reward total was -6.0. running mean: -4.968207937435344\n",
      "resetting env. episode reward total was -5.0. running mean: -4.968525858060991\n",
      "resetting env. episode reward total was 4.0. running mean: -4.878840599480381\n",
      "resetting env. episode reward total was -7.0. running mean: -4.900052193485577\n",
      "resetting env. episode reward total was 4.0. running mean: -4.811051671550722\n",
      "resetting env. episode reward total was -1.0. running mean: -4.772941154835214\n",
      "resetting env. episode reward total was -3.0. running mean: -4.755211743286862\n",
      "resetting env. episode reward total was -11.0. running mean: -4.817659625853994\n",
      "resetting env. episode reward total was -6.0. running mean: -4.829483029595454\n",
      "resetting env. episode reward total was 8.0. running mean: -4.701188199299499\n",
      "resetting env. episode reward total was -3.0. running mean: -4.684176317306504\n",
      "resetting env. episode reward total was 2.0. running mean: -4.617334554133439\n",
      "resetting env. episode reward total was -11.0. running mean: -4.681161208592105\n",
      "resetting env. episode reward total was -9.0. running mean: -4.724349596506183\n",
      "resetting env. episode reward total was -10.0. running mean: -4.777106100541121\n",
      "resetting env. episode reward total was -5.0. running mean: -4.7793350395357095\n",
      "resetting env. episode reward total was 3.0. running mean: -4.7015416891403525\n",
      "resetting env. episode reward total was 3.0. running mean: -4.624526272248949\n",
      "resetting env. episode reward total was 3.0. running mean: -4.548281009526459\n",
      "resetting env. episode reward total was -11.0. running mean: -4.612798199431195\n",
      "resetting env. episode reward total was 2.0. running mean: -4.546670217436883\n",
      "resetting env. episode reward total was -5.0. running mean: -4.5512035152625145\n",
      "resetting env. episode reward total was 9.0. running mean: -4.415691480109889\n",
      "resetting env. episode reward total was -7.0. running mean: -4.441534565308791\n",
      "resetting env. episode reward total was 1.0. running mean: -4.387119219655703\n",
      "resetting env. episode reward total was 3.0. running mean: -4.313248027459146\n",
      "resetting env. episode reward total was -5.0. running mean: -4.320115547184554\n",
      "resetting env. episode reward total was -8.0. running mean: -4.356914391712708\n",
      "resetting env. episode reward total was -4.0. running mean: -4.353345247795581\n",
      "resetting env. episode reward total was 8.0. running mean: -4.229811795317626\n",
      "resetting env. episode reward total was 4.0. running mean: -4.147513677364449\n",
      "resetting env. episode reward total was 4.0. running mean: -4.066038540590805\n",
      "resetting env. episode reward total was -5.0. running mean: -4.075378155184897\n",
      "resetting env. episode reward total was 5.0. running mean: -3.9846243736330482\n",
      "resetting env. episode reward total was -10.0. running mean: -4.044778129896717\n",
      "resetting env. episode reward total was 11.0. running mean: -3.8943303485977503\n",
      "resetting env. episode reward total was 6.0. running mean: -3.795387045111773\n",
      "resetting env. episode reward total was -4.0. running mean: -3.797433174660655\n",
      "resetting env. episode reward total was 1.0. running mean: -3.7494588429140485\n",
      "resetting env. episode reward total was 7.0. running mean: -3.641964254484908\n",
      "resetting env. episode reward total was -5.0. running mean: -3.6555446119400585\n",
      "resetting env. episode reward total was -5.0. running mean: -3.668989165820658\n",
      "resetting env. episode reward total was 2.0. running mean: -3.612299274162451\n",
      "resetting env. episode reward total was -5.0. running mean: -3.6261762814208263\n",
      "resetting env. episode reward total was -7.0. running mean: -3.6599145186066178\n",
      "resetting env. episode reward total was -11.0. running mean: -3.7333153734205515\n",
      "resetting env. episode reward total was -3.0. running mean: -3.7259822196863457\n",
      "resetting env. episode reward total was 4.0. running mean: -3.648722397489482\n",
      "resetting env. episode reward total was 8.0. running mean: -3.532235173514587\n",
      "resetting env. episode reward total was 6.0. running mean: -3.4369128217794414\n",
      "resetting env. episode reward total was 2.0. running mean: -3.382543693561647\n",
      "resetting env. episode reward total was 1.0. running mean: -3.3387182566260307\n",
      "resetting env. episode reward total was -10.0. running mean: -3.4053310740597706\n",
      "resetting env. episode reward total was 11.0. running mean: -3.261277763319173\n",
      "resetting env. episode reward total was -5.0. running mean: -3.278664985685981\n",
      "resetting env. episode reward total was -4.0. running mean: -3.2858783358291213\n",
      "resetting env. episode reward total was 3.0. running mean: -3.2230195524708303\n",
      "resetting env. episode reward total was 7.0. running mean: -3.1207893569461223\n",
      "resetting env. episode reward total was -6.0. running mean: -3.149581463376661\n",
      "resetting env. episode reward total was -11.0. running mean: -3.228085648742894\n",
      "resetting env. episode reward total was -4.0. running mean: -3.235804792255465\n",
      "resetting env. episode reward total was 3.0. running mean: -3.1734467443329106\n",
      "resetting env. episode reward total was -1.0. running mean: -3.1517122768895813\n",
      "resetting env. episode reward total was 8.0. running mean: -3.0401951541206853\n",
      "resetting env. episode reward total was -6.0. running mean: -3.0697932025794783\n",
      "resetting env. episode reward total was -2.0. running mean: -3.0590952705536836\n",
      "resetting env. episode reward total was 6.0. running mean: -2.9685043178481467\n",
      "resetting env. episode reward total was 3.0. running mean: -2.9088192746696655\n",
      "resetting env. episode reward total was 1.0. running mean: -2.869731081922969\n",
      "resetting env. episode reward total was 6.0. running mean: -2.7810337711037394\n",
      "resetting env. episode reward total was -3.0. running mean: -2.7832234333927017\n",
      "resetting env. episode reward total was -9.0. running mean: -2.8453911990587746\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8469372870681866\n",
      "resetting env. episode reward total was -11.0. running mean: -2.9284679141975047\n",
      "resetting env. episode reward total was -4.0. running mean: -2.9391832350555296\n",
      "resetting env. episode reward total was 13.0. running mean: -2.779791402704974\n",
      "resetting env. episode reward total was -2.0. running mean: -2.7719934886779245\n",
      "resetting env. episode reward total was -4.0. running mean: -2.784273553791145\n",
      "resetting env. episode reward total was 2.0. running mean: -2.7364308182532335\n",
      "resetting env. episode reward total was -2.0. running mean: -2.7290665100707012\n",
      "resetting env. episode reward total was 5.0. running mean: -2.651775844969994\n",
      "resetting env. episode reward total was 13.0. running mean: -2.4952580865202942\n",
      "resetting env. episode reward total was -7.0. running mean: -2.540305505655091\n",
      "resetting env. episode reward total was 5.0. running mean: -2.4649024505985406\n",
      "resetting env. episode reward total was 2.0. running mean: -2.4202534260925552\n",
      "resetting env. episode reward total was 14.0. running mean: -2.2560508918316295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: -2.173490382913313\n",
      "resetting env. episode reward total was 10.0. running mean: -2.05175547908418\n",
      "resetting env. episode reward total was 2.0. running mean: -2.0112379242933383\n",
      "resetting env. episode reward total was 8.0. running mean: -1.9111255450504048\n",
      "resetting env. episode reward total was -2.0. running mean: -1.9120142895999008\n",
      "resetting env. episode reward total was -4.0. running mean: -1.9328941467039018\n",
      "resetting env. episode reward total was 12.0. running mean: -1.7935652052368627\n",
      "resetting env. episode reward total was 5.0. running mean: -1.725629553184494\n",
      "resetting env. episode reward total was 3.0. running mean: -1.678373257652649\n",
      "resetting env. episode reward total was 5.0. running mean: -1.6115895250761225\n",
      "resetting env. episode reward total was 2.0. running mean: -1.5754736298253613\n",
      "resetting env. episode reward total was 1.0. running mean: -1.5497188935271078\n",
      "resetting env. episode reward total was 3.0. running mean: -1.5042217045918367\n",
      "resetting env. episode reward total was 11.0. running mean: -1.3791794875459182\n",
      "resetting env. episode reward total was 10.0. running mean: -1.265387692670459\n",
      "resetting env. episode reward total was -3.0. running mean: -1.2827338157437544\n",
      "resetting env. episode reward total was -6.0. running mean: -1.329906477586317\n",
      "resetting env. episode reward total was 3.0. running mean: -1.2866074128104537\n",
      "resetting env. episode reward total was -7.0. running mean: -1.3437413386823491\n",
      "resetting env. episode reward total was 2.0. running mean: -1.3103039252955255\n",
      "resetting env. episode reward total was -4.0. running mean: -1.3372008860425704\n",
      "resetting env. episode reward total was 3.0. running mean: -1.2938288771821447\n",
      "resetting env. episode reward total was 8.0. running mean: -1.2008905884103231\n",
      "resetting env. episode reward total was -6.0. running mean: -1.24888168252622\n",
      "resetting env. episode reward total was -2.0. running mean: -1.2563928657009578\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2538289370439482\n",
      "resetting env. episode reward total was 6.0. running mean: -1.1812906476735086\n",
      "resetting env. episode reward total was -7.0. running mean: -1.2394777411967735\n",
      "resetting env. episode reward total was 3.0. running mean: -1.1970829637848057\n",
      "resetting env. episode reward total was -2.0. running mean: -1.2051121341469577\n",
      "resetting env. episode reward total was 15.0. running mean: -1.0430610128054882\n",
      "resetting env. episode reward total was -7.0. running mean: -1.1026304026774334\n",
      "resetting env. episode reward total was 1.0. running mean: -1.081604098650659\n",
      "resetting env. episode reward total was 8.0. running mean: -0.9907880576641525\n",
      "resetting env. episode reward total was -7.0. running mean: -1.050880177087511\n",
      "resetting env. episode reward total was -2.0. running mean: -1.0603713753166357\n",
      "resetting env. episode reward total was -1.0. running mean: -1.0597676615634695\n",
      "resetting env. episode reward total was -10.0. running mean: -1.149169984947835\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1676782850983567\n",
      "resetting env. episode reward total was -9.0. running mean: -1.2460015022473732\n",
      "resetting env. episode reward total was 3.0. running mean: -1.2035414872248993\n",
      "resetting env. episode reward total was 7.0. running mean: -1.1215060723526502\n",
      "resetting env. episode reward total was 1.0. running mean: -1.1002910116291238\n",
      "resetting env. episode reward total was 15.0. running mean: -0.9392881015128326\n",
      "resetting env. episode reward total was 10.0. running mean: -0.8298952204977043\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8315962682927273\n",
      "resetting env. episode reward total was 1.0. running mean: -0.8132803056098\n",
      "resetting env. episode reward total was 10.0. running mean: -0.7051475025537021\n",
      "resetting env. episode reward total was -7.0. running mean: -0.768096027528165\n",
      "resetting env. episode reward total was 7.0. running mean: -0.6904150672528833\n",
      "resetting env. episode reward total was 1.0. running mean: -0.6735109165803544\n",
      "resetting env. episode reward total was 7.0. running mean: -0.5967758074145508\n",
      "resetting env. episode reward total was 3.0. running mean: -0.5608080493404053\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5451999688470012\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5297479691585312\n",
      "resetting env. episode reward total was 2.0. running mean: -0.5044504894669458\n",
      "resetting env. episode reward total was 4.0. running mean: -0.4594059845722764\n",
      "resetting env. episode reward total was 2.0. running mean: -0.4348119247265536\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4604638054792881\n",
      "resetting env. episode reward total was 7.0. running mean: -0.3858591674244952\n",
      "resetting env. episode reward total was -10.0. running mean: -0.48200057575025024\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5071805699927477\n",
      "resetting env. episode reward total was 10.0. running mean: -0.4021087642928203\n",
      "resetting env. episode reward total was -2.0. running mean: -0.4180876766498921\n",
      "resetting env. episode reward total was -6.0. running mean: -0.4739067998833932\n",
      "resetting env. episode reward total was 2.0. running mean: -0.4491677318845592\n",
      "resetting env. episode reward total was -9.0. running mean: -0.5346760545657137\n",
      "resetting env. episode reward total was 2.0. running mean: -0.5093292940200564\n",
      "resetting env. episode reward total was -9.0. running mean: -0.5942360010798559\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6382936410690574\n",
      "resetting env. episode reward total was 3.0. running mean: -0.6019107046583668\n",
      "resetting env. episode reward total was -2.0. running mean: -0.6158915976117831\n",
      "resetting env. episode reward total was 2.0. running mean: -0.5897326816356653\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6338353548193086\n",
      "resetting env. episode reward total was -6.0. running mean: -0.6874970012711155\n",
      "resetting env. episode reward total was -3.0. running mean: -0.7106220312584043\n",
      "resetting env. episode reward total was 4.0. running mean: -0.6635158109458202\n",
      "resetting env. episode reward total was 3.0. running mean: -0.626880652836362\n",
      "resetting env. episode reward total was 13.0. running mean: -0.49061184630799837\n",
      "resetting env. episode reward total was 15.0. running mean: -0.33570572784491837\n",
      "resetting env. episode reward total was -10.0. running mean: -0.4323486705664692\n",
      "resetting env. episode reward total was 5.0. running mean: -0.3780251838608045\n",
      "resetting env. episode reward total was 1.0. running mean: -0.3642449320221965\n",
      "resetting env. episode reward total was 11.0. running mean: -0.25060248270197455\n",
      "resetting env. episode reward total was -7.0. running mean: -0.3180964578749548\n",
      "resetting env. episode reward total was 9.0. running mean: -0.22491549329620522\n",
      "resetting env. episode reward total was 6.0. running mean: -0.16266633836324318\n",
      "resetting env. episode reward total was -4.0. running mean: -0.20103967497961076\n",
      "resetting env. episode reward total was 4.0. running mean: -0.15902927822981464\n",
      "resetting env. episode reward total was 9.0. running mean: -0.0674389854475165\n",
      "resetting env. episode reward total was 4.0. running mean: -0.026764595593041333\n",
      "resetting env. episode reward total was -2.0. running mean: -0.046496949637110915\n",
      "resetting env. episode reward total was 6.0. running mean: 0.013968019859260189\n",
      "resetting env. episode reward total was 8.0. running mean: 0.09382833966066759\n",
      "resetting env. episode reward total was 1.0. running mean: 0.1028900562640609\n",
      "resetting env. episode reward total was -3.0. running mean: 0.07186115570142029\n",
      "resetting env. episode reward total was 3.0. running mean: 0.10114254414440609\n",
      "resetting env. episode reward total was 1.0. running mean: 0.11013111870296202\n",
      "resetting env. episode reward total was 6.0. running mean: 0.16902980751593238\n",
      "resetting env. episode reward total was 4.0. running mean: 0.20733950944077306\n",
      "resetting env. episode reward total was 3.0. running mean: 0.23526611434636532\n",
      "resetting env. episode reward total was 6.0. running mean: 0.29291345320290163\n",
      "resetting env. episode reward total was -1.0. running mean: 0.2799843186708726\n",
      "resetting env. episode reward total was 1.0. running mean: 0.28718447548416387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: 0.23431263072932224\n",
      "resetting env. episode reward total was -1.0. running mean: 0.221969504422029\n",
      "resetting env. episode reward total was 8.0. running mean: 0.2997498093778087\n",
      "resetting env. episode reward total was -7.0. running mean: 0.22675231128403062\n",
      "resetting env. episode reward total was 5.0. running mean: 0.2744847881711903\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2417399402894784\n",
      "resetting env. episode reward total was 9.0. running mean: 0.32932254088658364\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3160293154777178\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3628690223229406\n",
      "resetting env. episode reward total was 7.0. running mean: 0.4292403320997112\n",
      "resetting env. episode reward total was 1.0. running mean: 0.4349479287787141\n",
      "resetting env. episode reward total was 4.0. running mean: 0.47059844949092694\n",
      "resetting env. episode reward total was -3.0. running mean: 0.43589246499601764\n",
      "resetting env. episode reward total was 3.0. running mean: 0.4615335403460574\n",
      "resetting env. episode reward total was 7.0. running mean: 0.5269182049425969\n",
      "resetting env. episode reward total was -5.0. running mean: 0.47164902289317095\n",
      "resetting env. episode reward total was -7.0. running mean: 0.3969325326642392\n",
      "resetting env. episode reward total was 6.0. running mean: 0.4529632073375968\n",
      "resetting env. episode reward total was -2.0. running mean: 0.4284335752642208\n",
      "resetting env. episode reward total was 7.0. running mean: 0.49414923951157863\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5692077471164628\n",
      "resetting env. episode reward total was -9.0. running mean: 0.47351566964529823\n",
      "resetting env. episode reward total was 1.0. running mean: 0.47878051294884527\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5139927078193568\n",
      "resetting env. episode reward total was 5.0. running mean: 0.5588527807411633\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5332642529337517\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5879316104044141\n",
      "resetting env. episode reward total was 6.0. running mean: 0.6420522943003699\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5856317713573662\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5897754536437926\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6338776991073547\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6775389221162812\n",
      "resetting env. episode reward total was 3.0. running mean: 0.7007635328951184\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7437558975661672\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7963183385905055\n",
      "resetting env. episode reward total was 7.0. running mean: 0.8583551552046005\n",
      "resetting env. episode reward total was -6.0. running mean: 0.7897716036525544\n",
      "resetting env. episode reward total was 11.0. running mean: 0.8918738876160288\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9629551487398684\n",
      "resetting env. episode reward total was 11.0. running mean: 1.0633255972524698\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0826923412799452\n",
      "resetting env. episode reward total was 9.0. running mean: 1.1618654178671457\n",
      "resetting env. episode reward total was 11.0. running mean: 1.2602467636884744\n",
      "resetting env. episode reward total was 13.0. running mean: 1.3776442960515896\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3838678530910737\n",
      "resetting env. episode reward total was -12.0. running mean: 1.2500291745601628\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2575288828145612\n",
      "resetting env. episode reward total was 1.0. running mean: 1.2549535939864156\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2624040580465514\n",
      "resetting env. episode reward total was 10.0. running mean: 1.349780017466086\n",
      "resetting env. episode reward total was 1.0. running mean: 1.346282217291425\n",
      "resetting env. episode reward total was -14.0. running mean: 1.1928193951185109\n",
      "resetting env. episode reward total was 14.0. running mean: 1.320891201167326\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3676822891556528\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4040054662640964\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4399654116014555\n",
      "resetting env. episode reward total was -1.0. running mean: 1.415565757485441\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3814100999105865\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4175959989114806\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4434200389223657\n",
      "resetting env. episode reward total was -1.0. running mean: 1.418985838533142\n",
      "resetting env. episode reward total was 14.0. running mean: 1.5447959801478106\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5193480203463325\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5341545401428691\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4688129947414403\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4041248647940259\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3800836161460857\n",
      "resetting env. episode reward total was 5.0. running mean: 1.416282779984625\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4421199521847787\n",
      "resetting env. episode reward total was 5.0. running mean: 1.477698752662931\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4929217651363018\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4679925474849387\n",
      "resetting env. episode reward total was -8.0. running mean: 1.3733126220100893\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3995794957899885\n",
      "resetting env. episode reward total was -8.0. running mean: 1.3055837008320885\n",
      "resetting env. episode reward total was 11.0. running mean: 1.4025278638237677\n",
      "resetting env. episode reward total was -8.0. running mean: 1.3085025851855299\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3354175593336746\n",
      "resetting env. episode reward total was -4.0. running mean: 1.2820633837403377\n",
      "resetting env. episode reward total was 11.0. running mean: 1.3792427499029345\n",
      "resetting env. episode reward total was -9.0. running mean: 1.275450322403905\n",
      "resetting env. episode reward total was 5.0. running mean: 1.312695819179866\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3795688609880674\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3557731723781867\n",
      "resetting env. episode reward total was 13.0. running mean: 1.4722154406544048\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4474932862478607\n",
      "resetting env. episode reward total was -4.0. running mean: 1.393018353385382\n",
      "resetting env. episode reward total was 5.0. running mean: 1.429088169851528\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4347972881530129\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4504493152714828\n",
      "resetting env. episode reward total was -1.0. running mean: 1.425944822118768\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3816853738975803\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4278685201586045\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4535898349570184\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4790539366074482\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3942633972413736\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3303207632689598\n",
      "resetting env. episode reward total was -3.0. running mean: 1.2870175556362702\n",
      "resetting env. episode reward total was -4.0. running mean: 1.2341473800799074\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2518059062791085\n",
      "resetting env. episode reward total was 1.0. running mean: 1.2492878472163174\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2667949687441542\n",
      "resetting env. episode reward total was -1.0. running mean: 1.2441270190567126\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3116857488661455\n",
      "resetting env. episode reward total was 2.0. running mean: 1.318568891377484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 1.3553832024637091\n",
      "resetting env. episode reward total was -2.0. running mean: 1.321829370439072\n",
      "resetting env. episode reward total was -12.0. running mean: 1.1886110767346811\n",
      "resetting env. episode reward total was -6.0. running mean: 1.1167249659673342\n",
      "resetting env. episode reward total was 14.0. running mean: 1.245557716307661\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2831021391445845\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3302711177531388\n",
      "resetting env. episode reward total was -7.0. running mean: 1.2469684065756073\n",
      "resetting env. episode reward total was 13.0. running mean: 1.3644987225098513\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4008537352847528\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4068451979319052\n",
      "resetting env. episode reward total was 9.0. running mean: 1.4827767459525862\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3979489784930603\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3639694887081297\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3303297938210483\n",
      "resetting env. episode reward total was 3.0. running mean: 1.347026495882838\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4135562309240097\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3894206686147696\n",
      "resetting env. episode reward total was 10.0. running mean: 1.4755264619286221\n",
      "resetting env. episode reward total was 10.0. running mean: 1.560771197309336\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4951634853362425\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5402118504828801\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5948097319780514\n",
      "resetting env. episode reward total was 10.0. running mean: 1.678861634658271\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7220730183116884\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7548522881285715\n",
      "resetting env. episode reward total was 9.0. running mean: 1.8273037652472859\n",
      "resetting env. episode reward total was -2.0. running mean: 1.789030727594813\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8211404203188648\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8329290161156762\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8245997259545195\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8663537286949743\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9676901914080247\n",
      "resetting env. episode reward total was 10.0. running mean: 2.0480132894939445\n",
      "resetting env. episode reward total was 7.0. running mean: 2.0975331565990047\n",
      "resetting env. episode reward total was 12.0. running mean: 2.1965578250330147\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2445922467826844\n",
      "resetting env. episode reward total was -3.0. running mean: 2.192146324314858\n",
      "resetting env. episode reward total was -2.0. running mean: 2.150224861071709\n",
      "resetting env. episode reward total was 2.0. running mean: 2.148722612460992\n",
      "resetting env. episode reward total was 4.0. running mean: 2.1672353863363822\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2155630324730184\n",
      "resetting env. episode reward total was 13.0. running mean: 2.323407402148288\n",
      "resetting env. episode reward total was 7.0. running mean: 2.370173328126805\n",
      "resetting env. episode reward total was 7.0. running mean: 2.416471594845537\n",
      "resetting env. episode reward total was 13.0. running mean: 2.5223068788970813\n",
      "resetting env. episode reward total was -2.0. running mean: 2.4770838101081103\n",
      "resetting env. episode reward total was 10.0. running mean: 2.5523129720070292\n",
      "resetting env. episode reward total was 5.0. running mean: 2.5767898422869586\n",
      "resetting env. episode reward total was 7.0. running mean: 2.621021943864089\n",
      "resetting env. episode reward total was -4.0. running mean: 2.554811724425448\n",
      "resetting env. episode reward total was -6.0. running mean: 2.4692636071811935\n",
      "resetting env. episode reward total was 4.0. running mean: 2.4845709711093815\n",
      "resetting env. episode reward total was 3.0. running mean: 2.4897252613982874\n",
      "resetting env. episode reward total was -3.0. running mean: 2.434828008784305\n",
      "resetting env. episode reward total was 11.0. running mean: 2.5204797286964618\n",
      "resetting env. episode reward total was -1.0. running mean: 2.4852749314094975\n",
      "resetting env. episode reward total was 1.0. running mean: 2.4704221820954024\n",
      "resetting env. episode reward total was -4.0. running mean: 2.4057179602744485\n",
      "resetting env. episode reward total was 6.0. running mean: 2.441660780671704\n",
      "resetting env. episode reward total was 5.0. running mean: 2.4672441728649868\n",
      "resetting env. episode reward total was -8.0. running mean: 2.362571731136337\n",
      "resetting env. episode reward total was 3.0. running mean: 2.3689460138249734\n",
      "resetting env. episode reward total was 1.0. running mean: 2.3552565536867234\n",
      "resetting env. episode reward total was 7.0. running mean: 2.401703988149856\n",
      "resetting env. episode reward total was 3.0. running mean: 2.407686948268357\n",
      "resetting env. episode reward total was 4.0. running mean: 2.4236100787856736\n",
      "resetting env. episode reward total was 1.0. running mean: 2.4093739779978165\n",
      "resetting env. episode reward total was -7.0. running mean: 2.3152802382178383\n",
      "resetting env. episode reward total was 4.0. running mean: 2.33212743583566\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3288061614773032\n",
      "resetting env. episode reward total was 9.0. running mean: 2.39551809986253\n",
      "resetting env. episode reward total was 3.0. running mean: 2.4015629188639043\n",
      "resetting env. episode reward total was 5.0. running mean: 2.4275472896752652\n",
      "resetting env. episode reward total was -5.0. running mean: 2.3532718167785127\n",
      "resetting env. episode reward total was 7.0. running mean: 2.3997390986107274\n",
      "resetting env. episode reward total was 15.0. running mean: 2.5257417076246202\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5304842905483738\n",
      "resetting env. episode reward total was 10.0. running mean: 2.60517944764289\n",
      "resetting env. episode reward total was -2.0. running mean: 2.559127653166461\n",
      "resetting env. episode reward total was 1.0. running mean: 2.5435363766347963\n",
      "resetting env. episode reward total was 6.0. running mean: 2.5781010128684483\n",
      "resetting env. episode reward total was -5.0. running mean: 2.502320002739764\n",
      "resetting env. episode reward total was 6.0. running mean: 2.5372968027123664\n",
      "resetting env. episode reward total was 13.0. running mean: 2.6419238346852425\n",
      "resetting env. episode reward total was 1.0. running mean: 2.6255045963383896\n",
      "resetting env. episode reward total was 2.0. running mean: 2.6192495503750055\n",
      "resetting env. episode reward total was 4.0. running mean: 2.6330570548712555\n",
      "resetting env. episode reward total was 7.0. running mean: 2.676726484322543\n",
      "resetting env. episode reward total was 17.0. running mean: 2.8199592194793173\n",
      "resetting env. episode reward total was 7.0. running mean: 2.861759627284524\n",
      "resetting env. episode reward total was 6.0. running mean: 2.8931420310116787\n",
      "resetting env. episode reward total was 1.0. running mean: 2.8742106107015615\n",
      "resetting env. episode reward total was -5.0. running mean: 2.795468504594546\n",
      "resetting env. episode reward total was -3.0. running mean: 2.737513819548601\n",
      "resetting env. episode reward total was -5.0. running mean: 2.660138681353115\n",
      "resetting env. episode reward total was 7.0. running mean: 2.7035372945395837\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7065019215941875\n",
      "resetting env. episode reward total was 6.0. running mean: 2.7394369023782454\n",
      "resetting env. episode reward total was 8.0. running mean: 2.792042533354463\n",
      "resetting env. episode reward total was -2.0. running mean: 2.7441221080209184\n",
      "resetting env. episode reward total was -1.0. running mean: 2.7066808869407093\n",
      "resetting env. episode reward total was 2.0. running mean: 2.6996140780713023\n",
      "resetting env. episode reward total was -1.0. running mean: 2.6626179372905896\n",
      "resetting env. episode reward total was 8.0. running mean: 2.7159917579176835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: 2.6488318403385067\n",
      "resetting env. episode reward total was 7.0. running mean: 2.6923435219351215\n",
      "resetting env. episode reward total was 10.0. running mean: 2.7654200867157703\n",
      "resetting env. episode reward total was 17.0. running mean: 2.9077658858486126\n",
      "resetting env. episode reward total was 9.0. running mean: 2.9686882269901265\n",
      "resetting env. episode reward total was -7.0. running mean: 2.869001344720225\n",
      "resetting env. episode reward total was -1.0. running mean: 2.8303113312730233\n",
      "resetting env. episode reward total was 7.0. running mean: 2.872008217960293\n",
      "resetting env. episode reward total was 4.0. running mean: 2.88328813578069\n",
      "resetting env. episode reward total was 3.0. running mean: 2.884455254422883\n",
      "resetting env. episode reward total was -13.0. running mean: 2.7256107018786544\n",
      "resetting env. episode reward total was 10.0. running mean: 2.798354594859868\n",
      "resetting env. episode reward total was 11.0. running mean: 2.880371048911269\n",
      "resetting env. episode reward total was 11.0. running mean: 2.961567338422156\n",
      "resetting env. episode reward total was 3.0. running mean: 2.9619516650379345\n",
      "resetting env. episode reward total was 4.0. running mean: 2.9723321483875553\n",
      "resetting env. episode reward total was 2.0. running mean: 2.9626088269036797\n",
      "resetting env. episode reward total was 8.0. running mean: 3.012982738634643\n",
      "resetting env. episode reward total was 2.0. running mean: 3.0028529112482962\n",
      "resetting env. episode reward total was 2.0. running mean: 2.9928243821358134\n",
      "resetting env. episode reward total was 3.0. running mean: 2.992896138314455\n",
      "resetting env. episode reward total was -2.0. running mean: 2.9429671769313104\n",
      "resetting env. episode reward total was 6.0. running mean: 2.9735375051619974\n",
      "resetting env. episode reward total was 3.0. running mean: 2.973802130110377\n",
      "resetting env. episode reward total was 2.0. running mean: 2.9640641088092736\n",
      "resetting env. episode reward total was 10.0. running mean: 3.0344234677211808\n",
      "resetting env. episode reward total was 6.0. running mean: 3.064079233043969\n",
      "resetting env. episode reward total was 5.0. running mean: 3.083438440713529\n",
      "resetting env. episode reward total was -13.0. running mean: 2.9226040563063935\n",
      "resetting env. episode reward total was 6.0. running mean: 2.9533780157433296\n",
      "resetting env. episode reward total was 11.0. running mean: 3.0338442355858963\n",
      "resetting env. episode reward total was -1.0. running mean: 2.9935057932300375\n",
      "resetting env. episode reward total was -1.0. running mean: 2.9535707352977374\n",
      "resetting env. episode reward total was -5.0. running mean: 2.87403502794476\n",
      "resetting env. episode reward total was 11.0. running mean: 2.955294677665312\n",
      "resetting env. episode reward total was -1.0. running mean: 2.915741730888659\n",
      "resetting env. episode reward total was 8.0. running mean: 2.9665843135797725\n",
      "resetting env. episode reward total was -2.0. running mean: 2.916918470443975\n",
      "resetting env. episode reward total was -1.0. running mean: 2.8777492857395353\n",
      "resetting env. episode reward total was 4.0. running mean: 2.88897179288214\n",
      "resetting env. episode reward total was 5.0. running mean: 2.9100820749533187\n",
      "resetting env. episode reward total was 7.0. running mean: 2.950981254203785\n",
      "resetting env. episode reward total was 6.0. running mean: 2.9814714416617476\n",
      "resetting env. episode reward total was 9.0. running mean: 3.04165672724513\n",
      "resetting env. episode reward total was 2.0. running mean: 3.0312401599726786\n",
      "resetting env. episode reward total was 10.0. running mean: 3.100927758372952\n",
      "resetting env. episode reward total was -1.0. running mean: 3.059918480789223\n",
      "resetting env. episode reward total was 7.0. running mean: 3.0993192959813305\n",
      "resetting env. episode reward total was 8.0. running mean: 3.148326103021517\n",
      "resetting env. episode reward total was 7.0. running mean: 3.1868428419913015\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2249744135713883\n",
      "resetting env. episode reward total was -3.0. running mean: 3.1627246694356743\n",
      "resetting env. episode reward total was 6.0. running mean: 3.1910974227413176\n",
      "resetting env. episode reward total was -9.0. running mean: 3.0691864485139044\n",
      "resetting env. episode reward total was 9.0. running mean: 3.1284945840287652\n",
      "resetting env. episode reward total was -1.0. running mean: 3.0872096381884777\n",
      "resetting env. episode reward total was 3.0. running mean: 3.086337541806593\n",
      "resetting env. episode reward total was 8.0. running mean: 3.135474166388527\n",
      "resetting env. episode reward total was -9.0. running mean: 3.0141194247246417\n",
      "resetting env. episode reward total was 10.0. running mean: 3.0839782304773955\n",
      "resetting env. episode reward total was 8.0. running mean: 3.1331384481726214\n",
      "resetting env. episode reward total was 2.0. running mean: 3.1218070636908952\n",
      "resetting env. episode reward total was 12.0. running mean: 3.210588993053986\n",
      "resetting env. episode reward total was 1.0. running mean: 3.188483103123446\n",
      "resetting env. episode reward total was 10.0. running mean: 3.2565982720922118\n",
      "resetting env. episode reward total was 2.0. running mean: 3.24403228937129\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2615919664775768\n",
      "resetting env. episode reward total was 1.0. running mean: 3.238976046812801\n",
      "resetting env. episode reward total was 4.0. running mean: 3.2465862863446726\n",
      "resetting env. episode reward total was 1.0. running mean: 3.2241204234812257\n",
      "resetting env. episode reward total was 1.0. running mean: 3.2018792192464134\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2398604270539493\n",
      "resetting env. episode reward total was 9.0. running mean: 3.2974618227834096\n",
      "resetting env. episode reward total was 4.0. running mean: 3.3044872045555755\n",
      "resetting env. episode reward total was 14.0. running mean: 3.41144233251002\n",
      "resetting env. episode reward total was 9.0. running mean: 3.46732790918492\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4526546300930705\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4381280837921397\n",
      "resetting env. episode reward total was -3.0. running mean: 3.3737468029542184\n",
      "resetting env. episode reward total was -7.0. running mean: 3.2700093349246764\n",
      "resetting env. episode reward total was 8.0. running mean: 3.3173092415754297\n",
      "resetting env. episode reward total was -6.0. running mean: 3.2241361491596754\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2418947876680786\n",
      "resetting env. episode reward total was -3.0. running mean: 3.179475839791398\n",
      "resetting env. episode reward total was -5.0. running mean: 3.097681081393484\n",
      "resetting env. episode reward total was 10.0. running mean: 3.166704270579549\n",
      "resetting env. episode reward total was 10.0. running mean: 3.235037227873754\n",
      "resetting env. episode reward total was -2.0. running mean: 3.182686855595016\n",
      "resetting env. episode reward total was 13.0. running mean: 3.2808599870390656\n",
      "resetting env. episode reward total was 8.0. running mean: 3.3280513871686748\n",
      "resetting env. episode reward total was 7.0. running mean: 3.3647708732969877\n",
      "resetting env. episode reward total was 12.0. running mean: 3.451123164564018\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4366119329183777\n",
      "resetting env. episode reward total was 4.0. running mean: 3.442245813589194\n",
      "resetting env. episode reward total was 5.0. running mean: 3.4578233554533018\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4632451218987685\n",
      "resetting env. episode reward total was 15.0. running mean: 3.5786126706797807\n",
      "resetting env. episode reward total was 4.0. running mean: 3.582826543972983\n",
      "resetting env. episode reward total was 3.0. running mean: 3.576998278533253\n",
      "resetting env. episode reward total was -9.0. running mean: 3.451228295747921\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4567160127904417\n",
      "resetting env. episode reward total was -11.0. running mean: 3.3121488526625376\n",
      "resetting env. episode reward total was 11.0. running mean: 3.389027364135912\n",
      "resetting env. episode reward total was -3.0. running mean: 3.325137090494553\n",
      "resetting env. episode reward total was -2.0. running mean: 3.2718857195896076\n",
      "resetting env. episode reward total was -12.0. running mean: 3.1191668623937114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -4.0. running mean: 3.047975193769774\n",
      "resetting env. episode reward total was -5.0. running mean: 2.9674954418320767\n",
      "resetting env. episode reward total was 6.0. running mean: 2.997820487413756\n",
      "resetting env. episode reward total was -4.0. running mean: 2.9278422825396184\n",
      "resetting env. episode reward total was -2.0. running mean: 2.8785638597142222\n",
      "resetting env. episode reward total was 2.0. running mean: 2.86977822111708\n",
      "resetting env. episode reward total was 1.0. running mean: 2.851080438905909\n",
      "resetting env. episode reward total was -3.0. running mean: 2.79256963451685\n",
      "resetting env. episode reward total was -7.0. running mean: 2.694643938171682\n",
      "resetting env. episode reward total was 2.0. running mean: 2.687697498789965\n",
      "resetting env. episode reward total was -7.0. running mean: 2.590820523802065\n",
      "resetting env. episode reward total was 6.0. running mean: 2.6249123185640446\n",
      "resetting env. episode reward total was -5.0. running mean: 2.5486631953784045\n",
      "resetting env. episode reward total was 9.0. running mean: 2.6131765634246205\n",
      "resetting env. episode reward total was 6.0. running mean: 2.6470447977903744\n",
      "resetting env. episode reward total was -1.0. running mean: 2.6105743498124707\n",
      "resetting env. episode reward total was 6.0. running mean: 2.644468606314346\n",
      "resetting env. episode reward total was -1.0. running mean: 2.608023920251203\n",
      "resetting env. episode reward total was 4.0. running mean: 2.621943681048691\n",
      "resetting env. episode reward total was -5.0. running mean: 2.545724244238204\n",
      "resetting env. episode reward total was 15.0. running mean: 2.670267001795822\n",
      "resetting env. episode reward total was -1.0. running mean: 2.633564331777864\n",
      "resetting env. episode reward total was 11.0. running mean: 2.7172286884600854\n",
      "resetting env. episode reward total was 8.0. running mean: 2.7700564015754847\n",
      "resetting env. episode reward total was -5.0. running mean: 2.69235583755973\n",
      "resetting env. episode reward total was -1.0. running mean: 2.655432279184133\n",
      "resetting env. episode reward total was 11.0. running mean: 2.7388779563922916\n",
      "resetting env. episode reward total was 8.0. running mean: 2.7914891768283687\n",
      "resetting env. episode reward total was 8.0. running mean: 2.843574285060085\n",
      "resetting env. episode reward total was -2.0. running mean: 2.795138542209484\n",
      "resetting env. episode reward total was 6.0. running mean: 2.827187156787389\n",
      "resetting env. episode reward total was -6.0. running mean: 2.738915285219515\n",
      "resetting env. episode reward total was 5.0. running mean: 2.7615261323673197\n",
      "resetting env. episode reward total was 6.0. running mean: 2.7939108710436464\n",
      "resetting env. episode reward total was -11.0. running mean: 2.65597176233321\n",
      "resetting env. episode reward total was 1.0. running mean: 2.6394120447098777\n",
      "resetting env. episode reward total was -3.0. running mean: 2.583017924262779\n",
      "resetting env. episode reward total was -6.0. running mean: 2.497187745020151\n",
      "resetting env. episode reward total was 6.0. running mean: 2.5322158675699495\n",
      "resetting env. episode reward total was 4.0. running mean: 2.5468937088942503\n",
      "resetting env. episode reward total was -6.0. running mean: 2.4614247718053077\n",
      "resetting env. episode reward total was 4.0. running mean: 2.4768105240872544\n",
      "resetting env. episode reward total was 8.0. running mean: 2.532042418846382\n",
      "resetting env. episode reward total was -7.0. running mean: 2.4367219946579186\n",
      "resetting env. episode reward total was 13.0. running mean: 2.542354774711339\n",
      "resetting env. episode reward total was -4.0. running mean: 2.4769312269642256\n",
      "resetting env. episode reward total was -5.0. running mean: 2.4021619146945836\n",
      "resetting env. episode reward total was -5.0. running mean: 2.328140295547638\n",
      "resetting env. episode reward total was -4.0. running mean: 2.2648588925921613\n",
      "resetting env. episode reward total was -4.0. running mean: 2.2022103036662397\n",
      "resetting env. episode reward total was 9.0. running mean: 2.270188200629577\n",
      "resetting env. episode reward total was 8.0. running mean: 2.3274863186232815\n",
      "resetting env. episode reward total was 11.0. running mean: 2.4142114554370484\n",
      "resetting env. episode reward total was 12.0. running mean: 2.510069340882678\n",
      "resetting env. episode reward total was -9.0. running mean: 2.3949686474738514\n",
      "resetting env. episode reward total was 12.0. running mean: 2.491018960999113\n",
      "resetting env. episode reward total was -10.0. running mean: 2.366108771389122\n",
      "resetting env. episode reward total was -3.0. running mean: 2.312447683675231\n",
      "resetting env. episode reward total was -4.0. running mean: 2.2493232068384783\n",
      "resetting env. episode reward total was -4.0. running mean: 2.1868299747700934\n",
      "resetting env. episode reward total was 9.0. running mean: 2.2549616750223924\n",
      "resetting env. episode reward total was -4.0. running mean: 2.1924120582721685\n",
      "resetting env. episode reward total was -9.0. running mean: 2.0804879376894467\n",
      "resetting env. episode reward total was 9.0. running mean: 2.149683058312552\n",
      "resetting env. episode reward total was -11.0. running mean: 2.018186227729427\n",
      "resetting env. episode reward total was 8.0. running mean: 2.0780043654521325\n",
      "resetting env. episode reward total was 13.0. running mean: 2.1872243217976113\n",
      "resetting env. episode reward total was -1.0. running mean: 2.1553520785796354\n",
      "resetting env. episode reward total was 11.0. running mean: 2.243798557793839\n",
      "resetting env. episode reward total was 3.0. running mean: 2.2513605722159005\n",
      "resetting env. episode reward total was 1.0. running mean: 2.238846966493741\n",
      "resetting env. episode reward total was -1.0. running mean: 2.206458496828804\n",
      "resetting env. episode reward total was 8.0. running mean: 2.264393911860516\n",
      "resetting env. episode reward total was 2.0. running mean: 2.261749972741911\n",
      "resetting env. episode reward total was 10.0. running mean: 2.339132473014492\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3357411482843466\n",
      "resetting env. episode reward total was -8.0. running mean: 2.232383736801503\n",
      "resetting env. episode reward total was -6.0. running mean: 2.150059899433488\n",
      "resetting env. episode reward total was -6.0. running mean: 2.0685593004391527\n",
      "resetting env. episode reward total was 6.0. running mean: 2.107873707434761\n",
      "resetting env. episode reward total was -1.0. running mean: 2.076794970360414\n",
      "resetting env. episode reward total was 4.0. running mean: 2.09602702065681\n",
      "resetting env. episode reward total was 13.0. running mean: 2.2050667504502415\n",
      "resetting env. episode reward total was 7.0. running mean: 2.253016082945739\n",
      "resetting env. episode reward total was -10.0. running mean: 2.1304859221162813\n",
      "resetting env. episode reward total was 7.0. running mean: 2.1791810628951183\n",
      "resetting env. episode reward total was 14.0. running mean: 2.297389252266167\n",
      "resetting env. episode reward total was 11.0. running mean: 2.384415359743505\n",
      "resetting env. episode reward total was -8.0. running mean: 2.2805712061460697\n",
      "resetting env. episode reward total was -4.0. running mean: 2.2177654940846088\n",
      "resetting env. episode reward total was -9.0. running mean: 2.105587839143763\n",
      "resetting env. episode reward total was -16.0. running mean: 1.924531960752325\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9752866411448018\n",
      "resetting env. episode reward total was -13.0. running mean: 1.8255337747333535\n",
      "resetting env. episode reward total was -1.0. running mean: 1.79727843698602\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7993056526161597\n",
      "resetting env. episode reward total was -5.0. running mean: 1.731312596089998\n",
      "resetting env. episode reward total was 9.0. running mean: 1.803999470129098\n",
      "resetting env. episode reward total was -5.0. running mean: 1.735959475427807\n",
      "resetting env. episode reward total was -7.0. running mean: 1.6485998806735287\n",
      "resetting env. episode reward total was -10.0. running mean: 1.5321138818667932\n",
      "resetting env. episode reward total was -11.0. running mean: 1.406792743048125\n",
      "resetting env. episode reward total was 10.0. running mean: 1.4927248156176438\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4677975674614674\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4631195917868527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: 1.4784883958689843\n",
      "resetting env. episode reward total was -6.0. running mean: 1.4037035119102943\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4396664767911913\n",
      "resetting env. episode reward total was -2.0. running mean: 1.4052698120232794\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3712171139030465\n",
      "resetting env. episode reward total was -5.0. running mean: 1.307504942764016\n",
      "resetting env. episode reward total was -6.0. running mean: 1.2344298933363758\n",
      "resetting env. episode reward total was -7.0. running mean: 1.152085594403012\n",
      "resetting env. episode reward total was -13.0. running mean: 1.010564738458982\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0604590910743923\n",
      "resetting env. episode reward total was -2.0. running mean: 1.0298545001636483\n",
      "resetting env. episode reward total was -10.0. running mean: 0.9195559551620119\n",
      "resetting env. episode reward total was -11.0. running mean: 0.8003603956103919\n",
      "resetting env. episode reward total was -10.0. running mean: 0.692356791654288\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6154332237377451\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5992788915003676\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5632861025853639\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5476532415595102\n",
      "resetting env. episode reward total was -8.0. running mean: 0.4621767091439151\n",
      "resetting env. episode reward total was -10.0. running mean: 0.35755494205247595\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3239793926319512\n",
      "resetting env. episode reward total was 4.0. running mean: 0.36073959870563166\n",
      "resetting env. episode reward total was -3.0. running mean: 0.32713220271857535\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2938608806913896\n",
      "resetting env. episode reward total was 2.0. running mean: 0.31092227188447574\n",
      "resetting env. episode reward total was 3.0. running mean: 0.33781304916563093\n",
      "resetting env. episode reward total was 2.0. running mean: 0.35443491867397464\n",
      "resetting env. episode reward total was 3.0. running mean: 0.3808905694872349\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3670816637923625\n",
      "resetting env. episode reward total was -6.0. running mean: 0.3034108471544389\n",
      "resetting env. episode reward total was 14.0. running mean: 0.4403767386828945\n",
      "resetting env. episode reward total was 1.0. running mean: 0.44597297129606556\n",
      "resetting env. episode reward total was -15.0. running mean: 0.2915132415831049\n",
      "resetting env. episode reward total was -5.0. running mean: 0.2385981091672738\n",
      "resetting env. episode reward total was 3.0. running mean: 0.2662121280756011\n",
      "resetting env. episode reward total was -8.0. running mean: 0.18355000679484507\n",
      "resetting env. episode reward total was 7.0. running mean: 0.25171450672689666\n",
      "resetting env. episode reward total was 6.0. running mean: 0.3091973616596277\n",
      "resetting env. episode reward total was -1.0. running mean: 0.2961053880430314\n",
      "resetting env. episode reward total was 5.0. running mean: 0.34314433416260104\n",
      "resetting env. episode reward total was 1.0. running mean: 0.349712890820975\n",
      "resetting env. episode reward total was 4.0. running mean: 0.38621576191276524\n",
      "resetting env. episode reward total was 9.0. running mean: 0.4723536042936376\n",
      "resetting env. episode reward total was 1.0. running mean: 0.4776300682507012\n",
      "resetting env. episode reward total was 5.0. running mean: 0.5228537675681942\n",
      "resetting env. episode reward total was -3.0. running mean: 0.4876252298925122\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4727489775935871\n",
      "resetting env. episode reward total was -7.0. running mean: 0.3980214878176512\n",
      "resetting env. episode reward total was 6.0. running mean: 0.45404127293947466\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3995008602100799\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3655058516079791\n",
      "resetting env. episode reward total was -9.0. running mean: 0.2718507930918993\n",
      "resetting env. episode reward total was 9.0. running mean: 0.3591322851609803\n",
      "resetting env. episode reward total was -11.0. running mean: 0.2455409623093705\n",
      "resetting env. episode reward total was -5.0. running mean: 0.1930855526862768\n",
      "resetting env. episode reward total was -5.0. running mean: 0.14115469715941403\n",
      "resetting env. episode reward total was -1.0. running mean: 0.12974315018781987\n",
      "resetting env. episode reward total was -6.0. running mean: 0.06844571868594168\n",
      "resetting env. episode reward total was 7.0. running mean: 0.13776126149908227\n",
      "resetting env. episode reward total was -6.0. running mean: 0.07638364888409144\n",
      "resetting env. episode reward total was 4.0. running mean: 0.11561981239525052\n",
      "resetting env. episode reward total was -4.0. running mean: 0.074463614271298\n",
      "resetting env. episode reward total was 3.0. running mean: 0.10371897812858501\n",
      "resetting env. episode reward total was -3.0. running mean: 0.07268178834729916\n",
      "resetting env. episode reward total was -5.0. running mean: 0.021954970463826162\n",
      "resetting env. episode reward total was 2.0. running mean: 0.0417354207591879\n",
      "resetting env. episode reward total was 11.0. running mean: 0.15131806655159602\n",
      "resetting env. episode reward total was 10.0. running mean: 0.24980488588608007\n",
      "resetting env. episode reward total was -9.0. running mean: 0.1573068370272193\n",
      "resetting env. episode reward total was 6.0. running mean: 0.2157337686569471\n",
      "resetting env. episode reward total was -6.0. running mean: 0.15357643097037763\n",
      "resetting env. episode reward total was 8.0. running mean: 0.23204066666067386\n",
      "resetting env. episode reward total was 4.0. running mean: 0.2697202599940671\n",
      "resetting env. episode reward total was 1.0. running mean: 0.27702305739412647\n",
      "resetting env. episode reward total was -1.0. running mean: 0.2642528268201852\n",
      "resetting env. episode reward total was -1.0. running mean: 0.25161029855198336\n",
      "resetting env. episode reward total was -3.0. running mean: 0.21909419556646353\n",
      "resetting env. episode reward total was 5.0. running mean: 0.2669032536107989\n",
      "resetting env. episode reward total was 4.0. running mean: 0.3042342210746909\n",
      "resetting env. episode reward total was -12.0. running mean: 0.181191878863944\n",
      "resetting env. episode reward total was 3.0. running mean: 0.20937996007530454\n",
      "resetting env. episode reward total was -4.0. running mean: 0.1672861604745515\n",
      "resetting env. episode reward total was -7.0. running mean: 0.09561329886980596\n",
      "resetting env. episode reward total was -10.0. running mean: -0.005342834118892109\n",
      "resetting env. episode reward total was -1.0. running mean: -0.015289405777703189\n",
      "resetting env. episode reward total was 4.0. running mean: 0.024863488280073842\n",
      "resetting env. episode reward total was -5.0. running mean: -0.0253851466027269\n",
      "resetting env. episode reward total was -15.0. running mean: -0.17513129513669962\n",
      "resetting env. episode reward total was 11.0. running mean: -0.06337998218533263\n",
      "resetting env. episode reward total was -7.0. running mean: -0.1327461823634793\n",
      "resetting env. episode reward total was 1.0. running mean: -0.1214187205398445\n",
      "resetting env. episode reward total was -5.0. running mean: -0.17020453333444607\n",
      "resetting env. episode reward total was 6.0. running mean: -0.10850248800110163\n",
      "resetting env. episode reward total was 10.0. running mean: -0.007417463121090609\n",
      "resetting env. episode reward total was 8.0. running mean: 0.07265671151012029\n",
      "resetting env. episode reward total was 2.0. running mean: 0.09193014439501909\n",
      "resetting env. episode reward total was 9.0. running mean: 0.1810108429510689\n",
      "resetting env. episode reward total was 10.0. running mean: 0.27920073452155825\n",
      "resetting env. episode reward total was -3.0. running mean: 0.24640872717634268\n",
      "resetting env. episode reward total was -5.0. running mean: 0.19394463990457927\n",
      "resetting env. episode reward total was 11.0. running mean: 0.30200519350553345\n",
      "resetting env. episode reward total was -9.0. running mean: 0.20898514157047812\n",
      "resetting env. episode reward total was 1.0. running mean: 0.21689529015477335\n",
      "resetting env. episode reward total was 8.0. running mean: 0.2947263372532256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: 0.3217790738806934\n",
      "resetting env. episode reward total was 7.0. running mean: 0.3885612831418864\n",
      "resetting env. episode reward total was 5.0. running mean: 0.43467567031046755\n",
      "resetting env. episode reward total was 13.0. running mean: 0.5603289136073628\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5247256244712891\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5294783682265762\n",
      "resetting env. episode reward total was -6.0. running mean: 0.46418358454431047\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5395417486988674\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5041463312118787\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5791048678997599\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5533138192207623\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5577806810285547\n",
      "resetting env. episode reward total was 7.0. running mean: 0.6222028742182693\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5659808454760865\n",
      "resetting env. episode reward total was -6.0. running mean: 0.5003210370213256\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5353178266511123\n",
      "resetting env. episode reward total was -5.0. running mean: 0.4799646483846011\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4651650019007551\n",
      "resetting env. episode reward total was -10.0. running mean: 0.3605133518817475\n",
      "resetting env. episode reward total was 4.0. running mean: 0.39690821836293\n",
      "resetting env. episode reward total was 1.0. running mean: 0.4029391361793007\n",
      "resetting env. episode reward total was 4.0. running mean: 0.43890974481750766\n",
      "resetting env. episode reward total was 3.0. running mean: 0.46452064736933263\n",
      "resetting env. episode reward total was 3.0. running mean: 0.4898754408956393\n",
      "resetting env. episode reward total was -2.0. running mean: 0.4649766864866829\n",
      "resetting env. episode reward total was -13.0. running mean: 0.33032691962181604\n",
      "resetting env. episode reward total was -3.0. running mean: 0.29702365042559786\n",
      "resetting env. episode reward total was 2.0. running mean: 0.3140534139213419\n",
      "resetting env. episode reward total was 8.0. running mean: 0.39091287978212846\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3370037509843072\n",
      "resetting env. episode reward total was -8.0. running mean: 0.2536337134744641\n",
      "resetting env. episode reward total was -10.0. running mean: 0.15109737633971945\n",
      "resetting env. episode reward total was -1.0. running mean: 0.13958640257632224\n",
      "resetting env. episode reward total was -4.0. running mean: 0.09819053855055901\n",
      "resetting env. episode reward total was -13.0. running mean: -0.032791366834946586\n",
      "resetting env. episode reward total was 3.0. running mean: -0.0024634531665971224\n",
      "resetting env. episode reward total was 1.0. running mean: 0.007561181365068849\n",
      "resetting env. episode reward total was 7.0. running mean: 0.07748556955141817\n",
      "resetting env. episode reward total was 4.0. running mean: 0.11671071385590398\n",
      "resetting env. episode reward total was -7.0. running mean: 0.045543606717344934\n",
      "resetting env. episode reward total was -2.0. running mean: 0.025088170650171483\n",
      "resetting env. episode reward total was 8.0. running mean: 0.10483728894366977\n",
      "resetting env. episode reward total was 4.0. running mean: 0.14378891605423308\n",
      "resetting env. episode reward total was 5.0. running mean: 0.19235102689369077\n",
      "resetting env. episode reward total was 2.0. running mean: 0.21042751662475384\n",
      "resetting env. episode reward total was 6.0. running mean: 0.2683232414585063\n",
      "resetting env. episode reward total was 6.0. running mean: 0.3256400090439212\n",
      "resetting env. episode reward total was 3.0. running mean: 0.352383608953482\n",
      "resetting env. episode reward total was 11.0. running mean: 0.45885977286394714\n",
      "resetting env. episode reward total was 4.0. running mean: 0.49427117513530766\n",
      "resetting env. episode reward total was -5.0. running mean: 0.4393284633839546\n",
      "resetting env. episode reward total was 3.0. running mean: 0.46493517875011503\n",
      "resetting env. episode reward total was 3.0. running mean: 0.4902858269626139\n",
      "resetting env. episode reward total was -3.0. running mean: 0.4553829686929878\n",
      "resetting env. episode reward total was -3.0. running mean: 0.4208291390060579\n",
      "resetting env. episode reward total was 4.0. running mean: 0.4566208476159973\n",
      "resetting env. episode reward total was -3.0. running mean: 0.4220546391398373\n",
      "resetting env. episode reward total was -4.0. running mean: 0.377834092748439\n",
      "resetting env. episode reward total was -2.0. running mean: 0.35405575182095456\n",
      "resetting env. episode reward total was 3.0. running mean: 0.38051519430274505\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3467100423597176\n",
      "resetting env. episode reward total was -5.0. running mean: 0.29324294193612044\n",
      "resetting env. episode reward total was -7.0. running mean: 0.2203105125167592\n",
      "resetting env. episode reward total was -7.0. running mean: 0.14810740739159162\n",
      "resetting env. episode reward total was -11.0. running mean: 0.03662633331767569\n",
      "resetting env. episode reward total was 10.0. running mean: 0.13626006998449894\n",
      "resetting env. episode reward total was 8.0. running mean: 0.21489746928465397\n",
      "resetting env. episode reward total was 10.0. running mean: 0.3127484945918074\n",
      "resetting env. episode reward total was -5.0. running mean: 0.25962100964588936\n",
      "resetting env. episode reward total was -4.0. running mean: 0.21702479954943046\n",
      "resetting env. episode reward total was -11.0. running mean: 0.10485455155393615\n",
      "resetting env. episode reward total was -1.0. running mean: 0.0938060060383968\n",
      "resetting env. episode reward total was -6.0. running mean: 0.03286794597801283\n",
      "resetting env. episode reward total was -6.0. running mean: -0.027460733481767294\n",
      "resetting env. episode reward total was 7.0. running mean: 0.04281387385305038\n",
      "resetting env. episode reward total was 5.0. running mean: 0.09238573511451989\n",
      "resetting env. episode reward total was 9.0. running mean: 0.1814618777633747\n",
      "resetting env. episode reward total was -1.0. running mean: 0.16964725898574093\n",
      "resetting env. episode reward total was 2.0. running mean: 0.1879507863958835\n",
      "resetting env. episode reward total was 6.0. running mean: 0.24607127853192468\n",
      "resetting env. episode reward total was 6.0. running mean: 0.3036105657466054\n",
      "resetting env. episode reward total was -1.0. running mean: 0.29057446008913934\n",
      "resetting env. episode reward total was 4.0. running mean: 0.32766871548824794\n",
      "resetting env. episode reward total was 5.0. running mean: 0.37439202833336543\n",
      "resetting env. episode reward total was -9.0. running mean: 0.2806481080500318\n",
      "resetting env. episode reward total was 2.0. running mean: 0.29784162696953154\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2648632106998362\n",
      "resetting env. episode reward total was -12.0. running mean: 0.14221457859283787\n",
      "resetting env. episode reward total was -5.0. running mean: 0.09079243280690948\n",
      "resetting env. episode reward total was 18.0. running mean: 0.2698845084788404\n",
      "resetting env. episode reward total was -7.0. running mean: 0.19718566339405197\n",
      "resetting env. episode reward total was -3.0. running mean: 0.16521380676011144\n",
      "resetting env. episode reward total was 4.0. running mean: 0.20356166869251033\n",
      "resetting env. episode reward total was -3.0. running mean: 0.1715260520055852\n",
      "resetting env. episode reward total was 10.0. running mean: 0.26981079148552933\n",
      "resetting env. episode reward total was 6.0. running mean: 0.327112683570674\n",
      "resetting env. episode reward total was 2.0. running mean: 0.3438415567349673\n",
      "resetting env. episode reward total was 11.0. running mean: 0.4504031411676176\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5558991097559415\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5603401186583821\n",
      "resetting env. episode reward total was 9.0. running mean: 0.6447367174717982\n",
      "resetting env. episode reward total was -2.0. running mean: 0.6182893502970802\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6421064567941094\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6856853922261683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -15.0. running mean: 0.5288285383039066\n",
      "resetting env. episode reward total was 5.0. running mean: 0.5735402529208676\n",
      "resetting env. episode reward total was 8.0. running mean: 0.6478048503916589\n",
      "resetting env. episode reward total was -9.0. running mean: 0.5513268018877423\n",
      "resetting env. episode reward total was 6.0. running mean: 0.6058135338688648\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6497553985301762\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7032578445448745\n",
      "resetting env. episode reward total was -2.0. running mean: 0.6762252660994257\n",
      "resetting env. episode reward total was -2.0. running mean: 0.6494630134384314\n",
      "resetting env. episode reward total was -5.0. running mean: 0.592968383304047\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5670386994710065\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6113683124762964\n",
      "resetting env. episode reward total was 11.0. running mean: 0.7152546293515334\n",
      "resetting env. episode reward total was -3.0. running mean: 0.678102083058018\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7313210622274378\n",
      "resetting env. episode reward total was -9.0. running mean: 0.6340078516051634\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6576677730891117\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6410910953582206\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5646801844046383\n",
      "resetting env. episode reward total was -7.0. running mean: 0.48903338256059187\n",
      "resetting env. episode reward total was -10.0. running mean: 0.38414304873498595\n",
      "resetting env. episode reward total was 15.0. running mean: 0.5303016182476361\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5549986020651597\n",
      "resetting env. episode reward total was 2.0. running mean: 0.5694486160445081\n",
      "resetting env. episode reward total was 12.0. running mean: 0.683754129884063\n",
      "resetting env. episode reward total was 9.0. running mean: 0.7669165885852224\n",
      "resetting env. episode reward total was 7.0. running mean: 0.8292474226993702\n",
      "resetting env. episode reward total was 7.0. running mean: 0.8909549484723764\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9520453989876527\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9725249449977762\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0127996955477985\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0726716985923206\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0819449816063973\n",
      "resetting env. episode reward total was 10.0. running mean: 1.1711255317903333\n",
      "resetting env. episode reward total was -5.0. running mean: 1.10941427647243\n",
      "resetting env. episode reward total was 8.0. running mean: 1.1783201337077058\n",
      "resetting env. episode reward total was -2.0. running mean: 1.1465369323706287\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1250715630469224\n",
      "resetting env. episode reward total was 3.0. running mean: 1.143820847416453\n",
      "resetting env. episode reward total was 3.0. running mean: 1.1623826389422887\n",
      "resetting env. episode reward total was -2.0. running mean: 1.1307588125528658\n",
      "resetting env. episode reward total was -2.0. running mean: 1.0994512244273371\n",
      "resetting env. episode reward total was -10.0. running mean: 0.9884567121830637\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9985721450612332\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0485864236106208\n",
      "resetting env. episode reward total was 9.0. running mean: 1.1281005593745146\n",
      "resetting env. episode reward total was 12.0. running mean: 1.2368195537807694\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2644513582429617\n",
      "resetting env. episode reward total was 13.0. running mean: 1.3818068446605323\n",
      "resetting env. episode reward total was 5.0. running mean: 1.417988776213927\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4738088884517877\n",
      "resetting env. episode reward total was -2.0. running mean: 1.4390707995672698\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4946800915715972\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5497332906558814\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5242359577493225\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5889935981718293\n",
      "resetting env. episode reward total was 5.0. running mean: 1.623103662190111\n",
      "resetting env. episode reward total was -9.0. running mean: 1.5168726255682097\n",
      "resetting env. episode reward total was -9.0. running mean: 1.4117038993125275\n",
      "resetting env. episode reward total was 11.0. running mean: 1.5075868603194023\n",
      "resetting env. episode reward total was 9.0. running mean: 1.5825109917162083\n",
      "resetting env. episode reward total was 13.0. running mean: 1.6966858817990462\n",
      "resetting env. episode reward total was 15.0. running mean: 1.8297190229810556\n",
      "resetting env. episode reward total was 11.0. running mean: 1.9214218327512451\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9822076144237326\n",
      "resetting env. episode reward total was 4.0. running mean: 2.002385538279495\n",
      "resetting env. episode reward total was -3.0. running mean: 1.9523616828967\n",
      "resetting env. episode reward total was 12.0. running mean: 2.052838066067733\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0723096854070557\n",
      "resetting env. episode reward total was 5.0. running mean: 2.101586588552985\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0605707226674554\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0499650154407805\n",
      "resetting env. episode reward total was -14.0. running mean: 1.8894653652863727\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9005707116335089\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8915650045171737\n",
      "resetting env. episode reward total was -10.0. running mean: 1.772649354472002\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7049228609272817\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6278736323180087\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5615948959948287\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6359789470348804\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6596191575645316\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6530229659888862\n",
      "resetting env. episode reward total was 15.0. running mean: 1.7864927363289973\n",
      "resetting env. episode reward total was -4.0. running mean: 1.7286278089657072\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7813415308760503\n",
      "resetting env. episode reward total was 12.0. running mean: 1.8835281155672896\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9046928344116167\n",
      "resetting env. episode reward total was -10.0. running mean: 1.7856459060675005\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8377894470068254\n",
      "resetting env. episode reward total was -9.0. running mean: 1.729411552536757\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6521174370113894\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7055962626412755\n",
      "resetting env. episode reward total was 14.0. running mean: 1.8285403000148626\n",
      "resetting env. episode reward total was 6.0. running mean: 1.870254897014714\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8415523480445668\n",
      "resetting env. episode reward total was -1.0. running mean: 1.813136824564121\n",
      "resetting env. episode reward total was -10.0. running mean: 1.6950054563184798\n",
      "resetting env. episode reward total was 5.0. running mean: 1.728055401755295\n",
      "resetting env. episode reward total was -4.0. running mean: 1.670774847737742\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6340670992603645\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6877264282677609\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7308491639850834\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6935406723452324\n",
      "resetting env. episode reward total was -5.0. running mean: 1.62660526562178\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6003392129655623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 1.7043358208359067\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7172924626275476\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6901195380012721\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6832183426212595\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6163861591950468\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6302222976030964\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5639200746270654\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6182808738807948\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6720980651419868\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6453770844905669\n",
      "resetting env. episode reward total was -4.0. running mean: 1.588923313645661\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6330340805092045\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6767037397041125\n",
      "resetting env. episode reward total was -11.0. running mean: 1.5499367023070711\n",
      "resetting env. episode reward total was 12.0. running mean: 1.6544373352840003\n",
      "resetting env. episode reward total was 14.0. running mean: 1.77789296193116\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7401140323118485\n",
      "resetting env. episode reward total was -9.0. running mean: 1.63271289198873\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6963857630688426\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7594219054381541\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8118276863837726\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7637094095199348\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6560723154247354\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6195115922704881\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6833164763477833\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6864833115843054\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6096184784684624\n",
      "resetting env. episode reward total was 12.0. running mean: 1.713522293683778\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7663870707469402\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7287232000394708\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7914359680390761\n",
      "resetting env. episode reward total was -7.0. running mean: 1.7035216083586853\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7164863922750984\n",
      "resetting env. episode reward total was 10.0. running mean: 1.7993215283523474\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8513283130688238\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8628150299381356\n",
      "resetting env. episode reward total was -7.0. running mean: 1.774186879638754\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7264450108423666\n",
      "resetting env. episode reward total was 8.0. running mean: 1.789180560733943\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7512887551266036\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7737758675753377\n",
      "resetting env. episode reward total was -7.0. running mean: 1.6860381088995842\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6891777278105884\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6622859505324825\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7156630910271577\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6885064601168862\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6116213955157173\n",
      "resetting env. episode reward total was -5.0. running mean: 1.54550518156056\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5600501297449545\n",
      "resetting env. episode reward total was 2.0. running mean: 1.564449628447505\n",
      "resetting env. episode reward total was 7.0. running mean: 1.61880513216303\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6626170808413996\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5759909100329854\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5802310009326557\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6644286909233292\n",
      "resetting env. episode reward total was 3.0. running mean: 1.677784404014096\n",
      "resetting env. episode reward total was 9.0. running mean: 1.751006559973955\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6834964943742154\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5966615294304731\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6606949141361684\n",
      "resetting env. episode reward total was 9.0. running mean: 1.7340879649948069\n",
      "resetting env. episode reward total was 12.0. running mean: 1.8367470853448586\n",
      "resetting env. episode reward total was 13.0. running mean: 1.9483796144914098\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9888958183464958\n",
      "resetting env. episode reward total was 10.0. running mean: 2.069006860163031\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9983167915614006\n",
      "resetting env. episode reward total was 3.0. running mean: 2.0083336236457865\n",
      "resetting env. episode reward total was 5.0. running mean: 2.0382502874093285\n",
      "resetting env. episode reward total was -7.0. running mean: 1.9478677845352352\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9383891066898828\n",
      "resetting env. episode reward total was 9.0. running mean: 2.009005215622984\n",
      "resetting env. episode reward total was 6.0. running mean: 2.048915163466754\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0684260118320865\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0877417517137657\n",
      "resetting env. episode reward total was 3.0. running mean: 2.0968643341966278\n",
      "resetting env. episode reward total was 9.0. running mean: 2.1658956908546614\n",
      "resetting env. episode reward total was 4.0. running mean: 2.184236733946115\n",
      "resetting env. episode reward total was 1.0. running mean: 2.1723943666066536\n",
      "resetting env. episode reward total was -8.0. running mean: 2.0706704229405872\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9899637187111812\n",
      "resetting env. episode reward total was 7.0. running mean: 2.0400640815240694\n",
      "resetting env. episode reward total was -3.0. running mean: 1.9896634407088285\n",
      "resetting env. episode reward total was 13.0. running mean: 2.0997668063017403\n",
      "resetting env. episode reward total was 4.0. running mean: 2.118769138238723\n",
      "resetting env. episode reward total was -4.0. running mean: 2.057581446856336\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0970056323877726\n",
      "resetting env. episode reward total was -1.0. running mean: 2.066035576063895\n",
      "resetting env. episode reward total was -10.0. running mean: 1.945375220303256\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9559214681002235\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9963622534192214\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9863986308850292\n",
      "resetting env. episode reward total was 8.0. running mean: 2.046534644576179\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0660692981304174\n",
      "resetting env. episode reward total was -2.0. running mean: 2.025408605149113\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9651545190976218\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0055029739066454\n",
      "resetting env. episode reward total was 3.0. running mean: 2.0154479441675788\n",
      "resetting env. episode reward total was 3.0. running mean: 2.025293464725903\n",
      "resetting env. episode reward total was -7.0. running mean: 1.9350405300786442\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9256901247778577\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9264332235300792\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9571688912947784\n",
      "resetting env. episode reward total was -8.0. running mean: 1.8575972023818306\n",
      "resetting env. episode reward total was -6.0. running mean: 1.7790212303580122\n",
      "resetting env. episode reward total was 6.0. running mean: 1.821231018054432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 1.8430187078738878\n",
      "resetting env. episode reward total was -8.0. running mean: 1.7445885207951488\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6371426355871972\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6407712092313251\n",
      "resetting env. episode reward total was 7.0. running mean: 1.694363497139012\n",
      "resetting env. episode reward total was 3.0. running mean: 1.707419862167622\n",
      "resetting env. episode reward total was 10.0. running mean: 1.7903456635459458\n",
      "resetting env. episode reward total was 14.0. running mean: 1.9124422069104865\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9733177848413817\n",
      "resetting env. episode reward total was 4.0. running mean: 1.993584606992968\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9936487609230382\n",
      "resetting env. episode reward total was -12.0. running mean: 1.8537122733138078\n",
      "resetting env. episode reward total was 11.0. running mean: 1.9451751505806698\n",
      "resetting env. episode reward total was 12.0. running mean: 2.045723399074863\n",
      "resetting env. episode reward total was 8.0. running mean: 2.1052661650841147\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0642135034332734\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1035713683989408\n",
      "resetting env. episode reward total was -1.0. running mean: 2.0725356547149514\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0318102981678017\n",
      "resetting env. episode reward total was 11.0. running mean: 2.1214921951861236\n",
      "resetting env. episode reward total was 7.0. running mean: 2.1702772732342623\n",
      "resetting env. episode reward total was -14.0. running mean: 2.0085745005019198\n",
      "resetting env. episode reward total was 9.0. running mean: 2.0784887554969007\n",
      "resetting env. episode reward total was 8.0. running mean: 2.137703867941932\n",
      "resetting env. episode reward total was -3.0. running mean: 2.0863268292625126\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1254635609698873\n",
      "resetting env. episode reward total was 14.0. running mean: 2.2442089253601885\n",
      "resetting env. episode reward total was 4.0. running mean: 2.261766836106587\n",
      "resetting env. episode reward total was 5.0. running mean: 2.2891491677455207\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3162576760680653\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3130950993073847\n",
      "resetting env. episode reward total was -6.0. running mean: 2.229964148314311\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2776645068311674\n",
      "resetting env. episode reward total was 7.0. running mean: 2.3248878617628557\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2916389831452273\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3187225933137747\n",
      "resetting env. episode reward total was -5.0. running mean: 2.2455353673806373\n",
      "resetting env. episode reward total was 2.0. running mean: 2.2430800137068307\n",
      "resetting env. episode reward total was 12.0. running mean: 2.3406492135697627\n",
      "resetting env. episode reward total was 2.0. running mean: 2.337242721434065\n",
      "resetting env. episode reward total was -2.0. running mean: 2.2938702942197247\n",
      "resetting env. episode reward total was 1.0. running mean: 2.280931591277527\n",
      "resetting env. episode reward total was -3.0. running mean: 2.2281222753647523\n",
      "resetting env. episode reward total was 6.0. running mean: 2.265841052611105\n",
      "resetting env. episode reward total was -6.0. running mean: 2.1831826420849936\n",
      "resetting env. episode reward total was 9.0. running mean: 2.2513508156641433\n",
      "resetting env. episode reward total was 5.0. running mean: 2.2788373075075015\n",
      "resetting env. episode reward total was -7.0. running mean: 2.1860489344324265\n",
      "resetting env. episode reward total was -8.0. running mean: 2.084188445088102\n",
      "resetting env. episode reward total was 5.0. running mean: 2.113346560637221\n",
      "resetting env. episode reward total was 5.0. running mean: 2.1422130950308484\n",
      "resetting env. episode reward total was -3.0. running mean: 2.09079096408054\n",
      "resetting env. episode reward total was 4.0. running mean: 2.1098830544397345\n",
      "resetting env. episode reward total was -3.0. running mean: 2.058784223895337\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9781963816563835\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9784144178398195\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9486302736614214\n",
      "resetting env. episode reward total was -5.0. running mean: 1.879143970924807\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8103525312155588\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7422490059034033\n",
      "resetting env. episode reward total was 12.0. running mean: 1.8448265158443693\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8763782506859257\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8476144681790665\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9091383234972759\n",
      "resetting env. episode reward total was 4.0. running mean: 1.930046940262303\n",
      "resetting env. episode reward total was 5.0. running mean: 1.96074647085968\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9911390061510832\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9312276160895723\n",
      "resetting env. episode reward total was -9.0. running mean: 1.8219153399286765\n",
      "resetting env. episode reward total was -9.0. running mean: 1.7136961865293896\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6665592246640957\n",
      "resetting env. episode reward total was -4.0. running mean: 1.6098936324174546\n",
      "resetting env. episode reward total was -8.0. running mean: 1.51379469609328\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5086567491323473\n",
      "resetting env. episode reward total was 8.0. running mean: 1.573570181641024\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5178344798246137\n",
      "resetting env. episode reward total was 9.0. running mean: 1.5926561350263677\n",
      "resetting env. episode reward total was 9.0. running mean: 1.666729573676104\n",
      "resetting env. episode reward total was -6.0. running mean: 1.590062277939343\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6741616551599496\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6374200386083502\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6110458382222665\n",
      "resetting env. episode reward total was 12.0. running mean: 1.714935379840044\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7177860260416435\n",
      "resetting env. episode reward total was 9.0. running mean: 1.7906081657812272\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7227020841234149\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7654750632821807\n",
      "resetting env. episode reward total was 3.0. running mean: 1.777820312649359\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8000421095228654\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8320416884276367\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8637212715433604\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8250840588279267\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7568332182396473\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6792648860572508\n",
      "resetting env. episode reward total was -8.0. running mean: 1.5824722371966782\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5566475148247114\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5610810396764643\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5354702292796996\n",
      "resetting env. episode reward total was 5.0. running mean: 1.5701155269869025\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6344143717170334\n",
      "resetting env. episode reward total was -2.0. running mean: 1.598070227999863\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5520895257198644\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5265686304626658\n",
      "resetting env. episode reward total was -1.0. running mean: 1.501302944158039\n",
      "resetting env. episode reward total was 13.0. running mean: 1.6162899147164587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 1.6701270155692942\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6734257454136012\n",
      "resetting env. episode reward total was 9.0. running mean: 1.7466914879594653\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7992245730798706\n",
      "resetting env. episode reward total was 9.0. running mean: 1.8712323273490719\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8925200040755812\n",
      "resetting env. episode reward total was -6.0. running mean: 1.8135948040348253\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9154588559944772\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9563042674345323\n",
      "resetting env. episode reward total was 2.0. running mean: 1.956741224760187\n",
      "resetting env. episode reward total was 4.0. running mean: 1.977173812512585\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9674020743874592\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9577280536435846\n",
      "resetting env. episode reward total was -3.0. running mean: 1.9081507731071488\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8590692653760772\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9104785727223164\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9313737869950933\n",
      "resetting env. episode reward total was 10.0. running mean: 2.012060049125142\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0019394486338906\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9919200541475517\n",
      "resetting env. episode reward total was 11.0. running mean: 2.0820008536060763\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1211808450700156\n",
      "resetting env. episode reward total was -9.0. running mean: 2.0099690366193155\n",
      "resetting env. episode reward total was -9.0. running mean: 1.8998693462531222\n",
      "resetting env. episode reward total was -5.0. running mean: 1.830870652790591\n",
      "resetting env. episode reward total was 2.0. running mean: 1.832561946262685\n",
      "resetting env. episode reward total was 2.0. running mean: 1.834236326800058\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8458939635320575\n",
      "resetting env. episode reward total was -5.0. running mean: 1.777435023896737\n",
      "resetting env. episode reward total was 13.0. running mean: 1.8896606736577697\n",
      "resetting env. episode reward total was 4.0. running mean: 1.910764066921192\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9416564262519802\n",
      "resetting env. episode reward total was 13.0. running mean: 2.0522398619894604\n",
      "resetting env. episode reward total was 5.0. running mean: 2.0817174633695656\n",
      "resetting env. episode reward total was -2.0. running mean: 2.04090028873587\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0604912858485114\n",
      "resetting env. episode reward total was 3.0. running mean: 2.069886372990026\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0591875092601253\n",
      "resetting env. episode reward total was -9.0. running mean: 1.9485956341675241\n",
      "resetting env. episode reward total was 14.0. running mean: 2.069109677825849\n",
      "resetting env. episode reward total was -4.0. running mean: 2.0084185810475903\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0483343952371142\n",
      "resetting env. episode reward total was 9.0. running mean: 2.117851051284743\n",
      "resetting env. episode reward total was 9.0. running mean: 2.1866725407718954\n",
      "resetting env. episode reward total was 5.0. running mean: 2.2148058153641763\n",
      "resetting env. episode reward total was 1.0. running mean: 2.202657757210534\n",
      "resetting env. episode reward total was -4.0. running mean: 2.1406311796384285\n",
      "resetting env. episode reward total was 4.0. running mean: 2.159224867842044\n",
      "resetting env. episode reward total was 4.0. running mean: 2.1776326191636235\n",
      "resetting env. episode reward total was -7.0. running mean: 2.0858562929719873\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0849977300422675\n",
      "resetting env. episode reward total was 3.0. running mean: 2.094147752741845\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0532062752144262\n",
      "resetting env. episode reward total was 4.0. running mean: 2.072674212462282\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0019474703376594\n",
      "resetting env. episode reward total was 2.0. running mean: 2.001927995634283\n",
      "resetting env. episode reward total was -2.0. running mean: 1.96190871567794\n",
      "resetting env. episode reward total was 7.0. running mean: 2.0122896285211604\n",
      "resetting env. episode reward total was 11.0. running mean: 2.1021667322359487\n",
      "resetting env. episode reward total was 10.0. running mean: 2.1811450649135895\n",
      "resetting env. episode reward total was -17.0. running mean: 1.9893336142644538\n",
      "resetting env. episode reward total was -7.0. running mean: 1.8994402781218092\n",
      "resetting env. episode reward total was -11.0. running mean: 1.770445875340591\n",
      "resetting env. episode reward total was -6.0. running mean: 1.692741416587185\n",
      "resetting env. episode reward total was 3.0. running mean: 1.705814002421313\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6787558623971\n",
      "resetting env. episode reward total was 2.0. running mean: 1.681968303773129\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6351486207353976\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5987971345280436\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5728091631827632\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6370810715509356\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5707102608354262\n",
      "resetting env. episode reward total was -2.0. running mean: 1.535003158227072\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6096531266448013\n",
      "resetting env. episode reward total was -11.0. running mean: 1.4835565953783532\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4187210294245696\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4245338191303238\n",
      "resetting env. episode reward total was -4.0. running mean: 1.3702884809390206\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3965855961296303\n",
      "resetting env. episode reward total was -1.0. running mean: 1.372619740168334\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3688935427666507\n",
      "resetting env. episode reward total was -1.0. running mean: 1.345204607338984\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4017525612655943\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4577350356529384\n",
      "resetting env. episode reward total was 9.0. running mean: 1.533157685296409\n",
      "resetting env. episode reward total was -3.0. running mean: 1.487826108443445\n",
      "resetting env. episode reward total was -2.0. running mean: 1.4529478473590105\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4984183688854205\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4534341851965662\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5188998433446006\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4737108449111544\n",
      "resetting env. episode reward total was 8.0. running mean: 1.538973736462043\n",
      "resetting env. episode reward total was -7.0. running mean: 1.4535839990974226\n",
      "resetting env. episode reward total was -6.0. running mean: 1.3790481591064483\n",
      "resetting env. episode reward total was 13.0. running mean: 1.4952576775153839\n",
      "resetting env. episode reward total was 6.0. running mean: 1.54030510074023\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6049020497328277\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6488530292354995\n",
      "resetting env. episode reward total was 10.0. running mean: 1.7323644989431446\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7550408539537132\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7074904454141762\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6704155409600343\n",
      "resetting env. episode reward total was -7.0. running mean: 1.583711385550434\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6178742716949295\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5816955289779802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 1.6258785736882004\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6596197879513184\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6630235900718051\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7163933541710872\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7592294206293764\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7516371264230826\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7841207551588518\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6762795476072632\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6895167521311905\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6926215846098787\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6656953687637799\n",
      "resetting env. episode reward total was -5.0. running mean: 1.599038415076142\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6030480309253807\n",
      "resetting env. episode reward total was -8.0. running mean: 1.5070175506161267\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5719473751099655\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6462279013588659\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6497656223452772\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6832679661218244\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6464352864606062\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6699709335960002\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5832712242600402\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6474385120174397\n",
      "resetting env. episode reward total was 10.0. running mean: 1.7309641268972653\n",
      "resetting env. episode reward total was -4.0. running mean: 1.6736544856282927\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6869179407720098\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6400487613642898\n",
      "resetting env. episode reward total was 11.0. running mean: 1.733648273750647\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6663117910131404\n",
      "resetting env. episode reward total was -11.0. running mean: 1.539648673103009\n",
      "resetting env. episode reward total was 8.0. running mean: 1.604252186371979\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6382096645082591\n",
      "resetting env. episode reward total was 14.0. running mean: 1.7618275678631767\n",
      "resetting env. episode reward total was 7.0. running mean: 1.814209292184545\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8260671992626996\n",
      "resetting env. episode reward total was 9.0. running mean: 1.8978065272700726\n",
      "resetting env. episode reward total was -4.0. running mean: 1.8388284619973718\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8804401773773982\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8816357756036242\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9828194178475878\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9929912236691119\n",
      "resetting env. episode reward total was -7.0. running mean: 1.9030613114324206\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9440306983180964\n",
      "resetting env. episode reward total was 11.0. running mean: 2.0345903913349153\n",
      "resetting env. episode reward total was 7.0. running mean: 2.0842444874215658\n",
      "resetting env. episode reward total was 5.0. running mean: 2.11340204254735\n",
      "resetting env. episode reward total was -6.0. running mean: 2.0322680221218765\n",
      "resetting env. episode reward total was 10.0. running mean: 2.111945341900658\n",
      "resetting env. episode reward total was 3.0. running mean: 2.1208258884816513\n",
      "resetting env. episode reward total was -2.0. running mean: 2.079617629596835\n",
      "resetting env. episode reward total was -11.0. running mean: 1.9488214533008665\n",
      "resetting env. episode reward total was -9.0. running mean: 1.8393332387678578\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8909399063801793\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8520305073163774\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8935102022432138\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9045751002207816\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9055293492185739\n",
      "resetting env. episode reward total was -4.0. running mean: 1.8464740557263881\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8480093151691241\n",
      "resetting env. episode reward total was 12.0. running mean: 1.949529222017433\n",
      "resetting env. episode reward total was 10.0. running mean: 2.0300339297972587\n",
      "resetting env. episode reward total was -9.0. running mean: 1.919733590499286\n",
      "resetting env. episode reward total was 13.0. running mean: 2.0305362545942933\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0702308920483503\n",
      "resetting env. episode reward total was -1.0. running mean: 2.039528583127867\n",
      "resetting env. episode reward total was 5.0. running mean: 2.069133297296588\n",
      "resetting env. episode reward total was 7.0. running mean: 2.118441964323622\n",
      "resetting env. episode reward total was 1.0. running mean: 2.107257544680386\n",
      "resetting env. episode reward total was 9.0. running mean: 2.176184969233582\n",
      "resetting env. episode reward total was -1.0. running mean: 2.1444231195412464\n",
      "resetting env. episode reward total was -1.0. running mean: 2.1129788883458342\n",
      "resetting env. episode reward total was -1.0. running mean: 2.081849099462376\n",
      "resetting env. episode reward total was -7.0. running mean: 1.9910306084677523\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9211203023830747\n",
      "resetting env. episode reward total was 9.0. running mean: 1.991909099359244\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9619900083656516\n",
      "resetting env. episode reward total was 9.0. running mean: 2.032370108281995\n",
      "resetting env. episode reward total was 1.0. running mean: 2.022046407199175\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9618259431271832\n",
      "resetting env. episode reward total was 13.0. running mean: 2.072207683695911\n",
      "resetting env. episode reward total was -3.0. running mean: 2.021485606858952\n",
      "resetting env. episode reward total was 7.0. running mean: 2.0712707507903625\n",
      "resetting env. episode reward total was 6.0. running mean: 2.110558043282459\n",
      "resetting env. episode reward total was 8.0. running mean: 2.1694524628496348\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2177579382211383\n",
      "resetting env. episode reward total was 15.0. running mean: 2.345580358838927\n",
      "resetting env. episode reward total was -4.0. running mean: 2.2821245552505376\n",
      "resetting env. episode reward total was 6.0. running mean: 2.3193033096980322\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3461102766010518\n",
      "resetting env. episode reward total was 5.0. running mean: 2.372649173835041\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3689226820966907\n",
      "resetting env. episode reward total was 19.0. running mean: 2.5352334552757236\n",
      "resetting env. episode reward total was 8.0. running mean: 2.5898811207229664\n",
      "resetting env. episode reward total was 10.0. running mean: 2.663982309515737\n",
      "resetting env. episode reward total was 6.0. running mean: 2.6973424864205797\n",
      "resetting env. episode reward total was 7.0. running mean: 2.7403690615563736\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7429653709408095\n",
      "resetting env. episode reward total was 8.0. running mean: 2.7955357172314015\n",
      "resetting env. episode reward total was 7.0. running mean: 2.8375803600590874\n",
      "resetting env. episode reward total was 4.0. running mean: 2.8492045564584965\n",
      "resetting env. episode reward total was 7.0. running mean: 2.8907125108939113\n",
      "resetting env. episode reward total was -3.0. running mean: 2.8318053857849725\n",
      "resetting env. episode reward total was 1.0. running mean: 2.8134873319271225\n",
      "resetting env. episode reward total was 2.0. running mean: 2.8053524586078513\n",
      "resetting env. episode reward total was 8.0. running mean: 2.857298934021773\n",
      "resetting env. episode reward total was 4.0. running mean: 2.868725944681555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 13.0. running mean: 2.9700386852347394\n",
      "resetting env. episode reward total was 1.0. running mean: 2.9503382983823916\n",
      "resetting env. episode reward total was -3.0. running mean: 2.890834915398568\n",
      "resetting env. episode reward total was 12.0. running mean: 2.9819265662445824\n",
      "resetting env. episode reward total was 1.0. running mean: 2.9621073005821366\n",
      "resetting env. episode reward total was 5.0. running mean: 2.982486227576315\n",
      "resetting env. episode reward total was -1.0. running mean: 2.942661365300552\n",
      "resetting env. episode reward total was -7.0. running mean: 2.8432347516475462\n",
      "resetting env. episode reward total was 9.0. running mean: 2.9048024041310705\n",
      "resetting env. episode reward total was 3.0. running mean: 2.9057543800897596\n",
      "resetting env. episode reward total was -1.0. running mean: 2.8666968362888623\n",
      "resetting env. episode reward total was -7.0. running mean: 2.7680298679259736\n",
      "resetting env. episode reward total was -1.0. running mean: 2.730349569246714\n",
      "resetting env. episode reward total was -7.0. running mean: 2.633046073554247\n",
      "resetting env. episode reward total was 7.0. running mean: 2.6767156128187044\n",
      "resetting env. episode reward total was 6.0. running mean: 2.709948456690517\n",
      "resetting env. episode reward total was 5.0. running mean: 2.732848972123612\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7355204824023756\n",
      "resetting env. episode reward total was 11.0. running mean: 2.8181652775783514\n",
      "resetting env. episode reward total was -4.0. running mean: 2.7499836248025677\n",
      "resetting env. episode reward total was 4.0. running mean: 2.762483788554542\n",
      "resetting env. episode reward total was 6.0. running mean: 2.794858950668997\n",
      "resetting env. episode reward total was 5.0. running mean: 2.8169103611623068\n",
      "resetting env. episode reward total was 6.0. running mean: 2.848741257550684\n",
      "resetting env. episode reward total was 13.0. running mean: 2.950253844975177\n",
      "resetting env. episode reward total was 3.0. running mean: 2.950751306525425\n",
      "resetting env. episode reward total was -3.0. running mean: 2.8912437934601707\n",
      "resetting env. episode reward total was 5.0. running mean: 2.912331355525569\n",
      "resetting env. episode reward total was 4.0. running mean: 2.9232080419703133\n",
      "resetting env. episode reward total was 12.0. running mean: 3.01397596155061\n",
      "resetting env. episode reward total was 10.0. running mean: 3.083836201935104\n",
      "resetting env. episode reward total was 5.0. running mean: 3.1029978399157527\n",
      "resetting env. episode reward total was 8.0. running mean: 3.1519678615165954\n",
      "resetting env. episode reward total was -2.0. running mean: 3.100448182901429\n",
      "resetting env. episode reward total was 16.0. running mean: 3.229443701072415\n",
      "resetting env. episode reward total was 8.0. running mean: 3.277149264061691\n",
      "resetting env. episode reward total was 8.0. running mean: 3.324377771421074\n",
      "resetting env. episode reward total was 4.0. running mean: 3.331133993706863\n",
      "resetting env. episode reward total was 8.0. running mean: 3.3778226537697944\n",
      "resetting env. episode reward total was 13.0. running mean: 3.4740444272320965\n",
      "resetting env. episode reward total was 9.0. running mean: 3.5293039829597754\n",
      "resetting env. episode reward total was 15.0. running mean: 3.6440109431301777\n",
      "resetting env. episode reward total was -5.0. running mean: 3.5575708336988763\n",
      "resetting env. episode reward total was 12.0. running mean: 3.6419951253618876\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6655751741082687\n",
      "resetting env. episode reward total was 4.0. running mean: 3.668919422367186\n",
      "resetting env. episode reward total was 8.0. running mean: 3.712230228143514\n",
      "resetting env. episode reward total was 5.0. running mean: 3.725107925862079\n",
      "resetting env. episode reward total was 1.0. running mean: 3.697856846603458\n",
      "resetting env. episode reward total was 16.0. running mean: 3.8208782781374233\n",
      "resetting env. episode reward total was 2.0. running mean: 3.802669495356049\n",
      "resetting env. episode reward total was -2.0. running mean: 3.7446428004024885\n",
      "resetting env. episode reward total was 14.0. running mean: 3.847196372398464\n",
      "resetting env. episode reward total was 7.0. running mean: 3.878724408674479\n",
      "resetting env. episode reward total was 14.0. running mean: 3.9799371645877346\n",
      "resetting env. episode reward total was 8.0. running mean: 4.020137792941857\n",
      "resetting env. episode reward total was 4.0. running mean: 4.019936415012438\n",
      "resetting env. episode reward total was -1.0. running mean: 3.9697370508623138\n",
      "resetting env. episode reward total was 10.0. running mean: 4.03003968035369\n",
      "resetting env. episode reward total was -3.0. running mean: 3.9597392835501535\n",
      "resetting env. episode reward total was 5.0. running mean: 3.9701418907146517\n",
      "resetting env. episode reward total was 4.0. running mean: 3.970440471807505\n",
      "resetting env. episode reward total was -9.0. running mean: 3.84073606708943\n",
      "resetting env. episode reward total was 8.0. running mean: 3.882328706418536\n",
      "resetting env. episode reward total was -3.0. running mean: 3.8135054193543505\n",
      "resetting env. episode reward total was -2.0. running mean: 3.755370365160807\n",
      "resetting env. episode reward total was 2.0. running mean: 3.737816661509199\n",
      "resetting env. episode reward total was 3.0. running mean: 3.730438494894107\n",
      "resetting env. episode reward total was 7.0. running mean: 3.763134109945166\n",
      "resetting env. episode reward total was 10.0. running mean: 3.8255027688457144\n",
      "resetting env. episode reward total was -10.0. running mean: 3.687247741157257\n",
      "resetting env. episode reward total was 5.0. running mean: 3.700375263745684\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6533715111082277\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6868377959971452\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7399694180371736\n",
      "resetting env. episode reward total was 12.0. running mean: 3.822569723856802\n",
      "resetting env. episode reward total was 3.0. running mean: 3.814344026618234\n",
      "resetting env. episode reward total was 2.0. running mean: 3.7962005863520516\n",
      "resetting env. episode reward total was -1.0. running mean: 3.748238580488531\n",
      "resetting env. episode reward total was 15.0. running mean: 3.860756194683646\n",
      "resetting env. episode reward total was 10.0. running mean: 3.9221486327368096\n",
      "resetting env. episode reward total was -1.0. running mean: 3.8729271464094417\n",
      "resetting env. episode reward total was 1.0. running mean: 3.844197874945347\n",
      "resetting env. episode reward total was -7.0. running mean: 3.7357558961958937\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7583983372339347\n",
      "resetting env. episode reward total was 7.0. running mean: 3.7908143538615953\n",
      "resetting env. episode reward total was -4.0. running mean: 3.7129062103229793\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7157771482197495\n",
      "resetting env. episode reward total was 6.0. running mean: 3.738619376737552\n",
      "resetting env. episode reward total was 10.0. running mean: 3.8012331829701766\n",
      "resetting env. episode reward total was 8.0. running mean: 3.843220851140475\n",
      "resetting env. episode reward total was 12.0. running mean: 3.9247886426290703\n",
      "resetting env. episode reward total was 2.0. running mean: 3.9055407562027797\n",
      "resetting env. episode reward total was 6.0. running mean: 3.926485348640752\n",
      "resetting env. episode reward total was -1.0. running mean: 3.8772204951543445\n",
      "resetting env. episode reward total was 2.0. running mean: 3.858448290202801\n",
      "resetting env. episode reward total was -10.0. running mean: 3.719863807300773\n",
      "resetting env. episode reward total was 5.0. running mean: 3.732665169227765\n",
      "resetting env. episode reward total was 10.0. running mean: 3.7953385175354875\n",
      "resetting env. episode reward total was -5.0. running mean: 3.7073851323601326\n",
      "resetting env. episode reward total was 7.0. running mean: 3.740311281036531\n",
      "resetting env. episode reward total was 6.0. running mean: 3.762908168226166\n",
      "resetting env. episode reward total was -10.0. running mean: 3.625279086543904\n",
      "resetting env. episode reward total was 5.0. running mean: 3.6390262956784647\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6126360327216798\n",
      "resetting env. episode reward total was -8.0. running mean: 3.496509672394463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: 3.491544575670518\n",
      "resetting env. episode reward total was 5.0. running mean: 3.506629129913813\n",
      "resetting env. episode reward total was -7.0. running mean: 3.401562838614675\n",
      "resetting env. episode reward total was 3.0. running mean: 3.397547210228528\n",
      "resetting env. episode reward total was 7.0. running mean: 3.4335717381262425\n",
      "resetting env. episode reward total was -7.0. running mean: 3.3292360207449803\n",
      "resetting env. episode reward total was 4.0. running mean: 3.3359436605375303\n",
      "resetting env. episode reward total was 1.0. running mean: 3.312584223932155\n",
      "resetting env. episode reward total was 7.0. running mean: 3.349458381692833\n",
      "resetting env. episode reward total was 3.0. running mean: 3.3459637978759047\n",
      "resetting env. episode reward total was -4.0. running mean: 3.2725041598971454\n",
      "resetting env. episode reward total was 13.0. running mean: 3.369779118298174\n",
      "resetting env. episode reward total was -13.0. running mean: 3.206081327115192\n",
      "resetting env. episode reward total was 8.0. running mean: 3.2540205138440403\n",
      "resetting env. episode reward total was -6.0. running mean: 3.1614803087056\n",
      "resetting env. episode reward total was 1.0. running mean: 3.1398655056185434\n",
      "resetting env. episode reward total was 12.0. running mean: 3.228466850562358\n",
      "resetting env. episode reward total was 4.0. running mean: 3.2361821820567345\n",
      "resetting env. episode reward total was 2.0. running mean: 3.223820360236167\n",
      "resetting env. episode reward total was 2.0. running mean: 3.2115821566338054\n",
      "resetting env. episode reward total was -3.0. running mean: 3.1494663350674674\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1579716717167927\n",
      "resetting env. episode reward total was 9.0. running mean: 3.2163919549996245\n",
      "resetting env. episode reward total was 1.0. running mean: 3.194228035449628\n",
      "resetting env. episode reward total was -3.0. running mean: 3.1322857550951317\n",
      "resetting env. episode reward total was -6.0. running mean: 3.0409628975441803\n",
      "resetting env. episode reward total was -4.0. running mean: 2.9705532685687386\n",
      "resetting env. episode reward total was 5.0. running mean: 2.990847735883051\n",
      "resetting env. episode reward total was 3.0. running mean: 2.9909392585242203\n",
      "resetting env. episode reward total was 5.0. running mean: 3.011029865938978\n",
      "resetting env. episode reward total was 1.0. running mean: 2.990919567279588\n",
      "resetting env. episode reward total was -11.0. running mean: 2.8510103716067925\n",
      "resetting env. episode reward total was 5.0. running mean: 2.8725002678907243\n",
      "resetting env. episode reward total was 14.0. running mean: 2.983775265211817\n",
      "resetting env. episode reward total was -7.0. running mean: 2.883937512559699\n",
      "resetting env. episode reward total was -9.0. running mean: 2.7650981374341024\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7674471560597613\n",
      "resetting env. episode reward total was 5.0. running mean: 2.7897726844991637\n",
      "resetting env. episode reward total was 5.0. running mean: 2.811874957654172\n",
      "resetting env. episode reward total was 10.0. running mean: 2.8837562080776302\n",
      "resetting env. episode reward total was 7.0. running mean: 2.9249186459968537\n",
      "resetting env. episode reward total was 5.0. running mean: 2.945669459536885\n",
      "resetting env. episode reward total was -4.0. running mean: 2.876212764941516\n",
      "resetting env. episode reward total was -1.0. running mean: 2.8374506372921013\n",
      "resetting env. episode reward total was 1.0. running mean: 2.8190761309191803\n",
      "resetting env. episode reward total was -7.0. running mean: 2.720885369609989\n",
      "resetting env. episode reward total was 4.0. running mean: 2.733676515913889\n",
      "resetting env. episode reward total was -1.0. running mean: 2.6963397507547504\n",
      "resetting env. episode reward total was 4.0. running mean: 2.709376353247203\n",
      "resetting env. episode reward total was 2.0. running mean: 2.7022825897147307\n",
      "resetting env. episode reward total was -9.0. running mean: 2.5852597638175836\n",
      "resetting env. episode reward total was -2.0. running mean: 2.5394071661794078\n",
      "resetting env. episode reward total was 8.0. running mean: 2.5940130945176136\n",
      "resetting env. episode reward total was 3.0. running mean: 2.598072963572437\n",
      "resetting env. episode reward total was 6.0. running mean: 2.6320922339367128\n",
      "resetting env. episode reward total was -2.0. running mean: 2.5857713115973455\n",
      "resetting env. episode reward total was 11.0. running mean: 2.6699135984813718\n",
      "resetting env. episode reward total was 4.0. running mean: 2.683214462496558\n",
      "resetting env. episode reward total was 8.0. running mean: 2.7363823178715925\n",
      "resetting env. episode reward total was -10.0. running mean: 2.6090184946928763\n",
      "resetting env. episode reward total was 7.0. running mean: 2.6529283097459473\n",
      "resetting env. episode reward total was 13.0. running mean: 2.756399026648488\n",
      "resetting env. episode reward total was 2.0. running mean: 2.748835036382003\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7513466860181826\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7538332191580004\n",
      "resetting env. episode reward total was 8.0. running mean: 2.8062948869664206\n",
      "resetting env. episode reward total was 6.0. running mean: 2.8382319380967562\n",
      "resetting env. episode reward total was 7.0. running mean: 2.8798496187157885\n",
      "resetting env. episode reward total was 9.0. running mean: 2.94105112252863\n",
      "resetting env. episode reward total was -3.0. running mean: 2.881640611303344\n",
      "resetting env. episode reward total was 2.0. running mean: 2.8728242051903106\n",
      "resetting env. episode reward total was 6.0. running mean: 2.9040959631384076\n",
      "resetting env. episode reward total was -5.0. running mean: 2.8250550035070234\n",
      "resetting env. episode reward total was 7.0. running mean: 2.866804453471953\n",
      "resetting env. episode reward total was -1.0. running mean: 2.8281364089372336\n",
      "resetting env. episode reward total was -3.0. running mean: 2.7698550448478616\n",
      "resetting env. episode reward total was 11.0. running mean: 2.8521564943993827\n",
      "resetting env. episode reward total was 10.0. running mean: 2.923634929455389\n",
      "resetting env. episode reward total was 6.0. running mean: 2.9543985801608352\n",
      "resetting env. episode reward total was -4.0. running mean: 2.884854594359227\n",
      "resetting env. episode reward total was 5.0. running mean: 2.9060060484156347\n",
      "resetting env. episode reward total was 9.0. running mean: 2.9669459879314783\n",
      "resetting env. episode reward total was 12.0. running mean: 3.0572765280521637\n",
      "resetting env. episode reward total was 5.0. running mean: 3.0767037627716416\n",
      "resetting env. episode reward total was 13.0. running mean: 3.175936725143925\n",
      "resetting env. episode reward total was 5.0. running mean: 3.1941773578924857\n",
      "resetting env. episode reward total was -1.0. running mean: 3.152235584313561\n",
      "resetting env. episode reward total was 14.0. running mean: 3.2607132284704257\n",
      "resetting env. episode reward total was 9.0. running mean: 3.3181060961857214\n",
      "resetting env. episode reward total was 7.0. running mean: 3.354925035223864\n",
      "resetting env. episode reward total was 14.0. running mean: 3.4613757848716253\n",
      "resetting env. episode reward total was 10.0. running mean: 3.526762027022909\n",
      "resetting env. episode reward total was 5.0. running mean: 3.5414944067526797\n",
      "resetting env. episode reward total was 14.0. running mean: 3.646079462685153\n",
      "resetting env. episode reward total was -4.0. running mean: 3.5696186680583017\n",
      "resetting env. episode reward total was 1.0. running mean: 3.5439224813777184\n",
      "resetting env. episode reward total was 3.0. running mean: 3.538483256563941\n",
      "resetting env. episode reward total was 7.0. running mean: 3.5730984239983012\n",
      "resetting env. episode reward total was 6.0. running mean: 3.5973674397583184\n",
      "resetting env. episode reward total was 7.0. running mean: 3.631393765360735\n",
      "resetting env. episode reward total was -6.0. running mean: 3.5350798277071274\n",
      "resetting env. episode reward total was 11.0. running mean: 3.609729029430056\n",
      "resetting env. episode reward total was -2.0. running mean: 3.5536317391357555\n",
      "resetting env. episode reward total was -16.0. running mean: 3.3580954217443977\n",
      "resetting env. episode reward total was 7.0. running mean: 3.3945144675269536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 3.430569322851684\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4162636296231668\n",
      "resetting env. episode reward total was 16.0. running mean: 3.5421009933269354\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6066799833936662\n",
      "resetting env. episode reward total was -2.0. running mean: 3.5506131835597294\n",
      "resetting env. episode reward total was 5.0. running mean: 3.565107051724132\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6294559812068905\n",
      "resetting env. episode reward total was 8.0. running mean: 3.6731614213948216\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6964298071808734\n",
      "resetting env. episode reward total was -4.0. running mean: 3.6194655091090646\n",
      "resetting env. episode reward total was 13.0. running mean: 3.7132708540179737\n",
      "resetting env. episode reward total was 3.0. running mean: 3.706138145477794\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6790767640230158\n",
      "resetting env. episode reward total was 4.0. running mean: 3.6822859963827854\n",
      "resetting env. episode reward total was 8.0. running mean: 3.7254631364189574\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7482085050547678\n",
      "resetting env. episode reward total was -1.0. running mean: 3.7007264200042203\n",
      "resetting env. episode reward total was -7.0. running mean: 3.593719155804178\n",
      "resetting env. episode reward total was -14.0. running mean: 3.417781964246136\n",
      "resetting env. episode reward total was 7.0. running mean: 3.4536041446036743\n",
      "resetting env. episode reward total was 6.0. running mean: 3.4790681031576374\n",
      "resetting env. episode reward total was -1.0. running mean: 3.434277422126061\n",
      "resetting env. episode reward total was 7.0. running mean: 3.4699346479048003\n",
      "resetting env. episode reward total was 9.0. running mean: 3.5252353014257523\n",
      "resetting env. episode reward total was 1.0. running mean: 3.4999829484114944\n",
      "resetting env. episode reward total was 6.0. running mean: 3.5249831189273793\n",
      "resetting env. episode reward total was -1.0. running mean: 3.4797332877381058\n",
      "resetting env. episode reward total was 4.0. running mean: 3.484935954860725\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4700865953121176\n",
      "resetting env. episode reward total was 13.0. running mean: 3.5653857293589963\n",
      "resetting env. episode reward total was 3.0. running mean: 3.5597318720654063\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5441345533447524\n",
      "resetting env. episode reward total was -3.0. running mean: 3.478693207811305\n",
      "resetting env. episode reward total was -5.0. running mean: 3.393906275733192\n",
      "resetting env. episode reward total was 1.0. running mean: 3.36996721297586\n",
      "resetting env. episode reward total was -5.0. running mean: 3.2862675408461017\n",
      "resetting env. episode reward total was -9.0. running mean: 3.163404865437641\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1717708167832646\n",
      "resetting env. episode reward total was -9.0. running mean: 3.050053108615432\n",
      "resetting env. episode reward total was 11.0. running mean: 3.1295525775292776\n",
      "resetting env. episode reward total was 3.0. running mean: 3.1282570517539847\n",
      "resetting env. episode reward total was -1.0. running mean: 3.086974481236445\n",
      "resetting env. episode reward total was 8.0. running mean: 3.136104736424081\n",
      "resetting env. episode reward total was 14.0. running mean: 3.24474368905984\n",
      "resetting env. episode reward total was -3.0. running mean: 3.182296252169242\n",
      "resetting env. episode reward total was 3.0. running mean: 3.180473289647549\n",
      "resetting env. episode reward total was 3.0. running mean: 3.1786685567510733\n",
      "resetting env. episode reward total was -8.0. running mean: 3.0668818711835626\n",
      "resetting env. episode reward total was 2.0. running mean: 3.056213052471727\n",
      "resetting env. episode reward total was 3.0. running mean: 3.0556509219470094\n",
      "resetting env. episode reward total was 3.0. running mean: 3.0550944127275392\n",
      "resetting env. episode reward total was 8.0. running mean: 3.104543468600264\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1134980339142615\n",
      "resetting env. episode reward total was 3.0. running mean: 3.1123630535751188\n",
      "resetting env. episode reward total was 7.0. running mean: 3.1512394230393674\n",
      "resetting env. episode reward total was 5.0. running mean: 3.1697270288089734\n",
      "resetting env. episode reward total was -3.0. running mean: 3.108029758520884\n",
      "resetting env. episode reward total was -9.0. running mean: 2.9869494609356755\n",
      "resetting env. episode reward total was 2.0. running mean: 2.9770799663263188\n",
      "resetting env. episode reward total was 1.0. running mean: 2.9573091666630553\n",
      "resetting env. episode reward total was -1.0. running mean: 2.917736074996425\n",
      "resetting env. episode reward total was 9.0. running mean: 2.9785587142464607\n",
      "resetting env. episode reward total was -1.0. running mean: 2.938773127103996\n",
      "resetting env. episode reward total was 4.0. running mean: 2.949385395832956\n",
      "resetting env. episode reward total was 6.0. running mean: 2.979891541874627\n",
      "resetting env. episode reward total was 13.0. running mean: 3.0800926264558806\n",
      "resetting env. episode reward total was 8.0. running mean: 3.1292917001913216\n",
      "resetting env. episode reward total was 7.0. running mean: 3.1679987831894083\n",
      "resetting env. episode reward total was 10.0. running mean: 3.2363187953575143\n",
      "resetting env. episode reward total was 6.0. running mean: 3.2639556074039393\n",
      "resetting env. episode reward total was 6.0. running mean: 3.2913160513299\n",
      "resetting env. episode reward total was -6.0. running mean: 3.198402890816601\n",
      "resetting env. episode reward total was -6.0. running mean: 3.106418861908435\n",
      "resetting env. episode reward total was 7.0. running mean: 3.1453546732893503\n",
      "resetting env. episode reward total was 7.0. running mean: 3.1839011265564565\n",
      "resetting env. episode reward total was 12.0. running mean: 3.272062115290892\n",
      "resetting env. episode reward total was 12.0. running mean: 3.359341494137983\n",
      "resetting env. episode reward total was -1.0. running mean: 3.3157480791966036\n",
      "resetting env. episode reward total was 4.0. running mean: 3.3225905984046378\n",
      "resetting env. episode reward total was 9.0. running mean: 3.3793646924205913\n",
      "resetting env. episode reward total was 3.0. running mean: 3.375571045496385\n",
      "resetting env. episode reward total was 1.0. running mean: 3.351815335041421\n",
      "resetting env. episode reward total was 1.0. running mean: 3.3282971816910067\n",
      "resetting env. episode reward total was 5.0. running mean: 3.3450142098740963\n",
      "resetting env. episode reward total was 7.0. running mean: 3.381564067775355\n",
      "resetting env. episode reward total was 7.0. running mean: 3.4177484270976013\n",
      "resetting env. episode reward total was -3.0. running mean: 3.3535709428266256\n",
      "resetting env. episode reward total was 2.0. running mean: 3.340035233398359\n",
      "resetting env. episode reward total was -2.0. running mean: 3.2866348810643755\n",
      "resetting env. episode reward total was 13.0. running mean: 3.3837685322537316\n",
      "resetting env. episode reward total was 10.0. running mean: 3.4499308469311942\n",
      "resetting env. episode reward total was -9.0. running mean: 3.325431538461882\n",
      "resetting env. episode reward total was 11.0. running mean: 3.4021772230772633\n",
      "resetting env. episode reward total was -6.0. running mean: 3.3081554508464905\n",
      "resetting env. episode reward total was 1.0. running mean: 3.2850738963380253\n",
      "resetting env. episode reward total was -3.0. running mean: 3.2222231573746454\n",
      "resetting env. episode reward total was 7.0. running mean: 3.260000925800899\n",
      "resetting env. episode reward total was 6.0. running mean: 3.28740091654289\n",
      "resetting env. episode reward total was 4.0. running mean: 3.294526907377461\n",
      "resetting env. episode reward total was 8.0. running mean: 3.3415816383036865\n",
      "resetting env. episode reward total was 9.0. running mean: 3.3981658219206494\n",
      "resetting env. episode reward total was 11.0. running mean: 3.474184163701443\n",
      "resetting env. episode reward total was 16.0. running mean: 3.5994423220644283\n",
      "resetting env. episode reward total was 10.0. running mean: 3.663447898843784\n",
      "resetting env. episode reward total was 8.0. running mean: 3.706813419855346\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6597452856567925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 15.0. running mean: 3.7731478328002246\n",
      "resetting env. episode reward total was 14.0. running mean: 3.875416354472222\n",
      "resetting env. episode reward total was 3.0. running mean: 3.8666621909275\n",
      "resetting env. episode reward total was 2.0. running mean: 3.847995569018225\n",
      "resetting env. episode reward total was 12.0. running mean: 3.929515613328043\n",
      "resetting env. episode reward total was 8.0. running mean: 3.9702204571947624\n",
      "resetting env. episode reward total was 5.0. running mean: 3.9805182526228147\n",
      "resetting env. episode reward total was 12.0. running mean: 4.060713070096586\n",
      "resetting env. episode reward total was 1.0. running mean: 4.03010593939562\n",
      "resetting env. episode reward total was -2.0. running mean: 3.9698048800016634\n",
      "resetting env. episode reward total was 12.0. running mean: 4.050106831201647\n",
      "resetting env. episode reward total was -5.0. running mean: 3.9596057628896304\n",
      "resetting env. episode reward total was 7.0. running mean: 3.990009705260734\n",
      "resetting env. episode reward total was -3.0. running mean: 3.9201096082081266\n",
      "resetting env. episode reward total was 2.0. running mean: 3.9009085121260454\n",
      "resetting env. episode reward total was -3.0. running mean: 3.8318994270047853\n",
      "resetting env. episode reward total was -4.0. running mean: 3.7535804327347373\n",
      "resetting env. episode reward total was -1.0. running mean: 3.70604462840739\n",
      "resetting env. episode reward total was 17.0. running mean: 3.838984182123316\n",
      "resetting env. episode reward total was -8.0. running mean: 3.7205943403020827\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6933883968990617\n",
      "resetting env. episode reward total was 7.0. running mean: 3.726454512930071\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6791899678007702\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7023980681227626\n",
      "resetting env. episode reward total was 3.0. running mean: 3.6953740874415346\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7084203465671193\n",
      "resetting env. episode reward total was 3.0. running mean: 3.701336143101448\n",
      "resetting env. episode reward total was 3.0. running mean: 3.6943227816704334\n",
      "resetting env. episode reward total was 11.0. running mean: 3.7673795538537287\n",
      "resetting env. episode reward total was -7.0. running mean: 3.6597057583151917\n",
      "resetting env. episode reward total was -3.0. running mean: 3.59310870073204\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5771776137247193\n",
      "resetting env. episode reward total was -4.0. running mean: 3.501405837587472\n",
      "resetting env. episode reward total was -9.0. running mean: 3.3763917792115974\n",
      "resetting env. episode reward total was -2.0. running mean: 3.3226278614194813\n",
      "resetting env. episode reward total was 7.0. running mean: 3.3594015828052863\n",
      "resetting env. episode reward total was 4.0. running mean: 3.3658075669772334\n",
      "resetting env. episode reward total was 6.0. running mean: 3.3921494913074612\n",
      "resetting env. episode reward total was -4.0. running mean: 3.3182279963943864\n",
      "resetting env. episode reward total was -3.0. running mean: 3.2550457164304425\n",
      "resetting env. episode reward total was 12.0. running mean: 3.3424952592661383\n",
      "resetting env. episode reward total was 5.0. running mean: 3.359070306673477\n",
      "resetting env. episode reward total was -1.0. running mean: 3.315479603606742\n",
      "resetting env. episode reward total was 5.0. running mean: 3.3323248075706746\n",
      "resetting env. episode reward total was 13.0. running mean: 3.4290015594949677\n",
      "resetting env. episode reward total was 4.0. running mean: 3.434711543900018\n",
      "resetting env. episode reward total was 3.0. running mean: 3.4303644284610177\n",
      "resetting env. episode reward total was -14.0. running mean: 3.2560607841764075\n",
      "resetting env. episode reward total was -5.0. running mean: 3.1735001763346435\n",
      "resetting env. episode reward total was 2.0. running mean: 3.161765174571297\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1701475228255838\n",
      "resetting env. episode reward total was 4.0. running mean: 3.178446047597328\n",
      "resetting env. episode reward total was 6.0. running mean: 3.2066615871213546\n",
      "resetting env. episode reward total was 12.0. running mean: 3.2945949712501412\n",
      "resetting env. episode reward total was -7.0. running mean: 3.19164902153764\n",
      "resetting env. episode reward total was 1.0. running mean: 3.1697325313222633\n",
      "resetting env. episode reward total was -12.0. running mean: 3.0180352060090407\n",
      "resetting env. episode reward total was 1.0. running mean: 2.99785485394895\n",
      "resetting env. episode reward total was 3.0. running mean: 2.99787630540946\n",
      "resetting env. episode reward total was 2.0. running mean: 2.9878975423553658\n",
      "resetting env. episode reward total was 12.0. running mean: 3.0780185669318123\n",
      "resetting env. episode reward total was -8.0. running mean: 2.967238381262494\n",
      "resetting env. episode reward total was -1.0. running mean: 2.9275659974498693\n",
      "resetting env. episode reward total was -5.0. running mean: 2.8482903374753707\n",
      "resetting env. episode reward total was 12.0. running mean: 2.9398074341006173\n",
      "resetting env. episode reward total was -9.0. running mean: 2.820409359759611\n",
      "resetting env. episode reward total was -5.0. running mean: 2.7422052661620153\n",
      "resetting env. episode reward total was -13.0. running mean: 2.5847832135003954\n",
      "resetting env. episode reward total was -15.0. running mean: 2.4089353813653913\n",
      "resetting env. episode reward total was 2.0. running mean: 2.4048460275517374\n",
      "resetting env. episode reward total was -12.0. running mean: 2.26079756727622\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2281895916034578\n",
      "resetting env. episode reward total was -9.0. running mean: 2.115907695687423\n",
      "resetting env. episode reward total was 2.0. running mean: 2.114748618730549\n",
      "resetting env. episode reward total was 5.0. running mean: 2.1436011325432434\n",
      "resetting env. episode reward total was -2.0. running mean: 2.1021651212178107\n",
      "resetting env. episode reward total was -16.0. running mean: 1.9211434700056327\n",
      "resetting env. episode reward total was 12.0. running mean: 2.0219320353055763\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9617127149525206\n",
      "resetting env. episode reward total was 7.0. running mean: 2.0120955878029956\n",
      "resetting env. episode reward total was 12.0. running mean: 2.1119746319249657\n",
      "resetting env. episode reward total was -1.0. running mean: 2.0808548856057163\n",
      "resetting env. episode reward total was -1.0. running mean: 2.0500463367496593\n",
      "resetting env. episode reward total was -9.0. running mean: 1.9395458733821627\n",
      "resetting env. episode reward total was -1.0. running mean: 1.910150414648341\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9310489105018576\n",
      "resetting env. episode reward total was -1.0. running mean: 1.901738421396839\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9527210371828705\n",
      "resetting env. episode reward total was 7.0. running mean: 2.003193826811042\n",
      "resetting env. episode reward total was 9.0. running mean: 2.0731618885429315\n",
      "resetting env. episode reward total was 11.0. running mean: 2.162430269657502\n",
      "resetting env. episode reward total was 6.0. running mean: 2.2008059669609272\n",
      "resetting env. episode reward total was 11.0. running mean: 2.288797907291318\n",
      "resetting env. episode reward total was -2.0. running mean: 2.2459099282184045\n",
      "resetting env. episode reward total was -3.0. running mean: 2.1934508289362205\n",
      "resetting env. episode reward total was 14.0. running mean: 2.3115163206468585\n",
      "resetting env. episode reward total was -6.0. running mean: 2.22840115744039\n",
      "resetting env. episode reward total was 3.0. running mean: 2.2361171458659856\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2837559744073257\n",
      "resetting env. episode reward total was 17.0. running mean: 2.4309184146632523\n",
      "resetting env. episode reward total was 7.0. running mean: 2.4766092305166194\n",
      "resetting env. episode reward total was 1.0. running mean: 2.461843138211453\n",
      "resetting env. episode reward total was 6.0. running mean: 2.4972247068293383\n",
      "resetting env. episode reward total was -4.0. running mean: 2.432252459761045\n",
      "resetting env. episode reward total was -13.0. running mean: 2.2779299351634346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: 2.1751506358118\n",
      "resetting env. episode reward total was -5.0. running mean: 2.103399129453682\n",
      "resetting env. episode reward total was -8.0. running mean: 2.002365138159145\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9223414867775537\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8831180719097782\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9242868911906805\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9450440222787737\n",
      "resetting env. episode reward total was -6.0. running mean: 1.865593582055986\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9169376462354262\n",
      "resetting env. episode reward total was -3.0. running mean: 1.867768269773072\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8290905870753411\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8007996812045877\n",
      "resetting env. episode reward total was -7.0. running mean: 1.7127916843925417\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6056637675486163\n",
      "resetting env. episode reward total was -1.0. running mean: 1.57960712987313\n",
      "resetting env. episode reward total was -9.0. running mean: 1.4738110585743986\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5390729479886547\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4736822185087681\n",
      "resetting env. episode reward total was -6.0. running mean: 1.3989453963236804\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3949559423604436\n",
      "resetting env. episode reward total was -3.0. running mean: 1.351006382936839\n",
      "resetting env. episode reward total was -4.0. running mean: 1.2974963191074707\n",
      "resetting env. episode reward total was -14.0. running mean: 1.144521355916396\n",
      "resetting env. episode reward total was 9.0. running mean: 1.223076142357232\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2508453809336597\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2783369271243232\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2155535578530798\n",
      "resetting env. episode reward total was -6.0. running mean: 1.143398022274549\n",
      "resetting env. episode reward total was -11.0. running mean: 1.0219640420518035\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9617444016312853\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9821269576149725\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9823056880388228\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8824826311584346\n",
      "resetting env. episode reward total was -10.0. running mean: 0.7736578048468503\n",
      "resetting env. episode reward total was 9.0. running mean: 0.8559212267983818\n",
      "resetting env. episode reward total was -8.0. running mean: 0.767362014530398\n",
      "resetting env. episode reward total was -7.0. running mean: 0.689688394385094\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6527915104412431\n",
      "resetting env. episode reward total was 14.0. running mean: 0.7862635953368307\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8584009593834623\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8898169497896277\n",
      "resetting env. episode reward total was -9.0. running mean: 0.7909187802917315\n",
      "resetting env. episode reward total was 7.0. running mean: 0.8530095924888141\n",
      "resetting env. episode reward total was 6.0. running mean: 0.904479496563926\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9154347015982868\n",
      "resetting env. episode reward total was 5.0. running mean: 0.956280354582304\n",
      "resetting env. episode reward total was -7.0. running mean: 0.8767175510364809\n",
      "resetting env. episode reward total was -13.0. running mean: 0.7379503755261161\n",
      "resetting env. episode reward total was 12.0. running mean: 0.8505708717708549\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8320651630531464\n",
      "resetting env. episode reward total was -8.0. running mean: 0.743744511422615\n",
      "resetting env. episode reward total was 2.0. running mean: 0.7563070663083888\n",
      "resetting env. episode reward total was -11.0. running mean: 0.6387439956453049\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6723565556888519\n",
      "resetting env. episode reward total was 4.0. running mean: 0.7056329901319633\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7585766602306436\n",
      "resetting env. episode reward total was 10.0. running mean: 0.8509908936283371\n",
      "resetting env. episode reward total was -8.0. running mean: 0.7624809846920538\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7348561748451332\n",
      "resetting env. episode reward total was 11.0. running mean: 0.8375076130966819\n",
      "resetting env. episode reward total was -7.0. running mean: 0.7591325369657151\n",
      "resetting env. episode reward total was -13.0. running mean: 0.621541211596058\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5653257994800974\n",
      "resetting env. episode reward total was -6.0. running mean: 0.49967254148529644\n",
      "resetting env. episode reward total was -7.0. running mean: 0.42467581607044347\n",
      "resetting env. episode reward total was 7.0. running mean: 0.49042905790973906\n",
      "resetting env. episode reward total was -6.0. running mean: 0.42552476733064165\n",
      "resetting env. episode reward total was -7.0. running mean: 0.3512695196573352\n",
      "resetting env. episode reward total was 1.0. running mean: 0.35775682446076185\n",
      "resetting env. episode reward total was 12.0. running mean: 0.4741792562161542\n",
      "resetting env. episode reward total was -8.0. running mean: 0.3894374636539926\n",
      "resetting env. episode reward total was -13.0. running mean: 0.2555430890174527\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2229876581272782\n",
      "resetting env. episode reward total was 4.0. running mean: 0.26075778154600543\n",
      "resetting env. episode reward total was -13.0. running mean: 0.12815020373054536\n",
      "resetting env. episode reward total was -2.0. running mean: 0.1068687016932399\n",
      "resetting env. episode reward total was -5.0. running mean: 0.055800014676307505\n",
      "resetting env. episode reward total was -3.0. running mean: 0.02524201452954443\n",
      "resetting env. episode reward total was 2.0. running mean: 0.04498959438424899\n",
      "resetting env. episode reward total was 15.0. running mean: 0.1945396984404065\n",
      "resetting env. episode reward total was -12.0. running mean: 0.07259430145600243\n",
      "resetting env. episode reward total was -11.0. running mean: -0.0381316415585576\n",
      "resetting env. episode reward total was -11.0. running mean: -0.147750325142972\n",
      "resetting env. episode reward total was 13.0. running mean: -0.016272821891542277\n",
      "resetting env. episode reward total was -14.0. running mean: -0.15611009367262688\n",
      "resetting env. episode reward total was -5.0. running mean: -0.2045489927359006\n",
      "resetting env. episode reward total was 1.0. running mean: -0.1925035028085416\n",
      "resetting env. episode reward total was -11.0. running mean: -0.30057846778045616\n",
      "resetting env. episode reward total was -11.0. running mean: -0.4075726831026516\n",
      "resetting env. episode reward total was -11.0. running mean: -0.5134969562716251\n",
      "resetting env. episode reward total was -12.0. running mean: -0.6283619867089087\n",
      "resetting env. episode reward total was 8.0. running mean: -0.5420783668418196\n",
      "resetting env. episode reward total was -7.0. running mean: -0.6066575831734013\n",
      "resetting env. episode reward total was -11.0. running mean: -0.7105910073416674\n",
      "resetting env. episode reward total was -13.0. running mean: -0.8334850972682507\n",
      "resetting env. episode reward total was -13.0. running mean: -0.9551502462955682\n",
      "resetting env. episode reward total was -9.0. running mean: -1.0355987438326126\n",
      "resetting env. episode reward total was 6.0. running mean: -0.9652427563942865\n",
      "resetting env. episode reward total was 15.0. running mean: -0.8055903288303435\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8575344255420401\n",
      "resetting env. episode reward total was -11.0. running mean: -0.9589590812866197\n",
      "resetting env. episode reward total was 1.0. running mean: -0.9393694904737534\n",
      "resetting env. episode reward total was -15.0. running mean: -1.079975795569016\n",
      "resetting env. episode reward total was -9.0. running mean: -1.1591760376133258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -9.0. running mean: -1.2375842772371926\n",
      "resetting env. episode reward total was 6.0. running mean: -1.1652084344648206\n",
      "resetting env. episode reward total was -7.0. running mean: -1.2235563501201725\n",
      "resetting env. episode reward total was 5.0. running mean: -1.1613207866189708\n",
      "resetting env. episode reward total was -4.0. running mean: -1.189707578752781\n",
      "resetting env. episode reward total was -15.0. running mean: -1.3278105029652532\n",
      "resetting env. episode reward total was -10.0. running mean: -1.4145323979356006\n",
      "resetting env. episode reward total was 7.0. running mean: -1.3303870739562444\n",
      "resetting env. episode reward total was -1.0. running mean: -1.327083203216682\n",
      "resetting env. episode reward total was 5.0. running mean: -1.263812371184515\n",
      "resetting env. episode reward total was 2.0. running mean: -1.23117424747267\n",
      "resetting env. episode reward total was -2.0. running mean: -1.2388625049979431\n",
      "resetting env. episode reward total was -2.0. running mean: -1.2464738799479638\n",
      "resetting env. episode reward total was -9.0. running mean: -1.3240091411484842\n",
      "resetting env. episode reward total was -13.0. running mean: -1.4407690497369994\n",
      "resetting env. episode reward total was -8.0. running mean: -1.5063613592396294\n",
      "resetting env. episode reward total was 1.0. running mean: -1.4812977456472332\n",
      "resetting env. episode reward total was -3.0. running mean: -1.496484768190761\n",
      "resetting env. episode reward total was -5.0. running mean: -1.5315199205088534\n",
      "resetting env. episode reward total was 4.0. running mean: -1.4762047213037648\n",
      "resetting env. episode reward total was -4.0. running mean: -1.5014426740907272\n",
      "resetting env. episode reward total was 5.0. running mean: -1.4364282473498198\n",
      "resetting env. episode reward total was -11.0. running mean: -1.5320639648763217\n",
      "resetting env. episode reward total was 8.0. running mean: -1.4367433252275583\n",
      "resetting env. episode reward total was -9.0. running mean: -1.5123758919752828\n",
      "resetting env. episode reward total was 7.0. running mean: -1.42725213305553\n",
      "resetting env. episode reward total was 4.0. running mean: -1.3729796117249746\n",
      "resetting env. episode reward total was -8.0. running mean: -1.439249815607725\n",
      "resetting env. episode reward total was -3.0. running mean: -1.4548573174516477\n",
      "resetting env. episode reward total was -4.0. running mean: -1.4803087442771312\n",
      "resetting env. episode reward total was -7.0. running mean: -1.53550565683436\n",
      "resetting env. episode reward total was 7.0. running mean: -1.4501506002660163\n",
      "resetting env. episode reward total was 5.0. running mean: -1.3856490942633561\n",
      "resetting env. episode reward total was -7.0. running mean: -1.4417926033207227\n",
      "resetting env. episode reward total was 8.0. running mean: -1.3473746772875155\n",
      "resetting env. episode reward total was 1.0. running mean: -1.3239009305146403\n",
      "resetting env. episode reward total was -3.0. running mean: -1.340661921209494\n",
      "resetting env. episode reward total was 17.0. running mean: -1.157255301997399\n",
      "resetting env. episode reward total was 1.0. running mean: -1.135682748977425\n",
      "resetting env. episode reward total was -3.0. running mean: -1.154325921487651\n",
      "resetting env. episode reward total was -1.0. running mean: -1.1527826622727744\n",
      "resetting env. episode reward total was 3.0. running mean: -1.1112548356500467\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1301422872935463\n",
      "resetting env. episode reward total was 11.0. running mean: -1.0088408644206106\n",
      "resetting env. episode reward total was 11.0. running mean: -0.8887524557764045\n",
      "resetting env. episode reward total was -6.0. running mean: -0.9398649312186405\n",
      "resetting env. episode reward total was 8.0. running mean: -0.8504662819064541\n",
      "resetting env. episode reward total was 3.0. running mean: -0.8119616190873895\n",
      "resetting env. episode reward total was -7.0. running mean: -0.8738420028965157\n",
      "resetting env. episode reward total was 1.0. running mean: -0.8551035828675505\n",
      "resetting env. episode reward total was 8.0. running mean: -0.766552547038875\n",
      "resetting env. episode reward total was 5.0. running mean: -0.7088870215684862\n",
      "resetting env. episode reward total was 3.0. running mean: -0.6717981513528013\n",
      "resetting env. episode reward total was 1.0. running mean: -0.6550801698392733\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7185293681408806\n",
      "resetting env. episode reward total was 12.0. running mean: -0.5913440744594718\n",
      "resetting env. episode reward total was -9.0. running mean: -0.675430633714877\n",
      "resetting env. episode reward total was -5.0. running mean: -0.7186763273777282\n",
      "resetting env. episode reward total was 5.0. running mean: -0.6614895641039509\n",
      "resetting env. episode reward total was -6.0. running mean: -0.7148746684629113\n",
      "resetting env. episode reward total was 3.0. running mean: -0.6777259217782821\n",
      "resetting env. episode reward total was 2.0. running mean: -0.6509486625604992\n",
      "resetting env. episode reward total was -2.0. running mean: -0.6644391759348942\n",
      "resetting env. episode reward total was 6.0. running mean: -0.5977947841755453\n",
      "resetting env. episode reward total was 6.0. running mean: -0.5318168363337898\n",
      "resetting env. episode reward total was -3.0. running mean: -0.556498667970452\n",
      "resetting env. episode reward total was -9.0. running mean: -0.6409336812907475\n",
      "resetting env. episode reward total was -13.0. running mean: -0.76452434447784\n",
      "resetting env. episode reward total was 10.0. running mean: -0.6568791010330616\n",
      "resetting env. episode reward total was -4.0. running mean: -0.690310310022731\n",
      "resetting env. episode reward total was -3.0. running mean: -0.7134072069225037\n",
      "resetting env. episode reward total was -8.0. running mean: -0.7862731348532787\n",
      "resetting env. episode reward total was 3.0. running mean: -0.7484104035047459\n",
      "resetting env. episode reward total was 3.0. running mean: -0.7109262994696983\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7738170364750014\n",
      "resetting env. episode reward total was 2.0. running mean: -0.7460788661102514\n",
      "resetting env. episode reward total was -7.0. running mean: -0.8086180774491489\n",
      "resetting env. episode reward total was 6.0. running mean: -0.7405318966746575\n",
      "resetting env. episode reward total was -13.0. running mean: -0.8631265777079109\n",
      "resetting env. episode reward total was -11.0. running mean: -0.9644953119308318\n",
      "resetting env. episode reward total was 7.0. running mean: -0.8848503588115235\n",
      "resetting env. episode reward total was -3.0. running mean: -0.9060018552234083\n",
      "resetting env. episode reward total was 8.0. running mean: -0.8169418366711743\n",
      "resetting env. episode reward total was -9.0. running mean: -0.8987724183044625\n",
      "resetting env. episode reward total was -8.0. running mean: -0.9697846941214179\n",
      "resetting env. episode reward total was -7.0. running mean: -1.0300868471802036\n",
      "resetting env. episode reward total was -5.0. running mean: -1.0697859787084016\n",
      "resetting env. episode reward total was 10.0. running mean: -0.9590881189213177\n",
      "resetting env. episode reward total was 6.0. running mean: -0.8894972377321047\n",
      "resetting env. episode reward total was 1.0. running mean: -0.8706022653547836\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8718962427012358\n",
      "resetting env. episode reward total was 3.0. running mean: -0.8331772802742234\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8548455074714812\n",
      "resetting env. episode reward total was -14.0. running mean: -0.9862970523967665\n",
      "resetting env. episode reward total was -11.0. running mean: -1.0864340818727989\n",
      "resetting env. episode reward total was -9.0. running mean: -1.165569741054071\n",
      "resetting env. episode reward total was 5.0. running mean: -1.1039140436435304\n",
      "resetting env. episode reward total was -12.0. running mean: -1.2128749032070951\n",
      "resetting env. episode reward total was 7.0. running mean: -1.130746154175024\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1494386926332738\n",
      "resetting env. episode reward total was 2.0. running mean: -1.1179443057069411\n",
      "resetting env. episode reward total was -5.0. running mean: -1.1567648626498717\n",
      "resetting env. episode reward total was -15.0. running mean: -1.295197214023373\n",
      "resetting env. episode reward total was -5.0. running mean: -1.3322452418831392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -12.0. running mean: -1.438922789464308\n",
      "resetting env. episode reward total was -7.0. running mean: -1.4945335615696649\n",
      "resetting env. episode reward total was -13.0. running mean: -1.6095882259539684\n",
      "resetting env. episode reward total was -7.0. running mean: -1.6634923436944289\n",
      "resetting env. episode reward total was 11.0. running mean: -1.5368574202574845\n",
      "resetting env. episode reward total was 5.0. running mean: -1.4714888460549096\n",
      "resetting env. episode reward total was -11.0. running mean: -1.5667739575943607\n",
      "resetting env. episode reward total was -5.0. running mean: -1.601106218018417\n",
      "resetting env. episode reward total was -11.0. running mean: -1.695095155838233\n",
      "resetting env. episode reward total was 8.0. running mean: -1.5981442042798506\n",
      "resetting env. episode reward total was 2.0. running mean: -1.562162762237052\n",
      "resetting env. episode reward total was -8.0. running mean: -1.6265411346146814\n",
      "resetting env. episode reward total was 7.0. running mean: -1.5402757232685345\n",
      "resetting env. episode reward total was -4.0. running mean: -1.5648729660358491\n",
      "resetting env. episode reward total was -11.0. running mean: -1.6592242363754908\n",
      "resetting env. episode reward total was -6.0. running mean: -1.7026319940117358\n",
      "resetting env. episode reward total was -7.0. running mean: -1.7556056740716186\n",
      "resetting env. episode reward total was 5.0. running mean: -1.6880496173309023\n",
      "resetting env. episode reward total was -11.0. running mean: -1.7811691211575933\n",
      "resetting env. episode reward total was -13.0. running mean: -1.8933574299460174\n",
      "resetting env. episode reward total was -8.0. running mean: -1.9544238556465572\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9048796170900915\n",
      "resetting env. episode reward total was -11.0. running mean: -1.9958308209191906\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9858725127099988\n",
      "resetting env. episode reward total was -9.0. running mean: -2.0560137875828985\n",
      "resetting env. episode reward total was 6.0. running mean: -1.9754536497070694\n",
      "resetting env. episode reward total was -11.0. running mean: -2.0656991132099987\n",
      "resetting env. episode reward total was 4.0. running mean: -2.0050421220778984\n",
      "resetting env. episode reward total was -7.0. running mean: -2.0549917008571192\n",
      "resetting env. episode reward total was -1.0. running mean: -2.044441783848548\n",
      "resetting env. episode reward total was -5.0. running mean: -2.073997366010062\n",
      "resetting env. episode reward total was -3.0. running mean: -2.083257392349961\n",
      "resetting env. episode reward total was -7.0. running mean: -2.132424818426461\n",
      "resetting env. episode reward total was -5.0. running mean: -2.1611005702421964\n",
      "resetting env. episode reward total was -10.0. running mean: -2.2394895645397743\n",
      "resetting env. episode reward total was -3.0. running mean: -2.2470946688943765\n",
      "resetting env. episode reward total was 8.0. running mean: -2.1446237222054325\n",
      "resetting env. episode reward total was 2.0. running mean: -2.103177484983378\n",
      "resetting env. episode reward total was 5.0. running mean: -2.0321457101335443\n",
      "resetting env. episode reward total was -8.0. running mean: -2.091824253032209\n",
      "resetting env. episode reward total was -9.0. running mean: -2.1609060105018867\n",
      "resetting env. episode reward total was -8.0. running mean: -2.219296950396868\n",
      "resetting env. episode reward total was 1.0. running mean: -2.1871039808928994\n",
      "resetting env. episode reward total was 4.0. running mean: -2.1252329410839703\n",
      "resetting env. episode reward total was -1.0. running mean: -2.1139806116731306\n",
      "resetting env. episode reward total was -8.0. running mean: -2.1728408055563992\n",
      "resetting env. episode reward total was -2.0. running mean: -2.1711123975008353\n",
      "resetting env. episode reward total was -16.0. running mean: -2.309401273525827\n",
      "resetting env. episode reward total was 8.0. running mean: -2.206307260790569\n",
      "resetting env. episode reward total was -5.0. running mean: -2.234244188182663\n",
      "resetting env. episode reward total was -1.0. running mean: -2.221901746300836\n",
      "resetting env. episode reward total was -3.0. running mean: -2.2296827288378274\n",
      "resetting env. episode reward total was 1.0. running mean: -2.1973859015494495\n",
      "resetting env. episode reward total was -10.0. running mean: -2.2754120425339552\n",
      "resetting env. episode reward total was -9.0. running mean: -2.3426579221086157\n",
      "resetting env. episode reward total was -9.0. running mean: -2.409231342887529\n",
      "resetting env. episode reward total was -9.0. running mean: -2.4751390294586537\n",
      "resetting env. episode reward total was -5.0. running mean: -2.500387639164067\n",
      "resetting env. episode reward total was -2.0. running mean: -2.4953837627724265\n",
      "resetting env. episode reward total was 2.0. running mean: -2.4504299251447024\n",
      "resetting env. episode reward total was -11.0. running mean: -2.535925625893255\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5605663696343224\n",
      "resetting env. episode reward total was -6.0. running mean: -2.594960705937979\n",
      "resetting env. episode reward total was 2.0. running mean: -2.5490110988785992\n",
      "resetting env. episode reward total was -8.0. running mean: -2.603520987889813\n",
      "resetting env. episode reward total was -7.0. running mean: -2.647485778010915\n",
      "resetting env. episode reward total was -6.0. running mean: -2.681010920230806\n",
      "resetting env. episode reward total was -13.0. running mean: -2.784200811028498\n",
      "resetting env. episode reward total was -8.0. running mean: -2.836358802918213\n",
      "resetting env. episode reward total was -9.0. running mean: -2.8979952148890304\n",
      "resetting env. episode reward total was 1.0. running mean: -2.85901526274014\n",
      "resetting env. episode reward total was 12.0. running mean: -2.710425110112739\n",
      "resetting env. episode reward total was 5.0. running mean: -2.6333208590116115\n",
      "resetting env. episode reward total was -3.0. running mean: -2.6369876504214953\n",
      "resetting env. episode reward total was -7.0. running mean: -2.6806177739172803\n",
      "resetting env. episode reward total was -11.0. running mean: -2.7638115961781073\n",
      "resetting env. episode reward total was -3.0. running mean: -2.766173480216326\n",
      "resetting env. episode reward total was -7.0. running mean: -2.8085117454141626\n",
      "resetting env. episode reward total was 3.0. running mean: -2.7504266279600214\n",
      "resetting env. episode reward total was -12.0. running mean: -2.8429223616804213\n",
      "resetting env. episode reward total was 4.0. running mean: -2.774493138063617\n",
      "resetting env. episode reward total was -8.0. running mean: -2.8267482066829808\n",
      "resetting env. episode reward total was -5.0. running mean: -2.8484807246161505\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8499959173699887\n",
      "resetting env. episode reward total was -2.0. running mean: -2.8414959581962886\n",
      "resetting env. episode reward total was 5.0. running mean: -2.763080998614326\n",
      "resetting env. episode reward total was -3.0. running mean: -2.7654501886281824\n",
      "resetting env. episode reward total was 3.0. running mean: -2.7077956867419006\n",
      "resetting env. episode reward total was -9.0. running mean: -2.7707177298744816\n",
      "resetting env. episode reward total was -1.0. running mean: -2.7530105525757365\n",
      "resetting env. episode reward total was -5.0. running mean: -2.7754804470499788\n",
      "resetting env. episode reward total was 1.0. running mean: -2.737725642579479\n",
      "resetting env. episode reward total was -2.0. running mean: -2.7303483861536844\n",
      "resetting env. episode reward total was -4.0. running mean: -2.7430449022921475\n",
      "resetting env. episode reward total was -7.0. running mean: -2.785614453269226\n",
      "resetting env. episode reward total was 2.0. running mean: -2.7377583087365336\n",
      "resetting env. episode reward total was -11.0. running mean: -2.820380725649168\n",
      "resetting env. episode reward total was -9.0. running mean: -2.882176918392676\n",
      "resetting env. episode reward total was -9.0. running mean: -2.943355149208749\n",
      "resetting env. episode reward total was -9.0. running mean: -3.003921597716661\n",
      "resetting env. episode reward total was -1.0. running mean: -2.983882381739494\n",
      "resetting env. episode reward total was -7.0. running mean: -3.024043557922099\n",
      "resetting env. episode reward total was -16.0. running mean: -3.153803122342878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -17.0. running mean: -3.292265091119449\n",
      "resetting env. episode reward total was -1.0. running mean: -3.2693424402082543\n",
      "resetting env. episode reward total was 4.0. running mean: -3.196649015806172\n",
      "resetting env. episode reward total was -9.0. running mean: -3.25468252564811\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2921357003916283\n",
      "resetting env. episode reward total was -4.0. running mean: -3.299214343387712\n",
      "resetting env. episode reward total was -2.0. running mean: -3.286222199953835\n",
      "resetting env. episode reward total was -15.0. running mean: -3.4033599779542962\n",
      "resetting env. episode reward total was -7.0. running mean: -3.439326378174753\n",
      "resetting env. episode reward total was 1.0. running mean: -3.3949331143930057\n",
      "resetting env. episode reward total was -4.0. running mean: -3.4009837832490755\n",
      "resetting env. episode reward total was -1.0. running mean: -3.3769739454165846\n",
      "resetting env. episode reward total was -8.0. running mean: -3.423204205962419\n",
      "resetting env. episode reward total was -17.0. running mean: -3.5589721639027947\n",
      "resetting env. episode reward total was 7.0. running mean: -3.453382442263767\n",
      "resetting env. episode reward total was 3.0. running mean: -3.3888486178411292\n",
      "resetting env. episode reward total was -11.0. running mean: -3.4649601316627177\n",
      "resetting env. episode reward total was -4.0. running mean: -3.4703105303460906\n",
      "resetting env. episode reward total was -13.0. running mean: -3.5656074250426295\n",
      "resetting env. episode reward total was -6.0. running mean: -3.5899513507922034\n",
      "resetting env. episode reward total was -4.0. running mean: -3.5940518372842813\n",
      "resetting env. episode reward total was -5.0. running mean: -3.608111318911438\n",
      "resetting env. episode reward total was -1.0. running mean: -3.5820302057223237\n",
      "resetting env. episode reward total was 10.0. running mean: -3.4462099036651\n",
      "resetting env. episode reward total was -6.0. running mean: -3.4717478046284493\n",
      "resetting env. episode reward total was -7.0. running mean: -3.5070303265821647\n",
      "resetting env. episode reward total was 3.0. running mean: -3.4419600233163434\n",
      "resetting env. episode reward total was -1.0. running mean: -3.41754042308318\n",
      "resetting env. episode reward total was -6.0. running mean: -3.443365018852348\n",
      "resetting env. episode reward total was -1.0. running mean: -3.4189313686638245\n",
      "resetting env. episode reward total was 3.0. running mean: -3.3547420549771862\n",
      "resetting env. episode reward total was -4.0. running mean: -3.3611946344274144\n",
      "resetting env. episode reward total was -1.0. running mean: -3.33758268808314\n",
      "resetting env. episode reward total was -8.0. running mean: -3.384206861202309\n",
      "resetting env. episode reward total was 6.0. running mean: -3.2903647925902857\n",
      "resetting env. episode reward total was -7.0. running mean: -3.3274611446643827\n",
      "resetting env. episode reward total was 1.0. running mean: -3.284186533217739\n",
      "resetting env. episode reward total was -13.0. running mean: -3.3813446678855614\n",
      "resetting env. episode reward total was -3.0. running mean: -3.3775312212067057\n",
      "resetting env. episode reward total was -3.0. running mean: -3.3737559089946383\n",
      "resetting env. episode reward total was -4.0. running mean: -3.380018349904692\n",
      "resetting env. episode reward total was 6.0. running mean: -3.286218166405645\n",
      "resetting env. episode reward total was 4.0. running mean: -3.2133559847415887\n",
      "resetting env. episode reward total was 6.0. running mean: -3.1212224248941727\n",
      "resetting env. episode reward total was -11.0. running mean: -3.200010200645231\n",
      "resetting env. episode reward total was -3.0. running mean: -3.1980100986387785\n",
      "resetting env. episode reward total was -8.0. running mean: -3.246029997652391\n",
      "resetting env. episode reward total was 8.0. running mean: -3.133569697675867\n",
      "resetting env. episode reward total was -3.0. running mean: -3.132234000699108\n",
      "resetting env. episode reward total was -9.0. running mean: -3.1909116606921164\n",
      "resetting env. episode reward total was -7.0. running mean: -3.229002544085195\n",
      "resetting env. episode reward total was 2.0. running mean: -3.1767125186443432\n",
      "resetting env. episode reward total was 6.0. running mean: -3.0849453934579\n",
      "resetting env. episode reward total was 1.0. running mean: -3.044095939523321\n",
      "resetting env. episode reward total was -1.0. running mean: -3.0236549801280876\n",
      "resetting env. episode reward total was -11.0. running mean: -3.1034184303268066\n",
      "resetting env. episode reward total was -5.0. running mean: -3.1223842460235383\n",
      "resetting env. episode reward total was 6.0. running mean: -3.0311604035633026\n",
      "resetting env. episode reward total was 3.0. running mean: -2.9708487995276696\n",
      "resetting env. episode reward total was -8.0. running mean: -3.0211403115323927\n",
      "resetting env. episode reward total was 10.0. running mean: -2.890928908417069\n",
      "resetting env. episode reward total was -5.0. running mean: -2.9120196193328978\n",
      "resetting env. episode reward total was -7.0. running mean: -2.9528994231395687\n",
      "resetting env. episode reward total was -7.0. running mean: -2.9933704289081726\n",
      "resetting env. episode reward total was -7.0. running mean: -3.0334367246190905\n",
      "resetting env. episode reward total was 3.0. running mean: -2.9731023573728996\n",
      "resetting env. episode reward total was 3.0. running mean: -2.9133713337991707\n",
      "resetting env. episode reward total was 1.0. running mean: -2.8742376204611793\n",
      "resetting env. episode reward total was -8.0. running mean: -2.9254952442565676\n",
      "resetting env. episode reward total was -2.0. running mean: -2.916240291814002\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8970778888958617\n",
      "resetting env. episode reward total was -9.0. running mean: -2.9581071100069027\n",
      "resetting env. episode reward total was -1.0. running mean: -2.9385260389068333\n",
      "resetting env. episode reward total was 2.0. running mean: -2.8891407785177647\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8902493707325867\n",
      "resetting env. episode reward total was -2.0. running mean: -2.881346877025261\n",
      "resetting env. episode reward total was -3.0. running mean: -2.882533408255008\n",
      "resetting env. episode reward total was 6.0. running mean: -2.793708074172458\n",
      "resetting env. episode reward total was -8.0. running mean: -2.8457709934307336\n",
      "resetting env. episode reward total was -1.0. running mean: -2.827313283496426\n",
      "resetting env. episode reward total was 4.0. running mean: -2.7590401506614617\n",
      "resetting env. episode reward total was -11.0. running mean: -2.841449749154847\n",
      "resetting env. episode reward total was -4.0. running mean: -2.8530352516632984\n",
      "resetting env. episode reward total was -10.0. running mean: -2.9245048991466653\n",
      "resetting env. episode reward total was -10.0. running mean: -2.9952598501551986\n",
      "resetting env. episode reward total was -10.0. running mean: -3.0653072516536466\n",
      "resetting env. episode reward total was -4.0. running mean: -3.0746541791371103\n",
      "resetting env. episode reward total was -12.0. running mean: -3.1639076373457393\n",
      "resetting env. episode reward total was -10.0. running mean: -3.232268560972282\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2699458753625588\n",
      "resetting env. episode reward total was 7.0. running mean: -3.167246416608933\n",
      "resetting env. episode reward total was -13.0. running mean: -3.2655739524428435\n",
      "resetting env. episode reward total was -5.0. running mean: -3.282918212918415\n",
      "resetting env. episode reward total was -4.0. running mean: -3.2900890307892308\n",
      "resetting env. episode reward total was -11.0. running mean: -3.367188140481338\n",
      "resetting env. episode reward total was 4.0. running mean: -3.2935162590765246\n",
      "resetting env. episode reward total was 4.0. running mean: -3.220581096485759\n",
      "resetting env. episode reward total was -5.0. running mean: -3.238375285520901\n",
      "resetting env. episode reward total was -6.0. running mean: -3.265991532665692\n",
      "resetting env. episode reward total was -3.0. running mean: -3.263331617339035\n",
      "resetting env. episode reward total was -9.0. running mean: -3.3206983011656446\n",
      "resetting env. episode reward total was -3.0. running mean: -3.317491318153988\n",
      "resetting env. episode reward total was -2.0. running mean: -3.304316404972448\n",
      "resetting env. episode reward total was 6.0. running mean: -3.2112732409227234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -3.249160508513496\n",
      "resetting env. episode reward total was -8.0. running mean: -3.296668903428361\n",
      "resetting env. episode reward total was 6.0. running mean: -3.2037022143940774\n",
      "resetting env. episode reward total was -6.0. running mean: -3.2316651922501367\n",
      "resetting env. episode reward total was -5.0. running mean: -3.249348540327635\n",
      "resetting env. episode reward total was -13.0. running mean: -3.3468550549243585\n",
      "resetting env. episode reward total was -8.0. running mean: -3.393386504375115\n",
      "resetting env. episode reward total was -8.0. running mean: -3.439452639331364\n",
      "resetting env. episode reward total was -2.0. running mean: -3.4250581129380504\n",
      "resetting env. episode reward total was -3.0. running mean: -3.4208075318086695\n",
      "resetting env. episode reward total was -4.0. running mean: -3.4265994564905826\n",
      "resetting env. episode reward total was 2.0. running mean: -3.3723334619256766\n",
      "resetting env. episode reward total was -7.0. running mean: -3.4086101273064195\n",
      "resetting env. episode reward total was 1.0. running mean: -3.3645240260333553\n",
      "resetting env. episode reward total was -3.0. running mean: -3.3608787857730213\n",
      "resetting env. episode reward total was 2.0. running mean: -3.307269997915291\n",
      "resetting env. episode reward total was 8.0. running mean: -3.194197297936138\n",
      "resetting env. episode reward total was -5.0. running mean: -3.2122553249567765\n",
      "resetting env. episode reward total was -11.0. running mean: -3.2901327717072086\n",
      "resetting env. episode reward total was -12.0. running mean: -3.3772314439901367\n",
      "resetting env. episode reward total was 5.0. running mean: -3.2934591295502353\n",
      "resetting env. episode reward total was 3.0. running mean: -3.230524538254733\n",
      "resetting env. episode reward total was 3.0. running mean: -3.168219292872186\n",
      "resetting env. episode reward total was 6.0. running mean: -3.0765370999434642\n",
      "resetting env. episode reward total was -2.0. running mean: -3.0657717289440294\n",
      "resetting env. episode reward total was 2.0. running mean: -3.015114011654589\n",
      "resetting env. episode reward total was -7.0. running mean: -3.054962871538043\n",
      "resetting env. episode reward total was -3.0. running mean: -3.0544132428226622\n",
      "resetting env. episode reward total was 6.0. running mean: -2.9638691103944357\n",
      "resetting env. episode reward total was -6.0. running mean: -2.994230419290491\n",
      "resetting env. episode reward total was -8.0. running mean: -3.0442881150975865\n",
      "resetting env. episode reward total was 2.0. running mean: -2.9938452339466104\n",
      "resetting env. episode reward total was -8.0. running mean: -3.043906781607144\n",
      "resetting env. episode reward total was 7.0. running mean: -2.943467713791073\n",
      "resetting env. episode reward total was 2.0. running mean: -2.894033036653162\n",
      "resetting env. episode reward total was 6.0. running mean: -2.8050927062866307\n",
      "resetting env. episode reward total was -3.0. running mean: -2.807041779223764\n",
      "resetting env. episode reward total was 8.0. running mean: -2.6989713614315263\n",
      "resetting env. episode reward total was 1.0. running mean: -2.6619816478172114\n",
      "resetting env. episode reward total was -4.0. running mean: -2.675361831339039\n",
      "resetting env. episode reward total was 7.0. running mean: -2.5786082130256487\n",
      "resetting env. episode reward total was 12.0. running mean: -2.432822130895392\n",
      "resetting env. episode reward total was 3.0. running mean: -2.3784939095864384\n",
      "resetting env. episode reward total was 1.0. running mean: -2.3447089704905744\n",
      "resetting env. episode reward total was 9.0. running mean: -2.231261880785669\n",
      "resetting env. episode reward total was 2.0. running mean: -2.188949261977812\n",
      "resetting env. episode reward total was 6.0. running mean: -2.1070597693580337\n",
      "resetting env. episode reward total was 3.0. running mean: -2.0559891716644536\n",
      "resetting env. episode reward total was -8.0. running mean: -2.115429279947809\n",
      "resetting env. episode reward total was 2.0. running mean: -2.074274987148331\n",
      "resetting env. episode reward total was 10.0. running mean: -1.9535322372768475\n",
      "resetting env. episode reward total was -5.0. running mean: -1.983996914904079\n",
      "resetting env. episode reward total was -7.0. running mean: -2.034156945755038\n",
      "resetting env. episode reward total was 11.0. running mean: -1.9038153762974874\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9147772225345125\n",
      "resetting env. episode reward total was 3.0. running mean: -1.8656294503091673\n",
      "resetting env. episode reward total was 1.0. running mean: -1.8369731558060756\n",
      "resetting env. episode reward total was 6.0. running mean: -1.7586034242480146\n",
      "resetting env. episode reward total was -6.0. running mean: -1.8010173900055346\n",
      "resetting env. episode reward total was 7.0. running mean: -1.7130072161054792\n",
      "resetting env. episode reward total was -5.0. running mean: -1.7458771439444245\n",
      "resetting env. episode reward total was 3.0. running mean: -1.6984183725049802\n",
      "resetting env. episode reward total was 2.0. running mean: -1.6614341887799304\n",
      "resetting env. episode reward total was -4.0. running mean: -1.6848198468921312\n",
      "resetting env. episode reward total was -7.0. running mean: -1.73797164842321\n",
      "resetting env. episode reward total was 6.0. running mean: -1.6605919319389777\n",
      "resetting env. episode reward total was -13.0. running mean: -1.7739860126195879\n",
      "resetting env. episode reward total was 1.0. running mean: -1.7462461524933919\n",
      "resetting env. episode reward total was -3.0. running mean: -1.758783690968458\n",
      "resetting env. episode reward total was -8.0. running mean: -1.8211958540587734\n",
      "resetting env. episode reward total was -8.0. running mean: -1.8829838955181857\n",
      "resetting env. episode reward total was 10.0. running mean: -1.7641540565630036\n",
      "resetting env. episode reward total was -4.0. running mean: -1.7865125159973736\n",
      "resetting env. episode reward total was -5.0. running mean: -1.8186473908374\n",
      "resetting env. episode reward total was -1.0. running mean: -1.810460916929026\n",
      "resetting env. episode reward total was 6.0. running mean: -1.7323563077597357\n",
      "resetting env. episode reward total was -11.0. running mean: -1.8250327446821384\n",
      "resetting env. episode reward total was 1.0. running mean: -1.796782417235317\n",
      "resetting env. episode reward total was -7.0. running mean: -1.848814593062964\n",
      "resetting env. episode reward total was 7.0. running mean: -1.7603264471323343\n",
      "resetting env. episode reward total was -9.0. running mean: -1.832723182661011\n",
      "resetting env. episode reward total was -1.0. running mean: -1.824395950834401\n",
      "resetting env. episode reward total was -6.0. running mean: -1.866151991326057\n",
      "resetting env. episode reward total was -5.0. running mean: -1.8974904714127965\n",
      "resetting env. episode reward total was -7.0. running mean: -1.9485155666986687\n",
      "resetting env. episode reward total was -9.0. running mean: -2.019030411031682\n",
      "resetting env. episode reward total was 1.0. running mean: -1.988840106921365\n",
      "resetting env. episode reward total was 7.0. running mean: -1.8989517058521512\n",
      "resetting env. episode reward total was -9.0. running mean: -1.9699621887936298\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9602625669056934\n",
      "resetting env. episode reward total was 3.0. running mean: -1.9106599412366365\n",
      "resetting env. episode reward total was 6.0. running mean: -1.83155334182427\n",
      "resetting env. episode reward total was 2.0. running mean: -1.7932378084060272\n",
      "resetting env. episode reward total was 1.0. running mean: -1.7653054303219669\n",
      "resetting env. episode reward total was -7.0. running mean: -1.8176523760187473\n",
      "resetting env. episode reward total was 1.0. running mean: -1.7894758522585599\n",
      "resetting env. episode reward total was 9.0. running mean: -1.681581093735974\n",
      "resetting env. episode reward total was 7.0. running mean: -1.5947652827986143\n",
      "resetting env. episode reward total was 6.0. running mean: -1.5188176299706282\n",
      "resetting env. episode reward total was -2.0. running mean: -1.5236294536709218\n",
      "resetting env. episode reward total was 8.0. running mean: -1.4283931591342125\n",
      "resetting env. episode reward total was 7.0. running mean: -1.3441092275428703\n",
      "resetting env. episode reward total was 2.0. running mean: -1.3106681352674416\n",
      "resetting env. episode reward total was 1.0. running mean: -1.2875614539147673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: -1.2046858393756195\n",
      "resetting env. episode reward total was 8.0. running mean: -1.112638980981863\n",
      "resetting env. episode reward total was -9.0. running mean: -1.1915125911720446\n",
      "resetting env. episode reward total was 7.0. running mean: -1.109597465260324\n",
      "resetting env. episode reward total was 6.0. running mean: -1.0385014906077208\n",
      "resetting env. episode reward total was 3.0. running mean: -0.9981164757016436\n",
      "resetting env. episode reward total was 11.0. running mean: -0.8781353109446272\n",
      "resetting env. episode reward total was -4.0. running mean: -0.9093539578351809\n",
      "resetting env. episode reward total was -11.0. running mean: -1.010260418256829\n",
      "resetting env. episode reward total was -2.0. running mean: -1.0201578140742609\n",
      "resetting env. episode reward total was 1.0. running mean: -0.9999562359335183\n",
      "resetting env. episode reward total was 12.0. running mean: -0.8699566735741832\n",
      "resetting env. episode reward total was 16.0. running mean: -0.7012571068384413\n",
      "resetting env. episode reward total was -5.0. running mean: -0.744244535770057\n",
      "resetting env. episode reward total was -7.0. running mean: -0.8068020904123565\n",
      "resetting env. episode reward total was 4.0. running mean: -0.7587340695082329\n",
      "resetting env. episode reward total was 3.0. running mean: -0.7211467288131505\n",
      "resetting env. episode reward total was -4.0. running mean: -0.753935261525019\n",
      "resetting env. episode reward total was 8.0. running mean: -0.6663959089097689\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6697319498206712\n",
      "resetting env. episode reward total was 1.0. running mean: -0.6530346303224644\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6565042840192398\n",
      "resetting env. episode reward total was 6.0. running mean: -0.5899392411790474\n",
      "resetting env. episode reward total was -6.0. running mean: -0.644039848767257\n",
      "resetting env. episode reward total was 4.0. running mean: -0.5975994502795844\n",
      "resetting env. episode reward total was -8.0. running mean: -0.6716234557767885\n",
      "resetting env. episode reward total was -2.0. running mean: -0.6849072212190206\n",
      "resetting env. episode reward total was -2.0. running mean: -0.6980581490068304\n",
      "resetting env. episode reward total was -8.0. running mean: -0.771077567516762\n",
      "resetting env. episode reward total was 3.0. running mean: -0.7333667918415944\n",
      "resetting env. episode reward total was -1.0. running mean: -0.7360331239231784\n",
      "resetting env. episode reward total was -1.0. running mean: -0.7386727926839467\n",
      "resetting env. episode reward total was 4.0. running mean: -0.6912860647571072\n",
      "resetting env. episode reward total was -5.0. running mean: -0.7343732041095361\n",
      "resetting env. episode reward total was 1.0. running mean: -0.7170294720684407\n",
      "resetting env. episode reward total was 4.0. running mean: -0.6698591773477562\n",
      "resetting env. episode reward total was -9.0. running mean: -0.7531605855742787\n",
      "resetting env. episode reward total was -3.0. running mean: -0.775628979718536\n",
      "resetting env. episode reward total was -8.0. running mean: -0.8478726899213506\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8193939630221371\n",
      "resetting env. episode reward total was -8.0. running mean: -0.8912000233919156\n",
      "resetting env. episode reward total was -5.0. running mean: -0.9322880231579965\n",
      "resetting env. episode reward total was 8.0. running mean: -0.8429651429264166\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8445354914971523\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8860901365821808\n",
      "resetting env. episode reward total was 7.0. running mean: -0.807229235216359\n",
      "resetting env. episode reward total was 2.0. running mean: -0.7791569428641955\n",
      "resetting env. episode reward total was 8.0. running mean: -0.6913653734355535\n",
      "resetting env. episode reward total was -10.0. running mean: -0.7844517197011979\n",
      "resetting env. episode reward total was 5.0. running mean: -0.7266072025041859\n",
      "resetting env. episode reward total was 10.0. running mean: -0.6193411304791441\n",
      "resetting env. episode reward total was 2.0. running mean: -0.5931477191743526\n",
      "resetting env. episode reward total was 5.0. running mean: -0.537216241982609\n",
      "resetting env. episode reward total was 2.0. running mean: -0.5118440795627829\n",
      "resetting env. episode reward total was -7.0. running mean: -0.5767256387671551\n",
      "resetting env. episode reward total was 4.0. running mean: -0.5309583823794836\n",
      "resetting env. episode reward total was 12.0. running mean: -0.4056487985556887\n",
      "resetting env. episode reward total was 5.0. running mean: -0.3515923105701318\n",
      "resetting env. episode reward total was 8.0. running mean: -0.26807638746443047\n",
      "resetting env. episode reward total was 8.0. running mean: -0.18539562358978612\n",
      "resetting env. episode reward total was 17.0. running mean: -0.013541667353888232\n",
      "resetting env. episode reward total was 3.0. running mean: 0.01659374931965065\n",
      "resetting env. episode reward total was -4.0. running mean: -0.023572188173545856\n",
      "resetting env. episode reward total was 2.0. running mean: -0.003336466291810395\n",
      "resetting env. episode reward total was 7.0. running mean: 0.06669689837110772\n",
      "resetting env. episode reward total was 10.0. running mean: 0.16602992938739664\n",
      "resetting env. episode reward total was -2.0. running mean: 0.1443696300935227\n",
      "resetting env. episode reward total was 9.0. running mean: 0.23292593379258747\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2005966744546616\n",
      "resetting env. episode reward total was -3.0. running mean: 0.16859070771011497\n",
      "resetting env. episode reward total was 11.0. running mean: 0.2769048006330138\n",
      "resetting env. episode reward total was 1.0. running mean: 0.28413575262668367\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3312943951004168\n",
      "resetting env. episode reward total was -3.0. running mean: 0.29798145114941266\n",
      "resetting env. episode reward total was 9.0. running mean: 0.38500163663791853\n",
      "resetting env. episode reward total was -2.0. running mean: 0.3611516202715393\n",
      "resetting env. episode reward total was -9.0. running mean: 0.2675401040688239\n",
      "resetting env. episode reward total was -7.0. running mean: 0.19486470302813563\n",
      "resetting env. episode reward total was 9.0. running mean: 0.2829160559978543\n",
      "resetting env. episode reward total was -1.0. running mean: 0.27008689543787573\n",
      "resetting env. episode reward total was 6.0. running mean: 0.32738602648349696\n",
      "resetting env. episode reward total was 6.0. running mean: 0.384112166218662\n",
      "resetting env. episode reward total was 1.0. running mean: 0.3902710445564754\n",
      "resetting env. episode reward total was -2.0. running mean: 0.3663683341109106\n",
      "resetting env. episode reward total was 1.0. running mean: 0.37270465076980147\n",
      "resetting env. episode reward total was 10.0. running mean: 0.46897760426210344\n",
      "resetting env. episode reward total was 7.0. running mean: 0.5342878282194824\n",
      "resetting env. episode reward total was 11.0. running mean: 0.6389449499372876\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6825555004379147\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6657299454335355\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6890726459792001\n",
      "resetting env. episode reward total was 3.0. running mean: 0.7121819195194081\n",
      "resetting env. episode reward total was 4.0. running mean: 0.7450601003242141\n",
      "resetting env. episode reward total was -10.0. running mean: 0.637609499320972\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5812334043277623\n",
      "resetting env. episode reward total was 10.0. running mean: 0.6754210702844846\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5986668595816398\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6126801909858234\n",
      "resetting env. episode reward total was 8.0. running mean: 0.6865533890759651\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7296878551852055\n",
      "resetting env. episode reward total was 10.0. running mean: 0.8223909766333535\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8941670668670199\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8352253961983496\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9268731422363661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: 0.8676044108140024\n",
      "resetting env. episode reward total was -8.0. running mean: 0.7789283667058624\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7211390830388037\n",
      "resetting env. episode reward total was 3.0. running mean: 0.7439276922084157\n",
      "resetting env. episode reward total was 12.0. running mean: 0.8564884152863316\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8279235311334683\n",
      "resetting env. episode reward total was 7.0. running mean: 0.8896442958221336\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9507478528639122\n",
      "resetting env. episode reward total was -6.0. running mean: 0.881240374335273\n",
      "resetting env. episode reward total was -4.0. running mean: 0.8324279705919202\n",
      "resetting env. episode reward total was 4.0. running mean: 0.864103690886001\n",
      "resetting env. episode reward total was 9.0. running mean: 0.945462653977141\n",
      "resetting env. episode reward total was -12.0. running mean: 0.8160080274373696\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8678479471629958\n",
      "resetting env. episode reward total was -6.0. running mean: 0.7991694676913659\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8511777730144523\n",
      "resetting env. episode reward total was 13.0. running mean: 0.9726659952843077\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9929393353314647\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8930099419781501\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9340798425583686\n",
      "resetting env. episode reward total was -8.0. running mean: 0.844739044132785\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9262916536914572\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9870287371545425\n",
      "resetting env. episode reward total was 10.0. running mean: 1.0771584497829971\n",
      "resetting env. episode reward total was -3.0. running mean: 1.036386865285167\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0460229966323153\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1055627666659922\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1645071389993322\n",
      "resetting env. episode reward total was 6.0. running mean: 1.212862067609339\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1907334469332456\n",
      "resetting env. episode reward total was -12.0. running mean: 1.0588261124639131\n",
      "resetting env. episode reward total was 3.0. running mean: 1.078237851339274\n",
      "resetting env. episode reward total was 6.0. running mean: 1.1274554728258814\n",
      "resetting env. episode reward total was 1.0. running mean: 1.1261809180976226\n",
      "resetting env. episode reward total was -14.0. running mean: 0.9749191089166463\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0351699178274798\n",
      "resetting env. episode reward total was 11.0. running mean: 1.134818218649205\n",
      "resetting env. episode reward total was 5.0. running mean: 1.173470036462713\n",
      "resetting env. episode reward total was -7.0. running mean: 1.091735336098086\n",
      "resetting env. episode reward total was 2.0. running mean: 1.1008179827371052\n",
      "resetting env. episode reward total was -5.0. running mean: 1.039809802909734\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0594117048806366\n",
      "resetting env. episode reward total was 11.0. running mean: 1.1588175878318303\n",
      "resetting env. episode reward total was 14.0. running mean: 1.2872294119535121\n",
      "resetting env. episode reward total was 12.0. running mean: 1.394357117833977\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4404135466556374\n",
      "resetting env. episode reward total was -5.0. running mean: 1.376009411189081\n",
      "resetting env. episode reward total was 11.0. running mean: 1.4722493170771904\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5375268239064186\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6021515556673545\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6161300401106808\n",
      "resetting env. episode reward total was 1.0. running mean: 1.609968739709574\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6638690523124784\n",
      "resetting env. episode reward total was -8.0. running mean: 1.5672303617893535\n",
      "resetting env. episode reward total was 8.0. running mean: 1.63155805817146\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6752424775897454\n",
      "resetting env. episode reward total was -3.0. running mean: 1.628490052813848\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6522051522857095\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6856831007628525\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7288262697552241\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6215380070576717\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6953226269870951\n",
      "resetting env. episode reward total was 2.0. running mean: 1.698369400717224\n",
      "resetting env. episode reward total was 3.0. running mean: 1.711385706710052\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6842718496429514\n",
      "resetting env. episode reward total was -1.0. running mean: 1.657429131146522\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7208548398350567\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7736462914367062\n",
      "resetting env. episode reward total was -1.0. running mean: 1.7459098285223391\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7084507302371157\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7313662229347446\n",
      "resetting env. episode reward total was 15.0. running mean: 1.864052560705397\n",
      "resetting env. episode reward total was 2.0. running mean: 1.865412035098343\n",
      "resetting env. episode reward total was -9.0. running mean: 1.7567579147473595\n",
      "resetting env. episode reward total was 8.0. running mean: 1.819190335599886\n",
      "resetting env. episode reward total was 3.0. running mean: 1.830998432243887\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8526884479214483\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9541615634422338\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9646199478078115\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9749737483297334\n",
      "resetting env. episode reward total was -3.0. running mean: 1.925224010846436\n",
      "resetting env. episode reward total was 13.0. running mean: 2.0359717707379716\n",
      "resetting env. episode reward total was -11.0. running mean: 1.9056120530305918\n",
      "resetting env. episode reward total was 20.0. running mean: 2.086555932500286\n",
      "resetting env. episode reward total was 7.0. running mean: 2.135690373175283\n",
      "resetting env. episode reward total was 2.0. running mean: 2.13433346944353\n",
      "resetting env. episode reward total was 11.0. running mean: 2.222990134749095\n",
      "resetting env. episode reward total was -7.0. running mean: 2.130760233401604\n",
      "resetting env. episode reward total was 12.0. running mean: 2.2294526310675877\n",
      "resetting env. episode reward total was -2.0. running mean: 2.1871581047569117\n",
      "resetting env. episode reward total was -3.0. running mean: 2.135286523709343\n",
      "resetting env. episode reward total was 8.0. running mean: 2.1939336584722495\n",
      "resetting env. episode reward total was 11.0. running mean: 2.281994321887527\n",
      "resetting env. episode reward total was 10.0. running mean: 2.359174378668652\n",
      "resetting env. episode reward total was -3.0. running mean: 2.3055826348819655\n",
      "resetting env. episode reward total was -7.0. running mean: 2.2125268085331458\n",
      "resetting env. episode reward total was 8.0. running mean: 2.270401540447814\n",
      "resetting env. episode reward total was 11.0. running mean: 2.357697525043336\n",
      "resetting env. episode reward total was 1.0. running mean: 2.344120549792902\n",
      "resetting env. episode reward total was 5.0. running mean: 2.370679344294973\n",
      "resetting env. episode reward total was -7.0. running mean: 2.2769725508520233\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2442028253435033\n",
      "resetting env. episode reward total was 7.0. running mean: 2.291760797090068\n",
      "resetting env. episode reward total was -3.0. running mean: 2.2388431891191676\n",
      "resetting env. episode reward total was 13.0. running mean: 2.346454757227976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 2.4029902096556963\n",
      "resetting env. episode reward total was 5.0. running mean: 2.428960307559139\n",
      "resetting env. episode reward total was -3.0. running mean: 2.374670704483548\n",
      "resetting env. episode reward total was -5.0. running mean: 2.3009239974387126\n",
      "resetting env. episode reward total was -4.0. running mean: 2.2379147574643254\n",
      "resetting env. episode reward total was -5.0. running mean: 2.1655356098896825\n",
      "resetting env. episode reward total was 3.0. running mean: 2.1738802537907853\n",
      "resetting env. episode reward total was -3.0. running mean: 2.122141451252878\n",
      "resetting env. episode reward total was 3.0. running mean: 2.1309200367403487\n",
      "resetting env. episode reward total was 12.0. running mean: 2.229610836372945\n",
      "resetting env. episode reward total was 6.0. running mean: 2.267314728009216\n",
      "resetting env. episode reward total was -3.0. running mean: 2.2146415807291238\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2624951649218326\n",
      "resetting env. episode reward total was 1.0. running mean: 2.249870213272614\n",
      "resetting env. episode reward total was 15.0. running mean: 2.3773715111398874\n",
      "resetting env. episode reward total was 3.0. running mean: 2.3835977960284884\n",
      "resetting env. episode reward total was 17.0. running mean: 2.5297618180682035\n",
      "resetting env. episode reward total was 5.0. running mean: 2.5544641998875215\n",
      "resetting env. episode reward total was 8.0. running mean: 2.608919557888646\n",
      "resetting env. episode reward total was -3.0. running mean: 2.5528303623097597\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5573020586866617\n",
      "resetting env. episode reward total was 5.0. running mean: 2.581729038099795\n",
      "resetting env. episode reward total was -8.0. running mean: 2.475911747718797\n",
      "resetting env. episode reward total was 6.0. running mean: 2.511152630241609\n",
      "resetting env. episode reward total was 11.0. running mean: 2.596041103939193\n",
      "resetting env. episode reward total was -2.0. running mean: 2.550080692899801\n",
      "resetting env. episode reward total was 16.0. running mean: 2.684579885970803\n",
      "resetting env. episode reward total was 13.0. running mean: 2.787734087111095\n",
      "resetting env. episode reward total was 1.0. running mean: 2.769856746239984\n",
      "resetting env. episode reward total was 4.0. running mean: 2.782158178777584\n",
      "resetting env. episode reward total was -3.0. running mean: 2.7243365969898083\n",
      "resetting env. episode reward total was 8.0. running mean: 2.77709323101991\n",
      "resetting env. episode reward total was 9.0. running mean: 2.839322298709711\n",
      "resetting env. episode reward total was 1.0. running mean: 2.8209290757226135\n",
      "resetting env. episode reward total was 2.0. running mean: 2.8127197849653873\n",
      "resetting env. episode reward total was 13.0. running mean: 2.914592587115733\n",
      "resetting env. episode reward total was -9.0. running mean: 2.795446661244576\n",
      "resetting env. episode reward total was -6.0. running mean: 2.70749219463213\n",
      "resetting env. episode reward total was 8.0. running mean: 2.760417272685809\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7628130999589504\n",
      "resetting env. episode reward total was -1.0. running mean: 2.7251849689593612\n",
      "resetting env. episode reward total was 6.0. running mean: 2.757933119269768\n",
      "resetting env. episode reward total was -3.0. running mean: 2.7003537880770705\n",
      "resetting env. episode reward total was 2.0. running mean: 2.6933502501963\n",
      "resetting env. episode reward total was -1.0. running mean: 2.656416747694337\n",
      "resetting env. episode reward total was 7.0. running mean: 2.6998525802173936\n",
      "resetting env. episode reward total was 11.0. running mean: 2.7828540544152194\n",
      "resetting env. episode reward total was -8.0. running mean: 2.6750255138710672\n",
      "resetting env. episode reward total was -2.0. running mean: 2.6282752587323563\n",
      "resetting env. episode reward total was 4.0. running mean: 2.6419925061450327\n",
      "resetting env. episode reward total was 4.0. running mean: 2.6555725810835824\n",
      "resetting env. episode reward total was 8.0. running mean: 2.7090168552727465\n",
      "resetting env. episode reward total was 5.0. running mean: 2.7319266867200187\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7346074198528183\n",
      "resetting env. episode reward total was 3.0. running mean: 2.73726134565429\n",
      "resetting env. episode reward total was -7.0. running mean: 2.639888732197747\n",
      "resetting env. episode reward total was 9.0. running mean: 2.703489844875769\n",
      "resetting env. episode reward total was 11.0. running mean: 2.7864549464270114\n",
      "resetting env. episode reward total was 8.0. running mean: 2.8385903969627413\n",
      "resetting env. episode reward total was 14.0. running mean: 2.950204492993114\n",
      "resetting env. episode reward total was -16.0. running mean: 2.7607024480631828\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7630954235825507\n",
      "resetting env. episode reward total was 13.0. running mean: 2.865464469346725\n",
      "resetting env. episode reward total was 5.0. running mean: 2.886809824653257\n",
      "resetting env. episode reward total was -1.0. running mean: 2.8479417264067246\n",
      "resetting env. episode reward total was 5.0. running mean: 2.869462309142657\n",
      "resetting env. episode reward total was 16.0. running mean: 3.0007676860512307\n",
      "resetting env. episode reward total was 6.0. running mean: 3.0307600091907183\n",
      "resetting env. episode reward total was -1.0. running mean: 2.990452409098811\n",
      "resetting env. episode reward total was 10.0. running mean: 3.060547885007823\n",
      "resetting env. episode reward total was 11.0. running mean: 3.139942406157745\n",
      "resetting env. episode reward total was 12.0. running mean: 3.2285429820961675\n",
      "resetting env. episode reward total was -4.0. running mean: 3.1562575522752057\n",
      "resetting env. episode reward total was -8.0. running mean: 3.0446949767524534\n",
      "resetting env. episode reward total was 7.0. running mean: 3.0842480269849286\n",
      "resetting env. episode reward total was 7.0. running mean: 3.123405546715079\n",
      "resetting env. episode reward total was -1.0. running mean: 3.0821714912479283\n",
      "resetting env. episode reward total was -3.0. running mean: 3.021349776335449\n",
      "resetting env. episode reward total was 2.0. running mean: 3.0111362785720948\n",
      "resetting env. episode reward total was -5.0. running mean: 2.931024915786374\n",
      "resetting env. episode reward total was 3.0. running mean: 2.93171466662851\n",
      "resetting env. episode reward total was 4.0. running mean: 2.942397519962225\n",
      "resetting env. episode reward total was 9.0. running mean: 3.0029735447626025\n",
      "resetting env. episode reward total was 8.0. running mean: 3.0529438093149763\n",
      "resetting env. episode reward total was 4.0. running mean: 3.0624143712218266\n",
      "resetting env. episode reward total was 12.0. running mean: 3.1517902275096086\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1602723252345126\n",
      "resetting env. episode reward total was -1.0. running mean: 3.118669601982168\n",
      "resetting env. episode reward total was -9.0. running mean: 2.9974829059623462\n",
      "resetting env. episode reward total was 4.0. running mean: 3.007508076902723\n",
      "resetting env. episode reward total was 3.0. running mean: 3.0074329961336956\n",
      "resetting env. episode reward total was 9.0. running mean: 3.0673586661723586\n",
      "resetting env. episode reward total was -2.0. running mean: 3.016685079510635\n",
      "resetting env. episode reward total was 7.0. running mean: 3.0565182287155284\n",
      "resetting env. episode reward total was 7.0. running mean: 3.095953046428373\n",
      "resetting env. episode reward total was -9.0. running mean: 2.9749935159640892\n",
      "resetting env. episode reward total was -13.0. running mean: 2.8152435808044483\n",
      "resetting env. episode reward total was -7.0. running mean: 2.7170911449964037\n",
      "resetting env. episode reward total was 6.0. running mean: 2.74992023354644\n",
      "resetting env. episode reward total was 1.0. running mean: 2.732421031210975\n",
      "resetting env. episode reward total was -2.0. running mean: 2.6850968208988655\n",
      "resetting env. episode reward total was -3.0. running mean: 2.628245852689877\n",
      "resetting env. episode reward total was 6.0. running mean: 2.6619633941629783\n",
      "resetting env. episode reward total was 10.0. running mean: 2.7353437602213484\n",
      "resetting env. episode reward total was 1.0. running mean: 2.717990322619135\n",
      "resetting env. episode reward total was -3.0. running mean: 2.6608104193929436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 2.694202315199014\n",
      "resetting env. episode reward total was -2.0. running mean: 2.647260292047024\n",
      "resetting env. episode reward total was 10.0. running mean: 2.720787689126554\n",
      "resetting env. episode reward total was 16.0. running mean: 2.8535798122352887\n",
      "resetting env. episode reward total was 3.0. running mean: 2.8550440141129356\n",
      "resetting env. episode reward total was 1.0. running mean: 2.836493573971806\n",
      "resetting env. episode reward total was -2.0. running mean: 2.788128638232088\n",
      "resetting env. episode reward total was 10.0. running mean: 2.8602473518497673\n",
      "resetting env. episode reward total was 3.0. running mean: 2.8616448783312696\n",
      "resetting env. episode reward total was 1.0. running mean: 2.8430284295479566\n",
      "resetting env. episode reward total was 5.0. running mean: 2.8645981452524767\n",
      "resetting env. episode reward total was 3.0. running mean: 2.865952163799952\n",
      "resetting env. episode reward total was -3.0. running mean: 2.8072926421619524\n",
      "resetting env. episode reward total was 10.0. running mean: 2.8792197157403328\n",
      "resetting env. episode reward total was -7.0. running mean: 2.7804275185829295\n",
      "resetting env. episode reward total was 6.0. running mean: 2.8126232433971\n",
      "resetting env. episode reward total was 7.0. running mean: 2.854497010963129\n",
      "resetting env. episode reward total was 9.0. running mean: 2.9159520408534974\n",
      "resetting env. episode reward total was 5.0. running mean: 2.9367925204449623\n",
      "resetting env. episode reward total was 4.0. running mean: 2.9474245952405127\n",
      "resetting env. episode reward total was 2.0. running mean: 2.9379503492881076\n",
      "resetting env. episode reward total was -9.0. running mean: 2.8185708457952265\n",
      "resetting env. episode reward total was 3.0. running mean: 2.820385137337274\n",
      "resetting env. episode reward total was 9.0. running mean: 2.882181285963901\n",
      "resetting env. episode reward total was 5.0. running mean: 2.903359473104262\n",
      "resetting env. episode reward total was 10.0. running mean: 2.9743258783732194\n",
      "resetting env. episode reward total was -6.0. running mean: 2.8845826195894873\n",
      "resetting env. episode reward total was 7.0. running mean: 2.9257367933935923\n",
      "resetting env. episode reward total was -1.0. running mean: 2.8864794254596564\n",
      "resetting env. episode reward total was 10.0. running mean: 2.9576146312050597\n",
      "resetting env. episode reward total was 3.0. running mean: 2.958038484893009\n",
      "resetting env. episode reward total was -1.0. running mean: 2.918458100044079\n",
      "resetting env. episode reward total was -4.0. running mean: 2.849273519043638\n",
      "resetting env. episode reward total was -7.0. running mean: 2.7507807838532017\n",
      "resetting env. episode reward total was 8.0. running mean: 2.8032729760146697\n",
      "resetting env. episode reward total was -6.0. running mean: 2.715240246254523\n",
      "resetting env. episode reward total was 13.0. running mean: 2.818087843791978\n",
      "resetting env. episode reward total was -7.0. running mean: 2.7199069653540584\n",
      "resetting env. episode reward total was -6.0. running mean: 2.6327078957005177\n",
      "resetting env. episode reward total was 10.0. running mean: 2.7063808167435126\n",
      "resetting env. episode reward total was 12.0. running mean: 2.7993170085760775\n",
      "resetting env. episode reward total was -2.0. running mean: 2.7513238384903165\n",
      "resetting env. episode reward total was -7.0. running mean: 2.6538106001054134\n",
      "resetting env. episode reward total was -10.0. running mean: 2.527272494104359\n",
      "resetting env. episode reward total was 8.0. running mean: 2.5819997691633154\n",
      "resetting env. episode reward total was -3.0. running mean: 2.5261797714716825\n",
      "resetting env. episode reward total was 11.0. running mean: 2.6109179737569654\n",
      "resetting env. episode reward total was 9.0. running mean: 2.6748087940193956\n",
      "resetting env. episode reward total was 9.0. running mean: 2.7380607060792017\n",
      "resetting env. episode reward total was 7.0. running mean: 2.7806800990184093\n",
      "resetting env. episode reward total was 8.0. running mean: 2.8328732980282254\n",
      "resetting env. episode reward total was -3.0. running mean: 2.7745445650479432\n",
      "resetting env. episode reward total was -3.0. running mean: 2.716799119397464\n",
      "resetting env. episode reward total was 9.0. running mean: 2.779631128203489\n",
      "resetting env. episode reward total was -11.0. running mean: 2.6418348169214543\n",
      "resetting env. episode reward total was -1.0. running mean: 2.60541646875224\n",
      "resetting env. episode reward total was 14.0. running mean: 2.7193623040647177\n",
      "resetting env. episode reward total was 5.0. running mean: 2.7421686810240704\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7447469942138296\n",
      "resetting env. episode reward total was 8.0. running mean: 2.797299524271691\n",
      "resetting env. episode reward total was 3.0. running mean: 2.799326529028974\n",
      "resetting env. episode reward total was 1.0. running mean: 2.7813332637386843\n",
      "resetting env. episode reward total was -7.0. running mean: 2.6835199311012974\n",
      "resetting env. episode reward total was 8.0. running mean: 2.7366847317902843\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7393178844723813\n",
      "resetting env. episode reward total was -5.0. running mean: 2.6619247056276576\n",
      "resetting env. episode reward total was 17.0. running mean: 2.805305458571381\n",
      "resetting env. episode reward total was 12.0. running mean: 2.897252403985667\n",
      "resetting env. episode reward total was -4.0. running mean: 2.82827987994581\n",
      "resetting env. episode reward total was 1.0. running mean: 2.809997081146352\n",
      "resetting env. episode reward total was -4.0. running mean: 2.741897110334888\n",
      "resetting env. episode reward total was 3.0. running mean: 2.744478139231539\n",
      "resetting env. episode reward total was -1.0. running mean: 2.707033357839224\n",
      "resetting env. episode reward total was -8.0. running mean: 2.599963024260832\n",
      "resetting env. episode reward total was -3.0. running mean: 2.5439633940182236\n",
      "resetting env. episode reward total was -4.0. running mean: 2.4785237600780414\n",
      "resetting env. episode reward total was -1.0. running mean: 2.443738522477261\n",
      "resetting env. episode reward total was -2.0. running mean: 2.3993011372524884\n",
      "resetting env. episode reward total was -3.0. running mean: 2.3453081258799635\n",
      "resetting env. episode reward total was -2.0. running mean: 2.301855044621164\n",
      "resetting env. episode reward total was 2.0. running mean: 2.298836494174952\n",
      "resetting env. episode reward total was 4.0. running mean: 2.3158481292332027\n",
      "resetting env. episode reward total was 8.0. running mean: 2.3726896479408706\n",
      "resetting env. episode reward total was 7.0. running mean: 2.4189627514614616\n",
      "resetting env. episode reward total was 7.0. running mean: 2.4647731239468467\n",
      "resetting env. episode reward total was -4.0. running mean: 2.4001253927073782\n",
      "resetting env. episode reward total was 16.0. running mean: 2.5361241387803046\n",
      "resetting env. episode reward total was -3.0. running mean: 2.4807628973925016\n",
      "resetting env. episode reward total was 14.0. running mean: 2.5959552684185767\n",
      "resetting env. episode reward total was 5.0. running mean: 2.6199957157343907\n",
      "resetting env. episode reward total was 5.0. running mean: 2.6437957585770464\n",
      "resetting env. episode reward total was -6.0. running mean: 2.557357800991276\n",
      "resetting env. episode reward total was 6.0. running mean: 2.5917842229813632\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5958663807515494\n",
      "resetting env. episode reward total was 4.0. running mean: 2.609907716944034\n",
      "resetting env. episode reward total was 3.0. running mean: 2.6138086397745934\n",
      "resetting env. episode reward total was -5.0. running mean: 2.5376705533768478\n",
      "resetting env. episode reward total was 3.0. running mean: 2.542293847843079\n",
      "resetting env. episode reward total was -7.0. running mean: 2.4468709093646486\n",
      "resetting env. episode reward total was 17.0. running mean: 2.592402200271002\n",
      "resetting env. episode reward total was -1.0. running mean: 2.556478178268292\n",
      "resetting env. episode reward total was 5.0. running mean: 2.580913396485609\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5851042625207525\n",
      "resetting env. episode reward total was 1.0. running mean: 2.5692532198955447\n",
      "resetting env. episode reward total was -1.0. running mean: 2.5335606876965895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 2.5982250808196232\n",
      "resetting env. episode reward total was 13.0. running mean: 2.7022428300114267\n",
      "resetting env. episode reward total was 6.0. running mean: 2.7352204017113126\n",
      "resetting env. episode reward total was 2.0. running mean: 2.7278681976941996\n",
      "resetting env. episode reward total was 13.0. running mean: 2.8305895157172576\n",
      "resetting env. episode reward total was 15.0. running mean: 2.952283620560085\n",
      "resetting env. episode reward total was 12.0. running mean: 3.0427607843544844\n",
      "resetting env. episode reward total was 3.0. running mean: 3.0423331765109394\n",
      "resetting env. episode reward total was 7.0. running mean: 3.0819098447458297\n",
      "resetting env. episode reward total was 10.0. running mean: 3.1510907462983715\n",
      "resetting env. episode reward total was -3.0. running mean: 3.089579838835388\n",
      "resetting env. episode reward total was 7.0. running mean: 3.128684040447034\n",
      "resetting env. episode reward total was 3.0. running mean: 3.1273972000425636\n",
      "resetting env. episode reward total was 2.0. running mean: 3.116123228042138\n",
      "resetting env. episode reward total was 5.0. running mean: 3.1349619957617163\n",
      "resetting env. episode reward total was -10.0. running mean: 3.003612375804099\n",
      "resetting env. episode reward total was -1.0. running mean: 2.963576252046058\n",
      "resetting env. episode reward total was 9.0. running mean: 3.0239404895255975\n",
      "resetting env. episode reward total was 2.0. running mean: 3.0137010846303416\n",
      "resetting env. episode reward total was 12.0. running mean: 3.1035640737840384\n",
      "resetting env. episode reward total was 12.0. running mean: 3.1925284330461983\n",
      "resetting env. episode reward total was 1.0. running mean: 3.170603148715736\n",
      "resetting env. episode reward total was 8.0. running mean: 3.2188971172285785\n",
      "resetting env. episode reward total was -5.0. running mean: 3.136708146056293\n",
      "resetting env. episode reward total was 6.0. running mean: 3.16534106459573\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1736876539497727\n",
      "resetting env. episode reward total was 4.0. running mean: 3.181950777410275\n",
      "resetting env. episode reward total was 8.0. running mean: 3.230131269636172\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2478299569398104\n",
      "resetting env. episode reward total was 13.0. running mean: 3.3453516573704123\n",
      "resetting env. episode reward total was 14.0. running mean: 3.4518981407967084\n",
      "resetting env. episode reward total was -6.0. running mean: 3.357379159388741\n",
      "resetting env. episode reward total was 10.0. running mean: 3.423805367794854\n",
      "resetting env. episode reward total was -8.0. running mean: 3.3095673141169053\n",
      "resetting env. episode reward total was 6.0. running mean: 3.3364716409757365\n",
      "resetting env. episode reward total was -5.0. running mean: 3.253106924565979\n",
      "resetting env. episode reward total was 2.0. running mean: 3.240575855320319\n",
      "resetting env. episode reward total was 4.0. running mean: 3.248170096767116\n",
      "resetting env. episode reward total was 10.0. running mean: 3.315688395799445\n",
      "resetting env. episode reward total was 12.0. running mean: 3.4025315118414508\n",
      "resetting env. episode reward total was 11.0. running mean: 3.478506196723036\n",
      "resetting env. episode reward total was 9.0. running mean: 3.5337211347558055\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5183839234082472\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5232000841741646\n",
      "resetting env. episode reward total was 1.0. running mean: 3.497968083332423\n",
      "resetting env. episode reward total was 7.0. running mean: 3.5329884024990985\n",
      "resetting env. episode reward total was 1.0. running mean: 3.5076585184741074\n",
      "resetting env. episode reward total was 9.0. running mean: 3.562581933289366\n",
      "resetting env. episode reward total was -11.0. running mean: 3.4169561139564726\n",
      "resetting env. episode reward total was 5.0. running mean: 3.4327865528169075\n",
      "resetting env. episode reward total was 8.0. running mean: 3.4784586872887386\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4636741004158513\n",
      "resetting env. episode reward total was 4.0. running mean: 3.469037359411693\n",
      "resetting env. episode reward total was 11.0. running mean: 3.544346985817576\n",
      "resetting env. episode reward total was -9.0. running mean: 3.4189035159594003\n",
      "resetting env. episode reward total was -1.0. running mean: 3.3747144807998066\n",
      "resetting env. episode reward total was 12.0. running mean: 3.4609673359918087\n",
      "resetting env. episode reward total was 6.0. running mean: 3.4863576626318906\n",
      "resetting env. episode reward total was -3.0. running mean: 3.421494086005572\n",
      "resetting env. episode reward total was -15.0. running mean: 3.2372791451455165\n",
      "resetting env. episode reward total was 4.0. running mean: 3.2449063536940614\n",
      "resetting env. episode reward total was -2.0. running mean: 3.1924572901571207\n",
      "resetting env. episode reward total was 8.0. running mean: 3.2405327172555496\n",
      "resetting env. episode reward total was -6.0. running mean: 3.148127390082994\n",
      "resetting env. episode reward total was -11.0. running mean: 3.0066461161821643\n",
      "resetting env. episode reward total was -5.0. running mean: 2.9265796550203427\n",
      "resetting env. episode reward total was 3.0. running mean: 2.927313858470139\n",
      "resetting env. episode reward total was 1.0. running mean: 2.908040719885437\n",
      "resetting env. episode reward total was -1.0. running mean: 2.8689603126865832\n",
      "resetting env. episode reward total was -5.0. running mean: 2.7902707095597177\n",
      "resetting env. episode reward total was 3.0. running mean: 2.79236800246412\n",
      "resetting env. episode reward total was -4.0. running mean: 2.7244443224394788\n",
      "resetting env. episode reward total was 1.0. running mean: 2.7071998792150835\n",
      "resetting env. episode reward total was -7.0. running mean: 2.6101278804229326\n",
      "resetting env. episode reward total was -2.0. running mean: 2.5640266016187034\n",
      "resetting env. episode reward total was -8.0. running mean: 2.4583863356025164\n",
      "resetting env. episode reward total was 9.0. running mean: 2.523802472246491\n",
      "resetting env. episode reward total was -7.0. running mean: 2.4285644475240264\n",
      "resetting env. episode reward total was -2.0. running mean: 2.3842788030487863\n",
      "resetting env. episode reward total was 8.0. running mean: 2.4404360150182987\n",
      "resetting env. episode reward total was -9.0. running mean: 2.3260316548681157\n",
      "resetting env. episode reward total was -8.0. running mean: 2.2227713383194345\n",
      "resetting env. episode reward total was -6.0. running mean: 2.14054362493624\n",
      "resetting env. episode reward total was -13.0. running mean: 1.9891381886868778\n",
      "resetting env. episode reward total was 11.0. running mean: 2.079246806800009\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9984543387320088\n",
      "resetting env. episode reward total was -2.0. running mean: 1.9584697953446888\n",
      "resetting env. episode reward total was -9.0. running mean: 1.8488850973912418\n",
      "resetting env. episode reward total was -13.0. running mean: 1.7003962464173292\n",
      "resetting env. episode reward total was 3.0. running mean: 1.713392283953156\n",
      "resetting env. episode reward total was -14.0. running mean: 1.5562583611136245\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5506957775024883\n",
      "resetting env. episode reward total was 5.0. running mean: 1.5851888197274635\n",
      "resetting env. episode reward total was -14.0. running mean: 1.4293369315301887\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4550435622148867\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4304931265927379\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4761881953268106\n",
      "resetting env. episode reward total was -11.0. running mean: 1.3514263133735422\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3979120502398068\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3739329297374088\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3301936004400345\n",
      "resetting env. episode reward total was 14.0. running mean: 1.4568916644356342\n",
      "resetting env. episode reward total was 3.0. running mean: 1.472322747791278\n",
      "resetting env. episode reward total was -8.0. running mean: 1.377599520313365\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3538235251102313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: 1.3102852898591288\n",
      "resetting env. episode reward total was -4.0. running mean: 1.2571824369605376\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2646106125909322\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2019645064650228\n",
      "resetting env. episode reward total was -2.0. running mean: 1.1699448614003727\n",
      "resetting env. episode reward total was -9.0. running mean: 1.068245412786369\n",
      "resetting env. episode reward total was -11.0. running mean: 0.9475629586585054\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9580873290719203\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0185064557812011\n",
      "resetting env. episode reward total was 6.0. running mean: 1.068321391223389\n",
      "resetting env. episode reward total was 14.0. running mean: 1.197638177311155\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1556617955380435\n",
      "resetting env. episode reward total was 1.0. running mean: 1.154105177582663\n",
      "resetting env. episode reward total was -7.0. running mean: 1.0725641258068364\n",
      "resetting env. episode reward total was -5.0. running mean: 1.011838484548768\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9817200997032802\n",
      "resetting env. episode reward total was -8.0. running mean: 0.8919028987062475\n",
      "resetting env. episode reward total was -2.0. running mean: 0.862983869719185\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9143540310219931\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9952104907117731\n",
      "resetting env. episode reward total was 12.0. running mean: 1.1052583858046554\n",
      "resetting env. episode reward total was -8.0. running mean: 1.0142058019466087\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9640637439271427\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0044231064878713\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9043788754229926\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9253350866687626\n",
      "resetting env. episode reward total was 11.0. running mean: 1.026081735802075\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0758209184440544\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0350627092596139\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0747120821670177\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0939649613453475\n",
      "resetting env. episode reward total was 6.0. running mean: 1.143025311731894\n",
      "resetting env. episode reward total was -7.0. running mean: 1.061595058614575\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1209791080284293\n",
      "resetting env. episode reward total was -7.0. running mean: 1.039769316948145\n",
      "resetting env. episode reward total was -14.0. running mean: 0.8893716237786636\n",
      "resetting env. episode reward total was 1.0. running mean: 0.890477907540877\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8715731284654682\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8328573971808135\n",
      "resetting env. episode reward total was -12.0. running mean: 0.7045288232090053\n",
      "resetting env. episode reward total was 13.0. running mean: 0.8274835349769153\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8092086996271461\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8811166126308746\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8423054465045658\n",
      "resetting env. episode reward total was -14.0. running mean: 0.6938823920395202\n",
      "resetting env. episode reward total was 7.0. running mean: 0.756943568119125\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8293741324379337\n",
      "resetting env. episode reward total was -8.0. running mean: 0.7410803911135544\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7836695872024189\n",
      "resetting env. episode reward total was -6.0. running mean: 0.7158328913303946\n",
      "resetting env. episode reward total was -10.0. running mean: 0.6086745624170907\n",
      "resetting env. episode reward total was -9.0. running mean: 0.5125878167929199\n",
      "resetting env. episode reward total was -4.0. running mean: 0.4674619386249907\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5427873192387408\n",
      "resetting env. episode reward total was 7.0. running mean: 0.6073594460463534\n",
      "resetting env. episode reward total was 11.0. running mean: 0.7112858515858899\n",
      "resetting env. episode reward total was -6.0. running mean: 0.6441729930700311\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6577312631393307\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5811539505079375\n",
      "resetting env. episode reward total was -9.0. running mean: 0.48534241100285813\n",
      "resetting env. episode reward total was 2.0. running mean: 0.5004889868928295\n",
      "resetting env. episode reward total was -2.0. running mean: 0.4754840970239012\n",
      "resetting env. episode reward total was -10.0. running mean: 0.37072925605366214\n",
      "resetting env. episode reward total was -9.0. running mean: 0.27702196349312547\n",
      "resetting env. episode reward total was 1.0. running mean: 0.28425174385819424\n",
      "resetting env. episode reward total was -13.0. running mean: 0.1514092264196123\n",
      "resetting env. episode reward total was -4.0. running mean: 0.10989513415541616\n",
      "resetting env. episode reward total was 7.0. running mean: 0.178796182813862\n",
      "resetting env. episode reward total was -1.0. running mean: 0.16700822098572338\n",
      "resetting env. episode reward total was -10.0. running mean: 0.06533813877586614\n",
      "resetting env. episode reward total was -7.0. running mean: -0.0053152426118925344\n",
      "resetting env. episode reward total was 9.0. running mean: 0.08473790981422638\n",
      "resetting env. episode reward total was 6.0. running mean: 0.1438905307160841\n",
      "resetting env. episode reward total was -11.0. running mean: 0.032451625408923254\n",
      "resetting env. episode reward total was 11.0. running mean: 0.142127109154834\n",
      "resetting env. episode reward total was 6.0. running mean: 0.20070583806328565\n",
      "resetting env. episode reward total was -9.0. running mean: 0.10869877968265279\n",
      "resetting env. episode reward total was -1.0. running mean: 0.09761179188582626\n",
      "resetting env. episode reward total was -5.0. running mean: 0.046635673966967994\n",
      "resetting env. episode reward total was -3.0. running mean: 0.016169317227298315\n",
      "resetting env. episode reward total was 3.0. running mean: 0.04600762405502533\n",
      "resetting env. episode reward total was -11.0. running mean: -0.06445245218552492\n",
      "resetting env. episode reward total was 6.0. running mean: -0.0038079276636696774\n",
      "resetting env. episode reward total was 6.0. running mean: 0.056230151612967016\n",
      "resetting env. episode reward total was -10.0. running mean: -0.04433214990316266\n",
      "resetting env. episode reward total was -1.0. running mean: -0.053888828404131034\n",
      "resetting env. episode reward total was 3.0. running mean: -0.023349940120089722\n",
      "resetting env. episode reward total was 5.0. running mean: 0.026883559281111177\n",
      "resetting env. episode reward total was -1.0. running mean: 0.016614723688300068\n",
      "resetting env. episode reward total was 5.0. running mean: 0.06644857645141707\n",
      "resetting env. episode reward total was 7.0. running mean: 0.1357840906869029\n",
      "resetting env. episode reward total was 5.0. running mean: 0.18442624978003386\n",
      "resetting env. episode reward total was 12.0. running mean: 0.3025819872822335\n",
      "resetting env. episode reward total was -12.0. running mean: 0.17955616740941116\n",
      "resetting env. episode reward total was -7.0. running mean: 0.10776060573531704\n",
      "resetting env. episode reward total was -6.0. running mean: 0.04668299967796387\n",
      "resetting env. episode reward total was -6.0. running mean: -0.01378383031881577\n",
      "resetting env. episode reward total was 2.0. running mean: 0.006354007984372389\n",
      "resetting env. episode reward total was 12.0. running mean: 0.12629046790452866\n",
      "resetting env. episode reward total was 3.0. running mean: 0.15502756322548336\n",
      "resetting env. episode reward total was -9.0. running mean: 0.06347728759322854\n",
      "resetting env. episode reward total was -5.0. running mean: 0.01284251471729625\n",
      "resetting env. episode reward total was 4.0. running mean: 0.05271408957012329\n",
      "resetting env. episode reward total was -8.0. running mean: -0.027813051325577945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: -0.03753492081232217\n",
      "resetting env. episode reward total was -5.0. running mean: -0.08715957160419895\n",
      "resetting env. episode reward total was 13.0. running mean: 0.04371202411184305\n",
      "resetting env. episode reward total was 8.0. running mean: 0.12327490387072462\n",
      "resetting env. episode reward total was 11.0. running mean: 0.23204215483201737\n",
      "resetting env. episode reward total was 4.0. running mean: 0.2697217332836972\n",
      "resetting env. episode reward total was -6.0. running mean: 0.20702451595086024\n",
      "resetting env. episode reward total was -10.0. running mean: 0.10495427079135164\n",
      "resetting env. episode reward total was -7.0. running mean: 0.03390472808343811\n",
      "resetting env. episode reward total was 1.0. running mean: 0.043565680802603736\n",
      "resetting env. episode reward total was -1.0. running mean: 0.0331300239945777\n",
      "resetting env. episode reward total was 1.0. running mean: 0.04279872375463192\n",
      "resetting env. episode reward total was 7.0. running mean: 0.11237073651708561\n",
      "resetting env. episode reward total was -3.0. running mean: 0.08124702915191476\n",
      "resetting env. episode reward total was 8.0. running mean: 0.1604345588603956\n",
      "resetting env. episode reward total was 1.0. running mean: 0.16883021327179165\n",
      "resetting env. episode reward total was 3.0. running mean: 0.19714191113907373\n",
      "resetting env. episode reward total was 4.0. running mean: 0.235170492027683\n",
      "resetting env. episode reward total was 6.0. running mean: 0.29281878710740616\n",
      "resetting env. episode reward total was 1.0. running mean: 0.2998905992363321\n",
      "resetting env. episode reward total was 7.0. running mean: 0.3668916932439688\n",
      "resetting env. episode reward total was 2.0. running mean: 0.3832227763115291\n",
      "resetting env. episode reward total was 11.0. running mean: 0.4893905485484138\n",
      "resetting env. episode reward total was -7.0. running mean: 0.41449664306292966\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4303516766323004\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4460481598659774\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3915876782673176\n",
      "resetting env. episode reward total was -14.0. running mean: 0.2476718014846444\n",
      "resetting env. episode reward total was 8.0. running mean: 0.325195083469798\n",
      "resetting env. episode reward total was -2.0. running mean: 0.3019431326351\n",
      "resetting env. episode reward total was 10.0. running mean: 0.398923701308749\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3449344642956615\n",
      "resetting env. episode reward total was -3.0. running mean: 0.31148511965270487\n",
      "resetting env. episode reward total was 8.0. running mean: 0.38837026845617784\n",
      "resetting env. episode reward total was 10.0. running mean: 0.4844865657716161\n",
      "resetting env. episode reward total was -4.0. running mean: 0.4396417001138999\n",
      "resetting env. episode reward total was 10.0. running mean: 0.5352452831127609\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5198928302816332\n",
      "resetting env. episode reward total was -2.0. running mean: 0.4946939019788169\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5197469629590288\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5445494933294385\n",
      "resetting env. episode reward total was 10.0. running mean: 0.6391039983961441\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6527129584121827\n",
      "resetting env. episode reward total was -9.0. running mean: 0.5561858288280609\n",
      "resetting env. episode reward total was 6.0. running mean: 0.6106239705397802\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5845177308343824\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6086725535260387\n",
      "resetting env. episode reward total was 8.0. running mean: 0.6825858279907783\n",
      "resetting env. episode reward total was -9.0. running mean: 0.5857599697108705\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5299023700137617\n",
      "resetting env. episode reward total was -8.0. running mean: 0.44460334631362414\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4601573128504879\n",
      "resetting env. episode reward total was 8.0. running mean: 0.535555739721983\n",
      "resetting env. episode reward total was 12.0. running mean: 0.6502001823247632\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6136981805015155\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6575611986965003\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7009855867095354\n",
      "resetting env. episode reward total was -4.0. running mean: 0.65397573084244\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6874359735340156\n",
      "resetting env. episode reward total was 7.0. running mean: 0.7505616137986755\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6730559976606887\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6363254376840818\n",
      "resetting env. episode reward total was -6.0. running mean: 0.569962183307241\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5142625614741686\n",
      "resetting env. episode reward total was 7.0. running mean: 0.579119935859427\n",
      "resetting env. episode reward total was -10.0. running mean: 0.47332873650083274\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5285954491358245\n",
      "resetting env. episode reward total was -4.0. running mean: 0.4833094946444662\n",
      "resetting env. episode reward total was -6.0. running mean: 0.41847639969802153\n",
      "resetting env. episode reward total was 5.0. running mean: 0.4642916357010413\n",
      "resetting env. episode reward total was -2.0. running mean: 0.4396487193440309\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5452522321505906\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5797997098290847\n",
      "resetting env. episode reward total was 12.0. running mean: 0.6940017127307938\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7470616956034859\n",
      "resetting env. episode reward total was 11.0. running mean: 0.849591078647451\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8910951678609765\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9821842161823667\n",
      "resetting env. episode reward total was 10.0. running mean: 1.072362374020543\n",
      "resetting env. episode reward total was 11.0. running mean: 1.1716387502803376\n",
      "resetting env. episode reward total was -2.0. running mean: 1.1399223627775341\n",
      "resetting env. episode reward total was -9.0. running mean: 1.0385231391497587\n",
      "resetting env. episode reward total was -1.0. running mean: 1.018137907758261\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0679565286806785\n",
      "resetting env. episode reward total was 9.0. running mean: 1.1472769633938718\n",
      "resetting env. episode reward total was -7.0. running mean: 1.065804193759933\n",
      "resetting env. episode reward total was -4.0. running mean: 1.0151461518223335\n",
      "resetting env. episode reward total was 7.0. running mean: 1.07499469030411\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9942447434010688\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9443022959670581\n",
      "resetting env. episode reward total was -13.0. running mean: 0.8048592730073875\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8068106802773136\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8487425734745405\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8802551477397952\n",
      "resetting env. episode reward total was 4.0. running mean: 0.9114525962623973\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9123380702997733\n",
      "resetting env. episode reward total was 10.0. running mean: 1.0032146895967755\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0031825427008076\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0431507172737995\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9927192101010613\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0527920180000507\n",
      "resetting env. episode reward total was 16.0. running mean: 1.20226409782005\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1402414568418495\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1188390422734311\n",
      "resetting env. episode reward total was 1.0. running mean: 1.1176506518506968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -9.0. running mean: 1.0164741453321897\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0363094038788678\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9859463098400791\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0360868467416784\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9557259782742615\n",
      "resetting env. episode reward total was -1.0. running mean: 0.936168718491519\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9568070313066038\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8972389609935377\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8782665713836023\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8494839056697663\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8309890666130686\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8126791759469378\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8345523841874685\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7962068603455937\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8382447917421378\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8598623438247165\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8712637203864694\n",
      "resetting env. episode reward total was -4.0. running mean: 0.8225510831826046\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8043255723507785\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7862823166272707\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7284194934609979\n",
      "resetting env. episode reward total was -6.0. running mean: 0.6611352985263879\n",
      "resetting env. episode reward total was 13.0. running mean: 0.784523945541124\n",
      "resetting env. episode reward total was 1.0. running mean: 0.7866787060857128\n",
      "resetting env. episode reward total was 11.0. running mean: 0.8888119190248557\n",
      "resetting env. episode reward total was -7.0. running mean: 0.8099237998346072\n",
      "resetting env. episode reward total was 10.0. running mean: 0.901824561836261\n",
      "resetting env. episode reward total was 4.0. running mean: 0.9328063162178984\n",
      "resetting env. episode reward total was 11.0. running mean: 1.0334782530557194\n",
      "resetting env. episode reward total was -10.0. running mean: 0.9231434705251621\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9939120358199104\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0139729154617112\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0438331863070942\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0233948544440232\n",
      "resetting env. episode reward total was 2.0. running mean: 1.033160905899583\n",
      "resetting env. episode reward total was 12.0. running mean: 1.142829296840587\n",
      "resetting env. episode reward total was 8.0. running mean: 1.2114010038721812\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2192869938334594\n",
      "resetting env. episode reward total was 7.0. running mean: 1.2770941238951248\n",
      "resetting env. episode reward total was -6.0. running mean: 1.2043231826561736\n",
      "resetting env. episode reward total was -6.0. running mean: 1.1322799508296117\n",
      "resetting env. episode reward total was 5.0. running mean: 1.1709571513213157\n",
      "resetting env. episode reward total was 3.0. running mean: 1.1892475798081026\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1473551040100216\n",
      "resetting env. episode reward total was -11.0. running mean: 1.0258815529699212\n",
      "resetting env. episode reward total was 1.0. running mean: 1.025622737440222\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0653665100658198\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0747128449651617\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9739657165155101\n",
      "resetting env. episode reward total was -4.0. running mean: 0.924226059350355\n",
      "resetting env. episode reward total was 11.0. running mean: 1.0249837987568515\n",
      "resetting env. episode reward total was -3.0. running mean: 0.9847339607692829\n",
      "resetting env. episode reward total was 12.0. running mean: 1.09488662116159\n",
      "resetting env. episode reward total was -8.0. running mean: 1.003937754949974\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9538983774004741\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9043593936264693\n",
      "resetting env. episode reward total was 11.0. running mean: 1.0053157996902047\n",
      "resetting env. episode reward total was 8.0. running mean: 1.0752626416933027\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0745100152763696\n",
      "resetting env. episode reward total was 8.0. running mean: 1.143764915123606\n",
      "resetting env. episode reward total was 9.0. running mean: 1.22232726597237\n",
      "resetting env. episode reward total was -9.0. running mean: 1.1201039933126462\n",
      "resetting env. episode reward total was -9.0. running mean: 1.0189029533795197\n",
      "resetting env. episode reward total was -12.0. running mean: 0.8887139238457246\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8498267846072672\n",
      "resetting env. episode reward total was -10.0. running mean: 0.7413285167611946\n",
      "resetting env. episode reward total was 12.0. running mean: 0.8539152315935826\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9453760792776468\n",
      "resetting env. episode reward total was 10.0. running mean: 1.0359223184848703\n",
      "resetting env. episode reward total was 17.0. running mean: 1.1955630953000216\n",
      "resetting env. episode reward total was 7.0. running mean: 1.2536074643470214\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2710713897035513\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3083606758065158\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3152770690484508\n",
      "resetting env. episode reward total was -9.0. running mean: 1.212124298357966\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2900030553743864\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2971030248206425\n",
      "resetting env. episode reward total was -6.0. running mean: 1.224131994572436\n",
      "resetting env. episode reward total was 11.0. running mean: 1.3218906746267118\n",
      "resetting env. episode reward total was 10.0. running mean: 1.4086717678804448\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4245850502016404\n",
      "resetting env. episode reward total was 8.0. running mean: 1.490339199699624\n",
      "resetting env. episode reward total was -9.0. running mean: 1.3854358077026276\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3515814496256013\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3280656351293454\n",
      "resetting env. episode reward total was 3.0. running mean: 1.344784978778052\n",
      "resetting env. episode reward total was 11.0. running mean: 1.4413371289902714\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4669237577003686\n",
      "resetting env. episode reward total was 3.0. running mean: 1.482254520123365\n",
      "resetting env. episode reward total was -6.0. running mean: 1.4074319749221313\n",
      "resetting env. episode reward total was -1.0. running mean: 1.38335765517291\n",
      "resetting env. episode reward total was -2.0. running mean: 1.349524078621181\n",
      "resetting env. episode reward total was 11.0. running mean: 1.4460288378349693\n",
      "resetting env. episode reward total was 16.0. running mean: 1.5915685494566194\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5856528639620533\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5797963353224327\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6539983719692084\n",
      "resetting env. episode reward total was 12.0. running mean: 1.7574583882495163\n",
      "resetting env. episode reward total was -4.0. running mean: 1.699883804367021\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7628849663233508\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7752561166601173\n",
      "resetting env. episode reward total was 13.0. running mean: 1.8875035554935162\n",
      "resetting env. episode reward total was -11.0. running mean: 1.758628519938581\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6910422347391951\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7041318123918032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: 1.6570904942678852\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6905195893252065\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7036143934319545\n",
      "resetting env. episode reward total was 9.0. running mean: 1.776578249497635\n",
      "resetting env. episode reward total was 16.0. running mean: 1.9188124670026585\n",
      "resetting env. episode reward total was -5.0. running mean: 1.849624342332632\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8011280989093057\n",
      "resetting env. episode reward total was -4.0. running mean: 1.7431168179202126\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7056856497410104\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7286287932436004\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6213425053111643\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5851290802580527\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6192777894554722\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6630850115609175\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6964541614453084\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6694896198308553\n",
      "resetting env. episode reward total was 10.0. running mean: 1.7527947236325467\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7552667763962213\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7077141086322591\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7306369675459365\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7333305978704772\n",
      "resetting env. episode reward total was 12.0. running mean: 1.8359972918917724\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8476373189728548\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9291609457831262\n",
      "resetting env. episode reward total was 14.0. running mean: 2.049869336325295\n",
      "resetting env. episode reward total was -1.0. running mean: 2.019370642962042\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0191769365324217\n",
      "resetting env. episode reward total was 10.0. running mean: 2.0989851671670974\n",
      "resetting env. episode reward total was -9.0. running mean: 1.9879953154954262\n",
      "resetting env. episode reward total was 11.0. running mean: 2.078115362340472\n",
      "resetting env. episode reward total was 7.0. running mean: 2.127334208717067\n",
      "resetting env. episode reward total was 11.0. running mean: 2.216060866629896\n",
      "resetting env. episode reward total was 2.0. running mean: 2.213900257963597\n",
      "resetting env. episode reward total was -9.0. running mean: 2.101761255383961\n",
      "resetting env. episode reward total was 8.0. running mean: 2.160743642830121\n",
      "resetting env. episode reward total was -5.0. running mean: 2.08913620640182\n",
      "resetting env. episode reward total was 7.0. running mean: 2.1382448443378017\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1368623958944237\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1754937719354794\n",
      "resetting env. episode reward total was 10.0. running mean: 2.253738834216125\n",
      "resetting env. episode reward total was 12.0. running mean: 2.3512014458739636\n",
      "resetting env. episode reward total was 2.0. running mean: 2.347689431415224\n",
      "resetting env. episode reward total was 2.0. running mean: 2.344212537101072\n",
      "resetting env. episode reward total was -7.0. running mean: 2.2507704117300613\n",
      "resetting env. episode reward total was 10.0. running mean: 2.328262707612761\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2949800805366336\n",
      "resetting env. episode reward total was -11.0. running mean: 2.162030279731267\n",
      "resetting env. episode reward total was -10.0. running mean: 2.0404099769339545\n",
      "resetting env. episode reward total was -5.0. running mean: 1.970005877164615\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9903058183929687\n",
      "resetting env. episode reward total was 5.0. running mean: 2.020402760209039\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0101987326069484\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9400967452808788\n",
      "resetting env. episode reward total was 4.0. running mean: 1.96069577782807\n",
      "resetting env. episode reward total was 10.0. running mean: 2.041088820049789\n",
      "resetting env. episode reward total was 4.0. running mean: 2.060677931849291\n",
      "resetting env. episode reward total was 11.0. running mean: 2.1500711525307983\n",
      "resetting env. episode reward total was 14.0. running mean: 2.2685704410054903\n",
      "resetting env. episode reward total was 3.0. running mean: 2.2758847365954353\n",
      "resetting env. episode reward total was 1.0. running mean: 2.2631258892294808\n",
      "resetting env. episode reward total was 11.0. running mean: 2.350494630337186\n",
      "resetting env. episode reward total was -3.0. running mean: 2.296989684033814\n",
      "resetting env. episode reward total was -2.0. running mean: 2.2540197871934757\n",
      "resetting env. episode reward total was 8.0. running mean: 2.311479589321541\n",
      "resetting env. episode reward total was 4.0. running mean: 2.328364793428326\n",
      "resetting env. episode reward total was 12.0. running mean: 2.4250811454940426\n",
      "resetting env. episode reward total was 1.0. running mean: 2.410830334039102\n",
      "resetting env. episode reward total was 1.0. running mean: 2.3967220306987107\n",
      "resetting env. episode reward total was 5.0. running mean: 2.4227548103917234\n",
      "resetting env. episode reward total was -5.0. running mean: 2.3485272622878064\n",
      "resetting env. episode reward total was 11.0. running mean: 2.4350419896649282\n",
      "resetting env. episode reward total was 3.0. running mean: 2.440691569768279\n",
      "resetting env. episode reward total was 7.0. running mean: 2.486284654070596\n",
      "resetting env. episode reward total was -2.0. running mean: 2.4414218075298897\n",
      "resetting env. episode reward total was -4.0. running mean: 2.377007589454591\n",
      "resetting env. episode reward total was -1.0. running mean: 2.343237513560045\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3398051384244445\n",
      "resetting env. episode reward total was 6.0. running mean: 2.3764070870402\n",
      "resetting env. episode reward total was -5.0. running mean: 2.302643016169798\n",
      "resetting env. episode reward total was -3.0. running mean: 2.2496165860081003\n",
      "resetting env. episode reward total was 6.0. running mean: 2.2871204201480193\n",
      "resetting env. episode reward total was -2.0. running mean: 2.2442492159465393\n",
      "resetting env. episode reward total was 3.0. running mean: 2.2518067237870736\n",
      "resetting env. episode reward total was -1.0. running mean: 2.219288656549203\n",
      "resetting env. episode reward total was 9.0. running mean: 2.287095769983711\n",
      "resetting env. episode reward total was 11.0. running mean: 2.374224812283874\n",
      "resetting env. episode reward total was -1.0. running mean: 2.3404825641610354\n",
      "resetting env. episode reward total was -3.0. running mean: 2.287077738519425\n",
      "resetting env. episode reward total was 7.0. running mean: 2.334206961134231\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3608648915228883\n",
      "resetting env. episode reward total was -7.0. running mean: 2.2672562426076595\n",
      "resetting env. episode reward total was 7.0. running mean: 2.314583680181583\n",
      "resetting env. episode reward total was 2.0. running mean: 2.311437843379767\n",
      "resetting env. episode reward total was 1.0. running mean: 2.298323464945969\n",
      "resetting env. episode reward total was 10.0. running mean: 2.3753402302965094\n",
      "resetting env. episode reward total was 9.0. running mean: 2.441586827993544\n",
      "resetting env. episode reward total was 1.0. running mean: 2.4271709597136084\n",
      "resetting env. episode reward total was -5.0. running mean: 2.3528992501164723\n",
      "resetting env. episode reward total was -1.0. running mean: 2.319370257615308\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3161765550391546\n",
      "resetting env. episode reward total was -5.0. running mean: 2.2430147894887633\n",
      "resetting env. episode reward total was 9.0. running mean: 2.3105846415938753\n",
      "resetting env. episode reward total was 8.0. running mean: 2.3674787951779366\n",
      "resetting env. episode reward total was -6.0. running mean: 2.283804007226157\n",
      "resetting env. episode reward total was 11.0. running mean: 2.370965967153895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 2.4672563074823564\n",
      "resetting env. episode reward total was 10.0. running mean: 2.542583744407533\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5471579069634576\n",
      "resetting env. episode reward total was 9.0. running mean: 2.611686327893823\n",
      "resetting env. episode reward total was 11.0. running mean: 2.6955694646148847\n",
      "resetting env. episode reward total was 12.0. running mean: 2.788613769968736\n",
      "resetting env. episode reward total was 7.0. running mean: 2.8307276322690487\n",
      "resetting env. episode reward total was 7.0. running mean: 2.872420355946358\n",
      "resetting env. episode reward total was 10.0. running mean: 2.9436961523868947\n",
      "resetting env. episode reward total was 12.0. running mean: 3.034259190863026\n",
      "resetting env. episode reward total was 6.0. running mean: 3.0639165989543957\n",
      "resetting env. episode reward total was -6.0. running mean: 2.9732774329648515\n",
      "resetting env. episode reward total was -5.0. running mean: 2.893544658635203\n",
      "resetting env. episode reward total was 14.0. running mean: 3.0046092120488512\n",
      "resetting env. episode reward total was 1.0. running mean: 2.9845631199283624\n",
      "resetting env. episode reward total was -11.0. running mean: 2.8447174887290787\n",
      "resetting env. episode reward total was 12.0. running mean: 2.936270313841788\n",
      "resetting env. episode reward total was 5.0. running mean: 2.95690761070337\n",
      "resetting env. episode reward total was 2.0. running mean: 2.9473385345963363\n",
      "resetting env. episode reward total was 5.0. running mean: 2.9678651492503727\n",
      "resetting env. episode reward total was 6.0. running mean: 2.998186497757869\n",
      "resetting env. episode reward total was 11.0. running mean: 3.0782046327802903\n",
      "resetting env. episode reward total was 6.0. running mean: 3.1074225864524876\n",
      "resetting env. episode reward total was -13.0. running mean: 2.946348360587963\n",
      "resetting env. episode reward total was -3.0. running mean: 2.8868848769820836\n",
      "resetting env. episode reward total was -3.0. running mean: 2.828016028212263\n",
      "resetting env. episode reward total was 2.0. running mean: 2.8197358679301403\n",
      "resetting env. episode reward total was 8.0. running mean: 2.871538509250839\n",
      "resetting env. episode reward total was -8.0. running mean: 2.7628231241583303\n",
      "resetting env. episode reward total was 9.0. running mean: 2.825194892916747\n",
      "resetting env. episode reward total was 7.0. running mean: 2.866942943987579\n",
      "resetting env. episode reward total was 3.0. running mean: 2.868273514547703\n",
      "resetting env. episode reward total was 10.0. running mean: 2.939590779402226\n",
      "resetting env. episode reward total was -3.0. running mean: 2.8801948716082038\n",
      "resetting env. episode reward total was 6.0. running mean: 2.9113929228921216\n",
      "resetting env. episode reward total was 5.0. running mean: 2.9322789936632003\n",
      "resetting env. episode reward total was -3.0. running mean: 2.8729562037265683\n",
      "resetting env. episode reward total was 9.0. running mean: 2.9342266416893024\n",
      "resetting env. episode reward total was 7.0. running mean: 2.974884375272409\n",
      "resetting env. episode reward total was -3.0. running mean: 2.915135531519685\n",
      "resetting env. episode reward total was 6.0. running mean: 2.945984176204488\n",
      "resetting env. episode reward total was 6.0. running mean: 2.976524334442443\n",
      "resetting env. episode reward total was -1.0. running mean: 2.936759091098019\n",
      "resetting env. episode reward total was 6.0. running mean: 2.9673915001870386\n",
      "resetting env. episode reward total was 1.0. running mean: 2.947717585185168\n",
      "resetting env. episode reward total was 4.0. running mean: 2.958240409333316\n",
      "resetting env. episode reward total was 5.0. running mean: 2.978658005239983\n",
      "resetting env. episode reward total was 5.0. running mean: 2.9988714251875828\n",
      "resetting env. episode reward total was 8.0. running mean: 3.048882710935707\n",
      "resetting env. episode reward total was 3.0. running mean: 3.04839388382635\n",
      "resetting env. episode reward total was 9.0. running mean: 3.1079099449880863\n",
      "resetting env. episode reward total was 6.0. running mean: 3.1368308455382055\n",
      "resetting env. episode reward total was 16.0. running mean: 3.2654625370828234\n",
      "resetting env. episode reward total was 11.0. running mean: 3.342807911711995\n",
      "resetting env. episode reward total was 10.0. running mean: 3.409379832594875\n",
      "resetting env. episode reward total was -6.0. running mean: 3.3152860342689263\n",
      "resetting env. episode reward total was -5.0. running mean: 3.232133173926237\n",
      "resetting env. episode reward total was 9.0. running mean: 3.2898118421869746\n",
      "resetting env. episode reward total was -3.0. running mean: 3.226913723765105\n",
      "resetting env. episode reward total was -1.0. running mean: 3.184644586527454\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2227981406621793\n",
      "resetting env. episode reward total was 2.0. running mean: 3.2105701592555573\n",
      "resetting env. episode reward total was 15.0. running mean: 3.3284644576630016\n",
      "resetting env. episode reward total was 10.0. running mean: 3.3951798130863717\n",
      "resetting env. episode reward total was 10.0. running mean: 3.461228014955508\n",
      "resetting env. episode reward total was 10.0. running mean: 3.526615734805953\n",
      "resetting env. episode reward total was 13.0. running mean: 3.6213495774578934\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6551360816833145\n",
      "resetting env. episode reward total was 10.0. running mean: 3.7185847208664815\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6713988736578167\n",
      "resetting env. episode reward total was 3.0. running mean: 3.6646848849212383\n",
      "resetting env. episode reward total was -3.0. running mean: 3.598038036072026\n",
      "resetting env. episode reward total was -3.0. running mean: 3.532057655711306\n",
      "resetting env. episode reward total was 2.0. running mean: 3.516737079154193\n",
      "resetting env. episode reward total was 5.0. running mean: 3.531569708362651\n",
      "resetting env. episode reward total was 12.0. running mean: 3.6162540112790245\n",
      "resetting env. episode reward total was 2.0. running mean: 3.6000914711662344\n",
      "resetting env. episode reward total was 1.0. running mean: 3.5740905564545717\n",
      "resetting env. episode reward total was -1.0. running mean: 3.5283496508900263\n",
      "resetting env. episode reward total was -5.0. running mean: 3.443066154381126\n",
      "resetting env. episode reward total was 10.0. running mean: 3.508635492837315\n",
      "resetting env. episode reward total was 1.0. running mean: 3.4835491379089416\n",
      "resetting env. episode reward total was 11.0. running mean: 3.558713646529852\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6231265100645533\n",
      "resetting env. episode reward total was 9.0. running mean: 3.6768952449639074\n",
      "resetting env. episode reward total was 11.0. running mean: 3.750126292514268\n",
      "resetting env. episode reward total was -1.0. running mean: 3.7026250295891256\n",
      "resetting env. episode reward total was 3.0. running mean: 3.6955987792932343\n",
      "resetting env. episode reward total was -7.0. running mean: 3.5886427915003023\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5727563635852992\n",
      "resetting env. episode reward total was -7.0. running mean: 3.4670287999494462\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4723585119499516\n",
      "resetting env. episode reward total was 7.0. running mean: 3.507634926830452\n",
      "resetting env. episode reward total was 11.0. running mean: 3.582558577562147\n",
      "resetting env. episode reward total was 4.0. running mean: 3.586732991786526\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6108656618686608\n",
      "resetting env. episode reward total was -11.0. running mean: 3.4647570052499743\n",
      "resetting env. episode reward total was -9.0. running mean: 3.3401094351974745\n",
      "resetting env. episode reward total was 2.0. running mean: 3.3267083408455\n",
      "resetting env. episode reward total was -5.0. running mean: 3.243441257437045\n",
      "resetting env. episode reward total was 11.0. running mean: 3.321006844862674\n",
      "resetting env. episode reward total was 3.0. running mean: 3.3177967764140472\n",
      "resetting env. episode reward total was 7.0. running mean: 3.3546188086499065\n",
      "resetting env. episode reward total was -8.0. running mean: 3.2410726205634073\n",
      "resetting env. episode reward total was 6.0. running mean: 3.2686618943577734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 3.2759752754141958\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2932155226600535\n",
      "resetting env. episode reward total was -7.0. running mean: 3.190283367433453\n",
      "resetting env. episode reward total was -2.0. running mean: 3.1383805337591184\n",
      "resetting env. episode reward total was -1.0. running mean: 3.0969967284215274\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1060267611373122\n",
      "resetting env. episode reward total was -5.0. running mean: 3.0249664935259393\n",
      "resetting env. episode reward total was 6.0. running mean: 3.05471682859068\n",
      "resetting env. episode reward total was -5.0. running mean: 2.9741696603047734\n",
      "resetting env. episode reward total was 12.0. running mean: 3.0644279637017258\n",
      "resetting env. episode reward total was 5.0. running mean: 3.0837836840647084\n",
      "resetting env. episode reward total was -15.0. running mean: 2.9029458472240615\n",
      "resetting env. episode reward total was 11.0. running mean: 2.9839163887518207\n",
      "resetting env. episode reward total was -5.0. running mean: 2.9040772248643028\n",
      "resetting env. episode reward total was 6.0. running mean: 2.93503645261566\n",
      "resetting env. episode reward total was -3.0. running mean: 2.875686088089503\n",
      "resetting env. episode reward total was 3.0. running mean: 2.876929227208608\n",
      "resetting env. episode reward total was 5.0. running mean: 2.8981599349365217\n",
      "resetting env. episode reward total was -2.0. running mean: 2.8491783355871565\n",
      "resetting env. episode reward total was -10.0. running mean: 2.720686552231285\n",
      "resetting env. episode reward total was 2.0. running mean: 2.713479686708972\n",
      "resetting env. episode reward total was -6.0. running mean: 2.626344889841882\n",
      "resetting env. episode reward total was 2.0. running mean: 2.620081440943463\n",
      "resetting env. episode reward total was 6.0. running mean: 2.6538806265340282\n",
      "resetting env. episode reward total was 6.0. running mean: 2.687341820268688\n",
      "resetting env. episode reward total was -14.0. running mean: 2.520468402066001\n",
      "resetting env. episode reward total was 11.0. running mean: 2.605263718045341\n",
      "resetting env. episode reward total was -3.0. running mean: 2.549211080864888\n",
      "resetting env. episode reward total was -10.0. running mean: 2.423718970056239\n",
      "resetting env. episode reward total was 8.0. running mean: 2.479481780355677\n",
      "resetting env. episode reward total was -5.0. running mean: 2.40468696255212\n",
      "resetting env. episode reward total was -5.0. running mean: 2.330640092926599\n",
      "resetting env. episode reward total was -11.0. running mean: 2.197333691997333\n",
      "resetting env. episode reward total was 4.0. running mean: 2.21536035507736\n",
      "resetting env. episode reward total was -3.0. running mean: 2.1632067515265865\n",
      "resetting env. episode reward total was -5.0. running mean: 2.091574684011321\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0906589371712077\n",
      "resetting env. episode reward total was 12.0. running mean: 2.189752347799496\n",
      "resetting env. episode reward total was 3.0. running mean: 2.197854824321501\n",
      "resetting env. episode reward total was 4.0. running mean: 2.2158762760782857\n",
      "resetting env. episode reward total was -3.0. running mean: 2.1637175133175033\n",
      "resetting env. episode reward total was -3.0. running mean: 2.1120803381843283\n",
      "resetting env. episode reward total was 8.0. running mean: 2.170959534802485\n",
      "resetting env. episode reward total was 8.0. running mean: 2.22924993945446\n",
      "resetting env. episode reward total was -5.0. running mean: 2.1569574400599154\n",
      "resetting env. episode reward total was 10.0. running mean: 2.2353878656593165\n",
      "resetting env. episode reward total was 11.0. running mean: 2.3230339870027232\n",
      "resetting env. episode reward total was 3.0. running mean: 2.329803647132696\n",
      "resetting env. episode reward total was 16.0. running mean: 2.466505610661369\n",
      "resetting env. episode reward total was 8.0. running mean: 2.5218405545547555\n",
      "resetting env. episode reward total was 5.0. running mean: 2.546622149009208\n",
      "resetting env. episode reward total was 4.0. running mean: 2.5611559275191156\n",
      "resetting env. episode reward total was 20.0. running mean: 2.7355443682439247\n",
      "resetting env. episode reward total was 3.0. running mean: 2.738188924561485\n",
      "resetting env. episode reward total was 14.0. running mean: 2.8508070353158703\n",
      "resetting env. episode reward total was 15.0. running mean: 2.9722989649627114\n",
      "resetting env. episode reward total was -5.0. running mean: 2.8925759753130844\n",
      "resetting env. episode reward total was 3.0. running mean: 2.8936502155599535\n",
      "resetting env. episode reward total was 9.0. running mean: 2.9547137134043537\n",
      "resetting env. episode reward total was 12.0. running mean: 3.04516657627031\n",
      "resetting env. episode reward total was 3.0. running mean: 3.044714910507607\n",
      "resetting env. episode reward total was 1.0. running mean: 3.024267761402531\n",
      "resetting env. episode reward total was 10.0. running mean: 3.0940250837885057\n",
      "resetting env. episode reward total was -1.0. running mean: 3.053084832950621\n",
      "resetting env. episode reward total was -3.0. running mean: 2.992553984621115\n",
      "resetting env. episode reward total was -5.0. running mean: 2.912628444774904\n",
      "resetting env. episode reward total was 14.0. running mean: 3.023502160327155\n",
      "resetting env. episode reward total was 11.0. running mean: 3.1032671387238833\n",
      "resetting env. episode reward total was 5.0. running mean: 3.1222344673366442\n",
      "resetting env. episode reward total was 11.0. running mean: 3.2010121226632777\n",
      "resetting env. episode reward total was 9.0. running mean: 3.2590020014366448\n",
      "resetting env. episode reward total was 9.0. running mean: 3.316411981422278\n",
      "resetting env. episode reward total was 7.0. running mean: 3.353247861608055\n",
      "resetting env. episode reward total was -1.0. running mean: 3.3097153829919748\n",
      "resetting env. episode reward total was 1.0. running mean: 3.286618229162055\n",
      "resetting env. episode reward total was 10.0. running mean: 3.3537520468704343\n",
      "resetting env. episode reward total was 4.0. running mean: 3.36021452640173\n",
      "resetting env. episode reward total was 3.0. running mean: 3.356612381137712\n",
      "resetting env. episode reward total was 2.0. running mean: 3.343046257326335\n",
      "resetting env. episode reward total was -5.0. running mean: 3.259615794753072\n",
      "resetting env. episode reward total was 3.0. running mean: 3.257019636805541\n",
      "resetting env. episode reward total was 2.0. running mean: 3.2444494404374855\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2820049460331107\n",
      "resetting env. episode reward total was 6.0. running mean: 3.3091848965727797\n",
      "resetting env. episode reward total was 6.0. running mean: 3.336093047607052\n",
      "resetting env. episode reward total was 2.0. running mean: 3.3227321171309816\n",
      "resetting env. episode reward total was 11.0. running mean: 3.399504795959672\n",
      "resetting env. episode reward total was 11.0. running mean: 3.475509748000075\n",
      "resetting env. episode reward total was 7.0. running mean: 3.510754650520074\n",
      "resetting env. episode reward total was 10.0. running mean: 3.5756471040148736\n",
      "resetting env. episode reward total was -7.0. running mean: 3.469890632974725\n",
      "resetting env. episode reward total was -1.0. running mean: 3.425191726644978\n",
      "resetting env. episode reward total was -3.0. running mean: 3.3609398093785283\n",
      "resetting env. episode reward total was 6.0. running mean: 3.387330411284743\n",
      "resetting env. episode reward total was 7.0. running mean: 3.4234571071718953\n",
      "resetting env. episode reward total was 11.0. running mean: 3.4992225361001763\n",
      "resetting env. episode reward total was -16.0. running mean: 3.3042303107391744\n",
      "resetting env. episode reward total was 3.0. running mean: 3.3011880076317826\n",
      "resetting env. episode reward total was -4.0. running mean: 3.228176127555465\n",
      "resetting env. episode reward total was -5.0. running mean: 3.14589436627991\n",
      "resetting env. episode reward total was 4.0. running mean: 3.154435422617111\n",
      "resetting env. episode reward total was -1.0. running mean: 3.11289106839094\n",
      "resetting env. episode reward total was 1.0. running mean: 3.0917621577070302\n",
      "resetting env. episode reward total was -7.0. running mean: 2.99084453612996\n",
      "resetting env. episode reward total was 3.0. running mean: 2.99093609076866\n",
      "resetting env. episode reward total was 7.0. running mean: 3.031026729860973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: 3.010716462562363\n",
      "resetting env. episode reward total was 11.0. running mean: 3.0906092979367394\n",
      "resetting env. episode reward total was 2.0. running mean: 3.079703204957372\n",
      "resetting env. episode reward total was -1.0. running mean: 3.038906172907798\n",
      "resetting env. episode reward total was -7.0. running mean: 2.9385171111787205\n",
      "resetting env. episode reward total was -6.0. running mean: 2.849131940066933\n",
      "resetting env. episode reward total was -6.0. running mean: 2.7606406206662637\n",
      "resetting env. episode reward total was 6.0. running mean: 2.793034214459601\n",
      "resetting env. episode reward total was 13.0. running mean: 2.895103872315005\n",
      "resetting env. episode reward total was -7.0. running mean: 2.796152833591855\n",
      "resetting env. episode reward total was 8.0. running mean: 2.8481913052559364\n",
      "resetting env. episode reward total was -5.0. running mean: 2.769709392203377\n",
      "resetting env. episode reward total was -10.0. running mean: 2.642012298281343\n",
      "resetting env. episode reward total was 5.0. running mean: 2.665592175298529\n",
      "resetting env. episode reward total was -2.0. running mean: 2.618936253545544\n",
      "resetting env. episode reward total was -7.0. running mean: 2.5227468910100885\n",
      "resetting env. episode reward total was 7.0. running mean: 2.5675194220999873\n",
      "resetting env. episode reward total was -11.0. running mean: 2.4318442278789876\n",
      "resetting env. episode reward total was -11.0. running mean: 2.2975257856001976\n",
      "resetting env. episode reward total was 6.0. running mean: 2.3345505277441956\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3612050224667533\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3875929722420857\n",
      "resetting env. episode reward total was 2.0. running mean: 2.383717042519665\n",
      "resetting env. episode reward total was 10.0. running mean: 2.4598798720944686\n",
      "resetting env. episode reward total was 16.0. running mean: 2.595281073373524\n",
      "resetting env. episode reward total was 2.0. running mean: 2.5893282626397887\n",
      "resetting env. episode reward total was 7.0. running mean: 2.6334349800133907\n",
      "resetting env. episode reward total was -5.0. running mean: 2.557100630213257\n",
      "resetting env. episode reward total was -1.0. running mean: 2.5215296239111247\n",
      "resetting env. episode reward total was -3.0. running mean: 2.4663143276720136\n",
      "resetting env. episode reward total was 1.0. running mean: 2.4516511843952933\n",
      "resetting env. episode reward total was 6.0. running mean: 2.4871346725513406\n",
      "resetting env. episode reward total was 1.0. running mean: 2.472263325825827\n",
      "resetting env. episode reward total was 8.0. running mean: 2.5275406925675687\n",
      "resetting env. episode reward total was -2.0. running mean: 2.482265285641893\n",
      "resetting env. episode reward total was 3.0. running mean: 2.487442632785474\n",
      "resetting env. episode reward total was 1.0. running mean: 2.472568206457619\n",
      "resetting env. episode reward total was 2.0. running mean: 2.467842524393043\n",
      "resetting env. episode reward total was 6.0. running mean: 2.5031640991491124\n",
      "resetting env. episode reward total was -1.0. running mean: 2.4681324581576214\n",
      "resetting env. episode reward total was 11.0. running mean: 2.5534511335760453\n",
      "resetting env. episode reward total was -11.0. running mean: 2.417916622240285\n",
      "resetting env. episode reward total was -1.0. running mean: 2.3837374560178826\n",
      "resetting env. episode reward total was -6.0. running mean: 2.2999000814577037\n",
      "resetting env. episode reward total was 7.0. running mean: 2.3469010806431267\n",
      "resetting env. episode reward total was 6.0. running mean: 2.3834320698366955\n",
      "resetting env. episode reward total was 3.0. running mean: 2.3895977491383285\n",
      "resetting env. episode reward total was 3.0. running mean: 2.395701771646945\n",
      "resetting env. episode reward total was -16.0. running mean: 2.2117447539304753\n",
      "resetting env. episode reward total was 13.0. running mean: 2.3196273063911703\n",
      "resetting env. episode reward total was 5.0. running mean: 2.346431033327258\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3729667229939855\n",
      "resetting env. episode reward total was 4.0. running mean: 2.3892370557640454\n",
      "resetting env. episode reward total was 12.0. running mean: 2.485344685206405\n",
      "resetting env. episode reward total was 6.0. running mean: 2.520491238354341\n",
      "resetting env. episode reward total was 15.0. running mean: 2.6452863259707975\n",
      "resetting env. episode reward total was -5.0. running mean: 2.5688334627110896\n",
      "resetting env. episode reward total was 5.0. running mean: 2.5931451280839783\n",
      "resetting env. episode reward total was -4.0. running mean: 2.5272136768031386\n",
      "resetting env. episode reward total was 4.0. running mean: 2.5419415400351073\n",
      "resetting env. episode reward total was -8.0. running mean: 2.436522124634756\n",
      "resetting env. episode reward total was -7.0. running mean: 2.3421569033884087\n",
      "resetting env. episode reward total was 4.0. running mean: 2.3587353343545248\n",
      "resetting env. episode reward total was -7.0. running mean: 2.26514798101098\n",
      "resetting env. episode reward total was -11.0. running mean: 2.1324965012008703\n",
      "resetting env. episode reward total was -11.0. running mean: 2.0011715361888616\n",
      "resetting env. episode reward total was -2.0. running mean: 1.961159820826973\n",
      "resetting env. episode reward total was 6.0. running mean: 2.001548222618703\n",
      "resetting env. episode reward total was 7.0. running mean: 2.051532740392516\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9710174129885907\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0113072388587048\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9511941664701176\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9516822248054164\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9721654025573623\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9624437485317887\n",
      "resetting env. episode reward total was -12.0. running mean: 1.8228193110464708\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8445911179360062\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7761452067566461\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8083837546890797\n",
      "resetting env. episode reward total was 9.0. running mean: 1.880299917142189\n",
      "resetting env. episode reward total was -7.0. running mean: 1.7914969179707672\n",
      "resetting env. episode reward total was -6.0. running mean: 1.7135819487910595\n",
      "resetting env. episode reward total was 3.0. running mean: 1.726446129303149\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7191816680101175\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6819898513300162\n",
      "resetting env. episode reward total was 1.0. running mean: 1.675169952816716\n",
      "resetting env. episode reward total was -11.0. running mean: 1.5484182532885489\n",
      "resetting env. episode reward total was -7.0. running mean: 1.4629340707556633\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5483047300481068\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5428216827476258\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5473934659201496\n",
      "resetting env. episode reward total was 16.0. running mean: 1.691919531260948\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6450003359483385\n",
      "resetting env. episode reward total was -8.0. running mean: 1.548550332588855\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5430648292629665\n",
      "resetting env. episode reward total was 6.0. running mean: 1.587634180970337\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5317578391606335\n",
      "resetting env. episode reward total was 3.0. running mean: 1.546440260769027\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5409758581613369\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6055660995797236\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6495104385839263\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6930153341980871\n",
      "resetting env. episode reward total was -9.0. running mean: 1.5860851808561063\n",
      "resetting env. episode reward total was 15.0. running mean: 1.7202243290475452\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7430220857570697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 1.805591864899499\n",
      "resetting env. episode reward total was 8.0. running mean: 1.8675359462505041\n",
      "resetting env. episode reward total was -4.0. running mean: 1.808860586787999\n",
      "resetting env. episode reward total was -1.0. running mean: 1.780771980920119\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7329642611109177\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6856346184998086\n",
      "resetting env. episode reward total was -4.0. running mean: 1.6287782723148103\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6324904895916623\n",
      "resetting env. episode reward total was -13.0. running mean: 1.4861655846957458\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5113039288487884\n",
      "resetting env. episode reward total was 13.0. running mean: 1.6261908895603003\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6999289806646973\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7129296908580505\n",
      "resetting env. episode reward total was 6.0. running mean: 1.75580039394947\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7882423900099753\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6803599661098754\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6335563664487767\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5772208027842889\n",
      "resetting env. episode reward total was 12.0. running mean: 1.681448594756446\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6846341088088814\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7477877677207927\n",
      "resetting env. episode reward total was 9.0. running mean: 1.8203098900435848\n",
      "resetting env. episode reward total was 11.0. running mean: 1.912106791143149\n",
      "resetting env. episode reward total was 14.0. running mean: 2.0329857232317177\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9526558659994002\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9231293073394062\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8938980142660122\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9749590341233523\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0152094437821186\n",
      "resetting env. episode reward total was 8.0. running mean: 2.075057349344297\n",
      "resetting env. episode reward total was 14.0. running mean: 2.1943067758508543\n",
      "resetting env. episode reward total was -8.0. running mean: 2.092363708092346\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0214400710114226\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0212256703013085\n",
      "resetting env. episode reward total was 11.0. running mean: 2.1110134135982954\n",
      "resetting env. episode reward total was 8.0. running mean: 2.1699032794623125\n",
      "resetting env. episode reward total was 3.0. running mean: 2.1782042466676894\n",
      "resetting env. episode reward total was 14.0. running mean: 2.2964222042010127\n",
      "resetting env. episode reward total was -3.0. running mean: 2.243457982159003\n",
      "resetting env. episode reward total was 4.0. running mean: 2.261023402337413\n",
      "resetting env. episode reward total was 4.0. running mean: 2.2784131683140387\n",
      "resetting env. episode reward total was 3.0. running mean: 2.285629036630898\n",
      "resetting env. episode reward total was 2.0. running mean: 2.282772746264589\n",
      "resetting env. episode reward total was 2.0. running mean: 2.279945018801943\n",
      "resetting env. episode reward total was 7.0. running mean: 2.3271455686139233\n",
      "resetting env. episode reward total was 8.0. running mean: 2.383874112927784\n",
      "resetting env. episode reward total was 16.0. running mean: 2.5200353717985062\n",
      "resetting env. episode reward total was 3.0. running mean: 2.524835018080521\n",
      "resetting env. episode reward total was 6.0. running mean: 2.559586667899716\n",
      "resetting env. episode reward total was 9.0. running mean: 2.6239908012207187\n",
      "resetting env. episode reward total was -1.0. running mean: 2.587750893208512\n",
      "resetting env. episode reward total was 2.0. running mean: 2.5818733842764265\n",
      "resetting env. episode reward total was 9.0. running mean: 2.646054650433662\n",
      "resetting env. episode reward total was -1.0. running mean: 2.6095941039293256\n",
      "resetting env. episode reward total was 8.0. running mean: 2.6634981628900323\n",
      "resetting env. episode reward total was 6.0. running mean: 2.696863181261132\n",
      "resetting env. episode reward total was 7.0. running mean: 2.7398945494485205\n",
      "resetting env. episode reward total was 1.0. running mean: 2.722495603954035\n",
      "resetting env. episode reward total was 4.0. running mean: 2.735270647914495\n",
      "resetting env. episode reward total was 10.0. running mean: 2.80791794143535\n",
      "resetting env. episode reward total was -1.0. running mean: 2.7698387620209965\n",
      "resetting env. episode reward total was 2.0. running mean: 2.7621403744007864\n",
      "resetting env. episode reward total was 7.0. running mean: 2.8045189706567784\n",
      "resetting env. episode reward total was 6.0. running mean: 2.8364737809502105\n",
      "resetting env. episode reward total was -3.0. running mean: 2.7781090431407085\n",
      "resetting env. episode reward total was 9.0. running mean: 2.840327952709301\n",
      "resetting env. episode reward total was 10.0. running mean: 2.911924673182208\n",
      "resetting env. episode reward total was 2.0. running mean: 2.902805426450386\n",
      "resetting env. episode reward total was 9.0. running mean: 2.963777372185882\n",
      "resetting env. episode reward total was 5.0. running mean: 2.984139598464023\n",
      "resetting env. episode reward total was 7.0. running mean: 3.0242982024793825\n",
      "resetting env. episode reward total was 9.0. running mean: 3.0840552204545886\n",
      "resetting env. episode reward total was 3.0. running mean: 3.0832146682500423\n",
      "resetting env. episode reward total was 1.0. running mean: 3.0623825215675415\n",
      "resetting env. episode reward total was 12.0. running mean: 3.151758696351866\n",
      "resetting env. episode reward total was 12.0. running mean: 3.2402411093883474\n",
      "resetting env. episode reward total was -9.0. running mean: 3.117838698294464\n",
      "resetting env. episode reward total was -7.0. running mean: 3.0166603113115196\n",
      "resetting env. episode reward total was 4.0. running mean: 3.0264937081984042\n",
      "resetting env. episode reward total was 5.0. running mean: 3.04622877111642\n",
      "resetting env. episode reward total was 1.0. running mean: 3.025766483405256\n",
      "resetting env. episode reward total was 6.0. running mean: 3.0555088185712034\n",
      "resetting env. episode reward total was 4.0. running mean: 3.0649537303854912\n",
      "resetting env. episode reward total was 9.0. running mean: 3.124304193081636\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1330611511508195\n",
      "resetting env. episode reward total was 7.0. running mean: 3.171730539639311\n",
      "resetting env. episode reward total was -1.0. running mean: 3.1300132342429183\n",
      "resetting env. episode reward total was -1.0. running mean: 3.088713101900489\n",
      "resetting env. episode reward total was 12.0. running mean: 3.1778259708814844\n",
      "resetting env. episode reward total was 5.0. running mean: 3.1960477111726693\n",
      "resetting env. episode reward total was -10.0. running mean: 3.0640872340609424\n",
      "resetting env. episode reward total was 9.0. running mean: 3.1234463617203327\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1322118981031295\n",
      "resetting env. episode reward total was 7.0. running mean: 3.170889779122098\n",
      "resetting env. episode reward total was -5.0. running mean: 3.089180881330877\n",
      "resetting env. episode reward total was 10.0. running mean: 3.1582890725175683\n",
      "resetting env. episode reward total was 12.0. running mean: 3.246706181792393\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2842391199744685\n",
      "resetting env. episode reward total was 11.0. running mean: 3.3613967287747237\n",
      "resetting env. episode reward total was 2.0. running mean: 3.3477827614869766\n",
      "resetting env. episode reward total was -2.0. running mean: 3.2943049338721067\n",
      "resetting env. episode reward total was 7.0. running mean: 3.3313618845333854\n",
      "resetting env. episode reward total was 1.0. running mean: 3.3080482656880514\n",
      "resetting env. episode reward total was 10.0. running mean: 3.374967783031171\n",
      "resetting env. episode reward total was -4.0. running mean: 3.301218105200859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 3.33820592414885\n",
      "resetting env. episode reward total was -4.0. running mean: 3.2648238649073615\n",
      "resetting env. episode reward total was 9.0. running mean: 3.3221756262582876\n",
      "resetting env. episode reward total was -16.0. running mean: 3.1289538699957045\n",
      "resetting env. episode reward total was 11.0. running mean: 3.207664331295747\n",
      "resetting env. episode reward total was -6.0. running mean: 3.1155876879827895\n",
      "resetting env. episode reward total was -5.0. running mean: 3.034431811102962\n",
      "resetting env. episode reward total was 4.0. running mean: 3.0440874929919324\n",
      "resetting env. episode reward total was 9.0. running mean: 3.103646618062013\n",
      "resetting env. episode reward total was 8.0. running mean: 3.152610151881393\n",
      "resetting env. episode reward total was 8.0. running mean: 3.2010840503625793\n",
      "resetting env. episode reward total was 2.0. running mean: 3.1890732098589534\n",
      "resetting env. episode reward total was -1.0. running mean: 3.147182477760364\n",
      "resetting env. episode reward total was 13.0. running mean: 3.24571065298276\n",
      "resetting env. episode reward total was -1.0. running mean: 3.203253546452933\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2412210109884034\n",
      "resetting env. episode reward total was 5.0. running mean: 3.258808800878519\n",
      "resetting env. episode reward total was 12.0. running mean: 3.346220712869734\n",
      "resetting env. episode reward total was -1.0. running mean: 3.302758505741037\n",
      "resetting env. episode reward total was -4.0. running mean: 3.2297309206836267\n",
      "resetting env. episode reward total was 1.0. running mean: 3.20743361147679\n",
      "resetting env. episode reward total was 6.0. running mean: 3.2353592753620224\n",
      "resetting env. episode reward total was 2.0. running mean: 3.2230056826084024\n",
      "resetting env. episode reward total was 4.0. running mean: 3.2307756257823184\n",
      "resetting env. episode reward total was 15.0. running mean: 3.348467869524495\n",
      "resetting env. episode reward total was 9.0. running mean: 3.40498319082925\n",
      "resetting env. episode reward total was 1.0. running mean: 3.380933358920957\n",
      "resetting env. episode reward total was 6.0. running mean: 3.4071240253317474\n",
      "resetting env. episode reward total was -1.0. running mean: 3.36305278507843\n",
      "resetting env. episode reward total was 9.0. running mean: 3.4194222572276454\n",
      "resetting env. episode reward total was 9.0. running mean: 3.475228034655369\n",
      "resetting env. episode reward total was 3.0. running mean: 3.470475754308815\n",
      "resetting env. episode reward total was 10.0. running mean: 3.5357709967657267\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5804132867980694\n",
      "resetting env. episode reward total was 5.0. running mean: 3.5946091539300884\n",
      "resetting env. episode reward total was 16.0. running mean: 3.7186630623907875\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7214764317668796\n",
      "resetting env. episode reward total was 6.0. running mean: 3.744261667449211\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7568190507747183\n",
      "resetting env. episode reward total was 5.0. running mean: 3.769250860266971\n",
      "resetting env. episode reward total was 10.0. running mean: 3.8315583516643015\n",
      "resetting env. episode reward total was 10.0. running mean: 3.8932427681476587\n",
      "resetting env. episode reward total was -8.0. running mean: 3.774310340466182\n",
      "resetting env. episode reward total was 1.0. running mean: 3.74656723706152\n",
      "resetting env. episode reward total was 11.0. running mean: 3.8191015646909046\n",
      "resetting env. episode reward total was -7.0. running mean: 3.7109105490439958\n",
      "resetting env. episode reward total was -1.0. running mean: 3.663801443553556\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6971634291180204\n",
      "resetting env. episode reward total was -3.0. running mean: 3.6301917948268403\n",
      "resetting env. episode reward total was 5.0. running mean: 3.6438898768785717\n",
      "resetting env. episode reward total was 10.0. running mean: 3.707450978109786\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7303764683286884\n",
      "resetting env. episode reward total was 3.0. running mean: 3.723072703645401\n",
      "resetting env. episode reward total was 4.0. running mean: 3.725841976608947\n",
      "resetting env. episode reward total was -4.0. running mean: 3.6485835568428575\n",
      "resetting env. episode reward total was 2.0. running mean: 3.632097721274429\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6057767440616844\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5897189766210675\n",
      "resetting env. episode reward total was 6.0. running mean: 3.613821786854857\n",
      "resetting env. episode reward total was -1.0. running mean: 3.5676835689863085\n",
      "resetting env. episode reward total was 7.0. running mean: 3.602006733296445\n",
      "resetting env. episode reward total was -8.0. running mean: 3.4859866659634804\n",
      "resetting env. episode reward total was 12.0. running mean: 3.571126799303846\n",
      "resetting env. episode reward total was -1.0. running mean: 3.5254155313108075\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5701613759976993\n",
      "resetting env. episode reward total was 3.0. running mean: 3.564459762237722\n",
      "resetting env. episode reward total was -4.0. running mean: 3.4888151646153447\n",
      "resetting env. episode reward total was -3.0. running mean: 3.4239270129691914\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4296877428394996\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4353908654111045\n",
      "resetting env. episode reward total was 6.0. running mean: 3.4610369567569936\n",
      "resetting env. episode reward total was -3.0. running mean: 3.3964265871894237\n",
      "resetting env. episode reward total was -6.0. running mean: 3.3024623213175293\n",
      "resetting env. episode reward total was -8.0. running mean: 3.1894376981043537\n",
      "resetting env. episode reward total was 8.0. running mean: 3.2375433211233102\n",
      "resetting env. episode reward total was 3.0. running mean: 3.235167887912077\n",
      "resetting env. episode reward total was 13.0. running mean: 3.332816209032956\n",
      "resetting env. episode reward total was 11.0. running mean: 3.4094880469426263\n",
      "resetting env. episode reward total was 5.0. running mean: 3.4253931664732\n",
      "resetting env. episode reward total was 1.0. running mean: 3.4011392348084675\n",
      "resetting env. episode reward total was 8.0. running mean: 3.447127842460383\n",
      "resetting env. episode reward total was -7.0. running mean: 3.3426565640357793\n",
      "resetting env. episode reward total was 2.0. running mean: 3.3292299983954217\n",
      "resetting env. episode reward total was 11.0. running mean: 3.405937698411467\n",
      "resetting env. episode reward total was 3.0. running mean: 3.4018783214273522\n",
      "resetting env. episode reward total was 12.0. running mean: 3.487859538213079\n",
      "resetting env. episode reward total was 15.0. running mean: 3.602980942830948\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6269511334026387\n",
      "resetting env. episode reward total was 1.0. running mean: 3.600681622068612\n",
      "resetting env. episode reward total was -5.0. running mean: 3.514674805847926\n",
      "resetting env. episode reward total was 5.0. running mean: 3.5295280577894466\n",
      "resetting env. episode reward total was 9.0. running mean: 3.584232777211552\n",
      "resetting env. episode reward total was 3.0. running mean: 3.5783904494394365\n",
      "resetting env. episode reward total was 12.0. running mean: 3.6626065449450422\n",
      "resetting env. episode reward total was 6.0. running mean: 3.685980479495592\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7091206747006362\n",
      "resetting env. episode reward total was 7.0. running mean: 3.7420294679536297\n",
      "resetting env. episode reward total was 11.0. running mean: 3.814609173274093\n",
      "resetting env. episode reward total was 9.0. running mean: 3.8664630815413523\n",
      "resetting env. episode reward total was 3.0. running mean: 3.8577984507259386\n",
      "resetting env. episode reward total was 4.0. running mean: 3.8592204662186793\n",
      "resetting env. episode reward total was 5.0. running mean: 3.8706282615564924\n",
      "resetting env. episode reward total was 9.0. running mean: 3.921921978940927\n",
      "resetting env. episode reward total was 6.0. running mean: 3.942702759151518\n",
      "resetting env. episode reward total was -4.0. running mean: 3.8632757315600026\n",
      "resetting env. episode reward total was 2.0. running mean: 3.8446429742444024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 3.826196544501958\n",
      "resetting env. episode reward total was 2.0. running mean: 3.8079345790569383\n",
      "resetting env. episode reward total was 15.0. running mean: 3.919855233266369\n",
      "resetting env. episode reward total was -5.0. running mean: 3.8306566809337053\n",
      "resetting env. episode reward total was -11.0. running mean: 3.682350114124368\n",
      "resetting env. episode reward total was -2.0. running mean: 3.6255266129831245\n",
      "resetting env. episode reward total was 3.0. running mean: 3.619271346853293\n",
      "resetting env. episode reward total was -3.0. running mean: 3.5530786333847604\n",
      "resetting env. episode reward total was -2.0. running mean: 3.497547847050913\n",
      "resetting env. episode reward total was 12.0. running mean: 3.582572368580404\n",
      "resetting env. episode reward total was 3.0. running mean: 3.5767466448945995\n",
      "resetting env. episode reward total was 8.0. running mean: 3.6209791784456535\n",
      "resetting env. episode reward total was 12.0. running mean: 3.704769386661197\n",
      "resetting env. episode reward total was 11.0. running mean: 3.777721692794585\n",
      "resetting env. episode reward total was 7.0. running mean: 3.8099444758666388\n",
      "resetting env. episode reward total was 12.0. running mean: 3.8918450311079726\n",
      "resetting env. episode reward total was 8.0. running mean: 3.932926580796893\n",
      "resetting env. episode reward total was 2.0. running mean: 3.913597314988924\n",
      "resetting env. episode reward total was 17.0. running mean: 4.0444613418390345\n",
      "resetting env. episode reward total was 11.0. running mean: 4.114016728420644\n",
      "resetting env. episode reward total was -2.0. running mean: 4.052876561136438\n",
      "resetting env. episode reward total was 12.0. running mean: 4.132347795525074\n",
      "resetting env. episode reward total was -3.0. running mean: 4.061024317569823\n",
      "resetting env. episode reward total was 12.0. running mean: 4.1404140743941245\n",
      "resetting env. episode reward total was 8.0. running mean: 4.179009933650184\n",
      "resetting env. episode reward total was 11.0. running mean: 4.247219834313682\n",
      "resetting env. episode reward total was 5.0. running mean: 4.254747635970546\n",
      "resetting env. episode reward total was 3.0. running mean: 4.2422001596108405\n",
      "resetting env. episode reward total was 9.0. running mean: 4.289778158014732\n",
      "resetting env. episode reward total was -5.0. running mean: 4.196880376434585\n",
      "resetting env. episode reward total was -16.0. running mean: 3.9949115726702393\n",
      "resetting env. episode reward total was 5.0. running mean: 4.004962456943537\n",
      "resetting env. episode reward total was 6.0. running mean: 4.024912832374102\n",
      "resetting env. episode reward total was -3.0. running mean: 3.9546637040503607\n",
      "resetting env. episode reward total was 17.0. running mean: 4.0851170670098575\n",
      "resetting env. episode reward total was -2.0. running mean: 4.0242658963397595\n",
      "resetting env. episode reward total was 7.0. running mean: 4.054023237376362\n",
      "resetting env. episode reward total was -1.0. running mean: 4.0034830050025985\n",
      "resetting env. episode reward total was -9.0. running mean: 3.8734481749525727\n",
      "resetting env. episode reward total was 1.0. running mean: 3.8447136932030466\n",
      "resetting env. episode reward total was 1.0. running mean: 3.816266556271016\n",
      "resetting env. episode reward total was 5.0. running mean: 3.828103890708306\n",
      "resetting env. episode reward total was -13.0. running mean: 3.659822851801223\n",
      "resetting env. episode reward total was -4.0. running mean: 3.583224623283211\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6173923770503786\n",
      "resetting env. episode reward total was 10.0. running mean: 3.681218453279875\n",
      "resetting env. episode reward total was 4.0. running mean: 3.684406268747076\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6575622060596054\n",
      "resetting env. episode reward total was -17.0. running mean: 3.4509865839990095\n",
      "resetting env. episode reward total was 8.0. running mean: 3.4964767181590193\n",
      "resetting env. episode reward total was 2.0. running mean: 3.481511950977429\n",
      "resetting env. episode reward total was 4.0. running mean: 3.486696831467655\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4918298631529785\n",
      "resetting env. episode reward total was -3.0. running mean: 3.4269115645214487\n",
      "resetting env. episode reward total was -5.0. running mean: 3.3426424488762345\n",
      "resetting env. episode reward total was 8.0. running mean: 3.3892160243874723\n",
      "resetting env. episode reward total was 15.0. running mean: 3.5053238641435973\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5102706255021614\n",
      "resetting env. episode reward total was 10.0. running mean: 3.5751679192471397\n",
      "resetting env. episode reward total was -4.0. running mean: 3.4994162400546682\n",
      "resetting env. episode reward total was -7.0. running mean: 3.394422077654122\n",
      "resetting env. episode reward total was 12.0. running mean: 3.4804778568775805\n",
      "resetting env. episode reward total was 10.0. running mean: 3.5456730783088046\n",
      "resetting env. episode reward total was 3.0. running mean: 3.5402163475257162\n",
      "resetting env. episode reward total was 5.0. running mean: 3.554814184050459\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5592660422099542\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5636733817878548\n",
      "resetting env. episode reward total was 2.0. running mean: 3.548036647969976\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5525562814902765\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6170307186753736\n",
      "resetting env. episode reward total was 3.0. running mean: 3.61086041148862\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5947518073737337\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6588042892999963\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6922162464069963\n",
      "resetting env. episode reward total was 8.0. running mean: 3.7352940839429265\n",
      "resetting env. episode reward total was -7.0. running mean: 3.6279411431034974\n",
      "resetting env. episode reward total was 8.0. running mean: 3.6716617316724625\n",
      "resetting env. episode reward total was 12.0. running mean: 3.754945114355738\n",
      "resetting env. episode reward total was 2.0. running mean: 3.7373956632121805\n",
      "resetting env. episode reward total was 3.0. running mean: 3.7300217065800587\n",
      "resetting env. episode reward total was 5.0. running mean: 3.742721489514258\n",
      "resetting env. episode reward total was 5.0. running mean: 3.755294274619115\n",
      "resetting env. episode reward total was 8.0. running mean: 3.797741331872924\n",
      "resetting env. episode reward total was 6.0. running mean: 3.819763918554195\n",
      "resetting env. episode reward total was 11.0. running mean: 3.8915662793686527\n",
      "resetting env. episode reward total was 3.0. running mean: 3.882650616574966\n",
      "resetting env. episode reward total was 4.0. running mean: 3.8838241104092166\n",
      "resetting env. episode reward total was -11.0. running mean: 3.7349858693051243\n",
      "resetting env. episode reward total was -4.0. running mean: 3.657636010612073\n",
      "resetting env. episode reward total was -9.0. running mean: 3.5310596505059526\n",
      "resetting env. episode reward total was -3.0. running mean: 3.4657490540008933\n",
      "resetting env. episode reward total was 15.0. running mean: 3.5810915634608844\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5852806478262758\n",
      "resetting env. episode reward total was 3.0. running mean: 3.579427841348013\n",
      "resetting env. episode reward total was 16.0. running mean: 3.7036335629345327\n",
      "resetting env. episode reward total was 11.0. running mean: 3.7765972273051873\n",
      "resetting env. episode reward total was 7.0. running mean: 3.808831255032135\n",
      "resetting env. episode reward total was 4.0. running mean: 3.8107429424818138\n",
      "resetting env. episode reward total was 9.0. running mean: 3.8626355130569956\n",
      "resetting env. episode reward total was 8.0. running mean: 3.9040091579264256\n",
      "resetting env. episode reward total was 5.0. running mean: 3.9149690663471612\n",
      "resetting env. episode reward total was 7.0. running mean: 3.9458193756836892\n",
      "resetting env. episode reward total was -3.0. running mean: 3.8763611819268524\n",
      "resetting env. episode reward total was -1.0. running mean: 3.827597570107584\n",
      "resetting env. episode reward total was 5.0. running mean: 3.839321594406508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 3.840928378462443\n",
      "resetting env. episode reward total was -7.0. running mean: 3.732519094677819\n",
      "resetting env. episode reward total was 5.0. running mean: 3.74519390373104\n",
      "resetting env. episode reward total was -1.0. running mean: 3.69774196469373\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6507645450467927\n",
      "resetting env. episode reward total was 12.0. running mean: 3.734256899596325\n",
      "resetting env. episode reward total was -7.0. running mean: 3.6269143306003615\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6506451872943577\n",
      "resetting env. episode reward total was 8.0. running mean: 3.694138735421414\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6471973480672\n",
      "resetting env. episode reward total was 3.0. running mean: 3.640725374586528\n",
      "resetting env. episode reward total was 11.0. running mean: 3.7143181208406624\n",
      "resetting env. episode reward total was 7.0. running mean: 3.7471749396322553\n",
      "resetting env. episode reward total was -3.0. running mean: 3.6797031902359327\n",
      "resetting env. episode reward total was -3.0. running mean: 3.6129061583335735\n",
      "resetting env. episode reward total was -3.0. running mean: 3.546777096750238\n",
      "resetting env. episode reward total was 12.0. running mean: 3.631309325782736\n",
      "resetting env. episode reward total was 12.0. running mean: 3.7149962325249084\n",
      "resetting env. episode reward total was -4.0. running mean: 3.6378462701996592\n",
      "resetting env. episode reward total was 4.0. running mean: 3.6414678074976625\n",
      "resetting env. episode reward total was -9.0. running mean: 3.515053129422686\n",
      "resetting env. episode reward total was -11.0. running mean: 3.369902598128459\n",
      "resetting env. episode reward total was 5.0. running mean: 3.386203572147174\n",
      "resetting env. episode reward total was 8.0. running mean: 3.4323415364257026\n",
      "resetting env. episode reward total was 1.0. running mean: 3.4080181210614455\n",
      "resetting env. episode reward total was 6.0. running mean: 3.433937939850831\n",
      "resetting env. episode reward total was 9.0. running mean: 3.4895985604523228\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5347025748477994\n",
      "resetting env. episode reward total was 5.0. running mean: 3.5493555490993214\n",
      "resetting env. episode reward total was 6.0. running mean: 3.573861993608328\n",
      "resetting env. episode reward total was 16.0. running mean: 3.698123373672245\n",
      "resetting env. episode reward total was -9.0. running mean: 3.5711421399355228\n",
      "resetting env. episode reward total was 12.0. running mean: 3.6554307185361674\n",
      "resetting env. episode reward total was -5.0. running mean: 3.568876411350806\n",
      "resetting env. episode reward total was 8.0. running mean: 3.613187647237298\n",
      "resetting env. episode reward total was -3.0. running mean: 3.547055770764925\n",
      "resetting env. episode reward total was 3.0. running mean: 3.541585213057276\n",
      "resetting env. episode reward total was 6.0. running mean: 3.566169360926703\n",
      "resetting env. episode reward total was -2.0. running mean: 3.510507667317436\n",
      "resetting env. episode reward total was 13.0. running mean: 3.6054025906442617\n",
      "resetting env. episode reward total was 10.0. running mean: 3.669348564737819\n",
      "resetting env. episode reward total was -1.0. running mean: 3.622655079090441\n",
      "resetting env. episode reward total was 3.0. running mean: 3.616428528299536\n",
      "resetting env. episode reward total was 3.0. running mean: 3.6102642430165406\n",
      "resetting env. episode reward total was 3.0. running mean: 3.604161600586375\n",
      "resetting env. episode reward total was 7.0. running mean: 3.638119984580511\n",
      "resetting env. episode reward total was 9.0. running mean: 3.6917387847347056\n",
      "resetting env. episode reward total was 10.0. running mean: 3.7548213968873587\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7572731829184853\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7797004510893006\n",
      "resetting env. episode reward total was 12.0. running mean: 3.861903446578408\n",
      "resetting env. episode reward total was 8.0. running mean: 3.903284412112624\n",
      "resetting env. episode reward total was 1.0. running mean: 3.8742515679914975\n",
      "resetting env. episode reward total was 16.0. running mean: 3.995509052311583\n",
      "resetting env. episode reward total was 9.0. running mean: 4.045553961788467\n",
      "resetting env. episode reward total was -9.0. running mean: 3.9150984221705825\n",
      "resetting env. episode reward total was -1.0. running mean: 3.865947437948877\n",
      "resetting env. episode reward total was -3.0. running mean: 3.797287963569388\n",
      "resetting env. episode reward total was 11.0. running mean: 3.869315083933694\n",
      "resetting env. episode reward total was -5.0. running mean: 3.7806219330943573\n",
      "resetting env. episode reward total was -4.0. running mean: 3.702815713763414\n",
      "resetting env. episode reward total was 11.0. running mean: 3.7757875566257795\n",
      "resetting env. episode reward total was 10.0. running mean: 3.838029681059522\n",
      "resetting env. episode reward total was -8.0. running mean: 3.7196493842489264\n",
      "resetting env. episode reward total was 3.0. running mean: 3.712452890406437\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6653283615023726\n",
      "resetting env. episode reward total was -9.0. running mean: 3.538675077887349\n",
      "resetting env. episode reward total was 6.0. running mean: 3.5632883271084754\n",
      "resetting env. episode reward total was -2.0. running mean: 3.5076554438373906\n",
      "resetting env. episode reward total was 11.0. running mean: 3.5825788893990165\n",
      "resetting env. episode reward total was -5.0. running mean: 3.4967531005050265\n",
      "resetting env. episode reward total was -5.0. running mean: 3.4117855694999766\n",
      "resetting env. episode reward total was 12.0. running mean: 3.4976677138049768\n",
      "resetting env. episode reward total was -3.0. running mean: 3.432691036666927\n",
      "resetting env. episode reward total was -5.0. running mean: 3.348364126300258\n",
      "resetting env. episode reward total was -2.0. running mean: 3.2948804850372553\n",
      "resetting env. episode reward total was 8.0. running mean: 3.3419316801868826\n",
      "resetting env. episode reward total was 6.0. running mean: 3.3685123633850136\n",
      "resetting env. episode reward total was 2.0. running mean: 3.3548272397511636\n",
      "resetting env. episode reward total was 8.0. running mean: 3.401278967353652\n",
      "resetting env. episode reward total was -4.0. running mean: 3.3272661776801153\n",
      "resetting env. episode reward total was 4.0. running mean: 3.3339935159033143\n",
      "resetting env. episode reward total was 1.0. running mean: 3.310653580744281\n",
      "resetting env. episode reward total was 5.0. running mean: 3.327547044936838\n",
      "resetting env. episode reward total was -1.0. running mean: 3.2842715744874695\n",
      "resetting env. episode reward total was 4.0. running mean: 3.291428858742595\n",
      "resetting env. episode reward total was 9.0. running mean: 3.348514570155169\n",
      "resetting env. episode reward total was -1.0. running mean: 3.3050294244536174\n",
      "resetting env. episode reward total was 16.0. running mean: 3.4319791302090814\n",
      "resetting env. episode reward total was -5.0. running mean: 3.3476593389069906\n",
      "resetting env. episode reward total was 11.0. running mean: 3.424182745517921\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4099409180627416\n",
      "resetting env. episode reward total was -1.0. running mean: 3.3658415088821143\n",
      "resetting env. episode reward total was 2.0. running mean: 3.3521830937932933\n",
      "resetting env. episode reward total was 10.0. running mean: 3.4186612628553603\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4244746502268066\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4302299037245385\n",
      "resetting env. episode reward total was 2.0. running mean: 3.415927604687293\n",
      "resetting env. episode reward total was 8.0. running mean: 3.4617683286404204\n",
      "resetting env. episode reward total was 14.0. running mean: 3.5671506453540163\n",
      "resetting env. episode reward total was 2.0. running mean: 3.551479138900476\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6159643475114716\n",
      "resetting env. episode reward total was 2.0. running mean: 3.599804704036357\n",
      "resetting env. episode reward total was 1.0. running mean: 3.573806656995993\n",
      "resetting env. episode reward total was 9.0. running mean: 3.628068590426033\n",
      "resetting env. episode reward total was 5.0. running mean: 3.6417879045217725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -6.0. running mean: 3.5453700254765548\n",
      "resetting env. episode reward total was 7.0. running mean: 3.579916325221789\n",
      "resetting env. episode reward total was 12.0. running mean: 3.664117161969571\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7174759903498753\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7403012304463767\n",
      "resetting env. episode reward total was -3.0. running mean: 3.672898218141913\n",
      "resetting env. episode reward total was -5.0. running mean: 3.586169235960494\n",
      "resetting env. episode reward total was -2.0. running mean: 3.5303075436008893\n",
      "resetting env. episode reward total was 6.0. running mean: 3.5550044681648805\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5394544234832317\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5840598792483993\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6482192804559155\n",
      "resetting env. episode reward total was 10.0. running mean: 3.7117370876513562\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7246197167748423\n",
      "resetting env. episode reward total was -5.0. running mean: 3.637373519607094\n",
      "resetting env. episode reward total was 12.0. running mean: 3.720999784411023\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6937897865669127\n",
      "resetting env. episode reward total was 4.0. running mean: 3.6968518887012434\n",
      "resetting env. episode reward total was 2.0. running mean: 3.679883369814231\n",
      "resetting env. episode reward total was 10.0. running mean: 3.743084536116089\n",
      "resetting env. episode reward total was 7.0. running mean: 3.775653690754928\n",
      "resetting env. episode reward total was 3.0. running mean: 3.7678971538473784\n",
      "resetting env. episode reward total was 1.0. running mean: 3.7402181823089045\n",
      "resetting env. episode reward total was 2.0. running mean: 3.7228160004858153\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7255878404809573\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7783319620761473\n",
      "resetting env. episode reward total was 8.0. running mean: 3.820548642455386\n",
      "resetting env. episode reward total was -4.0. running mean: 3.742343156030832\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7649197244705235\n",
      "resetting env. episode reward total was 3.0. running mean: 3.7572705272258182\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7696978219535597\n",
      "resetting env. episode reward total was 5.0. running mean: 3.782000843734024\n",
      "resetting env. episode reward total was 6.0. running mean: 3.804180835296684\n",
      "resetting env. episode reward total was -9.0. running mean: 3.676139026943717\n",
      "resetting env. episode reward total was 11.0. running mean: 3.74937763667428\n",
      "resetting env. episode reward total was 1.0. running mean: 3.721883860307537\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6746650217044614\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7279183714874167\n",
      "resetting env. episode reward total was -4.0. running mean: 3.6506391877725424\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7041327958948167\n",
      "resetting env. episode reward total was -9.0. running mean: 3.5770914679358685\n",
      "resetting env. episode reward total was -1.0. running mean: 3.53132055325651\n",
      "resetting env. episode reward total was 4.0. running mean: 3.536007347723945\n",
      "resetting env. episode reward total was -6.0. running mean: 3.440647274246705\n",
      "resetting env. episode reward total was 11.0. running mean: 3.516240801504238\n",
      "resetting env. episode reward total was -2.0. running mean: 3.4610783934891955\n",
      "resetting env. episode reward total was -4.0. running mean: 3.3864676095543036\n",
      "resetting env. episode reward total was -1.0. running mean: 3.342602933458761\n",
      "resetting env. episode reward total was -6.0. running mean: 3.249176904124173\n",
      "resetting env. episode reward total was 10.0. running mean: 3.3166851350829316\n",
      "resetting env. episode reward total was 2.0. running mean: 3.303518283732102\n",
      "resetting env. episode reward total was 3.0. running mean: 3.300483100894781\n",
      "resetting env. episode reward total was 12.0. running mean: 3.387478269885833\n",
      "resetting env. episode reward total was 2.0. running mean: 3.3736034871869744\n",
      "resetting env. episode reward total was 12.0. running mean: 3.459867452315105\n",
      "resetting env. episode reward total was 3.0. running mean: 3.4552687777919537\n",
      "resetting env. episode reward total was 9.0. running mean: 3.510716090014034\n",
      "resetting env. episode reward total was 7.0. running mean: 3.5456089291138935\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6101528398227547\n",
      "resetting env. episode reward total was 6.0. running mean: 3.634051311424527\n",
      "resetting env. episode reward total was 13.0. running mean: 3.7277107983102815\n",
      "resetting env. episode reward total was 11.0. running mean: 3.8004336903271785\n",
      "resetting env. episode reward total was 8.0. running mean: 3.8424293534239067\n",
      "resetting env. episode reward total was 2.0. running mean: 3.8240050598896675\n",
      "resetting env. episode reward total was -1.0. running mean: 3.775765009290771\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7980073591978636\n",
      "resetting env. episode reward total was -7.0. running mean: 3.690027285605885\n",
      "resetting env. episode reward total was 3.0. running mean: 3.683127012749826\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6362957426223277\n",
      "resetting env. episode reward total was 4.0. running mean: 3.6399327851961045\n",
      "resetting env. episode reward total was 4.0. running mean: 3.6435334573441436\n",
      "resetting env. episode reward total was -3.0. running mean: 3.5770981227707024\n",
      "resetting env. episode reward total was 11.0. running mean: 3.6513271415429953\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6048138701275656\n",
      "resetting env. episode reward total was -3.0. running mean: 3.53876573142629\n",
      "resetting env. episode reward total was -12.0. running mean: 3.3833780741120267\n",
      "resetting env. episode reward total was 9.0. running mean: 3.4395442933709064\n",
      "resetting env. episode reward total was -1.0. running mean: 3.3951488504371974\n",
      "resetting env. episode reward total was 7.0. running mean: 3.431197361932825\n",
      "resetting env. episode reward total was -3.0. running mean: 3.366885388313497\n",
      "resetting env. episode reward total was 1.0. running mean: 3.3432165344303617\n",
      "resetting env. episode reward total was 12.0. running mean: 3.4297843690860583\n",
      "resetting env. episode reward total was 7.0. running mean: 3.4654865253951974\n",
      "resetting env. episode reward total was 12.0. running mean: 3.5508316601412457\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5553233435398335\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5597701101044352\n",
      "resetting env. episode reward total was 9.0. running mean: 3.6141724090033907\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6480306849133566\n",
      "resetting env. episode reward total was -1.0. running mean: 3.601550378064223\n",
      "resetting env. episode reward total was 5.0. running mean: 3.6155348742835804\n",
      "resetting env. episode reward total was -3.0. running mean: 3.5493795255407448\n",
      "resetting env. episode reward total was 9.0. running mean: 3.603885730285337\n",
      "resetting env. episode reward total was 12.0. running mean: 3.6878468729824836\n",
      "resetting env. episode reward total was -7.0. running mean: 3.580968404252659\n",
      "resetting env. episode reward total was 8.0. running mean: 3.6251587202101323\n",
      "resetting env. episode reward total was 7.0. running mean: 3.658907133008031\n",
      "resetting env. episode reward total was 8.0. running mean: 3.7023180616779507\n",
      "resetting env. episode reward total was -2.0. running mean: 3.6452948810611714\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6188419322505596\n",
      "resetting env. episode reward total was 15.0. running mean: 3.732653512928054\n",
      "resetting env. episode reward total was -15.0. running mean: 3.5453269777987733\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5498737080207854\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5343749709405774\n",
      "resetting env. episode reward total was 13.0. running mean: 3.6290312212311715\n",
      "resetting env. episode reward total was 14.0. running mean: 3.73274090901886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 3.8154134999286713\n",
      "resetting env. episode reward total was -1.0. running mean: 3.7672593649293846\n",
      "resetting env. episode reward total was 7.0. running mean: 3.7995867712800906\n",
      "resetting env. episode reward total was 4.0. running mean: 3.80159090356729\n",
      "resetting env. episode reward total was -3.0. running mean: 3.733574994531617\n",
      "resetting env. episode reward total was 8.0. running mean: 3.776239244586301\n",
      "resetting env. episode reward total was 15.0. running mean: 3.8884768521404376\n",
      "resetting env. episode reward total was 8.0. running mean: 3.9295920836190334\n",
      "resetting env. episode reward total was 11.0. running mean: 4.000296162782843\n",
      "resetting env. episode reward total was 4.0. running mean: 4.0002932011550145\n",
      "resetting env. episode reward total was 8.0. running mean: 4.040290269143465\n",
      "resetting env. episode reward total was 6.0. running mean: 4.059887366452029\n",
      "resetting env. episode reward total was 14.0. running mean: 4.159288492787509\n",
      "resetting env. episode reward total was 9.0. running mean: 4.207695607859633\n",
      "resetting env. episode reward total was 2.0. running mean: 4.185618651781036\n",
      "resetting env. episode reward total was 7.0. running mean: 4.213762465263226\n",
      "resetting env. episode reward total was 6.0. running mean: 4.231624840610594\n",
      "resetting env. episode reward total was 14.0. running mean: 4.329308592204487\n",
      "resetting env. episode reward total was -7.0. running mean: 4.216015506282442\n",
      "resetting env. episode reward total was 2.0. running mean: 4.193855351219617\n",
      "resetting env. episode reward total was -5.0. running mean: 4.101916797707421\n",
      "resetting env. episode reward total was 13.0. running mean: 4.190897629730347\n",
      "resetting env. episode reward total was 11.0. running mean: 4.258988653433043\n",
      "resetting env. episode reward total was -3.0. running mean: 4.186398766898712\n",
      "resetting env. episode reward total was 8.0. running mean: 4.224534779229725\n",
      "resetting env. episode reward total was 17.0. running mean: 4.352289431437428\n",
      "resetting env. episode reward total was 4.0. running mean: 4.348766537123054\n",
      "resetting env. episode reward total was 5.0. running mean: 4.355278871751823\n",
      "resetting env. episode reward total was 4.0. running mean: 4.351726083034305\n",
      "resetting env. episode reward total was 4.0. running mean: 4.348208822203962\n",
      "resetting env. episode reward total was 14.0. running mean: 4.4447267339819225\n",
      "resetting env. episode reward total was 11.0. running mean: 4.510279466642103\n",
      "resetting env. episode reward total was -6.0. running mean: 4.405176671975683\n",
      "resetting env. episode reward total was 8.0. running mean: 4.4411249052559265\n",
      "resetting env. episode reward total was 5.0. running mean: 4.446713656203367\n",
      "resetting env. episode reward total was 4.0. running mean: 4.442246519641333\n",
      "resetting env. episode reward total was 12.0. running mean: 4.51782405444492\n",
      "resetting env. episode reward total was 5.0. running mean: 4.52264581390047\n",
      "resetting env. episode reward total was 6.0. running mean: 4.5374193557614655\n",
      "resetting env. episode reward total was 3.0. running mean: 4.522045162203851\n",
      "resetting env. episode reward total was 6.0. running mean: 4.536824710581811\n",
      "resetting env. episode reward total was 10.0. running mean: 4.591456463475993\n",
      "resetting env. episode reward total was 9.0. running mean: 4.6355418988412325\n",
      "resetting env. episode reward total was 7.0. running mean: 4.659186479852821\n",
      "resetting env. episode reward total was 2.0. running mean: 4.632594615054292\n",
      "resetting env. episode reward total was -4.0. running mean: 4.546268668903749\n",
      "resetting env. episode reward total was 8.0. running mean: 4.580805982214711\n",
      "resetting env. episode reward total was 1.0. running mean: 4.544997922392564\n",
      "resetting env. episode reward total was 5.0. running mean: 4.549547943168638\n",
      "resetting env. episode reward total was -12.0. running mean: 4.384052463736952\n",
      "resetting env. episode reward total was 2.0. running mean: 4.360211939099582\n",
      "resetting env. episode reward total was 8.0. running mean: 4.396609819708586\n",
      "resetting env. episode reward total was 11.0. running mean: 4.4626437215115\n",
      "resetting env. episode reward total was -4.0. running mean: 4.378017284296385\n",
      "resetting env. episode reward total was 13.0. running mean: 4.464237111453421\n",
      "resetting env. episode reward total was 10.0. running mean: 4.519594740338887\n",
      "resetting env. episode reward total was 7.0. running mean: 4.544398792935498\n",
      "resetting env. episode reward total was 7.0. running mean: 4.568954805006143\n",
      "resetting env. episode reward total was -7.0. running mean: 4.453265256956081\n",
      "resetting env. episode reward total was 4.0. running mean: 4.44873260438652\n",
      "resetting env. episode reward total was -3.0. running mean: 4.374245278342655\n",
      "resetting env. episode reward total was -1.0. running mean: 4.320502825559228\n",
      "resetting env. episode reward total was -1.0. running mean: 4.267297797303637\n",
      "resetting env. episode reward total was -3.0. running mean: 4.1946248193306\n",
      "resetting env. episode reward total was 1.0. running mean: 4.162678571137294\n",
      "resetting env. episode reward total was 3.0. running mean: 4.151051785425921\n",
      "resetting env. episode reward total was -1.0. running mean: 4.099541267571661\n",
      "resetting env. episode reward total was -10.0. running mean: 3.9585458548959447\n",
      "resetting env. episode reward total was 1.0. running mean: 3.928960396346985\n",
      "resetting env. episode reward total was 11.0. running mean: 3.999670792383515\n",
      "resetting env. episode reward total was 5.0. running mean: 4.00967408445968\n",
      "resetting env. episode reward total was 16.0. running mean: 4.129577343615082\n",
      "resetting env. episode reward total was -7.0. running mean: 4.018281570178932\n",
      "resetting env. episode reward total was 2.0. running mean: 3.9980987544771422\n",
      "resetting env. episode reward total was 3.0. running mean: 3.9881177669323704\n",
      "resetting env. episode reward total was -11.0. running mean: 3.838236589263047\n",
      "resetting env. episode reward total was 2.0. running mean: 3.8198542233704167\n",
      "resetting env. episode reward total was 3.0. running mean: 3.8116556811367124\n",
      "resetting env. episode reward total was 4.0. running mean: 3.813539124325345\n",
      "resetting env. episode reward total was 9.0. running mean: 3.8654037330820916\n",
      "resetting env. episode reward total was -3.0. running mean: 3.796749695751271\n",
      "resetting env. episode reward total was 9.0. running mean: 3.8487821987937583\n",
      "resetting env. episode reward total was 9.0. running mean: 3.9002943768058205\n",
      "resetting env. episode reward total was -7.0. running mean: 3.7912914330377623\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7933785187073847\n",
      "resetting env. episode reward total was 3.0. running mean: 3.7854447335203107\n",
      "resetting env. episode reward total was 16.0. running mean: 3.907590286185108\n",
      "resetting env. episode reward total was 3.0. running mean: 3.8985143833232567\n",
      "resetting env. episode reward total was -3.0. running mean: 3.829529239490024\n",
      "resetting env. episode reward total was -7.0. running mean: 3.721233947095124\n",
      "resetting env. episode reward total was -4.0. running mean: 3.6440216076241727\n",
      "resetting env. episode reward total was 6.0. running mean: 3.667581391547931\n",
      "resetting env. episode reward total was 6.0. running mean: 3.690905577632452\n",
      "resetting env. episode reward total was 8.0. running mean: 3.7339965218561275\n",
      "resetting env. episode reward total was -12.0. running mean: 3.576656556637566\n",
      "resetting env. episode reward total was -7.0. running mean: 3.4708899910711906\n",
      "resetting env. episode reward total was 7.0. running mean: 3.5061810911604785\n",
      "resetting env. episode reward total was 7.0. running mean: 3.5411192802488736\n",
      "resetting env. episode reward total was -2.0. running mean: 3.4857080874463846\n",
      "resetting env. episode reward total was 5.0. running mean: 3.5008510065719207\n",
      "resetting env. episode reward total was 3.0. running mean: 3.495842496506201\n",
      "resetting env. episode reward total was -4.0. running mean: 3.4208840715411393\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4066752308257278\n",
      "resetting env. episode reward total was 9.0. running mean: 3.4626084785174704\n",
      "resetting env. episode reward total was -3.0. running mean: 3.397982393732296\n",
      "resetting env. episode reward total was 11.0. running mean: 3.474002569794973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 3.4592625440970233\n",
      "resetting env. episode reward total was -11.0. running mean: 3.3146699186560533\n",
      "resetting env. episode reward total was 12.0. running mean: 3.401523219469493\n",
      "resetting env. episode reward total was 11.0. running mean: 3.4775079872747976\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5227329074020495\n",
      "resetting env. episode reward total was -5.0. running mean: 3.4375055783280293\n",
      "resetting env. episode reward total was -8.0. running mean: 3.3231305225447487\n",
      "resetting env. episode reward total was 10.0. running mean: 3.3898992173193014\n",
      "resetting env. episode reward total was -2.0. running mean: 3.3360002251461083\n",
      "resetting env. episode reward total was -1.0. running mean: 3.292640222894647\n",
      "resetting env. episode reward total was 3.0. running mean: 3.2897138206657006\n",
      "resetting env. episode reward total was 9.0. running mean: 3.3468166824590435\n",
      "resetting env. episode reward total was -14.0. running mean: 3.1733485156344527\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1816150304781083\n",
      "resetting env. episode reward total was -3.0. running mean: 3.1197988801733274\n",
      "resetting env. episode reward total was -8.0. running mean: 3.008600891371594\n",
      "resetting env. episode reward total was -11.0. running mean: 2.868514882457878\n",
      "resetting env. episode reward total was -4.0. running mean: 2.7998297336332993\n",
      "resetting env. episode reward total was -4.0. running mean: 2.7318314362969662\n",
      "resetting env. episode reward total was 13.0. running mean: 2.8345131219339965\n",
      "resetting env. episode reward total was 2.0. running mean: 2.8261679907146564\n",
      "resetting env. episode reward total was 6.0. running mean: 2.85790631080751\n",
      "resetting env. episode reward total was -4.0. running mean: 2.7893272476994344\n",
      "resetting env. episode reward total was 10.0. running mean: 2.86143397522244\n",
      "resetting env. episode reward total was -11.0. running mean: 2.722819635470216\n",
      "resetting env. episode reward total was -5.0. running mean: 2.6455914391155138\n",
      "resetting env. episode reward total was 5.0. running mean: 2.6691355247243584\n",
      "resetting env. episode reward total was 5.0. running mean: 2.6924441694771146\n",
      "resetting env. episode reward total was -9.0. running mean: 2.5755197277823436\n",
      "resetting env. episode reward total was -2.0. running mean: 2.52976453050452\n",
      "resetting env. episode reward total was 1.0. running mean: 2.5144668851994747\n",
      "resetting env. episode reward total was -5.0. running mean: 2.43932221634748\n",
      "resetting env. episode reward total was -9.0. running mean: 2.3249289941840057\n",
      "resetting env. episode reward total was -2.0. running mean: 2.2816797042421655\n",
      "resetting env. episode reward total was -5.0. running mean: 2.208862907199744\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2567742781277467\n",
      "resetting env. episode reward total was 10.0. running mean: 2.3342065353464694\n",
      "resetting env. episode reward total was -5.0. running mean: 2.2608644699930047\n",
      "resetting env. episode reward total was -15.0. running mean: 2.088255825293075\n",
      "resetting env. episode reward total was -6.0. running mean: 2.007373267040144\n",
      "resetting env. episode reward total was 8.0. running mean: 2.0672995343697425\n",
      "resetting env. episode reward total was -9.0. running mean: 1.9566265390260449\n",
      "resetting env. episode reward total was 11.0. running mean: 2.0470602736357844\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0065896708994266\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0465237741904323\n",
      "resetting env. episode reward total was 8.0. running mean: 2.106058536448528\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1049979510840426\n",
      "resetting env. episode reward total was -4.0. running mean: 2.043947971573202\n",
      "resetting env. episode reward total was 6.0. running mean: 2.08350849185747\n",
      "resetting env. episode reward total was 1.0. running mean: 2.072673406938895\n",
      "resetting env. episode reward total was -1.0. running mean: 2.041946672869506\n",
      "resetting env. episode reward total was -3.0. running mean: 1.991527206140811\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0116119340794025\n",
      "resetting env. episode reward total was 5.0. running mean: 2.0414958147386084\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9710808565912223\n",
      "resetting env. episode reward total was -1.0. running mean: 1.94137004802531\n",
      "resetting env. episode reward total was -3.0. running mean: 1.891956347545057\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9730367840696064\n",
      "resetting env. episode reward total was 5.0. running mean: 2.0033064162289103\n",
      "resetting env. episode reward total was 4.0. running mean: 2.023273352066621\n",
      "resetting env. episode reward total was 2.0. running mean: 2.023040618545955\n",
      "resetting env. episode reward total was 3.0. running mean: 2.032810212360495\n",
      "resetting env. episode reward total was 11.0. running mean: 2.12248211023689\n",
      "resetting env. episode reward total was -3.0. running mean: 2.0712572891345213\n",
      "resetting env. episode reward total was 7.0. running mean: 2.120544716243176\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0793392690807444\n",
      "resetting env. episode reward total was 8.0. running mean: 2.138545876389937\n",
      "resetting env. episode reward total was -5.0. running mean: 2.067160417626038\n",
      "resetting env. episode reward total was -2.0. running mean: 2.026488813449778\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0162239253152796\n",
      "resetting env. episode reward total was -3.0. running mean: 1.9660616860621267\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9064010692015054\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8673370585094904\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9086636879243954\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9295770510451515\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9902812805347\n",
      "resetting env. episode reward total was 10.0. running mean: 2.070378467729353\n",
      "resetting env. episode reward total was -1.0. running mean: 2.0396746830520596\n",
      "resetting env. episode reward total was 1.0. running mean: 2.029277936221539\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0489851568593234\n",
      "resetting env. episode reward total was -1.0. running mean: 2.01849530529073\n",
      "resetting env. episode reward total was 2.0. running mean: 2.018310352237823\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0181272487154445\n",
      "resetting env. episode reward total was 4.0. running mean: 2.03794597622829\n",
      "resetting env. episode reward total was 2.0. running mean: 2.037566516466007\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0771908513013466\n",
      "resetting env. episode reward total was 2.0. running mean: 2.076418942788333\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0956547533604497\n",
      "resetting env. episode reward total was 2.0. running mean: 2.094698205826845\n",
      "resetting env. episode reward total was 11.0. running mean: 2.1837512237685766\n",
      "resetting env. episode reward total was 11.0. running mean: 2.2719137115308907\n",
      "resetting env. episode reward total was 4.0. running mean: 2.289194574415582\n",
      "resetting env. episode reward total was -2.0. running mean: 2.246302628671426\n",
      "resetting env. episode reward total was 8.0. running mean: 2.303839602384712\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3308012063608645\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3574931942972555\n",
      "resetting env. episode reward total was -7.0. running mean: 2.263918262354283\n",
      "resetting env. episode reward total was 1.0. running mean: 2.25127907973074\n",
      "resetting env. episode reward total was -11.0. running mean: 2.1187662889334327\n",
      "resetting env. episode reward total was -8.0. running mean: 2.017578626044098\n",
      "resetting env. episode reward total was 2.0. running mean: 2.017402839783657\n",
      "resetting env. episode reward total was 7.0. running mean: 2.0672288113858204\n",
      "resetting env. episode reward total was 8.0. running mean: 2.126556523271962\n",
      "resetting env. episode reward total was 5.0. running mean: 2.155290958039242\n",
      "resetting env. episode reward total was 9.0. running mean: 2.2237380484588494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: 2.121500667974261\n",
      "resetting env. episode reward total was 10.0. running mean: 2.2002856612945183\n",
      "resetting env. episode reward total was -8.0. running mean: 2.098282804681573\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0272999766347577\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0170269768684097\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0368567070997257\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0364881400287285\n",
      "resetting env. episode reward total was -1.0. running mean: 2.0061232586284414\n",
      "resetting env. episode reward total was 2.0. running mean: 2.006062026042157\n",
      "resetting env. episode reward total was 7.0. running mean: 2.056001405781735\n",
      "resetting env. episode reward total was -3.0. running mean: 2.005441391723918\n",
      "resetting env. episode reward total was 2.0. running mean: 2.005386977806679\n",
      "resetting env. episode reward total was 13.0. running mean: 2.115333108028612\n",
      "resetting env. episode reward total was 7.0. running mean: 2.1641797769483255\n",
      "resetting env. episode reward total was 7.0. running mean: 2.212537979178842\n",
      "resetting env. episode reward total was 12.0. running mean: 2.3104125993870537\n",
      "resetting env. episode reward total was -5.0. running mean: 2.2373084733931834\n",
      "resetting env. episode reward total was 8.0. running mean: 2.2949353886592516\n",
      "resetting env. episode reward total was 11.0. running mean: 2.381986034772659\n",
      "resetting env. episode reward total was -4.0. running mean: 2.3181661744249324\n",
      "resetting env. episode reward total was -3.0. running mean: 2.2649845126806833\n",
      "resetting env. episode reward total was -2.0. running mean: 2.2223346675538767\n",
      "resetting env. episode reward total was -4.0. running mean: 2.160111320878338\n",
      "resetting env. episode reward total was 1.0. running mean: 2.1485102076695544\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1870251055928587\n",
      "resetting env. episode reward total was 12.0. running mean: 2.28515485453693\n",
      "resetting env. episode reward total was 3.0. running mean: 2.2923033059915605\n",
      "resetting env. episode reward total was -10.0. running mean: 2.1693802729316447\n",
      "resetting env. episode reward total was 5.0. running mean: 2.197686470202328\n",
      "resetting env. episode reward total was 3.0. running mean: 2.2057096055003047\n",
      "resetting env. episode reward total was -9.0. running mean: 2.0936525094453016\n",
      "resetting env. episode reward total was 13.0. running mean: 2.2027159843508484\n",
      "resetting env. episode reward total was -6.0. running mean: 2.1206888245073396\n",
      "resetting env. episode reward total was 9.0. running mean: 2.189481936262266\n",
      "resetting env. episode reward total was 9.0. running mean: 2.2575871168996433\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2250112457306472\n",
      "resetting env. episode reward total was -4.0. running mean: 2.1627611332733405\n",
      "resetting env. episode reward total was 7.0. running mean: 2.211133521940607\n",
      "resetting env. episode reward total was 10.0. running mean: 2.289022186721201\n",
      "resetting env. episode reward total was -2.0. running mean: 2.246131964853989\n",
      "resetting env. episode reward total was -2.0. running mean: 2.203670645205449\n",
      "resetting env. episode reward total was 7.0. running mean: 2.251633938753394\n",
      "resetting env. episode reward total was -2.0. running mean: 2.20911759936586\n",
      "resetting env. episode reward total was 14.0. running mean: 2.3270264233722013\n",
      "resetting env. episode reward total was 7.0. running mean: 2.373756159138479\n",
      "resetting env. episode reward total was 4.0. running mean: 2.3900185975470944\n",
      "resetting env. episode reward total was 6.0. running mean: 2.4261184115716237\n",
      "resetting env. episode reward total was 6.0. running mean: 2.4618572274559076\n",
      "resetting env. episode reward total was 12.0. running mean: 2.5572386551813486\n",
      "resetting env. episode reward total was 1.0. running mean: 2.541666268629535\n",
      "resetting env. episode reward total was 3.0. running mean: 2.546249605943239\n",
      "resetting env. episode reward total was 2.0. running mean: 2.540787109883807\n",
      "resetting env. episode reward total was -6.0. running mean: 2.455379238784969\n",
      "resetting env. episode reward total was -6.0. running mean: 2.3708254463971192\n",
      "resetting env. episode reward total was -3.0. running mean: 2.317117191933148\n",
      "resetting env. episode reward total was 7.0. running mean: 2.3639460200138163\n",
      "resetting env. episode reward total was -11.0. running mean: 2.230306559813678\n",
      "resetting env. episode reward total was -8.0. running mean: 2.1280034942155415\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0567234592733863\n",
      "resetting env. episode reward total was 8.0. running mean: 2.1161562246806525\n",
      "resetting env. episode reward total was -2.0. running mean: 2.074994662433846\n",
      "resetting env. episode reward total was 10.0. running mean: 2.1542447158095075\n",
      "resetting env. episode reward total was 4.0. running mean: 2.1727022686514124\n",
      "resetting env. episode reward total was 7.0. running mean: 2.220975245964898\n",
      "resetting env. episode reward total was -14.0. running mean: 2.058765493505249\n",
      "resetting env. episode reward total was 7.0. running mean: 2.1081778385701964\n",
      "resetting env. episode reward total was 3.0. running mean: 2.1170960601844944\n",
      "resetting env. episode reward total was -1.0. running mean: 2.0859250995826497\n",
      "resetting env. episode reward total was -3.0. running mean: 2.0350658485868234\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0347151901009553\n",
      "resetting env. episode reward total was 12.0. running mean: 2.1343680381999457\n",
      "resetting env. episode reward total was 11.0. running mean: 2.223024357817946\n",
      "resetting env. episode reward total was 9.0. running mean: 2.2907941142397665\n",
      "resetting env. episode reward total was -5.0. running mean: 2.217886173097369\n",
      "resetting env. episode reward total was 5.0. running mean: 2.2457073113663952\n",
      "resetting env. episode reward total was -5.0. running mean: 2.1732502382527312\n",
      "resetting env. episode reward total was -7.0. running mean: 2.081517735870204\n",
      "resetting env. episode reward total was -2.0. running mean: 2.040702558511502\n",
      "resetting env. episode reward total was 2.0. running mean: 2.040295532926387\n",
      "resetting env. episode reward total was 2.0. running mean: 2.039892577597123\n",
      "resetting env. episode reward total was 3.0. running mean: 2.0494936518211517\n",
      "resetting env. episode reward total was 4.0. running mean: 2.06899871530294\n",
      "resetting env. episode reward total was -7.0. running mean: 1.9783087281499105\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9685256408684115\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9088403844597273\n",
      "resetting env. episode reward total was 2.0. running mean: 1.90975198061513\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9706544608089787\n",
      "resetting env. episode reward total was 1.0. running mean: 1.960947916200889\n",
      "resetting env. episode reward total was 7.0. running mean: 2.01133843703888\n",
      "resetting env. episode reward total was 8.0. running mean: 2.071225052668491\n",
      "resetting env. episode reward total was -3.0. running mean: 2.0205128021418064\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0603076741203883\n",
      "resetting env. episode reward total was -3.0. running mean: 2.0097045973791845\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0496075514053924\n",
      "resetting env. episode reward total was 8.0. running mean: 2.1091114758913387\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0980203611324253\n",
      "resetting env. episode reward total was -11.0. running mean: 1.9670401575211007\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9773697559458898\n",
      "resetting env. episode reward total was 2.0. running mean: 1.977596058386431\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9778200978025666\n",
      "resetting env. episode reward total was -5.0. running mean: 1.908041896824541\n",
      "resetting env. episode reward total was -9.0. running mean: 1.7989614778562955\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8409718630777325\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9225621444469552\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8733365230024857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 3.0. running mean: 1.884603157772461\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9657571261947364\n",
      "resetting env. episode reward total was 8.0. running mean: 2.026099554932789\n",
      "resetting env. episode reward total was 1.0. running mean: 2.015838559383461\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0156801737896264\n",
      "resetting env. episode reward total was -8.0. running mean: 1.91552337205173\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9563681383312126\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9968044569479004\n",
      "resetting env. episode reward total was 13.0. running mean: 2.1068364123784216\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0957680482546373\n",
      "resetting env. episode reward total was 7.0. running mean: 2.1448103677720907\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1833622640943697\n",
      "resetting env. episode reward total was 7.0. running mean: 2.231528641453426\n",
      "resetting env. episode reward total was 2.0. running mean: 2.2292133550388917\n",
      "resetting env. episode reward total was 2.0. running mean: 2.226921221488503\n",
      "resetting env. episode reward total was 14.0. running mean: 2.3446520092736183\n",
      "resetting env. episode reward total was 13.0. running mean: 2.451205489180882\n",
      "resetting env. episode reward total was 11.0. running mean: 2.536693434289073\n",
      "resetting env. episode reward total was -6.0. running mean: 2.451326499946182\n",
      "resetting env. episode reward total was -3.0. running mean: 2.3968132349467206\n",
      "resetting env. episode reward total was -4.0. running mean: 2.332845102597253\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3595166515712807\n",
      "resetting env. episode reward total was -5.0. running mean: 2.285921485055568\n",
      "resetting env. episode reward total was 3.0. running mean: 2.293062270205012\n",
      "resetting env. episode reward total was 11.0. running mean: 2.380131647502962\n",
      "resetting env. episode reward total was 13.0. running mean: 2.4863303310279323\n",
      "resetting env. episode reward total was -9.0. running mean: 2.371467027717653\n",
      "resetting env. episode reward total was -5.0. running mean: 2.297752357440477\n",
      "resetting env. episode reward total was 8.0. running mean: 2.354774833866072\n",
      "resetting env. episode reward total was -6.0. running mean: 2.2712270855274115\n",
      "resetting env. episode reward total was -2.0. running mean: 2.2285148146721374\n",
      "resetting env. episode reward total was 11.0. running mean: 2.316229666525416\n",
      "resetting env. episode reward total was -6.0. running mean: 2.2330673698601617\n",
      "resetting env. episode reward total was 7.0. running mean: 2.28073669616156\n",
      "resetting env. episode reward total was -5.0. running mean: 2.2079293291999447\n",
      "resetting env. episode reward total was -7.0. running mean: 2.1158500359079455\n",
      "resetting env. episode reward total was 5.0. running mean: 2.144691535548866\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1832446201933773\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1814121739914434\n",
      "resetting env. episode reward total was 13.0. running mean: 2.2895980522515287\n",
      "resetting env. episode reward total was 9.0. running mean: 2.3567020717290132\n",
      "resetting env. episode reward total was 1.0. running mean: 2.343135051011723\n",
      "resetting env. episode reward total was -2.0. running mean: 2.2997037005016057\n",
      "resetting env. episode reward total was 6.0. running mean: 2.3367066634965896\n",
      "resetting env. episode reward total was 3.0. running mean: 2.3433395968616235\n",
      "resetting env. episode reward total was -4.0. running mean: 2.279906200893007\n",
      "resetting env. episode reward total was 6.0. running mean: 2.317107138884077\n",
      "resetting env. episode reward total was 6.0. running mean: 2.3539360674952365\n",
      "resetting env. episode reward total was 5.0. running mean: 2.380396706820284\n",
      "resetting env. episode reward total was -7.0. running mean: 2.286592739752081\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2537268123545604\n",
      "resetting env. episode reward total was 5.0. running mean: 2.2811895442310144\n",
      "resetting env. episode reward total was 2.0. running mean: 2.2783776487887044\n",
      "resetting env. episode reward total was 11.0. running mean: 2.3655938723008174\n",
      "resetting env. episode reward total was 3.0. running mean: 2.3719379335778092\n",
      "resetting env. episode reward total was 4.0. running mean: 2.388218554242031\n",
      "resetting env. episode reward total was -5.0. running mean: 2.314336368699611\n",
      "resetting env. episode reward total was -2.0. running mean: 2.2711930050126146\n",
      "resetting env. episode reward total was 8.0. running mean: 2.3284810749624887\n",
      "resetting env. episode reward total was -8.0. running mean: 2.2251962642128635\n",
      "resetting env. episode reward total was -10.0. running mean: 2.102944301570735\n",
      "resetting env. episode reward total was 2.0. running mean: 2.101914858555028\n",
      "resetting env. episode reward total was 7.0. running mean: 2.150895709969477\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0793867528697825\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0085928853410846\n",
      "resetting env. episode reward total was 3.0. running mean: 2.018506956487674\n",
      "resetting env. episode reward total was 2.0. running mean: 2.018321886922797\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0081386680535687\n",
      "resetting env. episode reward total was 1.0. running mean: 1.998057281373033\n",
      "resetting env. episode reward total was 8.0. running mean: 2.0580767085593026\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0974959414737095\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0965209820589723\n",
      "resetting env. episode reward total was 3.0. running mean: 2.1055557722383824\n",
      "resetting env. episode reward total was 10.0. running mean: 2.1845002145159986\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2326552123708385\n",
      "resetting env. episode reward total was 1.0. running mean: 2.2203286602471297\n",
      "resetting env. episode reward total was -5.0. running mean: 2.1481253736446586\n",
      "resetting env. episode reward total was 1.0. running mean: 2.136644119908212\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1752776787091297\n",
      "resetting env. episode reward total was 10.0. running mean: 2.2535249019220385\n",
      "resetting env. episode reward total was 1.0. running mean: 2.240989652902818\n",
      "resetting env. episode reward total was -8.0. running mean: 2.13857975637379\n",
      "resetting env. episode reward total was -2.0. running mean: 2.097193958810052\n",
      "resetting env. episode reward total was -4.0. running mean: 2.0362220192219516\n",
      "resetting env. episode reward total was 8.0. running mean: 2.095859799029732\n",
      "resetting env. episode reward total was -1.0. running mean: 2.0649012010394348\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9942521890290406\n",
      "resetting env. episode reward total was -3.0. running mean: 1.94430966713875\n",
      "resetting env. episode reward total was 10.0. running mean: 2.0248665704673625\n",
      "resetting env. episode reward total was -2.0. running mean: 1.9846179047626888\n",
      "resetting env. episode reward total was 3.0. running mean: 1.994771725715062\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9648240084579112\n",
      "resetting env. episode reward total was 8.0. running mean: 2.025175768373332\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0249240106895985\n",
      "resetting env. episode reward total was 12.0. running mean: 2.1246747705827027\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0834280228768756\n",
      "resetting env. episode reward total was -5.0. running mean: 2.012593742648107\n",
      "resetting env. episode reward total was -2.0. running mean: 1.9724678052216258\n",
      "resetting env. episode reward total was 5.0. running mean: 2.0027431271694094\n",
      "resetting env. episode reward total was -8.0. running mean: 1.9027156958977152\n",
      "resetting env. episode reward total was 5.0. running mean: 1.933688538938738\n",
      "resetting env. episode reward total was -4.0. running mean: 1.8743516535493505\n",
      "resetting env. episode reward total was -5.0. running mean: 1.805608137013857\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9075520556437184\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9384765350872812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 1.9590917697364085\n",
      "resetting env. episode reward total was -6.0. running mean: 1.8795008520390444\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8307058435186538\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7623987850834673\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6947747972326326\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6278270492603062\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5415487787677031\n",
      "resetting env. episode reward total was 3.0. running mean: 1.556133290980026\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6105719580702258\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5744662384895236\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6487215761046283\n",
      "resetting env. episode reward total was 6.0. running mean: 1.692234360343582\n",
      "resetting env. episode reward total was 12.0. running mean: 1.7953120167401462\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8073588965727447\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7992853076070172\n",
      "resetting env. episode reward total was 14.0. running mean: 1.9212924545309469\n",
      "resetting env. episode reward total was 12.0. running mean: 2.0220795299856373\n",
      "resetting env. episode reward total was -1.0. running mean: 1.991858734685781\n",
      "resetting env. episode reward total was -4.0. running mean: 1.931940147338923\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8826207458655337\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9437945384068784\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9143565930228097\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8852130270925815\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9163608968216557\n",
      "resetting env. episode reward total was 9.0. running mean: 1.9871972878534392\n",
      "resetting env. episode reward total was -7.0. running mean: 1.8973253149749048\n",
      "resetting env. episode reward total was 11.0. running mean: 1.9883520618251558\n",
      "resetting env. episode reward total was 8.0. running mean: 2.0484685412069044\n",
      "resetting env. episode reward total was -11.0. running mean: 1.9179838557948352\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9588040172368868\n",
      "resetting env. episode reward total was 12.0. running mean: 2.0592159770645178\n",
      "resetting env. episode reward total was 9.0. running mean: 2.1286238172938723\n",
      "resetting env. episode reward total was 1.0. running mean: 2.1173375791209335\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0461642033297243\n",
      "resetting env. episode reward total was -8.0. running mean: 1.945702561296427\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9562455356834627\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8866830803266281\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8578162495233619\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8992380870281282\n",
      "resetting env. episode reward total was 4.0. running mean: 1.920245706157847\n",
      "resetting env. episode reward total was -6.0. running mean: 1.8410432490962685\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7726328166053058\n",
      "resetting env. episode reward total was -15.0. running mean: 1.6049064884392528\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5188574235548602\n",
      "resetting env. episode reward total was -2.0. running mean: 1.4836688493193115\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4388321608261183\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4844438392178572\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4195994008256785\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3554034068174217\n",
      "resetting env. episode reward total was -4.0. running mean: 1.3018493727492475\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3588308790217551\n",
      "resetting env. episode reward total was -15.0. running mean: 1.1952425702315377\n",
      "resetting env. episode reward total was -9.0. running mean: 1.0932901445292222\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0923572430839301\n",
      "resetting env. episode reward total was 2.0. running mean: 1.1014336706530907\n",
      "resetting env. episode reward total was -6.0. running mean: 1.0304193339465597\n",
      "resetting env. episode reward total was -5.0. running mean: 0.970115140607094\n",
      "resetting env. episode reward total was -8.0. running mean: 0.8804139892010231\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8416098493090128\n",
      "resetting env. episode reward total was -7.0. running mean: 0.7631937508159228\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8155618133077636\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7774061951746859\n",
      "resetting env. episode reward total was -9.0. running mean: 0.679632133222939\n",
      "resetting env. episode reward total was -6.0. running mean: 0.6128358118907096\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6367074537718025\n",
      "resetting env. episode reward total was 9.0. running mean: 0.7203403792340844\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6431369754417435\n",
      "resetting env. episode reward total was -1.0. running mean: 0.626705605687326\n",
      "resetting env. episode reward total was -8.0. running mean: 0.5404385496304528\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5250341641341483\n",
      "resetting env. episode reward total was -4.0. running mean: 0.47978382249280677\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4649859842678787\n",
      "resetting env. episode reward total was -11.0. running mean: 0.3503361244251999\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3168327631809479\n",
      "resetting env. episode reward total was -8.0. running mean: 0.2336644355491384\n",
      "resetting env. episode reward total was 4.0. running mean: 0.271327791193647\n",
      "resetting env. episode reward total was 3.0. running mean: 0.2986145132817105\n",
      "resetting env. episode reward total was -1.0. running mean: 0.2856283681488934\n",
      "resetting env. episode reward total was 9.0. running mean: 0.3727720844674045\n",
      "resetting env. episode reward total was -8.0. running mean: 0.28904436362273045\n",
      "resetting env. episode reward total was 4.0. running mean: 0.3261539199865031\n",
      "resetting env. episode reward total was -4.0. running mean: 0.2828923807866381\n",
      "resetting env. episode reward total was 1.0. running mean: 0.2900634569787717\n",
      "resetting env. episode reward total was 6.0. running mean: 0.347162822408984\n",
      "resetting env. episode reward total was 12.0. running mean: 0.46369119418489413\n",
      "resetting env. episode reward total was -7.0. running mean: 0.38905428224304517\n",
      "resetting env. episode reward total was 10.0. running mean: 0.48516373942061475\n",
      "resetting env. episode reward total was 5.0. running mean: 0.5303121020264087\n",
      "resetting env. episode reward total was -11.0. running mean: 0.4150089810061446\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5008588911960832\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5258503022841223\n",
      "resetting env. episode reward total was -9.0. running mean: 0.4305917992612811\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4462858812686683\n",
      "resetting env. episode reward total was 1.0. running mean: 0.4518230224559816\n",
      "resetting env. episode reward total was -9.0. running mean: 0.35730479223142175\n",
      "resetting env. episode reward total was -5.0. running mean: 0.30373174430910754\n",
      "resetting env. episode reward total was -10.0. running mean: 0.20069442686601643\n",
      "resetting env. episode reward total was 7.0. running mean: 0.2686874825973563\n",
      "resetting env. episode reward total was 1.0. running mean: 0.27600060777138274\n",
      "resetting env. episode reward total was -11.0. running mean: 0.16324060169366894\n",
      "resetting env. episode reward total was 6.0. running mean: 0.22160819567673226\n",
      "resetting env. episode reward total was -10.0. running mean: 0.11939211371996494\n",
      "resetting env. episode reward total was -6.0. running mean: 0.05819819258276529\n",
      "resetting env. episode reward total was 4.0. running mean: 0.09761621065693764\n",
      "resetting env. episode reward total was -5.0. running mean: 0.046640048550368254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 0.11617364806486458\n",
      "resetting env. episode reward total was 15.0. running mean: 0.26501191158421594\n",
      "resetting env. episode reward total was -7.0. running mean: 0.19236179246837376\n",
      "resetting env. episode reward total was 8.0. running mean: 0.27043817454369\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3177337927982531\n",
      "resetting env. episode reward total was 4.0. running mean: 0.35455645487027054\n",
      "resetting env. episode reward total was -5.0. running mean: 0.30101089032156786\n",
      "resetting env. episode reward total was 12.0. running mean: 0.4180007814183522\n",
      "resetting env. episode reward total was -4.0. running mean: 0.37382077360416865\n",
      "resetting env. episode reward total was 5.0. running mean: 0.420082565868127\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5058817402094457\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5808229228073511\n",
      "resetting env. episode reward total was -13.0. running mean: 0.4450146935792776\n",
      "resetting env. episode reward total was -3.0. running mean: 0.41056454664348485\n",
      "resetting env. episode reward total was 3.0. running mean: 0.43645890117705\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4220943121652795\n",
      "resetting env. episode reward total was -6.0. running mean: 0.3578733690436267\n",
      "resetting env. episode reward total was 12.0. running mean: 0.47429463535319044\n",
      "resetting env. episode reward total was -2.0. running mean: 0.4495516889996585\n",
      "resetting env. episode reward total was 4.0. running mean: 0.4850561721096619\n",
      "resetting env. episode reward total was -8.0. running mean: 0.4002056103885653\n",
      "resetting env. episode reward total was 8.0. running mean: 0.47620355428467964\n",
      "resetting env. episode reward total was -10.0. running mean: 0.37144151874183284\n",
      "resetting env. episode reward total was -11.0. running mean: 0.2577271035544145\n",
      "resetting env. episode reward total was 10.0. running mean: 0.35514983251887033\n",
      "resetting env. episode reward total was -3.0. running mean: 0.32159833419368167\n",
      "resetting env. episode reward total was 12.0. running mean: 0.4383823508517448\n",
      "resetting env. episode reward total was -3.0. running mean: 0.4039985273432274\n",
      "resetting env. episode reward total was 5.0. running mean: 0.4499585420697951\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4354589566490971\n",
      "resetting env. episode reward total was 3.0. running mean: 0.46110436708260616\n",
      "resetting env. episode reward total was 1.0. running mean: 0.4664933234117801\n",
      "resetting env. episode reward total was -9.0. running mean: 0.37182839017766234\n",
      "resetting env. episode reward total was 7.0. running mean: 0.4381101062758857\n",
      "resetting env. episode reward total was -5.0. running mean: 0.38372900521312686\n",
      "resetting env. episode reward total was 4.0. running mean: 0.41989171516099555\n",
      "resetting env. episode reward total was -16.0. running mean: 0.2556927980093856\n",
      "resetting env. episode reward total was -1.0. running mean: 0.2431358700292917\n",
      "resetting env. episode reward total was 14.0. running mean: 0.3807045113289988\n",
      "resetting env. episode reward total was -9.0. running mean: 0.2868974662157088\n",
      "resetting env. episode reward total was -1.0. running mean: 0.2740284915535517\n",
      "resetting env. episode reward total was 2.0. running mean: 0.2912882066380162\n",
      "resetting env. episode reward total was 7.0. running mean: 0.358375324571636\n",
      "resetting env. episode reward total was 6.0. running mean: 0.41479157132591965\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4306436556126605\n",
      "resetting env. episode reward total was 4.0. running mean: 0.46633721905653386\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4516738468659685\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5271571083973088\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5818855373133356\n",
      "resetting env. episode reward total was -12.0. running mean: 0.4560666819402023\n",
      "resetting env. episode reward total was 5.0. running mean: 0.5015060151208003\n",
      "resetting env. episode reward total was -6.0. running mean: 0.4364909549695923\n",
      "resetting env. episode reward total was 10.0. running mean: 0.5321260454198964\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5668047849656974\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5311367371160404\n",
      "resetting env. episode reward total was -13.0. running mean: 0.3958253697448799\n",
      "resetting env. episode reward total was 7.0. running mean: 0.46186711604743114\n",
      "resetting env. episode reward total was 10.0. running mean: 0.5572484448869568\n",
      "resetting env. episode reward total was 2.0. running mean: 0.5716759604380872\n",
      "resetting env. episode reward total was -15.0. running mean: 0.4159592008337063\n",
      "resetting env. episode reward total was -4.0. running mean: 0.3717996088253693\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3180816127371156\n",
      "resetting env. episode reward total was 2.0. running mean: 0.3349007966097445\n",
      "resetting env. episode reward total was -8.0. running mean: 0.251551788643647\n",
      "resetting env. episode reward total was 4.0. running mean: 0.28903627075721056\n",
      "resetting env. episode reward total was -2.0. running mean: 0.26614590804963845\n",
      "resetting env. episode reward total was 7.0. running mean: 0.3334844489691421\n",
      "resetting env. episode reward total was 4.0. running mean: 0.37014960447945067\n",
      "resetting env. episode reward total was -8.0. running mean: 0.2864481084346561\n",
      "resetting env. episode reward total was -5.0. running mean: 0.23358362735030958\n",
      "resetting env. episode reward total was 7.0. running mean: 0.3012477910768065\n",
      "resetting env. episode reward total was -8.0. running mean: 0.2182353131660384\n",
      "resetting env. episode reward total was -3.0. running mean: 0.18605296003437802\n",
      "resetting env. episode reward total was -1.0. running mean: 0.17419243043403423\n",
      "resetting env. episode reward total was -1.0. running mean: 0.1624505061296939\n",
      "resetting env. episode reward total was -5.0. running mean: 0.11082600106839695\n",
      "resetting env. episode reward total was 3.0. running mean: 0.13971774105771298\n",
      "resetting env. episode reward total was 3.0. running mean: 0.16832056364713585\n",
      "resetting env. episode reward total was 5.0. running mean: 0.21663735801066447\n",
      "resetting env. episode reward total was 7.0. running mean: 0.28447098443055785\n",
      "resetting env. episode reward total was 7.0. running mean: 0.3516262745862523\n",
      "resetting env. episode reward total was -5.0. running mean: 0.29811001184038977\n",
      "resetting env. episode reward total was 8.0. running mean: 0.37512891172198587\n",
      "resetting env. episode reward total was 9.0. running mean: 0.461377622604766\n",
      "resetting env. episode reward total was -1.0. running mean: 0.44676384637871835\n",
      "resetting env. episode reward total was 5.0. running mean: 0.49229620791493117\n",
      "resetting env. episode reward total was -8.0. running mean: 0.4073732458357818\n",
      "resetting env. episode reward total was 2.0. running mean: 0.423299513377424\n",
      "resetting env. episode reward total was 1.0. running mean: 0.4290665182436498\n",
      "resetting env. episode reward total was 7.0. running mean: 0.4947758530612133\n",
      "resetting env. episode reward total was -7.0. running mean: 0.41982809453060116\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5256298135852951\n",
      "resetting env. episode reward total was -6.0. running mean: 0.4603735154494422\n",
      "resetting env. episode reward total was -5.0. running mean: 0.4057697802949478\n",
      "resetting env. episode reward total was -1.0. running mean: 0.39171208249199835\n",
      "resetting env. episode reward total was -6.0. running mean: 0.3277949616670784\n",
      "resetting env. episode reward total was 9.0. running mean: 0.4145170120504076\n",
      "resetting env. episode reward total was -15.0. running mean: 0.2603718419299035\n",
      "resetting env. episode reward total was -4.0. running mean: 0.21776812351060446\n",
      "resetting env. episode reward total was 8.0. running mean: 0.2955904422754984\n",
      "resetting env. episode reward total was -6.0. running mean: 0.2326345378527434\n",
      "resetting env. episode reward total was -8.0. running mean: 0.15030819247421595\n",
      "resetting env. episode reward total was 1.0. running mean: 0.1588051105494738\n",
      "resetting env. episode reward total was 6.0. running mean: 0.21721705944397907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: 0.16504488884953927\n",
      "resetting env. episode reward total was -1.0. running mean: 0.15339443996104388\n",
      "resetting env. episode reward total was 3.0. running mean: 0.18186049556143344\n",
      "resetting env. episode reward total was -12.0. running mean: 0.060041890605819104\n",
      "resetting env. episode reward total was 3.0. running mean: 0.08944147169976091\n",
      "resetting env. episode reward total was -1.0. running mean: 0.0785470569827633\n",
      "resetting env. episode reward total was -2.0. running mean: 0.05776158641293566\n",
      "resetting env. episode reward total was 3.0. running mean: 0.0871839705488063\n",
      "resetting env. episode reward total was -11.0. running mean: -0.023687869156681765\n",
      "resetting env. episode reward total was -7.0. running mean: -0.09345099046511496\n",
      "resetting env. episode reward total was 10.0. running mean: 0.007483519439536193\n",
      "resetting env. episode reward total was 5.0. running mean: 0.05740868424514083\n",
      "resetting env. episode reward total was -4.0. running mean: 0.016834597402689423\n",
      "resetting env. episode reward total was -10.0. running mean: -0.08333374857133748\n",
      "resetting env. episode reward total was -13.0. running mean: -0.21250041108562412\n",
      "resetting env. episode reward total was -2.0. running mean: -0.23037540697476785\n",
      "resetting env. episode reward total was -13.0. running mean: -0.3580716529050202\n",
      "resetting env. episode reward total was 5.0. running mean: -0.30449093637596997\n",
      "resetting env. episode reward total was 7.0. running mean: -0.23144602701221023\n",
      "resetting env. episode reward total was -13.0. running mean: -0.3591315667420881\n",
      "resetting env. episode reward total was 7.0. running mean: -0.28554025107466724\n",
      "resetting env. episode reward total was 6.0. running mean: -0.22268484856392057\n",
      "resetting env. episode reward total was -4.0. running mean: -0.26045800007828135\n",
      "resetting env. episode reward total was 5.0. running mean: -0.20785342007749852\n",
      "resetting env. episode reward total was -16.0. running mean: -0.3657748858767235\n",
      "resetting env. episode reward total was -7.0. running mean: -0.4321171370179563\n",
      "resetting env. episode reward total was -5.0. running mean: -0.4777959656477767\n",
      "resetting env. episode reward total was -6.0. running mean: -0.533018005991299\n",
      "resetting env. episode reward total was 4.0. running mean: -0.487687825931386\n",
      "resetting env. episode reward total was 9.0. running mean: -0.39281094767207214\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3588828381953514\n",
      "resetting env. episode reward total was 8.0. running mean: -0.27529400981339786\n",
      "resetting env. episode reward total was -13.0. running mean: -0.4025410697152639\n",
      "resetting env. episode reward total was 3.0. running mean: -0.36851565901811123\n",
      "resetting env. episode reward total was -3.0. running mean: -0.39483050242793016\n",
      "resetting env. episode reward total was -6.0. running mean: -0.4508821974036509\n",
      "resetting env. episode reward total was -1.0. running mean: -0.45637337542961437\n",
      "resetting env. episode reward total was -3.0. running mean: -0.48180964167531826\n",
      "resetting env. episode reward total was 6.0. running mean: -0.4169915452585651\n",
      "resetting env. episode reward total was -5.0. running mean: -0.4628216298059794\n",
      "resetting env. episode reward total was 1.0. running mean: -0.4481934135079196\n",
      "resetting env. episode reward total was -7.0. running mean: -0.5137114793728403\n",
      "resetting env. episode reward total was -1.0. running mean: -0.518574364579112\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5033886209333208\n",
      "resetting env. episode reward total was -7.0. running mean: -0.5683547347239877\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5926711873767478\n",
      "resetting env. episode reward total was -6.0. running mean: -0.6467444755029803\n",
      "resetting env. episode reward total was 3.0. running mean: -0.6102770307479505\n",
      "resetting env. episode reward total was -3.0. running mean: -0.634174260440471\n",
      "resetting env. episode reward total was -10.0. running mean: -0.7278325178360663\n",
      "resetting env. episode reward total was -8.0. running mean: -0.8005541926577056\n",
      "resetting env. episode reward total was -11.0. running mean: -0.9025486507311284\n",
      "resetting env. episode reward total was -2.0. running mean: -0.9135231642238172\n",
      "resetting env. episode reward total was -9.0. running mean: -0.994387932581579\n",
      "resetting env. episode reward total was 3.0. running mean: -0.9544440532557632\n",
      "resetting env. episode reward total was 1.0. running mean: -0.9348996127232055\n",
      "resetting env. episode reward total was -2.0. running mean: -0.9455506165959735\n",
      "resetting env. episode reward total was -12.0. running mean: -1.0560951104300138\n",
      "resetting env. episode reward total was -9.0. running mean: -1.1355341593257138\n",
      "resetting env. episode reward total was -1.0. running mean: -1.1341788177324565\n",
      "resetting env. episode reward total was -8.0. running mean: -1.202837029555132\n",
      "resetting env. episode reward total was -6.0. running mean: -1.2508086592595808\n",
      "resetting env. episode reward total was 13.0. running mean: -1.1083005726669852\n",
      "resetting env. episode reward total was -13.0. running mean: -1.2272175669403156\n",
      "resetting env. episode reward total was 9.0. running mean: -1.1249453912709124\n",
      "resetting env. episode reward total was -10.0. running mean: -1.2136959373582035\n",
      "resetting env. episode reward total was 1.0. running mean: -1.1915589779846214\n",
      "resetting env. episode reward total was 4.0. running mean: -1.1396433882047752\n",
      "resetting env. episode reward total was 14.0. running mean: -0.9882469543227274\n",
      "resetting env. episode reward total was 10.0. running mean: -0.8783644847795001\n",
      "resetting env. episode reward total was 11.0. running mean: -0.7595808399317051\n",
      "resetting env. episode reward total was 2.0. running mean: -0.731985031532388\n",
      "resetting env. episode reward total was 12.0. running mean: -0.6046651812170641\n",
      "resetting env. episode reward total was 9.0. running mean: -0.5086185294048935\n",
      "resetting env. episode reward total was 3.0. running mean: -0.47353234411084455\n",
      "resetting env. episode reward total was 3.0. running mean: -0.43879702066973614\n",
      "resetting env. episode reward total was 6.0. running mean: -0.3744090504630388\n",
      "resetting env. episode reward total was -1.0. running mean: -0.38066495995840843\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3468583103588243\n",
      "resetting env. episode reward total was -2.0. running mean: -0.3633897272552361\n",
      "resetting env. episode reward total was 7.0. running mean: -0.28975582998268373\n",
      "resetting env. episode reward total was 6.0. running mean: -0.22685827168285688\n",
      "resetting env. episode reward total was 4.0. running mean: -0.18458968896602831\n",
      "resetting env. episode reward total was -3.0. running mean: -0.21274379207636804\n",
      "resetting env. episode reward total was 3.0. running mean: -0.18061635415560437\n",
      "resetting env. episode reward total was 1.0. running mean: -0.1688101906140483\n",
      "resetting env. episode reward total was 2.0. running mean: -0.14712208870790783\n",
      "resetting env. episode reward total was -4.0. running mean: -0.18565086782082876\n",
      "resetting env. episode reward total was -6.0. running mean: -0.24379435914262046\n",
      "resetting env. episode reward total was 2.0. running mean: -0.22135641555119426\n",
      "resetting env. episode reward total was 10.0. running mean: -0.11914285139568231\n",
      "resetting env. episode reward total was 8.0. running mean: -0.03795142288172548\n",
      "resetting env. episode reward total was -8.0. running mean: -0.11757190865290823\n",
      "resetting env. episode reward total was -1.0. running mean: -0.12639618956637916\n",
      "resetting env. episode reward total was -13.0. running mean: -0.25513222767071536\n",
      "resetting env. episode reward total was 7.0. running mean: -0.18258090539400817\n",
      "resetting env. episode reward total was -8.0. running mean: -0.2607550963400681\n",
      "resetting env. episode reward total was 5.0. running mean: -0.2081475453766674\n",
      "resetting env. episode reward total was 2.0. running mean: -0.18606606992290076\n",
      "resetting env. episode reward total was -13.0. running mean: -0.31420540922367174\n",
      "resetting env. episode reward total was -10.0. running mean: -0.411063355131435\n",
      "resetting env. episode reward total was -10.0. running mean: -0.5069527215801206\n",
      "resetting env. episode reward total was 10.0. running mean: -0.4018831943643194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: -0.30786436242067616\n",
      "resetting env. episode reward total was 1.0. running mean: -0.29478571879646936\n",
      "resetting env. episode reward total was -4.0. running mean: -0.33183786160850465\n",
      "resetting env. episode reward total was 8.0. running mean: -0.2485194829924196\n",
      "resetting env. episode reward total was 1.0. running mean: -0.2360342881624954\n",
      "resetting env. episode reward total was 1.0. running mean: -0.22367394528087042\n",
      "resetting env. episode reward total was 10.0. running mean: -0.12143720582806172\n",
      "resetting env. episode reward total was 2.0. running mean: -0.1002228337697811\n",
      "resetting env. episode reward total was 1.0. running mean: -0.0892206054320833\n",
      "resetting env. episode reward total was 11.0. running mean: 0.02167160062223754\n",
      "resetting env. episode reward total was 2.0. running mean: 0.04145488461601517\n",
      "resetting env. episode reward total was -13.0. running mean: -0.08895966423014498\n",
      "resetting env. episode reward total was 5.0. running mean: -0.03807006758784352\n",
      "resetting env. episode reward total was -6.0. running mean: -0.09768936691196509\n",
      "resetting env. episode reward total was -6.0. running mean: -0.15671247324284543\n",
      "resetting env. episode reward total was -6.0. running mean: -0.21514534851041697\n",
      "resetting env. episode reward total was -2.0. running mean: -0.23299389502531279\n",
      "resetting env. episode reward total was 4.0. running mean: -0.19066395607505965\n",
      "resetting env. episode reward total was -13.0. running mean: -0.31875731651430905\n",
      "resetting env. episode reward total was -11.0. running mean: -0.4255697433491659\n",
      "resetting env. episode reward total was -9.0. running mean: -0.5113140459156742\n",
      "resetting env. episode reward total was 3.0. running mean: -0.4762009054565174\n",
      "resetting env. episode reward total was 1.0. running mean: -0.4614388964019522\n",
      "resetting env. episode reward total was 4.0. running mean: -0.4168245074379327\n",
      "resetting env. episode reward total was -9.0. running mean: -0.5026562623635533\n",
      "resetting env. episode reward total was 12.0. running mean: -0.3776296997399178\n",
      "resetting env. episode reward total was -11.0. running mean: -0.4838534027425186\n",
      "resetting env. episode reward total was 7.0. running mean: -0.4090148687150934\n",
      "resetting env. episode reward total was 8.0. running mean: -0.3249247200279424\n",
      "resetting env. episode reward total was 3.0. running mean: -0.29167547282766304\n",
      "resetting env. episode reward total was 10.0. running mean: -0.1887587180993864\n",
      "resetting env. episode reward total was 2.0. running mean: -0.16687113091839256\n",
      "resetting env. episode reward total was 4.0. running mean: -0.12520241960920864\n",
      "resetting env. episode reward total was 8.0. running mean: -0.043950395413116544\n",
      "resetting env. episode reward total was -7.0. running mean: -0.11351089145898538\n",
      "resetting env. episode reward total was -2.0. running mean: -0.13237578254439553\n",
      "resetting env. episode reward total was 3.0. running mean: -0.10105202471895158\n",
      "resetting env. episode reward total was 3.0. running mean: -0.07004150447176206\n",
      "resetting env. episode reward total was -7.0. running mean: -0.13934108942704446\n",
      "resetting env. episode reward total was -5.0. running mean: -0.187947678532774\n",
      "resetting env. episode reward total was -5.0. running mean: -0.23606820174744625\n",
      "resetting env. episode reward total was 9.0. running mean: -0.14370751972997178\n",
      "resetting env. episode reward total was 3.0. running mean: -0.11227044453267207\n",
      "resetting env. episode reward total was -2.0. running mean: -0.13114774008734534\n",
      "resetting env. episode reward total was -3.0. running mean: -0.15983626268647189\n",
      "resetting env. episode reward total was 14.0. running mean: -0.018237900059607154\n",
      "resetting env. episode reward total was 3.0. running mean: 0.011944478940988917\n",
      "resetting env. episode reward total was 8.0. running mean: 0.09182503415157903\n",
      "resetting env. episode reward total was 2.0. running mean: 0.11090678381006323\n",
      "resetting env. episode reward total was -3.0. running mean: 0.0797977159719626\n",
      "resetting env. episode reward total was -9.0. running mean: -0.01100026118775703\n",
      "resetting env. episode reward total was 11.0. running mean: 0.09910974142412055\n",
      "resetting env. episode reward total was 6.0. running mean: 0.15811864400987935\n",
      "resetting env. episode reward total was 2.0. running mean: 0.17653745756978054\n",
      "resetting env. episode reward total was 1.0. running mean: 0.18477208299408274\n",
      "resetting env. episode reward total was 5.0. running mean: 0.23292436216414192\n",
      "resetting env. episode reward total was 9.0. running mean: 0.3205951185425005\n",
      "resetting env. episode reward total was 3.0. running mean: 0.3473891673570755\n",
      "resetting env. episode reward total was 11.0. running mean: 0.4539152756835047\n",
      "resetting env. episode reward total was 1.0. running mean: 0.4593761229266697\n",
      "resetting env. episode reward total was 12.0. running mean: 0.574782361697403\n",
      "resetting env. episode reward total was -11.0. running mean: 0.45903453808042904\n",
      "resetting env. episode reward total was 7.0. running mean: 0.5244441926996248\n",
      "resetting env. episode reward total was -4.0. running mean: 0.4791997507726286\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5844077532649024\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5885636757322533\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5126780389749308\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5375512585851815\n",
      "resetting env. episode reward total was -5.0. running mean: 0.4821757459993297\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5373539885393364\n",
      "resetting env. episode reward total was -7.0. running mean: 0.461980448653943\n",
      "resetting env. episode reward total was -2.0. running mean: 0.43736064416740356\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4529870377257295\n",
      "resetting env. episode reward total was 10.0. running mean: 0.5484571673484723\n",
      "resetting env. episode reward total was 8.0. running mean: 0.6229725956749875\n",
      "resetting env. episode reward total was 7.0. running mean: 0.6867428697182376\n",
      "resetting env. episode reward total was 9.0. running mean: 0.7698754410210552\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7521766866108447\n",
      "resetting env. episode reward total was -9.0. running mean: 0.6546549197447362\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6181083705472888\n",
      "resetting env. episode reward total was 6.0. running mean: 0.671927286841816\n",
      "resetting env. episode reward total was 8.0. running mean: 0.7452080139733979\n",
      "resetting env. episode reward total was 11.0. running mean: 0.8477559338336639\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8792783744953273\n",
      "resetting env. episode reward total was -1.0. running mean: 0.860485590750374\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8018807348428703\n",
      "resetting env. episode reward total was 11.0. running mean: 0.9038619274944415\n",
      "resetting env. episode reward total was 10.0. running mean: 0.994823308219497\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9648750751373021\n",
      "resetting env. episode reward total was -5.0. running mean: 0.905226324385929\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9661740611420697\n",
      "resetting env. episode reward total was -5.0. running mean: 0.906512320530649\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9174471973253425\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9882727253520891\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0283899980985682\n",
      "resetting env. episode reward total was 15.0. running mean: 1.1681060981175824\n",
      "resetting env. episode reward total was 8.0. running mean: 1.2364250371364065\n",
      "resetting env. episode reward total was -1.0. running mean: 1.2140607867650424\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1719201788973919\n",
      "resetting env. episode reward total was 13.0. running mean: 1.2902009771084177\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3772989673373337\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3335259776639603\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4001907178873207\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3661888107084474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 9.0. running mean: 1.442526922601363\n",
      "resetting env. episode reward total was -4.0. running mean: 1.3881016533753494\n",
      "resetting env. episode reward total was -1.0. running mean: 1.364220636841596\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3005784304731798\n",
      "resetting env. episode reward total was -1.0. running mean: 1.277572646168448\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3047969197067635\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3717489505096958\n",
      "resetting env. episode reward total was 7.0. running mean: 1.428031461004599\n",
      "resetting env. episode reward total was 1.0. running mean: 1.423751146394553\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4795136349306075\n",
      "resetting env. episode reward total was -6.0. running mean: 1.4047184985813013\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3806713135954882\n",
      "resetting env. episode reward total was -16.0. running mean: 1.2068646004595334\n",
      "resetting env. episode reward total was -4.0. running mean: 1.154795954454938\n",
      "resetting env. episode reward total was 2.0. running mean: 1.1632479949103887\n",
      "resetting env. episode reward total was 8.0. running mean: 1.2316155149612849\n",
      "resetting env. episode reward total was -1.0. running mean: 1.209299359811672\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2472063662135553\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2947343025514197\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3517869595259056\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2882690899306464\n",
      "resetting env. episode reward total was 5.0. running mean: 1.32538639903134\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3221325350410265\n",
      "resetting env. episode reward total was 14.0. running mean: 1.4489112096906163\n",
      "resetting env. episode reward total was -6.0. running mean: 1.37442209759371\n",
      "resetting env. episode reward total was -3.0. running mean: 1.330677876617773\n",
      "resetting env. episode reward total was -5.0. running mean: 1.267371097851595\n",
      "resetting env. episode reward total was -3.0. running mean: 1.224697386873079\n",
      "resetting env. episode reward total was 13.0. running mean: 1.3424504130043484\n",
      "resetting env. episode reward total was 11.0. running mean: 1.439025908874305\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4146356497855619\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4504892932877063\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3859844003548292\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3021245563512809\n",
      "resetting env. episode reward total was -3.0. running mean: 1.259103310787768\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3265122776798903\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3232471549030915\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2600146833540606\n",
      "resetting env. episode reward total was 14.0. running mean: 1.3874145365205202\n",
      "resetting env. episode reward total was -11.0. running mean: 1.263540391155315\n",
      "resetting env. episode reward total was -3.0. running mean: 1.2209049872437616\n",
      "resetting env. episode reward total was -12.0. running mean: 1.088695937371324\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1478089779976108\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1763308882176347\n",
      "resetting env. episode reward total was -4.0. running mean: 1.1245675793354584\n",
      "resetting env. episode reward total was 11.0. running mean: 1.223321903542104\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1610886845066828\n",
      "resetting env. episode reward total was 6.0. running mean: 1.209477797661616\n",
      "resetting env. episode reward total was 2.0. running mean: 1.217383019685\n",
      "resetting env. episode reward total was -1.0. running mean: 1.19520918948815\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2732570975932687\n",
      "resetting env. episode reward total was -4.0. running mean: 1.220524526617336\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2283192813511625\n",
      "resetting env. episode reward total was -14.0. running mean: 1.0760360885376508\n",
      "resetting env. episode reward total was -4.0. running mean: 1.0252757276522741\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9950229703757514\n",
      "resetting env. episode reward total was 4.0. running mean: 1.025072740671994\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9648220132652741\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9351737931326213\n",
      "resetting env. episode reward total was 2.0. running mean: 0.945822055201295\n",
      "resetting env. episode reward total was 4.0. running mean: 0.9763638346492821\n",
      "resetting env. episode reward total was -3.0. running mean: 0.9366001963027892\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9772341943397613\n",
      "resetting env. episode reward total was 9.0. running mean: 1.0574618523963637\n",
      "resetting env. episode reward total was 9.0. running mean: 1.1368872338724\n",
      "resetting env. episode reward total was 11.0. running mean: 1.2355183615336762\n",
      "resetting env. episode reward total was -2.0. running mean: 1.2031631779183394\n",
      "resetting env. episode reward total was -1.0. running mean: 1.181131546139156\n",
      "resetting env. episode reward total was -6.0. running mean: 1.1093202306777645\n",
      "resetting env. episode reward total was 15.0. running mean: 1.2482270283709869\n",
      "resetting env. episode reward total was -10.0. running mean: 1.1357447580872768\n",
      "resetting env. episode reward total was -1.0. running mean: 1.114387310506404\n",
      "resetting env. episode reward total was 8.0. running mean: 1.1832434374013399\n",
      "resetting env. episode reward total was 8.0. running mean: 1.2514110030273264\n",
      "resetting env. episode reward total was 9.0. running mean: 1.3288968929970533\n",
      "resetting env. episode reward total was 13.0. running mean: 1.4456079240670827\n",
      "resetting env. episode reward total was -9.0. running mean: 1.3411518448264117\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4077403263781476\n",
      "resetting env. episode reward total was 5.0. running mean: 1.443662923114366\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4392262938832223\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4548340309443901\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4502856906349462\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4057828337285967\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4017250053913106\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3977077553373976\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3537306777840235\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3901933710061833\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3462914372961214\n",
      "resetting env. episode reward total was -8.0. running mean: 1.2528285229231602\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2603002376939285\n",
      "resetting env. episode reward total was 1.0. running mean: 1.2576972353169893\n",
      "resetting env. episode reward total was -1.0. running mean: 1.2351202629638194\n",
      "resetting env. episode reward total was 11.0. running mean: 1.3327690603341813\n",
      "resetting env. episode reward total was -7.0. running mean: 1.2494413697308393\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1869469560335308\n",
      "resetting env. episode reward total was -4.0. running mean: 1.1350774864731954\n",
      "resetting env. episode reward total was 12.0. running mean: 1.2437267116084634\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2712894444923788\n",
      "resetting env. episode reward total was 4.0. running mean: 1.298576550047455\n",
      "resetting env. episode reward total was -7.0. running mean: 1.2155907845469804\n",
      "resetting env. episode reward total was -7.0. running mean: 1.1334348767015106\n",
      "resetting env. episode reward total was 2.0. running mean: 1.1421005279344953\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1706795226551505\n",
      "resetting env. episode reward total was -9.0. running mean: 1.068972727428599\n",
      "resetting env. episode reward total was 10.0. running mean: 1.158283000154313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: 1.11670017015277\n",
      "resetting env. episode reward total was 11.0. running mean: 1.2155331684512423\n",
      "resetting env. episode reward total was 1.0. running mean: 1.2133778367667298\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2212440583990625\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1790316178150717\n",
      "resetting env. episode reward total was 4.0. running mean: 1.207241301636921\n",
      "resetting env. episode reward total was -4.0. running mean: 1.1551688886205518\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1836171997343463\n",
      "resetting env. episode reward total was 6.0. running mean: 1.231781027737003\n",
      "resetting env. episode reward total was -9.0. running mean: 1.1294632174596329\n",
      "resetting env. episode reward total was -7.0. running mean: 1.0481685852850364\n",
      "resetting env. episode reward total was -13.0. running mean: 0.907686899432186\n",
      "resetting env. episode reward total was 8.0. running mean: 0.978610030437864\n",
      "resetting env. episode reward total was -8.0. running mean: 0.8888239301334854\n",
      "resetting env. episode reward total was 16.0. running mean: 1.0399356908321504\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0395363339238288\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0391409705845904\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0587495608787445\n",
      "resetting env. episode reward total was -5.0. running mean: 0.998162065269957\n",
      "resetting env. episode reward total was -11.0. running mean: 0.8781804446172574\n",
      "resetting env. episode reward total was -7.0. running mean: 0.7993986401710849\n",
      "resetting env. episode reward total was 5.0. running mean: 0.841404653769374\n",
      "resetting env. episode reward total was -9.0. running mean: 0.7429906072316803\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7055607011593634\n",
      "resetting env. episode reward total was 10.0. running mean: 0.7985050941477697\n",
      "resetting env. episode reward total was 3.0. running mean: 0.820520043206292\n",
      "resetting env. episode reward total was -2.0. running mean: 0.792314842774229\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7343916943464867\n",
      "resetting env. episode reward total was -9.0. running mean: 0.6370477774030218\n",
      "resetting env. episode reward total was 6.0. running mean: 0.6906772996289916\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6537705266327016\n",
      "resetting env. episode reward total was -2.0. running mean: 0.6272328213663746\n",
      "resetting env. episode reward total was 7.0. running mean: 0.6909604931527109\n",
      "resetting env. episode reward total was 13.0. running mean: 0.8140508882211838\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8159103793389719\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8177512755455822\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8395737627901264\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8911780251622252\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8622662449106029\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8436435824614968\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8152071466368819\n",
      "resetting env. episode reward total was 2.0. running mean: 0.827055075170513\n",
      "resetting env. episode reward total was 7.0. running mean: 0.888784524418808\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9598966791746198\n",
      "resetting env. episode reward total was -8.0. running mean: 0.8702977123828737\n",
      "resetting env. episode reward total was -7.0. running mean: 0.7915947352590449\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8136787879064544\n",
      "resetting env. episode reward total was -7.0. running mean: 0.7355420000273898\n",
      "resetting env. episode reward total was 7.0. running mean: 0.798186580027116\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8702047142268448\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9215026670845763\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8622876404137305\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9236647640095932\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9644281163694973\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9447838352058023\n",
      "resetting env. episode reward total was -7.0. running mean: 0.8653359968537444\n",
      "resetting env. episode reward total was 7.0. running mean: 0.926682636885207\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9774158105163548\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9276416524111912\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9783652358870794\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0385815835282086\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0881957676929266\n",
      "resetting env. episode reward total was 10.0. running mean: 1.1773138100159974\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2155406719158375\n",
      "resetting env. episode reward total was 2.0. running mean: 1.223385265196679\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2511514125447123\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2886398984192653\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3157534994350726\n",
      "resetting env. episode reward total was 3.0. running mean: 1.332595964440722\n",
      "resetting env. episode reward total was 9.0. running mean: 1.4092700047963147\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4451773047483516\n",
      "resetting env. episode reward total was 4.0. running mean: 1.470725531700868\n",
      "resetting env. episode reward total was 12.0. running mean: 1.5760182763838593\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6202580936200208\n",
      "resetting env. episode reward total was -6.0. running mean: 1.5440555126838205\n",
      "resetting env. episode reward total was -4.0. running mean: 1.4886149575569823\n",
      "resetting env. episode reward total was -8.0. running mean: 1.3937288079814123\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3997915199015982\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3157936047025822\n",
      "resetting env. episode reward total was -1.0. running mean: 1.2926356686555565\n",
      "resetting env. episode reward total was -3.0. running mean: 1.2497093119690008\n",
      "resetting env. episode reward total was -9.0. running mean: 1.1472122188493108\n",
      "resetting env. episode reward total was 8.0. running mean: 1.2157400966608178\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1735826956942097\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1518468687372676\n",
      "resetting env. episode reward total was -9.0. running mean: 1.050328400049895\n",
      "resetting env. episode reward total was 8.0. running mean: 1.119825116049396\n",
      "resetting env. episode reward total was 8.0. running mean: 1.188626864888902\n",
      "resetting env. episode reward total was 4.0. running mean: 1.216740596240013\n",
      "resetting env. episode reward total was 2.0. running mean: 1.224573190277613\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1823274583748367\n",
      "resetting env. episode reward total was -14.0. running mean: 1.0305041837910882\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0301991419531773\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9498971505336455\n",
      "resetting env. episode reward total was -3.0. running mean: 0.910398179028309\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8912941972380259\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8723812552656457\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9436574427129892\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9542208682858594\n",
      "resetting env. episode reward total was 19.0. running mean: 1.1346786596030007\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1633318730069708\n",
      "resetting env. episode reward total was 7.0. running mean: 1.2216985542769012\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2394815687341323\n",
      "resetting env. episode reward total was -14.0. running mean: 1.087086753046791\n",
      "resetting env. episode reward total was -8.0. running mean: 0.9962158855163231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: 0.9762537266611598\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0164911893945483\n",
      "resetting env. episode reward total was 10.0. running mean: 1.1063262775006029\n",
      "resetting env. episode reward total was -7.0. running mean: 1.0252630147255968\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0550103845783407\n",
      "resetting env. episode reward total was -4.0. running mean: 1.0044602807325573\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0444156779252318\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0639715211459795\n",
      "resetting env. episode reward total was 13.0. running mean: 1.1833318059345195\n",
      "resetting env. episode reward total was 1.0. running mean: 1.1814984878751742\n",
      "resetting env. episode reward total was 1.0. running mean: 1.1796835029964226\n",
      "resetting env. episode reward total was -13.0. running mean: 1.0378866679664585\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0875078012867938\n",
      "resetting env. episode reward total was 14.0. running mean: 1.2166327232739258\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2244663960411866\n",
      "resetting env. episode reward total was -1.0. running mean: 1.2022217320807747\n",
      "resetting env. episode reward total was 3.0. running mean: 1.220199514759967\n",
      "resetting env. episode reward total was -3.0. running mean: 1.177997519612367\n",
      "resetting env. episode reward total was -8.0. running mean: 1.0862175444162434\n",
      "resetting env. episode reward total was 5.0. running mean: 1.125355368972081\n",
      "resetting env. episode reward total was 10.0. running mean: 1.2141018152823602\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2619607971295366\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2993411891582411\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3463477772666588\n",
      "resetting env. episode reward total was 3.0. running mean: 1.3628842994939923\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3992554564990525\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3152629019340618\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3221102729147212\n",
      "resetting env. episode reward total was 4.0. running mean: 1.348889170185574\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3454002784837182\n",
      "resetting env. episode reward total was -5.0. running mean: 1.281946275698881\n",
      "resetting env. episode reward total was 9.0. running mean: 1.3591268129418923\n",
      "resetting env. episode reward total was -15.0. running mean: 1.1955355448124734\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2135801893643487\n",
      "resetting env. episode reward total was 7.0. running mean: 1.2714443874707053\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3587299435959983\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3251426441600382\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3018912177184379\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3688723055412535\n",
      "resetting env. episode reward total was 6.0. running mean: 1.415183582485841\n",
      "resetting env. episode reward total was 11.0. running mean: 1.5110317466609826\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5659214291943728\n",
      "resetting env. episode reward total was 2.0. running mean: 1.570262214902429\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5645595927534046\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6289139968258706\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5426248568576117\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5871986082890357\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5313266222061452\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5260133559840838\n",
      "resetting env. episode reward total was 7.0. running mean: 1.580753222424243\n",
      "resetting env. episode reward total was 12.0. running mean: 1.6849456902000006\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6580962332980005\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6315152709650205\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6352001182553704\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6888481170728167\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6419596359020885\n",
      "resetting env. episode reward total was -8.0. running mean: 1.5455400395430676\n",
      "resetting env. episode reward total was 8.0. running mean: 1.610084639147637\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5839837927561606\n",
      "resetting env. episode reward total was -2.0. running mean: 1.548143954828599\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5526625152803128\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5671358901275096\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5914645312262345\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5455498859139722\n",
      "resetting env. episode reward total was -11.0. running mean: 1.4200943870548324\n",
      "resetting env. episode reward total was -7.0. running mean: 1.335893443184284\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3425345087524412\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3891091636649169\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4152180720282677\n",
      "resetting env. episode reward total was -3.0. running mean: 1.371065891307985\n",
      "resetting env. episode reward total was -11.0. running mean: 1.247355232394905\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2848816800709562\n",
      "resetting env. episode reward total was -7.0. running mean: 1.2020328632702466\n",
      "resetting env. episode reward total was -1.0. running mean: 1.180012534637544\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1182124092911685\n",
      "resetting env. episode reward total was 6.0. running mean: 1.1670302851982568\n",
      "resetting env. episode reward total was 10.0. running mean: 1.2553599823462742\n",
      "resetting env. episode reward total was 1.0. running mean: 1.2528063825228115\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1902783186975834\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1283755355106075\n",
      "resetting env. episode reward total was 3.0. running mean: 1.1470917801555014\n",
      "resetting env. episode reward total was -8.0. running mean: 1.0556208623539463\n",
      "resetting env. episode reward total was 8.0. running mean: 1.1250646537304068\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1538140071931027\n",
      "resetting env. episode reward total was -13.0. running mean: 1.0122758671211716\n",
      "resetting env. episode reward total was 10.0. running mean: 1.1021531084499598\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1611315773654602\n",
      "resetting env. episode reward total was -9.0. running mean: 1.0595202615918056\n",
      "resetting env. episode reward total was -4.0. running mean: 1.0089250589758874\n",
      "resetting env. episode reward total was 8.0. running mean: 1.0788358083861285\n",
      "resetting env. episode reward total was -8.0. running mean: 0.9880474503022673\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0181669757992446\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0579853060412523\n",
      "resetting env. episode reward total was 4.0. running mean: 1.08740545298084\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0465313984510314\n",
      "resetting env. episode reward total was 1.0. running mean: 1.046066084466521\n",
      "resetting env. episode reward total was 1.0. running mean: 1.045605423621856\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0751493693856373\n",
      "resetting env. episode reward total was -4.0. running mean: 1.0243978756917809\n",
      "resetting env. episode reward total was -13.0. running mean: 0.8841538969348631\n",
      "resetting env. episode reward total was -8.0. running mean: 0.7953123579655145\n",
      "resetting env. episode reward total was -15.0. running mean: 0.6373592343858593\n",
      "resetting env. episode reward total was -4.0. running mean: 0.5909856420420007\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6150757856215807\n",
      "resetting env. episode reward total was 4.0. running mean: 0.648925027765365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: 0.6124357774877113\n",
      "resetting env. episode reward total was 8.0. running mean: 0.6863114197128342\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6094483055157058\n",
      "resetting env. episode reward total was 6.0. running mean: 0.6633538224605489\n",
      "resetting env. episode reward total was -6.0. running mean: 0.5967202842359434\n",
      "resetting env. episode reward total was 1.0. running mean: 0.600753081393584\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5447455505796481\n",
      "resetting env. episode reward total was -4.0. running mean: 0.49929809507385164\n",
      "resetting env. episode reward total was -10.0. running mean: 0.3943051141231131\n",
      "resetting env. episode reward total was 7.0. running mean: 0.460362062981882\n",
      "resetting env. episode reward total was -3.0. running mean: 0.42575844235206317\n",
      "resetting env. episode reward total was 6.0. running mean: 0.4815008579285425\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4666858493492571\n",
      "resetting env. episode reward total was -3.0. running mean: 0.43201899085576456\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3776988009472069\n",
      "resetting env. episode reward total was 5.0. running mean: 0.42392181293773484\n",
      "resetting env. episode reward total was -9.0. running mean: 0.3296825948083575\n",
      "resetting env. episode reward total was -9.0. running mean: 0.23638576886027393\n",
      "resetting env. episode reward total was 9.0. running mean: 0.3240219111716712\n",
      "resetting env. episode reward total was -8.0. running mean: 0.24078169205995442\n",
      "resetting env. episode reward total was 11.0. running mean: 0.34837387513935486\n",
      "resetting env. episode reward total was 2.0. running mean: 0.3648901363879613\n",
      "resetting env. episode reward total was 9.0. running mean: 0.45124123502408164\n",
      "resetting env. episode reward total was 1.0. running mean: 0.45672882267384085\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5421615344471025\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5067399191026314\n",
      "resetting env. episode reward total was 13.0. running mean: 0.6316725199116051\n",
      "resetting env. episode reward total was 8.0. running mean: 0.705355794712489\n",
      "resetting env. episode reward total was -9.0. running mean: 0.6083022367653641\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6322192143977104\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6658970222537334\n",
      "resetting env. episode reward total was 8.0. running mean: 0.739238052031196\n",
      "resetting env. episode reward total was 5.0. running mean: 0.781845671510884\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8240272147957752\n",
      "resetting env. episode reward total was 15.0. running mean: 0.9657869426478175\n",
      "resetting env. episode reward total was -8.0. running mean: 0.8761290732213394\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9573677824891259\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9377941046642346\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8784161636175922\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8996320019814164\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9806356819616021\n",
      "resetting env. episode reward total was -2.0. running mean: 0.950829325141986\n",
      "resetting env. episode reward total was -8.0. running mean: 0.8613210318905662\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9427078215716604\n",
      "resetting env. episode reward total was 14.0. running mean: 1.073280743355944\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1025479359223844\n",
      "resetting env. episode reward total was 10.0. running mean: 1.1915224565631606\n",
      "resetting env. episode reward total was -11.0. running mean: 1.069607231997529\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0489111596775536\n",
      "resetting env. episode reward total was -1.0. running mean: 1.028422048080778\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0081378275999702\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0280564493239703\n",
      "resetting env. episode reward total was -12.0. running mean: 0.8977758848307306\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9787981259824232\n",
      "resetting env. episode reward total was 5.0. running mean: 1.019010144722599\n",
      "resetting env. episode reward total was 8.0. running mean: 1.088820043275373\n",
      "resetting env. episode reward total was -8.0. running mean: 0.9979318428426193\n",
      "resetting env. episode reward total was 5.0. running mean: 1.037952524414193\n",
      "resetting env. episode reward total was -12.0. running mean: 0.9075729991700511\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9484972691783506\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9590122964865672\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9594221735217014\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9998279517864844\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0598296722686196\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1192313755459333\n",
      "resetting env. episode reward total was 15.0. running mean: 1.258039061790474\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3454586711725693\n",
      "resetting env. episode reward total was 3.0. running mean: 1.3620040844608436\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4083840436162351\n",
      "resetting env. episode reward total was -8.0. running mean: 1.3143002031800728\n",
      "resetting env. episode reward total was -7.0. running mean: 1.231157201148272\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2388456291367893\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2764571728454215\n",
      "resetting env. episode reward total was 12.0. running mean: 1.3836926011169672\n",
      "resetting env. episode reward total was 9.0. running mean: 1.4598556751057976\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5152571183547396\n",
      "resetting env. episode reward total was -6.0. running mean: 1.4401045471711922\n",
      "resetting env. episode reward total was 11.0. running mean: 1.5357035016994804\n",
      "resetting env. episode reward total was 5.0. running mean: 1.5703464666824856\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5246430020156607\n",
      "resetting env. episode reward total was -1.0. running mean: 1.499396571995504\n",
      "resetting env. episode reward total was 2.0. running mean: 1.504402606275549\n",
      "resetting env. episode reward total was 14.0. running mean: 1.6293585802127932\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5830649944106652\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5872343444665584\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6413620010218928\n",
      "resetting env. episode reward total was 8.0. running mean: 1.704948381011674\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7578988972015572\n",
      "resetting env. episode reward total was 8.0. running mean: 1.8203199082295418\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8421167091472463\n",
      "resetting env. episode reward total was 12.0. running mean: 1.943695542055774\n",
      "resetting env. episode reward total was -4.0. running mean: 1.8842585866352162\n",
      "resetting env. episode reward total was -3.0. running mean: 1.835416000768864\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8270618407611754\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7787912223535636\n",
      "resetting env. episode reward total was 13.0. running mean: 1.8910033101300279\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8420932770287275\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9036723442584402\n",
      "resetting env. episode reward total was 10.0. running mean: 1.984635620815856\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9147892646076974\n",
      "resetting env. episode reward total was 14.0. running mean: 2.03564137196162\n",
      "resetting env. episode reward total was 8.0. running mean: 2.095284958242004\n",
      "resetting env. episode reward total was -6.0. running mean: 2.0143321086595836\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9841887875729878\n",
      "resetting env. episode reward total was 10.0. running mean: 2.064346899697258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 16.0. running mean: 2.2037034307002856\n",
      "resetting env. episode reward total was 3.0. running mean: 2.2116663963932828\n",
      "resetting env. episode reward total was 9.0. running mean: 2.27954973242935\n",
      "resetting env. episode reward total was 2.0. running mean: 2.2767542351050563\n",
      "resetting env. episode reward total was 2.0. running mean: 2.2739866927540056\n",
      "resetting env. episode reward total was 7.0. running mean: 2.3212468258264654\n",
      "resetting env. episode reward total was 4.0. running mean: 2.3380343575682008\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3346540139925187\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3313074738525934\n",
      "resetting env. episode reward total was 9.0. running mean: 2.3979943991140673\n",
      "resetting env. episode reward total was 4.0. running mean: 2.414014455122927\n",
      "resetting env. episode reward total was -13.0. running mean: 2.2598743105716976\n",
      "resetting env. episode reward total was 6.0. running mean: 2.297275567465981\n",
      "resetting env. episode reward total was 15.0. running mean: 2.424302811791321\n",
      "resetting env. episode reward total was -2.0. running mean: 2.3800597836734076\n",
      "resetting env. episode reward total was 6.0. running mean: 2.4162591858366738\n",
      "resetting env. episode reward total was -2.0. running mean: 2.372096593978307\n",
      "resetting env. episode reward total was -7.0. running mean: 2.278375628038524\n",
      "resetting env. episode reward total was 7.0. running mean: 2.3255918717581383\n",
      "resetting env. episode reward total was -7.0. running mean: 2.232335953040557\n",
      "resetting env. episode reward total was -13.0. running mean: 2.0800125935101517\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9992124675750502\n",
      "resetting env. episode reward total was 5.0. running mean: 2.0292203428992996\n",
      "resetting env. episode reward total was -7.0. running mean: 1.9389281394703064\n",
      "resetting env. episode reward total was -6.0. running mean: 1.8595388580756034\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8709434694948472\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8822340347998987\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9634116944518998\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9537775775073807\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9442398017323068\n",
      "resetting env. episode reward total was 12.0. running mean: 2.0447974037149836\n",
      "resetting env. episode reward total was -3.0. running mean: 1.9943494296778337\n",
      "resetting env. episode reward total was 7.0. running mean: 2.044405935381055\n",
      "resetting env. episode reward total was 10.0. running mean: 2.1239618760272445\n",
      "resetting env. episode reward total was 3.0. running mean: 2.132722257266972\n",
      "resetting env. episode reward total was 8.0. running mean: 2.191395034694302\n",
      "resetting env. episode reward total was 5.0. running mean: 2.219481084347359\n",
      "resetting env. episode reward total was 2.0. running mean: 2.2172862735038854\n",
      "resetting env. episode reward total was 2.0. running mean: 2.2151134107688466\n",
      "resetting env. episode reward total was 6.0. running mean: 2.252962276661158\n",
      "resetting env. episode reward total was 9.0. running mean: 2.3204326538945463\n",
      "resetting env. episode reward total was 9.0. running mean: 2.3872283273556008\n",
      "resetting env. episode reward total was 4.0. running mean: 2.4033560440820447\n",
      "resetting env. episode reward total was 6.0. running mean: 2.439322483641224\n",
      "resetting env. episode reward total was 1.0. running mean: 2.424929258804812\n",
      "resetting env. episode reward total was 8.0. running mean: 2.480679966216764\n",
      "resetting env. episode reward total was -1.0. running mean: 2.4458731665545965\n",
      "resetting env. episode reward total was -1.0. running mean: 2.4114144348890507\n",
      "resetting env. episode reward total was 1.0. running mean: 2.39730029054016\n",
      "resetting env. episode reward total was 11.0. running mean: 2.4833272876347583\n",
      "resetting env. episode reward total was -8.0. running mean: 2.378494014758411\n",
      "resetting env. episode reward total was 4.0. running mean: 2.3947090746108266\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3907619838647185\n",
      "resetting env. episode reward total was 7.0. running mean: 2.436854364026071\n",
      "resetting env. episode reward total was -1.0. running mean: 2.4024858203858104\n",
      "resetting env. episode reward total was 6.0. running mean: 2.4384609621819524\n",
      "resetting env. episode reward total was 5.0. running mean: 2.4640763525601326\n",
      "resetting env. episode reward total was -3.0. running mean: 2.4094355890345316\n",
      "resetting env. episode reward total was 5.0. running mean: 2.435341233144186\n",
      "resetting env. episode reward total was 6.0. running mean: 2.470987820812744\n",
      "resetting env. episode reward total was -6.0. running mean: 2.3862779426046163\n",
      "resetting env. episode reward total was 14.0. running mean: 2.5024151631785703\n",
      "resetting env. episode reward total was -2.0. running mean: 2.4573910115467847\n",
      "resetting env. episode reward total was 4.0. running mean: 2.4728171014313167\n",
      "resetting env. episode reward total was -4.0. running mean: 2.4080889304170037\n",
      "resetting env. episode reward total was 4.0. running mean: 2.4240080411128337\n",
      "resetting env. episode reward total was 9.0. running mean: 2.4897679607017054\n",
      "resetting env. episode reward total was 13.0. running mean: 2.594870281094688\n",
      "resetting env. episode reward total was 1.0. running mean: 2.578921578283741\n",
      "resetting env. episode reward total was 8.0. running mean: 2.6331323625009038\n",
      "resetting env. episode reward total was 14.0. running mean: 2.746801038875895\n",
      "resetting env. episode reward total was 9.0. running mean: 2.809333028487136\n",
      "resetting env. episode reward total was 8.0. running mean: 2.8612396982022643\n",
      "resetting env. episode reward total was 12.0. running mean: 2.9526273012202418\n",
      "resetting env. episode reward total was -10.0. running mean: 2.8231010282080393\n",
      "resetting env. episode reward total was -4.0. running mean: 2.754870017925959\n",
      "resetting env. episode reward total was 3.0. running mean: 2.757321317746699\n",
      "resetting env. episode reward total was -8.0. running mean: 2.6497481045692317\n",
      "resetting env. episode reward total was 6.0. running mean: 2.6832506235235396\n",
      "resetting env. episode reward total was 9.0. running mean: 2.746418117288304\n",
      "resetting env. episode reward total was -6.0. running mean: 2.658953936115421\n",
      "resetting env. episode reward total was 8.0. running mean: 2.7123643967542668\n",
      "resetting env. episode reward total was 2.0. running mean: 2.705240752786724\n",
      "resetting env. episode reward total was -6.0. running mean: 2.6181883452588566\n",
      "resetting env. episode reward total was 5.0. running mean: 2.6420064618062677\n",
      "resetting env. episode reward total was 5.0. running mean: 2.665586397188205\n",
      "resetting env. episode reward total was 3.0. running mean: 2.6689305332163227\n",
      "resetting env. episode reward total was 4.0. running mean: 2.6822412278841594\n",
      "resetting env. episode reward total was 6.0. running mean: 2.715418815605318\n",
      "resetting env. episode reward total was -5.0. running mean: 2.638264627449265\n",
      "resetting env. episode reward total was 12.0. running mean: 2.7318819811747725\n",
      "resetting env. episode reward total was 5.0. running mean: 2.754563161363025\n",
      "resetting env. episode reward total was 2.0. running mean: 2.7470175297493946\n",
      "resetting env. episode reward total was 16.0. running mean: 2.879547354451901\n",
      "resetting env. episode reward total was 8.0. running mean: 2.930751880907382\n",
      "resetting env. episode reward total was 1.0. running mean: 2.911444362098308\n",
      "resetting env. episode reward total was -10.0. running mean: 2.782329918477325\n",
      "resetting env. episode reward total was 10.0. running mean: 2.854506619292552\n",
      "resetting env. episode reward total was 8.0. running mean: 2.9059615530996266\n",
      "resetting env. episode reward total was 1.0. running mean: 2.8869019375686302\n",
      "resetting env. episode reward total was 4.0. running mean: 2.898032918192944\n",
      "resetting env. episode reward total was 9.0. running mean: 2.9590525890110144\n",
      "resetting env. episode reward total was -4.0. running mean: 2.889462063120904\n",
      "resetting env. episode reward total was 3.0. running mean: 2.890567442489695\n",
      "resetting env. episode reward total was 6.0. running mean: 2.9216617680647983\n",
      "resetting env. episode reward total was 1.0. running mean: 2.90244515038415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 2.9134206988803086\n",
      "resetting env. episode reward total was 11.0. running mean: 2.9942864918915055\n",
      "resetting env. episode reward total was 3.0. running mean: 2.99434362697259\n",
      "resetting env. episode reward total was 6.0. running mean: 3.024400190702864\n",
      "resetting env. episode reward total was 14.0. running mean: 3.134156188795836\n",
      "resetting env. episode reward total was 14.0. running mean: 3.2428146269078777\n",
      "resetting env. episode reward total was -1.0. running mean: 3.200386480638799\n",
      "resetting env. episode reward total was 3.0. running mean: 3.198382615832411\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2163987896740864\n",
      "resetting env. episode reward total was 10.0. running mean: 3.2842348017773455\n",
      "resetting env. episode reward total was 9.0. running mean: 3.341392453759572\n",
      "resetting env. episode reward total was 9.0. running mean: 3.397978529221976\n",
      "resetting env. episode reward total was 5.0. running mean: 3.4139987439297563\n",
      "resetting env. episode reward total was 1.0. running mean: 3.3898587564904585\n",
      "resetting env. episode reward total was -10.0. running mean: 3.255960168925554\n",
      "resetting env. episode reward total was -10.0. running mean: 3.123400567236298\n",
      "resetting env. episode reward total was -8.0. running mean: 3.012166561563935\n",
      "resetting env. episode reward total was 5.0. running mean: 3.0320448959482955\n",
      "resetting env. episode reward total was 12.0. running mean: 3.1217244469888126\n",
      "resetting env. episode reward total was -2.0. running mean: 3.0705072025189244\n",
      "resetting env. episode reward total was 2.0. running mean: 3.0598021304937353\n",
      "resetting env. episode reward total was 5.0. running mean: 3.079204109188798\n",
      "resetting env. episode reward total was 5.0. running mean: 3.0984120680969096\n",
      "resetting env. episode reward total was 5.0. running mean: 3.11742794741594\n",
      "resetting env. episode reward total was 1.0. running mean: 3.0962536679417805\n",
      "resetting env. episode reward total was 5.0. running mean: 3.1152911312623623\n",
      "resetting env. episode reward total was 6.0. running mean: 3.1441382199497387\n",
      "resetting env. episode reward total was 7.0. running mean: 3.182696837750241\n",
      "resetting env. episode reward total was -7.0. running mean: 3.080869869372739\n",
      "resetting env. episode reward total was -6.0. running mean: 2.9900611706790117\n",
      "resetting env. episode reward total was 2.0. running mean: 2.9801605589722215\n",
      "resetting env. episode reward total was -5.0. running mean: 2.9003589533824994\n",
      "resetting env. episode reward total was 1.0. running mean: 2.881355363848674\n",
      "resetting env. episode reward total was 7.0. running mean: 2.922541810210187\n",
      "resetting env. episode reward total was 14.0. running mean: 3.0333163921080852\n",
      "resetting env. episode reward total was 12.0. running mean: 3.1229832281870045\n",
      "resetting env. episode reward total was 5.0. running mean: 3.141753395905134\n",
      "resetting env. episode reward total was 12.0. running mean: 3.2303358619460827\n",
      "resetting env. episode reward total was -10.0. running mean: 3.0980325033266216\n",
      "resetting env. episode reward total was -1.0. running mean: 3.0570521782933557\n",
      "resetting env. episode reward total was 6.0. running mean: 3.086481656510422\n",
      "resetting env. episode reward total was 13.0. running mean: 3.1856168399453177\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1937606715458644\n",
      "resetting env. episode reward total was 3.0. running mean: 3.1918230648304053\n",
      "resetting env. episode reward total was 11.0. running mean: 3.269904834182101\n",
      "resetting env. episode reward total was 12.0. running mean: 3.35720578584028\n",
      "resetting env. episode reward total was 2.0. running mean: 3.343633727981877\n",
      "resetting env. episode reward total was 5.0. running mean: 3.360197390702058\n",
      "resetting env. episode reward total was 9.0. running mean: 3.416595416795037\n",
      "resetting env. episode reward total was 13.0. running mean: 3.512429462627087\n",
      "resetting env. episode reward total was -4.0. running mean: 3.4373051680008158\n",
      "resetting env. episode reward total was 9.0. running mean: 3.4929321163208074\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4980027951575994\n",
      "resetting env. episode reward total was -6.0. running mean: 3.403022767206023\n",
      "resetting env. episode reward total was 8.0. running mean: 3.448992539533963\n",
      "resetting env. episode reward total was -7.0. running mean: 3.3445026141386234\n",
      "resetting env. episode reward total was 15.0. running mean: 3.461057587997237\n",
      "resetting env. episode reward total was 13.0. running mean: 3.5564470121172644\n",
      "resetting env. episode reward total was 1.0. running mean: 3.5308825419960916\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5155737165761307\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5604179794103694\n",
      "resetting env. episode reward total was 8.0. running mean: 3.6048137996162657\n",
      "resetting env. episode reward total was 7.0. running mean: 3.638765661620103\n",
      "resetting env. episode reward total was -14.0. running mean: 3.462378005003902\n",
      "resetting env. episode reward total was 8.0. running mean: 3.507754224953863\n",
      "resetting env. episode reward total was -1.0. running mean: 3.4626766827043243\n",
      "resetting env. episode reward total was -3.0. running mean: 3.398049915877281\n",
      "resetting env. episode reward total was 1.0. running mean: 3.374069416718508\n",
      "resetting env. episode reward total was -11.0. running mean: 3.2303287225513233\n",
      "resetting env. episode reward total was 5.0. running mean: 3.24802543532581\n",
      "resetting env. episode reward total was 2.0. running mean: 3.2355451809725517\n",
      "resetting env. episode reward total was 2.0. running mean: 3.223189729162826\n",
      "resetting env. episode reward total was 1.0. running mean: 3.2009578318711975\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2189482535524854\n",
      "resetting env. episode reward total was 1.0. running mean: 3.1967587710169605\n",
      "resetting env. episode reward total was 2.0. running mean: 3.184791183306791\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1929432714737227\n",
      "resetting env. episode reward total was -1.0. running mean: 3.1510138387589857\n",
      "resetting env. episode reward total was 15.0. running mean: 3.269503700371396\n",
      "resetting env. episode reward total was -9.0. running mean: 3.146808663367682\n",
      "resetting env. episode reward total was 9.0. running mean: 3.205340576734005\n",
      "resetting env. episode reward total was 4.0. running mean: 3.213287170966665\n",
      "resetting env. episode reward total was -5.0. running mean: 3.1311542992569987\n",
      "resetting env. episode reward total was 6.0. running mean: 3.1598427562644287\n",
      "resetting env. episode reward total was -8.0. running mean: 3.0482443287017844\n",
      "resetting env. episode reward total was 11.0. running mean: 3.1277618854147664\n",
      "resetting env. episode reward total was 6.0. running mean: 3.1564842665606188\n",
      "resetting env. episode reward total was 3.0. running mean: 3.1549194238950125\n",
      "resetting env. episode reward total was 3.0. running mean: 3.153370229656062\n",
      "resetting env. episode reward total was -7.0. running mean: 3.0518365273595016\n",
      "resetting env. episode reward total was -1.0. running mean: 3.0113181620859066\n",
      "resetting env. episode reward total was -4.0. running mean: 2.9412049804650473\n",
      "resetting env. episode reward total was -5.0. running mean: 2.861792930660397\n",
      "resetting env. episode reward total was 4.0. running mean: 2.8731750013537933\n",
      "resetting env. episode reward total was 7.0. running mean: 2.914443251340255\n",
      "resetting env. episode reward total was 10.0. running mean: 2.9852988188268528\n",
      "resetting env. episode reward total was 1.0. running mean: 2.965445830638584\n",
      "resetting env. episode reward total was 9.0. running mean: 3.025791372332198\n",
      "resetting env. episode reward total was 10.0. running mean: 3.095533458608876\n",
      "resetting env. episode reward total was -3.0. running mean: 3.0345781240227874\n",
      "resetting env. episode reward total was 15.0. running mean: 3.1542323427825596\n",
      "resetting env. episode reward total was 2.0. running mean: 3.142690019354734\n",
      "resetting env. episode reward total was 5.0. running mean: 3.161263119161186\n",
      "resetting env. episode reward total was 7.0. running mean: 3.199650487969574\n",
      "resetting env. episode reward total was -3.0. running mean: 3.1376539830898786\n",
      "resetting env. episode reward total was -3.0. running mean: 3.07627744325898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 3.06551466882639\n",
      "resetting env. episode reward total was 10.0. running mean: 3.134859522138126\n",
      "resetting env. episode reward total was 5.0. running mean: 3.1535109269167445\n",
      "resetting env. episode reward total was -3.0. running mean: 3.0919758176475773\n",
      "resetting env. episode reward total was -9.0. running mean: 2.9710560594711017\n",
      "resetting env. episode reward total was 10.0. running mean: 3.0413454988763906\n",
      "resetting env. episode reward total was 3.0. running mean: 3.0409320438876266\n",
      "resetting env. episode reward total was 5.0. running mean: 3.06052272344875\n",
      "resetting env. episode reward total was 9.0. running mean: 3.119917496214262\n",
      "resetting env. episode reward total was -1.0. running mean: 3.07871832125212\n",
      "resetting env. episode reward total was 6.0. running mean: 3.1079311380395986\n",
      "resetting env. episode reward total was -5.0. running mean: 3.0268518266592026\n",
      "resetting env. episode reward total was 16.0. running mean: 3.1565833083926105\n",
      "resetting env. episode reward total was 10.0. running mean: 3.225017475308684\n",
      "resetting env. episode reward total was 13.0. running mean: 3.322767300555597\n",
      "resetting env. episode reward total was 1.0. running mean: 3.299539627550041\n",
      "resetting env. episode reward total was 8.0. running mean: 3.3465442312745406\n",
      "resetting env. episode reward total was 11.0. running mean: 3.423078788961795\n",
      "resetting env. episode reward total was 4.0. running mean: 3.428848001072177\n",
      "resetting env. episode reward total was 12.0. running mean: 3.514559521061455\n",
      "resetting env. episode reward total was 13.0. running mean: 3.6094139258508404\n",
      "resetting env. episode reward total was 9.0. running mean: 3.6633197865923317\n",
      "resetting env. episode reward total was 1.0. running mean: 3.636686588726408\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6103197228391437\n",
      "resetting env. episode reward total was 8.0. running mean: 3.654216525610752\n",
      "resetting env. episode reward total was -10.0. running mean: 3.5176743603546443\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5224976167510977\n",
      "resetting env. episode reward total was 9.0. running mean: 3.5772726405835864\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6014999141777504\n",
      "resetting env. episode reward total was -7.0. running mean: 3.495484915035973\n",
      "resetting env. episode reward total was 3.0. running mean: 3.490530065885613\n",
      "resetting env. episode reward total was 8.0. running mean: 3.535624765226757\n",
      "resetting env. episode reward total was 9.0. running mean: 3.590268517574489\n",
      "resetting env. episode reward total was 13.0. running mean: 3.684365832398744\n",
      "resetting env. episode reward total was 8.0. running mean: 3.7275221740747564\n",
      "resetting env. episode reward total was -3.0. running mean: 3.660246952334009\n",
      "resetting env. episode reward total was 12.0. running mean: 3.743644482810669\n",
      "resetting env. episode reward total was 7.0. running mean: 3.776208037982562\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7784459576027363\n",
      "resetting env. episode reward total was 9.0. running mean: 3.830661498026709\n",
      "resetting env. episode reward total was 11.0. running mean: 3.9023548830464416\n",
      "resetting env. episode reward total was 5.0. running mean: 3.913331334215977\n",
      "resetting env. episode reward total was 4.0. running mean: 3.914198020873817\n",
      "resetting env. episode reward total was 7.0. running mean: 3.945056040665079\n",
      "resetting env. episode reward total was 3.0. running mean: 3.935605480258428\n",
      "resetting env. episode reward total was 13.0. running mean: 4.026249425455844\n",
      "resetting env. episode reward total was 5.0. running mean: 4.035986931201285\n",
      "resetting env. episode reward total was 1.0. running mean: 4.005627061889272\n",
      "resetting env. episode reward total was 6.0. running mean: 4.025570791270379\n",
      "resetting env. episode reward total was 2.0. running mean: 4.005315083357675\n",
      "resetting env. episode reward total was 10.0. running mean: 4.065261932524098\n",
      "resetting env. episode reward total was -3.0. running mean: 3.994609313198857\n",
      "resetting env. episode reward total was 3.0. running mean: 3.984663220066868\n",
      "resetting env. episode reward total was 7.0. running mean: 4.0148165878662\n",
      "resetting env. episode reward total was -12.0. running mean: 3.8546684219875376\n",
      "resetting env. episode reward total was 3.0. running mean: 3.8461217377676618\n",
      "resetting env. episode reward total was -5.0. running mean: 3.7576605203899853\n",
      "resetting env. episode reward total was 8.0. running mean: 3.8000839151860855\n",
      "resetting env. episode reward total was 10.0. running mean: 3.862083076034225\n",
      "resetting env. episode reward total was 5.0. running mean: 3.8734622452738825\n",
      "resetting env. episode reward total was 1.0. running mean: 3.8447276228211433\n",
      "resetting env. episode reward total was -11.0. running mean: 3.696280346592932\n",
      "resetting env. episode reward total was -5.0. running mean: 3.609317543127003\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5932243676957327\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6572921240187752\n",
      "resetting env. episode reward total was 12.0. running mean: 3.7407192027785876\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7633120107508016\n",
      "resetting env. episode reward total was -2.0. running mean: 3.7056788906432936\n",
      "resetting env. episode reward total was 6.0. running mean: 3.728622101736861\n",
      "resetting env. episode reward total was 9.0. running mean: 3.781335880719492\n",
      "resetting env. episode reward total was -2.0. running mean: 3.723522521912297\n",
      "resetting env. episode reward total was 6.0. running mean: 3.746287296693174\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7688244237262425\n",
      "resetting env. episode reward total was 9.0. running mean: 3.8211361794889798\n",
      "resetting env. episode reward total was -6.0. running mean: 3.7229248176940897\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7356955695171488\n",
      "resetting env. episode reward total was 8.0. running mean: 3.7783386138219774\n",
      "resetting env. episode reward total was -7.0. running mean: 3.670555227683758\n",
      "resetting env. episode reward total was -13.0. running mean: 3.5038496754069204\n",
      "resetting env. episode reward total was -2.0. running mean: 3.4488111786528513\n",
      "resetting env. episode reward total was 8.0. running mean: 3.4943230668663228\n",
      "resetting env. episode reward total was 12.0. running mean: 3.5793798361976594\n",
      "resetting env. episode reward total was -3.0. running mean: 3.513586037835683\n",
      "resetting env. episode reward total was -1.0. running mean: 3.4684501774573264\n",
      "resetting env. episode reward total was 17.0. running mean: 3.603765675682753\n",
      "resetting env. episode reward total was 8.0. running mean: 3.6477280189259256\n",
      "resetting env. episode reward total was -3.0. running mean: 3.5812507387366663\n",
      "resetting env. episode reward total was -3.0. running mean: 3.5154382313493\n",
      "resetting env. episode reward total was -2.0. running mean: 3.4602838490358065\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4656810105454485\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4710242004399943\n",
      "resetting env. episode reward total was 1.0. running mean: 3.446313958435594\n",
      "resetting env. episode reward total was 5.0. running mean: 3.461850818851238\n",
      "resetting env. episode reward total was 4.0. running mean: 3.467232310662726\n",
      "resetting env. episode reward total was -9.0. running mean: 3.3425599875560987\n",
      "resetting env. episode reward total was 5.0. running mean: 3.3591343876805375\n",
      "resetting env. episode reward total was 4.0. running mean: 3.365543043803732\n",
      "resetting env. episode reward total was 10.0. running mean: 3.431887613365695\n",
      "resetting env. episode reward total was 3.0. running mean: 3.4275687372320376\n",
      "resetting env. episode reward total was 17.0. running mean: 3.563293049859717\n",
      "resetting env. episode reward total was 1.0. running mean: 3.5376601193611195\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6022835181675084\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6662606829858335\n",
      "resetting env. episode reward total was 8.0. running mean: 3.709598076155975\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7125020953944152\n",
      "resetting env. episode reward total was 14.0. running mean: 3.8153770744404714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 3.8872233036960666\n",
      "resetting env. episode reward total was -3.0. running mean: 3.818351070659106\n",
      "resetting env. episode reward total was 5.0. running mean: 3.830167559952515\n",
      "resetting env. episode reward total was 3.0. running mean: 3.8218658843529894\n",
      "resetting env. episode reward total was 5.0. running mean: 3.833647225509459\n",
      "resetting env. episode reward total was 3.0. running mean: 3.825310753254364\n",
      "resetting env. episode reward total was -1.0. running mean: 3.7770576457218206\n",
      "resetting env. episode reward total was 13.0. running mean: 3.8692870692646024\n",
      "resetting env. episode reward total was -7.0. running mean: 3.7605941985719564\n",
      "resetting env. episode reward total was 10.0. running mean: 3.8229882565862368\n",
      "resetting env. episode reward total was 11.0. running mean: 3.894758374020374\n",
      "resetting env. episode reward total was -5.0. running mean: 3.8058107902801708\n",
      "resetting env. episode reward total was 10.0. running mean: 3.867752682377369\n",
      "resetting env. episode reward total was 8.0. running mean: 3.9090751555535954\n",
      "resetting env. episode reward total was 8.0. running mean: 3.9499844039980596\n",
      "resetting env. episode reward total was 7.0. running mean: 3.9804845599580787\n",
      "resetting env. episode reward total was -5.0. running mean: 3.890679714358498\n",
      "resetting env. episode reward total was 4.0. running mean: 3.8917729172149134\n",
      "resetting env. episode reward total was -2.0. running mean: 3.8328551880427644\n",
      "resetting env. episode reward total was 5.0. running mean: 3.8445266361623367\n",
      "resetting env. episode reward total was -3.0. running mean: 3.7760813698007136\n",
      "resetting env. episode reward total was 9.0. running mean: 3.8283205561027063\n",
      "resetting env. episode reward total was -13.0. running mean: 3.6600373505416792\n",
      "resetting env. episode reward total was -7.0. running mean: 3.5534369770362626\n",
      "resetting env. episode reward total was 9.0. running mean: 3.6079026072659\n",
      "resetting env. episode reward total was 5.0. running mean: 3.6218235811932407\n",
      "resetting env. episode reward total was -7.0. running mean: 3.5156053453813083\n",
      "resetting env. episode reward total was 3.0. running mean: 3.510449291927495\n",
      "resetting env. episode reward total was -2.0. running mean: 3.45534479900822\n",
      "resetting env. episode reward total was -3.0. running mean: 3.390791351018138\n",
      "resetting env. episode reward total was 7.0. running mean: 3.426883437507956\n",
      "resetting env. episode reward total was -2.0. running mean: 3.3726146031328765\n",
      "resetting env. episode reward total was -1.0. running mean: 3.328888457101548\n",
      "resetting env. episode reward total was 2.0. running mean: 3.3155995725305325\n",
      "resetting env. episode reward total was 5.0. running mean: 3.332443576805227\n",
      "resetting env. episode reward total was 4.0. running mean: 3.339119141037175\n",
      "resetting env. episode reward total was -5.0. running mean: 3.2557279496268032\n",
      "resetting env. episode reward total was 2.0. running mean: 3.243170670130535\n",
      "resetting env. episode reward total was 8.0. running mean: 3.29073896342923\n",
      "resetting env. episode reward total was 6.0. running mean: 3.3178315737949378\n",
      "resetting env. episode reward total was -3.0. running mean: 3.2546532580569885\n",
      "resetting env. episode reward total was -16.0. running mean: 3.0621067254764185\n",
      "resetting env. episode reward total was 1.0. running mean: 3.041485658221654\n",
      "resetting env. episode reward total was -9.0. running mean: 2.9210708016394373\n",
      "resetting env. episode reward total was 5.0. running mean: 2.941860093623043\n",
      "resetting env. episode reward total was 1.0. running mean: 2.9224414926868123\n",
      "resetting env. episode reward total was -15.0. running mean: 2.7432170777599443\n",
      "resetting env. episode reward total was -13.0. running mean: 2.585784906982345\n",
      "resetting env. episode reward total was 5.0. running mean: 2.6099270579125213\n",
      "resetting env. episode reward total was -12.0. running mean: 2.463827787333396\n",
      "resetting env. episode reward total was 5.0. running mean: 2.489189509460062\n",
      "resetting env. episode reward total was -8.0. running mean: 2.3842976143654613\n",
      "resetting env. episode reward total was 5.0. running mean: 2.4104546382218066\n",
      "resetting env. episode reward total was 16.0. running mean: 2.5463500918395887\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5508865909211926\n",
      "resetting env. episode reward total was -9.0. running mean: 2.435377725011981\n",
      "resetting env. episode reward total was 9.0. running mean: 2.501023947761861\n",
      "resetting env. episode reward total was -3.0. running mean: 2.4460137082842426\n",
      "resetting env. episode reward total was 3.0. running mean: 2.4515535712014\n",
      "resetting env. episode reward total was 9.0. running mean: 2.517038035489386\n",
      "resetting env. episode reward total was -3.0. running mean: 2.4618676551344922\n",
      "resetting env. episode reward total was -3.0. running mean: 2.4072489785831475\n",
      "resetting env. episode reward total was 4.0. running mean: 2.423176488797316\n",
      "resetting env. episode reward total was -3.0. running mean: 2.368944723909343\n",
      "resetting env. episode reward total was -5.0. running mean: 2.29525527667025\n",
      "resetting env. episode reward total was -5.0. running mean: 2.2223027239035473\n",
      "resetting env. episode reward total was -5.0. running mean: 2.150079696664512\n",
      "resetting env. episode reward total was 4.0. running mean: 2.168578899697867\n",
      "resetting env. episode reward total was -7.0. running mean: 2.0768931107008886\n",
      "resetting env. episode reward total was 3.0. running mean: 2.0861241795938796\n",
      "resetting env. episode reward total was -8.0. running mean: 1.9852629377979407\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9554103084199612\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9258562053357615\n",
      "resetting env. episode reward total was -10.0. running mean: 1.8065976432824038\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7685316668495796\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8108463501810839\n",
      "resetting env. episode reward total was 2.0. running mean: 1.812737886679273\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8246105078124801\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8563644027343553\n",
      "resetting env. episode reward total was -4.0. running mean: 1.7978007587070117\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7498227511199416\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7523245236087421\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7648012783726548\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8071532655889282\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6990817329330388\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6720909156037083\n",
      "resetting env. episode reward total was -2.0. running mean: 1.635370006447671\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6390163063831944\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6326261433193625\n",
      "resetting env. episode reward total was 7.0. running mean: 1.686299881886169\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6894368830673072\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6925425142366342\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6556170890942679\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6490609182033251\n",
      "resetting env. episode reward total was 10.0. running mean: 1.732570309021292\n",
      "resetting env. episode reward total was -3.0. running mean: 1.685244605931079\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7483921598717682\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7809082382730506\n",
      "resetting env. episode reward total was -5.0. running mean: 1.71309915589032\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6459681643314166\n",
      "resetting env. episode reward total was -8.0. running mean: 1.5495084826881023\n",
      "resetting env. episode reward total was -15.0. running mean: 1.3840133978612212\n",
      "resetting env. episode reward total was -8.0. running mean: 1.290173263882609\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3272715312437828\n",
      "resetting env. episode reward total was 1.0. running mean: 1.323998815931345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 1.3307588277720315\n",
      "resetting env. episode reward total was -6.0. running mean: 1.2574512394943111\n",
      "resetting env. episode reward total was 1.0. running mean: 1.254876727099368\n",
      "resetting env. episode reward total was 9.0. running mean: 1.3323279598283744\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3990046802300906\n",
      "resetting env. episode reward total was 12.0. running mean: 1.5050146334277898\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5899644870935121\n",
      "resetting env. episode reward total was -10.0. running mean: 1.4740648422225768\n",
      "resetting env. episode reward total was 4.0. running mean: 1.499324193800351\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5543309518623476\n",
      "resetting env. episode reward total was -5.0. running mean: 1.488787642343724\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4238997659202868\n",
      "resetting env. episode reward total was -7.0. running mean: 1.339660768261084\n",
      "resetting env. episode reward total was 3.0. running mean: 1.356264160578473\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3327015189726883\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3593745037829614\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4157807587451319\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4516229511576806\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4871067216461038\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5422356544296427\n",
      "resetting env. episode reward total was -4.0. running mean: 1.4868132978853463\n",
      "resetting env. episode reward total was 2.0. running mean: 1.491945164906493\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5770257132574281\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5912554561248538\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6053429015636052\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5492894725479691\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4837965778224893\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4989586120442644\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4339690259238216\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4496293356645833\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4851330423079374\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4902817118848581\n",
      "resetting env. episode reward total was -8.0. running mean: 1.3953788947660095\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4114251058183493\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4273108547601658\n",
      "resetting env. episode reward total was 5.0. running mean: 1.463037746212564\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4684073687504384\n",
      "resetting env. episode reward total was 8.0. running mean: 1.533723295062934\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5883860621123047\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6025022014911816\n",
      "resetting env. episode reward total was -10.0. running mean: 1.4864771794762697\n",
      "resetting env. episode reward total was -7.0. running mean: 1.4016124076815069\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3375962836046917\n",
      "resetting env. episode reward total was 13.0. running mean: 1.4542203207686448\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4896781175609584\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4247813363853488\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3905335230214952\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3866281877912803\n",
      "resetting env. episode reward total was -11.0. running mean: 1.2627619059133675\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3301342868542338\n",
      "resetting env. episode reward total was -2.0. running mean: 1.2968329439856914\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3538646145458346\n",
      "resetting env. episode reward total was -12.0. running mean: 1.2203259684003762\n",
      "resetting env. episode reward total was 11.0. running mean: 1.3181227087163725\n",
      "resetting env. episode reward total was 3.0. running mean: 1.334941481629209\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3415920668129169\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3681761461447877\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4344943846833398\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4101494408365063\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4060479464281412\n",
      "resetting env. episode reward total was -11.0. running mean: 1.2819874669638598\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3091675922942212\n",
      "resetting env. episode reward total was -3.0. running mean: 1.266075916371279\n",
      "resetting env. episode reward total was 4.0. running mean: 1.293415157207566\n",
      "resetting env. episode reward total was -7.0. running mean: 1.2104810056354902\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1883761955791352\n",
      "resetting env. episode reward total was -11.0. running mean: 1.0664924336233437\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0458275092871103\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0753692341942394\n",
      "resetting env. episode reward total was 12.0. running mean: 1.1846155418522968\n",
      "resetting env. episode reward total was -2.0. running mean: 1.1527693864337738\n",
      "resetting env. episode reward total was 4.0. running mean: 1.181241692569436\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1394292756437416\n",
      "resetting env. episode reward total was 6.0. running mean: 1.1880349828873042\n",
      "resetting env. episode reward total was 8.0. running mean: 1.2561546330584312\n",
      "resetting env. episode reward total was 1.0. running mean: 1.2535930867278469\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3410571558605684\n",
      "resetting env. episode reward total was -8.0. running mean: 1.2476465843019626\n",
      "resetting env. episode reward total was 7.0. running mean: 1.305170118458943\n",
      "resetting env. episode reward total was -12.0. running mean: 1.1721184172743535\n",
      "resetting env. episode reward total was 4.0. running mean: 1.20039723310161\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1783932607705938\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1566093281628878\n",
      "resetting env. episode reward total was -7.0. running mean: 1.0750432348812589\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0342928025324463\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0639498745071219\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0633103757620506\n",
      "resetting env. episode reward total was 5.0. running mean: 1.10267727200443\n",
      "resetting env. episode reward total was -5.0. running mean: 1.0416504992843856\n",
      "resetting env. episode reward total was -6.0. running mean: 0.9712339942915416\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9715216543486261\n",
      "resetting env. episode reward total was -7.0. running mean: 0.8918064378051398\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9528883734270883\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0133594896928175\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9932258947958894\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0032936358479305\n",
      "resetting env. episode reward total was -11.0. running mean: 0.8832606994894512\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9444280924945567\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0049838115696113\n",
      "resetting env. episode reward total was 16.0. running mean: 1.154933973453915\n",
      "resetting env. episode reward total was 5.0. running mean: 1.1933846337193759\n",
      "resetting env. episode reward total was -1.0. running mean: 1.171450787382182\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1997362795083601\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2377389167132766\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2553615275461438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 1.3628079122706822\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3191798331479754\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3559880348164957\n",
      "resetting env. episode reward total was -6.0. running mean: 1.2824281544683307\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2996038729236474\n",
      "resetting env. episode reward total was -5.0. running mean: 1.236607834194411\n",
      "resetting env. episode reward total was 7.0. running mean: 1.2942417558524668\n",
      "resetting env. episode reward total was 13.0. running mean: 1.4112993382939423\n",
      "resetting env. episode reward total was 7.0. running mean: 1.467186344911003\n",
      "resetting env. episode reward total was -15.0. running mean: 1.302514481461893\n",
      "resetting env. episode reward total was 1.0. running mean: 1.299489336647274\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3864944432808013\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4226294988479933\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3784032038595133\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3846191718209182\n",
      "resetting env. episode reward total was 11.0. running mean: 1.4807729801027092\n",
      "resetting env. episode reward total was 4.0. running mean: 1.505965250301682\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5109055977986652\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5057965418206785\n",
      "resetting env. episode reward total was -7.0. running mean: 1.4207385764024716\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3765311906384468\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4427658787320623\n",
      "resetting env. episode reward total was -10.0. running mean: 1.3283382199447415\n",
      "resetting env. episode reward total was 11.0. running mean: 1.4250548377452943\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4908042893678415\n",
      "resetting env. episode reward total was -3.0. running mean: 1.445896246474163\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4214372840094214\n",
      "resetting env. episode reward total was 11.0. running mean: 1.5172229111693272\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5420506820576338\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5866301752370575\n",
      "resetting env. episode reward total was 9.0. running mean: 1.660763873484687\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6541562347498402\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7076146724023418\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7505385256783184\n",
      "resetting env. episode reward total was 16.0. running mean: 1.893033140421535\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9341028090173198\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9647617809271467\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8951141631178752\n",
      "resetting env. episode reward total was 11.0. running mean: 1.9861630214866965\n",
      "resetting env. episode reward total was 13.0. running mean: 2.0963013912718296\n",
      "resetting env. episode reward total was 5.0. running mean: 2.1253383773591112\n",
      "resetting env. episode reward total was -1.0. running mean: 2.09408499358552\n",
      "resetting env. episode reward total was -11.0. running mean: 1.9631441436496646\n",
      "resetting env. episode reward total was -7.0. running mean: 1.873512702213168\n",
      "resetting env. episode reward total was 13.0. running mean: 1.9847775751910364\n",
      "resetting env. episode reward total was -8.0. running mean: 1.8849297994391259\n",
      "resetting env. episode reward total was 9.0. running mean: 1.9560805014447347\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8865196964302873\n",
      "resetting env. episode reward total was -7.0. running mean: 1.7976544994659842\n",
      "resetting env. episode reward total was -4.0. running mean: 1.7396779544713243\n",
      "resetting env. episode reward total was 11.0. running mean: 1.8322811749266112\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9339583631773452\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9046187795455716\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8755725917501158\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8668168658326147\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8281486971742886\n",
      "resetting env. episode reward total was -12.0. running mean: 1.6898672102025456\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7229685381005202\n",
      "resetting env. episode reward total was -11.0. running mean: 1.5957388527195149\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5997814641923198\n",
      "resetting env. episode reward total was 12.0. running mean: 1.7037836495503966\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7167458130548927\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6895783549243437\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7126825713751004\n",
      "resetting env. episode reward total was -11.0. running mean: 1.5855557456613492\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5497001882047357\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6142031863226884\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6380611544594617\n",
      "resetting env. episode reward total was 1.0. running mean: 1.631680542914867\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6353637374857184\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6890101001108613\n",
      "resetting env. episode reward total was -9.0. running mean: 1.5821199991097525\n",
      "resetting env. episode reward total was 9.0. running mean: 1.656298799118655\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6497358111274685\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5932384530161938\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6373060684860319\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6309330078011715\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6646236777231598\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5779774409459282\n",
      "resetting env. episode reward total was 4.0. running mean: 1.602197666536469\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5761756898711043\n",
      "resetting env. episode reward total was -12.0. running mean: 1.4404139329723935\n",
      "resetting env. episode reward total was -6.0. running mean: 1.3660097936426696\n",
      "resetting env. episode reward total was 4.0. running mean: 1.392349695706243\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4584261987491804\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4738419367616886\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4991035173940717\n",
      "resetting env. episode reward total was 7.0. running mean: 1.554112482220131\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5585713573979298\n",
      "resetting env. episode reward total was 13.0. running mean: 1.6729856438239503\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6062557873857108\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6701932295118538\n",
      "resetting env. episode reward total was -10.0. running mean: 1.5534912972167352\n",
      "resetting env. episode reward total was -8.0. running mean: 1.4579563842445677\n",
      "resetting env. episode reward total was 5.0. running mean: 1.493376820402122\n",
      "resetting env. episode reward total was 1.0. running mean: 1.488443052198101\n",
      "resetting env. episode reward total was 5.0. running mean: 1.5235586216761199\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5883230354593587\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6224398051047653\n",
      "resetting env. episode reward total was 12.0. running mean: 1.7262154070537177\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7489532529831806\n",
      "resetting env. episode reward total was -10.0. running mean: 1.6314637204533486\n",
      "resetting env. episode reward total was -9.0. running mean: 1.525149083248815\n",
      "resetting env. episode reward total was 5.0. running mean: 1.559897592416327\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6142986164921638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: 1.5481556303272421\n",
      "resetting env. episode reward total was 11.0. running mean: 1.6426740740239698\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7062473332837302\n",
      "resetting env. episode reward total was 5.0. running mean: 1.739184859950893\n",
      "resetting env. episode reward total was -5.0. running mean: 1.671793011351384\n",
      "resetting env. episode reward total was 10.0. running mean: 1.7550750812378701\n",
      "resetting env. episode reward total was 15.0. running mean: 1.8875243304254914\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8486490871212364\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9501625962500242\n",
      "resetting env. episode reward total was -3.0. running mean: 1.900660970287524\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9516543605846488\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8821378169788023\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8533164388090142\n",
      "resetting env. episode reward total was -9.0. running mean: 1.744783274420924\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7973354416767147\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7993620872599476\n",
      "resetting env. episode reward total was -6.0. running mean: 1.721368466387348\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6941547817234746\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7572132339062398\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7596411015671773\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6520446905515054\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6555242436459903\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6989690012095304\n",
      "resetting env. episode reward total was -3.0. running mean: 1.651979311197435\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6554595180854608\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6489049229046062\n",
      "resetting env. episode reward total was 9.0. running mean: 1.7224158736755601\n",
      "resetting env. episode reward total was 13.0. running mean: 1.8351917149388046\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8768397977894167\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9080713998115226\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9189906858134074\n",
      "resetting env. episode reward total was 11.0. running mean: 2.0098007789552734\n",
      "resetting env. episode reward total was -7.0. running mean: 1.9197027711657206\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9305057434540633\n",
      "resetting env. episode reward total was -9.0. running mean: 1.8212006860195227\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8329886791593275\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8746587923677343\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8759122044440568\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9771530823996164\n",
      "resetting env. episode reward total was 10.0. running mean: 2.05738155157562\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9968077360598637\n",
      "resetting env. episode reward total was -2.0. running mean: 1.9568396586992651\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9672712621122725\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9675985494911499\n",
      "resetting env. episode reward total was 9.0. running mean: 2.037922563996238\n",
      "resetting env. episode reward total was 3.0. running mean: 2.0475433383562756\n",
      "resetting env. episode reward total was 6.0. running mean: 2.087067904972713\n",
      "resetting env. episode reward total was 7.0. running mean: 2.1361972259229858\n",
      "resetting env. episode reward total was 12.0. running mean: 2.234835253663756\n",
      "resetting env. episode reward total was -10.0. running mean: 2.1124869011271183\n",
      "resetting env. episode reward total was 14.0. running mean: 2.231362032115847\n",
      "resetting env. episode reward total was 1.0. running mean: 2.2190484117946885\n",
      "resetting env. episode reward total was 10.0. running mean: 2.296857927676742\n",
      "resetting env. episode reward total was 7.0. running mean: 2.343889348399974\n",
      "resetting env. episode reward total was 16.0. running mean: 2.4804504549159745\n",
      "resetting env. episode reward total was -4.0. running mean: 2.4156459503668146\n",
      "resetting env. episode reward total was 2.0. running mean: 2.4114894908631466\n",
      "resetting env. episode reward total was -6.0. running mean: 2.327374595954515\n",
      "resetting env. episode reward total was 6.0. running mean: 2.3641008499949696\n",
      "resetting env. episode reward total was -13.0. running mean: 2.21045984149502\n",
      "resetting env. episode reward total was 6.0. running mean: 2.24835524308007\n",
      "resetting env. episode reward total was 8.0. running mean: 2.305871690649269\n",
      "resetting env. episode reward total was 4.0. running mean: 2.3228129737427765\n",
      "resetting env. episode reward total was 11.0. running mean: 2.4095848440053484\n",
      "resetting env. episode reward total was 16.0. running mean: 2.5454889955652953\n",
      "resetting env. episode reward total was 10.0. running mean: 2.6200341056096423\n",
      "resetting env. episode reward total was 5.0. running mean: 2.6438337645535457\n",
      "resetting env. episode reward total was 7.0. running mean: 2.6873954269080103\n",
      "resetting env. episode reward total was -2.0. running mean: 2.64052147263893\n",
      "resetting env. episode reward total was 11.0. running mean: 2.7241162579125406\n",
      "resetting env. episode reward total was 1.0. running mean: 2.706875095333415\n",
      "resetting env. episode reward total was 4.0. running mean: 2.719806344380081\n",
      "resetting env. episode reward total was -1.0. running mean: 2.6826082809362806\n",
      "resetting env. episode reward total was -8.0. running mean: 2.5757821981269178\n",
      "resetting env. episode reward total was 13.0. running mean: 2.6800243761456484\n",
      "resetting env. episode reward total was 13.0. running mean: 2.7832241323841918\n",
      "resetting env. episode reward total was 6.0. running mean: 2.81539189106035\n",
      "resetting env. episode reward total was 2.0. running mean: 2.8072379721497462\n",
      "resetting env. episode reward total was -3.0. running mean: 2.7491655924282488\n",
      "resetting env. episode reward total was 7.0. running mean: 2.7916739365039662\n",
      "resetting env. episode reward total was -13.0. running mean: 2.6337571971389266\n",
      "resetting env. episode reward total was 2.0. running mean: 2.6274196251675375\n",
      "resetting env. episode reward total was 3.0. running mean: 2.631145428915862\n",
      "resetting env. episode reward total was 6.0. running mean: 2.6648339746267036\n",
      "resetting env. episode reward total was -1.0. running mean: 2.628185634880437\n",
      "resetting env. episode reward total was 7.0. running mean: 2.6719037785316324\n",
      "resetting env. episode reward total was 12.0. running mean: 2.7651847407463164\n",
      "resetting env. episode reward total was 1.0. running mean: 2.7475328933388528\n",
      "resetting env. episode reward total was -4.0. running mean: 2.6800575644054643\n",
      "resetting env. episode reward total was -2.0. running mean: 2.6332569887614095\n",
      "resetting env. episode reward total was -6.0. running mean: 2.5469244188737954\n",
      "resetting env. episode reward total was 7.0. running mean: 2.5914551746850574\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5955406229382065\n",
      "resetting env. episode reward total was -4.0. running mean: 2.529585216708824\n",
      "resetting env. episode reward total was -10.0. running mean: 2.404289364541736\n",
      "resetting env. episode reward total was -13.0. running mean: 2.2502464708963186\n",
      "resetting env. episode reward total was 4.0. running mean: 2.2677440061873555\n",
      "resetting env. episode reward total was -13.0. running mean: 2.115066566125482\n",
      "resetting env. episode reward total was 3.0. running mean: 2.123915900464227\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1226767414595846\n",
      "resetting env. episode reward total was 3.0. running mean: 2.1314499740449886\n",
      "resetting env. episode reward total was 11.0. running mean: 2.2201354743045387\n",
      "resetting env. episode reward total was -2.0. running mean: 2.177934119561493\n",
      "resetting env. episode reward total was 4.0. running mean: 2.1961547783658784\n",
      "resetting env. episode reward total was -12.0. running mean: 2.0541932305822193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 2.0536512982763973\n",
      "resetting env. episode reward total was 7.0. running mean: 2.103114785293633\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0920836374406964\n",
      "resetting env. episode reward total was 10.0. running mean: 2.1711628010662896\n",
      "resetting env. episode reward total was -3.0. running mean: 2.119451173055627\n",
      "resetting env. episode reward total was 3.0. running mean: 2.1282566613250706\n",
      "resetting env. episode reward total was 4.0. running mean: 2.14697409471182\n",
      "resetting env. episode reward total was -1.0. running mean: 2.115504353764702\n",
      "resetting env. episode reward total was 11.0. running mean: 2.204349310227055\n",
      "resetting env. episode reward total was -7.0. running mean: 2.1123058171247844\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0411827589535365\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0807709313640013\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9999632220503614\n",
      "resetting env. episode reward total was -7.0. running mean: 1.9099635898298577\n",
      "resetting env. episode reward total was 1.0. running mean: 1.900863953931559\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9818553143922435\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0020367612483208\n",
      "resetting env. episode reward total was -12.0. running mean: 1.8620163936358374\n",
      "resetting env. episode reward total was 7.0. running mean: 1.913396229699479\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9042622674024843\n",
      "resetting env. episode reward total was -11.0. running mean: 1.7752196447284594\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8274674482811748\n",
      "resetting env. episode reward total was -11.0. running mean: 1.699192773798363\n",
      "resetting env. episode reward total was -9.0. running mean: 1.5922008460603791\n",
      "resetting env. episode reward total was 9.0. running mean: 1.6662788375997755\n",
      "resetting env. episode reward total was -4.0. running mean: 1.6096160492237777\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6435198887315399\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5770846898442243\n",
      "resetting env. episode reward total was 14.0. running mean: 1.701313842945782\n",
      "resetting env. episode reward total was 3.0. running mean: 1.714300704516324\n",
      "resetting env. episode reward total was 8.0. running mean: 1.777157697471161\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7793861204964494\n",
      "resetting env. episode reward total was 5.0. running mean: 1.811592259291485\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8534763366985703\n",
      "resetting env. episode reward total was 9.0. running mean: 1.9249415733315847\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9656921575982689\n",
      "resetting env. episode reward total was 7.0. running mean: 2.016035236022286\n",
      "resetting env. episode reward total was 8.0. running mean: 2.0758748836620633\n",
      "resetting env. episode reward total was 8.0. running mean: 2.135116134825443\n",
      "resetting env. episode reward total was 4.0. running mean: 2.1537649734771884\n",
      "resetting env. episode reward total was 11.0. running mean: 2.242227323742416\n",
      "resetting env. episode reward total was 13.0. running mean: 2.349805050504992\n",
      "resetting env. episode reward total was -8.0. running mean: 2.246306999999942\n",
      "resetting env. episode reward total was -1.0. running mean: 2.213843929999943\n",
      "resetting env. episode reward total was -12.0. running mean: 2.0717054906999435\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0709884357929442\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0302785514350146\n",
      "resetting env. episode reward total was -8.0. running mean: 1.9299757659206644\n",
      "resetting env. episode reward total was -6.0. running mean: 1.8506760082614577\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9521692481788433\n",
      "resetting env. episode reward total was 7.0. running mean: 2.0026475556970547\n",
      "resetting env. episode reward total was -3.0. running mean: 1.952621080140084\n",
      "resetting env. episode reward total was 16.0. running mean: 2.093094869338683\n",
      "resetting env. episode reward total was -6.0. running mean: 2.012163920645296\n",
      "resetting env. episode reward total was -2.0. running mean: 1.9720422814388432\n",
      "resetting env. episode reward total was -9.0. running mean: 1.8623218586244548\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8736986400382103\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9249616536378282\n",
      "resetting env. episode reward total was 5.0. running mean: 1.95571203710145\n",
      "resetting env. episode reward total was 7.0. running mean: 2.0061549167304356\n",
      "resetting env. episode reward total was -5.0. running mean: 1.936093367563131\n",
      "resetting env. episode reward total was -14.0. running mean: 1.7767324338874997\n",
      "resetting env. episode reward total was -4.0. running mean: 1.7189651095486247\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7317754584531384\n",
      "resetting env. episode reward total was -6.0. running mean: 1.654457703868607\n",
      "resetting env. episode reward total was 10.0. running mean: 1.737913126829921\n",
      "resetting env. episode reward total was -8.0. running mean: 1.6405339955616218\n",
      "resetting env. episode reward total was -8.0. running mean: 1.5441286556060054\n",
      "resetting env. episode reward total was -11.0. running mean: 1.4186873690499453\n",
      "resetting env. episode reward total was -15.0. running mean: 1.2545004953594459\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3419554904058515\n",
      "resetting env. episode reward total was 4.0. running mean: 1.368535935501793\n",
      "resetting env. episode reward total was 3.0. running mean: 1.384850576146775\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4310020703853075\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4066920496814543\n",
      "resetting env. episode reward total was 8.0. running mean: 1.47262512918464\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4978988778927935\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4929198891138655\n",
      "resetting env. episode reward total was 6.0. running mean: 1.537990690222727\n",
      "resetting env. episode reward total was 13.0. running mean: 1.6526107833204997\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6260846754872946\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6298238287324216\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5635255904450973\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6478903345406464\n",
      "resetting env. episode reward total was 5.0. running mean: 1.68141143119524\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6145973168832874\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6284513437144545\n",
      "resetting env. episode reward total was 3.0. running mean: 1.64216683027731\n",
      "resetting env. episode reward total was 9.0. running mean: 1.715745161974537\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6385877103547914\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6722018332512436\n",
      "resetting env. episode reward total was 12.0. running mean: 1.775479814918731\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6977250167695437\n",
      "resetting env. episode reward total was 13.0. running mean: 1.8107477666018483\n",
      "resetting env. episode reward total was 4.0. running mean: 1.83264028893583\n",
      "resetting env. episode reward total was -7.0. running mean: 1.7443138860464715\n",
      "resetting env. episode reward total was -7.0. running mean: 1.6568707471860067\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6603020397141466\n",
      "resetting env. episode reward total was 9.0. running mean: 1.7336990193170052\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7863620291238351\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8184984088325968\n",
      "resetting env. episode reward total was 2.0. running mean: 1.820313424744271\n",
      "resetting env. episode reward total was 8.0. running mean: 1.8821102904968283\n",
      "resetting env. episode reward total was 8.0. running mean: 1.94328918759186\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8738562957159415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 1.935117732758782\n",
      "resetting env. episode reward total was 9.0. running mean: 2.0057665554311943\n",
      "resetting env. episode reward total was 8.0. running mean: 2.0657088898768823\n",
      "resetting env. episode reward total was 9.0. running mean: 2.1350518009781134\n",
      "resetting env. episode reward total was -1.0. running mean: 2.1037012829683324\n",
      "resetting env. episode reward total was 10.0. running mean: 2.182664270138649\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1808376274372625\n",
      "resetting env. episode reward total was 5.0. running mean: 2.2090292511628897\n",
      "resetting env. episode reward total was 5.0. running mean: 2.2369389586512605\n",
      "resetting env. episode reward total was 2.0. running mean: 2.234569569064748\n",
      "resetting env. episode reward total was 6.0. running mean: 2.2722238733741005\n",
      "resetting env. episode reward total was 6.0. running mean: 2.3095016346403594\n",
      "resetting env. episode reward total was 3.0. running mean: 2.3164066182939558\n",
      "resetting env. episode reward total was 10.0. running mean: 2.3932425521110163\n",
      "resetting env. episode reward total was -2.0. running mean: 2.349310126589906\n",
      "resetting env. episode reward total was 8.0. running mean: 2.405817025324007\n",
      "resetting env. episode reward total was 6.0. running mean: 2.441758855070767\n",
      "resetting env. episode reward total was 9.0. running mean: 2.507341266520059\n",
      "resetting env. episode reward total was 8.0. running mean: 2.5622678538548587\n",
      "resetting env. episode reward total was 7.0. running mean: 2.60664517531631\n",
      "resetting env. episode reward total was 1.0. running mean: 2.5905787235631466\n",
      "resetting env. episode reward total was 9.0. running mean: 2.6546729363275148\n",
      "resetting env. episode reward total was -2.0. running mean: 2.6081262069642395\n",
      "resetting env. episode reward total was 4.0. running mean: 2.622044944894597\n",
      "resetting env. episode reward total was 9.0. running mean: 2.685824495445651\n",
      "resetting env. episode reward total was 16.0. running mean: 2.8189662504911945\n",
      "resetting env. episode reward total was 9.0. running mean: 2.8807765879862823\n",
      "resetting env. episode reward total was 9.0. running mean: 2.9419688221064195\n",
      "resetting env. episode reward total was 8.0. running mean: 2.9925491338853556\n",
      "resetting env. episode reward total was 4.0. running mean: 3.002623642546502\n",
      "resetting env. episode reward total was -5.0. running mean: 2.9225974061210374\n",
      "resetting env. episode reward total was 6.0. running mean: 2.953371432059827\n",
      "resetting env. episode reward total was -2.0. running mean: 2.9038377177392287\n",
      "resetting env. episode reward total was 4.0. running mean: 2.9147993405618364\n",
      "resetting env. episode reward total was 1.0. running mean: 2.895651347156218\n",
      "resetting env. episode reward total was 8.0. running mean: 2.946694833684656\n",
      "resetting env. episode reward total was 9.0. running mean: 3.007227885347809\n",
      "resetting env. episode reward total was 14.0. running mean: 3.117155606494331\n",
      "resetting env. episode reward total was 8.0. running mean: 3.1659840504293877\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1743242099250937\n",
      "resetting env. episode reward total was 2.0. running mean: 3.1625809678258427\n",
      "resetting env. episode reward total was -2.0. running mean: 3.110955158147584\n",
      "resetting env. episode reward total was -5.0. running mean: 3.0298456065661084\n",
      "resetting env. episode reward total was -5.0. running mean: 2.9495471505004476\n",
      "resetting env. episode reward total was 9.0. running mean: 3.010051678995443\n",
      "resetting env. episode reward total was 6.0. running mean: 3.0399511622054884\n",
      "resetting env. episode reward total was 5.0. running mean: 3.0595516505834333\n",
      "resetting env. episode reward total was -9.0. running mean: 2.938956134077599\n",
      "resetting env. episode reward total was 5.0. running mean: 2.9595665727368226\n",
      "resetting env. episode reward total was 8.0. running mean: 3.0099709070094542\n",
      "resetting env. episode reward total was 19.0. running mean: 3.1698711979393597\n",
      "resetting env. episode reward total was 8.0. running mean: 3.218172485959966\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2559907611003664\n",
      "resetting env. episode reward total was -4.0. running mean: 3.1834308534893627\n",
      "resetting env. episode reward total was 8.0. running mean: 3.2315965449544692\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2692805795049242\n",
      "resetting env. episode reward total was 1.0. running mean: 3.2465877737098747\n",
      "resetting env. episode reward total was -9.0. running mean: 3.124121895972776\n",
      "resetting env. episode reward total was -3.0. running mean: 3.0628806770130486\n",
      "resetting env. episode reward total was 8.0. running mean: 3.1122518702429183\n",
      "resetting env. episode reward total was 6.0. running mean: 3.141129351540489\n",
      "resetting env. episode reward total was -5.0. running mean: 3.0597180580250845\n",
      "resetting env. episode reward total was 9.0. running mean: 3.1191208774448334\n",
      "resetting env. episode reward total was 2.0. running mean: 3.1079296686703852\n",
      "resetting env. episode reward total was -6.0. running mean: 3.0168503719836814\n",
      "resetting env. episode reward total was 8.0. running mean: 3.066681868263845\n",
      "resetting env. episode reward total was -6.0. running mean: 2.976015049581206\n",
      "resetting env. episode reward total was 11.0. running mean: 3.0562548990853937\n",
      "resetting env. episode reward total was 9.0. running mean: 3.1156923500945397\n",
      "resetting env. episode reward total was -4.0. running mean: 3.0445354265935944\n",
      "resetting env. episode reward total was 3.0. running mean: 3.0440900723276583\n",
      "resetting env. episode reward total was 6.0. running mean: 3.073649171604382\n",
      "resetting env. episode reward total was -11.0. running mean: 2.932912679888338\n",
      "resetting env. episode reward total was -1.0. running mean: 2.8935835530894547\n",
      "resetting env. episode reward total was 4.0. running mean: 2.9046477175585603\n",
      "resetting env. episode reward total was 3.0. running mean: 2.9056012403829743\n",
      "resetting env. episode reward total was -9.0. running mean: 2.7865452279791447\n",
      "resetting env. episode reward total was -2.0. running mean: 2.738679775699353\n",
      "resetting env. episode reward total was 6.0. running mean: 2.7712929779423594\n",
      "resetting env. episode reward total was -7.0. running mean: 2.673580048162936\n",
      "resetting env. episode reward total was 6.0. running mean: 2.706844247681307\n",
      "resetting env. episode reward total was 6.0. running mean: 2.7397758052044936\n",
      "resetting env. episode reward total was 14.0. running mean: 2.852378047152449\n",
      "resetting env. episode reward total was -9.0. running mean: 2.7338542666809245\n",
      "resetting env. episode reward total was 5.0. running mean: 2.756515724014115\n",
      "resetting env. episode reward total was 12.0. running mean: 2.8489505667739743\n",
      "resetting env. episode reward total was -9.0. running mean: 2.7304610611062348\n",
      "resetting env. episode reward total was 1.0. running mean: 2.7131564504951724\n",
      "resetting env. episode reward total was 13.0. running mean: 2.8160248859902204\n",
      "resetting env. episode reward total was -6.0. running mean: 2.727864637130318\n",
      "resetting env. episode reward total was 8.0. running mean: 2.780585990759015\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7827801308514246\n",
      "resetting env. episode reward total was 8.0. running mean: 2.83495232954291\n",
      "resetting env. episode reward total was -9.0. running mean: 2.716602806247481\n",
      "resetting env. episode reward total was 6.0. running mean: 2.7494367781850064\n",
      "resetting env. episode reward total was 3.0. running mean: 2.751942410403156\n",
      "resetting env. episode reward total was 16.0. running mean: 2.8844229862991244\n",
      "resetting env. episode reward total was 10.0. running mean: 2.9555787564361333\n",
      "resetting env. episode reward total was 1.0. running mean: 2.9360229688717716\n",
      "resetting env. episode reward total was 8.0. running mean: 2.986662739183054\n",
      "resetting env. episode reward total was 3.0. running mean: 2.986796111791223\n",
      "resetting env. episode reward total was 7.0. running mean: 3.0269281506733106\n",
      "resetting env. episode reward total was 5.0. running mean: 3.0466588691665772\n",
      "resetting env. episode reward total was 7.0. running mean: 3.0861922804749113\n",
      "resetting env. episode reward total was 4.0. running mean: 3.095330357670162\n",
      "resetting env. episode reward total was -7.0. running mean: 2.9943770540934604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: 2.954433283552526\n",
      "resetting env. episode reward total was 1.0. running mean: 2.9348889507170006\n",
      "resetting env. episode reward total was 11.0. running mean: 3.0155400612098306\n",
      "resetting env. episode reward total was 5.0. running mean: 3.035384660597732\n",
      "resetting env. episode reward total was -6.0. running mean: 2.945030813991755\n",
      "resetting env. episode reward total was 12.0. running mean: 3.0355805058518373\n",
      "resetting env. episode reward total was 2.0. running mean: 3.025224700793319\n",
      "resetting env. episode reward total was 11.0. running mean: 3.1049724537853858\n",
      "resetting env. episode reward total was 3.0. running mean: 3.1039227292475315\n",
      "resetting env. episode reward total was -1.0. running mean: 3.0628835019550564\n",
      "resetting env. episode reward total was 8.0. running mean: 3.112254666935506\n",
      "resetting env. episode reward total was 10.0. running mean: 3.181132120266151\n",
      "resetting env. episode reward total was 1.0. running mean: 3.1593207990634893\n",
      "resetting env. episode reward total was 7.0. running mean: 3.197727591072854\n",
      "resetting env. episode reward total was 9.0. running mean: 3.2557503151621257\n",
      "resetting env. episode reward total was 4.0. running mean: 3.2631928120105043\n",
      "resetting env. episode reward total was -11.0. running mean: 3.1205608838903993\n",
      "resetting env. episode reward total was 12.0. running mean: 3.2093552750514953\n",
      "resetting env. episode reward total was 3.0. running mean: 3.2072617223009803\n",
      "resetting env. episode reward total was -1.0. running mean: 3.1651891050779706\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1735372140271907\n",
      "resetting env. episode reward total was 11.0. running mean: 3.251801841886919\n",
      "resetting env. episode reward total was 6.0. running mean: 3.2792838234680497\n",
      "resetting env. episode reward total was 4.0. running mean: 3.2864909852333692\n",
      "resetting env. episode reward total was -1.0. running mean: 3.2436260753810355\n",
      "resetting env. episode reward total was -5.0. running mean: 3.1611898146272255\n",
      "resetting env. episode reward total was 2.0. running mean: 3.149577916480953\n",
      "resetting env. episode reward total was 3.0. running mean: 3.1480821373161434\n",
      "resetting env. episode reward total was -5.0. running mean: 3.066601315942982\n",
      "resetting env. episode reward total was -8.0. running mean: 2.955935302783552\n",
      "resetting env. episode reward total was -5.0. running mean: 2.8763759497557166\n",
      "resetting env. episode reward total was 13.0. running mean: 2.977612190258159\n",
      "resetting env. episode reward total was 2.0. running mean: 2.9678360683555773\n",
      "resetting env. episode reward total was 4.0. running mean: 2.9781577076720214\n",
      "resetting env. episode reward total was 1.0. running mean: 2.958376130595301\n",
      "resetting env. episode reward total was -7.0. running mean: 2.858792369289348\n",
      "resetting env. episode reward total was 3.0. running mean: 2.8602044455964544\n",
      "resetting env. episode reward total was 5.0. running mean: 2.8816024011404897\n",
      "resetting env. episode reward total was -10.0. running mean: 2.752786377129085\n",
      "resetting env. episode reward total was 2.0. running mean: 2.745258513357794\n",
      "resetting env. episode reward total was -3.0. running mean: 2.687805928224216\n",
      "resetting env. episode reward total was 5.0. running mean: 2.710927868941974\n",
      "resetting env. episode reward total was -8.0. running mean: 2.603818590252554\n",
      "resetting env. episode reward total was -1.0. running mean: 2.5677804043500285\n",
      "resetting env. episode reward total was 7.0. running mean: 2.612102600306528\n",
      "resetting env. episode reward total was -3.0. running mean: 2.555981574303463\n",
      "resetting env. episode reward total was 6.0. running mean: 2.5904217585604283\n",
      "resetting env. episode reward total was -7.0. running mean: 2.494517540974824\n",
      "resetting env. episode reward total was -10.0. running mean: 2.3695723655650758\n",
      "resetting env. episode reward total was -7.0. running mean: 2.275876641909425\n",
      "resetting env. episode reward total was 4.0. running mean: 2.2931178754903305\n",
      "resetting env. episode reward total was 12.0. running mean: 2.3901866967354275\n",
      "resetting env. episode reward total was -6.0. running mean: 2.306284829768073\n",
      "resetting env. episode reward total was 1.0. running mean: 2.293221981470392\n",
      "resetting env. episode reward total was -4.0. running mean: 2.2302897616556883\n",
      "resetting env. episode reward total was 14.0. running mean: 2.3479868640391315\n",
      "resetting env. episode reward total was -3.0. running mean: 2.2945069953987405\n",
      "resetting env. episode reward total was -2.0. running mean: 2.251561925444753\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2190463061903056\n",
      "resetting env. episode reward total was 4.0. running mean: 2.2368558431284025\n",
      "resetting env. episode reward total was -2.0. running mean: 2.1944872846971184\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1925424118501473\n",
      "resetting env. episode reward total was 12.0. running mean: 2.290616987731646\n",
      "resetting env. episode reward total was 12.0. running mean: 2.3877108178543294\n",
      "resetting env. episode reward total was 10.0. running mean: 2.4638337096757863\n",
      "resetting env. episode reward total was 5.0. running mean: 2.489195372579028\n",
      "resetting env. episode reward total was -11.0. running mean: 2.354303418853238\n",
      "resetting env. episode reward total was -10.0. running mean: 2.2307603846647055\n",
      "resetting env. episode reward total was 6.0. running mean: 2.2684527808180586\n",
      "resetting env. episode reward total was -4.0. running mean: 2.205768253009878\n",
      "resetting env. episode reward total was 2.0. running mean: 2.203710570479779\n",
      "resetting env. episode reward total was 3.0. running mean: 2.211673464774981\n",
      "resetting env. episode reward total was -10.0. running mean: 2.089556730127231\n",
      "resetting env. episode reward total was -9.0. running mean: 1.9786611628259585\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9488745511976988\n",
      "resetting env. episode reward total was 13.0. running mean: 2.059385805685722\n",
      "resetting env. episode reward total was 9.0. running mean: 2.1287919476288644\n",
      "resetting env. episode reward total was 2.0. running mean: 2.127504028152576\n",
      "resetting env. episode reward total was 12.0. running mean: 2.22622898787105\n",
      "resetting env. episode reward total was -6.0. running mean: 2.1439666979923397\n",
      "resetting env. episode reward total was -1.0. running mean: 2.1125270310124167\n",
      "resetting env. episode reward total was 5.0. running mean: 2.1414017607022924\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1399877430952694\n",
      "resetting env. episode reward total was 4.0. running mean: 2.158587865664317\n",
      "resetting env. episode reward total was -4.0. running mean: 2.0970019870076735\n",
      "resetting env. episode reward total was 3.0. running mean: 2.1060319671375964\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1049716474662206\n",
      "resetting env. episode reward total was 3.0. running mean: 2.113921930991558\n",
      "resetting env. episode reward total was 5.0. running mean: 2.142782711681642\n",
      "resetting env. episode reward total was -3.0. running mean: 2.0913548845648258\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0904413357191776\n",
      "resetting env. episode reward total was 5.0. running mean: 2.1195369223619855\n",
      "resetting env. episode reward total was 8.0. running mean: 2.178341553138366\n",
      "resetting env. episode reward total was -7.0. running mean: 2.0865581376069824\n",
      "resetting env. episode reward total was 4.0. running mean: 2.105692556230913\n",
      "resetting env. episode reward total was -8.0. running mean: 2.0046356306686035\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0245892743619174\n",
      "resetting env. episode reward total was 5.0. running mean: 2.054343381618298\n",
      "resetting env. episode reward total was 3.0. running mean: 2.063799947802115\n",
      "resetting env. episode reward total was 4.0. running mean: 2.083161948324094\n",
      "resetting env. episode reward total was 5.0. running mean: 2.112330328840853\n",
      "resetting env. episode reward total was -6.0. running mean: 2.0312070255524444\n",
      "resetting env. episode reward total was 11.0. running mean: 2.1208949552969196\n",
      "resetting env. episode reward total was -1.0. running mean: 2.0896860057439506\n",
      "resetting env. episode reward total was 1.0. running mean: 2.078789145686511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 2.098001254229646\n",
      "resetting env. episode reward total was -4.0. running mean: 2.0370212416873494\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9566510292704757\n",
      "resetting env. episode reward total was -4.0. running mean: 1.897084518977771\n",
      "resetting env. episode reward total was -8.0. running mean: 1.7981136737879932\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8201325370501134\n",
      "resetting env. episode reward total was -1.0. running mean: 1.7919312116796122\n",
      "resetting env. episode reward total was -6.0. running mean: 1.714011899562816\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7068717805671878\n",
      "resetting env. episode reward total was -13.0. running mean: 1.559803062761516\n",
      "resetting env. episode reward total was 9.0. running mean: 1.634205032133901\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6878629818125621\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7309843519944366\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7236745084744922\n",
      "resetting env. episode reward total was 11.0. running mean: 1.8164377633897473\n",
      "resetting env. episode reward total was -4.0. running mean: 1.7582733857558497\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7706906518982912\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8029837453793083\n",
      "resetting env. episode reward total was -7.0. running mean: 1.7149539079255152\n",
      "resetting env. episode reward total was -16.0. running mean: 1.5378043688462602\n",
      "resetting env. episode reward total was -9.0. running mean: 1.4324263251577976\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4381020619062195\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4537210412871573\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5191838308742858\n",
      "resetting env. episode reward total was 8.0. running mean: 1.583991992565543\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5981520726398877\n",
      "resetting env. episode reward total was 14.0. running mean: 1.722170551913489\n",
      "resetting env. episode reward total was 14.0. running mean: 1.8449488463943542\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8164993579304107\n",
      "resetting env. episode reward total was 11.0. running mean: 1.9083343643511066\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8692510207075954\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9505585105005194\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9510529253955142\n",
      "resetting env. episode reward total was 6.0. running mean: 1.991542396141559\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9816269721801434\n",
      "resetting env. episode reward total was -6.0. running mean: 1.901810702458342\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9327925954337586\n",
      "resetting env. episode reward total was -5.0. running mean: 1.863464669479421\n",
      "resetting env. episode reward total was 11.0. running mean: 1.954830022784627\n",
      "resetting env. episode reward total was 8.0. running mean: 2.0152817225567805\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9451289053312126\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9356776162779006\n",
      "resetting env. episode reward total was 12.0. running mean: 2.0363208401151214\n",
      "resetting env. episode reward total was 14.0. running mean: 2.1559576317139704\n",
      "resetting env. episode reward total was -2.0. running mean: 2.1143980553968307\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1132540748428625\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1521215340944337\n",
      "resetting env. episode reward total was -4.0. running mean: 2.090600318753489\n",
      "resetting env. episode reward total was 10.0. running mean: 2.1696943155659545\n",
      "resetting env. episode reward total was -5.0. running mean: 2.097997372410295\n",
      "resetting env. episode reward total was 7.0. running mean: 2.147017398686192\n",
      "resetting env. episode reward total was -1.0. running mean: 2.11554722469933\n",
      "resetting env. episode reward total was 12.0. running mean: 2.214391752452337\n",
      "resetting env. episode reward total was 8.0. running mean: 2.2722478349278137\n",
      "resetting env. episode reward total was 10.0. running mean: 2.3495253565785355\n",
      "resetting env. episode reward total was 8.0. running mean: 2.40603010301275\n",
      "resetting env. episode reward total was 9.0. running mean: 2.4719698019826226\n",
      "resetting env. episode reward total was 5.0. running mean: 2.4972501039627963\n",
      "resetting env. episode reward total was -3.0. running mean: 2.4422776029231685\n",
      "resetting env. episode reward total was 5.0. running mean: 2.467854826893937\n",
      "resetting env. episode reward total was -14.0. running mean: 2.3031762786249974\n",
      "resetting env. episode reward total was -2.0. running mean: 2.260144515838747\n",
      "resetting env. episode reward total was 5.0. running mean: 2.2875430706803597\n",
      "resetting env. episode reward total was 10.0. running mean: 2.3646676399735562\n",
      "resetting env. episode reward total was -5.0. running mean: 2.291020963573821\n",
      "resetting env. episode reward total was -1.0. running mean: 2.258110753938083\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2255296463987024\n",
      "resetting env. episode reward total was 3.0. running mean: 2.233274349934715\n",
      "resetting env. episode reward total was -3.0. running mean: 2.1809416064353684\n",
      "resetting env. episode reward total was 9.0. running mean: 2.2491321903710144\n",
      "resetting env. episode reward total was 4.0. running mean: 2.2666408684673045\n",
      "resetting env. episode reward total was -7.0. running mean: 2.173974459782632\n",
      "resetting env. episode reward total was 3.0. running mean: 2.1822347151848054\n",
      "resetting env. episode reward total was 1.0. running mean: 2.1704123680329572\n",
      "resetting env. episode reward total was 1.0. running mean: 2.1587082443526273\n",
      "resetting env. episode reward total was -6.0. running mean: 2.077121161909101\n",
      "resetting env. episode reward total was 10.0. running mean: 2.15634995029001\n",
      "resetting env. episode reward total was 2.0. running mean: 2.15478645078711\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2032385862792387\n",
      "resetting env. episode reward total was -5.0. running mean: 2.1312062004164467\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1298941384122823\n",
      "resetting env. episode reward total was 12.0. running mean: 2.2285951970281594\n",
      "resetting env. episode reward total was 3.0. running mean: 2.2363092450578774\n",
      "resetting env. episode reward total was 6.0. running mean: 2.273946152607299\n",
      "resetting env. episode reward total was 14.0. running mean: 2.391206691081226\n",
      "resetting env. episode reward total was 11.0. running mean: 2.4772946241704137\n",
      "resetting env. episode reward total was 14.0. running mean: 2.5925216779287097\n",
      "resetting env. episode reward total was 9.0. running mean: 2.6565964611494226\n",
      "resetting env. episode reward total was 14.0. running mean: 2.7700304965379283\n",
      "resetting env. episode reward total was 5.0. running mean: 2.7923301915725487\n",
      "resetting env. episode reward total was -2.0. running mean: 2.744406889656823\n",
      "resetting env. episode reward total was 15.0. running mean: 2.8669628207602544\n",
      "resetting env. episode reward total was -1.0. running mean: 2.828293192552652\n",
      "resetting env. episode reward total was -6.0. running mean: 2.7400102606271255\n",
      "resetting env. episode reward total was 8.0. running mean: 2.7926101580208544\n",
      "resetting env. episode reward total was 2.0. running mean: 2.784684056440646\n",
      "resetting env. episode reward total was 4.0. running mean: 2.7968372158762396\n",
      "resetting env. episode reward total was 5.0. running mean: 2.818868843717477\n",
      "resetting env. episode reward total was 12.0. running mean: 2.910680155280302\n",
      "resetting env. episode reward total was 9.0. running mean: 2.971573353727499\n",
      "resetting env. episode reward total was 9.0. running mean: 3.031857620190224\n",
      "resetting env. episode reward total was 16.0. running mean: 3.1615390439883218\n",
      "resetting env. episode reward total was 5.0. running mean: 3.1799236535484385\n",
      "resetting env. episode reward total was 2.0. running mean: 3.168124417012954\n",
      "resetting env. episode reward total was -1.0. running mean: 3.1264431728428246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 3.1351787411143963\n",
      "resetting env. episode reward total was 12.0. running mean: 3.2238269537032522\n",
      "resetting env. episode reward total was 1.0. running mean: 3.2015886841662193\n",
      "resetting env. episode reward total was -3.0. running mean: 3.1395727973245573\n",
      "resetting env. episode reward total was -4.0. running mean: 3.0681770693513117\n",
      "resetting env. episode reward total was 11.0. running mean: 3.1474952986577986\n",
      "resetting env. episode reward total was 12.0. running mean: 3.236020345671221\n",
      "resetting env. episode reward total was -11.0. running mean: 3.093660142214509\n",
      "resetting env. episode reward total was -3.0. running mean: 3.032723540792364\n",
      "resetting env. episode reward total was 6.0. running mean: 3.0623963053844405\n",
      "resetting env. episode reward total was 7.0. running mean: 3.101772342330596\n",
      "resetting env. episode reward total was -1.0. running mean: 3.06075461890729\n",
      "resetting env. episode reward total was 3.0. running mean: 3.060147072718217\n",
      "resetting env. episode reward total was 12.0. running mean: 3.149545601991035\n",
      "resetting env. episode reward total was -10.0. running mean: 3.0180501459711246\n",
      "resetting env. episode reward total was 6.0. running mean: 3.0478696445114135\n",
      "resetting env. episode reward total was 8.0. running mean: 3.0973909480662996\n",
      "resetting env. episode reward total was 6.0. running mean: 3.1264170385856365\n",
      "resetting env. episode reward total was -1.0. running mean: 3.0851528681997804\n",
      "resetting env. episode reward total was -7.0. running mean: 2.9843013395177826\n",
      "resetting env. episode reward total was -8.0. running mean: 2.8744583261226047\n",
      "resetting env. episode reward total was 7.0. running mean: 2.9157137428613784\n",
      "resetting env. episode reward total was -2.0. running mean: 2.8665566054327645\n",
      "resetting env. episode reward total was 13.0. running mean: 2.967891039378437\n",
      "resetting env. episode reward total was 9.0. running mean: 3.028212128984652\n",
      "resetting env. episode reward total was -7.0. running mean: 2.9279300076948056\n",
      "resetting env. episode reward total was -8.0. running mean: 2.8186507076178575\n",
      "resetting env. episode reward total was 4.0. running mean: 2.830464200541679\n",
      "resetting env. episode reward total was 12.0. running mean: 2.9221595585362623\n",
      "resetting env. episode reward total was -3.0. running mean: 2.8629379629509\n",
      "resetting env. episode reward total was 8.0. running mean: 2.914308583321391\n",
      "resetting env. episode reward total was 7.0. running mean: 2.955165497488177\n",
      "resetting env. episode reward total was -7.0. running mean: 2.855613842513295\n",
      "resetting env. episode reward total was -7.0. running mean: 2.757057704088162\n",
      "resetting env. episode reward total was 5.0. running mean: 2.7794871270472803\n",
      "resetting env. episode reward total was 18.0. running mean: 2.9316922557768077\n",
      "resetting env. episode reward total was -2.0. running mean: 2.8823753332190396\n",
      "resetting env. episode reward total was 4.0. running mean: 2.893551579886849\n",
      "resetting env. episode reward total was -1.0. running mean: 2.8546160640879807\n",
      "resetting env. episode reward total was 3.0. running mean: 2.856069903447101\n",
      "resetting env. episode reward total was 3.0. running mean: 2.85750920441263\n",
      "resetting env. episode reward total was -5.0. running mean: 2.778934112368504\n",
      "resetting env. episode reward total was 9.0. running mean: 2.8411447712448186\n",
      "resetting env. episode reward total was -9.0. running mean: 2.7227333235323705\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7255059902970467\n",
      "resetting env. episode reward total was 7.0. running mean: 2.768250930394076\n",
      "resetting env. episode reward total was -1.0. running mean: 2.7305684210901355\n",
      "resetting env. episode reward total was -5.0. running mean: 2.6532627368792343\n",
      "resetting env. episode reward total was -1.0. running mean: 2.616730109510442\n",
      "resetting env. episode reward total was 5.0. running mean: 2.6405628084153374\n",
      "resetting env. episode reward total was -4.0. running mean: 2.574157180331184\n",
      "resetting env. episode reward total was 7.0. running mean: 2.618415608527872\n",
      "resetting env. episode reward total was 6.0. running mean: 2.652231452442593\n",
      "resetting env. episode reward total was -5.0. running mean: 2.5757091379181674\n",
      "resetting env. episode reward total was -5.0. running mean: 2.499952046538986\n",
      "resetting env. episode reward total was 5.0. running mean: 2.524952526073596\n",
      "resetting env. episode reward total was -14.0. running mean: 2.35970300081286\n",
      "resetting env. episode reward total was -5.0. running mean: 2.2861059708047318\n",
      "resetting env. episode reward total was 16.0. running mean: 2.4232449110966847\n",
      "resetting env. episode reward total was -7.0. running mean: 2.329012461985718\n",
      "resetting env. episode reward total was 2.0. running mean: 2.325722337365861\n",
      "resetting env. episode reward total was -8.0. running mean: 2.222465113992202\n",
      "resetting env. episode reward total was 3.0. running mean: 2.23024046285228\n",
      "resetting env. episode reward total was 6.0. running mean: 2.267938058223757\n",
      "resetting env. episode reward total was 6.0. running mean: 2.3052586776415196\n",
      "resetting env. episode reward total was 8.0. running mean: 2.3622060908651044\n",
      "resetting env. episode reward total was 8.0. running mean: 2.4185840299564534\n",
      "resetting env. episode reward total was 11.0. running mean: 2.5043981896568885\n",
      "resetting env. episode reward total was 9.0. running mean: 2.5693542077603193\n",
      "resetting env. episode reward total was 8.0. running mean: 2.623660665682716\n",
      "resetting env. episode reward total was 11.0. running mean: 2.7074240590258887\n",
      "resetting env. episode reward total was 7.0. running mean: 2.7503498184356294\n",
      "resetting env. episode reward total was -3.0. running mean: 2.6928463202512734\n",
      "resetting env. episode reward total was 2.0. running mean: 2.6859178570487607\n",
      "resetting env. episode reward total was 4.0. running mean: 2.699058678478273\n",
      "resetting env. episode reward total was -3.0. running mean: 2.6420680916934907\n",
      "resetting env. episode reward total was 10.0. running mean: 2.715647410776556\n",
      "resetting env. episode reward total was -3.0. running mean: 2.6584909366687905\n",
      "resetting env. episode reward total was 2.0. running mean: 2.6519060273021027\n",
      "resetting env. episode reward total was -2.0. running mean: 2.6053869670290815\n",
      "resetting env. episode reward total was -4.0. running mean: 2.5393330973587904\n",
      "resetting env. episode reward total was 5.0. running mean: 2.5639397663852024\n",
      "resetting env. episode reward total was -5.0. running mean: 2.4883003687213505\n",
      "resetting env. episode reward total was 2.0. running mean: 2.483417365034137\n",
      "resetting env. episode reward total was -3.0. running mean: 2.4285831913837956\n",
      "resetting env. episode reward total was -5.0. running mean: 2.3542973594699577\n",
      "resetting env. episode reward total was -4.0. running mean: 2.290754385875258\n",
      "resetting env. episode reward total was 10.0. running mean: 2.3678468420165055\n",
      "resetting env. episode reward total was 7.0. running mean: 2.41416837359634\n",
      "resetting env. episode reward total was 17.0. running mean: 2.5600266898603765\n",
      "resetting env. episode reward total was 12.0. running mean: 2.6544264229617727\n",
      "resetting env. episode reward total was 3.0. running mean: 2.657882158732155\n",
      "resetting env. episode reward total was -3.0. running mean: 2.6013033371448335\n",
      "resetting env. episode reward total was 2.0. running mean: 2.595290303773385\n",
      "resetting env. episode reward total was 3.0. running mean: 2.599337400735651\n",
      "resetting env. episode reward total was -15.0. running mean: 2.423344026728295\n",
      "resetting env. episode reward total was -3.0. running mean: 2.3691105864610122\n",
      "resetting env. episode reward total was 2.0. running mean: 2.365419480596402\n",
      "resetting env. episode reward total was 10.0. running mean: 2.441765285790438\n",
      "resetting env. episode reward total was -7.0. running mean: 2.347347632932534\n",
      "resetting env. episode reward total was 3.0. running mean: 2.3538741566032084\n",
      "resetting env. episode reward total was 12.0. running mean: 2.4503354150371766\n",
      "resetting env. episode reward total was -1.0. running mean: 2.415832060886805\n",
      "resetting env. episode reward total was -8.0. running mean: 2.3116737402779366\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2785570028751576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: 2.205771432846406\n",
      "resetting env. episode reward total was 12.0. running mean: 2.303713718517942\n",
      "resetting env. episode reward total was 4.0. running mean: 2.3206765813327626\n",
      "resetting env. episode reward total was 1.0. running mean: 2.307469815519435\n",
      "resetting env. episode reward total was -6.0. running mean: 2.2243951173642404\n",
      "resetting env. episode reward total was -6.0. running mean: 2.142151166190598\n",
      "resetting env. episode reward total was 9.0. running mean: 2.210729654528692\n",
      "resetting env. episode reward total was 8.0. running mean: 2.268622357983405\n",
      "resetting env. episode reward total was -3.0. running mean: 2.215936134403571\n",
      "resetting env. episode reward total was 4.0. running mean: 2.2337767730595353\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2814390053289397\n",
      "resetting env. episode reward total was 1.0. running mean: 2.26862461527565\n",
      "resetting env. episode reward total was 5.0. running mean: 2.295938369122893\n",
      "resetting env. episode reward total was -6.0. running mean: 2.2129789854316644\n",
      "resetting env. episode reward total was -2.0. running mean: 2.1708491955773477\n",
      "resetting env. episode reward total was -4.0. running mean: 2.1091407036215744\n",
      "resetting env. episode reward total was -11.0. running mean: 1.9780492965853587\n",
      "resetting env. episode reward total was 14.0. running mean: 2.098268803619505\n",
      "resetting env. episode reward total was -6.0. running mean: 2.01728611558331\n",
      "resetting env. episode reward total was -11.0. running mean: 1.8871132544274767\n",
      "resetting env. episode reward total was -5.0. running mean: 1.818242121883202\n",
      "resetting env. episode reward total was 7.0. running mean: 1.87005970066437\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8713591036577264\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8226455126211492\n",
      "resetting env. episode reward total was -8.0. running mean: 1.7244190574949376\n",
      "resetting env. episode reward total was -15.0. running mean: 1.5571748669199883\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5316031182507883\n",
      "resetting env. episode reward total was -2.0. running mean: 1.4962870870682805\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4513242161975977\n",
      "resetting env. episode reward total was 9.0. running mean: 1.5268109740356217\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5815428642952656\n",
      "resetting env. episode reward total was -10.0. running mean: 1.465727435652313\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4610701612957897\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4364594596828317\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4120948650860035\n",
      "resetting env. episode reward total was -9.0. running mean: 1.3079739164351434\n",
      "resetting env. episode reward total was -5.0. running mean: 1.244894177270792\n",
      "resetting env. episode reward total was -7.0. running mean: 1.162445235498084\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1908207831431032\n",
      "resetting env. episode reward total was 12.0. running mean: 1.2989125753116721\n",
      "resetting env. episode reward total was -1.0. running mean: 1.2759234495585554\n",
      "resetting env. episode reward total was -2.0. running mean: 1.2431642150629698\n",
      "resetting env. episode reward total was 11.0. running mean: 1.3407325729123403\n",
      "resetting env. episode reward total was -3.0. running mean: 1.2973252471832168\n",
      "resetting env. episode reward total was 3.0. running mean: 1.3143519947113846\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3212084747642707\n",
      "resetting env. episode reward total was 1.0. running mean: 1.317996390016628\n",
      "resetting env. episode reward total was -8.0. running mean: 1.2248164261164616\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1625682618552968\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1009425792367438\n",
      "resetting env. episode reward total was -13.0. running mean: 0.9599331534443764\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9103338219099325\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9312304836908332\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9419181788539248\n",
      "resetting env. episode reward total was -10.0. running mean: 0.8324989970653855\n",
      "resetting env. episode reward total was 12.0. running mean: 0.9441740070947316\n",
      "resetting env. episode reward total was -6.0. running mean: 0.8747322670237843\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8559849443535464\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9174250949100109\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9182508439609108\n",
      "resetting env. episode reward total was 10.0. running mean: 1.0090683355213017\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0489776521660887\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0584878756444278\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0579029968879836\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9773239669191036\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9875507272499126\n",
      "resetting env. episode reward total was 8.0. running mean: 1.0576752199774135\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0770984677776394\n",
      "resetting env. episode reward total was -5.0. running mean: 1.016327483099863\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0461642082688645\n",
      "resetting env. episode reward total was -17.0. running mean: 0.8657025661861758\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8870455405243141\n",
      "resetting env. episode reward total was -10.0. running mean: 0.778175085119071\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8503933342678802\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8918894009252014\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8329705069159493\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8746408018467898\n",
      "resetting env. episode reward total was -8.0. running mean: 0.7858943938283219\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8280354498900387\n",
      "resetting env. episode reward total was -4.0. running mean: 0.7797550953911383\n",
      "resetting env. episode reward total was 15.0. running mean: 0.9219575444372269\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8827379689928546\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8639105893029261\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8752714834098968\n",
      "resetting env. episode reward total was 11.0. running mean: 0.9765187685757978\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0367535808900399\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0363860450811395\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9360221846303282\n",
      "resetting env. episode reward total was 6.0. running mean: 0.986661962784025\n",
      "resetting env. episode reward total was 10.0. running mean: 1.0767953431561847\n",
      "resetting env. episode reward total was -4.0. running mean: 1.0260273897246228\n",
      "resetting env. episode reward total was 8.0. running mean: 1.0957671158273767\n",
      "resetting env. episode reward total was 7.0. running mean: 1.154809444669103\n",
      "resetting env. episode reward total was 11.0. running mean: 1.2532613502224121\n",
      "resetting env. episode reward total was -3.0. running mean: 1.210728736720188\n",
      "resetting env. episode reward total was -4.0. running mean: 1.158621449352986\n",
      "resetting env. episode reward total was 2.0. running mean: 1.1670352348594561\n",
      "resetting env. episode reward total was -4.0. running mean: 1.1153648825108615\n",
      "resetting env. episode reward total was -8.0. running mean: 1.0242112336857527\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9239691213488953\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9847294301354064\n",
      "resetting env. episode reward total was -3.0. running mean: 0.9448821358340522\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9254333144757116\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8661789813309545\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9375171915176449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -3.0. running mean: 0.8981420196024684\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8691605994064437\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8704689934123793\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8117643034782555\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7736466604434729\n",
      "resetting env. episode reward total was 9.0. running mean: 0.8559101938390381\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8173510919006477\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7891775809816411\n",
      "resetting env. episode reward total was -12.0. running mean: 0.6612858051718248\n",
      "resetting env. episode reward total was -4.0. running mean: 0.6146729471201064\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5785262176489053\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5827409554724163\n",
      "resetting env. episode reward total was 14.0. running mean: 0.7169135459176922\n",
      "resetting env. episode reward total was -6.0. running mean: 0.6497444104585153\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5732469663539301\n",
      "resetting env. episode reward total was 10.0. running mean: 0.6675144966903908\n",
      "resetting env. episode reward total was -2.0. running mean: 0.6408393517234868\n",
      "resetting env. episode reward total was 6.0. running mean: 0.694430958206252\n",
      "resetting env. episode reward total was 10.0. running mean: 0.7874866486241895\n",
      "resetting env. episode reward total was 11.0. running mean: 0.8896117821379476\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9107156643165681\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9516085076734025\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8520924225966685\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9435714983707018\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9441357833869948\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9546944255531249\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0151474812975936\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0349960064846178\n",
      "resetting env. episode reward total was 8.0. running mean: 1.1046460464197716\n",
      "resetting env. episode reward total was -2.0. running mean: 1.0735995859555738\n",
      "resetting env. episode reward total was 12.0. running mean: 1.182863590096018\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1210349541950577\n",
      "resetting env. episode reward total was -2.0. running mean: 1.089824604653107\n",
      "resetting env. episode reward total was 2.0. running mean: 1.098926358606576\n",
      "resetting env. episode reward total was 14.0. running mean: 1.2279370950205104\n",
      "resetting env. episode reward total was 7.0. running mean: 1.2856577240703053\n",
      "resetting env. episode reward total was -2.0. running mean: 1.2528011468296023\n",
      "resetting env. episode reward total was -7.0. running mean: 1.1702731353613063\n",
      "resetting env. episode reward total was 3.0. running mean: 1.1885704040076932\n",
      "resetting env. episode reward total was -4.0. running mean: 1.1366846999676161\n",
      "resetting env. episode reward total was 4.0. running mean: 1.16531785296794\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2436646744382607\n",
      "resetting env. episode reward total was -5.0. running mean: 1.181228027693878\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2194157474169394\n",
      "resetting env. episode reward total was -5.0. running mean: 1.15722158994277\n",
      "resetting env. episode reward total was 3.0. running mean: 1.1756493740433422\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1338928803029087\n",
      "resetting env. episode reward total was 18.0. running mean: 1.3025539514998796\n",
      "resetting env. episode reward total was -3.0. running mean: 1.2595284119848809\n",
      "resetting env. episode reward total was 1.0. running mean: 1.256933127865032\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3043637965863817\n",
      "resetting env. episode reward total was -6.0. running mean: 1.2313201586205178\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2790069570343128\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2862168874639697\n",
      "resetting env. episode reward total was -8.0. running mean: 1.1933547185893298\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2014211714034366\n",
      "resetting env. episode reward total was -4.0. running mean: 1.1494069596894023\n",
      "resetting env. episode reward total was -11.0. running mean: 1.027912890092508\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9276337611915829\n",
      "resetting env. episode reward total was 7.0. running mean: 0.988357423579667\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0484738493438703\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0679891108504316\n",
      "resetting env. episode reward total was -2.0. running mean: 1.0373092197419271\n",
      "resetting env. episode reward total was 7.0. running mean: 1.096936127544508\n",
      "resetting env. episode reward total was 2.0. running mean: 1.1059667662690629\n",
      "resetting env. episode reward total was 9.0. running mean: 1.1849070986063723\n",
      "resetting env. episode reward total was 2.0. running mean: 1.1930580276203087\n",
      "resetting env. episode reward total was -9.0. running mean: 1.0911274473441055\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0702161728706645\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0495140111419579\n",
      "resetting env. episode reward total was 1.0. running mean: 1.0490188710305384\n",
      "resetting env. episode reward total was 5.0. running mean: 1.088528682320233\n",
      "resetting env. episode reward total was -5.0. running mean: 1.0276433954970305\n",
      "resetting env. episode reward total was 14.0. running mean: 1.1573669615420603\n",
      "resetting env. episode reward total was 1.0. running mean: 1.1557932919266396\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2342353590073734\n",
      "resetting env. episode reward total was -9.0. running mean: 1.1318930054172995\n",
      "resetting env. episode reward total was 14.0. running mean: 1.2605740753631265\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1979683346094951\n",
      "resetting env. episode reward total was 8.0. running mean: 1.2659886512634002\n",
      "resetting env. episode reward total was -7.0. running mean: 1.1833287647507662\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2614954771032587\n",
      "resetting env. episode reward total was -3.0. running mean: 1.218880522332226\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1766917171089037\n",
      "resetting env. episode reward total was 2.0. running mean: 1.1849247999378147\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2030755519384366\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1610447964190522\n",
      "resetting env. episode reward total was 7.0. running mean: 1.2194343484548618\n",
      "resetting env. episode reward total was 16.0. running mean: 1.367240004970313\n",
      "resetting env. episode reward total was -4.0. running mean: 1.31356760492061\n",
      "resetting env. episode reward total was 6.0. running mean: 1.360431928871404\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2968276095826898\n",
      "resetting env. episode reward total was 2.0. running mean: 1.303859333486863\n",
      "resetting env. episode reward total was -7.0. running mean: 1.2208207401519942\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3086125327504743\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3155264074229696\n",
      "resetting env. episode reward total was 2.0. running mean: 1.32237114334874\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3591474319152526\n",
      "resetting env. episode reward total was -4.0. running mean: 1.3055559575961\n",
      "resetting env. episode reward total was 2.0. running mean: 1.312500398020139\n",
      "resetting env. episode reward total was -10.0. running mean: 1.1993753940399376\n",
      "resetting env. episode reward total was -10.0. running mean: 1.0873816400995382\n",
      "resetting env. episode reward total was 5.0. running mean: 1.1265078236985429\n",
      "resetting env. episode reward total was -13.0. running mean: 0.9852427454615574\n",
      "resetting env. episode reward total was 10.0. running mean: 1.075390318006942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: 1.0746364148268726\n",
      "resetting env. episode reward total was 5.0. running mean: 1.1138900506786038\n",
      "resetting env. episode reward total was -4.0. running mean: 1.0627511501718176\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1221236386700995\n",
      "resetting env. episode reward total was -4.0. running mean: 1.0709024022833984\n",
      "resetting env. episode reward total was 7.0. running mean: 1.1301933782605644\n",
      "resetting env. episode reward total was -6.0. running mean: 1.0588914444779587\n",
      "resetting env. episode reward total was 8.0. running mean: 1.1283025300331793\n",
      "resetting env. episode reward total was -12.0. running mean: 0.9970195047328475\n",
      "resetting env. episode reward total was 14.0. running mean: 1.127049309685519\n",
      "resetting env. episode reward total was 11.0. running mean: 1.2257788165886638\n",
      "resetting env. episode reward total was 13.0. running mean: 1.343521028422777\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3400858181385493\n",
      "resetting env. episode reward total was -11.0. running mean: 1.2166849599571636\n",
      "resetting env. episode reward total was 8.0. running mean: 1.284518110357592\n",
      "resetting env. episode reward total was -13.0. running mean: 1.1416729292540162\n",
      "resetting env. episode reward total was -9.0. running mean: 1.040256199961476\n",
      "resetting env. episode reward total was -7.0. running mean: 0.959853637961861\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9602551015822424\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9006525505664199\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9916460250607557\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9917295648101482\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0418122691620466\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0713941464704262\n",
      "resetting env. episode reward total was -11.0. running mean: 0.950680205005722\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8911734029556647\n",
      "resetting env. episode reward total was 10.0. running mean: 0.982261668926108\n",
      "resetting env. episode reward total was 4.0. running mean: 1.012439052236847\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9323146617144784\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9029915150973336\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9539615999463602\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9644219839468966\n",
      "resetting env. episode reward total was -8.0. running mean: 0.8747777641074277\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9260299864663535\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9267696866016899\n",
      "resetting env. episode reward total was 3.0. running mean: 0.947501989735673\n",
      "resetting env. episode reward total was -4.0. running mean: 0.8980269698383162\n",
      "resetting env. episode reward total was 11.0. running mean: 0.999046700139933\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0290562331385336\n",
      "resetting env. episode reward total was 8.0. running mean: 1.0987656708071483\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0577780140990767\n",
      "resetting env. episode reward total was -6.0. running mean: 0.9872002339580859\n",
      "resetting env. episode reward total was -7.0. running mean: 0.907328231618505\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9282549493023199\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9989723998092966\n",
      "resetting env. episode reward total was 15.0. running mean: 1.1389826758112036\n",
      "resetting env. episode reward total was 1.0. running mean: 1.1375928490530915\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2162169205625608\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2640547513569353\n",
      "resetting env. episode reward total was -5.0. running mean: 1.201414203843366\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2194000618049323\n",
      "resetting env. episode reward total was 3.0. running mean: 1.237206061186883\n",
      "resetting env. episode reward total was 6.0. running mean: 1.284834000575014\n",
      "resetting env. episode reward total was -2.0. running mean: 1.2519856605692639\n",
      "resetting env. episode reward total was -2.0. running mean: 1.2194658039635713\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3072711459239357\n",
      "resetting env. episode reward total was 13.0. running mean: 1.4241984344646963\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3999564501200492\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4259568856188487\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3616973167626603\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3680803435950337\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4343995401590834\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3700555447574925\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3763549893099176\n",
      "resetting env. episode reward total was 9.0. running mean: 1.4525914394168185\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4580655250226502\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4734848697724237\n",
      "resetting env. episode reward total was -2.0. running mean: 1.4387500210746993\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4743625208639524\n",
      "resetting env. episode reward total was 2.0. running mean: 1.479618895655313\n",
      "resetting env. episode reward total was -9.0. running mean: 1.3748227066987597\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3510744796317722\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3875637348354546\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3836880974871\n",
      "resetting env. episode reward total was -9.0. running mean: 1.2798512165122289\n",
      "resetting env. episode reward total was 1.0. running mean: 1.2770527043471065\n",
      "resetting env. episode reward total was -6.0. running mean: 1.2042821773036354\n",
      "resetting env. episode reward total was -6.0. running mean: 1.132239355530599\n",
      "resetting env. episode reward total was -11.0. running mean: 1.010916961975293\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0708077923555401\n",
      "resetting env. episode reward total was 5.0. running mean: 1.1100997144319849\n",
      "resetting env. episode reward total was 9.0. running mean: 1.188998717287665\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2371087301147885\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2447376428136405\n",
      "resetting env. episode reward total was -13.0. running mean: 1.1022902663855043\n",
      "resetting env. episode reward total was -5.0. running mean: 1.0412673637216492\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9408546900844327\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9214461431835883\n",
      "resetting env. episode reward total was -13.0. running mean: 0.7822316817517524\n",
      "resetting env. episode reward total was 10.0. running mean: 0.8744093649342348\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9356652712848925\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9563086185720436\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9967455323863232\n",
      "resetting env. episode reward total was 7.0. running mean: 1.05677807706246\n",
      "resetting env. episode reward total was 10.0. running mean: 1.1462102962918355\n",
      "resetting env. episode reward total was -11.0. running mean: 1.024748193328917\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9645007113956279\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0248557042816715\n",
      "resetting env. episode reward total was 10.0. running mean: 1.1146071472388548\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0934610757664662\n",
      "resetting env. episode reward total was 6.0. running mean: 1.1425264650088016\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1011012003587135\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1300901883551264\n",
      "resetting env. episode reward total was 8.0. running mean: 1.1987892864715752\n",
      "resetting env. episode reward total was 19.0. running mean: 1.3768013936068595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 16.0. running mean: 1.5230333796707909\n",
      "resetting env. episode reward total was 7.0. running mean: 1.577803045874083\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6120250154153422\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5659047652611886\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5402457176085766\n",
      "resetting env. episode reward total was -13.0. running mean: 1.394843260432491\n",
      "resetting env. episode reward total was 10.0. running mean: 1.4808948278281662\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5360858795498846\n",
      "resetting env. episode reward total was 17.0. running mean: 1.6907250207543858\n",
      "resetting env. episode reward total was 4.0. running mean: 1.713817770546842\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7166795928413736\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7395127969129598\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7021176689438302\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6350964922543918\n",
      "resetting env. episode reward total was -12.0. running mean: 1.498745527331848\n",
      "resetting env. episode reward total was 14.0. running mean: 1.6237580720585294\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5575204913379441\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5519452864245646\n",
      "resetting env. episode reward total was -9.0. running mean: 1.4464258335603188\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4019615752247157\n",
      "resetting env. episode reward total was 12.0. running mean: 1.5079419594724683\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5228625398777436\n",
      "resetting env. episode reward total was -11.0. running mean: 1.397633914478966\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3336575753341764\n",
      "resetting env. episode reward total was -6.0. running mean: 1.2603209995808347\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1977177895850262\n",
      "resetting env. episode reward total was 4.0. running mean: 1.225740611689176\n",
      "resetting env. episode reward total was -8.0. running mean: 1.133483205572284\n",
      "resetting env. episode reward total was 11.0. running mean: 1.2321483735165613\n",
      "resetting env. episode reward total was 12.0. running mean: 1.3398268897813956\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3664286208835816\n",
      "resetting env. episode reward total was 13.0. running mean: 1.4827643346747457\n",
      "resetting env. episode reward total was -5.0. running mean: 1.417936691327998\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4837573244147182\n",
      "resetting env. episode reward total was -9.0. running mean: 1.3789197511705709\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4151305536588652\n",
      "resetting env. episode reward total was -15.0. running mean: 1.2509792481222766\n",
      "resetting env. episode reward total was -2.0. running mean: 1.2184694556410538\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2262847610846432\n",
      "resetting env. episode reward total was -6.0. running mean: 1.1540219134737968\n",
      "resetting env. episode reward total was 1.0. running mean: 1.1524816943390588\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1109568773956682\n",
      "resetting env. episode reward total was -5.0. running mean: 1.0498473086217115\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9693488355354942\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9396553471801392\n",
      "resetting env. episode reward total was -11.0. running mean: 0.8202587937083379\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8220562057712545\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7838356437135419\n",
      "resetting env. episode reward total was 1.0. running mean: 0.7859972872764065\n",
      "resetting env. episode reward total was 1.0. running mean: 0.7881373144036424\n",
      "resetting env. episode reward total was 2.0. running mean: 0.800255941259606\n",
      "resetting env. episode reward total was -6.0. running mean: 0.7322533818470098\n",
      "resetting env. episode reward total was 2.0. running mean: 0.7449308480285397\n",
      "resetting env. episode reward total was 4.0. running mean: 0.7774815395482544\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7397067241527718\n",
      "resetting env. episode reward total was 14.0. running mean: 0.8723096569112441\n",
      "resetting env. episode reward total was -7.0. running mean: 0.7935865603421317\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7556506947387104\n",
      "resetting env. episode reward total was -9.0. running mean: 0.6580941877913233\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6415132459134101\n",
      "resetting env. episode reward total was 2.0. running mean: 0.655098113454276\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6885471323197333\n",
      "resetting env. episode reward total was 14.0. running mean: 0.8216616609965359\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7834450443865705\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7456105939427048\n",
      "resetting env. episode reward total was -9.0. running mean: 0.6481544880032778\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7016729431232449\n",
      "resetting env. episode reward total was 2.0. running mean: 0.7146562136920125\n",
      "resetting env. episode reward total was -4.0. running mean: 0.6675096515550923\n",
      "resetting env. episode reward total was 1.0. running mean: 0.6708345550395414\n",
      "resetting env. episode reward total was -10.0. running mean: 0.5641262094891459\n",
      "resetting env. episode reward total was 6.0. running mean: 0.6184849473942544\n",
      "resetting env. episode reward total was 1.0. running mean: 0.6223000979203118\n",
      "resetting env. episode reward total was 8.0. running mean: 0.6960770969411086\n",
      "resetting env. episode reward total was -7.0. running mean: 0.6191163259716976\n",
      "resetting env. episode reward total was 11.0. running mean: 0.7229251627119806\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7056959110848607\n",
      "resetting env. episode reward total was 2.0. running mean: 0.7186389519740122\n",
      "resetting env. episode reward total was -6.0. running mean: 0.651452562454272\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6849380368297293\n",
      "resetting env. episode reward total was -3.0. running mean: 0.648088656461432\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6316077698968177\n",
      "resetting env. episode reward total was -6.0. running mean: 0.5652916921978495\n",
      "resetting env. episode reward total was -9.0. running mean: 0.46963877527587106\n",
      "resetting env. episode reward total was -17.0. running mean: 0.2949423875231123\n",
      "resetting env. episode reward total was -9.0. running mean: 0.2019929636478812\n",
      "resetting env. episode reward total was 3.0. running mean: 0.22997303401140237\n",
      "resetting env. episode reward total was 8.0. running mean: 0.30767330367128837\n",
      "resetting env. episode reward total was -7.0. running mean: 0.23459657063457545\n",
      "resetting env. episode reward total was -8.0. running mean: 0.15225060492822967\n",
      "resetting env. episode reward total was -9.0. running mean: 0.06072809887894737\n",
      "resetting env. episode reward total was 8.0. running mean: 0.1401208178901579\n",
      "resetting env. episode reward total was -1.0. running mean: 0.12871960971125632\n",
      "resetting env. episode reward total was 4.0. running mean: 0.16743241361414377\n",
      "resetting env. episode reward total was -4.0. running mean: 0.12575808947800232\n",
      "resetting env. episode reward total was 6.0. running mean: 0.1845005085832223\n",
      "resetting env. episode reward total was 9.0. running mean: 0.2726555034973901\n",
      "resetting env. episode reward total was 3.0. running mean: 0.29992894846241624\n",
      "resetting env. episode reward total was -5.0. running mean: 0.24692965897779207\n",
      "resetting env. episode reward total was -1.0. running mean: 0.23446036238801413\n",
      "resetting env. episode reward total was -4.0. running mean: 0.19211575876413398\n",
      "resetting env. episode reward total was -5.0. running mean: 0.14019460117649263\n",
      "resetting env. episode reward total was 2.0. running mean: 0.15879265516472768\n",
      "resetting env. episode reward total was -13.0. running mean: 0.027204728613080403\n",
      "resetting env. episode reward total was -1.0. running mean: 0.016932681326949597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -6.0. running mean: -0.0432366454863199\n",
      "resetting env. episode reward total was -7.0. running mean: -0.1128042790314567\n",
      "resetting env. episode reward total was 6.0. running mean: -0.051676236241142134\n",
      "resetting env. episode reward total was 2.0. running mean: -0.03115947387873071\n",
      "resetting env. episode reward total was -5.0. running mean: -0.0808478791399434\n",
      "resetting env. episode reward total was 8.0. running mean: -3.940034854396646e-05\n",
      "resetting env. episode reward total was 9.0. running mean: 0.08996099365494147\n",
      "resetting env. episode reward total was -2.0. running mean: 0.06906138371839204\n",
      "resetting env. episode reward total was 1.0. running mean: 0.07837076988120811\n",
      "resetting env. episode reward total was -1.0. running mean: 0.06758706218239603\n",
      "resetting env. episode reward total was 10.0. running mean: 0.16691119156057208\n",
      "resetting env. episode reward total was -6.0. running mean: 0.10524207964496635\n",
      "resetting env. episode reward total was -6.0. running mean: 0.04418965884851668\n",
      "resetting env. episode reward total was -16.0. running mean: -0.11625223773996848\n",
      "resetting env. episode reward total was 4.0. running mean: -0.07508971536256881\n",
      "resetting env. episode reward total was 7.0. running mean: -0.004338818208943121\n",
      "resetting env. episode reward total was 5.0. running mean: 0.045704569973146314\n",
      "resetting env. episode reward total was 10.0. running mean: 0.14524752427341486\n",
      "resetting env. episode reward total was -15.0. running mean: -0.006204950969319278\n",
      "resetting env. episode reward total was 8.0. running mean: 0.07385709854037392\n",
      "resetting env. episode reward total was 4.0. running mean: 0.11311852755497018\n",
      "resetting env. episode reward total was -8.0. running mean: 0.031987342279420475\n",
      "resetting env. episode reward total was 12.0. running mean: 0.15166746885662627\n",
      "resetting env. episode reward total was 4.0. running mean: 0.19015079416806002\n",
      "resetting env. episode reward total was -12.0. running mean: 0.06824928622637944\n",
      "resetting env. episode reward total was -4.0. running mean: 0.02756679336411564\n",
      "resetting env. episode reward total was 5.0. running mean: 0.07729112543047448\n",
      "resetting env. episode reward total was 3.0. running mean: 0.10651821417616973\n",
      "resetting env. episode reward total was -1.0. running mean: 0.09545303203440804\n",
      "resetting env. episode reward total was 5.0. running mean: 0.14449850171406398\n",
      "resetting env. episode reward total was -1.0. running mean: 0.13305351669692334\n",
      "resetting env. episode reward total was -6.0. running mean: 0.0717229815299541\n",
      "resetting env. episode reward total was -9.0. running mean: -0.018994248285345433\n",
      "resetting env. episode reward total was 1.0. running mean: -0.00880430580249198\n",
      "resetting env. episode reward total was -7.0. running mean: -0.07871626274446707\n",
      "resetting env. episode reward total was -10.0. running mean: -0.1779291001170224\n",
      "resetting env. episode reward total was -9.0. running mean: -0.2661498091158522\n",
      "resetting env. episode reward total was 8.0. running mean: -0.18348831102469365\n",
      "resetting env. episode reward total was -2.0. running mean: -0.2016534279144467\n",
      "resetting env. episode reward total was -8.0. running mean: -0.27963689363530225\n",
      "resetting env. episode reward total was -14.0. running mean: -0.4168405246989492\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4426721194519597\n",
      "resetting env. episode reward total was -7.0. running mean: -0.5082453982574402\n",
      "resetting env. episode reward total was -11.0. running mean: -0.6131629442748657\n",
      "resetting env. episode reward total was 3.0. running mean: -0.577031314832117\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6212610016837958\n",
      "resetting env. episode reward total was -9.0. running mean: -0.7050483916669579\n",
      "resetting env. episode reward total was 14.0. running mean: -0.5579979077502882\n",
      "resetting env. episode reward total was -4.0. running mean: -0.5924179286727854\n",
      "resetting env. episode reward total was 7.0. running mean: -0.5164937493860575\n",
      "resetting env. episode reward total was 9.0. running mean: -0.42132881189219695\n",
      "resetting env. episode reward total was -11.0. running mean: -0.527115523773275\n",
      "resetting env. episode reward total was 3.0. running mean: -0.49184436853554214\n",
      "resetting env. episode reward total was 1.0. running mean: -0.4769259248501867\n",
      "resetting env. episode reward total was -14.0. running mean: -0.6121566656016848\n",
      "resetting env. episode reward total was 3.0. running mean: -0.576035098945668\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5802747479562113\n",
      "resetting env. episode reward total was 7.0. running mean: -0.5044720004766492\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5094272804718827\n",
      "resetting env. episode reward total was 6.0. running mean: -0.4443330076671638\n",
      "resetting env. episode reward total was -6.0. running mean: -0.4998896775904922\n",
      "resetting env. episode reward total was 11.0. running mean: -0.3848907808145873\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3510418730064414\n",
      "resetting env. episode reward total was 1.0. running mean: -0.337531454276377\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3041561397336132\n",
      "resetting env. episode reward total was -8.0. running mean: -0.3811145783362771\n",
      "resetting env. episode reward total was -5.0. running mean: -0.4273034325529143\n",
      "resetting env. episode reward total was -1.0. running mean: -0.43303039822738515\n",
      "resetting env. episode reward total was 1.0. running mean: -0.4187000942451113\n",
      "resetting env. episode reward total was 11.0. running mean: -0.3045130933026602\n",
      "resetting env. episode reward total was 8.0. running mean: -0.22146796236963356\n",
      "resetting env. episode reward total was -4.0. running mean: -0.25925328274593723\n",
      "resetting env. episode reward total was -12.0. running mean: -0.37666074991847787\n",
      "resetting env. episode reward total was 1.0. running mean: -0.3628941424192931\n",
      "resetting env. episode reward total was 4.0. running mean: -0.31926520099510014\n",
      "resetting env. episode reward total was -6.0. running mean: -0.37607254898514914\n",
      "resetting env. episode reward total was -10.0. running mean: -0.47231182349529766\n",
      "resetting env. episode reward total was -2.0. running mean: -0.4875887052603447\n",
      "resetting env. episode reward total was 13.0. running mean: -0.35271281820774125\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3191856900256639\n",
      "resetting env. episode reward total was -5.0. running mean: -0.36599383312540723\n",
      "resetting env. episode reward total was 6.0. running mean: -0.3023338947941532\n",
      "resetting env. episode reward total was 13.0. running mean: -0.16931055584621163\n",
      "resetting env. episode reward total was 9.0. running mean: -0.07761745028774952\n",
      "resetting env. episode reward total was -7.0. running mean: -0.14684127578487205\n",
      "resetting env. episode reward total was 6.0. running mean: -0.08537286302702332\n",
      "resetting env. episode reward total was -4.0. running mean: -0.12451913439675308\n",
      "resetting env. episode reward total was -7.0. running mean: -0.19327394305278556\n",
      "resetting env. episode reward total was 6.0. running mean: -0.1313412036222577\n",
      "resetting env. episode reward total was 8.0. running mean: -0.05002779158603514\n",
      "resetting env. episode reward total was 2.0. running mean: -0.029527513670174785\n",
      "resetting env. episode reward total was 4.0. running mean: 0.010767761466526964\n",
      "resetting env. episode reward total was 4.0. running mean: 0.050660083851861694\n",
      "resetting env. episode reward total was 2.0. running mean: 0.07015348301334308\n",
      "resetting env. episode reward total was -11.0. running mean: -0.04054805181679036\n",
      "resetting env. episode reward total was 3.0. running mean: -0.010142571298622456\n",
      "resetting env. episode reward total was -7.0. running mean: -0.08004114558563624\n",
      "resetting env. episode reward total was 4.0. running mean: -0.039240734129779874\n",
      "resetting env. episode reward total was -9.0. running mean: -0.12884832678848207\n",
      "resetting env. episode reward total was 6.0. running mean: -0.06755984352059724\n",
      "resetting env. episode reward total was 3.0. running mean: -0.03688424508539127\n",
      "resetting env. episode reward total was 5.0. running mean: 0.01348459736546264\n",
      "resetting env. episode reward total was 2.0. running mean: 0.033349751391808014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: 0.04301625387788993\n",
      "resetting env. episode reward total was -3.0. running mean: 0.012586091339111032\n",
      "resetting env. episode reward total was 10.0. running mean: 0.11246023042571993\n",
      "resetting env. episode reward total was 1.0. running mean: 0.12133562812146272\n",
      "resetting env. episode reward total was 4.0. running mean: 0.16012227184024808\n",
      "resetting env. episode reward total was 3.0. running mean: 0.18852104912184559\n",
      "resetting env. episode reward total was 2.0. running mean: 0.20663583863062712\n",
      "resetting env. episode reward total was 7.0. running mean: 0.2745694802443208\n",
      "resetting env. episode reward total was -14.0. running mean: 0.13182378544187762\n",
      "resetting env. episode reward total was -5.0. running mean: 0.08050554758745883\n",
      "resetting env. episode reward total was 6.0. running mean: 0.13970049211158425\n",
      "resetting env. episode reward total was 10.0. running mean: 0.2383034871904684\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2059204523185637\n",
      "resetting env. episode reward total was -11.0. running mean: 0.09386124779537806\n",
      "resetting env. episode reward total was -11.0. running mean: -0.017077364682575716\n",
      "resetting env. episode reward total was 1.0. running mean: -0.006906591035749957\n",
      "resetting env. episode reward total was -3.0. running mean: -0.036837525125392456\n",
      "resetting env. episode reward total was -2.0. running mean: -0.056469149874138536\n",
      "resetting env. episode reward total was 6.0. running mean: 0.00409554162460285\n",
      "resetting env. episode reward total was 4.0. running mean: 0.044054586208356825\n",
      "resetting env. episode reward total was 12.0. running mean: 0.16361404034627325\n",
      "resetting env. episode reward total was -2.0. running mean: 0.14197789994281051\n",
      "resetting env. episode reward total was 3.0. running mean: 0.1705581209433824\n",
      "resetting env. episode reward total was 4.0. running mean: 0.2088525397339486\n",
      "resetting env. episode reward total was 6.0. running mean: 0.2667640143366091\n",
      "resetting env. episode reward total was -3.0. running mean: 0.23409637419324306\n",
      "resetting env. episode reward total was 12.0. running mean: 0.35175541045131065\n",
      "resetting env. episode reward total was 6.0. running mean: 0.40823785634679755\n",
      "resetting env. episode reward total was 1.0. running mean: 0.41415547778332956\n",
      "resetting env. episode reward total was -10.0. running mean: 0.31001392300549624\n",
      "resetting env. episode reward total was 1.0. running mean: 0.31691378377544127\n",
      "resetting env. episode reward total was 10.0. running mean: 0.4137446459376869\n",
      "resetting env. episode reward total was 6.0. running mean: 0.46960719947831003\n",
      "resetting env. episode reward total was 1.0. running mean: 0.47491112748352693\n",
      "resetting env. episode reward total was -11.0. running mean: 0.36016201620869165\n",
      "resetting env. episode reward total was -8.0. running mean: 0.2765603960466047\n",
      "resetting env. episode reward total was -15.0. running mean: 0.12379479208613867\n",
      "resetting env. episode reward total was -10.0. running mean: 0.02255684416527727\n",
      "resetting env. episode reward total was -1.0. running mean: 0.012331275723624498\n",
      "resetting env. episode reward total was -13.0. running mean: -0.11779203703361175\n",
      "resetting env. episode reward total was -7.0. running mean: -0.18661411666327565\n",
      "resetting env. episode reward total was -11.0. running mean: -0.2947479754966429\n",
      "resetting env. episode reward total was -3.0. running mean: -0.32180049574167646\n",
      "resetting env. episode reward total was 2.0. running mean: -0.2985824907842597\n",
      "resetting env. episode reward total was 3.0. running mean: -0.26559666587641706\n",
      "resetting env. episode reward total was 8.0. running mean: -0.18294069921765288\n",
      "resetting env. episode reward total was -4.0. running mean: -0.22111129222547635\n",
      "resetting env. episode reward total was -4.0. running mean: -0.25890017930322157\n",
      "resetting env. episode reward total was 2.0. running mean: -0.23631117751018935\n",
      "resetting env. episode reward total was -11.0. running mean: -0.34394806573508746\n",
      "resetting env. episode reward total was -5.0. running mean: -0.39050858507773656\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3566034992269592\n",
      "resetting env. episode reward total was -12.0. running mean: -0.4730374642346896\n",
      "resetting env. episode reward total was 5.0. running mean: -0.41830708959234275\n",
      "resetting env. episode reward total was 6.0. running mean: -0.3541240186964193\n",
      "resetting env. episode reward total was 1.0. running mean: -0.34058277850945506\n",
      "resetting env. episode reward total was -6.0. running mean: -0.3971769507243605\n",
      "resetting env. episode reward total was -2.0. running mean: -0.4132051812171169\n",
      "resetting env. episode reward total was 10.0. running mean: -0.3090731294049457\n",
      "resetting env. episode reward total was -11.0. running mean: -0.4159823981108962\n",
      "resetting env. episode reward total was -1.0. running mean: -0.42182257412978724\n",
      "resetting env. episode reward total was -1.0. running mean: -0.4276043483884894\n",
      "resetting env. episode reward total was 1.0. running mean: -0.4133283049046045\n",
      "resetting env. episode reward total was -5.0. running mean: -0.45919502185555844\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4846030716370029\n",
      "resetting env. episode reward total was -12.0. running mean: -0.5997570409206329\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6037594705114265\n",
      "resetting env. episode reward total was -9.0. running mean: -0.6877218758063123\n",
      "resetting env. episode reward total was -3.0. running mean: -0.7108446570482492\n",
      "resetting env. episode reward total was -7.0. running mean: -0.7737362104777668\n",
      "resetting env. episode reward total was 2.0. running mean: -0.745998848372989\n",
      "resetting env. episode reward total was -3.0. running mean: -0.7685388598892592\n",
      "resetting env. episode reward total was -13.0. running mean: -0.8908534712903666\n",
      "resetting env. episode reward total was -8.0. running mean: -0.9619449365774629\n",
      "resetting env. episode reward total was 4.0. running mean: -0.9123254872116883\n",
      "resetting env. episode reward total was 10.0. running mean: -0.8032022323395714\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8451702100161758\n",
      "resetting env. episode reward total was -7.0. running mean: -0.906718507916014\n",
      "resetting env. episode reward total was 1.0. running mean: -0.8876513228368539\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8587748096084853\n",
      "resetting env. episode reward total was -8.0. running mean: -0.9301870615124004\n",
      "resetting env. episode reward total was -15.0. running mean: -1.0708851908972763\n",
      "resetting env. episode reward total was 1.0. running mean: -1.0501763389883034\n",
      "resetting env. episode reward total was -4.0. running mean: -1.0796745755984205\n",
      "resetting env. episode reward total was -4.0. running mean: -1.1088778298424364\n",
      "resetting env. episode reward total was -4.0. running mean: -1.137789051544012\n",
      "resetting env. episode reward total was -6.0. running mean: -1.1864111610285721\n",
      "resetting env. episode reward total was 6.0. running mean: -1.1145470494182863\n",
      "resetting env. episode reward total was -11.0. running mean: -1.2134015789241035\n",
      "resetting env. episode reward total was 1.0. running mean: -1.1912675631348624\n",
      "resetting env. episode reward total was -1.0. running mean: -1.1893548875035138\n",
      "resetting env. episode reward total was -17.0. running mean: -1.3474613386284786\n",
      "resetting env. episode reward total was -9.0. running mean: -1.4239867252421938\n",
      "resetting env. episode reward total was -9.0. running mean: -1.499746857989772\n",
      "resetting env. episode reward total was -12.0. running mean: -1.604749389409874\n",
      "resetting env. episode reward total was -6.0. running mean: -1.6487018955157755\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6822148765606177\n",
      "resetting env. episode reward total was -5.0. running mean: -1.7153927277950116\n",
      "resetting env. episode reward total was -1.0. running mean: -1.7082388005170615\n",
      "resetting env. episode reward total was -7.0. running mean: -1.7611564125118908\n",
      "resetting env. episode reward total was -10.0. running mean: -1.843544848386772\n",
      "resetting env. episode reward total was -11.0. running mean: -1.9351093999029043\n",
      "resetting env. episode reward total was -9.0. running mean: -2.0057583059038753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -2.0557007228448363\n",
      "resetting env. episode reward total was 3.0. running mean: -2.0051437156163883\n",
      "resetting env. episode reward total was -3.0. running mean: -2.0150922784602243\n",
      "resetting env. episode reward total was 11.0. running mean: -1.884941355675622\n",
      "resetting env. episode reward total was -2.0. running mean: -1.8860919421188658\n",
      "resetting env. episode reward total was -3.0. running mean: -1.8972310226976772\n",
      "resetting env. episode reward total was 3.0. running mean: -1.8482587124707004\n",
      "resetting env. episode reward total was 6.0. running mean: -1.7697761253459934\n",
      "resetting env. episode reward total was -13.0. running mean: -1.8820783640925334\n",
      "resetting env. episode reward total was 3.0. running mean: -1.833257580451608\n",
      "resetting env. episode reward total was -2.0. running mean: -1.834925004647092\n",
      "resetting env. episode reward total was 5.0. running mean: -1.7665757546006209\n",
      "resetting env. episode reward total was 8.0. running mean: -1.6689099970546146\n",
      "resetting env. episode reward total was 15.0. running mean: -1.5022208970840685\n",
      "resetting env. episode reward total was 4.0. running mean: -1.4471986881132277\n",
      "resetting env. episode reward total was -3.0. running mean: -1.4627267012320955\n",
      "resetting env. episode reward total was 2.0. running mean: -1.4280994342197746\n",
      "resetting env. episode reward total was -6.0. running mean: -1.4738184398775769\n",
      "resetting env. episode reward total was -9.0. running mean: -1.5490802554788012\n",
      "resetting env. episode reward total was 7.0. running mean: -1.4635894529240132\n",
      "resetting env. episode reward total was 1.0. running mean: -1.438953558394773\n",
      "resetting env. episode reward total was -1.0. running mean: -1.4345640228108252\n",
      "resetting env. episode reward total was -5.0. running mean: -1.4702183825827169\n",
      "resetting env. episode reward total was -8.0. running mean: -1.5355161987568897\n",
      "resetting env. episode reward total was -12.0. running mean: -1.640161036769321\n",
      "resetting env. episode reward total was 4.0. running mean: -1.5837594264016277\n",
      "resetting env. episode reward total was 7.0. running mean: -1.4979218321376113\n",
      "resetting env. episode reward total was -2.0. running mean: -1.5029426138162352\n",
      "resetting env. episode reward total was -3.0. running mean: -1.517913187678073\n",
      "resetting env. episode reward total was 10.0. running mean: -1.4027340558012922\n",
      "resetting env. episode reward total was 2.0. running mean: -1.3687067152432792\n",
      "resetting env. episode reward total was 1.0. running mean: -1.3450196480908465\n",
      "resetting env. episode reward total was 4.0. running mean: -1.291569451609938\n",
      "resetting env. episode reward total was 16.0. running mean: -1.1186537570938389\n",
      "resetting env. episode reward total was 8.0. running mean: -1.0274672195229004\n",
      "resetting env. episode reward total was -5.0. running mean: -1.0671925473276715\n",
      "resetting env. episode reward total was -11.0. running mean: -1.1665206218543949\n",
      "resetting env. episode reward total was 3.0. running mean: -1.1248554156358508\n",
      "resetting env. episode reward total was -10.0. running mean: -1.2136068614794924\n",
      "resetting env. episode reward total was 3.0. running mean: -1.1714707928646975\n",
      "resetting env. episode reward total was 2.0. running mean: -1.1397560849360504\n",
      "resetting env. episode reward total was -6.0. running mean: -1.1883585240866898\n",
      "resetting env. episode reward total was -5.0. running mean: -1.226474938845823\n",
      "resetting env. episode reward total was -5.0. running mean: -1.2642101894573647\n",
      "resetting env. episode reward total was -15.0. running mean: -1.401568087562791\n",
      "resetting env. episode reward total was -7.0. running mean: -1.457552406687163\n",
      "resetting env. episode reward total was -9.0. running mean: -1.5329768826202914\n",
      "resetting env. episode reward total was -8.0. running mean: -1.5976471137940886\n",
      "resetting env. episode reward total was 2.0. running mean: -1.5616706426561477\n",
      "resetting env. episode reward total was 6.0. running mean: -1.4860539362295861\n",
      "resetting env. episode reward total was 5.0. running mean: -1.4211933968672903\n",
      "resetting env. episode reward total was 3.0. running mean: -1.3769814628986174\n",
      "resetting env. episode reward total was -12.0. running mean: -1.4832116482696311\n",
      "resetting env. episode reward total was 8.0. running mean: -1.3883795317869347\n",
      "resetting env. episode reward total was -11.0. running mean: -1.4844957364690654\n",
      "resetting env. episode reward total was 6.0. running mean: -1.4096507791043746\n",
      "resetting env. episode reward total was -19.0. running mean: -1.5855542713133308\n",
      "resetting env. episode reward total was -1.0. running mean: -1.5796987286001976\n",
      "resetting env. episode reward total was 3.0. running mean: -1.5339017413141955\n",
      "resetting env. episode reward total was -1.0. running mean: -1.5285627239010535\n",
      "resetting env. episode reward total was -7.0. running mean: -1.583277096662043\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6174443256954227\n",
      "resetting env. episode reward total was -2.0. running mean: -1.6212698824384686\n",
      "resetting env. episode reward total was -1.0. running mean: -1.615057183614084\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6489066117779432\n",
      "resetting env. episode reward total was -9.0. running mean: -1.7224175456601638\n",
      "resetting env. episode reward total was -3.0. running mean: -1.7351933702035622\n",
      "resetting env. episode reward total was 13.0. running mean: -1.5878414365015265\n",
      "resetting env. episode reward total was -4.0. running mean: -1.6119630221365113\n",
      "resetting env. episode reward total was -15.0. running mean: -1.7458433919151461\n",
      "resetting env. episode reward total was 5.0. running mean: -1.6783849579959946\n",
      "resetting env. episode reward total was -9.0. running mean: -1.7516011084160348\n",
      "resetting env. episode reward total was -7.0. running mean: -1.8040850973318745\n",
      "resetting env. episode reward total was -1.0. running mean: -1.7960442463585558\n",
      "resetting env. episode reward total was -13.0. running mean: -1.9080838038949701\n",
      "resetting env. episode reward total was 8.0. running mean: -1.8090029658560203\n",
      "resetting env. episode reward total was -1.0. running mean: -1.80091293619746\n",
      "resetting env. episode reward total was -5.0. running mean: -1.8329038068354855\n",
      "resetting env. episode reward total was -9.0. running mean: -1.9045747687671306\n",
      "resetting env. episode reward total was -5.0. running mean: -1.9355290210794593\n",
      "resetting env. episode reward total was -14.0. running mean: -2.056173730868665\n",
      "resetting env. episode reward total was -7.0. running mean: -2.105611993559978\n",
      "resetting env. episode reward total was -5.0. running mean: -2.134555873624378\n",
      "resetting env. episode reward total was -5.0. running mean: -2.163210314888134\n",
      "resetting env. episode reward total was -9.0. running mean: -2.2315782117392526\n",
      "resetting env. episode reward total was -1.0. running mean: -2.21926242962186\n",
      "resetting env. episode reward total was -5.0. running mean: -2.247069805325641\n",
      "resetting env. episode reward total was 4.0. running mean: -2.1845991072723847\n",
      "resetting env. episode reward total was -2.0. running mean: -2.182753116199661\n",
      "resetting env. episode reward total was -3.0. running mean: -2.190925585037664\n",
      "resetting env. episode reward total was 7.0. running mean: -2.0990163291872874\n",
      "resetting env. episode reward total was -1.0. running mean: -2.0880261658954145\n",
      "resetting env. episode reward total was -1.0. running mean: -2.07714590423646\n",
      "resetting env. episode reward total was -3.0. running mean: -2.0863744451940955\n",
      "resetting env. episode reward total was -5.0. running mean: -2.1155107007421545\n",
      "resetting env. episode reward total was 5.0. running mean: -2.0443555937347333\n",
      "resetting env. episode reward total was 11.0. running mean: -1.9139120377973857\n",
      "resetting env. episode reward total was 2.0. running mean: -1.8747729174194119\n",
      "resetting env. episode reward total was 13.0. running mean: -1.7260251882452176\n",
      "resetting env. episode reward total was -3.0. running mean: -1.7387649363627653\n",
      "resetting env. episode reward total was 3.0. running mean: -1.6913772869991377\n",
      "resetting env. episode reward total was -17.0. running mean: -1.8444635141291463\n",
      "resetting env. episode reward total was -3.0. running mean: -1.856018878987855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -1.9074586901979764\n",
      "resetting env. episode reward total was -8.0. running mean: -1.9683841032959968\n",
      "resetting env. episode reward total was -6.0. running mean: -2.0087002622630368\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9986132596404065\n",
      "resetting env. episode reward total was 12.0. running mean: -1.8586271270440022\n",
      "resetting env. episode reward total was -2.0. running mean: -1.8600408557735622\n",
      "resetting env. episode reward total was 4.0. running mean: -1.8014404472158265\n",
      "resetting env. episode reward total was -9.0. running mean: -1.8734260427436684\n",
      "resetting env. episode reward total was -9.0. running mean: -1.9446917823162317\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9552448644930693\n",
      "resetting env. episode reward total was -7.0. running mean: -2.0056924158481384\n",
      "resetting env. episode reward total was 2.0. running mean: -1.965635491689657\n",
      "resetting env. episode reward total was -2.0. running mean: -1.9659791367727604\n",
      "resetting env. episode reward total was 7.0. running mean: -1.8763193454050326\n",
      "resetting env. episode reward total was 4.0. running mean: -1.8175561519509822\n",
      "resetting env. episode reward total was -13.0. running mean: -1.9293805904314723\n",
      "resetting env. episode reward total was 2.0. running mean: -1.8900867845271574\n",
      "resetting env. episode reward total was 3.0. running mean: -1.8411859166818858\n",
      "resetting env. episode reward total was -9.0. running mean: -1.912774057515067\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9236463169399163\n",
      "resetting env. episode reward total was -5.0. running mean: -1.9544098537705172\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9648657552328122\n",
      "resetting env. episode reward total was -3.0. running mean: -1.9752170976804841\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9654649267036792\n",
      "resetting env. episode reward total was 5.0. running mean: -1.8958102774366423\n",
      "resetting env. episode reward total was -6.0. running mean: -1.936852174662276\n",
      "resetting env. episode reward total was -1.0. running mean: -1.9274836529156532\n",
      "resetting env. episode reward total was 10.0. running mean: -1.8082088163864964\n",
      "resetting env. episode reward total was 8.0. running mean: -1.7101267282226313\n",
      "resetting env. episode reward total was -7.0. running mean: -1.763025460940405\n",
      "resetting env. episode reward total was -9.0. running mean: -1.835395206331001\n",
      "resetting env. episode reward total was 4.0. running mean: -1.777041254267691\n",
      "resetting env. episode reward total was -1.0. running mean: -1.769270841725014\n",
      "resetting env. episode reward total was 4.0. running mean: -1.7115781333077638\n",
      "resetting env. episode reward total was 2.0. running mean: -1.6744623519746862\n",
      "resetting env. episode reward total was -18.0. running mean: -1.8377177284549393\n",
      "resetting env. episode reward total was -5.0. running mean: -1.86934055117039\n",
      "resetting env. episode reward total was -1.0. running mean: -1.8606471456586862\n",
      "resetting env. episode reward total was 14.0. running mean: -1.7020406742020993\n",
      "resetting env. episode reward total was 12.0. running mean: -1.5650202674600782\n",
      "resetting env. episode reward total was -3.0. running mean: -1.5793700647854774\n",
      "resetting env. episode reward total was 9.0. running mean: -1.4735763641376225\n",
      "resetting env. episode reward total was 7.0. running mean: -1.3888406004962461\n",
      "resetting env. episode reward total was 4.0. running mean: -1.3349521944912837\n",
      "resetting env. episode reward total was -1.0. running mean: -1.3316026725463708\n",
      "resetting env. episode reward total was 8.0. running mean: -1.238286645820907\n",
      "resetting env. episode reward total was -5.0. running mean: -1.275903779362698\n",
      "resetting env. episode reward total was 5.0. running mean: -1.2131447415690708\n",
      "resetting env. episode reward total was 4.0. running mean: -1.1610132941533802\n",
      "resetting env. episode reward total was -3.0. running mean: -1.1794031612118463\n",
      "resetting env. episode reward total was 10.0. running mean: -1.0676091295997276\n",
      "resetting env. episode reward total was 14.0. running mean: -0.9169330383037303\n",
      "resetting env. episode reward total was -13.0. running mean: -1.037763707920693\n",
      "resetting env. episode reward total was -5.0. running mean: -1.077386070841486\n",
      "resetting env. episode reward total was 5.0. running mean: -1.016612210133071\n",
      "resetting env. episode reward total was 2.0. running mean: -0.9864460880317403\n",
      "resetting env. episode reward total was 4.0. running mean: -0.9365816271514228\n",
      "resetting env. episode reward total was 6.0. running mean: -0.8672158108799086\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9285436527711095\n",
      "resetting env. episode reward total was -4.0. running mean: -0.9592582162433985\n",
      "resetting env. episode reward total was -8.0. running mean: -1.0296656340809645\n",
      "resetting env. episode reward total was 3.0. running mean: -0.9893689777401549\n",
      "resetting env. episode reward total was 9.0. running mean: -0.8894752879627533\n",
      "resetting env. episode reward total was -1.0. running mean: -0.8905805350831258\n",
      "resetting env. episode reward total was -10.0. running mean: -0.9816747297322945\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9818579824349716\n",
      "resetting env. episode reward total was 1.0. running mean: -0.9620394026106218\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9624190085845156\n",
      "resetting env. episode reward total was -1.0. running mean: -0.9627948184986704\n",
      "resetting env. episode reward total was 6.0. running mean: -0.8931668703136837\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9542352016105469\n",
      "resetting env. episode reward total was 3.0. running mean: -0.9146928495944414\n",
      "resetting env. episode reward total was 5.0. running mean: -0.8555459210984969\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8069904618875119\n",
      "resetting env. episode reward total was -2.0. running mean: -0.8189205572686368\n",
      "resetting env. episode reward total was -2.0. running mean: -0.8307313516959505\n",
      "resetting env. episode reward total was -2.0. running mean: -0.842424038178991\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8639997977972012\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8153597998192291\n",
      "resetting env. episode reward total was -8.0. running mean: -0.8872062018210368\n",
      "resetting env. episode reward total was -7.0. running mean: -0.9483341398028264\n",
      "resetting env. episode reward total was -15.0. running mean: -1.0888507984047981\n",
      "resetting env. episode reward total was -1.0. running mean: -1.0879622904207502\n",
      "resetting env. episode reward total was -8.0. running mean: -1.1570826675165429\n",
      "resetting env. episode reward total was -7.0. running mean: -1.2155118408413774\n",
      "resetting env. episode reward total was -4.0. running mean: -1.2433567224329636\n",
      "resetting env. episode reward total was -6.0. running mean: -1.290923155208634\n",
      "resetting env. episode reward total was 3.0. running mean: -1.2480139236565475\n",
      "resetting env. episode reward total was -1.0. running mean: -1.245533784419982\n",
      "resetting env. episode reward total was -1.0. running mean: -1.2430784465757823\n",
      "resetting env. episode reward total was 8.0. running mean: -1.1506476621100243\n",
      "resetting env. episode reward total was 1.0. running mean: -1.1291411854889242\n",
      "resetting env. episode reward total was -9.0. running mean: -1.207849773634035\n",
      "resetting env. episode reward total was -11.0. running mean: -1.3057712758976947\n",
      "resetting env. episode reward total was -9.0. running mean: -1.3827135631387177\n",
      "resetting env. episode reward total was -7.0. running mean: -1.4388864275073305\n",
      "resetting env. episode reward total was -4.0. running mean: -1.4644975632322572\n",
      "resetting env. episode reward total was -1.0. running mean: -1.4598525875999346\n",
      "resetting env. episode reward total was -1.0. running mean: -1.4552540617239353\n",
      "resetting env. episode reward total was -7.0. running mean: -1.510701521106696\n",
      "resetting env. episode reward total was 1.0. running mean: -1.485594505895629\n",
      "resetting env. episode reward total was 10.0. running mean: -1.3707385608366727\n",
      "resetting env. episode reward total was 9.0. running mean: -1.2670311752283059\n",
      "resetting env. episode reward total was -12.0. running mean: -1.374360863476023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -1.4306172548412628\n",
      "resetting env. episode reward total was -3.0. running mean: -1.4463110822928502\n",
      "resetting env. episode reward total was 2.0. running mean: -1.4118479714699217\n",
      "resetting env. episode reward total was -5.0. running mean: -1.4477294917552226\n",
      "resetting env. episode reward total was -7.0. running mean: -1.5032521968376704\n",
      "resetting env. episode reward total was -7.0. running mean: -1.5582196748692938\n",
      "resetting env. episode reward total was 10.0. running mean: -1.4426374781206008\n",
      "resetting env. episode reward total was 5.0. running mean: -1.3782111033393947\n",
      "resetting env. episode reward total was -5.0. running mean: -1.4144289923060007\n",
      "resetting env. episode reward total was -13.0. running mean: -1.5302847023829407\n",
      "resetting env. episode reward total was -7.0. running mean: -1.5849818553591113\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6191320368055202\n",
      "resetting env. episode reward total was -13.0. running mean: -1.732940716437465\n",
      "resetting env. episode reward total was -9.0. running mean: -1.8056113092730905\n",
      "resetting env. episode reward total was 9.0. running mean: -1.6975551961803594\n",
      "resetting env. episode reward total was -13.0. running mean: -1.810579644218556\n",
      "resetting env. episode reward total was -1.0. running mean: -1.8024738477763704\n",
      "resetting env. episode reward total was -1.0. running mean: -1.7944491092986068\n",
      "resetting env. episode reward total was -12.0. running mean: -1.8965046182056207\n",
      "resetting env. episode reward total was 9.0. running mean: -1.7875395720235643\n",
      "resetting env. episode reward total was 8.0. running mean: -1.6896641763033287\n",
      "resetting env. episode reward total was 4.0. running mean: -1.6327675345402952\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6464398591948923\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6599754606029433\n",
      "resetting env. episode reward total was -1.0. running mean: -1.6533757059969139\n",
      "resetting env. episode reward total was 2.0. running mean: -1.6168419489369448\n",
      "resetting env. episode reward total was -2.0. running mean: -1.6206735294475754\n",
      "resetting env. episode reward total was -4.0. running mean: -1.6444667941530997\n",
      "resetting env. episode reward total was -17.0. running mean: -1.7980221262115685\n",
      "resetting env. episode reward total was 3.0. running mean: -1.7500419049494529\n",
      "resetting env. episode reward total was -11.0. running mean: -1.8425414858999585\n",
      "resetting env. episode reward total was 7.0. running mean: -1.754116071040959\n",
      "resetting env. episode reward total was 1.0. running mean: -1.7265749103305492\n",
      "resetting env. episode reward total was -11.0. running mean: -1.8193091612272438\n",
      "resetting env. episode reward total was -16.0. running mean: -1.9611160696149712\n",
      "resetting env. episode reward total was -7.0. running mean: -2.0115049089188215\n",
      "resetting env. episode reward total was -11.0. running mean: -2.1013898598296334\n",
      "resetting env. episode reward total was 6.0. running mean: -2.0203759612313372\n",
      "resetting env. episode reward total was -7.0. running mean: -2.0701722016190236\n",
      "resetting env. episode reward total was 10.0. running mean: -1.9494704796028333\n",
      "resetting env. episode reward total was -10.0. running mean: -2.029975774806805\n",
      "resetting env. episode reward total was -13.0. running mean: -2.139676017058737\n",
      "resetting env. episode reward total was -1.0. running mean: -2.128279256888149\n",
      "resetting env. episode reward total was 5.0. running mean: -2.0569964643192677\n",
      "resetting env. episode reward total was -2.0. running mean: -2.0564264996760753\n",
      "resetting env. episode reward total was -3.0. running mean: -2.0658622346793143\n",
      "resetting env. episode reward total was -11.0. running mean: -2.155203612332521\n",
      "resetting env. episode reward total was -9.0. running mean: -2.2236515762091957\n",
      "resetting env. episode reward total was -10.0. running mean: -2.3014150604471038\n",
      "resetting env. episode reward total was -2.0. running mean: -2.298400909842633\n",
      "resetting env. episode reward total was -15.0. running mean: -2.4254169007442066\n",
      "resetting env. episode reward total was -5.0. running mean: -2.451162731736764\n",
      "resetting env. episode reward total was 2.0. running mean: -2.4066511044193963\n",
      "resetting env. episode reward total was -5.0. running mean: -2.432584593375202\n",
      "resetting env. episode reward total was -10.0. running mean: -2.50825874744145\n",
      "resetting env. episode reward total was -3.0. running mean: -2.5131761599670353\n",
      "resetting env. episode reward total was -5.0. running mean: -2.5380443983673646\n",
      "resetting env. episode reward total was -7.0. running mean: -2.582663954383691\n",
      "resetting env. episode reward total was 7.0. running mean: -2.486837314839854\n",
      "resetting env. episode reward total was -8.0. running mean: -2.5419689416914557\n",
      "resetting env. episode reward total was 6.0. running mean: -2.456549252274541\n",
      "resetting env. episode reward total was -17.0. running mean: -2.6019837597517954\n",
      "resetting env. episode reward total was 7.0. running mean: -2.5059639221542778\n",
      "resetting env. episode reward total was -8.0. running mean: -2.560904282932735\n",
      "resetting env. episode reward total was -2.0. running mean: -2.5552952401034075\n",
      "resetting env. episode reward total was -3.0. running mean: -2.559742287702373\n",
      "resetting env. episode reward total was -6.0. running mean: -2.594144864825349\n",
      "resetting env. episode reward total was -6.0. running mean: -2.6282034161770955\n",
      "resetting env. episode reward total was 4.0. running mean: -2.5619213820153246\n",
      "resetting env. episode reward total was -1.0. running mean: -2.546302168195171\n",
      "resetting env. episode reward total was -5.0. running mean: -2.570839146513219\n",
      "resetting env. episode reward total was -12.0. running mean: -2.665130755048087\n",
      "resetting env. episode reward total was -7.0. running mean: -2.708479447497606\n",
      "resetting env. episode reward total was -2.0. running mean: -2.7013946530226303\n",
      "resetting env. episode reward total was -1.0. running mean: -2.6843807064924037\n",
      "resetting env. episode reward total was -2.0. running mean: -2.6775368994274795\n",
      "resetting env. episode reward total was -1.0. running mean: -2.6607615304332044\n",
      "resetting env. episode reward total was -8.0. running mean: -2.7141539151288723\n",
      "resetting env. episode reward total was -8.0. running mean: -2.7670123759775835\n",
      "resetting env. episode reward total was 10.0. running mean: -2.6393422522178076\n",
      "resetting env. episode reward total was -8.0. running mean: -2.6929488296956294\n",
      "resetting env. episode reward total was -3.0. running mean: -2.696019341398673\n",
      "resetting env. episode reward total was -8.0. running mean: -2.749059147984686\n",
      "resetting env. episode reward total was -10.0. running mean: -2.8215685565048396\n",
      "resetting env. episode reward total was -12.0. running mean: -2.913352870939791\n",
      "resetting env. episode reward total was -2.0. running mean: -2.9042193422303932\n",
      "resetting env. episode reward total was -7.0. running mean: -2.945177148808089\n",
      "resetting env. episode reward total was -13.0. running mean: -3.045725377320008\n",
      "resetting env. episode reward total was 8.0. running mean: -2.935268123546808\n",
      "resetting env. episode reward total was -13.0. running mean: -3.0359154423113397\n",
      "resetting env. episode reward total was 4.0. running mean: -2.9655562878882264\n",
      "resetting env. episode reward total was 4.0. running mean: -2.8959007250093443\n",
      "resetting env. episode reward total was 6.0. running mean: -2.806941717759251\n",
      "resetting env. episode reward total was -5.0. running mean: -2.8288723005816583\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8105835775758417\n",
      "resetting env. episode reward total was -3.0. running mean: -2.812477741800083\n",
      "resetting env. episode reward total was 2.0. running mean: -2.7643529643820823\n",
      "resetting env. episode reward total was 2.0. running mean: -2.7167094347382617\n",
      "resetting env. episode reward total was 1.0. running mean: -2.679542340390879\n",
      "resetting env. episode reward total was 16.0. running mean: -2.4927469169869703\n",
      "resetting env. episode reward total was 2.0. running mean: -2.4478194478171007\n",
      "resetting env. episode reward total was -11.0. running mean: -2.5333412533389295\n",
      "resetting env. episode reward total was -4.0. running mean: -2.54800784080554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: -2.4425277623974844\n",
      "resetting env. episode reward total was -6.0. running mean: -2.4781024847735096\n",
      "resetting env. episode reward total was 10.0. running mean: -2.3533214599257746\n",
      "resetting env. episode reward total was -11.0. running mean: -2.4397882453265165\n",
      "resetting env. episode reward total was 6.0. running mean: -2.3553903628732513\n",
      "resetting env. episode reward total was 3.0. running mean: -2.301836459244519\n",
      "resetting env. episode reward total was -7.0. running mean: -2.348818094652074\n",
      "resetting env. episode reward total was 7.0. running mean: -2.255329913705553\n",
      "resetting env. episode reward total was 8.0. running mean: -2.1527766145684977\n",
      "resetting env. episode reward total was -7.0. running mean: -2.2012488484228125\n",
      "resetting env. episode reward total was -7.0. running mean: -2.249236359938584\n",
      "resetting env. episode reward total was -11.0. running mean: -2.336743996339198\n",
      "resetting env. episode reward total was -6.0. running mean: -2.3733765563758062\n",
      "resetting env. episode reward total was -3.0. running mean: -2.379642790812048\n",
      "resetting env. episode reward total was -7.0. running mean: -2.4258463629039273\n",
      "resetting env. episode reward total was 5.0. running mean: -2.351587899274888\n",
      "resetting env. episode reward total was -3.0. running mean: -2.358072020282139\n",
      "resetting env. episode reward total was -3.0. running mean: -2.3644913000793175\n",
      "resetting env. episode reward total was -3.0. running mean: -2.370846387078524\n",
      "resetting env. episode reward total was 2.0. running mean: -2.3271379232077387\n",
      "resetting env. episode reward total was 6.0. running mean: -2.243866543975661\n",
      "resetting env. episode reward total was -8.0. running mean: -2.3014278785359044\n",
      "resetting env. episode reward total was 5.0. running mean: -2.2284135997505454\n",
      "resetting env. episode reward total was -9.0. running mean: -2.2961294637530396\n",
      "resetting env. episode reward total was -6.0. running mean: -2.3331681691155093\n",
      "resetting env. episode reward total was 5.0. running mean: -2.259836487424354\n",
      "resetting env. episode reward total was 3.0. running mean: -2.2072381225501108\n",
      "resetting env. episode reward total was -1.0. running mean: -2.1951657413246095\n",
      "resetting env. episode reward total was 3.0. running mean: -2.1432140839113636\n",
      "resetting env. episode reward total was -5.0. running mean: -2.17178194307225\n",
      "resetting env. episode reward total was -10.0. running mean: -2.2500641236415273\n",
      "resetting env. episode reward total was 2.0. running mean: -2.207563482405112\n",
      "resetting env. episode reward total was 8.0. running mean: -2.1054878475810606\n",
      "resetting env. episode reward total was 7.0. running mean: -2.01443296910525\n",
      "resetting env. episode reward total was -4.0. running mean: -2.0342886394141972\n",
      "resetting env. episode reward total was -8.0. running mean: -2.0939457530200554\n",
      "resetting env. episode reward total was 5.0. running mean: -2.023006295489855\n",
      "resetting env. episode reward total was 4.0. running mean: -1.9627762325349565\n",
      "resetting env. episode reward total was 6.0. running mean: -1.8831484702096069\n",
      "resetting env. episode reward total was 6.0. running mean: -1.8043169855075107\n",
      "resetting env. episode reward total was -14.0. running mean: -1.9262738156524355\n",
      "resetting env. episode reward total was -11.0. running mean: -2.017011077495911\n",
      "resetting env. episode reward total was 6.0. running mean: -1.9368409667209519\n",
      "resetting env. episode reward total was 8.0. running mean: -1.8374725570537422\n",
      "resetting env. episode reward total was -4.0. running mean: -1.8590978314832047\n",
      "resetting env. episode reward total was 8.0. running mean: -1.7605068531683725\n",
      "resetting env. episode reward total was 2.0. running mean: -1.7229017846366887\n",
      "resetting env. episode reward total was -1.0. running mean: -1.7156727667903218\n",
      "resetting env. episode reward total was 2.0. running mean: -1.6785160391224185\n",
      "resetting env. episode reward total was 4.0. running mean: -1.6217308787311944\n",
      "resetting env. episode reward total was -7.0. running mean: -1.6755135699438826\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6887584342444437\n",
      "resetting env. episode reward total was -3.0. running mean: -1.7018708499019992\n",
      "resetting env. episode reward total was -5.0. running mean: -1.7348521414029792\n",
      "resetting env. episode reward total was -2.0. running mean: -1.7375036199889493\n",
      "resetting env. episode reward total was -2.0. running mean: -1.7401285837890599\n",
      "resetting env. episode reward total was -7.0. running mean: -1.7927272979511693\n",
      "resetting env. episode reward total was 14.0. running mean: -1.6348000249716574\n",
      "resetting env. episode reward total was 5.0. running mean: -1.568452024721941\n",
      "resetting env. episode reward total was 1.0. running mean: -1.5427675044747216\n",
      "resetting env. episode reward total was -13.0. running mean: -1.6573398294299744\n",
      "resetting env. episode reward total was 4.0. running mean: -1.6007664311356746\n",
      "resetting env. episode reward total was -5.0. running mean: -1.634758766824318\n",
      "resetting env. episode reward total was 1.0. running mean: -1.6084111791560747\n",
      "resetting env. episode reward total was -4.0. running mean: -1.632327067364514\n",
      "resetting env. episode reward total was 2.0. running mean: -1.596003796690869\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6300437587239602\n",
      "resetting env. episode reward total was 2.0. running mean: -1.5937433211367207\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6278058879253534\n",
      "resetting env. episode reward total was -3.0. running mean: -1.6415278290461\n",
      "resetting env. episode reward total was -2.0. running mean: -1.645112550755639\n",
      "resetting env. episode reward total was 10.0. running mean: -1.5286614252480826\n",
      "resetting env. episode reward total was -4.0. running mean: -1.5533748109956018\n",
      "resetting env. episode reward total was -7.0. running mean: -1.6078410628856459\n",
      "resetting env. episode reward total was 4.0. running mean: -1.5517626522567893\n",
      "resetting env. episode reward total was 6.0. running mean: -1.4762450257342214\n",
      "resetting env. episode reward total was -9.0. running mean: -1.5514825754768793\n",
      "resetting env. episode reward total was 5.0. running mean: -1.4859677497221104\n",
      "resetting env. episode reward total was 4.0. running mean: -1.4311080722248892\n",
      "resetting env. episode reward total was 4.0. running mean: -1.3767969915026403\n",
      "resetting env. episode reward total was -6.0. running mean: -1.423029021587614\n",
      "resetting env. episode reward total was 2.0. running mean: -1.3887987313717378\n",
      "resetting env. episode reward total was 5.0. running mean: -1.3249107440580203\n",
      "resetting env. episode reward total was -11.0. running mean: -1.4216616366174402\n",
      "resetting env. episode reward total was 5.0. running mean: -1.3574450202512658\n",
      "resetting env. episode reward total was 2.0. running mean: -1.3238705700487532\n",
      "resetting env. episode reward total was -10.0. running mean: -1.4106318643482658\n",
      "resetting env. episode reward total was -3.0. running mean: -1.4265255457047832\n",
      "resetting env. episode reward total was -7.0. running mean: -1.4822602902477353\n",
      "resetting env. episode reward total was -1.0. running mean: -1.477437687345258\n",
      "resetting env. episode reward total was 2.0. running mean: -1.4426633104718054\n",
      "resetting env. episode reward total was -15.0. running mean: -1.5782366773670873\n",
      "resetting env. episode reward total was 3.0. running mean: -1.5324543105934163\n",
      "resetting env. episode reward total was -4.0. running mean: -1.5571297674874822\n",
      "resetting env. episode reward total was 5.0. running mean: -1.4915584698126074\n",
      "resetting env. episode reward total was 6.0. running mean: -1.4166428851144812\n",
      "resetting env. episode reward total was -2.0. running mean: -1.4224764562633365\n",
      "resetting env. episode reward total was 8.0. running mean: -1.328251691700703\n",
      "resetting env. episode reward total was -6.0. running mean: -1.374969174783696\n",
      "resetting env. episode reward total was 5.0. running mean: -1.311219483035859\n",
      "resetting env. episode reward total was -3.0. running mean: -1.3281072882055005\n",
      "resetting env. episode reward total was -9.0. running mean: -1.4048262153234456\n",
      "resetting env. episode reward total was -5.0. running mean: -1.4407779531702112\n",
      "resetting env. episode reward total was 7.0. running mean: -1.356370173638509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -13.0. running mean: -1.4728064719021239\n",
      "resetting env. episode reward total was 2.0. running mean: -1.4380784071831025\n",
      "resetting env. episode reward total was -4.0. running mean: -1.4636976231112715\n",
      "resetting env. episode reward total was 8.0. running mean: -1.3690606468801587\n",
      "resetting env. episode reward total was 3.0. running mean: -1.325370040411357\n",
      "resetting env. episode reward total was -10.0. running mean: -1.4121163400072436\n",
      "resetting env. episode reward total was -3.0. running mean: -1.4279951766071712\n",
      "resetting env. episode reward total was -5.0. running mean: -1.4637152248410996\n",
      "resetting env. episode reward total was -1.0. running mean: -1.4590780725926886\n",
      "resetting env. episode reward total was 1.0. running mean: -1.4344872918667617\n",
      "resetting env. episode reward total was -4.0. running mean: -1.460142418948094\n",
      "resetting env. episode reward total was -2.0. running mean: -1.465540994758613\n",
      "resetting env. episode reward total was -5.0. running mean: -1.500885584811027\n",
      "resetting env. episode reward total was -7.0. running mean: -1.5558767289629167\n",
      "resetting env. episode reward total was -10.0. running mean: -1.6403179616732877\n",
      "resetting env. episode reward total was -11.0. running mean: -1.7339147820565548\n",
      "resetting env. episode reward total was -1.0. running mean: -1.7265756342359893\n",
      "resetting env. episode reward total was -6.0. running mean: -1.7693098778936294\n",
      "resetting env. episode reward total was -5.0. running mean: -1.801616779114693\n",
      "resetting env. episode reward total was -3.0. running mean: -1.813600611323546\n",
      "resetting env. episode reward total was 1.0. running mean: -1.7854646052103107\n",
      "resetting env. episode reward total was 3.0. running mean: -1.7376099591582075\n",
      "resetting env. episode reward total was 4.0. running mean: -1.6802338595666253\n",
      "resetting env. episode reward total was -11.0. running mean: -1.773431520970959\n",
      "resetting env. episode reward total was -2.0. running mean: -1.7756972057612495\n",
      "resetting env. episode reward total was 8.0. running mean: -1.6779402337036369\n",
      "resetting env. episode reward total was 5.0. running mean: -1.6111608313666004\n",
      "resetting env. episode reward total was -2.0. running mean: -1.6150492230529343\n",
      "resetting env. episode reward total was -11.0. running mean: -1.708898730822405\n",
      "resetting env. episode reward total was 1.0. running mean: -1.681809743514181\n",
      "resetting env. episode reward total was 7.0. running mean: -1.5949916460790392\n",
      "resetting env. episode reward total was -11.0. running mean: -1.689041729618249\n",
      "resetting env. episode reward total was -8.0. running mean: -1.7521513123220664\n",
      "resetting env. episode reward total was 8.0. running mean: -1.6546297991988457\n",
      "resetting env. episode reward total was -13.0. running mean: -1.7680835012068572\n",
      "resetting env. episode reward total was -4.0. running mean: -1.7904026661947887\n",
      "resetting env. episode reward total was -9.0. running mean: -1.862498639532841\n",
      "resetting env. episode reward total was -1.0. running mean: -1.8538736531375124\n",
      "resetting env. episode reward total was -4.0. running mean: -1.8753349166061373\n",
      "resetting env. episode reward total was -7.0. running mean: -1.926581567440076\n",
      "resetting env. episode reward total was -11.0. running mean: -2.017315751765675\n",
      "resetting env. episode reward total was -5.0. running mean: -2.0471425942480184\n",
      "resetting env. episode reward total was 1.0. running mean: -2.0166711683055385\n",
      "resetting env. episode reward total was -13.0. running mean: -2.126504456622483\n",
      "resetting env. episode reward total was -5.0. running mean: -2.155239412056258\n",
      "resetting env. episode reward total was -15.0. running mean: -2.283687017935695\n",
      "resetting env. episode reward total was -9.0. running mean: -2.350850147756338\n",
      "resetting env. episode reward total was -3.0. running mean: -2.3573416462787744\n",
      "resetting env. episode reward total was 5.0. running mean: -2.283768229815987\n",
      "resetting env. episode reward total was -9.0. running mean: -2.350930547517827\n",
      "resetting env. episode reward total was -3.0. running mean: -2.3574212420426486\n",
      "resetting env. episode reward total was -8.0. running mean: -2.413847029622222\n",
      "resetting env. episode reward total was -6.0. running mean: -2.449708559326\n",
      "resetting env. episode reward total was 1.0. running mean: -2.4152114737327404\n",
      "resetting env. episode reward total was 10.0. running mean: -2.2910593589954127\n",
      "resetting env. episode reward total was -15.0. running mean: -2.4181487654054585\n",
      "resetting env. episode reward total was 1.0. running mean: -2.3839672777514043\n",
      "resetting env. episode reward total was -15.0. running mean: -2.5101276049738903\n",
      "resetting env. episode reward total was -4.0. running mean: -2.5250263289241515\n",
      "resetting env. episode reward total was -13.0. running mean: -2.6297760656349096\n",
      "resetting env. episode reward total was -10.0. running mean: -2.7034783049785607\n",
      "resetting env. episode reward total was -5.0. running mean: -2.726443521928775\n",
      "resetting env. episode reward total was -9.0. running mean: -2.789179086709487\n",
      "resetting env. episode reward total was -5.0. running mean: -2.811287295842392\n",
      "resetting env. episode reward total was -5.0. running mean: -2.833174422883968\n",
      "resetting env. episode reward total was -6.0. running mean: -2.8648426786551284\n",
      "resetting env. episode reward total was -11.0. running mean: -2.946194251868577\n",
      "resetting env. episode reward total was 7.0. running mean: -2.8467323093498913\n",
      "resetting env. episode reward total was -3.0. running mean: -2.848264986256392\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8297823363938277\n",
      "resetting env. episode reward total was 3.0. running mean: -2.7714845130298897\n",
      "resetting env. episode reward total was -1.0. running mean: -2.7537696678995904\n",
      "resetting env. episode reward total was 2.0. running mean: -2.7062319712205944\n",
      "resetting env. episode reward total was -3.0. running mean: -2.7091696515083883\n",
      "resetting env. episode reward total was -9.0. running mean: -2.7720779549933043\n",
      "resetting env. episode reward total was -7.0. running mean: -2.814357175443371\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8162136036889374\n",
      "resetting env. episode reward total was -5.0. running mean: -2.838051467652048\n",
      "resetting env. episode reward total was -2.0. running mean: -2.8296709529755275\n",
      "resetting env. episode reward total was -10.0. running mean: -2.901374243445772\n",
      "resetting env. episode reward total was -3.0. running mean: -2.902360501011314\n",
      "resetting env. episode reward total was -3.0. running mean: -2.9033368960012007\n",
      "resetting env. episode reward total was -7.0. running mean: -2.9443035270411886\n",
      "resetting env. episode reward total was -2.0. running mean: -2.9348604917707766\n",
      "resetting env. episode reward total was 8.0. running mean: -2.825511886853069\n",
      "resetting env. episode reward total was -6.0. running mean: -2.857256767984538\n",
      "resetting env. episode reward total was -10.0. running mean: -2.928684200304693\n",
      "resetting env. episode reward total was -5.0. running mean: -2.949397358301646\n",
      "resetting env. episode reward total was -13.0. running mean: -3.0499033847186294\n",
      "resetting env. episode reward total was -2.0. running mean: -3.0394043508714432\n",
      "resetting env. episode reward total was -1.0. running mean: -3.0190103073627284\n",
      "resetting env. episode reward total was -5.0. running mean: -3.038820204289101\n",
      "resetting env. episode reward total was 8.0. running mean: -2.92843200224621\n",
      "resetting env. episode reward total was 10.0. running mean: -2.7991476822237478\n",
      "resetting env. episode reward total was -4.0. running mean: -2.8111562054015105\n",
      "resetting env. episode reward total was -7.0. running mean: -2.853044643347495\n",
      "resetting env. episode reward total was -5.0. running mean: -2.8745141969140198\n",
      "resetting env. episode reward total was -4.0. running mean: -2.8857690549448796\n",
      "resetting env. episode reward total was -9.0. running mean: -2.9469113643954308\n",
      "resetting env. episode reward total was -5.0. running mean: -2.967442250751476\n",
      "resetting env. episode reward total was -8.0. running mean: -3.0177678282439615\n",
      "resetting env. episode reward total was 6.0. running mean: -2.927590149961522\n",
      "resetting env. episode reward total was 4.0. running mean: -2.8583142484619066\n",
      "resetting env. episode reward total was -9.0. running mean: -2.9197311059772875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -13.0. running mean: -3.0205337949175144\n",
      "resetting env. episode reward total was -6.0. running mean: -3.050328456968339\n",
      "resetting env. episode reward total was -9.0. running mean: -3.1098251723986556\n",
      "resetting env. episode reward total was 3.0. running mean: -3.048726920674669\n",
      "resetting env. episode reward total was -14.0. running mean: -3.1582396514679227\n",
      "resetting env. episode reward total was -1.0. running mean: -3.1366572549532434\n",
      "resetting env. episode reward total was 3.0. running mean: -3.075290682403711\n",
      "resetting env. episode reward total was -11.0. running mean: -3.1545377755796737\n",
      "resetting env. episode reward total was -10.0. running mean: -3.222992397823877\n",
      "resetting env. episode reward total was -10.0. running mean: -3.2907624738456382\n",
      "resetting env. episode reward total was -2.0. running mean: -3.277854849107182\n",
      "resetting env. episode reward total was -9.0. running mean: -3.33507630061611\n",
      "resetting env. episode reward total was -9.0. running mean: -3.391725537609949\n",
      "resetting env. episode reward total was -16.0. running mean: -3.5178082822338497\n",
      "resetting env. episode reward total was -6.0. running mean: -3.5426301994115112\n",
      "resetting env. episode reward total was -7.0. running mean: -3.577203897417396\n",
      "resetting env. episode reward total was -7.0. running mean: -3.611431858443222\n",
      "resetting env. episode reward total was -2.0. running mean: -3.5953175398587898\n",
      "resetting env. episode reward total was -7.0. running mean: -3.629364364460202\n",
      "resetting env. episode reward total was -3.0. running mean: -3.6230707208155994\n",
      "resetting env. episode reward total was -7.0. running mean: -3.656840013607443\n",
      "resetting env. episode reward total was -11.0. running mean: -3.7302716134713685\n",
      "resetting env. episode reward total was -2.0. running mean: -3.712968897336655\n",
      "resetting env. episode reward total was -4.0. running mean: -3.7158392083632883\n",
      "resetting env. episode reward total was -7.0. running mean: -3.748680816279655\n",
      "resetting env. episode reward total was -5.0. running mean: -3.7611940081168584\n",
      "resetting env. episode reward total was -7.0. running mean: -3.7935820680356898\n",
      "resetting env. episode reward total was -11.0. running mean: -3.8656462473553326\n",
      "resetting env. episode reward total was -6.0. running mean: -3.8869897848817794\n",
      "resetting env. episode reward total was -3.0. running mean: -3.878119887032961\n",
      "resetting env. episode reward total was -12.0. running mean: -3.9593386881626316\n",
      "resetting env. episode reward total was -13.0. running mean: -4.049745301281005\n",
      "resetting env. episode reward total was -9.0. running mean: -4.099247848268195\n",
      "resetting env. episode reward total was 1.0. running mean: -4.0482553697855135\n",
      "resetting env. episode reward total was -7.0. running mean: -4.077772816087658\n",
      "resetting env. episode reward total was -6.0. running mean: -4.096995087926781\n",
      "resetting env. episode reward total was -9.0. running mean: -4.146025137047513\n",
      "resetting env. episode reward total was 4.0. running mean: -4.064564885677037\n",
      "resetting env. episode reward total was -5.0. running mean: -4.073919236820267\n",
      "resetting env. episode reward total was -2.0. running mean: -4.053180044452064\n",
      "resetting env. episode reward total was 4.0. running mean: -3.9726482440075426\n",
      "resetting env. episode reward total was 3.0. running mean: -3.9029217615674674\n",
      "resetting env. episode reward total was 4.0. running mean: -3.823892543951793\n",
      "resetting env. episode reward total was -9.0. running mean: -3.8756536185122745\n",
      "resetting env. episode reward total was -6.0. running mean: -3.896897082327152\n",
      "resetting env. episode reward total was -9.0. running mean: -3.94792811150388\n",
      "resetting env. episode reward total was -3.0. running mean: -3.938448830388841\n",
      "resetting env. episode reward total was 4.0. running mean: -3.8590643420849524\n",
      "resetting env. episode reward total was -7.0. running mean: -3.8904736986641026\n",
      "resetting env. episode reward total was 6.0. running mean: -3.7915689616774615\n",
      "resetting env. episode reward total was 7.0. running mean: -3.683653272060687\n",
      "resetting env. episode reward total was -5.0. running mean: -3.69681673934008\n",
      "resetting env. episode reward total was -3.0. running mean: -3.689848571946679\n",
      "resetting env. episode reward total was -6.0. running mean: -3.7129500862272122\n",
      "resetting env. episode reward total was -5.0. running mean: -3.7258205853649398\n",
      "resetting env. episode reward total was -11.0. running mean: -3.7985623795112904\n",
      "resetting env. episode reward total was -12.0. running mean: -3.8805767557161777\n",
      "resetting env. episode reward total was -5.0. running mean: -3.8917709881590157\n",
      "resetting env. episode reward total was 2.0. running mean: -3.8328532782774256\n",
      "resetting env. episode reward total was -9.0. running mean: -3.884524745494651\n",
      "resetting env. episode reward total was -5.0. running mean: -3.8956794980397045\n",
      "resetting env. episode reward total was -1.0. running mean: -3.866722703059307\n",
      "resetting env. episode reward total was -7.0. running mean: -3.8980554760287136\n",
      "resetting env. episode reward total was 4.0. running mean: -3.8190749212684265\n",
      "resetting env. episode reward total was -8.0. running mean: -3.860884172055742\n",
      "resetting env. episode reward total was -4.0. running mean: -3.8622753303351844\n",
      "resetting env. episode reward total was 2.0. running mean: -3.8036525770318326\n",
      "resetting env. episode reward total was 10.0. running mean: -3.665616051261514\n",
      "resetting env. episode reward total was -9.0. running mean: -3.718959890748899\n",
      "resetting env. episode reward total was -1.0. running mean: -3.6917702918414097\n",
      "resetting env. episode reward total was 1.0. running mean: -3.644852588922996\n",
      "resetting env. episode reward total was -8.0. running mean: -3.688404063033766\n",
      "resetting env. episode reward total was 1.0. running mean: -3.6415200224034283\n",
      "resetting env. episode reward total was -8.0. running mean: -3.6851048221793943\n",
      "resetting env. episode reward total was -5.0. running mean: -3.6982537739576\n",
      "resetting env. episode reward total was -13.0. running mean: -3.791271236218024\n",
      "resetting env. episode reward total was -11.0. running mean: -3.8633585238558434\n",
      "resetting env. episode reward total was -8.0. running mean: -3.904724938617285\n",
      "resetting env. episode reward total was -12.0. running mean: -3.985677689231112\n",
      "resetting env. episode reward total was -6.0. running mean: -4.005820912338801\n",
      "resetting env. episode reward total was -7.0. running mean: -4.035762703215413\n",
      "resetting env. episode reward total was -7.0. running mean: -4.065405076183259\n",
      "resetting env. episode reward total was 4.0. running mean: -3.984751025421426\n",
      "resetting env. episode reward total was -2.0. running mean: -3.9649035151672116\n",
      "resetting env. episode reward total was -9.0. running mean: -4.01525448001554\n",
      "resetting env. episode reward total was 2.0. running mean: -3.9551019352153842\n",
      "resetting env. episode reward total was 1.0. running mean: -3.9055509158632304\n",
      "resetting env. episode reward total was -5.0. running mean: -3.916495406704598\n",
      "resetting env. episode reward total was 4.0. running mean: -3.8373304526375516\n",
      "resetting env. episode reward total was 13.0. running mean: -3.668957148111176\n",
      "resetting env. episode reward total was -5.0. running mean: -3.682267576630064\n",
      "resetting env. episode reward total was -7.0. running mean: -3.7154449008637633\n",
      "resetting env. episode reward total was 8.0. running mean: -3.5982904518551257\n",
      "resetting env. episode reward total was -6.0. running mean: -3.6223075473365745\n",
      "resetting env. episode reward total was -1.0. running mean: -3.5960844718632083\n",
      "resetting env. episode reward total was 1.0. running mean: -3.5501236271445764\n",
      "resetting env. episode reward total was -5.0. running mean: -3.5646223908731303\n",
      "resetting env. episode reward total was 1.0. running mean: -3.518976166964399\n",
      "resetting env. episode reward total was -2.0. running mean: -3.503786405294755\n",
      "resetting env. episode reward total was -4.0. running mean: -3.5087485412418076\n",
      "resetting env. episode reward total was 6.0. running mean: -3.4136610558293894\n",
      "resetting env. episode reward total was 9.0. running mean: -3.2895244452710957\n",
      "resetting env. episode reward total was -4.0. running mean: -3.296629200818385\n",
      "resetting env. episode reward total was -3.0. running mean: -3.2936629088102007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: -3.3107262797220987\n",
      "resetting env. episode reward total was -9.0. running mean: -3.3676190169248774\n",
      "resetting env. episode reward total was -7.0. running mean: -3.4039428267556286\n",
      "resetting env. episode reward total was 3.0. running mean: -3.3399033984880724\n",
      "resetting env. episode reward total was 1.0. running mean: -3.2965043645031917\n",
      "resetting env. episode reward total was -5.0. running mean: -3.3135393208581596\n",
      "resetting env. episode reward total was -6.0. running mean: -3.340403927649578\n",
      "resetting env. episode reward total was -8.0. running mean: -3.386999888373082\n",
      "resetting env. episode reward total was -8.0. running mean: -3.433129889489351\n",
      "resetting env. episode reward total was -5.0. running mean: -3.4487985905944574\n",
      "resetting env. episode reward total was -9.0. running mean: -3.5043106046885124\n",
      "resetting env. episode reward total was -1.0. running mean: -3.479267498641627\n",
      "resetting env. episode reward total was 6.0. running mean: -3.3844748236552107\n",
      "resetting env. episode reward total was 3.0. running mean: -3.320630075418659\n",
      "resetting env. episode reward total was -1.0. running mean: -3.297423774664472\n",
      "resetting env. episode reward total was -7.0. running mean: -3.334449536917827\n",
      "resetting env. episode reward total was 1.0. running mean: -3.291105041548649\n",
      "resetting env. episode reward total was 2.0. running mean: -3.2381939911331625\n",
      "resetting env. episode reward total was -8.0. running mean: -3.2858120512218307\n",
      "resetting env. episode reward total was 7.0. running mean: -3.1829539307096124\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2211243914025163\n",
      "resetting env. episode reward total was 2.0. running mean: -3.168913147488491\n",
      "resetting env. episode reward total was 2.0. running mean: -3.117224016013606\n",
      "resetting env. episode reward total was 3.0. running mean: -3.0560517758534704\n",
      "resetting env. episode reward total was -5.0. running mean: -3.0754912580949356\n",
      "resetting env. episode reward total was 3.0. running mean: -3.0147363455139864\n",
      "resetting env. episode reward total was 2.0. running mean: -2.9645889820588467\n",
      "resetting env. episode reward total was -10.0. running mean: -3.034943092238258\n",
      "resetting env. episode reward total was -3.0. running mean: -3.0345936613158755\n",
      "resetting env. episode reward total was -6.0. running mean: -3.064247724702717\n",
      "resetting env. episode reward total was -15.0. running mean: -3.1836052474556897\n",
      "resetting env. episode reward total was -7.0. running mean: -3.2217691949811327\n",
      "resetting env. episode reward total was -7.0. running mean: -3.259551503031321\n",
      "resetting env. episode reward total was -10.0. running mean: -3.326955988001008\n",
      "resetting env. episode reward total was -10.0. running mean: -3.393686428120998\n",
      "resetting env. episode reward total was -12.0. running mean: -3.479749563839788\n",
      "resetting env. episode reward total was -6.0. running mean: -3.50495206820139\n",
      "resetting env. episode reward total was -3.0. running mean: -3.499902547519376\n",
      "resetting env. episode reward total was -8.0. running mean: -3.5449035220441822\n",
      "resetting env. episode reward total was 11.0. running mean: -3.3994544868237404\n",
      "resetting env. episode reward total was -6.0. running mean: -3.425459941955503\n",
      "resetting env. episode reward total was 7.0. running mean: -3.321205342535948\n",
      "resetting env. episode reward total was -8.0. running mean: -3.3679932891105886\n",
      "resetting env. episode reward total was -8.0. running mean: -3.4143133562194827\n",
      "resetting env. episode reward total was -6.0. running mean: -3.440170222657288\n",
      "resetting env. episode reward total was 1.0. running mean: -3.3957685204307153\n",
      "resetting env. episode reward total was 2.0. running mean: -3.341810835226408\n",
      "resetting env. episode reward total was 1.0. running mean: -3.298392726874144\n",
      "resetting env. episode reward total was -10.0. running mean: -3.3654087996054027\n",
      "resetting env. episode reward total was 7.0. running mean: -3.261754711609349\n",
      "resetting env. episode reward total was -5.0. running mean: -3.2791371644932554\n",
      "resetting env. episode reward total was -2.0. running mean: -3.266345792848323\n",
      "resetting env. episode reward total was 3.0. running mean: -3.2036823349198396\n",
      "resetting env. episode reward total was 2.0. running mean: -3.151645511570641\n",
      "resetting env. episode reward total was 7.0. running mean: -3.050129056454935\n",
      "resetting env. episode reward total was 4.0. running mean: -2.9796277658903856\n",
      "resetting env. episode reward total was 7.0. running mean: -2.8798314882314817\n",
      "resetting env. episode reward total was 1.0. running mean: -2.841033173349167\n",
      "resetting env. episode reward total was 5.0. running mean: -2.7626228416156753\n",
      "resetting env. episode reward total was 4.0. running mean: -2.6949966131995184\n",
      "resetting env. episode reward total was -1.0. running mean: -2.678046647067523\n",
      "resetting env. episode reward total was 7.0. running mean: -2.5812661805968475\n",
      "resetting env. episode reward total was -7.0. running mean: -2.625453518790879\n",
      "resetting env. episode reward total was -6.0. running mean: -2.65919898360297\n",
      "resetting env. episode reward total was -3.0. running mean: -2.66260699376694\n",
      "resetting env. episode reward total was -4.0. running mean: -2.675980923829271\n",
      "resetting env. episode reward total was 3.0. running mean: -2.6192211145909785\n",
      "resetting env. episode reward total was -10.0. running mean: -2.693028903445069\n",
      "resetting env. episode reward total was -3.0. running mean: -2.696098614410618\n",
      "resetting env. episode reward total was -9.0. running mean: -2.7591376282665117\n",
      "resetting env. episode reward total was -6.0. running mean: -2.7915462519838465\n",
      "resetting env. episode reward total was -5.0. running mean: -2.813630789464008\n",
      "resetting env. episode reward total was 2.0. running mean: -2.765494481569368\n",
      "resetting env. episode reward total was -6.0. running mean: -2.797839536753674\n",
      "resetting env. episode reward total was -6.0. running mean: -2.8298611413861376\n",
      "resetting env. episode reward total was -1.0. running mean: -2.811562529972276\n",
      "resetting env. episode reward total was 14.0. running mean: -2.6434469046725533\n",
      "resetting env. episode reward total was -4.0. running mean: -2.657012435625828\n",
      "resetting env. episode reward total was -7.0. running mean: -2.7004423112695695\n",
      "resetting env. episode reward total was -4.0. running mean: -2.7134378881568737\n",
      "resetting env. episode reward total was -9.0. running mean: -2.776303509275305\n",
      "resetting env. episode reward total was -4.0. running mean: -2.788540474182552\n",
      "resetting env. episode reward total was -10.0. running mean: -2.860655069440727\n",
      "resetting env. episode reward total was -2.0. running mean: -2.8520485187463196\n",
      "resetting env. episode reward total was -1.0. running mean: -2.833528033558856\n",
      "resetting env. episode reward total was -6.0. running mean: -2.8651927532232673\n",
      "resetting env. episode reward total was -6.0. running mean: -2.8965408256910345\n",
      "resetting env. episode reward total was 5.0. running mean: -2.8175754174341243\n",
      "resetting env. episode reward total was -9.0. running mean: -2.879399663259783\n",
      "resetting env. episode reward total was -13.0. running mean: -2.9806056666271847\n",
      "resetting env. episode reward total was -3.0. running mean: -2.9807996099609126\n",
      "resetting env. episode reward total was 6.0. running mean: -2.8909916138613037\n",
      "resetting env. episode reward total was 3.0. running mean: -2.832081697722691\n",
      "resetting env. episode reward total was -7.0. running mean: -2.8737608807454635\n",
      "resetting env. episode reward total was -8.0. running mean: -2.925023271938009\n",
      "resetting env. episode reward total was 3.0. running mean: -2.865773039218629\n",
      "resetting env. episode reward total was 4.0. running mean: -2.797115308826443\n",
      "resetting env. episode reward total was -6.0. running mean: -2.8291441557381787\n",
      "resetting env. episode reward total was -2.0. running mean: -2.820852714180797\n",
      "resetting env. episode reward total was -3.0. running mean: -2.8226441870389887\n",
      "resetting env. episode reward total was 1.0. running mean: -2.784417745168599\n",
      "resetting env. episode reward total was 5.0. running mean: -2.706573567716913\n",
      "resetting env. episode reward total was -6.0. running mean: -2.739507832039744\n",
      "resetting env. episode reward total was -3.0. running mean: -2.742112753719346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: -2.7046916261821528\n",
      "resetting env. episode reward total was 4.0. running mean: -2.6376447099203313\n",
      "resetting env. episode reward total was 5.0. running mean: -2.561268262821128\n",
      "resetting env. episode reward total was -7.0. running mean: -2.6056555801929164\n",
      "resetting env. episode reward total was -12.0. running mean: -2.6995990243909875\n",
      "resetting env. episode reward total was 9.0. running mean: -2.582603034147078\n",
      "resetting env. episode reward total was -11.0. running mean: -2.6667770038056067\n",
      "resetting env. episode reward total was -11.0. running mean: -2.7501092337675503\n",
      "resetting env. episode reward total was 5.0. running mean: -2.672608141429875\n",
      "resetting env. episode reward total was -6.0. running mean: -2.705882060015576\n",
      "resetting env. episode reward total was 6.0. running mean: -2.6188232394154203\n",
      "resetting env. episode reward total was -11.0. running mean: -2.702635007021266\n",
      "resetting env. episode reward total was -3.0. running mean: -2.7056086569510533\n",
      "resetting env. episode reward total was -5.0. running mean: -2.7285525703815425\n",
      "resetting env. episode reward total was -10.0. running mean: -2.801267044677727\n",
      "resetting env. episode reward total was 12.0. running mean: -2.65325437423095\n",
      "resetting env. episode reward total was -11.0. running mean: -2.7367218304886403\n",
      "resetting env. episode reward total was -5.0. running mean: -2.7593546121837536\n",
      "resetting env. episode reward total was -15.0. running mean: -2.881761066061916\n",
      "resetting env. episode reward total was -5.0. running mean: -2.9029434554012967\n",
      "resetting env. episode reward total was -1.0. running mean: -2.8839140208472833\n",
      "resetting env. episode reward total was -1.0. running mean: -2.86507488063881\n",
      "resetting env. episode reward total was 2.0. running mean: -2.816424131832422\n",
      "resetting env. episode reward total was -10.0. running mean: -2.8882598905140977\n",
      "resetting env. episode reward total was -5.0. running mean: -2.9093772916089566\n",
      "resetting env. episode reward total was 3.0. running mean: -2.8502835186928674\n",
      "resetting env. episode reward total was -8.0. running mean: -2.901780683505939\n",
      "resetting env. episode reward total was 10.0. running mean: -2.7727628766708796\n",
      "resetting env. episode reward total was 8.0. running mean: -2.6650352479041706\n",
      "resetting env. episode reward total was -11.0. running mean: -2.748384895425129\n",
      "resetting env. episode reward total was -3.0. running mean: -2.750901046470877\n",
      "resetting env. episode reward total was -3.0. running mean: -2.753392036006168\n",
      "resetting env. episode reward total was 3.0. running mean: -2.695858115646107\n",
      "resetting env. episode reward total was -12.0. running mean: -2.7888995344896457\n",
      "resetting env. episode reward total was -3.0. running mean: -2.791010539144749\n",
      "resetting env. episode reward total was -9.0. running mean: -2.8531004337533012\n",
      "resetting env. episode reward total was 2.0. running mean: -2.804569429415768\n",
      "resetting env. episode reward total was 2.0. running mean: -2.7565237351216103\n",
      "resetting env. episode reward total was -12.0. running mean: -2.8489584977703943\n",
      "resetting env. episode reward total was -8.0. running mean: -2.9004689127926904\n",
      "resetting env. episode reward total was -5.0. running mean: -2.9214642236647634\n",
      "resetting env. episode reward total was -2.0. running mean: -2.912249581428116\n",
      "resetting env. episode reward total was -13.0. running mean: -3.0131270856138346\n",
      "resetting env. episode reward total was -7.0. running mean: -3.052995814757696\n",
      "resetting env. episode reward total was 2.0. running mean: -3.002465856610119\n",
      "resetting env. episode reward total was -12.0. running mean: -3.092441198044018\n",
      "resetting env. episode reward total was -11.0. running mean: -3.171516786063578\n",
      "resetting env. episode reward total was -7.0. running mean: -3.209801618202942\n",
      "resetting env. episode reward total was -9.0. running mean: -3.2677036020209123\n",
      "resetting env. episode reward total was -12.0. running mean: -3.3550265660007033\n",
      "resetting env. episode reward total was -5.0. running mean: -3.3714763003406962\n",
      "resetting env. episode reward total was -7.0. running mean: -3.407761537337289\n",
      "resetting env. episode reward total was 1.0. running mean: -3.3636839219639163\n",
      "resetting env. episode reward total was -1.0. running mean: -3.340047082744277\n",
      "resetting env. episode reward total was -1.0. running mean: -3.316646611916834\n",
      "resetting env. episode reward total was 4.0. running mean: -3.243480145797666\n",
      "resetting env. episode reward total was -5.0. running mean: -3.261045344339689\n",
      "resetting env. episode reward total was 1.0. running mean: -3.218434890896292\n",
      "resetting env. episode reward total was -7.0. running mean: -3.256250541987329\n",
      "resetting env. episode reward total was -5.0. running mean: -3.273688036567455\n",
      "resetting env. episode reward total was -4.0. running mean: -3.280951156201781\n",
      "resetting env. episode reward total was 3.0. running mean: -3.218141644639763\n",
      "resetting env. episode reward total was -7.0. running mean: -3.255960228193365\n",
      "resetting env. episode reward total was 1.0. running mean: -3.2134006259114316\n",
      "resetting env. episode reward total was -8.0. running mean: -3.2612666196523175\n",
      "resetting env. episode reward total was -3.0. running mean: -3.258653953455794\n",
      "resetting env. episode reward total was -14.0. running mean: -3.366067413921236\n",
      "resetting env. episode reward total was -11.0. running mean: -3.4424067397820237\n",
      "resetting env. episode reward total was -7.0. running mean: -3.4779826723842033\n",
      "resetting env. episode reward total was 4.0. running mean: -3.403202845660361\n",
      "resetting env. episode reward total was -3.0. running mean: -3.3991708172037574\n",
      "resetting env. episode reward total was -6.0. running mean: -3.4251791090317196\n",
      "resetting env. episode reward total was -10.0. running mean: -3.4909273179414027\n",
      "resetting env. episode reward total was -4.0. running mean: -3.4960180447619886\n",
      "resetting env. episode reward total was -7.0. running mean: -3.5310578643143686\n",
      "resetting env. episode reward total was -1.0. running mean: -3.505747285671225\n",
      "resetting env. episode reward total was -3.0. running mean: -3.5006898128145125\n",
      "resetting env. episode reward total was -12.0. running mean: -3.5856829146863674\n",
      "resetting env. episode reward total was -10.0. running mean: -3.649826085539504\n",
      "resetting env. episode reward total was -5.0. running mean: -3.663327824684109\n",
      "resetting env. episode reward total was -5.0. running mean: -3.6766945464372673\n",
      "resetting env. episode reward total was 6.0. running mean: -3.5799276009728946\n",
      "resetting env. episode reward total was -1.0. running mean: -3.5541283249631657\n",
      "resetting env. episode reward total was -11.0. running mean: -3.628587041713534\n",
      "resetting env. episode reward total was -7.0. running mean: -3.6623011712963986\n",
      "resetting env. episode reward total was -12.0. running mean: -3.7456781595834348\n",
      "resetting env. episode reward total was -3.0. running mean: -3.7382213779876\n",
      "resetting env. episode reward total was -3.0. running mean: -3.730839164207724\n",
      "resetting env. episode reward total was -4.0. running mean: -3.7335307725656466\n",
      "resetting env. episode reward total was -3.0. running mean: -3.7261954648399898\n",
      "resetting env. episode reward total was -5.0. running mean: -3.7389335101915897\n",
      "resetting env. episode reward total was -4.0. running mean: -3.7415441750896736\n",
      "resetting env. episode reward total was 4.0. running mean: -3.6641287333387766\n",
      "resetting env. episode reward total was 8.0. running mean: -3.547487446005389\n",
      "resetting env. episode reward total was -3.0. running mean: -3.5420125715453348\n",
      "resetting env. episode reward total was -2.0. running mean: -3.5265924458298814\n",
      "resetting env. episode reward total was -6.0. running mean: -3.551326521371583\n",
      "resetting env. episode reward total was -2.0. running mean: -3.535813256157867\n",
      "resetting env. episode reward total was -8.0. running mean: -3.5804551235962885\n",
      "resetting env. episode reward total was -5.0. running mean: -3.5946505723603255\n",
      "resetting env. episode reward total was -1.0. running mean: -3.568704066636722\n",
      "resetting env. episode reward total was -13.0. running mean: -3.6630170259703543\n",
      "resetting env. episode reward total was 12.0. running mean: -3.506386855710651\n",
      "resetting env. episode reward total was 1.0. running mean: -3.4613229871535443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: -3.506709757282009\n",
      "resetting env. episode reward total was -12.0. running mean: -3.591642659709189\n",
      "resetting env. episode reward total was -8.0. running mean: -3.635726233112097\n",
      "resetting env. episode reward total was 7.0. running mean: -3.5293689707809763\n",
      "resetting env. episode reward total was -3.0. running mean: -3.5240752810731664\n",
      "resetting env. episode reward total was 4.0. running mean: -3.4488345282624344\n",
      "resetting env. episode reward total was -12.0. running mean: -3.53434618297981\n",
      "resetting env. episode reward total was -1.0. running mean: -3.509002721150012\n",
      "resetting env. episode reward total was -1.0. running mean: -3.4839126939385117\n",
      "resetting env. episode reward total was 12.0. running mean: -3.3290735669991265\n",
      "resetting env. episode reward total was 5.0. running mean: -3.2457828313291355\n",
      "resetting env. episode reward total was -2.0. running mean: -3.2333250030158442\n",
      "resetting env. episode reward total was -2.0. running mean: -3.220991752985686\n",
      "resetting env. episode reward total was 13.0. running mean: -3.058781835455829\n",
      "resetting env. episode reward total was -7.0. running mean: -3.0981940171012705\n",
      "resetting env. episode reward total was -9.0. running mean: -3.1572120769302576\n",
      "resetting env. episode reward total was 1.0. running mean: -3.115639956160955\n",
      "resetting env. episode reward total was 5.0. running mean: -3.0344835565993455\n",
      "resetting env. episode reward total was 8.0. running mean: -2.924138721033352\n",
      "resetting env. episode reward total was 12.0. running mean: -2.7748973338230183\n",
      "resetting env. episode reward total was 7.0. running mean: -2.677148360484788\n",
      "resetting env. episode reward total was 3.0. running mean: -2.6203768768799405\n",
      "resetting env. episode reward total was -7.0. running mean: -2.664173108111141\n",
      "resetting env. episode reward total was 3.0. running mean: -2.6075313770300297\n",
      "resetting env. episode reward total was -5.0. running mean: -2.631456063259729\n",
      "resetting env. episode reward total was -11.0. running mean: -2.7151415026271315\n",
      "resetting env. episode reward total was 3.0. running mean: -2.65799008760086\n",
      "resetting env. episode reward total was -1.0. running mean: -2.641410186724851\n",
      "resetting env. episode reward total was -3.0. running mean: -2.6449960848576026\n",
      "resetting env. episode reward total was -9.0. running mean: -2.7085461240090263\n",
      "resetting env. episode reward total was 15.0. running mean: -2.531460662768936\n",
      "resetting env. episode reward total was 2.0. running mean: -2.486146056141247\n",
      "resetting env. episode reward total was -6.0. running mean: -2.5212845955798344\n",
      "resetting env. episode reward total was 3.0. running mean: -2.466071749624036\n",
      "resetting env. episode reward total was -1.0. running mean: -2.4514110321277953\n",
      "resetting env. episode reward total was -7.0. running mean: -2.4968969218065173\n",
      "resetting env. episode reward total was -5.0. running mean: -2.521927952588452\n",
      "resetting env. episode reward total was -7.0. running mean: -2.5667086730625672\n",
      "resetting env. episode reward total was 4.0. running mean: -2.5010415863319415\n",
      "resetting env. episode reward total was 1.0. running mean: -2.4660311704686224\n",
      "resetting env. episode reward total was -1.0. running mean: -2.451370858763936\n",
      "resetting env. episode reward total was 7.0. running mean: -2.3568571501762965\n",
      "resetting env. episode reward total was -1.0. running mean: -2.3432885786745334\n",
      "resetting env. episode reward total was 6.0. running mean: -2.259855692887788\n",
      "resetting env. episode reward total was -2.0. running mean: -2.25725713595891\n",
      "resetting env. episode reward total was 5.0. running mean: -2.184684564599321\n",
      "resetting env. episode reward total was 14.0. running mean: -2.0228377189533275\n",
      "resetting env. episode reward total was 13.0. running mean: -1.8726093417637943\n",
      "resetting env. episode reward total was 11.0. running mean: -1.7438832483461564\n",
      "resetting env. episode reward total was 11.0. running mean: -1.6164444158626947\n",
      "resetting env. episode reward total was -6.0. running mean: -1.6602799717040677\n",
      "resetting env. episode reward total was 11.0. running mean: -1.533677171987027\n",
      "resetting env. episode reward total was -12.0. running mean: -1.6383404002671567\n",
      "resetting env. episode reward total was -5.0. running mean: -1.6719569962644851\n",
      "resetting env. episode reward total was 3.0. running mean: -1.6252374263018403\n",
      "resetting env. episode reward total was 12.0. running mean: -1.4889850520388217\n",
      "resetting env. episode reward total was -2.0. running mean: -1.4940952015184334\n",
      "resetting env. episode reward total was -3.0. running mean: -1.509154249503249\n",
      "resetting env. episode reward total was 4.0. running mean: -1.4540627070082166\n",
      "resetting env. episode reward total was -1.0. running mean: -1.4495220799381345\n",
      "resetting env. episode reward total was 5.0. running mean: -1.3850268591387531\n",
      "resetting env. episode reward total was 3.0. running mean: -1.3411765905473656\n",
      "resetting env. episode reward total was -3.0. running mean: -1.3577648246418919\n",
      "resetting env. episode reward total was -1.0. running mean: -1.354187176395473\n",
      "resetting env. episode reward total was 13.0. running mean: -1.2106453046315182\n",
      "resetting env. episode reward total was 12.0. running mean: -1.0785388515852028\n",
      "resetting env. episode reward total was 5.0. running mean: -1.0177534630693508\n",
      "resetting env. episode reward total was -7.0. running mean: -1.0775759284386572\n",
      "resetting env. episode reward total was 11.0. running mean: -0.9568001691542706\n",
      "resetting env. episode reward total was -3.0. running mean: -0.9772321674627279\n",
      "resetting env. episode reward total was -6.0. running mean: -1.0274598457881006\n",
      "resetting env. episode reward total was -3.0. running mean: -1.0471852473302197\n",
      "resetting env. episode reward total was 6.0. running mean: -0.9767133948569173\n",
      "resetting env. episode reward total was -2.0. running mean: -0.9869462609083481\n",
      "resetting env. episode reward total was 3.0. running mean: -0.9470767982992646\n",
      "resetting env. episode reward total was 14.0. running mean: -0.797606030316272\n",
      "resetting env. episode reward total was -5.0. running mean: -0.8396299700131092\n",
      "resetting env. episode reward total was -2.0. running mean: -0.8512336703129781\n",
      "resetting env. episode reward total was 11.0. running mean: -0.7327213336098484\n",
      "resetting env. episode reward total was 5.0. running mean: -0.6753941202737498\n",
      "resetting env. episode reward total was 7.0. running mean: -0.5986401790710123\n",
      "resetting env. episode reward total was 5.0. running mean: -0.5426537772803022\n",
      "resetting env. episode reward total was 8.0. running mean: -0.45722723950749916\n",
      "resetting env. episode reward total was 4.0. running mean: -0.41265496711242416\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4385284174412999\n",
      "resetting env. episode reward total was -2.0. running mean: -0.4541431332668869\n",
      "resetting env. episode reward total was 4.0. running mean: -0.409601701934218\n",
      "resetting env. episode reward total was -1.0. running mean: -0.41550568491487583\n",
      "resetting env. episode reward total was -1.0. running mean: -0.4213506280657271\n",
      "resetting env. episode reward total was 5.0. running mean: -0.36713712178506985\n",
      "resetting env. episode reward total was 7.0. running mean: -0.29346575056721913\n",
      "resetting env. episode reward total was 6.0. running mean: -0.23053109306154695\n",
      "resetting env. episode reward total was 2.0. running mean: -0.20822578213093149\n",
      "resetting env. episode reward total was -1.0. running mean: -0.21614352430962216\n",
      "resetting env. episode reward total was -5.0. running mean: -0.2639820890665259\n",
      "resetting env. episode reward total was 7.0. running mean: -0.19134226817586064\n",
      "resetting env. episode reward total was 7.0. running mean: -0.11942884549410202\n",
      "resetting env. episode reward total was 9.0. running mean: -0.028234557039161\n",
      "resetting env. episode reward total was -1.0. running mean: -0.03795221146876939\n",
      "resetting env. episode reward total was -4.0. running mean: -0.0775726893540817\n",
      "resetting env. episode reward total was -3.0. running mean: -0.10679696246054088\n",
      "resetting env. episode reward total was 4.0. running mean: -0.06572899283593547\n",
      "resetting env. episode reward total was -4.0. running mean: -0.10507170290757611\n",
      "resetting env. episode reward total was 1.0. running mean: -0.09402098587850036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: -0.14308077601971536\n",
      "resetting env. episode reward total was -6.0. running mean: -0.2016499682595182\n",
      "resetting env. episode reward total was 10.0. running mean: -0.09963346857692301\n",
      "resetting env. episode reward total was 10.0. running mean: 0.001362866108846228\n",
      "resetting env. episode reward total was -3.0. running mean: -0.028650762552242234\n",
      "resetting env. episode reward total was 11.0. running mean: 0.0816357450732802\n",
      "resetting env. episode reward total was 11.0. running mean: 0.1908193876225474\n",
      "resetting env. episode reward total was 1.0. running mean: 0.19891119374632193\n",
      "resetting env. episode reward total was -1.0. running mean: 0.1869220818088587\n",
      "resetting env. episode reward total was 10.0. running mean: 0.2850528609907701\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3322023323808624\n",
      "resetting env. episode reward total was 6.0. running mean: 0.38888030905705373\n",
      "resetting env. episode reward total was 9.0. running mean: 0.4749915059664832\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5002415909068184\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5352391749977502\n",
      "resetting env. episode reward total was -5.0. running mean: 0.47988678324777273\n",
      "resetting env. episode reward total was 10.0. running mean: 0.575087915415295\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5593370362611421\n",
      "resetting env. episode reward total was 11.0. running mean: 0.6637436658985306\n",
      "resetting env. episode reward total was -7.0. running mean: 0.5871062292395453\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5712351669471498\n",
      "resetting env. episode reward total was -9.0. running mean: 0.47552281527767837\n",
      "resetting env. episode reward total was -17.0. running mean: 0.3007675871249016\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3477599112536526\n",
      "resetting env. episode reward total was -5.0. running mean: 0.29428231214111605\n",
      "resetting env. episode reward total was -1.0. running mean: 0.2813394890197049\n",
      "resetting env. episode reward total was -1.0. running mean: 0.26852609412950784\n",
      "resetting env. episode reward total was -10.0. running mean: 0.16584083318821277\n",
      "resetting env. episode reward total was 12.0. running mean: 0.2841824248563306\n",
      "resetting env. episode reward total was -8.0. running mean: 0.20134060060776726\n",
      "resetting env. episode reward total was -5.0. running mean: 0.14932719460168958\n",
      "resetting env. episode reward total was -3.0. running mean: 0.11783392265567269\n",
      "resetting env. episode reward total was -2.0. running mean: 0.09665558342911595\n",
      "resetting env. episode reward total was -5.0. running mean: 0.045689027594824794\n",
      "resetting env. episode reward total was 1.0. running mean: 0.05523213731887655\n",
      "resetting env. episode reward total was 8.0. running mean: 0.1346798159456878\n",
      "resetting env. episode reward total was -5.0. running mean: 0.08333301778623091\n",
      "resetting env. episode reward total was -5.0. running mean: 0.03249968760836859\n",
      "resetting env. episode reward total was -2.0. running mean: 0.012174690732284905\n",
      "resetting env. episode reward total was 7.0. running mean: 0.08205294382496206\n",
      "resetting env. episode reward total was -7.0. running mean: 0.011232414386712436\n",
      "resetting env. episode reward total was 3.0. running mean: 0.04112009024284531\n",
      "resetting env. episode reward total was -1.0. running mean: 0.030708889340416858\n",
      "resetting env. episode reward total was 4.0. running mean: 0.07040180044701269\n",
      "resetting env. episode reward total was 2.0. running mean: 0.08969778244254256\n",
      "resetting env. episode reward total was 2.0. running mean: 0.10880080461811714\n",
      "resetting env. episode reward total was -11.0. running mean: -0.00228720342806403\n",
      "resetting env. episode reward total was -1.0. running mean: -0.012264331393783391\n",
      "resetting env. episode reward total was -9.0. running mean: -0.10214168807984556\n",
      "resetting env. episode reward total was -2.0. running mean: -0.1211202711990471\n",
      "resetting env. episode reward total was -10.0. running mean: -0.21990906848705663\n",
      "resetting env. episode reward total was 1.0. running mean: -0.20770997780218606\n",
      "resetting env. episode reward total was -5.0. running mean: -0.2556328780241642\n",
      "resetting env. episode reward total was 2.0. running mean: -0.23307654924392254\n",
      "resetting env. episode reward total was -4.0. running mean: -0.2707457837514833\n",
      "resetting env. episode reward total was 1.0. running mean: -0.2580383259139684\n",
      "resetting env. episode reward total was -4.0. running mean: -0.2954579426548287\n",
      "resetting env. episode reward total was 7.0. running mean: -0.2225033632282804\n",
      "resetting env. episode reward total was 4.0. running mean: -0.1802783295959976\n",
      "resetting env. episode reward total was -6.0. running mean: -0.23847554630003762\n",
      "resetting env. episode reward total was 9.0. running mean: -0.14609079083703724\n",
      "resetting env. episode reward total was 9.0. running mean: -0.054629882928666884\n",
      "resetting env. episode reward total was 4.0. running mean: -0.014083584099380216\n",
      "resetting env. episode reward total was -3.0. running mean: -0.04394274825838641\n",
      "resetting env. episode reward total was 6.0. running mean: 0.016496679224197452\n",
      "resetting env. episode reward total was -1.0. running mean: 0.006331712431955476\n",
      "resetting env. episode reward total was 9.0. running mean: 0.09626839530763592\n",
      "resetting env. episode reward total was 2.0. running mean: 0.11530571135455957\n",
      "resetting env. episode reward total was 1.0. running mean: 0.12415265424101396\n",
      "resetting env. episode reward total was -4.0. running mean: 0.08291112769860381\n",
      "resetting env. episode reward total was 8.0. running mean: 0.1620820164216178\n",
      "resetting env. episode reward total was 1.0. running mean: 0.1704611962574016\n",
      "resetting env. episode reward total was 7.0. running mean: 0.2387565842948276\n",
      "resetting env. episode reward total was 9.0. running mean: 0.3263690184518793\n",
      "resetting env. episode reward total was -9.0. running mean: 0.23310532826736055\n",
      "resetting env. episode reward total was -1.0. running mean: 0.22077427498468694\n",
      "resetting env. episode reward total was -4.0. running mean: 0.17856653223484006\n",
      "resetting env. episode reward total was -10.0. running mean: 0.07678086691249167\n",
      "resetting env. episode reward total was 2.0. running mean: 0.09601305824336676\n",
      "resetting env. episode reward total was -8.0. running mean: 0.01505292766093308\n",
      "resetting env. episode reward total was -5.0. running mean: -0.03509760161567625\n",
      "resetting env. episode reward total was 10.0. running mean: 0.06525337440048051\n",
      "resetting env. episode reward total was 1.0. running mean: 0.07460084065647571\n",
      "resetting env. episode reward total was -3.0. running mean: 0.04385483224991095\n",
      "resetting env. episode reward total was 8.0. running mean: 0.12341628392741184\n",
      "resetting env. episode reward total was 6.0. running mean: 0.18218212108813772\n",
      "resetting env. episode reward total was -8.0. running mean: 0.10036029987725635\n",
      "resetting env. episode reward total was 13.0. running mean: 0.22935669687848378\n",
      "resetting env. episode reward total was -1.0. running mean: 0.21706312990969895\n",
      "resetting env. episode reward total was -10.0. running mean: 0.11489249861060194\n",
      "resetting env. episode reward total was 9.0. running mean: 0.2037435736244959\n",
      "resetting env. episode reward total was -6.0. running mean: 0.14170613788825095\n",
      "resetting env. episode reward total was -6.0. running mean: 0.08028907650936845\n",
      "resetting env. episode reward total was 2.0. running mean: 0.09948618574427477\n",
      "resetting env. episode reward total was -3.0. running mean: 0.06849132388683202\n",
      "resetting env. episode reward total was 10.0. running mean: 0.1678064106479637\n",
      "resetting env. episode reward total was -7.0. running mean: 0.09612834654148406\n",
      "resetting env. episode reward total was -2.0. running mean: 0.07516706307606921\n",
      "resetting env. episode reward total was -1.0. running mean: 0.06441539244530853\n",
      "resetting env. episode reward total was 11.0. running mean: 0.17377123852085544\n",
      "resetting env. episode reward total was 6.0. running mean: 0.23203352613564687\n",
      "resetting env. episode reward total was 12.0. running mean: 0.3497131908742904\n",
      "resetting env. episode reward total was 12.0. running mean: 0.4662160589655475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: 0.41155389837589207\n",
      "resetting env. episode reward total was -15.0. running mean: 0.2574383593921331\n",
      "resetting env. episode reward total was -8.0. running mean: 0.17486397579821178\n",
      "resetting env. episode reward total was 11.0. running mean: 0.28311533604022965\n",
      "resetting env. episode reward total was -1.0. running mean: 0.27028418267982735\n",
      "resetting env. episode reward total was 11.0. running mean: 0.3775813408530291\n",
      "resetting env. episode reward total was 1.0. running mean: 0.3838055274444988\n",
      "resetting env. episode reward total was -7.0. running mean: 0.3099674721700538\n",
      "resetting env. episode reward total was 3.0. running mean: 0.33686779744835327\n",
      "resetting env. episode reward total was -2.0. running mean: 0.3134991194738697\n",
      "resetting env. episode reward total was -4.0. running mean: 0.27036412827913103\n",
      "resetting env. episode reward total was -13.0. running mean: 0.1376604869963397\n",
      "resetting env. episode reward total was 8.0. running mean: 0.21628388212637628\n",
      "resetting env. episode reward total was -3.0. running mean: 0.18412104330511253\n",
      "resetting env. episode reward total was 9.0. running mean: 0.27227983287206137\n",
      "resetting env. episode reward total was 6.0. running mean: 0.32955703454334073\n",
      "resetting env. episode reward total was 2.0. running mean: 0.3462614641979073\n",
      "resetting env. episode reward total was -1.0. running mean: 0.33279884955592826\n",
      "resetting env. episode reward total was 3.0. running mean: 0.35947086106036896\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3458761524497653\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3324173909252676\n",
      "resetting env. episode reward total was 8.0. running mean: 0.409093217016015\n",
      "resetting env. episode reward total was -3.0. running mean: 0.37500228484585485\n",
      "resetting env. episode reward total was 2.0. running mean: 0.3912522619973963\n",
      "resetting env. episode reward total was 16.0. running mean: 0.5473397393774223\n",
      "resetting env. episode reward total was 3.0. running mean: 0.571866341983648\n",
      "resetting env. episode reward total was -8.0. running mean: 0.4861476785638115\n",
      "resetting env. episode reward total was -6.0. running mean: 0.4212862017781734\n",
      "resetting env. episode reward total was -4.0. running mean: 0.37707333976039165\n",
      "resetting env. episode reward total was -2.0. running mean: 0.3533026063627877\n",
      "resetting env. episode reward total was -8.0. running mean: 0.2697695802991598\n",
      "resetting env. episode reward total was -6.0. running mean: 0.2070718844961682\n",
      "resetting env. episode reward total was 8.0. running mean: 0.28500116565120653\n",
      "resetting env. episode reward total was 6.0. running mean: 0.3421511539946945\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3287296424547475\n",
      "resetting env. episode reward total was -9.0. running mean: 0.2354423460302\n",
      "resetting env. episode reward total was 8.0. running mean: 0.313087922569898\n",
      "resetting env. episode reward total was 4.0. running mean: 0.34995704334419897\n",
      "resetting env. episode reward total was -1.0. running mean: 0.33645747291075695\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3030928981816494\n",
      "resetting env. episode reward total was -11.0. running mean: 0.19006196919983293\n",
      "resetting env. episode reward total was 7.0. running mean: 0.2581613495078346\n",
      "resetting env. episode reward total was -5.0. running mean: 0.20557973601275625\n",
      "resetting env. episode reward total was 4.0. running mean: 0.2435239386526287\n",
      "resetting env. episode reward total was -11.0. running mean: 0.1310886992661024\n",
      "resetting env. episode reward total was 4.0. running mean: 0.16977781227344138\n",
      "resetting env. episode reward total was 11.0. running mean: 0.278080034150707\n",
      "resetting env. episode reward total was -4.0. running mean: 0.2352992338091999\n",
      "resetting env. episode reward total was 2.0. running mean: 0.2529462414711079\n",
      "resetting env. episode reward total was 3.0. running mean: 0.28041677905639684\n",
      "resetting env. episode reward total was -7.0. running mean: 0.20761261126583286\n",
      "resetting env. episode reward total was -10.0. running mean: 0.10553648515317451\n",
      "resetting env. episode reward total was 3.0. running mean: 0.13448112030164278\n",
      "resetting env. episode reward total was -8.0. running mean: 0.053136309098626336\n",
      "resetting env. episode reward total was 9.0. running mean: 0.14260494600764007\n",
      "resetting env. episode reward total was -9.0. running mean: 0.05117889654756366\n",
      "resetting env. episode reward total was -1.0. running mean: 0.040667107582088025\n",
      "resetting env. episode reward total was 3.0. running mean: 0.07026043650626715\n",
      "resetting env. episode reward total was 13.0. running mean: 0.19955783214120448\n",
      "resetting env. episode reward total was 2.0. running mean: 0.21756225381979244\n",
      "resetting env. episode reward total was 17.0. running mean: 0.38538663128159456\n",
      "resetting env. episode reward total was -9.0. running mean: 0.29153276496877867\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2586174373190909\n",
      "resetting env. episode reward total was -12.0. running mean: 0.1360312629459\n",
      "resetting env. episode reward total was 1.0. running mean: 0.144670950316441\n",
      "resetting env. episode reward total was 8.0. running mean: 0.22322424081327658\n",
      "resetting env. episode reward total was -2.0. running mean: 0.2009919984051438\n",
      "resetting env. episode reward total was -10.0. running mean: 0.09898207842109236\n",
      "resetting env. episode reward total was -6.0. running mean: 0.03799225763688144\n",
      "resetting env. episode reward total was -15.0. running mean: -0.11238766493948738\n",
      "resetting env. episode reward total was -1.0. running mean: -0.12126378829009249\n",
      "resetting env. episode reward total was 6.0. running mean: -0.06005115040719157\n",
      "resetting env. episode reward total was 7.0. running mean: 0.010549361096880351\n",
      "resetting env. episode reward total was -4.0. running mean: -0.02955613251408845\n",
      "resetting env. episode reward total was -3.0. running mean: -0.059260571188947564\n",
      "resetting env. episode reward total was -5.0. running mean: -0.10866796547705809\n",
      "resetting env. episode reward total was 2.0. running mean: -0.08758128582228751\n",
      "resetting env. episode reward total was -6.0. running mean: -0.14670547296406464\n",
      "resetting env. episode reward total was 3.0. running mean: -0.11523841823442399\n",
      "resetting env. episode reward total was 8.0. running mean: -0.034086034052079744\n",
      "resetting env. episode reward total was -10.0. running mean: -0.13374517371155895\n",
      "resetting env. episode reward total was -11.0. running mean: -0.24240772197444338\n",
      "resetting env. episode reward total was -7.0. running mean: -0.309983644754699\n",
      "resetting env. episode reward total was 9.0. running mean: -0.216883808307152\n",
      "resetting env. episode reward total was 10.0. running mean: -0.11471497022408048\n",
      "resetting env. episode reward total was -3.0. running mean: -0.14356782052183967\n",
      "resetting env. episode reward total was -5.0. running mean: -0.1921321423166213\n",
      "resetting env. episode reward total was -9.0. running mean: -0.28021082089345506\n",
      "resetting env. episode reward total was 7.0. running mean: -0.2074087126845205\n",
      "resetting env. episode reward total was 7.0. running mean: -0.13533462555767528\n",
      "resetting env. episode reward total was -5.0. running mean: -0.1839812793020985\n",
      "resetting env. episode reward total was -3.0. running mean: -0.21214146650907753\n",
      "resetting env. episode reward total was 7.0. running mean: -0.14002005184398675\n",
      "resetting env. episode reward total was 1.0. running mean: -0.12861985132554687\n",
      "resetting env. episode reward total was -7.0. running mean: -0.1973336528122914\n",
      "resetting env. episode reward total was -3.0. running mean: -0.22536031628416847\n",
      "resetting env. episode reward total was 4.0. running mean: -0.1831067131213268\n",
      "resetting env. episode reward total was -1.0. running mean: -0.1912756459901135\n",
      "resetting env. episode reward total was -5.0. running mean: -0.2393628895302124\n",
      "resetting env. episode reward total was 8.0. running mean: -0.1569692606349103\n",
      "resetting env. episode reward total was 11.0. running mean: -0.045399568028561196\n",
      "resetting env. episode reward total was 6.0. running mean: 0.015054427651724413\n",
      "resetting env. episode reward total was 5.0. running mean: 0.06490388337520717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: -0.015745155458544907\n",
      "resetting env. episode reward total was -12.0. running mean: -0.13558770390395947\n",
      "resetting env. episode reward total was -7.0. running mean: -0.2042318268649199\n",
      "resetting env. episode reward total was 7.0. running mean: -0.13218950859627068\n",
      "resetting env. episode reward total was -3.0. running mean: -0.16086761351030798\n",
      "resetting env. episode reward total was -9.0. running mean: -0.2492589373752049\n",
      "resetting env. episode reward total was 10.0. running mean: -0.14676634800145286\n",
      "resetting env. episode reward total was -3.0. running mean: -0.17529868452143832\n",
      "resetting env. episode reward total was -7.0. running mean: -0.24354569767622394\n",
      "resetting env. episode reward total was -13.0. running mean: -0.37111024069946175\n",
      "resetting env. episode reward total was 8.0. running mean: -0.2873991382924671\n",
      "resetting env. episode reward total was -3.0. running mean: -0.3145251469095425\n",
      "resetting env. episode reward total was 12.0. running mean: -0.19137989544044703\n",
      "resetting env. episode reward total was 11.0. running mean: -0.07946609648604257\n",
      "resetting env. episode reward total was 1.0. running mean: -0.06867143552118214\n",
      "resetting env. episode reward total was -3.0. running mean: -0.09798472116597032\n",
      "resetting env. episode reward total was 11.0. running mean: 0.012995126045689392\n",
      "resetting env. episode reward total was 6.0. running mean: 0.0728651747852325\n",
      "resetting env. episode reward total was 2.0. running mean: 0.09213652303738017\n",
      "resetting env. episode reward total was 3.0. running mean: 0.12121515780700637\n",
      "resetting env. episode reward total was 8.0. running mean: 0.2000030062289363\n",
      "resetting env. episode reward total was 7.0. running mean: 0.2680029761666469\n",
      "resetting env. episode reward total was -2.0. running mean: 0.24532294640498045\n",
      "resetting env. episode reward total was -8.0. running mean: 0.16286971694093066\n",
      "resetting env. episode reward total was 7.0. running mean: 0.23124101977152137\n",
      "resetting env. episode reward total was 5.0. running mean: 0.27892860957380616\n",
      "resetting env. episode reward total was 6.0. running mean: 0.3361393234780681\n",
      "resetting env. episode reward total was -3.0. running mean: 0.30277793024328736\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3497501509408545\n",
      "resetting env. episode reward total was 5.0. running mean: 0.39625264943144595\n",
      "resetting env. episode reward total was 5.0. running mean: 0.4422901229371315\n",
      "resetting env. episode reward total was 6.0. running mean: 0.49786722170776015\n",
      "resetting env. episode reward total was -3.0. running mean: 0.4628885494906826\n",
      "resetting env. episode reward total was -6.0. running mean: 0.3982596639957758\n",
      "resetting env. episode reward total was -3.0. running mean: 0.364277067355818\n",
      "resetting env. episode reward total was 11.0. running mean: 0.4706342966822598\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5559279537154372\n",
      "resetting env. episode reward total was -6.0. running mean: 0.49036867417828284\n",
      "resetting env. episode reward total was 2.0. running mean: 0.5054649874365\n",
      "resetting env. episode reward total was -1.0. running mean: 0.49041033756213503\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5955062341865137\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6095511718446486\n",
      "resetting env. episode reward total was 5.0. running mean: 0.6534556601262022\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6869211035249402\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6500518924896908\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6835513735647939\n",
      "resetting env. episode reward total was 8.0. running mean: 0.7567158598291459\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7191487012308544\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7619572142185459\n",
      "resetting env. episode reward total was -1.0. running mean: 0.7443376420763604\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7868942656555968\n",
      "resetting env. episode reward total was 2.0. running mean: 0.7990253229990408\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8110350697690505\n",
      "resetting env. episode reward total was -1.0. running mean: 0.79292471907136\n",
      "resetting env. episode reward total was 2.0. running mean: 0.8049954718806464\n",
      "resetting env. episode reward total was -3.0. running mean: 0.7669455171618399\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8092760619902215\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8511833013703193\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8226714683566161\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9044447536730499\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8454003061363193\n",
      "resetting env. episode reward total was -6.0. running mean: 0.7769463030749562\n",
      "resetting env. episode reward total was 2.0. running mean: 0.7891768400442066\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7612850716437646\n",
      "resetting env. episode reward total was 14.0. running mean: 0.8936722209273269\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8347354987180535\n",
      "resetting env. episode reward total was 12.0. running mean: 0.946388143730873\n",
      "resetting env. episode reward total was 6.0. running mean: 0.9969242622935643\n",
      "resetting env. episode reward total was 9.0. running mean: 1.0769550196706288\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0861854694739226\n",
      "resetting env. episode reward total was 5.0. running mean: 1.1253236147791834\n",
      "resetting env. episode reward total was -8.0. running mean: 1.0340703786313914\n",
      "resetting env. episode reward total was 12.0. running mean: 1.1437296748450776\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1222923780966267\n",
      "resetting env. episode reward total was -7.0. running mean: 1.0410694543156604\n",
      "resetting env. episode reward total was 6.0. running mean: 1.090658759772504\n",
      "resetting env. episode reward total was 4.0. running mean: 1.119752172174779\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0985546504530312\n",
      "resetting env. episode reward total was -11.0. running mean: 0.9775691039485009\n",
      "resetting env. episode reward total was -7.0. running mean: 0.8977934129090159\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8788154787799257\n",
      "resetting env. episode reward total was -6.0. running mean: 0.8100273239921265\n",
      "resetting env. episode reward total was 14.0. running mean: 0.9419270507522053\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9425077802446832\n",
      "resetting env. episode reward total was -8.0. running mean: 0.8530827024422364\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8945518754178141\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9756063566636359\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9458502930969995\n",
      "resetting env. episode reward total was 8.0. running mean: 1.0163917901660295\n",
      "resetting env. episode reward total was -10.0. running mean: 0.9062278722643692\n",
      "resetting env. episode reward total was 5.0. running mean: 0.9471655935417256\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8476939376063084\n",
      "resetting env. episode reward total was 5.0. running mean: 0.8892169982302454\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8303248282479428\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9020215799654634\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8630013641658087\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8443713505241507\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8459276370189092\n",
      "resetting env. episode reward total was -6.0. running mean: 0.77746836064872\n",
      "resetting env. episode reward total was 1.0. running mean: 0.7796936770422328\n",
      "resetting env. episode reward total was -4.0. running mean: 0.7318967402718104\n",
      "resetting env. episode reward total was -10.0. running mean: 0.6245777728690923\n",
      "resetting env. episode reward total was -1.0. running mean: 0.6083319951404014\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5522486751889973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: 0.5367261884371074\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5213589265527363\n",
      "resetting env. episode reward total was -5.0. running mean: 0.4661453372872089\n",
      "resetting env. episode reward total was 12.0. running mean: 0.5814838839143368\n",
      "resetting env. episode reward total was 3.0. running mean: 0.6056690450751935\n",
      "resetting env. episode reward total was -14.0. running mean: 0.4596123546244415\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5450162310781971\n",
      "resetting env. episode reward total was -5.0. running mean: 0.4895660687674151\n",
      "resetting env. episode reward total was -7.0. running mean: 0.4146704080797409\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4305237039989435\n",
      "resetting env. episode reward total was -2.0. running mean: 0.4062184669589541\n",
      "resetting env. episode reward total was 3.0. running mean: 0.43215628228936454\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5378347194664709\n",
      "resetting env. episode reward total was -11.0. running mean: 0.4224563722718062\n",
      "resetting env. episode reward total was -5.0. running mean: 0.36823180854908816\n",
      "resetting env. episode reward total was 5.0. running mean: 0.41454949046359724\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3604039955589613\n",
      "resetting env. episode reward total was -7.0. running mean: 0.2867999556033717\n",
      "resetting env. episode reward total was -12.0. running mean: 0.16393195604733796\n",
      "resetting env. episode reward total was -8.0. running mean: 0.08229263648686456\n",
      "resetting env. episode reward total was -1.0. running mean: 0.07146971012199592\n",
      "resetting env. episode reward total was 2.0. running mean: 0.09075501302077596\n",
      "resetting env. episode reward total was 1.0. running mean: 0.0998474628905682\n",
      "resetting env. episode reward total was 9.0. running mean: 0.18884898826166252\n",
      "resetting env. episode reward total was -9.0. running mean: 0.09696049837904588\n",
      "resetting env. episode reward total was 2.0. running mean: 0.11599089339525542\n",
      "resetting env. episode reward total was -2.0. running mean: 0.09483098446130286\n",
      "resetting env. episode reward total was -6.0. running mean: 0.03388267461668984\n",
      "resetting env. episode reward total was -6.0. running mean: -0.026456152129477058\n",
      "resetting env. episode reward total was -11.0. running mean: -0.13619159060818228\n",
      "resetting env. episode reward total was 9.0. running mean: -0.044829674702100475\n",
      "resetting env. episode reward total was -2.0. running mean: -0.06438137795507946\n",
      "resetting env. episode reward total was -13.0. running mean: -0.19373756417552868\n",
      "resetting env. episode reward total was 8.0. running mean: -0.1118001885337734\n",
      "resetting env. episode reward total was -7.0. running mean: -0.18068218664843566\n",
      "resetting env. episode reward total was -2.0. running mean: -0.19887536478195128\n",
      "resetting env. episode reward total was 6.0. running mean: -0.13688661113413178\n",
      "resetting env. episode reward total was -11.0. running mean: -0.24551774502279045\n",
      "resetting env. episode reward total was 1.0. running mean: -0.23306256757256252\n",
      "resetting env. episode reward total was 7.0. running mean: -0.1607319418968369\n",
      "resetting env. episode reward total was -9.0. running mean: -0.2491246224778685\n",
      "resetting env. episode reward total was 7.0. running mean: -0.1766333762530898\n",
      "resetting env. episode reward total was -4.0. running mean: -0.2148670424905589\n",
      "resetting env. episode reward total was 6.0. running mean: -0.1527183720656533\n",
      "resetting env. episode reward total was 9.0. running mean: -0.06119118834499679\n",
      "resetting env. episode reward total was -3.0. running mean: -0.09057927646154681\n",
      "resetting env. episode reward total was 5.0. running mean: -0.03967348369693134\n",
      "resetting env. episode reward total was -3.0. running mean: -0.06927674885996202\n",
      "resetting env. episode reward total was 4.0. running mean: -0.0285839813713624\n",
      "resetting env. episode reward total was 2.0. running mean: -0.008298141557648776\n",
      "resetting env. episode reward total was 7.0. running mean: 0.061784839857927716\n",
      "resetting env. episode reward total was -2.0. running mean: 0.041166991459348434\n",
      "resetting env. episode reward total was -7.0. running mean: -0.02924467845524506\n",
      "resetting env. episode reward total was 1.0. running mean: -0.018952231670692606\n",
      "resetting env. episode reward total was -5.0. running mean: -0.06876270935398568\n",
      "resetting env. episode reward total was 12.0. running mean: 0.05192491773955417\n",
      "resetting env. episode reward total was -16.0. running mean: -0.10859433143784138\n",
      "resetting env. episode reward total was -4.0. running mean: -0.14750838812346295\n",
      "resetting env. episode reward total was 10.0. running mean: -0.04603330424222832\n",
      "resetting env. episode reward total was -1.0. running mean: -0.05557297119980604\n",
      "resetting env. episode reward total was 3.0. running mean: -0.025017241487807977\n",
      "resetting env. episode reward total was 1.0. running mean: -0.014767069072929897\n",
      "resetting env. episode reward total was -3.0. running mean: -0.044619398382200595\n",
      "resetting env. episode reward total was -3.0. running mean: -0.07417320439837859\n",
      "resetting env. episode reward total was 6.0. running mean: -0.013431472354394805\n",
      "resetting env. episode reward total was 10.0. running mean: 0.08670284236914914\n",
      "resetting env. episode reward total was -5.0. running mean: 0.03583581394545765\n",
      "resetting env. episode reward total was -5.0. running mean: -0.014522544193996928\n",
      "resetting env. episode reward total was 2.0. running mean: 0.005622681247943042\n",
      "resetting env. episode reward total was 4.0. running mean: 0.045566454435463616\n",
      "resetting env. episode reward total was -11.0. running mean: -0.06488921010889102\n",
      "resetting env. episode reward total was 5.0. running mean: -0.014240318007802108\n",
      "resetting env. episode reward total was 9.0. running mean: 0.07590208517227591\n",
      "resetting env. episode reward total was -1.0. running mean: 0.06514306432055315\n",
      "resetting env. episode reward total was -4.0. running mean: 0.024491633677347614\n",
      "resetting env. episode reward total was 3.0. running mean: 0.05424671734057414\n",
      "resetting env. episode reward total was -3.0. running mean: 0.0237042501671684\n",
      "resetting env. episode reward total was -1.0. running mean: 0.013467207665496717\n",
      "resetting env. episode reward total was 4.0. running mean: 0.053332535588841753\n",
      "resetting env. episode reward total was -4.0. running mean: 0.012799210232953336\n",
      "resetting env. episode reward total was 8.0. running mean: 0.0926712181306238\n",
      "resetting env. episode reward total was 7.0. running mean: 0.16174450594931755\n",
      "resetting env. episode reward total was -8.0. running mean: 0.08012706088982437\n",
      "resetting env. episode reward total was -1.0. running mean: 0.06932579028092613\n",
      "resetting env. episode reward total was -12.0. running mean: -0.05136746762188313\n",
      "resetting env. episode reward total was -3.0. running mean: -0.0808537929456643\n",
      "resetting env. episode reward total was 7.0. running mean: -0.01004525501620765\n",
      "resetting env. episode reward total was 3.0. running mean: 0.020055197533954426\n",
      "resetting env. episode reward total was -3.0. running mean: -0.010145354441385118\n",
      "resetting env. episode reward total was -10.0. running mean: -0.11004390089697128\n",
      "resetting env. episode reward total was -19.0. running mean: -0.2989434618880016\n",
      "resetting env. episode reward total was -7.0. running mean: -0.3659540272691216\n",
      "resetting env. episode reward total was -7.0. running mean: -0.43229448699643036\n",
      "resetting env. episode reward total was -7.0. running mean: -0.49797154212646605\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5029918267052014\n",
      "resetting env. episode reward total was 8.0. running mean: -0.41796190843814934\n",
      "resetting env. episode reward total was 12.0. running mean: -0.2937822893537679\n",
      "resetting env. episode reward total was -2.0. running mean: -0.31084446646023023\n",
      "resetting env. episode reward total was -1.0. running mean: -0.31773602179562793\n",
      "resetting env. episode reward total was -6.0. running mean: -0.37455866157767165\n",
      "resetting env. episode reward total was -6.0. running mean: -0.4308130749618949\n",
      "resetting env. episode reward total was -1.0. running mean: -0.436504944212276\n",
      "resetting env. episode reward total was -10.0. running mean: -0.5321398947701532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: -0.5968184958224516\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6408503108642272\n",
      "resetting env. episode reward total was 1.0. running mean: -0.6244418077555849\n",
      "resetting env. episode reward total was -11.0. running mean: -0.728197389678029\n",
      "resetting env. episode reward total was -8.0. running mean: -0.8009154157812487\n",
      "resetting env. episode reward total was -2.0. running mean: -0.8129062616234363\n",
      "resetting env. episode reward total was -5.0. running mean: -0.854777199007202\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8062294270171299\n",
      "resetting env. episode reward total was -7.0. running mean: -0.8681671327469584\n",
      "resetting env. episode reward total was 5.0. running mean: -0.8094854614194888\n",
      "resetting env. episode reward total was -2.0. running mean: -0.821390606805294\n",
      "resetting env. episode reward total was 7.0. running mean: -0.743176700737241\n",
      "resetting env. episode reward total was 6.0. running mean: -0.6757449337298684\n",
      "resetting env. episode reward total was -2.0. running mean: -0.6889874843925697\n",
      "resetting env. episode reward total was 6.0. running mean: -0.6220976095486441\n",
      "resetting env. episode reward total was -12.0. running mean: -0.7358766334531577\n",
      "resetting env. episode reward total was 12.0. running mean: -0.6085178671186261\n",
      "resetting env. episode reward total was 6.0. running mean: -0.5424326884474397\n",
      "resetting env. episode reward total was 9.0. running mean: -0.4470083615629654\n",
      "resetting env. episode reward total was 5.0. running mean: -0.39253827794733576\n",
      "resetting env. episode reward total was 6.0. running mean: -0.3286128951678624\n",
      "resetting env. episode reward total was 11.0. running mean: -0.2153267662161838\n",
      "resetting env. episode reward total was -4.0. running mean: -0.25317349855402194\n",
      "resetting env. episode reward total was -15.0. running mean: -0.4006417635684817\n",
      "resetting env. episode reward total was -7.0. running mean: -0.4666353459327969\n",
      "resetting env. episode reward total was -1.0. running mean: -0.4719689924734689\n",
      "resetting env. episode reward total was 9.0. running mean: -0.37724930254873423\n",
      "resetting env. episode reward total was 7.0. running mean: -0.3034768095232469\n",
      "resetting env. episode reward total was 3.0. running mean: -0.2704420414280144\n",
      "resetting env. episode reward total was 3.0. running mean: -0.23773762101373427\n",
      "resetting env. episode reward total was -7.0. running mean: -0.3053602448035969\n",
      "resetting env. episode reward total was -3.0. running mean: -0.33230664235556095\n",
      "resetting env. episode reward total was 4.0. running mean: -0.28898357593200535\n",
      "resetting env. episode reward total was 6.0. running mean: -0.2260937401726853\n",
      "resetting env. episode reward total was 4.0. running mean: -0.18383280277095843\n",
      "resetting env. episode reward total was 7.0. running mean: -0.11199447474324883\n",
      "resetting env. episode reward total was 10.0. running mean: -0.01087452999581634\n",
      "resetting env. episode reward total was -12.0. running mean: -0.13076578469585817\n",
      "resetting env. episode reward total was -5.0. running mean: -0.1794581268488996\n",
      "resetting env. episode reward total was 12.0. running mean: -0.05766354558041062\n",
      "resetting env. episode reward total was -3.0. running mean: -0.08708691012460651\n",
      "resetting env. episode reward total was 1.0. running mean: -0.07621604102336045\n",
      "resetting env. episode reward total was 5.0. running mean: -0.02545388061312684\n",
      "resetting env. episode reward total was 10.0. running mean: 0.07480065819300444\n",
      "resetting env. episode reward total was 4.0. running mean: 0.11405265161107439\n",
      "resetting env. episode reward total was 5.0. running mean: 0.16291212509496367\n",
      "resetting env. episode reward total was -6.0. running mean: 0.10128300384401404\n",
      "resetting env. episode reward total was -3.0. running mean: 0.07027017380557389\n",
      "resetting env. episode reward total was 6.0. running mean: 0.12956747206751815\n",
      "resetting env. episode reward total was -13.0. running mean: -0.0017282026531570405\n",
      "resetting env. episode reward total was -5.0. running mean: -0.051710920626625474\n",
      "resetting env. episode reward total was 11.0. running mean: 0.05880618857964078\n",
      "resetting env. episode reward total was 8.0. running mean: 0.13821812669384437\n",
      "resetting env. episode reward total was -1.0. running mean: 0.1268359454269059\n",
      "resetting env. episode reward total was 5.0. running mean: 0.17556758597263683\n",
      "resetting env. episode reward total was 1.0. running mean: 0.18381191011291048\n",
      "resetting env. episode reward total was 10.0. running mean: 0.2819737910117814\n",
      "resetting env. episode reward total was 14.0. running mean: 0.4191540531016636\n",
      "resetting env. episode reward total was -5.0. running mean: 0.364962512570647\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3113128874449405\n",
      "resetting env. episode reward total was 12.0. running mean: 0.4281997585704911\n",
      "resetting env. episode reward total was 2.0. running mean: 0.4439177609847862\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5494785833749384\n",
      "resetting env. episode reward total was 1.0. running mean: 0.553983797541189\n",
      "resetting env. episode reward total was 5.0. running mean: 0.5984439595657771\n",
      "resetting env. episode reward total was -4.0. running mean: 0.5524595199701193\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5869349247704182\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5310655755227139\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5557549197674868\n",
      "resetting env. episode reward total was 14.0. running mean: 0.6901973705698119\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7432953968641138\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8158624428954726\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8677038184665178\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8090267802818526\n",
      "resetting env. episode reward total was 9.0. running mean: 0.890936512479034\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8920271473542437\n",
      "resetting env. episode reward total was 13.0. running mean: 1.0131068758807014\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0729758071218944\n",
      "resetting env. episode reward total was 9.0. running mean: 1.1522460490506756\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2307235885601688\n",
      "resetting env. episode reward total was -3.0. running mean: 1.188416352674567\n",
      "resetting env. episode reward total was 7.0. running mean: 1.2465321891478214\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3040668672563431\n",
      "resetting env. episode reward total was 9.0. running mean: 1.3810261985837797\n",
      "resetting env. episode reward total was 3.0. running mean: 1.397215936597942\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4032437772319626\n",
      "resetting env. episode reward total was 8.0. running mean: 1.469211339459643\n",
      "resetting env. episode reward total was -3.0. running mean: 1.4245192260650466\n",
      "resetting env. episode reward total was 6.0. running mean: 1.470274033804396\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5355712934663521\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6002155805316887\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6542134247263718\n",
      "resetting env. episode reward total was 11.0. running mean: 1.747671290479108\n",
      "resetting env. episode reward total was 5.0. running mean: 1.780194577574317\n",
      "resetting env. episode reward total was 7.0. running mean: 1.832392631798574\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8440687054805882\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8356280184257823\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8272717382415244\n",
      "resetting env. episode reward total was -6.0. running mean: 1.748999020859109\n",
      "resetting env. episode reward total was 5.0. running mean: 1.781509030650518\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8336939403440127\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8353570009405726\n",
      "resetting env. episode reward total was -7.0. running mean: 1.7470034309311668\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7395333966218551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 1.8021380626556367\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7541166820290803\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6465755152087895\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6701097600567016\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6034086624561346\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6273745758315732\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6711008300732575\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6043898217725248\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6283459235547995\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6520624643192514\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6755418396760589\n",
      "resetting env. episode reward total was 1.0. running mean: 1.6687864212792982\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6420985570665052\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5956775714958402\n",
      "resetting env. episode reward total was 6.0. running mean: 1.639720795780882\n",
      "resetting env. episode reward total was 13.0. running mean: 1.7533235878230733\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7857903519448426\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7479324484253942\n",
      "resetting env. episode reward total was 8.0. running mean: 1.8104531239411403\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9123485927017287\n",
      "resetting env. episode reward total was 17.0. running mean: 2.0632251067747114\n",
      "resetting env. episode reward total was -3.0. running mean: 2.0125928557069646\n",
      "resetting env. episode reward total was 12.0. running mean: 2.112466927149895\n",
      "resetting env. episode reward total was -1.0. running mean: 2.081342257878396\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0105288352996125\n",
      "resetting env. episode reward total was 10.0. running mean: 2.0904235469466164\n",
      "resetting env. episode reward total was 9.0. running mean: 2.15951931147715\n",
      "resetting env. episode reward total was 4.0. running mean: 2.1779241183623785\n",
      "resetting env. episode reward total was 1.0. running mean: 2.1661448771787546\n",
      "resetting env. episode reward total was -3.0. running mean: 2.114483428406967\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0733385941228972\n",
      "resetting env. episode reward total was 5.0. running mean: 2.102605208181668\n",
      "resetting env. episode reward total was -3.0. running mean: 2.0515791560998515\n",
      "resetting env. episode reward total was 11.0. running mean: 2.141063364538853\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0996527308934643\n",
      "resetting env. episode reward total was 5.0. running mean: 2.1286562035845296\n",
      "resetting env. episode reward total was -1.0. running mean: 2.0973696415486844\n",
      "resetting env. episode reward total was 10.0. running mean: 2.176395945133198\n",
      "resetting env. episode reward total was 5.0. running mean: 2.2046319856818655\n",
      "resetting env. episode reward total was -9.0. running mean: 2.092585665825047\n",
      "resetting env. episode reward total was -8.0. running mean: 1.991659809166796\n",
      "resetting env. episode reward total was 6.0. running mean: 2.031743211075128\n",
      "resetting env. episode reward total was 4.0. running mean: 2.051425778964377\n",
      "resetting env. episode reward total was 7.0. running mean: 2.100911521174733\n",
      "resetting env. episode reward total was -3.0. running mean: 2.049902405962986\n",
      "resetting env. episode reward total was -3.0. running mean: 1.9994033819033559\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9294093480843222\n",
      "resetting env. episode reward total was -7.0. running mean: 1.840115254603479\n",
      "resetting env. episode reward total was -2.0. running mean: 1.801714102057444\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8336969610368696\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8653599914265009\n",
      "resetting env. episode reward total was -3.0. running mean: 1.816706391512236\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8285393275971136\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7802539343211423\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8024513949779308\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8144268810281516\n",
      "resetting env. episode reward total was -10.0. running mean: 1.69628261221787\n",
      "resetting env. episode reward total was 9.0. running mean: 1.7693197860956913\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8016265882347344\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7936103223523872\n",
      "resetting env. episode reward total was 11.0. running mean: 1.8856742191288633\n",
      "resetting env. episode reward total was 9.0. running mean: 1.9568174769375748\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9272493021681991\n",
      "resetting env. episode reward total was 3.0. running mean: 1.937976809146517\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8885970410550519\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8197110706445012\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7815139599380563\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8036988203386757\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8356618321352889\n",
      "resetting env. episode reward total was -8.0. running mean: 1.737305213813936\n",
      "resetting env. episode reward total was -6.0. running mean: 1.6599321616757965\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6333328400590386\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6669995116584482\n",
      "resetting env. episode reward total was 16.0. running mean: 1.8103295165418636\n",
      "resetting env. episode reward total was -1.0. running mean: 1.7822262213764448\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7744039591626803\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7966599195710535\n",
      "resetting env. episode reward total was -3.0. running mean: 1.748693320375343\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7012063871715895\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7541943232998736\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7766523800668748\n",
      "resetting env. episode reward total was 8.0. running mean: 1.838885856266206\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8104969977035439\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8623920277265085\n",
      "resetting env. episode reward total was 15.0. running mean: 1.9937681074492433\n",
      "resetting env. episode reward total was -2.0. running mean: 1.9538304263747508\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9942921221110033\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9843492008898933\n",
      "resetting env. episode reward total was 9.0. running mean: 2.054505708880994\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0739606517921843\n",
      "resetting env. episode reward total was 11.0. running mean: 2.163221045274262\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1615888348215195\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2099729464733042\n",
      "resetting env. episode reward total was -9.0. running mean: 2.0978732170085714\n",
      "resetting env. episode reward total was 7.0. running mean: 2.1468944848384854\n",
      "resetting env. episode reward total was 8.0. running mean: 2.2054255399901006\n",
      "resetting env. episode reward total was 3.0. running mean: 2.2133712845901994\n",
      "resetting env. episode reward total was -4.0. running mean: 2.1512375717442973\n",
      "resetting env. episode reward total was 7.0. running mean: 2.1997251960268542\n",
      "resetting env. episode reward total was 11.0. running mean: 2.2877279440665856\n",
      "resetting env. episode reward total was 7.0. running mean: 2.3348506646259195\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3315021579796604\n",
      "resetting env. episode reward total was 1.0. running mean: 2.3181871363998634\n",
      "resetting env. episode reward total was 6.0. running mean: 2.3550052650358646\n",
      "resetting env. episode reward total was -2.0. running mean: 2.311455212385506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: 2.218340660261651\n",
      "resetting env. episode reward total was 1.0. running mean: 2.2061572536590344\n",
      "resetting env. episode reward total was 2.0. running mean: 2.204095681122444\n",
      "resetting env. episode reward total was 3.0. running mean: 2.212054724311219\n",
      "resetting env. episode reward total was 6.0. running mean: 2.249934177068107\n",
      "resetting env. episode reward total was -6.0. running mean: 2.167434835297426\n",
      "resetting env. episode reward total was 7.0. running mean: 2.2157604869444514\n",
      "resetting env. episode reward total was 2.0. running mean: 2.2136028820750067\n",
      "resetting env. episode reward total was 9.0. running mean: 2.2814668532542566\n",
      "resetting env. episode reward total was 2.0. running mean: 2.278652184721714\n",
      "resetting env. episode reward total was 3.0. running mean: 2.285865662874497\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3130070062457517\n",
      "resetting env. episode reward total was 10.0. running mean: 2.389876936183294\n",
      "resetting env. episode reward total was -5.0. running mean: 2.3159781668214614\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3128183851532467\n",
      "resetting env. episode reward total was 2.0. running mean: 2.309690201301714\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2765932992886975\n",
      "resetting env. episode reward total was 12.0. running mean: 2.3738273662958105\n",
      "resetting env. episode reward total was 6.0. running mean: 2.410089092632852\n",
      "resetting env. episode reward total was 11.0. running mean: 2.4959882017065236\n",
      "resetting env. episode reward total was 6.0. running mean: 2.5310283196894585\n",
      "resetting env. episode reward total was 7.0. running mean: 2.575718036492564\n",
      "resetting env. episode reward total was 5.0. running mean: 2.599960856127638\n",
      "resetting env. episode reward total was 10.0. running mean: 2.6739612475663614\n",
      "resetting env. episode reward total was 11.0. running mean: 2.7572216350906977\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7596494187397904\n",
      "resetting env. episode reward total was -2.0. running mean: 2.7120529245523923\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7149323953068683\n",
      "resetting env. episode reward total was 9.0. running mean: 2.777783071353799\n",
      "resetting env. episode reward total was 11.0. running mean: 2.860005240640261\n",
      "resetting env. episode reward total was -5.0. running mean: 2.7814051882338586\n",
      "resetting env. episode reward total was 2.0. running mean: 2.77359113635152\n",
      "resetting env. episode reward total was 4.0. running mean: 2.785855224988005\n",
      "resetting env. episode reward total was 8.0. running mean: 2.8379966727381247\n",
      "resetting env. episode reward total was 12.0. running mean: 2.9296167060107434\n",
      "resetting env. episode reward total was 12.0. running mean: 3.020320538950636\n",
      "resetting env. episode reward total was 8.0. running mean: 3.0701173335611296\n",
      "resetting env. episode reward total was 11.0. running mean: 3.149416160225518\n",
      "resetting env. episode reward total was -6.0. running mean: 3.057921998623263\n",
      "resetting env. episode reward total was 13.0. running mean: 3.1573427786370303\n",
      "resetting env. episode reward total was 3.0. running mean: 3.15576935085066\n",
      "resetting env. episode reward total was 15.0. running mean: 3.2742116573421534\n",
      "resetting env. episode reward total was -5.0. running mean: 3.191469540768732\n",
      "resetting env. episode reward total was -8.0. running mean: 3.0795548453610446\n",
      "resetting env. episode reward total was 6.0. running mean: 3.1087592969074342\n",
      "resetting env. episode reward total was 8.0. running mean: 3.15767170393836\n",
      "resetting env. episode reward total was 5.0. running mean: 3.1760949868989763\n",
      "resetting env. episode reward total was -9.0. running mean: 3.0543340370299865\n",
      "resetting env. episode reward total was 1.0. running mean: 3.0337906966596866\n",
      "resetting env. episode reward total was 6.0. running mean: 3.06345278969309\n",
      "resetting env. episode reward total was 3.0. running mean: 3.0628182617961586\n",
      "resetting env. episode reward total was -1.0. running mean: 3.022190079178197\n",
      "resetting env. episode reward total was -2.0. running mean: 2.971968178386415\n",
      "resetting env. episode reward total was 4.0. running mean: 2.982248496602551\n",
      "resetting env. episode reward total was 8.0. running mean: 3.0324260116365256\n",
      "resetting env. episode reward total was 3.0. running mean: 3.0321017515201603\n",
      "resetting env. episode reward total was 2.0. running mean: 3.0217807340049587\n",
      "resetting env. episode reward total was -6.0. running mean: 2.9315629266649093\n",
      "resetting env. episode reward total was -14.0. running mean: 2.76224729739826\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7646248244242773\n",
      "resetting env. episode reward total was 13.0. running mean: 2.8669785761800344\n",
      "resetting env. episode reward total was 2.0. running mean: 2.858308790418234\n",
      "resetting env. episode reward total was -6.0. running mean: 2.7697257025140516\n",
      "resetting env. episode reward total was 4.0. running mean: 2.782028445488911\n",
      "resetting env. episode reward total was 5.0. running mean: 2.8042081610340217\n",
      "resetting env. episode reward total was 8.0. running mean: 2.8561660794236814\n",
      "resetting env. episode reward total was -9.0. running mean: 2.7376044186294446\n",
      "resetting env. episode reward total was 4.0. running mean: 2.75022837444315\n",
      "resetting env. episode reward total was -5.0. running mean: 2.6727260906987187\n",
      "resetting env. episode reward total was 4.0. running mean: 2.6859988297917314\n",
      "resetting env. episode reward total was -7.0. running mean: 2.5891388414938143\n",
      "resetting env. episode reward total was 4.0. running mean: 2.6032474530788763\n",
      "resetting env. episode reward total was -9.0. running mean: 2.4872149785480877\n",
      "resetting env. episode reward total was -4.0. running mean: 2.422342828762607\n",
      "resetting env. episode reward total was -7.0. running mean: 2.3281194004749812\n",
      "resetting env. episode reward total was 7.0. running mean: 2.374838206470231\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3710898244055287\n",
      "resetting env. episode reward total was 7.0. running mean: 2.417378926161473\n",
      "resetting env. episode reward total was 5.0. running mean: 2.443205136899858\n",
      "resetting env. episode reward total was 3.0. running mean: 2.4487730855308594\n",
      "resetting env. episode reward total was 5.0. running mean: 2.4742853546755508\n",
      "resetting env. episode reward total was -6.0. running mean: 2.3895425011287954\n",
      "resetting env. episode reward total was 7.0. running mean: 2.4356470761175073\n",
      "resetting env. episode reward total was 1.0. running mean: 2.421290605356332\n",
      "resetting env. episode reward total was 14.0. running mean: 2.537077699302769\n",
      "resetting env. episode reward total was 5.0. running mean: 2.561706922309741\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5660898530866434\n",
      "resetting env. episode reward total was 1.0. running mean: 2.550428954555777\n",
      "resetting env. episode reward total was 4.0. running mean: 2.564924665010219\n",
      "resetting env. episode reward total was 10.0. running mean: 2.639275418360117\n",
      "resetting env. episode reward total was 12.0. running mean: 2.7328826641765156\n",
      "resetting env. episode reward total was 2.0. running mean: 2.7255538375347506\n",
      "resetting env. episode reward total was 11.0. running mean: 2.8082982991594028\n",
      "resetting env. episode reward total was 10.0. running mean: 2.880215316167809\n",
      "resetting env. episode reward total was 10.0. running mean: 2.951413163006131\n",
      "resetting env. episode reward total was 3.0. running mean: 2.9518990313760693\n",
      "resetting env. episode reward total was 10.0. running mean: 3.0223800410623087\n",
      "resetting env. episode reward total was 2.0. running mean: 3.0121562406516857\n",
      "resetting env. episode reward total was -2.0. running mean: 2.962034678245169\n",
      "resetting env. episode reward total was 1.0. running mean: 2.942414331462717\n",
      "resetting env. episode reward total was 3.0. running mean: 2.9429901881480895\n",
      "resetting env. episode reward total was 11.0. running mean: 3.0235602862666084\n",
      "resetting env. episode reward total was 5.0. running mean: 3.043324683403942\n",
      "resetting env. episode reward total was 6.0. running mean: 3.0728914365699027\n",
      "resetting env. episode reward total was -9.0. running mean: 2.952162522204204\n",
      "resetting env. episode reward total was 9.0. running mean: 3.0126408969821616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 14.0. running mean: 3.12251448801234\n",
      "resetting env. episode reward total was 6.0. running mean: 3.1512893431322166\n",
      "resetting env. episode reward total was 2.0. running mean: 3.1397764497008946\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1483786852038858\n",
      "resetting env. episode reward total was 6.0. running mean: 3.176894898351847\n",
      "resetting env. episode reward total was 8.0. running mean: 3.2251259493683286\n",
      "resetting env. episode reward total was 7.0. running mean: 3.262874689874645\n",
      "resetting env. episode reward total was 4.0. running mean: 3.2702459429758988\n",
      "resetting env. episode reward total was 3.0. running mean: 3.2675434835461394\n",
      "resetting env. episode reward total was 9.0. running mean: 3.324868048710678\n",
      "resetting env. episode reward total was 1.0. running mean: 3.3016193682235713\n",
      "resetting env. episode reward total was 3.0. running mean: 3.298603174541335\n",
      "resetting env. episode reward total was 8.0. running mean: 3.3456171427959216\n",
      "resetting env. episode reward total was 5.0. running mean: 3.3621609713679623\n",
      "resetting env. episode reward total was 11.0. running mean: 3.4385393616542825\n",
      "resetting env. episode reward total was -5.0. running mean: 3.35415396803774\n",
      "resetting env. episode reward total was 4.0. running mean: 3.3606124283573626\n",
      "resetting env. episode reward total was 7.0. running mean: 3.397006304073789\n",
      "resetting env. episode reward total was -4.0. running mean: 3.323036241033051\n",
      "resetting env. episode reward total was -1.0. running mean: 3.2798058786227204\n",
      "resetting env. episode reward total was 2.0. running mean: 3.2670078198364934\n",
      "resetting env. episode reward total was 8.0. running mean: 3.3143377416381283\n",
      "resetting env. episode reward total was 1.0. running mean: 3.291194364221747\n",
      "resetting env. episode reward total was 9.0. running mean: 3.348282420579529\n",
      "resetting env. episode reward total was 10.0. running mean: 3.414799596373734\n",
      "resetting env. episode reward total was 1.0. running mean: 3.3906516004099965\n",
      "resetting env. episode reward total was 1.0. running mean: 3.3667450844058964\n",
      "resetting env. episode reward total was 13.0. running mean: 3.4630776335618374\n",
      "resetting env. episode reward total was 9.0. running mean: 3.518446857226219\n",
      "resetting env. episode reward total was -3.0. running mean: 3.4532623886539566\n",
      "resetting env. episode reward total was 13.0. running mean: 3.5487297647674168\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5932424671197425\n",
      "resetting env. episode reward total was -4.0. running mean: 3.517310042448545\n",
      "resetting env. episode reward total was -1.0. running mean: 3.4721369420240595\n",
      "resetting env. episode reward total was 5.0. running mean: 3.4874155726038185\n",
      "resetting env. episode reward total was 3.0. running mean: 3.48254141687778\n",
      "resetting env. episode reward total was 3.0. running mean: 3.477716002709002\n",
      "resetting env. episode reward total was -3.0. running mean: 3.4129388426819123\n",
      "resetting env. episode reward total was -5.0. running mean: 3.3288094542550932\n",
      "resetting env. episode reward total was 15.0. running mean: 3.4455213597125423\n",
      "resetting env. episode reward total was 6.0. running mean: 3.4710661461154166\n",
      "resetting env. episode reward total was 11.0. running mean: 3.546355484654262\n",
      "resetting env. episode reward total was -5.0. running mean: 3.46089192980772\n",
      "resetting env. episode reward total was 11.0. running mean: 3.5362830105096426\n",
      "resetting env. episode reward total was 9.0. running mean: 3.590920180404546\n",
      "resetting env. episode reward total was 5.0. running mean: 3.6050109786005002\n",
      "resetting env. episode reward total was 7.0. running mean: 3.638960868814495\n",
      "resetting env. episode reward total was 12.0. running mean: 3.72257126012635\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7353455475250863\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6879920920498357\n",
      "resetting env. episode reward total was 1.0. running mean: 3.661112171129337\n",
      "resetting env. episode reward total was 4.0. running mean: 3.664501049418044\n",
      "resetting env. episode reward total was 5.0. running mean: 3.677856038923863\n",
      "resetting env. episode reward total was -12.0. running mean: 3.5210774785346244\n",
      "resetting env. episode reward total was 7.0. running mean: 3.555866703749278\n",
      "resetting env. episode reward total was 13.0. running mean: 3.650308036711785\n",
      "resetting env. episode reward total was 3.0. running mean: 3.643804956344667\n",
      "resetting env. episode reward total was 7.0. running mean: 3.67736690678122\n",
      "resetting env. episode reward total was -5.0. running mean: 3.5905932377134078\n",
      "resetting env. episode reward total was 12.0. running mean: 3.6746873053362736\n",
      "resetting env. episode reward total was 6.0. running mean: 3.697940432282911\n",
      "resetting env. episode reward total was 2.0. running mean: 3.6809610279600817\n",
      "resetting env. episode reward total was 2.0. running mean: 3.664151417680481\n",
      "resetting env. episode reward total was 8.0. running mean: 3.707509903503676\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6604348044686392\n",
      "resetting env. episode reward total was 14.0. running mean: 3.763830456423953\n",
      "resetting env. episode reward total was 1.0. running mean: 3.736192151859713\n",
      "resetting env. episode reward total was 11.0. running mean: 3.808830230341116\n",
      "resetting env. episode reward total was 6.0. running mean: 3.8307419280377046\n",
      "resetting env. episode reward total was 10.0. running mean: 3.8924345087573275\n",
      "resetting env. episode reward total was 9.0. running mean: 3.943510163669754\n",
      "resetting env. episode reward total was 9.0. running mean: 3.9940750620330565\n",
      "resetting env. episode reward total was -6.0. running mean: 3.894134311412726\n",
      "resetting env. episode reward total was 10.0. running mean: 3.955192968298599\n",
      "resetting env. episode reward total was 2.0. running mean: 3.935641038615613\n",
      "resetting env. episode reward total was 6.0. running mean: 3.9562846282294566\n",
      "resetting env. episode reward total was 4.0. running mean: 3.956721781947162\n",
      "resetting env. episode reward total was 5.0. running mean: 3.96715456412769\n",
      "resetting env. episode reward total was 12.0. running mean: 4.047483018486413\n",
      "resetting env. episode reward total was 3.0. running mean: 4.037008188301549\n",
      "resetting env. episode reward total was -1.0. running mean: 3.9866381064185332\n",
      "resetting env. episode reward total was 3.0. running mean: 3.9767717253543475\n",
      "resetting env. episode reward total was 8.0. running mean: 4.017004008100804\n",
      "resetting env. episode reward total was 3.0. running mean: 4.006833968019795\n",
      "resetting env. episode reward total was -4.0. running mean: 3.9267656283395973\n",
      "resetting env. episode reward total was 11.0. running mean: 3.9974979720562014\n",
      "resetting env. episode reward total was -1.0. running mean: 3.9475229923356396\n",
      "resetting env. episode reward total was 11.0. running mean: 4.018047762412284\n",
      "resetting env. episode reward total was 13.0. running mean: 4.107867284788161\n",
      "resetting env. episode reward total was 12.0. running mean: 4.186788611940279\n",
      "resetting env. episode reward total was 9.0. running mean: 4.234920725820876\n",
      "resetting env. episode reward total was -4.0. running mean: 4.1525715185626675\n",
      "resetting env. episode reward total was 9.0. running mean: 4.201045803377041\n",
      "resetting env. episode reward total was -1.0. running mean: 4.149035345343271\n",
      "resetting env. episode reward total was 7.0. running mean: 4.177544991889839\n",
      "resetting env. episode reward total was 6.0. running mean: 4.19576954197094\n",
      "resetting env. episode reward total was 6.0. running mean: 4.213811846551231\n",
      "resetting env. episode reward total was 8.0. running mean: 4.251673728085718\n",
      "resetting env. episode reward total was 8.0. running mean: 4.2891569908048615\n",
      "resetting env. episode reward total was 3.0. running mean: 4.276265420896813\n",
      "resetting env. episode reward total was 6.0. running mean: 4.293502766687844\n",
      "resetting env. episode reward total was -1.0. running mean: 4.240567739020966\n",
      "resetting env. episode reward total was 15.0. running mean: 4.348162061630757\n",
      "resetting env. episode reward total was 9.0. running mean: 4.394680441014449\n",
      "resetting env. episode reward total was 12.0. running mean: 4.4707336366043045\n",
      "resetting env. episode reward total was 13.0. running mean: 4.556026300238261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 4.580466037235879\n",
      "resetting env. episode reward total was 13.0. running mean: 4.66466137686352\n",
      "resetting env. episode reward total was 3.0. running mean: 4.648014763094885\n",
      "resetting env. episode reward total was 2.0. running mean: 4.621534615463935\n",
      "resetting env. episode reward total was 12.0. running mean: 4.695319269309296\n",
      "resetting env. episode reward total was 6.0. running mean: 4.708366076616203\n",
      "resetting env. episode reward total was 15.0. running mean: 4.811282415850041\n",
      "resetting env. episode reward total was 2.0. running mean: 4.78316959169154\n",
      "resetting env. episode reward total was -1.0. running mean: 4.725337895774625\n",
      "resetting env. episode reward total was 16.0. running mean: 4.8380845168168785\n",
      "resetting env. episode reward total was 5.0. running mean: 4.839703671648709\n",
      "resetting env. episode reward total was -6.0. running mean: 4.731306634932222\n",
      "resetting env. episode reward total was 5.0. running mean: 4.7339935685829\n",
      "resetting env. episode reward total was 9.0. running mean: 4.77665363289707\n",
      "resetting env. episode reward total was -5.0. running mean: 4.6788870965681\n",
      "resetting env. episode reward total was 14.0. running mean: 4.772098225602418\n",
      "resetting env. episode reward total was 5.0. running mean: 4.774377243346394\n",
      "resetting env. episode reward total was 7.0. running mean: 4.79663347091293\n",
      "resetting env. episode reward total was 11.0. running mean: 4.858667136203801\n",
      "resetting env. episode reward total was 14.0. running mean: 4.950080464841762\n",
      "resetting env. episode reward total was 8.0. running mean: 4.980579660193345\n",
      "resetting env. episode reward total was 7.0. running mean: 5.000773863591411\n",
      "resetting env. episode reward total was 4.0. running mean: 4.990766124955497\n",
      "resetting env. episode reward total was 14.0. running mean: 5.080858463705942\n",
      "resetting env. episode reward total was 12.0. running mean: 5.150049879068883\n",
      "resetting env. episode reward total was -5.0. running mean: 5.048549380278194\n",
      "resetting env. episode reward total was 5.0. running mean: 5.048063886475412\n",
      "resetting env. episode reward total was 6.0. running mean: 5.0575832476106575\n",
      "resetting env. episode reward total was 8.0. running mean: 5.087007415134551\n",
      "resetting env. episode reward total was 3.0. running mean: 5.066137340983206\n",
      "resetting env. episode reward total was 9.0. running mean: 5.105475967573374\n",
      "resetting env. episode reward total was 12.0. running mean: 5.17442120789764\n",
      "resetting env. episode reward total was -1.0. running mean: 5.1126769958186635\n",
      "resetting env. episode reward total was 15.0. running mean: 5.211550225860477\n",
      "resetting env. episode reward total was -5.0. running mean: 5.109434723601872\n",
      "resetting env. episode reward total was 3.0. running mean: 5.088340376365854\n",
      "resetting env. episode reward total was 12.0. running mean: 5.157456972602195\n",
      "resetting env. episode reward total was 7.0. running mean: 5.175882402876173\n",
      "resetting env. episode reward total was 11.0. running mean: 5.234123578847411\n",
      "resetting env. episode reward total was 6.0. running mean: 5.2417823430589365\n",
      "resetting env. episode reward total was -8.0. running mean: 5.109364519628347\n",
      "resetting env. episode reward total was -3.0. running mean: 5.028270874432063\n",
      "resetting env. episode reward total was 7.0. running mean: 5.047988165687743\n",
      "resetting env. episode reward total was -3.0. running mean: 4.967508284030865\n",
      "resetting env. episode reward total was 11.0. running mean: 5.027833201190557\n",
      "resetting env. episode reward total was 8.0. running mean: 5.057554869178651\n",
      "resetting env. episode reward total was 14.0. running mean: 5.146979320486865\n",
      "resetting env. episode reward total was 11.0. running mean: 5.205509527281996\n",
      "resetting env. episode reward total was -7.0. running mean: 5.083454432009176\n",
      "resetting env. episode reward total was 6.0. running mean: 5.092619887689083\n",
      "resetting env. episode reward total was -4.0. running mean: 5.001693688812193\n",
      "resetting env. episode reward total was 8.0. running mean: 5.031676751924071\n",
      "resetting env. episode reward total was 12.0. running mean: 5.10135998440483\n",
      "resetting env. episode reward total was 12.0. running mean: 5.170346384560782\n",
      "resetting env. episode reward total was -6.0. running mean: 5.058642920715174\n",
      "resetting env. episode reward total was 3.0. running mean: 5.038056491508023\n",
      "resetting env. episode reward total was 12.0. running mean: 5.107675926592942\n",
      "resetting env. episode reward total was -9.0. running mean: 4.966599167327013\n",
      "resetting env. episode reward total was 5.0. running mean: 4.966933175653743\n",
      "resetting env. episode reward total was 6.0. running mean: 4.977263843897205\n",
      "resetting env. episode reward total was 9.0. running mean: 5.017491205458233\n",
      "resetting env. episode reward total was 8.0. running mean: 5.047316293403651\n",
      "resetting env. episode reward total was -5.0. running mean: 4.946843130469615\n",
      "resetting env. episode reward total was 14.0. running mean: 5.037374699164919\n",
      "resetting env. episode reward total was 9.0. running mean: 5.077000952173269\n",
      "resetting env. episode reward total was -7.0. running mean: 4.956230942651536\n",
      "resetting env. episode reward total was 9.0. running mean: 4.9966686332250205\n",
      "resetting env. episode reward total was -4.0. running mean: 4.90670194689277\n",
      "resetting env. episode reward total was -5.0. running mean: 4.807634927423843\n",
      "resetting env. episode reward total was 3.0. running mean: 4.789558578149604\n",
      "resetting env. episode reward total was 6.0. running mean: 4.801662992368108\n",
      "resetting env. episode reward total was 6.0. running mean: 4.813646362444427\n",
      "resetting env. episode reward total was 2.0. running mean: 4.785509898819982\n",
      "resetting env. episode reward total was 6.0. running mean: 4.797654799831782\n",
      "resetting env. episode reward total was 5.0. running mean: 4.7996782518334635\n",
      "resetting env. episode reward total was -2.0. running mean: 4.731681469315129\n",
      "resetting env. episode reward total was 8.0. running mean: 4.764364654621978\n",
      "resetting env. episode reward total was 1.0. running mean: 4.726721008075757\n",
      "resetting env. episode reward total was 1.0. running mean: 4.689453797994999\n",
      "resetting env. episode reward total was 4.0. running mean: 4.682559260015049\n",
      "resetting env. episode reward total was 4.0. running mean: 4.675733667414899\n",
      "resetting env. episode reward total was 9.0. running mean: 4.718976330740749\n",
      "resetting env. episode reward total was 1.0. running mean: 4.681786567433341\n",
      "resetting env. episode reward total was -3.0. running mean: 4.604968701759007\n",
      "resetting env. episode reward total was -5.0. running mean: 4.508919014741417\n",
      "resetting env. episode reward total was 16.0. running mean: 4.623829824594003\n",
      "resetting env. episode reward total was 8.0. running mean: 4.657591526348063\n",
      "resetting env. episode reward total was 12.0. running mean: 4.731015611084582\n",
      "resetting env. episode reward total was -3.0. running mean: 4.653705454973736\n",
      "resetting env. episode reward total was 7.0. running mean: 4.677168400424\n",
      "resetting env. episode reward total was 2.0. running mean: 4.650396716419759\n",
      "resetting env. episode reward total was 4.0. running mean: 4.643892749255561\n",
      "resetting env. episode reward total was 6.0. running mean: 4.657453821763005\n",
      "resetting env. episode reward total was -4.0. running mean: 4.570879283545374\n",
      "resetting env. episode reward total was 9.0. running mean: 4.615170490709921\n",
      "resetting env. episode reward total was 7.0. running mean: 4.639018785802822\n",
      "resetting env. episode reward total was 7.0. running mean: 4.662628597944794\n",
      "resetting env. episode reward total was 11.0. running mean: 4.726002311965346\n",
      "resetting env. episode reward total was 6.0. running mean: 4.7387422888456925\n",
      "resetting env. episode reward total was -3.0. running mean: 4.661354865957235\n",
      "resetting env. episode reward total was 8.0. running mean: 4.694741317297662\n",
      "resetting env. episode reward total was 14.0. running mean: 4.787793904124685\n",
      "resetting env. episode reward total was 11.0. running mean: 4.849915965083438\n",
      "resetting env. episode reward total was 4.0. running mean: 4.841416805432604\n",
      "resetting env. episode reward total was -7.0. running mean: 4.723002637378277\n",
      "resetting env. episode reward total was 14.0. running mean: 4.815772611004494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 4.887614884894449\n",
      "resetting env. episode reward total was 2.0. running mean: 4.858738736045504\n",
      "resetting env. episode reward total was 11.0. running mean: 4.920151348685049\n",
      "resetting env. episode reward total was 10.0. running mean: 4.970949835198199\n",
      "resetting env. episode reward total was -6.0. running mean: 4.861240336846217\n",
      "resetting env. episode reward total was 8.0. running mean: 4.892627933477755\n",
      "resetting env. episode reward total was 5.0. running mean: 4.893701654142977\n",
      "resetting env. episode reward total was -5.0. running mean: 4.794764637601547\n",
      "resetting env. episode reward total was 6.0. running mean: 4.806816991225531\n",
      "resetting env. episode reward total was 11.0. running mean: 4.868748821313276\n",
      "resetting env. episode reward total was 1.0. running mean: 4.830061333100143\n",
      "resetting env. episode reward total was 9.0. running mean: 4.871760719769141\n",
      "resetting env. episode reward total was 9.0. running mean: 4.91304311257145\n",
      "resetting env. episode reward total was 9.0. running mean: 4.953912681445735\n",
      "resetting env. episode reward total was 9.0. running mean: 4.994373554631277\n",
      "resetting env. episode reward total was -6.0. running mean: 4.884429819084965\n",
      "resetting env. episode reward total was -3.0. running mean: 4.805585520894115\n",
      "resetting env. episode reward total was 4.0. running mean: 4.797529665685174\n",
      "resetting env. episode reward total was -13.0. running mean: 4.619554369028322\n",
      "resetting env. episode reward total was -4.0. running mean: 4.533358825338039\n",
      "resetting env. episode reward total was 3.0. running mean: 4.518025237084658\n",
      "resetting env. episode reward total was 9.0. running mean: 4.562844984713812\n",
      "resetting env. episode reward total was 1.0. running mean: 4.527216534866674\n",
      "resetting env. episode reward total was -5.0. running mean: 4.431944369518007\n",
      "resetting env. episode reward total was -3.0. running mean: 4.357624925822827\n",
      "resetting env. episode reward total was 11.0. running mean: 4.424048676564599\n",
      "resetting env. episode reward total was 11.0. running mean: 4.4898081897989535\n",
      "resetting env. episode reward total was -5.0. running mean: 4.394910107900964\n",
      "resetting env. episode reward total was -13.0. running mean: 4.2209610068219545\n",
      "resetting env. episode reward total was 9.0. running mean: 4.268751396753735\n",
      "resetting env. episode reward total was 9.0. running mean: 4.316063882786197\n",
      "resetting env. episode reward total was 2.0. running mean: 4.292903243958334\n",
      "resetting env. episode reward total was 4.0. running mean: 4.289974211518751\n",
      "resetting env. episode reward total was 4.0. running mean: 4.287074469403564\n",
      "resetting env. episode reward total was 3.0. running mean: 4.274203724709528\n",
      "resetting env. episode reward total was 1.0. running mean: 4.241461687462432\n",
      "resetting env. episode reward total was -1.0. running mean: 4.189047070587808\n",
      "resetting env. episode reward total was 8.0. running mean: 4.22715659988193\n",
      "resetting env. episode reward total was -7.0. running mean: 4.11488503388311\n",
      "resetting env. episode reward total was -7.0. running mean: 4.003736183544278\n",
      "resetting env. episode reward total was 4.0. running mean: 4.003698821708835\n",
      "resetting env. episode reward total was 15.0. running mean: 4.113661833491747\n",
      "resetting env. episode reward total was 12.0. running mean: 4.19252521515683\n",
      "resetting env. episode reward total was -1.0. running mean: 4.140599963005262\n",
      "resetting env. episode reward total was 12.0. running mean: 4.21919396337521\n",
      "resetting env. episode reward total was -3.0. running mean: 4.147002023741457\n",
      "resetting env. episode reward total was 6.0. running mean: 4.165532003504042\n",
      "resetting env. episode reward total was -3.0. running mean: 4.093876683469001\n",
      "resetting env. episode reward total was -2.0. running mean: 4.032937916634312\n",
      "resetting env. episode reward total was 9.0. running mean: 4.082608537467969\n",
      "resetting env. episode reward total was 2.0. running mean: 4.061782452093289\n",
      "resetting env. episode reward total was 7.0. running mean: 4.091164627572357\n",
      "resetting env. episode reward total was 9.0. running mean: 4.140252981296633\n",
      "resetting env. episode reward total was 3.0. running mean: 4.128850451483666\n",
      "resetting env. episode reward total was 15.0. running mean: 4.23756194696883\n",
      "resetting env. episode reward total was 1.0. running mean: 4.205186327499141\n",
      "resetting env. episode reward total was 7.0. running mean: 4.2331344642241495\n",
      "resetting env. episode reward total was 1.0. running mean: 4.2008031195819076\n",
      "resetting env. episode reward total was 14.0. running mean: 4.298795088386088\n",
      "resetting env. episode reward total was 5.0. running mean: 4.305807137502227\n",
      "resetting env. episode reward total was 8.0. running mean: 4.342749066127205\n",
      "resetting env. episode reward total was 7.0. running mean: 4.369321575465933\n",
      "resetting env. episode reward total was 2.0. running mean: 4.345628359711273\n",
      "resetting env. episode reward total was 11.0. running mean: 4.41217207611416\n",
      "resetting env. episode reward total was -5.0. running mean: 4.3180503553530185\n",
      "resetting env. episode reward total was 8.0. running mean: 4.354869851799489\n",
      "resetting env. episode reward total was -4.0. running mean: 4.271321153281494\n",
      "resetting env. episode reward total was 9.0. running mean: 4.318607941748678\n",
      "resetting env. episode reward total was -2.0. running mean: 4.2554218623311915\n",
      "resetting env. episode reward total was 12.0. running mean: 4.332867643707879\n",
      "resetting env. episode reward total was 11.0. running mean: 4.399538967270801\n",
      "resetting env. episode reward total was 8.0. running mean: 4.435543577598093\n",
      "resetting env. episode reward total was -1.0. running mean: 4.381188141822112\n",
      "resetting env. episode reward total was -4.0. running mean: 4.297376260403891\n",
      "resetting env. episode reward total was -6.0. running mean: 4.194402497799853\n",
      "resetting env. episode reward total was 11.0. running mean: 4.262458472821855\n",
      "resetting env. episode reward total was 11.0. running mean: 4.329833888093637\n",
      "resetting env. episode reward total was 6.0. running mean: 4.3465355492127\n",
      "resetting env. episode reward total was -11.0. running mean: 4.1930701937205725\n",
      "resetting env. episode reward total was 4.0. running mean: 4.191139491783367\n",
      "resetting env. episode reward total was 6.0. running mean: 4.209228096865533\n",
      "resetting env. episode reward total was 8.0. running mean: 4.247135815896877\n",
      "resetting env. episode reward total was -5.0. running mean: 4.154664457737908\n",
      "resetting env. episode reward total was 7.0. running mean: 4.183117813160529\n",
      "resetting env. episode reward total was -4.0. running mean: 4.101286635028924\n",
      "resetting env. episode reward total was -5.0. running mean: 4.010273768678634\n",
      "resetting env. episode reward total was 2.0. running mean: 3.990171030991848\n",
      "resetting env. episode reward total was 4.0. running mean: 3.9902693206819295\n",
      "resetting env. episode reward total was 6.0. running mean: 4.01036662747511\n",
      "resetting env. episode reward total was -2.0. running mean: 3.9502629612003592\n",
      "resetting env. episode reward total was -1.0. running mean: 3.900760331588356\n",
      "resetting env. episode reward total was -3.0. running mean: 3.8317527282724724\n",
      "resetting env. episode reward total was 5.0. running mean: 3.8434352009897474\n",
      "resetting env. episode reward total was 7.0. running mean: 3.87500084897985\n",
      "resetting env. episode reward total was -1.0. running mean: 3.8262508404900517\n",
      "resetting env. episode reward total was 3.0. running mean: 3.817988332085151\n",
      "resetting env. episode reward total was 3.0. running mean: 3.8098084487642994\n",
      "resetting env. episode reward total was 6.0. running mean: 3.8317103642766566\n",
      "resetting env. episode reward total was -3.0. running mean: 3.7633932606338902\n",
      "resetting env. episode reward total was 10.0. running mean: 3.8257593280275515\n",
      "resetting env. episode reward total was -6.0. running mean: 3.727501734747276\n",
      "resetting env. episode reward total was 7.0. running mean: 3.760226717399803\n",
      "resetting env. episode reward total was 7.0. running mean: 3.7926244502258046\n",
      "resetting env. episode reward total was -1.0. running mean: 3.7446982057235467\n",
      "resetting env. episode reward total was -5.0. running mean: 3.6572512236663113\n",
      "resetting env. episode reward total was 8.0. running mean: 3.700678711429648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: 3.673671924315351\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6969352050721977\n",
      "resetting env. episode reward total was 6.0. running mean: 3.719965853021476\n",
      "resetting env. episode reward total was -5.0. running mean: 3.632766194491261\n",
      "resetting env. episode reward total was -1.0. running mean: 3.5864385325463486\n",
      "resetting env. episode reward total was -7.0. running mean: 3.480574147220885\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5257684057486762\n",
      "resetting env. episode reward total was 12.0. running mean: 3.6105107216911896\n",
      "resetting env. episode reward total was 8.0. running mean: 3.654405614474278\n",
      "resetting env. episode reward total was 5.0. running mean: 3.667861558329535\n",
      "resetting env. episode reward total was 5.0. running mean: 3.6811829427462395\n",
      "resetting env. episode reward total was 4.0. running mean: 3.684371113318777\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7075274021855895\n",
      "resetting env. episode reward total was -7.0. running mean: 3.6004521281637336\n",
      "resetting env. episode reward total was 13.0. running mean: 3.694447606882096\n",
      "resetting env. episode reward total was 7.0. running mean: 3.727503130813275\n",
      "resetting env. episode reward total was -5.0. running mean: 3.6402280995051424\n",
      "resetting env. episode reward total was -3.0. running mean: 3.573825818510091\n",
      "resetting env. episode reward total was 2.0. running mean: 3.55808756032499\n",
      "resetting env. episode reward total was -7.0. running mean: 3.4525066847217403\n",
      "resetting env. episode reward total was 7.0. running mean: 3.4879816178745227\n",
      "resetting env. episode reward total was 3.0. running mean: 3.4831018016957773\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4882707836788196\n",
      "resetting env. episode reward total was 12.0. running mean: 3.5733880758420313\n",
      "resetting env. episode reward total was -6.0. running mean: 3.477654195083611\n",
      "resetting env. episode reward total was 10.0. running mean: 3.542877653132775\n",
      "resetting env. episode reward total was 4.0. running mean: 3.547448876601447\n",
      "resetting env. episode reward total was 11.0. running mean: 3.6219743878354325\n",
      "resetting env. episode reward total was 10.0. running mean: 3.685754643957078\n",
      "resetting env. episode reward total was 1.0. running mean: 3.658897097517507\n",
      "resetting env. episode reward total was 3.0. running mean: 3.652308126542332\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6857850452769085\n",
      "resetting env. episode reward total was 5.0. running mean: 3.6989271948241393\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7119379228758977\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7248185436471384\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6975703582106667\n",
      "resetting env. episode reward total was 2.0. running mean: 3.68059465462856\n",
      "resetting env. episode reward total was 10.0. running mean: 3.7437887080822745\n",
      "resetting env. episode reward total was 14.0. running mean: 3.846350821001452\n",
      "resetting env. episode reward total was 5.0. running mean: 3.857887312791437\n",
      "resetting env. episode reward total was 4.0. running mean: 3.859308439663523\n",
      "resetting env. episode reward total was 11.0. running mean: 3.9307153552668876\n",
      "resetting env. episode reward total was 13.0. running mean: 4.021408201714219\n",
      "resetting env. episode reward total was 15.0. running mean: 4.131194119697077\n",
      "resetting env. episode reward total was 5.0. running mean: 4.139882178500106\n",
      "resetting env. episode reward total was 4.0. running mean: 4.138483356715105\n",
      "resetting env. episode reward total was 10.0. running mean: 4.197098523147954\n",
      "resetting env. episode reward total was -7.0. running mean: 4.085127537916474\n",
      "resetting env. episode reward total was 4.0. running mean: 4.084276262537309\n",
      "resetting env. episode reward total was 9.0. running mean: 4.133433499911936\n",
      "resetting env. episode reward total was 2.0. running mean: 4.1120991649128165\n",
      "resetting env. episode reward total was 12.0. running mean: 4.190978173263688\n",
      "resetting env. episode reward total was 5.0. running mean: 4.199068391531051\n",
      "resetting env. episode reward total was -13.0. running mean: 4.0270777076157405\n",
      "resetting env. episode reward total was 8.0. running mean: 4.066806930539583\n",
      "resetting env. episode reward total was 6.0. running mean: 4.086138861234186\n",
      "resetting env. episode reward total was 6.0. running mean: 4.105277472621844\n",
      "resetting env. episode reward total was -1.0. running mean: 4.054224697895625\n",
      "resetting env. episode reward total was 5.0. running mean: 4.0636824509166685\n",
      "resetting env. episode reward total was 14.0. running mean: 4.163045626407501\n",
      "resetting env. episode reward total was 7.0. running mean: 4.191415170143427\n",
      "resetting env. episode reward total was 7.0. running mean: 4.219501018441993\n",
      "resetting env. episode reward total was 7.0. running mean: 4.247306008257573\n",
      "resetting env. episode reward total was 12.0. running mean: 4.324832948174998\n",
      "resetting env. episode reward total was 8.0. running mean: 4.361584618693248\n",
      "resetting env. episode reward total was 1.0. running mean: 4.327968772506315\n",
      "resetting env. episode reward total was -2.0. running mean: 4.264689084781252\n",
      "resetting env. episode reward total was 13.0. running mean: 4.352042193933439\n",
      "resetting env. episode reward total was 6.0. running mean: 4.3685217719941045\n",
      "resetting env. episode reward total was 6.0. running mean: 4.384836554274163\n",
      "resetting env. episode reward total was 6.0. running mean: 4.4009881887314215\n",
      "resetting env. episode reward total was 6.0. running mean: 4.416978306844107\n",
      "resetting env. episode reward total was 6.0. running mean: 4.432808523775665\n",
      "resetting env. episode reward total was 9.0. running mean: 4.4784804385379084\n",
      "resetting env. episode reward total was -13.0. running mean: 4.30369563415253\n",
      "resetting env. episode reward total was 4.0. running mean: 4.300658677811005\n",
      "resetting env. episode reward total was 5.0. running mean: 4.307652091032895\n",
      "resetting env. episode reward total was 5.0. running mean: 4.314575570122566\n",
      "resetting env. episode reward total was -3.0. running mean: 4.241429814421339\n",
      "resetting env. episode reward total was 8.0. running mean: 4.279015516277126\n",
      "resetting env. episode reward total was 7.0. running mean: 4.306225361114355\n",
      "resetting env. episode reward total was -7.0. running mean: 4.193163107503211\n",
      "resetting env. episode reward total was 2.0. running mean: 4.171231476428178\n",
      "resetting env. episode reward total was 3.0. running mean: 4.159519161663897\n",
      "resetting env. episode reward total was -1.0. running mean: 4.107923970047258\n",
      "resetting env. episode reward total was 2.0. running mean: 4.086844730346785\n",
      "resetting env. episode reward total was 12.0. running mean: 4.165976283043317\n",
      "resetting env. episode reward total was -7.0. running mean: 4.0543165202128835\n",
      "resetting env. episode reward total was 6.0. running mean: 4.073773355010754\n",
      "resetting env. episode reward total was 13.0. running mean: 4.163035621460646\n",
      "resetting env. episode reward total was 10.0. running mean: 4.221405265246039\n",
      "resetting env. episode reward total was 10.0. running mean: 4.279191212593578\n",
      "resetting env. episode reward total was 10.0. running mean: 4.336399300467642\n",
      "resetting env. episode reward total was 7.0. running mean: 4.363035307462966\n",
      "resetting env. episode reward total was -8.0. running mean: 4.239404954388337\n",
      "resetting env. episode reward total was 8.0. running mean: 4.277010904844453\n",
      "resetting env. episode reward total was 8.0. running mean: 4.3142407957960085\n",
      "resetting env. episode reward total was 12.0. running mean: 4.391098387838048\n",
      "resetting env. episode reward total was -2.0. running mean: 4.327187403959668\n",
      "resetting env. episode reward total was 8.0. running mean: 4.363915529920071\n",
      "resetting env. episode reward total was 7.0. running mean: 4.39027637462087\n",
      "resetting env. episode reward total was -9.0. running mean: 4.256373610874662\n",
      "resetting env. episode reward total was -2.0. running mean: 4.193809874765916\n",
      "resetting env. episode reward total was 5.0. running mean: 4.2018717760182565\n",
      "resetting env. episode reward total was -7.0. running mean: 4.089853058258074\n",
      "resetting env. episode reward total was 11.0. running mean: 4.158954527675493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: 4.047364982398737\n",
      "resetting env. episode reward total was 9.0. running mean: 4.09689133257475\n",
      "resetting env. episode reward total was 4.0. running mean: 4.0959224192490025\n",
      "resetting env. episode reward total was -1.0. running mean: 4.044963195056512\n",
      "resetting env. episode reward total was 8.0. running mean: 4.084513563105947\n",
      "resetting env. episode reward total was 8.0. running mean: 4.123668427474888\n",
      "resetting env. episode reward total was 7.0. running mean: 4.152431743200139\n",
      "resetting env. episode reward total was 5.0. running mean: 4.160907425768137\n",
      "resetting env. episode reward total was 5.0. running mean: 4.169298351510456\n",
      "resetting env. episode reward total was 11.0. running mean: 4.237605367995352\n",
      "resetting env. episode reward total was 8.0. running mean: 4.275229314315398\n",
      "resetting env. episode reward total was 10.0. running mean: 4.332477021172243\n",
      "resetting env. episode reward total was 10.0. running mean: 4.389152250960521\n",
      "resetting env. episode reward total was 5.0. running mean: 4.395260728450916\n",
      "resetting env. episode reward total was 1.0. running mean: 4.361308121166407\n",
      "resetting env. episode reward total was 7.0. running mean: 4.387695039954743\n",
      "resetting env. episode reward total was 7.0. running mean: 4.413818089555196\n",
      "resetting env. episode reward total was 6.0. running mean: 4.429679908659644\n",
      "resetting env. episode reward total was 11.0. running mean: 4.495383109573048\n",
      "resetting env. episode reward total was 2.0. running mean: 4.470429278477317\n",
      "resetting env. episode reward total was 8.0. running mean: 4.505724985692543\n",
      "resetting env. episode reward total was 4.0. running mean: 4.500667735835618\n",
      "resetting env. episode reward total was 5.0. running mean: 4.505661058477262\n",
      "resetting env. episode reward total was 8.0. running mean: 4.540604447892489\n",
      "resetting env. episode reward total was -3.0. running mean: 4.465198403413564\n",
      "resetting env. episode reward total was 6.0. running mean: 4.4805464193794275\n",
      "resetting env. episode reward total was 14.0. running mean: 4.5757409551856325\n",
      "resetting env. episode reward total was 1.0. running mean: 4.539983545633776\n",
      "resetting env. episode reward total was -5.0. running mean: 4.444583710177438\n",
      "resetting env. episode reward total was -5.0. running mean: 4.350137873075664\n",
      "resetting env. episode reward total was 2.0. running mean: 4.326636494344907\n",
      "resetting env. episode reward total was 6.0. running mean: 4.343370129401458\n",
      "resetting env. episode reward total was 5.0. running mean: 4.349936428107443\n",
      "resetting env. episode reward total was -1.0. running mean: 4.296437063826369\n",
      "resetting env. episode reward total was -11.0. running mean: 4.143472693188105\n",
      "resetting env. episode reward total was 5.0. running mean: 4.152037966256224\n",
      "resetting env. episode reward total was 6.0. running mean: 4.170517586593662\n",
      "resetting env. episode reward total was 4.0. running mean: 4.168812410727726\n",
      "resetting env. episode reward total was 6.0. running mean: 4.187124286620448\n",
      "resetting env. episode reward total was -3.0. running mean: 4.115253043754243\n",
      "resetting env. episode reward total was 11.0. running mean: 4.184100513316701\n",
      "resetting env. episode reward total was 13.0. running mean: 4.2722595081835335\n",
      "resetting env. episode reward total was 5.0. running mean: 4.279536913101698\n",
      "resetting env. episode reward total was 7.0. running mean: 4.306741543970681\n",
      "resetting env. episode reward total was 2.0. running mean: 4.283674128530973\n",
      "resetting env. episode reward total was -1.0. running mean: 4.230837387245663\n",
      "resetting env. episode reward total was -5.0. running mean: 4.138529013373207\n",
      "resetting env. episode reward total was 9.0. running mean: 4.187143723239474\n",
      "resetting env. episode reward total was -9.0. running mean: 4.05527228600708\n",
      "resetting env. episode reward total was 7.0. running mean: 4.084719563147009\n",
      "resetting env. episode reward total was -2.0. running mean: 4.023872367515539\n",
      "resetting env. episode reward total was -2.0. running mean: 3.9636336438403834\n",
      "resetting env. episode reward total was 1.0. running mean: 3.933997307401979\n",
      "resetting env. episode reward total was -1.0. running mean: 3.8846573343279593\n",
      "resetting env. episode reward total was -6.0. running mean: 3.78581076098468\n",
      "resetting env. episode reward total was 14.0. running mean: 3.887952653374833\n",
      "resetting env. episode reward total was 7.0. running mean: 3.9190731268410848\n",
      "resetting env. episode reward total was 6.0. running mean: 3.939882395572674\n",
      "resetting env. episode reward total was -2.0. running mean: 3.8804835716169475\n",
      "resetting env. episode reward total was 6.0. running mean: 3.901678735900778\n",
      "resetting env. episode reward total was 2.0. running mean: 3.88266194854177\n",
      "resetting env. episode reward total was 9.0. running mean: 3.933835329056352\n",
      "resetting env. episode reward total was -2.0. running mean: 3.8744969757657888\n",
      "resetting env. episode reward total was 6.0. running mean: 3.8957520060081308\n",
      "resetting env. episode reward total was 9.0. running mean: 3.9467944859480495\n",
      "resetting env. episode reward total was 11.0. running mean: 4.017326541088569\n",
      "resetting env. episode reward total was 11.0. running mean: 4.087153275677683\n",
      "resetting env. episode reward total was -4.0. running mean: 4.0062817429209066\n",
      "resetting env. episode reward total was 2.0. running mean: 3.9862189254916975\n",
      "resetting env. episode reward total was 7.0. running mean: 4.016356736236781\n",
      "resetting env. episode reward total was 5.0. running mean: 4.026193168874413\n",
      "resetting env. episode reward total was 7.0. running mean: 4.0559312371856695\n",
      "resetting env. episode reward total was 12.0. running mean: 4.135371924813813\n",
      "resetting env. episode reward total was 2.0. running mean: 4.114018205565674\n",
      "resetting env. episode reward total was 9.0. running mean: 4.162878023510017\n",
      "resetting env. episode reward total was -6.0. running mean: 4.061249243274918\n",
      "resetting env. episode reward total was -3.0. running mean: 3.9906367508421687\n",
      "resetting env. episode reward total was 14.0. running mean: 4.090730383333747\n",
      "resetting env. episode reward total was -7.0. running mean: 3.979823079500409\n",
      "resetting env. episode reward total was -2.0. running mean: 3.920024848705405\n",
      "resetting env. episode reward total was 4.0. running mean: 3.9208246002183507\n",
      "resetting env. episode reward total was 8.0. running mean: 3.9616163542161673\n",
      "resetting env. episode reward total was 5.0. running mean: 3.9720001906740054\n",
      "resetting env. episode reward total was 6.0. running mean: 3.9922801887672654\n",
      "resetting env. episode reward total was 8.0. running mean: 4.0323573868795926\n",
      "resetting env. episode reward total was 6.0. running mean: 4.052033813010796\n",
      "resetting env. episode reward total was -6.0. running mean: 3.9515134748806884\n",
      "resetting env. episode reward total was 3.0. running mean: 3.941998340131881\n",
      "resetting env. episode reward total was 5.0. running mean: 3.9525783567305623\n",
      "resetting env. episode reward total was -1.0. running mean: 3.903052573163257\n",
      "resetting env. episode reward total was 1.0. running mean: 3.874022047431624\n",
      "resetting env. episode reward total was 7.0. running mean: 3.9052818269573075\n",
      "resetting env. episode reward total was 4.0. running mean: 3.9062290086877343\n",
      "resetting env. episode reward total was 5.0. running mean: 3.9171667186008565\n",
      "resetting env. episode reward total was -1.0. running mean: 3.867995051414848\n",
      "resetting env. episode reward total was 10.0. running mean: 3.9293151009006997\n",
      "resetting env. episode reward total was 5.0. running mean: 3.9400219498916926\n",
      "resetting env. episode reward total was -4.0. running mean: 3.8606217303927757\n",
      "resetting env. episode reward total was 8.0. running mean: 3.902015513088848\n",
      "resetting env. episode reward total was 11.0. running mean: 3.9729953579579593\n",
      "resetting env. episode reward total was 8.0. running mean: 4.013265404378379\n",
      "resetting env. episode reward total was 1.0. running mean: 3.9831327503345952\n",
      "resetting env. episode reward total was -1.0. running mean: 3.9333014228312493\n",
      "resetting env. episode reward total was 1.0. running mean: 3.9039684086029367\n",
      "resetting env. episode reward total was -6.0. running mean: 3.8049287245169072\n",
      "resetting env. episode reward total was 10.0. running mean: 3.8668794372717383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: 3.928210642899021\n",
      "resetting env. episode reward total was -1.0. running mean: 3.878928536470031\n",
      "resetting env. episode reward total was 9.0. running mean: 3.930139251105331\n",
      "resetting env. episode reward total was -12.0. running mean: 3.7708378585942772\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7931294800083344\n",
      "resetting env. episode reward total was 8.0. running mean: 3.835198185208251\n",
      "resetting env. episode reward total was 10.0. running mean: 3.896846203356169\n",
      "resetting env. episode reward total was -1.0. running mean: 3.8478777413226073\n",
      "resetting env. episode reward total was 9.0. running mean: 3.899398963909381\n",
      "resetting env. episode reward total was 8.0. running mean: 3.940404974270287\n",
      "resetting env. episode reward total was 11.0. running mean: 4.011000924527584\n",
      "resetting env. episode reward total was 5.0. running mean: 4.020890915282308\n",
      "resetting env. episode reward total was 6.0. running mean: 4.040682006129485\n",
      "resetting env. episode reward total was 1.0. running mean: 4.010275186068189\n",
      "resetting env. episode reward total was 4.0. running mean: 4.010172434207507\n",
      "resetting env. episode reward total was 8.0. running mean: 4.050070709865432\n",
      "resetting env. episode reward total was 5.0. running mean: 4.059570002766778\n",
      "resetting env. episode reward total was 9.0. running mean: 4.10897430273911\n",
      "resetting env. episode reward total was -3.0. running mean: 4.037884559711719\n",
      "resetting env. episode reward total was 12.0. running mean: 4.117505714114602\n",
      "resetting env. episode reward total was -2.0. running mean: 4.056330656973456\n",
      "resetting env. episode reward total was 2.0. running mean: 4.035767350403721\n",
      "resetting env. episode reward total was 11.0. running mean: 4.105409676899684\n",
      "resetting env. episode reward total was 3.0. running mean: 4.094355580130687\n",
      "resetting env. episode reward total was 8.0. running mean: 4.13341202432938\n",
      "resetting env. episode reward total was 2.0. running mean: 4.112077904086086\n",
      "resetting env. episode reward total was -1.0. running mean: 4.060957125045226\n",
      "resetting env. episode reward total was 9.0. running mean: 4.110347553794774\n",
      "resetting env. episode reward total was 1.0. running mean: 4.079244078256826\n",
      "resetting env. episode reward total was -15.0. running mean: 3.8884516374742577\n",
      "resetting env. episode reward total was -4.0. running mean: 3.8095671210995152\n",
      "resetting env. episode reward total was -5.0. running mean: 3.7214714498885204\n",
      "resetting env. episode reward total was -12.0. running mean: 3.5642567353896353\n",
      "resetting env. episode reward total was 1.0. running mean: 3.5386141680357386\n",
      "resetting env. episode reward total was 2.0. running mean: 3.523228026355381\n",
      "resetting env. episode reward total was 1.0. running mean: 3.497995746091827\n",
      "resetting env. episode reward total was 9.0. running mean: 3.5530157886309084\n",
      "resetting env. episode reward total was 13.0. running mean: 3.6474856307445993\n",
      "resetting env. episode reward total was 10.0. running mean: 3.7110107744371534\n",
      "resetting env. episode reward total was -5.0. running mean: 3.623900666692782\n",
      "resetting env. episode reward total was 1.0. running mean: 3.597661660025854\n",
      "resetting env. episode reward total was 3.0. running mean: 3.591685043425595\n",
      "resetting env. episode reward total was 7.0. running mean: 3.625768192991339\n",
      "resetting env. episode reward total was 8.0. running mean: 3.6695105110614255\n",
      "resetting env. episode reward total was 8.0. running mean: 3.712815405950811\n",
      "resetting env. episode reward total was 10.0. running mean: 3.775687251891303\n",
      "resetting env. episode reward total was 4.0. running mean: 3.77793037937239\n",
      "resetting env. episode reward total was 4.0. running mean: 3.780151075578666\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7823495648228795\n",
      "resetting env. episode reward total was -6.0. running mean: 3.684526069174651\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6576808084829042\n",
      "resetting env. episode reward total was -3.0. running mean: 3.5911040003980754\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6251929603940947\n",
      "resetting env. episode reward total was -3.0. running mean: 3.558941030790154\n",
      "resetting env. episode reward total was -1.0. running mean: 3.5133516204822524\n",
      "resetting env. episode reward total was -7.0. running mean: 3.40821810427743\n",
      "resetting env. episode reward total was -1.0. running mean: 3.364135923234656\n",
      "resetting env. episode reward total was -7.0. running mean: 3.2604945640023093\n",
      "resetting env. episode reward total was 6.0. running mean: 3.287889618362286\n",
      "resetting env. episode reward total was 1.0. running mean: 3.265010722178663\n",
      "resetting env. episode reward total was 9.0. running mean: 3.322360614956876\n",
      "resetting env. episode reward total was -9.0. running mean: 3.1991370088073072\n",
      "resetting env. episode reward total was 14.0. running mean: 3.307145638719234\n",
      "resetting env. episode reward total was 8.0. running mean: 3.3540741823320417\n",
      "resetting env. episode reward total was -7.0. running mean: 3.2505334405087214\n",
      "resetting env. episode reward total was 2.0. running mean: 3.2380281061036342\n",
      "resetting env. episode reward total was -2.0. running mean: 3.1856478250425977\n",
      "resetting env. episode reward total was 6.0. running mean: 3.213791346792172\n",
      "resetting env. episode reward total was 6.0. running mean: 3.24165343332425\n",
      "resetting env. episode reward total was 2.0. running mean: 3.2292368989910076\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2469445300010973\n",
      "resetting env. episode reward total was 3.0. running mean: 3.244475084701086\n",
      "resetting env. episode reward total was 11.0. running mean: 3.3220303338540753\n",
      "resetting env. episode reward total was 7.0. running mean: 3.358810030515534\n",
      "resetting env. episode reward total was 14.0. running mean: 3.465221930210379\n",
      "resetting env. episode reward total was 10.0. running mean: 3.530569710908275\n",
      "resetting env. episode reward total was -1.0. running mean: 3.485264013799193\n",
      "resetting env. episode reward total was -6.0. running mean: 3.390411373661201\n",
      "resetting env. episode reward total was 2.0. running mean: 3.376507259924589\n",
      "resetting env. episode reward total was 1.0. running mean: 3.352742187325343\n",
      "resetting env. episode reward total was -9.0. running mean: 3.2292147654520895\n",
      "resetting env. episode reward total was 11.0. running mean: 3.3069226177975684\n",
      "resetting env. episode reward total was 3.0. running mean: 3.3038533916195925\n",
      "resetting env. episode reward total was 4.0. running mean: 3.3108148577033965\n",
      "resetting env. episode reward total was 6.0. running mean: 3.3377067091263624\n",
      "resetting env. episode reward total was -1.0. running mean: 3.2943296420350987\n",
      "resetting env. episode reward total was 13.0. running mean: 3.3913863456147477\n",
      "resetting env. episode reward total was 8.0. running mean: 3.4374724821586002\n",
      "resetting env. episode reward total was 5.0. running mean: 3.453097757337014\n",
      "resetting env. episode reward total was 6.0. running mean: 3.478566779763644\n",
      "resetting env. episode reward total was 6.0. running mean: 3.5037811119660076\n",
      "resetting env. episode reward total was 10.0. running mean: 3.5687433008463474\n",
      "resetting env. episode reward total was 11.0. running mean: 3.6430558678378837\n",
      "resetting env. episode reward total was -7.0. running mean: 3.536625309159505\n",
      "resetting env. episode reward total was 5.0. running mean: 3.55125905606791\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6157464655072307\n",
      "resetting env. episode reward total was 12.0. running mean: 3.6995890008521584\n",
      "resetting env. episode reward total was -9.0. running mean: 3.572593110843637\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6068671797352003\n",
      "resetting env. episode reward total was 11.0. running mean: 3.680798507937848\n",
      "resetting env. episode reward total was 12.0. running mean: 3.7639905228584696\n",
      "resetting env. episode reward total was 6.0. running mean: 3.786350617629885\n",
      "resetting env. episode reward total was 7.0. running mean: 3.818487111453586\n",
      "resetting env. episode reward total was 11.0. running mean: 3.89030224033905\n",
      "resetting env. episode reward total was 13.0. running mean: 3.9813992179356594\n",
      "resetting env. episode reward total was 6.0. running mean: 4.001585225756303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 12.0. running mean: 4.0815693734987395\n",
      "resetting env. episode reward total was 5.0. running mean: 4.090753679763752\n",
      "resetting env. episode reward total was 3.0. running mean: 4.079846142966115\n",
      "resetting env. episode reward total was 12.0. running mean: 4.159047681536454\n",
      "resetting env. episode reward total was 6.0. running mean: 4.177457204721089\n",
      "resetting env. episode reward total was 5.0. running mean: 4.1856826326738785\n",
      "resetting env. episode reward total was 5.0. running mean: 4.19382580634714\n",
      "resetting env. episode reward total was 2.0. running mean: 4.171887548283668\n",
      "resetting env. episode reward total was 13.0. running mean: 4.260168672800831\n",
      "resetting env. episode reward total was 4.0. running mean: 4.257566986072823\n",
      "resetting env. episode reward total was 12.0. running mean: 4.334991316212095\n",
      "resetting env. episode reward total was 2.0. running mean: 4.311641403049974\n",
      "resetting env. episode reward total was 4.0. running mean: 4.308524989019474\n",
      "resetting env. episode reward total was -1.0. running mean: 4.2554397391292795\n",
      "resetting env. episode reward total was 4.0. running mean: 4.252885341737986\n",
      "resetting env. episode reward total was 6.0. running mean: 4.270356488320606\n",
      "resetting env. episode reward total was 12.0. running mean: 4.3476529234373995\n",
      "resetting env. episode reward total was 8.0. running mean: 4.384176394203026\n",
      "resetting env. episode reward total was 10.0. running mean: 4.440334630260995\n",
      "resetting env. episode reward total was 6.0. running mean: 4.455931283958385\n",
      "resetting env. episode reward total was 9.0. running mean: 4.501371971118801\n",
      "resetting env. episode reward total was 10.0. running mean: 4.556358251407612\n",
      "resetting env. episode reward total was 1.0. running mean: 4.520794668893536\n",
      "resetting env. episode reward total was 8.0. running mean: 4.5555867222046\n",
      "resetting env. episode reward total was 7.0. running mean: 4.580030854982554\n",
      "resetting env. episode reward total was 7.0. running mean: 4.604230546432729\n",
      "resetting env. episode reward total was 7.0. running mean: 4.628188240968401\n",
      "resetting env. episode reward total was -1.0. running mean: 4.571906358558717\n",
      "resetting env. episode reward total was -11.0. running mean: 4.416187294973129\n",
      "resetting env. episode reward total was 7.0. running mean: 4.442025422023399\n",
      "resetting env. episode reward total was 4.0. running mean: 4.437605167803165\n",
      "resetting env. episode reward total was 16.0. running mean: 4.5532291161251335\n",
      "resetting env. episode reward total was -1.0. running mean: 4.4976968249638825\n",
      "resetting env. episode reward total was -3.0. running mean: 4.422719856714243\n",
      "resetting env. episode reward total was -7.0. running mean: 4.308492658147101\n",
      "resetting env. episode reward total was 1.0. running mean: 4.275407731565629\n",
      "resetting env. episode reward total was 3.0. running mean: 4.262653654249973\n",
      "resetting env. episode reward total was 1.0. running mean: 4.230027117707473\n",
      "resetting env. episode reward total was 4.0. running mean: 4.227726846530398\n",
      "resetting env. episode reward total was 3.0. running mean: 4.215449578065095\n",
      "resetting env. episode reward total was -8.0. running mean: 4.093295082284444\n",
      "resetting env. episode reward total was 8.0. running mean: 4.1323621314615995\n",
      "resetting env. episode reward total was -4.0. running mean: 4.0510385101469835\n",
      "resetting env. episode reward total was 1.0. running mean: 4.020528125045513\n",
      "resetting env. episode reward total was 9.0. running mean: 4.070322843795058\n",
      "resetting env. episode reward total was -4.0. running mean: 3.989619615357107\n",
      "resetting env. episode reward total was 7.0. running mean: 4.019723419203536\n",
      "resetting env. episode reward total was 4.0. running mean: 4.0195261850115\n",
      "resetting env. episode reward total was -1.0. running mean: 3.9693309231613854\n",
      "resetting env. episode reward total was 3.0. running mean: 3.9596376139297713\n",
      "resetting env. episode reward total was 11.0. running mean: 4.030041237790473\n",
      "resetting env. episode reward total was -3.0. running mean: 3.9597408254125686\n",
      "resetting env. episode reward total was -9.0. running mean: 3.830143417158443\n",
      "resetting env. episode reward total was -4.0. running mean: 3.7518419829868583\n",
      "resetting env. episode reward total was 14.0. running mean: 3.85432356315699\n",
      "resetting env. episode reward total was -8.0. running mean: 3.7357803275254198\n",
      "resetting env. episode reward total was -11.0. running mean: 3.5884225242501655\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5725382990076637\n",
      "resetting env. episode reward total was -11.0. running mean: 3.426812916017587\n",
      "resetting env. episode reward total was 9.0. running mean: 3.482544786857411\n",
      "resetting env. episode reward total was 7.0. running mean: 3.5177193389888366\n",
      "resetting env. episode reward total was -12.0. running mean: 3.362542145598948\n",
      "resetting env. episode reward total was -5.0. running mean: 3.2789167241429586\n",
      "resetting env. episode reward total was 16.0. running mean: 3.406127556901529\n",
      "resetting env. episode reward total was 6.0. running mean: 3.4320662813325136\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4377456185191884\n",
      "resetting env. episode reward total was 3.0. running mean: 3.433368162333996\n",
      "resetting env. episode reward total was -1.0. running mean: 3.3890344807106563\n",
      "resetting env. episode reward total was -7.0. running mean: 3.28514413590355\n",
      "resetting env. episode reward total was 5.0. running mean: 3.3022926945445144\n",
      "resetting env. episode reward total was 10.0. running mean: 3.3692697675990693\n",
      "resetting env. episode reward total was -2.0. running mean: 3.3155770699230787\n",
      "resetting env. episode reward total was 5.0. running mean: 3.3324212992238476\n",
      "resetting env. episode reward total was -3.0. running mean: 3.2690970862316093\n",
      "resetting env. episode reward total was 3.0. running mean: 3.266406115369293\n",
      "resetting env. episode reward total was 7.0. running mean: 3.3037420542156\n",
      "resetting env. episode reward total was -11.0. running mean: 3.1607046336734443\n",
      "resetting env. episode reward total was 3.0. running mean: 3.1590975873367095\n",
      "resetting env. episode reward total was -2.0. running mean: 3.1075066114633425\n",
      "resetting env. episode reward total was 1.0. running mean: 3.086431545348709\n",
      "resetting env. episode reward total was -6.0. running mean: 2.995567229895222\n",
      "resetting env. episode reward total was 9.0. running mean: 3.0556115575962695\n",
      "resetting env. episode reward total was -6.0. running mean: 2.9650554420203066\n",
      "resetting env. episode reward total was 9.0. running mean: 3.025404887600103\n",
      "resetting env. episode reward total was 7.0. running mean: 3.0651508387241018\n",
      "resetting env. episode reward total was 4.0. running mean: 3.074499330336861\n",
      "resetting env. episode reward total was 2.0. running mean: 3.063754337033492\n",
      "resetting env. episode reward total was -6.0. running mean: 2.973116793663157\n",
      "resetting env. episode reward total was 3.0. running mean: 2.973385625726525\n",
      "resetting env. episode reward total was 8.0. running mean: 3.02365176946926\n",
      "resetting env. episode reward total was -8.0. running mean: 2.913415251774567\n",
      "resetting env. episode reward total was 7.0. running mean: 2.9542810992568214\n",
      "resetting env. episode reward total was -1.0. running mean: 2.914738288264253\n",
      "resetting env. episode reward total was 3.0. running mean: 2.9155909053816105\n",
      "resetting env. episode reward total was 2.0. running mean: 2.9064349963277945\n",
      "resetting env. episode reward total was -13.0. running mean: 2.7473706463645167\n",
      "resetting env. episode reward total was -2.0. running mean: 2.6998969399008717\n",
      "resetting env. episode reward total was -5.0. running mean: 2.622897970501863\n",
      "resetting env. episode reward total was 5.0. running mean: 2.646668990796844\n",
      "resetting env. episode reward total was 1.0. running mean: 2.6302023008888753\n",
      "resetting env. episode reward total was -1.0. running mean: 2.5939002778799867\n",
      "resetting env. episode reward total was 9.0. running mean: 2.6579612751011865\n",
      "resetting env. episode reward total was -4.0. running mean: 2.5913816623501744\n",
      "resetting env. episode reward total was -8.0. running mean: 2.4854678457266726\n",
      "resetting env. episode reward total was -2.0. running mean: 2.440613167269406\n",
      "resetting env. episode reward total was 7.0. running mean: 2.4862070355967116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 2.5013449652407447\n",
      "resetting env. episode reward total was -1.0. running mean: 2.4663315155883376\n",
      "resetting env. episode reward total was 7.0. running mean: 2.511668200432454\n",
      "resetting env. episode reward total was -1.0. running mean: 2.4765515184281295\n",
      "resetting env. episode reward total was 5.0. running mean: 2.501786003243848\n",
      "resetting env. episode reward total was -5.0. running mean: 2.4267681432114094\n",
      "resetting env. episode reward total was -5.0. running mean: 2.3525004617792953\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3489754571615022\n",
      "resetting env. episode reward total was -6.0. running mean: 2.265485702589887\n",
      "resetting env. episode reward total was 4.0. running mean: 2.2828308455639883\n",
      "resetting env. episode reward total was -4.0. running mean: 2.2200025371083485\n",
      "resetting env. episode reward total was -3.0. running mean: 2.167802511737265\n",
      "resetting env. episode reward total was 7.0. running mean: 2.216124486619892\n",
      "resetting env. episode reward total was -5.0. running mean: 2.1439632417536933\n",
      "resetting env. episode reward total was -4.0. running mean: 2.0825236093361563\n",
      "resetting env. episode reward total was 12.0. running mean: 2.181698373242795\n",
      "resetting env. episode reward total was -11.0. running mean: 2.049881389510367\n",
      "resetting env. episode reward total was -9.0. running mean: 1.9393825756152634\n",
      "resetting env. episode reward total was -9.0. running mean: 1.8299887498591108\n",
      "resetting env. episode reward total was -10.0. running mean: 1.7116888623605195\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6745719737369142\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7178262539995452\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7506479914595499\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7631415115449545\n",
      "resetting env. episode reward total was 7.0. running mean: 1.815510096429505\n",
      "resetting env. episode reward total was 5.0. running mean: 1.84735499546521\n",
      "resetting env. episode reward total was -13.0. running mean: 1.6988814455105579\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7018926310554523\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6748737047448978\n",
      "resetting env. episode reward total was 12.0. running mean: 1.7781249676974489\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7403437180204744\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7729402808402697\n",
      "resetting env. episode reward total was 11.0. running mean: 1.865210878031867\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8165587692515484\n",
      "resetting env. episode reward total was -7.0. running mean: 1.7283931815590328\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7411092497434424\n",
      "resetting env. episode reward total was -3.0. running mean: 1.693698157246008\n",
      "resetting env. episode reward total was -10.0. running mean: 1.5767611756735478\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5209935639168122\n",
      "resetting env. episode reward total was -4.0. running mean: 1.465783628277644\n",
      "resetting env. episode reward total was 5.0. running mean: 1.5011257919948675\n",
      "resetting env. episode reward total was -2.0. running mean: 1.4661145340749189\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4614533887341696\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4868388548468279\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4619704662983595\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5273507616353759\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5320772540190222\n",
      "resetting env. episode reward total was 1.0. running mean: 1.526756481478832\n",
      "resetting env. episode reward total was -10.0. running mean: 1.4114889166640434\n",
      "resetting env. episode reward total was 2.0. running mean: 1.417374027497403\n",
      "resetting env. episode reward total was -3.0. running mean: 1.373200287222429\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4194682843502047\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3952736015067027\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4613208654916356\n",
      "resetting env. episode reward total was -8.0. running mean: 1.3667076568367191\n",
      "resetting env. episode reward total was -7.0. running mean: 1.2830405802683518\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2902101744656682\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3773080727210116\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3435349919938016\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3500996420738636\n",
      "resetting env. episode reward total was 5.0. running mean: 1.386598645653125\n",
      "resetting env. episode reward total was -5.0. running mean: 1.3227326591965936\n",
      "resetting env. episode reward total was -4.0. running mean: 1.2695053326046275\n",
      "resetting env. episode reward total was 9.0. running mean: 1.3468102792785812\n",
      "resetting env. episode reward total was -8.0. running mean: 1.2533421764857953\n",
      "resetting env. episode reward total was -7.0. running mean: 1.1708087547209372\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1991006671737279\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2371096605019907\n",
      "resetting env. episode reward total was 7.0. running mean: 1.2947385638969708\n",
      "resetting env. episode reward total was -2.0. running mean: 1.2617911782580011\n",
      "resetting env. episode reward total was 12.0. running mean: 1.3691732664754213\n",
      "resetting env. episode reward total was 10.0. running mean: 1.455481533810667\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4309267184725603\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4866174512878347\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5117512767749564\n",
      "resetting env. episode reward total was -5.0. running mean: 1.4466337640072067\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4221674263671347\n",
      "resetting env. episode reward total was -17.0. running mean: 1.2379457521034634\n",
      "resetting env. episode reward total was 1.0. running mean: 1.2355662945824286\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2732106316366043\n",
      "resetting env. episode reward total was -8.0. running mean: 1.1804785253202381\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1586737400670357\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1370870026663653\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2157161326397017\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2235589713133046\n",
      "resetting env. episode reward total was -9.0. running mean: 1.1213233816001715\n",
      "resetting env. episode reward total was 3.0. running mean: 1.1401101477841697\n",
      "resetting env. episode reward total was -11.0. running mean: 1.018709046306328\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0485219558432648\n",
      "resetting env. episode reward total was 6.0. running mean: 1.0980367362848322\n",
      "resetting env. episode reward total was -2.0. running mean: 1.0670563689219839\n",
      "resetting env. episode reward total was -3.0. running mean: 1.026385805232764\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9661219471804363\n",
      "resetting env. episode reward total was 1.0. running mean: 0.966460727708632\n",
      "resetting env. episode reward total was -3.0. running mean: 0.9267961204315457\n",
      "resetting env. episode reward total was 4.0. running mean: 0.9575281592272302\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8979528776349579\n",
      "resetting env. episode reward total was -5.0. running mean: 0.8389733488586083\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9305836153700222\n",
      "resetting env. episode reward total was 1.0. running mean: 0.931277779216322\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9119650014241588\n",
      "resetting env. episode reward total was 19.0. running mean: 1.0928453514099172\n",
      "resetting env. episode reward total was 8.0. running mean: 1.161916897895818\n",
      "resetting env. episode reward total was -2.0. running mean: 1.1302977289168599\n",
      "resetting env. episode reward total was 3.0. running mean: 1.1489947516276913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -6.0. running mean: 1.0775048041114144\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0867297560703002\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0958624585095973\n",
      "resetting env. episode reward total was 3.0. running mean: 1.1149038339245014\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0737547955852564\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9930172476294039\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9930870751531099\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0331562044015787\n",
      "resetting env. episode reward total was -3.0. running mean: 0.9928246423575628\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0128963959339872\n",
      "resetting env. episode reward total was 8.0. running mean: 1.0827674319746474\n",
      "resetting env. episode reward total was -5.0. running mean: 1.021939757654901\n",
      "resetting env. episode reward total was -2.0. running mean: 0.991720360078352\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9618031564775684\n",
      "resetting env. episode reward total was 14.0. running mean: 1.0921851249127927\n",
      "resetting env. episode reward total was 5.0. running mean: 1.1312632736636647\n",
      "resetting env. episode reward total was -2.0. running mean: 1.099950640927028\n",
      "resetting env. episode reward total was 14.0. running mean: 1.2289511345177577\n",
      "resetting env. episode reward total was 11.0. running mean: 1.3266616231725803\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2633950069408544\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3107610568714458\n",
      "resetting env. episode reward total was -14.0. running mean: 1.1576534463027315\n",
      "resetting env. episode reward total was -1.0. running mean: 1.136076911839704\n",
      "resetting env. episode reward total was 6.0. running mean: 1.184716142721307\n",
      "resetting env. episode reward total was 1.0. running mean: 1.182868981294094\n",
      "resetting env. episode reward total was 7.0. running mean: 1.2410402914811531\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2886298885663416\n",
      "resetting env. episode reward total was -3.0. running mean: 1.245743589680678\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3032861537838714\n",
      "resetting env. episode reward total was 9.0. running mean: 1.3802532922460327\n",
      "resetting env. episode reward total was 6.0. running mean: 1.4264507593235725\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4621862517303368\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3775643892130334\n",
      "resetting env. episode reward total was 6.0. running mean: 1.423788745320903\n",
      "resetting env. episode reward total was 4.0. running mean: 1.449550857867694\n",
      "resetting env. episode reward total was 4.0. running mean: 1.4750553492890173\n",
      "resetting env. episode reward total was -6.0. running mean: 1.400304795796127\n",
      "resetting env. episode reward total was -8.0. running mean: 1.3063017478381656\n",
      "resetting env. episode reward total was 12.0. running mean: 1.413238730359784\n",
      "resetting env. episode reward total was 1.0. running mean: 1.409106343056186\n",
      "resetting env. episode reward total was 10.0. running mean: 1.4950152796256244\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5500651268293681\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5145644755610745\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4894188308054637\n",
      "resetting env. episode reward total was -8.0. running mean: 1.394524642497409\n",
      "resetting env. episode reward total was 6.0. running mean: 1.440579396072435\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3561736021117106\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2926118660905934\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2996857474296875\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3566888899553906\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2931220010558366\n",
      "resetting env. episode reward total was -8.0. running mean: 1.200190781045278\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2081888732348254\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2161069845024772\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2339459146574525\n",
      "resetting env. episode reward total was -3.0. running mean: 1.1916064555108778\n",
      "resetting env. episode reward total was 16.0. running mean: 1.339690390955769\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3862934870462114\n",
      "resetting env. episode reward total was -11.0. running mean: 1.262430552175749\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3198062466539917\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3766081841874518\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3728421023455772\n",
      "resetting env. episode reward total was 13.0. running mean: 1.4891136813221215\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5342225445089004\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5488803190638114\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5733915158731733\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5676576007144416\n",
      "resetting env. episode reward total was -7.0. running mean: 1.481981024707297\n",
      "resetting env. episode reward total was -11.0. running mean: 1.357161214460224\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2935896023156217\n",
      "resetting env. episode reward total was 11.0. running mean: 1.3906537062924655\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3967471692295408\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3527796975372453\n",
      "resetting env. episode reward total was 5.0. running mean: 1.3892519005618729\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4053593815562542\n",
      "resetting env. episode reward total was 9.0. running mean: 1.4813057877406917\n",
      "resetting env. episode reward total was 9.0. running mean: 1.556492729863285\n",
      "resetting env. episode reward total was 6.0. running mean: 1.600927802564652\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6849185245390057\n",
      "resetting env. episode reward total was 7.0. running mean: 1.7380693392936157\n",
      "resetting env. episode reward total was 8.0. running mean: 1.8006886459006797\n",
      "resetting env. episode reward total was 14.0. running mean: 1.922681759441673\n",
      "resetting env. episode reward total was 10.0. running mean: 2.0034549418472563\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9234203924287836\n",
      "resetting env. episode reward total was 10.0. running mean: 2.004186188504496\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9741443266194507\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9944028833532563\n",
      "resetting env. episode reward total was 12.0. running mean: 2.094458854519724\n",
      "resetting env. episode reward total was 2.0. running mean: 2.0935142659745267\n",
      "resetting env. episode reward total was -2.0. running mean: 2.052579123314781\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9820533320816331\n",
      "resetting env. episode reward total was -14.0. running mean: 1.8222327987608167\n",
      "resetting env. episode reward total was -6.0. running mean: 1.7440104707732085\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7865703660654764\n",
      "resetting env. episode reward total was 12.0. running mean: 1.8887046624048214\n",
      "resetting env. episode reward total was -1.0. running mean: 1.859817615780773\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9012194396229654\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8722072452267358\n",
      "resetting env. episode reward total was 12.0. running mean: 1.9734851727744682\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9137503210467235\n",
      "resetting env. episode reward total was 13.0. running mean: 2.0246128178362564\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0443666896578936\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9739230227613145\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0141837925337014\n",
      "resetting env. episode reward total was -2.0. running mean: 1.9740419546083643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 6.0. running mean: 2.0143015350622804\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9841585197116576\n",
      "resetting env. episode reward total was -2.0. running mean: 1.944316934514541\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9948737651693957\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9149250275177017\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9057757772425246\n",
      "resetting env. episode reward total was -10.0. running mean: 1.7867180194700991\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7888508392753981\n",
      "resetting env. episode reward total was -3.0. running mean: 1.740962330882644\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7535527075738175\n",
      "resetting env. episode reward total was 15.0. running mean: 1.8860171804980792\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9671570086930985\n",
      "resetting env. episode reward total was -3.0. running mean: 1.9174854386061675\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8483105842201057\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8798274783779048\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9210292035941257\n",
      "resetting env. episode reward total was -9.0. running mean: 1.8118189115581842\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8537007224426023\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9051637152181764\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8661120780659946\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8374509572853346\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7690764477124812\n",
      "resetting env. episode reward total was -2.0. running mean: 1.7313856832353562\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7440718264030026\n",
      "resetting env. episode reward total was 14.0. running mean: 1.8666311081389728\n",
      "resetting env. episode reward total was -3.0. running mean: 1.817964797057583\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8197851490870072\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8615872975961372\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9029714246201759\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8339417103739741\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9156022932702346\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8464462703375322\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8479818076341568\n",
      "resetting env. episode reward total was -8.0. running mean: 1.749501989557815\n",
      "resetting env. episode reward total was 8.0. running mean: 1.812006969662237\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7438868999656145\n",
      "resetting env. episode reward total was 9.0. running mean: 1.8164480309659585\n",
      "resetting env. episode reward total was 10.0. running mean: 1.898283550656299\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8893007151497359\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9304077079982385\n",
      "resetting env. episode reward total was -3.0. running mean: 1.881103630918256\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8122925946090733\n",
      "resetting env. episode reward total was 14.0. running mean: 1.9341696686629826\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8848279719763528\n",
      "resetting env. episode reward total was -7.0. running mean: 1.7959796922565892\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8080198953340232\n",
      "resetting env. episode reward total was -4.0. running mean: 1.7499396963806828\n",
      "resetting env. episode reward total was 4.0. running mean: 1.772440299416876\n",
      "resetting env. episode reward total was -10.0. running mean: 1.654715896422707\n",
      "resetting env. episode reward total was -5.0. running mean: 1.58816873745848\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6022870500838953\n",
      "resetting env. episode reward total was 12.0. running mean: 1.7062641795830564\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7492015377872259\n",
      "resetting env. episode reward total was -4.0. running mean: 1.6917095224093535\n",
      "resetting env. episode reward total was -9.0. running mean: 1.5847924271852598\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5289445029134072\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6136550578842732\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6475185073054306\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6810433222323764\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7442328890100527\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7867905601199523\n",
      "resetting env. episode reward total was 15.0. running mean: 1.9189226545187528\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9197334279735652\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9205360936938296\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9313307327568914\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9320174254293225\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9426972511750293\n",
      "resetting env. episode reward total was 3.0. running mean: 1.953270278663279\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9437375758766462\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9943002001178798\n",
      "resetting env. episode reward total was -12.0. running mean: 1.854357198116701\n",
      "resetting env. episode reward total was 6.0. running mean: 1.895813626135534\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8668554898741787\n",
      "resetting env. episode reward total was 3.0. running mean: 1.878186934975437\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8294050656256826\n",
      "resetting env. episode reward total was -8.0. running mean: 1.7311110149694258\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6937999048197314\n",
      "resetting env. episode reward total was -2.0. running mean: 1.6568619057715341\n",
      "resetting env. episode reward total was -10.0. running mean: 1.5402932867138186\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5648903538466805\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5392414503082137\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5938490358051316\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6079105454470803\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5218314399926094\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5866131255926834\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5407469943367564\n",
      "resetting env. episode reward total was -1.0. running mean: 1.515339524393389\n",
      "resetting env. episode reward total was 4.0. running mean: 1.540186129149455\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5147842678579604\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4896364251793808\n",
      "resetting env. episode reward total was -11.0. running mean: 1.3647400609275868\n",
      "resetting env. episode reward total was 1.0. running mean: 1.3610926603183109\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3374817337151277\n",
      "resetting env. episode reward total was -7.0. running mean: 1.2541069163779763\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1915658472141966\n",
      "resetting env. episode reward total was 10.0. running mean: 1.2796501887420546\n",
      "resetting env. episode reward total was -1.0. running mean: 1.256853686854634\n",
      "resetting env. episode reward total was 4.0. running mean: 1.2842851499860877\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3114422984862268\n",
      "resetting env. episode reward total was -3.0. running mean: 1.2683278755013645\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2056445967463507\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2135881507788873\n",
      "resetting env. episode reward total was -15.0. running mean: 1.0514522692710984\n",
      "resetting env. episode reward total was 12.0. running mean: 1.1609377465783872\n",
      "resetting env. episode reward total was 11.0. running mean: 1.2593283691126034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: 1.2367350854214774\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3043677345672626\n",
      "resetting env. episode reward total was -12.0. running mean: 1.17132405722159\n",
      "resetting env. episode reward total was 12.0. running mean: 1.2796108166493738\n",
      "resetting env. episode reward total was -9.0. running mean: 1.17681470848288\n",
      "resetting env. episode reward total was 9.0. running mean: 1.2550465613980513\n",
      "resetting env. episode reward total was -9.0. running mean: 1.1524960957840706\n",
      "resetting env. episode reward total was 3.0. running mean: 1.17097113482623\n",
      "resetting env. episode reward total was -5.0. running mean: 1.1092614234779676\n",
      "resetting env. episode reward total was 4.0. running mean: 1.138168809243188\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0967871211507563\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9958192499392488\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0158610574398563\n",
      "resetting env. episode reward total was 7.0. running mean: 1.075702446865458\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0849454223968034\n",
      "resetting env. episode reward total was -6.0. running mean: 1.0140959681728352\n",
      "resetting env. episode reward total was -6.0. running mean: 0.9439550084911068\n",
      "resetting env. episode reward total was -4.0. running mean: 0.8945154584061957\n",
      "resetting env. episode reward total was -7.0. running mean: 0.8155703038221338\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8474146007839125\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8989404547760733\n",
      "resetting env. episode reward total was -13.0. running mean: 0.7599510502283126\n",
      "resetting env. episode reward total was 10.0. running mean: 0.8523515397260294\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8238280243287691\n",
      "resetting env. episode reward total was 9.0. running mean: 0.9055897440854814\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9165338466446267\n",
      "resetting env. episode reward total was -9.0. running mean: 0.8173685081781804\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9091948230963985\n",
      "resetting env. episode reward total was 7.0. running mean: 0.9701028748654346\n",
      "resetting env. episode reward total was -6.0. running mean: 0.9004018461167802\n",
      "resetting env. episode reward total was 10.0. running mean: 0.9913978276556124\n",
      "resetting env. episode reward total was 3.0. running mean: 1.011483849379056\n",
      "resetting env. episode reward total was -2.0. running mean: 0.9813690108852655\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9615553207764128\n",
      "resetting env. episode reward total was 2.0. running mean: 0.9719397675686487\n",
      "resetting env. episode reward total was 3.0. running mean: 0.9922203698929623\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0122981661940327\n",
      "resetting env. episode reward total was -1.0. running mean: 0.9921751845320923\n",
      "resetting env. episode reward total was 7.0. running mean: 1.0522534326867714\n",
      "resetting env. episode reward total was 5.0. running mean: 1.0917308983599037\n",
      "resetting env. episode reward total was 12.0. running mean: 1.2008135893763048\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2388054534825417\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3064173989477164\n",
      "resetting env. episode reward total was 11.0. running mean: 1.4033532249582392\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3193196927086568\n",
      "resetting env. episode reward total was 9.0. running mean: 1.3961264957815702\n",
      "resetting env. episode reward total was -9.0. running mean: 1.2921652308237543\n",
      "resetting env. episode reward total was -1.0. running mean: 1.2692435785155167\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3365511427303616\n",
      "resetting env. episode reward total was 2.0. running mean: 1.343185631303058\n",
      "resetting env. episode reward total was -5.0. running mean: 1.2797537749900272\n",
      "resetting env. episode reward total was 8.0. running mean: 1.346956237240127\n",
      "resetting env. episode reward total was 3.0. running mean: 1.3634866748677257\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4298518081190486\n",
      "resetting env. episode reward total was -8.0. running mean: 1.335553290037858\n",
      "resetting env. episode reward total was 3.0. running mean: 1.3521977571374795\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3586757795661046\n",
      "resetting env. episode reward total was 9.0. running mean: 1.4350890217704437\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4907381315527393\n",
      "resetting env. episode reward total was 5.0. running mean: 1.525830750237212\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5505724427348397\n",
      "resetting env. episode reward total was 11.0. running mean: 1.6450667183074914\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6486160511244166\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6621298906131725\n",
      "resetting env. episode reward total was 6.0. running mean: 1.7055085917070407\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7084535057899704\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7713689707320708\n",
      "resetting env. episode reward total was 9.0. running mean: 1.8436552810247502\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8452187282145027\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8167665409323577\n",
      "resetting env. episode reward total was 5.0. running mean: 1.848598875523034\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8501128867678036\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8716117579001257\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9528956403211244\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9533666839179131\n",
      "resetting env. episode reward total was 7.0. running mean: 2.0038330170787337\n",
      "resetting env. episode reward total was 4.0. running mean: 2.023794686907946\n",
      "resetting env. episode reward total was 7.0. running mean: 2.0735567400388666\n",
      "resetting env. episode reward total was 3.0. running mean: 2.0828211726384778\n",
      "resetting env. episode reward total was 16.0. running mean: 2.221992960912093\n",
      "resetting env. episode reward total was 2.0. running mean: 2.219773031302972\n",
      "resetting env. episode reward total was -5.0. running mean: 2.1475753009899425\n",
      "resetting env. episode reward total was 2.0. running mean: 2.146099547980043\n",
      "resetting env. episode reward total was 13.0. running mean: 2.2546385525002424\n",
      "resetting env. episode reward total was 7.0. running mean: 2.30209216697524\n",
      "resetting env. episode reward total was -6.0. running mean: 2.2190712453054875\n",
      "resetting env. episode reward total was -5.0. running mean: 2.1468805328524327\n",
      "resetting env. episode reward total was 9.0. running mean: 2.2154117275239082\n",
      "resetting env. episode reward total was 16.0. running mean: 2.353257610248669\n",
      "resetting env. episode reward total was -5.0. running mean: 2.2797250341461828\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3069277838047206\n",
      "resetting env. episode reward total was -3.0. running mean: 2.2538585059666736\n",
      "resetting env. episode reward total was 11.0. running mean: 2.3413199209070066\n",
      "resetting env. episode reward total was -5.0. running mean: 2.2679067216979365\n",
      "resetting env. episode reward total was -1.0. running mean: 2.2352276544809575\n",
      "resetting env. episode reward total was 4.0. running mean: 2.252875377936148\n",
      "resetting env. episode reward total was -3.0. running mean: 2.200346624156787\n",
      "resetting env. episode reward total was -8.0. running mean: 2.098343157915219\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0873597263360666\n",
      "resetting env. episode reward total was 4.0. running mean: 2.106486129072706\n",
      "resetting env. episode reward total was 5.0. running mean: 2.135421267781979\n",
      "resetting env. episode reward total was -5.0. running mean: 2.064067055104159\n",
      "resetting env. episode reward total was -13.0. running mean: 1.9134263845531176\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9042921207075865\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9052491995005105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -7.0. running mean: 1.8161967075055054\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8480347404304505\n",
      "resetting env. episode reward total was -1.0. running mean: 1.819554393026146\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9013588490958846\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8523452606049258\n",
      "resetting env. episode reward total was -4.0. running mean: 1.7938218079988764\n",
      "resetting env. episode reward total was 12.0. running mean: 1.8958835899188875\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9569247540196988\n",
      "resetting env. episode reward total was -6.0. running mean: 1.8773555064795018\n",
      "resetting env. episode reward total was 9.0. running mean: 1.948581951414707\n",
      "resetting env. episode reward total was 7.0. running mean: 1.9990961319005598\n",
      "resetting env. episode reward total was -2.0. running mean: 1.959105170581554\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9495141188757386\n",
      "resetting env. episode reward total was -7.0. running mean: 1.860018977686981\n",
      "resetting env. episode reward total was 10.0. running mean: 1.9414187879101115\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9420046000310103\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9325845540307\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9632587084903932\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9936261214054893\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9636898601914343\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0040529615895197\n",
      "resetting env. episode reward total was 8.0. running mean: 2.0640124319736244\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1033723076538884\n",
      "resetting env. episode reward total was 7.0. running mean: 2.1523385845773495\n",
      "resetting env. episode reward total was 3.0. running mean: 2.1608151987315756\n",
      "resetting env. episode reward total was -3.0. running mean: 2.10920704674426\n",
      "resetting env. episode reward total was -5.0. running mean: 2.038114976276818\n",
      "resetting env. episode reward total was -4.0. running mean: 1.9777338265140494\n",
      "resetting env. episode reward total was -3.0. running mean: 1.9279564882489089\n",
      "resetting env. episode reward total was 9.0. running mean: 1.9986769233664199\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9286901541327557\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9694032525914282\n",
      "resetting env. episode reward total was 1.0. running mean: 1.959709220065514\n",
      "resetting env. episode reward total was -9.0. running mean: 1.8501121278648587\n",
      "resetting env. episode reward total was 11.0. running mean: 1.9416110065862102\n",
      "resetting env. episode reward total was 9.0. running mean: 2.012194896520348\n",
      "resetting env. episode reward total was 15.0. running mean: 2.1420729475551448\n",
      "resetting env. episode reward total was 7.0. running mean: 2.190652218079593\n",
      "resetting env. episode reward total was 2.0. running mean: 2.188745695898797\n",
      "resetting env. episode reward total was 8.0. running mean: 2.2468582389398093\n",
      "resetting env. episode reward total was -6.0. running mean: 2.1643896565504113\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0927457599849073\n",
      "resetting env. episode reward total was 6.0. running mean: 2.1318183023850583\n",
      "resetting env. episode reward total was 12.0. running mean: 2.2305001193612077\n",
      "resetting env. episode reward total was 13.0. running mean: 2.3381951181675955\n",
      "resetting env. episode reward total was -1.0. running mean: 2.3048131669859195\n",
      "resetting env. episode reward total was -4.0. running mean: 2.2417650353160603\n",
      "resetting env. episode reward total was -6.0. running mean: 2.1593473849628997\n",
      "resetting env. episode reward total was -3.0. running mean: 2.107753911113271\n",
      "resetting env. episode reward total was 3.0. running mean: 2.116676372002138\n",
      "resetting env. episode reward total was 1.0. running mean: 2.1055096082821163\n",
      "resetting env. episode reward total was 6.0. running mean: 2.144454512199295\n",
      "resetting env. episode reward total was -1.0. running mean: 2.113009967077302\n",
      "resetting env. episode reward total was -2.0. running mean: 2.0718798674065293\n",
      "resetting env. episode reward total was 13.0. running mean: 2.181161068732464\n",
      "resetting env. episode reward total was -7.0. running mean: 2.0893494580451395\n",
      "resetting env. episode reward total was -1.0. running mean: 2.0584559634646884\n",
      "resetting env. episode reward total was 12.0. running mean: 2.1578714038300415\n",
      "resetting env. episode reward total was 3.0. running mean: 2.166292689791741\n",
      "resetting env. episode reward total was -6.0. running mean: 2.0846297628938233\n",
      "resetting env. episode reward total was 13.0. running mean: 2.193783465264885\n",
      "resetting env. episode reward total was 10.0. running mean: 2.271845630612236\n",
      "resetting env. episode reward total was 3.0. running mean: 2.2791271743061134\n",
      "resetting env. episode reward total was 13.0. running mean: 2.386335902563052\n",
      "resetting env. episode reward total was -8.0. running mean: 2.2824725435374216\n",
      "resetting env. episode reward total was -5.0. running mean: 2.2096478181020474\n",
      "resetting env. episode reward total was -1.0. running mean: 2.177551339921027\n",
      "resetting env. episode reward total was 8.0. running mean: 2.235775826521817\n",
      "resetting env. episode reward total was 6.0. running mean: 2.273418068256599\n",
      "resetting env. episode reward total was 8.0. running mean: 2.330683887574033\n",
      "resetting env. episode reward total was 15.0. running mean: 2.4573770486982927\n",
      "resetting env. episode reward total was 6.0. running mean: 2.49280327821131\n",
      "resetting env. episode reward total was 5.0. running mean: 2.5178752454291966\n",
      "resetting env. episode reward total was 8.0. running mean: 2.5726964929749045\n",
      "resetting env. episode reward total was 10.0. running mean: 2.6469695280451555\n",
      "resetting env. episode reward total was 4.0. running mean: 2.660499832764704\n",
      "resetting env. episode reward total was -2.0. running mean: 2.613894834437057\n",
      "resetting env. episode reward total was 10.0. running mean: 2.6877558860926865\n",
      "resetting env. episode reward total was -9.0. running mean: 2.57087832723176\n",
      "resetting env. episode reward total was -5.0. running mean: 2.4951695439594426\n",
      "resetting env. episode reward total was 18.0. running mean: 2.650217848519848\n",
      "resetting env. episode reward total was -9.0. running mean: 2.53371567003465\n",
      "resetting env. episode reward total was 6.0. running mean: 2.5683785133343036\n",
      "resetting env. episode reward total was 6.0. running mean: 2.6026947282009605\n",
      "resetting env. episode reward total was -14.0. running mean: 2.4366677809189508\n",
      "resetting env. episode reward total was -3.0. running mean: 2.3823011031097616\n",
      "resetting env. episode reward total was 11.0. running mean: 2.468478092078664\n",
      "resetting env. episode reward total was 1.0. running mean: 2.453793311157877\n",
      "resetting env. episode reward total was 9.0. running mean: 2.519255378046298\n",
      "resetting env. episode reward total was -8.0. running mean: 2.414062824265835\n",
      "resetting env. episode reward total was 4.0. running mean: 2.4299221960231767\n",
      "resetting env. episode reward total was -3.0. running mean: 2.3756229740629453\n",
      "resetting env. episode reward total was -4.0. running mean: 2.311866744322316\n",
      "resetting env. episode reward total was -3.0. running mean: 2.258748076879093\n",
      "resetting env. episode reward total was -3.0. running mean: 2.206160596110302\n",
      "resetting env. episode reward total was 6.0. running mean: 2.2440989901491992\n",
      "resetting env. episode reward total was -10.0. running mean: 2.1216580002477072\n",
      "resetting env. episode reward total was -4.0. running mean: 2.06044142024523\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9798370060427777\n",
      "resetting env. episode reward total was -7.0. running mean: 1.8900386359823498\n",
      "resetting env. episode reward total was -6.0. running mean: 1.8111382496225261\n",
      "resetting env. episode reward total was 11.0. running mean: 1.9030268671263009\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9039965984550378\n",
      "resetting env. episode reward total was -11.0. running mean: 1.7749566324704873\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7272070661457823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -5.0. running mean: 1.6599349954843245\n",
      "resetting env. episode reward total was -6.0. running mean: 1.5833356455294811\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5975022890741863\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5915272661834445\n",
      "resetting env. episode reward total was 1.0. running mean: 1.58561199352161\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5397558735863939\n",
      "resetting env. episode reward total was -6.0. running mean: 1.46435831485053\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5497147317020248\n",
      "resetting env. episode reward total was -8.0. running mean: 1.4542175843850045\n",
      "resetting env. episode reward total was -13.0. running mean: 1.3096754085411546\n",
      "resetting env. episode reward total was -1.0. running mean: 1.286578654455743\n",
      "resetting env. episode reward total was 8.0. running mean: 1.3537128679111856\n",
      "resetting env. episode reward total was -2.0. running mean: 1.3201757392320737\n",
      "resetting env. episode reward total was -11.0. running mean: 1.196973981839753\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2450042420213554\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2925541996011418\n",
      "resetting env. episode reward total was 2.0. running mean: 1.2996286576051304\n",
      "resetting env. episode reward total was 13.0. running mean: 1.416632371029079\n",
      "resetting env. episode reward total was 1.0. running mean: 1.4124660473187882\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4283413868456003\n",
      "resetting env. episode reward total was 14.0. running mean: 1.5540579729771444\n",
      "resetting env. episode reward total was 2.0. running mean: 1.558517393247373\n",
      "resetting env. episode reward total was -11.0. running mean: 1.4329322193148992\n",
      "resetting env. episode reward total was -3.0. running mean: 1.3886028971217501\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3047168681505326\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3616696994690274\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3380530024743371\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3946724724495938\n",
      "resetting env. episode reward total was -8.0. running mean: 1.3007257477250977\n",
      "resetting env. episode reward total was -9.0. running mean: 1.1977184902478466\n",
      "resetting env. episode reward total was -1.0. running mean: 1.175741305345368\n",
      "resetting env. episode reward total was -10.0. running mean: 1.0639838922919143\n",
      "resetting env. episode reward total was -9.0. running mean: 0.9633440533689951\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9037106128353051\n",
      "resetting env. episode reward total was -12.0. running mean: 0.774673506706952\n",
      "resetting env. episode reward total was 7.0. running mean: 0.8369267716398825\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8885575039234836\n",
      "resetting env. episode reward total was -2.0. running mean: 0.8596719288842488\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8810752095954063\n",
      "resetting env. episode reward total was -6.0. running mean: 0.8122644574994522\n",
      "resetting env. episode reward total was -10.0. running mean: 0.7041418129244577\n",
      "resetting env. episode reward total was -2.0. running mean: 0.677100394795213\n",
      "resetting env. episode reward total was -5.0. running mean: 0.6203293908472608\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5641260969387881\n",
      "resetting env. episode reward total was -14.0. running mean: 0.4184848359694002\n",
      "resetting env. episode reward total was 13.0. running mean: 0.5442999876097062\n",
      "resetting env. episode reward total was -3.0. running mean: 0.5088569877336091\n",
      "resetting env. episode reward total was -5.0. running mean: 0.45376841785627303\n",
      "resetting env. episode reward total was 4.0. running mean: 0.48923073367771025\n",
      "resetting env. episode reward total was -4.0. running mean: 0.4443384263409332\n",
      "resetting env. episode reward total was -4.0. running mean: 0.39989504207752385\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5058960916567486\n",
      "resetting env. episode reward total was -11.0. running mean: 0.3908371307401811\n",
      "resetting env. episode reward total was 2.0. running mean: 0.40692875943277934\n",
      "resetting env. episode reward total was -9.0. running mean: 0.31285947183845153\n",
      "resetting env. episode reward total was 6.0. running mean: 0.369730877120067\n",
      "resetting env. episode reward total was -11.0. running mean: 0.25603356834886637\n",
      "resetting env. episode reward total was 14.0. running mean: 0.3934732326653777\n",
      "resetting env. episode reward total was 1.0. running mean: 0.39953850033872396\n",
      "resetting env. episode reward total was 4.0. running mean: 0.4355431153353367\n",
      "resetting env. episode reward total was 1.0. running mean: 0.44118768418198334\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4267758073401635\n",
      "resetting env. episode reward total was -1.0. running mean: 0.4125080492667619\n",
      "resetting env. episode reward total was 8.0. running mean: 0.48838296877409426\n",
      "resetting env. episode reward total was -9.0. running mean: 0.39349913908635337\n",
      "resetting env. episode reward total was -15.0. running mean: 0.2395641476954898\n",
      "resetting env. episode reward total was -5.0. running mean: 0.18716850621853492\n",
      "resetting env. episode reward total was -3.0. running mean: 0.15529682115634957\n",
      "resetting env. episode reward total was 11.0. running mean: 0.2637438529447861\n",
      "resetting env. episode reward total was 2.0. running mean: 0.28110641441533823\n",
      "resetting env. episode reward total was -15.0. running mean: 0.12829535027118485\n",
      "resetting env. episode reward total was -2.0. running mean: 0.107012396768473\n",
      "resetting env. episode reward total was 8.0. running mean: 0.1859422728007883\n",
      "resetting env. episode reward total was 1.0. running mean: 0.19408285007278042\n",
      "resetting env. episode reward total was 11.0. running mean: 0.3021420215720526\n",
      "resetting env. episode reward total was 10.0. running mean: 0.3991206013563321\n",
      "resetting env. episode reward total was 12.0. running mean: 0.5151293953427687\n",
      "resetting env. episode reward total was 3.0. running mean: 0.539978101389341\n",
      "resetting env. episode reward total was -4.0. running mean: 0.49457832037544763\n",
      "resetting env. episode reward total was 5.0. running mean: 0.5396325371716931\n",
      "resetting env. episode reward total was 2.0. running mean: 0.5542362117999762\n",
      "resetting env. episode reward total was -12.0. running mean: 0.42869384968197644\n",
      "resetting env. episode reward total was -1.0. running mean: 0.41440691118515666\n",
      "resetting env. episode reward total was -7.0. running mean: 0.3402628420733051\n",
      "resetting env. episode reward total was 8.0. running mean: 0.41686021365257203\n",
      "resetting env. episode reward total was 12.0. running mean: 0.5326916115160463\n",
      "resetting env. episode reward total was -9.0. running mean: 0.43736469540088585\n",
      "resetting env. episode reward total was -9.0. running mean: 0.342991048446877\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3295611379624082\n",
      "resetting env. episode reward total was 4.0. running mean: 0.3662655265827841\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3326028713169563\n",
      "resetting env. episode reward total was 1.0. running mean: 0.33927684260378677\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3258840741777489\n",
      "resetting env. episode reward total was 3.0. running mean: 0.3526252334359714\n",
      "resetting env. episode reward total was -2.0. running mean: 0.3290989811016117\n",
      "resetting env. episode reward total was 3.0. running mean: 0.3558079912905956\n",
      "resetting env. episode reward total was 8.0. running mean: 0.43224991137768964\n",
      "resetting env. episode reward total was 1.0. running mean: 0.43792741226391274\n",
      "resetting env. episode reward total was -4.0. running mean: 0.39354813814127365\n",
      "resetting env. episode reward total was 3.0. running mean: 0.4196126567598609\n",
      "resetting env. episode reward total was -5.0. running mean: 0.36541653019226233\n",
      "resetting env. episode reward total was 9.0. running mean: 0.4517623648903397\n",
      "resetting env. episode reward total was 9.0. running mean: 0.5372447412414363\n",
      "resetting env. episode reward total was 5.0. running mean: 0.581872293829022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 0.6260535708907318\n",
      "resetting env. episode reward total was -11.0. running mean: 0.5097930351818245\n",
      "resetting env. episode reward total was -6.0. running mean: 0.44469510483000624\n",
      "resetting env. episode reward total was -3.0. running mean: 0.4102481537817062\n",
      "resetting env. episode reward total was -8.0. running mean: 0.32614567224388913\n",
      "resetting env. episode reward total was -2.0. running mean: 0.30288421552145023\n",
      "resetting env. episode reward total was 6.0. running mean: 0.35985537336623574\n",
      "resetting env. episode reward total was -5.0. running mean: 0.3062568196325734\n",
      "resetting env. episode reward total was -6.0. running mean: 0.24319425143624768\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2107623089218852\n",
      "resetting env. episode reward total was 1.0. running mean: 0.21865468583266634\n",
      "resetting env. episode reward total was 4.0. running mean: 0.2564681389743397\n",
      "resetting env. episode reward total was -5.0. running mean: 0.20390345758459627\n",
      "resetting env. episode reward total was -13.0. running mean: 0.07186442300875029\n",
      "resetting env. episode reward total was 6.0. running mean: 0.1311457787786628\n",
      "resetting env. episode reward total was -2.0. running mean: 0.10983432099087616\n",
      "resetting env. episode reward total was -11.0. running mean: -0.0012640222190326011\n",
      "resetting env. episode reward total was 15.0. running mean: 0.14874861800315772\n",
      "resetting env. episode reward total was 6.0. running mean: 0.20726113182312614\n",
      "resetting env. episode reward total was -11.0. running mean: 0.09518852050489486\n",
      "resetting env. episode reward total was 8.0. running mean: 0.1742366352998459\n",
      "resetting env. episode reward total was -12.0. running mean: 0.052494268946847444\n",
      "resetting env. episode reward total was 4.0. running mean: 0.09196932625737897\n",
      "resetting env. episode reward total was 5.0. running mean: 0.14104963299480516\n",
      "resetting env. episode reward total was 6.0. running mean: 0.1996391366648571\n",
      "resetting env. episode reward total was 5.0. running mean: 0.2476427452982085\n",
      "resetting env. episode reward total was 4.0. running mean: 0.2851663178452264\n",
      "resetting env. episode reward total was -15.0. running mean: 0.13231465466677414\n",
      "resetting env. episode reward total was 2.0. running mean: 0.1509915081201064\n",
      "resetting env. episode reward total was 2.0. running mean: 0.1694815930389053\n",
      "resetting env. episode reward total was 10.0. running mean: 0.2677867771085163\n",
      "resetting env. episode reward total was 8.0. running mean: 0.34510890933743116\n",
      "resetting env. episode reward total was 4.0. running mean: 0.3816578202440568\n",
      "resetting env. episode reward total was 3.0. running mean: 0.4078412420416162\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3737628296212\n",
      "resetting env. episode reward total was -5.0. running mean: 0.320025201324988\n",
      "resetting env. episode reward total was -2.0. running mean: 0.29682494931173814\n",
      "resetting env. episode reward total was 5.0. running mean: 0.34385669981862077\n",
      "resetting env. episode reward total was -5.0. running mean: 0.29041813282043455\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2575139514922302\n",
      "resetting env. episode reward total was -15.0. running mean: 0.1049388119773079\n",
      "resetting env. episode reward total was -2.0. running mean: 0.08388942385753481\n",
      "resetting env. episode reward total was -7.0. running mean: 0.013050529618959458\n",
      "resetting env. episode reward total was 2.0. running mean: 0.032920024322769866\n",
      "resetting env. episode reward total was -1.0. running mean: 0.022590824079542167\n",
      "resetting env. episode reward total was -11.0. running mean: -0.08763508416125326\n",
      "resetting env. episode reward total was 3.0. running mean: -0.056758733319640736\n",
      "resetting env. episode reward total was 4.0. running mean: -0.016191145986444326\n",
      "resetting env. episode reward total was 4.0. running mean: 0.023970765473420117\n",
      "resetting env. episode reward total was 4.0. running mean: 0.06373105781868592\n",
      "resetting env. episode reward total was -8.0. running mean: -0.016906252759500945\n",
      "resetting env. episode reward total was -4.0. running mean: -0.05673719023190593\n",
      "resetting env. episode reward total was 4.0. running mean: -0.016169818329586874\n",
      "resetting env. episode reward total was 1.0. running mean: -0.006008120146291004\n",
      "resetting env. episode reward total was 10.0. running mean: 0.09405196105517191\n",
      "resetting env. episode reward total was 5.0. running mean: 0.14311144144462018\n",
      "resetting env. episode reward total was 1.0. running mean: 0.15168032703017398\n",
      "resetting env. episode reward total was -5.0. running mean: 0.10016352375987224\n",
      "resetting env. episode reward total was -5.0. running mean: 0.04916188852227352\n",
      "resetting env. episode reward total was -7.0. running mean: -0.021329730362949224\n",
      "resetting env. episode reward total was -9.0. running mean: -0.11111643305931973\n",
      "resetting env. episode reward total was -6.0. running mean: -0.1700052687287265\n",
      "resetting env. episode reward total was -7.0. running mean: -0.23830521604143926\n",
      "resetting env. episode reward total was 8.0. running mean: -0.15592216388102487\n",
      "resetting env. episode reward total was -8.0. running mean: -0.2343629422422146\n",
      "resetting env. episode reward total was -5.0. running mean: -0.2820193128197925\n",
      "resetting env. episode reward total was -3.0. running mean: -0.3091991196915945\n",
      "resetting env. episode reward total was -3.0. running mean: -0.3361071284946786\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3027460572097318\n",
      "resetting env. episode reward total was -5.0. running mean: -0.3497185966376345\n",
      "resetting env. episode reward total was 4.0. running mean: -0.3062214106712582\n",
      "resetting env. episode reward total was -1.0. running mean: -0.3131591965645456\n",
      "resetting env. episode reward total was -7.0. running mean: -0.38002760459890017\n",
      "resetting env. episode reward total was -5.0. running mean: -0.4262273285529112\n",
      "resetting env. episode reward total was 10.0. running mean: -0.32196505526738206\n",
      "resetting env. episode reward total was -5.0. running mean: -0.36874540471470824\n",
      "resetting env. episode reward total was 9.0. running mean: -0.2750579506675611\n",
      "resetting env. episode reward total was 9.0. running mean: -0.1823073711608855\n",
      "resetting env. episode reward total was 17.0. running mean: -0.01048429744927662\n",
      "resetting env. episode reward total was -3.0. running mean: -0.04037945447478385\n",
      "resetting env. episode reward total was -7.0. running mean: -0.10997565993003602\n",
      "resetting env. episode reward total was -5.0. running mean: -0.15887590333073565\n",
      "resetting env. episode reward total was -12.0. running mean: -0.2772871442974283\n",
      "resetting env. episode reward total was -3.0. running mean: -0.304514272854454\n",
      "resetting env. episode reward total was 2.0. running mean: -0.2814691301259094\n",
      "resetting env. episode reward total was -6.0. running mean: -0.3386544388246503\n",
      "resetting env. episode reward total was -5.0. running mean: -0.3852678944364038\n",
      "resetting env. episode reward total was 6.0. running mean: -0.3214152154920398\n",
      "resetting env. episode reward total was -3.0. running mean: -0.3482010633371194\n",
      "resetting env. episode reward total was 11.0. running mean: -0.2347190527037482\n",
      "resetting env. episode reward total was 1.0. running mean: -0.2223718621767107\n",
      "resetting env. episode reward total was -12.0. running mean: -0.3401481435549436\n",
      "resetting env. episode reward total was -9.0. running mean: -0.42674666211939416\n",
      "resetting env. episode reward total was -3.0. running mean: -0.45247919549820026\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4779544035432183\n",
      "resetting env. episode reward total was 2.0. running mean: -0.4531748595077861\n",
      "resetting env. episode reward total was 9.0. running mean: -0.3586431109127082\n",
      "resetting env. episode reward total was 11.0. running mean: -0.2450566798035811\n",
      "resetting env. episode reward total was -10.0. running mean: -0.3426061130055453\n",
      "resetting env. episode reward total was 3.0. running mean: -0.3091800518754898\n",
      "resetting env. episode reward total was 6.0. running mean: -0.2460882513567349\n",
      "resetting env. episode reward total was 4.0. running mean: -0.20362736884316754\n",
      "resetting env. episode reward total was 1.0. running mean: -0.19159109515473585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: -0.1696751842031885\n",
      "resetting env. episode reward total was 7.0. running mean: -0.09797843236115661\n",
      "resetting env. episode reward total was 6.0. running mean: -0.036998648037545045\n",
      "resetting env. episode reward total was -8.0. running mean: -0.1166286615571696\n",
      "resetting env. episode reward total was 4.0. running mean: -0.07546237494159791\n",
      "resetting env. episode reward total was -3.0. running mean: -0.10470775119218192\n",
      "resetting env. episode reward total was 6.0. running mean: -0.04366067368026011\n",
      "resetting env. episode reward total was 5.0. running mean: 0.006775933056542498\n",
      "resetting env. episode reward total was 4.0. running mean: 0.046708173725977076\n",
      "resetting env. episode reward total was -4.0. running mean: 0.006241091988717307\n",
      "resetting env. episode reward total was 3.0. running mean: 0.03617868106883013\n",
      "resetting env. episode reward total was -1.0. running mean: 0.025816894258141827\n",
      "resetting env. episode reward total was -9.0. running mean: -0.06444127468443958\n",
      "resetting env. episode reward total was 12.0. running mean: 0.05620313806240482\n",
      "resetting env. episode reward total was 6.0. running mean: 0.11564110668178076\n",
      "resetting env. episode reward total was -11.0. running mean: 0.0044846956149629524\n",
      "resetting env. episode reward total was 8.0. running mean: 0.08443984865881332\n",
      "resetting env. episode reward total was 7.0. running mean: 0.1535954501722252\n",
      "resetting env. episode reward total was 6.0. running mean: 0.21205949567050295\n",
      "resetting env. episode reward total was 8.0. running mean: 0.2899389007137979\n",
      "resetting env. episode reward total was -11.0. running mean: 0.17703951170665994\n",
      "resetting env. episode reward total was 6.0. running mean: 0.23526911658959332\n",
      "resetting env. episode reward total was -1.0. running mean: 0.22291642542369738\n",
      "resetting env. episode reward total was -4.0. running mean: 0.1806872611694604\n",
      "resetting env. episode reward total was 4.0. running mean: 0.21888038855776581\n",
      "resetting env. episode reward total was -1.0. running mean: 0.20669158467218815\n",
      "resetting env. episode reward total was 2.0. running mean: 0.22462466882546625\n",
      "resetting env. episode reward total was 7.0. running mean: 0.2923784221372116\n",
      "resetting env. episode reward total was 5.0. running mean: 0.33945463791583946\n",
      "resetting env. episode reward total was 4.0. running mean: 0.376060091536681\n",
      "resetting env. episode reward total was -3.0. running mean: 0.34229949062131415\n",
      "resetting env. episode reward total was 1.0. running mean: 0.34887649571510104\n",
      "resetting env. episode reward total was 3.0. running mean: 0.37538773075795007\n",
      "resetting env. episode reward total was -2.0. running mean: 0.35163385345037057\n",
      "resetting env. episode reward total was 3.0. running mean: 0.37811751491586687\n",
      "resetting env. episode reward total was -9.0. running mean: 0.28433633976670825\n",
      "resetting env. episode reward total was -1.0. running mean: 0.27149297636904113\n",
      "resetting env. episode reward total was 6.0. running mean: 0.3287780466053507\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3154902661392972\n",
      "resetting env. episode reward total was 5.0. running mean: 0.36233536347790424\n",
      "resetting env. episode reward total was -3.0. running mean: 0.3287120098431252\n",
      "resetting env. episode reward total was 2.0. running mean: 0.345424889744694\n",
      "resetting env. episode reward total was -4.0. running mean: 0.30197064084724706\n",
      "resetting env. episode reward total was -11.0. running mean: 0.1889509344387746\n",
      "resetting env. episode reward total was -6.0. running mean: 0.12706142509438684\n",
      "resetting env. episode reward total was 3.0. running mean: 0.15579081084344296\n",
      "resetting env. episode reward total was 2.0. running mean: 0.17423290273500852\n",
      "resetting env. episode reward total was -4.0. running mean: 0.13249057370765843\n",
      "resetting env. episode reward total was -4.0. running mean: 0.09116566797058184\n",
      "resetting env. episode reward total was -1.0. running mean: 0.08025401129087603\n",
      "resetting env. episode reward total was 4.0. running mean: 0.11945147117796728\n",
      "resetting env. episode reward total was -9.0. running mean: 0.028256956466187616\n",
      "resetting env. episode reward total was 5.0. running mean: 0.07797438690152575\n",
      "resetting env. episode reward total was 3.0. running mean: 0.10719464303251049\n",
      "resetting env. episode reward total was 4.0. running mean: 0.14612269660218538\n",
      "resetting env. episode reward total was 7.0. running mean: 0.21466146963616353\n",
      "resetting env. episode reward total was -1.0. running mean: 0.2025148549398019\n",
      "resetting env. episode reward total was 5.0. running mean: 0.25048970639040385\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2179848093264998\n",
      "resetting env. episode reward total was 4.0. running mean: 0.2558049612332348\n",
      "resetting env. episode reward total was 7.0. running mean: 0.32324691162090247\n",
      "resetting env. episode reward total was -2.0. running mean: 0.30001444250469345\n",
      "resetting env. episode reward total was -3.0. running mean: 0.2670142980796465\n",
      "resetting env. episode reward total was -9.0. running mean: 0.17434415509885\n",
      "resetting env. episode reward total was -2.0. running mean: 0.15260071354786153\n",
      "resetting env. episode reward total was -4.0. running mean: 0.1110747064123829\n",
      "resetting env. episode reward total was -7.0. running mean: 0.03996395934825907\n",
      "resetting env. episode reward total was 16.0. running mean: 0.19956431975477648\n",
      "resetting env. episode reward total was -5.0. running mean: 0.14756867655722872\n",
      "resetting env. episode reward total was -8.0. running mean: 0.06609298979165644\n",
      "resetting env. episode reward total was 3.0. running mean: 0.09543205989373987\n",
      "resetting env. episode reward total was 5.0. running mean: 0.14447773929480248\n",
      "resetting env. episode reward total was -2.0. running mean: 0.12303296190185446\n",
      "resetting env. episode reward total was -6.0. running mean: 0.06180263228283592\n",
      "resetting env. episode reward total was 4.0. running mean: 0.10118460596000756\n",
      "resetting env. episode reward total was -13.0. running mean: -0.02982724009959252\n",
      "resetting env. episode reward total was 3.0. running mean: 0.0004710323014034054\n",
      "resetting env. episode reward total was -4.0. running mean: -0.03953367802161063\n",
      "resetting env. episode reward total was 12.0. running mean: 0.08086165875860547\n",
      "resetting env. episode reward total was 6.0. running mean: 0.1400530421710194\n",
      "resetting env. episode reward total was 4.0. running mean: 0.1786525117493092\n",
      "resetting env. episode reward total was 14.0. running mean: 0.31686598663181614\n",
      "resetting env. episode reward total was -6.0. running mean: 0.253697326765498\n",
      "resetting env. episode reward total was 7.0. running mean: 0.321160353497843\n",
      "resetting env. episode reward total was 3.0. running mean: 0.3479487499628645\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3944692624632358\n",
      "resetting env. episode reward total was 2.0. running mean: 0.41052456983860347\n",
      "resetting env. episode reward total was 4.0. running mean: 0.4464193241402174\n",
      "resetting env. episode reward total was -12.0. running mean: 0.3219551308988152\n",
      "resetting env. episode reward total was -18.0. running mean: 0.13873557958982707\n",
      "resetting env. episode reward total was 11.0. running mean: 0.2473482237939288\n",
      "resetting env. episode reward total was -11.0. running mean: 0.1348747415559895\n",
      "resetting env. episode reward total was 4.0. running mean: 0.1735259941404296\n",
      "resetting env. episode reward total was -8.0. running mean: 0.0917907341990253\n",
      "resetting env. episode reward total was -2.0. running mean: 0.07087282685703504\n",
      "resetting env. episode reward total was -9.0. running mean: -0.01983590141153531\n",
      "resetting env. episode reward total was 13.0. running mean: 0.11036245760258005\n",
      "resetting env. episode reward total was -7.0. running mean: 0.03925883302655424\n",
      "resetting env. episode reward total was -5.0. running mean: -0.011133755303711308\n",
      "resetting env. episode reward total was 11.0. running mean: 0.0989775822493258\n",
      "resetting env. episode reward total was -2.0. running mean: 0.07798780642683255\n",
      "resetting env. episode reward total was 11.0. running mean: 0.18720792836256422\n",
      "resetting env. episode reward total was 10.0. running mean: 0.2853358490789386\n",
      "resetting env. episode reward total was 5.0. running mean: 0.3324824905881492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 4.0. running mean: 0.3691576656822677\n",
      "resetting env. episode reward total was -5.0. running mean: 0.31546608902544504\n",
      "resetting env. episode reward total was -2.0. running mean: 0.29231142813519057\n",
      "resetting env. episode reward total was -9.0. running mean: 0.19938831385383868\n",
      "resetting env. episode reward total was -1.0. running mean: 0.1873944307153003\n",
      "resetting env. episode reward total was 4.0. running mean: 0.22552048640814729\n",
      "resetting env. episode reward total was -6.0. running mean: 0.1632652815440658\n",
      "resetting env. episode reward total was -13.0. running mean: 0.03163262872862513\n",
      "resetting env. episode reward total was -9.0. running mean: -0.05868369755866112\n",
      "resetting env. episode reward total was -5.0. running mean: -0.10809686058307451\n",
      "resetting env. episode reward total was -13.0. running mean: -0.23701589197724376\n",
      "resetting env. episode reward total was 3.0. running mean: -0.20464573305747133\n",
      "resetting env. episode reward total was -3.0. running mean: -0.23259927572689662\n",
      "resetting env. episode reward total was -3.0. running mean: -0.26027328296962765\n",
      "resetting env. episode reward total was 2.0. running mean: -0.2376705501399314\n",
      "resetting env. episode reward total was -9.0. running mean: -0.32529384463853206\n",
      "resetting env. episode reward total was 6.0. running mean: -0.26204090619214676\n",
      "resetting env. episode reward total was -6.0. running mean: -0.3194204971302253\n",
      "resetting env. episode reward total was -2.0. running mean: -0.3362262921589231\n",
      "resetting env. episode reward total was 7.0. running mean: -0.2628640292373338\n",
      "resetting env. episode reward total was -8.0. running mean: -0.34023538894496047\n",
      "resetting env. episode reward total was -8.0. running mean: -0.4168330350555109\n",
      "resetting env. episode reward total was -7.0. running mean: -0.48266470470495576\n",
      "resetting env. episode reward total was -3.0. running mean: -0.5078380576579062\n",
      "resetting env. episode reward total was 9.0. running mean: -0.4127596770813272\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4386320803105139\n",
      "resetting env. episode reward total was -1.0. running mean: -0.4442457595074088\n",
      "resetting env. episode reward total was -3.0. running mean: -0.46980330191233466\n",
      "resetting env. episode reward total was -9.0. running mean: -0.5551052688932113\n",
      "resetting env. episode reward total was 5.0. running mean: -0.49955421620427926\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5045586740422364\n",
      "resetting env. episode reward total was 10.0. running mean: -0.399513087301814\n",
      "resetting env. episode reward total was -4.0. running mean: -0.4355179564287958\n",
      "resetting env. episode reward total was 9.0. running mean: -0.3411627768645079\n",
      "resetting env. episode reward total was 14.0. running mean: -0.19775114909586283\n",
      "resetting env. episode reward total was 1.0. running mean: -0.1857736376049042\n",
      "resetting env. episode reward total was -7.0. running mean: -0.25391590122885516\n",
      "resetting env. episode reward total was -3.0. running mean: -0.2813767422165666\n",
      "resetting env. episode reward total was 8.0. running mean: -0.19856297479440094\n",
      "resetting env. episode reward total was -6.0. running mean: -0.2565773450464569\n",
      "resetting env. episode reward total was 9.0. running mean: -0.16401157159599236\n",
      "resetting env. episode reward total was 6.0. running mean: -0.10237145588003244\n",
      "resetting env. episode reward total was -6.0. running mean: -0.1613477413212321\n",
      "resetting env. episode reward total was -5.0. running mean: -0.2097342639080198\n",
      "resetting env. episode reward total was -2.0. running mean: -0.22763692126893958\n",
      "resetting env. episode reward total was -7.0. running mean: -0.2953605520562502\n",
      "resetting env. episode reward total was -3.0. running mean: -0.3224069465356877\n",
      "resetting env. episode reward total was 3.0. running mean: -0.28918287707033086\n",
      "resetting env. episode reward total was 9.0. running mean: -0.19629104829962754\n",
      "resetting env. episode reward total was -8.0. running mean: -0.2743281378166313\n",
      "resetting env. episode reward total was -7.0. running mean: -0.341584856438465\n",
      "resetting env. episode reward total was 4.0. running mean: -0.29816900787408035\n",
      "resetting env. episode reward total was 7.0. running mean: -0.22518731779533951\n",
      "resetting env. episode reward total was 12.0. running mean: -0.10293544461738613\n",
      "resetting env. episode reward total was -4.0. running mean: -0.14190609017121228\n",
      "resetting env. episode reward total was -7.0. running mean: -0.21048702926950016\n",
      "resetting env. episode reward total was -13.0. running mean: -0.3383821589768051\n",
      "resetting env. episode reward total was -6.0. running mean: -0.39499833738703705\n",
      "resetting env. episode reward total was 5.0. running mean: -0.3410483540131667\n",
      "resetting env. episode reward total was 11.0. running mean: -0.22763787047303502\n",
      "resetting env. episode reward total was 7.0. running mean: -0.15536149176830466\n",
      "resetting env. episode reward total was 2.0. running mean: -0.13380787685062162\n",
      "resetting env. episode reward total was 2.0. running mean: -0.1124697980821154\n",
      "resetting env. episode reward total was -8.0. running mean: -0.19134510010129424\n",
      "resetting env. episode reward total was 11.0. running mean: -0.07943164910028129\n",
      "resetting env. episode reward total was -2.0. running mean: -0.09863733260927848\n",
      "resetting env. episode reward total was 15.0. running mean: 0.0523490407168143\n",
      "resetting env. episode reward total was 5.0. running mean: 0.10182555030964616\n",
      "resetting env. episode reward total was -1.0. running mean: 0.0908072948065497\n",
      "resetting env. episode reward total was -7.0. running mean: 0.019899221858484195\n",
      "resetting env. episode reward total was -3.0. running mean: -0.010299770360100647\n",
      "resetting env. episode reward total was -9.0. running mean: -0.10019677265649964\n",
      "resetting env. episode reward total was 7.0. running mean: -0.029194804929934634\n",
      "resetting env. episode reward total was -4.0. running mean: -0.06890285688063529\n",
      "resetting env. episode reward total was -3.0. running mean: -0.09821382831182893\n",
      "resetting env. episode reward total was -6.0. running mean: -0.15723169002871062\n",
      "resetting env. episode reward total was 3.0. running mean: -0.1256593731284235\n",
      "resetting env. episode reward total was 1.0. running mean: -0.11440277939713928\n",
      "resetting env. episode reward total was 1.0. running mean: -0.10325875160316789\n",
      "resetting env. episode reward total was -13.0. running mean: -0.2322261640871362\n",
      "resetting env. episode reward total was 1.0. running mean: -0.21990390244626482\n",
      "resetting env. episode reward total was 3.0. running mean: -0.18770486342180218\n",
      "resetting env. episode reward total was -3.0. running mean: -0.21582781478758414\n",
      "resetting env. episode reward total was -6.0. running mean: -0.2736695366397083\n",
      "resetting env. episode reward total was -5.0. running mean: -0.3209328412733112\n",
      "resetting env. episode reward total was -5.0. running mean: -0.36772351286057803\n",
      "resetting env. episode reward total was 6.0. running mean: -0.30404627773197224\n",
      "resetting env. episode reward total was -5.0. running mean: -0.3510058149546525\n",
      "resetting env. episode reward total was -4.0. running mean: -0.38749575680510595\n",
      "resetting env. episode reward total was -8.0. running mean: -0.4636207992370549\n",
      "resetting env. episode reward total was 8.0. running mean: -0.3789845912446843\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4051947453322374\n",
      "resetting env. episode reward total was -3.0. running mean: -0.4311427978789151\n",
      "resetting env. episode reward total was -1.0. running mean: -0.43683136990012594\n",
      "resetting env. episode reward total was 3.0. running mean: -0.40246305620112466\n",
      "resetting env. episode reward total was 9.0. running mean: -0.3084384256391134\n",
      "resetting env. episode reward total was 7.0. running mean: -0.23535404138272226\n",
      "resetting env. episode reward total was 12.0. running mean: -0.11300050096889502\n",
      "resetting env. episode reward total was 6.0. running mean: -0.05187049595920608\n",
      "resetting env. episode reward total was 1.0. running mean: -0.041351790999614016\n",
      "resetting env. episode reward total was -9.0. running mean: -0.13093827308961786\n",
      "resetting env. episode reward total was -8.0. running mean: -0.20962889035872168\n",
      "resetting env. episode reward total was 8.0. running mean: -0.12753260145513445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 10.0. running mean: -0.026257275440583094\n",
      "resetting env. episode reward total was -1.0. running mean: -0.035994702686177264\n",
      "resetting env. episode reward total was -10.0. running mean: -0.1356347556593155\n",
      "resetting env. episode reward total was 4.0. running mean: -0.09427840810272231\n",
      "resetting env. episode reward total was 9.0. running mean: -0.0033356240216950855\n",
      "resetting env. episode reward total was -4.0. running mean: -0.04330226778147814\n",
      "resetting env. episode reward total was 3.0. running mean: -0.012869245103663357\n",
      "resetting env. episode reward total was -6.0. running mean: -0.07274055265262672\n",
      "resetting env. episode reward total was -4.0. running mean: -0.11201314712610044\n",
      "resetting env. episode reward total was -1.0. running mean: -0.12089301565483944\n",
      "resetting env. episode reward total was 5.0. running mean: -0.06968408549829104\n",
      "resetting env. episode reward total was -1.0. running mean: -0.07898724464330813\n",
      "resetting env. episode reward total was 11.0. running mean: 0.031802627803124955\n",
      "resetting env. episode reward total was 5.0. running mean: 0.08148460152509371\n",
      "resetting env. episode reward total was -13.0. running mean: -0.04933024449015723\n",
      "resetting env. episode reward total was 1.0. running mean: -0.03883694204525565\n",
      "resetting env. episode reward total was 3.0. running mean: -0.0084485726248031\n",
      "resetting env. episode reward total was -7.0. running mean: -0.07836408689855508\n",
      "resetting env. episode reward total was -1.0. running mean: -0.08758044602956952\n",
      "resetting env. episode reward total was -12.0. running mean: -0.20670464156927382\n",
      "resetting env. episode reward total was -3.0. running mean: -0.23463759515358107\n",
      "resetting env. episode reward total was 4.0. running mean: -0.19229121920204525\n",
      "resetting env. episode reward total was -5.0. running mean: -0.24036830701002482\n",
      "resetting env. episode reward total was -3.0. running mean: -0.2679646239399246\n",
      "resetting env. episode reward total was 2.0. running mean: -0.24528497770052535\n",
      "resetting env. episode reward total was 1.0. running mean: -0.2328321279235201\n",
      "resetting env. episode reward total was -11.0. running mean: -0.34050380664428487\n",
      "resetting env. episode reward total was 3.0. running mean: -0.307098768577842\n",
      "resetting env. episode reward total was -1.0. running mean: -0.3140277808920636\n",
      "resetting env. episode reward total was 5.0. running mean: -0.260887503083143\n",
      "resetting env. episode reward total was 12.0. running mean: -0.13827862805231156\n",
      "resetting env. episode reward total was -7.0. running mean: -0.20689584177178844\n",
      "resetting env. episode reward total was -1.0. running mean: -0.21482688335407055\n",
      "resetting env. episode reward total was -3.0. running mean: -0.24267861452052983\n",
      "resetting env. episode reward total was 1.0. running mean: -0.2302518283753245\n",
      "resetting env. episode reward total was -13.0. running mean: -0.35794931009157127\n",
      "resetting env. episode reward total was -9.0. running mean: -0.4443698169906556\n",
      "resetting env. episode reward total was -14.0. running mean: -0.579926118820749\n",
      "resetting env. episode reward total was 5.0. running mean: -0.5241268576325414\n",
      "resetting env. episode reward total was 11.0. running mean: -0.40888558905621597\n",
      "resetting env. episode reward total was 7.0. running mean: -0.3347967331656538\n",
      "resetting env. episode reward total was -8.0. running mean: -0.41144876583399725\n",
      "resetting env. episode reward total was -10.0. running mean: -0.5073342781756572\n",
      "resetting env. episode reward total was -13.0. running mean: -0.6322609353939007\n",
      "resetting env. episode reward total was -9.0. running mean: -0.7159383260399617\n",
      "resetting env. episode reward total was -1.0. running mean: -0.718778942779562\n",
      "resetting env. episode reward total was -9.0. running mean: -0.8015911533517663\n",
      "resetting env. episode reward total was 9.0. running mean: -0.7035752418182487\n",
      "resetting env. episode reward total was 11.0. running mean: -0.5865394894000663\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6306740945060657\n",
      "resetting env. episode reward total was 10.0. running mean: -0.5243673535610051\n",
      "resetting env. episode reward total was -10.0. running mean: -0.619123680025395\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6229324432251411\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6267031187928896\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6304360876049607\n",
      "resetting env. episode reward total was 4.0. running mean: -0.5841317267289111\n",
      "resetting env. episode reward total was -11.0. running mean: -0.688290409461622\n",
      "resetting env. episode reward total was 2.0. running mean: -0.6614075053670058\n",
      "resetting env. episode reward total was 7.0. running mean: -0.5847934303133357\n",
      "resetting env. episode reward total was -18.0. running mean: -0.7589454960102024\n",
      "resetting env. episode reward total was -4.0. running mean: -0.7913560410501005\n",
      "resetting env. episode reward total was 2.0. running mean: -0.7634424806395994\n",
      "resetting env. episode reward total was -3.0. running mean: -0.7858080558332035\n",
      "resetting env. episode reward total was -7.0. running mean: -0.8479499752748714\n",
      "resetting env. episode reward total was 2.0. running mean: -0.8194704755221226\n",
      "resetting env. episode reward total was 6.0. running mean: -0.7512757707669013\n",
      "resetting env. episode reward total was -1.0. running mean: -0.7537630130592323\n",
      "resetting env. episode reward total was 10.0. running mean: -0.6462253829286401\n",
      "resetting env. episode reward total was -11.0. running mean: -0.7497631290993536\n",
      "resetting env. episode reward total was -1.0. running mean: -0.75226549780836\n",
      "resetting env. episode reward total was 5.0. running mean: -0.6947428428302764\n",
      "resetting env. episode reward total was -6.0. running mean: -0.7477954144019736\n",
      "resetting env. episode reward total was 2.0. running mean: -0.7203174602579538\n",
      "resetting env. episode reward total was -3.0. running mean: -0.7431142856553743\n",
      "resetting env. episode reward total was -4.0. running mean: -0.7756831427988206\n",
      "resetting env. episode reward total was -11.0. running mean: -0.8779263113708323\n",
      "resetting env. episode reward total was 8.0. running mean: -0.789147048257124\n",
      "resetting env. episode reward total was 11.0. running mean: -0.6712555777745528\n",
      "resetting env. episode reward total was -11.0. running mean: -0.7745430219968072\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8267975917768391\n",
      "resetting env. episode reward total was 6.0. running mean: -0.7585296158590706\n",
      "resetting env. episode reward total was 1.0. running mean: -0.7409443197004799\n",
      "resetting env. episode reward total was 14.0. running mean: -0.5935348765034751\n",
      "resetting env. episode reward total was -5.0. running mean: -0.6375995277384404\n",
      "resetting env. episode reward total was -21.0. running mean: -0.841223532461056\n",
      "resetting env. episode reward total was -6.0. running mean: -0.8928112971364455\n",
      "resetting env. episode reward total was -8.0. running mean: -0.963883184165081\n",
      "resetting env. episode reward total was -6.0. running mean: -1.0142443523234301\n",
      "resetting env. episode reward total was 5.0. running mean: -0.9541019088001959\n",
      "resetting env. episode reward total was -5.0. running mean: -0.9945608897121939\n",
      "resetting env. episode reward total was 2.0. running mean: -0.964615280815072\n",
      "resetting env. episode reward total was -7.0. running mean: -1.0249691280069213\n",
      "resetting env. episode reward total was 9.0. running mean: -0.9247194367268522\n",
      "resetting env. episode reward total was 4.0. running mean: -0.8754722423595837\n",
      "resetting env. episode reward total was -6.0. running mean: -0.9267175199359878\n",
      "resetting env. episode reward total was -11.0. running mean: -1.0274503447366279\n",
      "resetting env. episode reward total was 5.0. running mean: -0.9671758412892615\n",
      "resetting env. episode reward total was -12.0. running mean: -1.077504082876369\n",
      "resetting env. episode reward total was 1.0. running mean: -1.0567290420476052\n",
      "resetting env. episode reward total was -6.0. running mean: -1.1061617516271292\n",
      "resetting env. episode reward total was 4.0. running mean: -1.055100134110858\n",
      "resetting env. episode reward total was 8.0. running mean: -0.9645491327697494\n",
      "resetting env. episode reward total was 6.0. running mean: -0.8949036414420519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: -0.8659546050276313\n",
      "resetting env. episode reward total was -3.0. running mean: -0.8872950589773551\n",
      "resetting env. episode reward total was -6.0. running mean: -0.9384221083875814\n",
      "resetting env. episode reward total was -3.0. running mean: -0.9590378873037056\n",
      "resetting env. episode reward total was 4.0. running mean: -0.9094475084306686\n",
      "resetting env. episode reward total was -6.0. running mean: -0.9603530333463619\n",
      "resetting env. episode reward total was 13.0. running mean: -0.8207495030128983\n",
      "resetting env. episode reward total was 1.0. running mean: -0.8025420079827693\n",
      "resetting env. episode reward total was 12.0. running mean: -0.6745165879029417\n",
      "resetting env. episode reward total was 7.0. running mean: -0.5977714220239123\n",
      "resetting env. episode reward total was 1.0. running mean: -0.5817937078036731\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5859757707256364\n",
      "resetting env. episode reward total was 6.0. running mean: -0.5201160130183802\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5249148528881964\n",
      "resetting env. episode reward total was 4.0. running mean: -0.4796657043593145\n",
      "resetting env. episode reward total was -5.0. running mean: -0.5248690473157214\n",
      "resetting env. episode reward total was 6.0. running mean: -0.45962035684256414\n",
      "resetting env. episode reward total was -7.0. running mean: -0.5250241532741384\n",
      "resetting env. episode reward total was 4.0. running mean: -0.4797739117413971\n",
      "resetting env. episode reward total was 2.0. running mean: -0.4549761726239831\n",
      "resetting env. episode reward total was -1.0. running mean: -0.4604264108977433\n",
      "resetting env. episode reward total was 15.0. running mean: -0.30582214678876585\n",
      "resetting env. episode reward total was -9.0. running mean: -0.3927639253208782\n",
      "resetting env. episode reward total was -8.0. running mean: -0.46883628606766947\n",
      "resetting env. episode reward total was -9.0. running mean: -0.5541479232069928\n",
      "resetting env. episode reward total was -1.0. running mean: -0.5586064439749229\n",
      "resetting env. episode reward total was -8.0. running mean: -0.6330203795351736\n",
      "resetting env. episode reward total was 2.0. running mean: -0.6066901757398219\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6106232739824237\n",
      "resetting env. episode reward total was -2.0. running mean: -0.6245170412425994\n",
      "resetting env. episode reward total was -1.0. running mean: -0.6282718708301734\n",
      "resetting env. episode reward total was 11.0. running mean: -0.5119891521218717\n",
      "resetting env. episode reward total was 9.0. running mean: -0.416869260600653\n",
      "resetting env. episode reward total was 6.0. running mean: -0.35270056799464644\n",
      "resetting env. episode reward total was -7.0. running mean: -0.4191735623147\n",
      "resetting env. episode reward total was 8.0. running mean: -0.33498182669155296\n",
      "resetting env. episode reward total was 11.0. running mean: -0.22163200842463743\n",
      "resetting env. episode reward total was 5.0. running mean: -0.16941568834039106\n",
      "resetting env. episode reward total was 1.0. running mean: -0.15772153145698714\n",
      "resetting env. episode reward total was 6.0. running mean: -0.09614431614241728\n",
      "resetting env. episode reward total was -5.0. running mean: -0.1451828729809931\n",
      "resetting env. episode reward total was 4.0. running mean: -0.10373104425118318\n",
      "resetting env. episode reward total was 2.0. running mean: -0.08269373380867134\n",
      "resetting env. episode reward total was -1.0. running mean: -0.09186679647058463\n",
      "resetting env. episode reward total was 6.0. running mean: -0.03094812850587879\n",
      "resetting env. episode reward total was -3.0. running mean: -0.06063864722082\n",
      "resetting env. episode reward total was 5.0. running mean: -0.010032260748611792\n",
      "resetting env. episode reward total was 8.0. running mean: 0.07006806185887433\n",
      "resetting env. episode reward total was -3.0. running mean: 0.03936738124028559\n",
      "resetting env. episode reward total was 6.0. running mean: 0.09897370742788272\n",
      "resetting env. episode reward total was 9.0. running mean: 0.1879839703536039\n",
      "resetting env. episode reward total was 4.0. running mean: 0.22610413065006787\n",
      "resetting env. episode reward total was -5.0. running mean: 0.17384308934356718\n",
      "resetting env. episode reward total was 7.0. running mean: 0.24210465845013152\n",
      "resetting env. episode reward total was 10.0. running mean: 0.33968361186563023\n",
      "resetting env. episode reward total was 12.0. running mean: 0.4562867757469739\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5617239079895042\n",
      "resetting env. episode reward total was -5.0. running mean: 0.5061066689096091\n",
      "resetting env. episode reward total was -3.0. running mean: 0.47104560222051295\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5263351461983078\n",
      "resetting env. episode reward total was -7.0. running mean: 0.4510717947363247\n",
      "resetting env. episode reward total was -6.0. running mean: 0.38656107678896146\n",
      "resetting env. episode reward total was -12.0. running mean: 0.26269546602107186\n",
      "resetting env. episode reward total was -8.0. running mean: 0.1800685113608611\n",
      "resetting env. episode reward total was 12.0. running mean: 0.29826782624725245\n",
      "resetting env. episode reward total was -1.0. running mean: 0.28528514798477994\n",
      "resetting env. episode reward total was 4.0. running mean: 0.3224322965049321\n",
      "resetting env. episode reward total was -11.0. running mean: 0.2092079735398828\n",
      "resetting env. episode reward total was -1.0. running mean: 0.19711589380448397\n",
      "resetting env. episode reward total was 8.0. running mean: 0.27514473486643914\n",
      "resetting env. episode reward total was 1.0. running mean: 0.28239328751777476\n",
      "resetting env. episode reward total was -2.0. running mean: 0.259569354642597\n",
      "resetting env. episode reward total was 8.0. running mean: 0.33697366109617105\n",
      "resetting env. episode reward total was -1.0. running mean: 0.3236039244852093\n",
      "resetting env. episode reward total was 7.0. running mean: 0.3903678852403572\n",
      "resetting env. episode reward total was -7.0. running mean: 0.31646420638795364\n",
      "resetting env. episode reward total was 2.0. running mean: 0.3332995643240741\n",
      "resetting env. episode reward total was 7.0. running mean: 0.39996656868083336\n",
      "resetting env. episode reward total was 2.0. running mean: 0.41596690299402506\n",
      "resetting env. episode reward total was 1.0. running mean: 0.4218072339640848\n",
      "resetting env. episode reward total was 2.0. running mean: 0.437589161624444\n",
      "resetting env. episode reward total was 8.0. running mean: 0.5132132700081995\n",
      "resetting env. episode reward total was 3.0. running mean: 0.5380811373081176\n",
      "resetting env. episode reward total was -9.0. running mean: 0.4427003259350364\n",
      "resetting env. episode reward total was 8.0. running mean: 0.518273322675686\n",
      "resetting env. episode reward total was -14.0. running mean: 0.37309058944892914\n",
      "resetting env. episode reward total was -1.0. running mean: 0.35935968355443987\n",
      "resetting env. episode reward total was 10.0. running mean: 0.4557660867188955\n",
      "resetting env. episode reward total was -3.0. running mean: 0.4212084258517066\n",
      "resetting env. episode reward total was 8.0. running mean: 0.49699634159318956\n",
      "resetting env. episode reward total was 5.0. running mean: 0.5420263781772576\n",
      "resetting env. episode reward total was -4.0. running mean: 0.496606114395485\n",
      "resetting env. episode reward total was -6.0. running mean: 0.43164005325153015\n",
      "resetting env. episode reward total was -7.0. running mean: 0.35732365271901484\n",
      "resetting env. episode reward total was 10.0. running mean: 0.45375041619182466\n",
      "resetting env. episode reward total was 10.0. running mean: 0.5492129120299064\n",
      "resetting env. episode reward total was 5.0. running mean: 0.5937207829096074\n",
      "resetting env. episode reward total was 2.0. running mean: 0.6077835750805113\n",
      "resetting env. episode reward total was -1.0. running mean: 0.5917057393297062\n",
      "resetting env. episode reward total was -5.0. running mean: 0.535788681936409\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5904307951170449\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5945264871658744\n",
      "resetting env. episode reward total was 8.0. running mean: 0.6685812222942157\n",
      "resetting env. episode reward total was -6.0. running mean: 0.6018954100712735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 2.0. running mean: 0.6158764559705607\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6497176914108551\n",
      "resetting env. episode reward total was -6.0. running mean: 0.5832205144967466\n",
      "resetting env. episode reward total was 9.0. running mean: 0.6673883093517791\n",
      "resetting env. episode reward total was -3.0. running mean: 0.6307144262582612\n",
      "resetting env. episode reward total was 4.0. running mean: 0.6644072819956787\n",
      "resetting env. episode reward total was 11.0. running mean: 0.7677632091757218\n",
      "resetting env. episode reward total was -4.0. running mean: 0.7200855770839646\n",
      "resetting env. episode reward total was -13.0. running mean: 0.582884721313125\n",
      "resetting env. episode reward total was -2.0. running mean: 0.5570558740999937\n",
      "resetting env. episode reward total was -6.0. running mean: 0.4914853153589937\n",
      "resetting env. episode reward total was -2.0. running mean: 0.46657046220540377\n",
      "resetting env. episode reward total was 4.0. running mean: 0.5019047575833497\n",
      "resetting env. episode reward total was -11.0. running mean: 0.38688571000751626\n",
      "resetting env. episode reward total was 9.0. running mean: 0.4730168529074411\n",
      "resetting env. episode reward total was -4.0. running mean: 0.4282866843783667\n",
      "resetting env. episode reward total was 3.0. running mean: 0.4540038175345831\n",
      "resetting env. episode reward total was 6.0. running mean: 0.5094637793592373\n",
      "resetting env. episode reward total was 16.0. running mean: 0.6643691415656449\n",
      "resetting env. episode reward total was -11.0. running mean: 0.5477254501499884\n",
      "resetting env. episode reward total was -4.0. running mean: 0.5022481956484884\n",
      "resetting env. episode reward total was 7.0. running mean: 0.5672257136920036\n",
      "resetting env. episode reward total was -8.0. running mean: 0.4815534565550836\n",
      "resetting env. episode reward total was -5.0. running mean: 0.42673792198953275\n",
      "resetting env. episode reward total was 10.0. running mean: 0.5224705427696374\n",
      "resetting env. episode reward total was -3.0. running mean: 0.48724583734194105\n",
      "resetting env. episode reward total was -9.0. running mean: 0.39237337896852165\n",
      "resetting env. episode reward total was 4.0. running mean: 0.4284496451788364\n",
      "resetting env. episode reward total was 8.0. running mean: 0.504165148727048\n",
      "resetting env. episode reward total was 2.0. running mean: 0.5191234972397775\n",
      "resetting env. episode reward total was 1.0. running mean: 0.5239322622673797\n",
      "resetting env. episode reward total was -7.0. running mean: 0.44869293964470586\n",
      "resetting env. episode reward total was 4.0. running mean: 0.48420601024825877\n",
      "resetting env. episode reward total was -1.0. running mean: 0.46936395014577614\n",
      "resetting env. episode reward total was -1.0. running mean: 0.45467031064431834\n",
      "resetting env. episode reward total was 11.0. running mean: 0.5601236075378752\n",
      "resetting env. episode reward total was 6.0. running mean: 0.6145223714624963\n",
      "resetting env. episode reward total was 7.0. running mean: 0.6783771477478713\n",
      "resetting env. episode reward total was 6.0. running mean: 0.7315933762703926\n",
      "resetting env. episode reward total was 5.0. running mean: 0.7742774425076887\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7465346680826118\n",
      "resetting env. episode reward total was -2.0. running mean: 0.7190693214017857\n",
      "resetting env. episode reward total was 8.0. running mean: 0.7918786281877678\n",
      "resetting env. episode reward total was -5.0. running mean: 0.73395984190589\n",
      "resetting env. episode reward total was 13.0. running mean: 0.8566202434868311\n",
      "resetting env. episode reward total was 1.0. running mean: 0.8580540410519628\n",
      "resetting env. episode reward total was 4.0. running mean: 0.8894735006414433\n",
      "resetting env. episode reward total was -4.0. running mean: 0.8405787656350288\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8221729779786785\n",
      "resetting env. episode reward total was 8.0. running mean: 0.8939512481988917\n",
      "resetting env. episode reward total was -9.0. running mean: 0.7950117357169029\n",
      "resetting env. episode reward total was 3.0. running mean: 0.8170616183597339\n",
      "resetting env. episode reward total was -4.0. running mean: 0.7688910021761365\n",
      "resetting env. episode reward total was 6.0. running mean: 0.821202092154375\n",
      "resetting env. episode reward total was -5.0. running mean: 0.7629900712328312\n",
      "resetting env. episode reward total was 5.0. running mean: 0.805360170520503\n",
      "resetting env. episode reward total was 7.0. running mean: 0.8673065688152979\n",
      "resetting env. episode reward total was -1.0. running mean: 0.8486335031271449\n",
      "resetting env. episode reward total was 13.0. running mean: 0.9701471680958734\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0004456964149147\n",
      "resetting env. episode reward total was 4.0. running mean: 1.0304412394507654\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0101368270562576\n",
      "resetting env. episode reward total was 12.0. running mean: 1.1200354587856949\n",
      "resetting env. episode reward total was -9.0. running mean: 1.0188351041978378\n",
      "resetting env. episode reward total was -4.0. running mean: 0.9686467531558594\n",
      "resetting env. episode reward total was 8.0. running mean: 1.0389602856243008\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0585706827680579\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0779849759403772\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9972051261809733\n",
      "resetting env. episode reward total was 1.0. running mean: 0.9972330749191636\n",
      "resetting env. episode reward total was 6.0. running mean: 1.047260744169972\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0267881367282723\n",
      "resetting env. episode reward total was -7.0. running mean: 0.9465202553609895\n",
      "resetting env. episode reward total was -6.0. running mean: 0.8770550528073795\n",
      "resetting env. episode reward total was -3.0. running mean: 0.8382845022793056\n",
      "resetting env. episode reward total was 6.0. running mean: 0.8899016572565126\n",
      "resetting env. episode reward total was 8.0. running mean: 0.9610026406839475\n",
      "resetting env. episode reward total was 14.0. running mean: 1.091392614277108\n",
      "resetting env. episode reward total was -3.0. running mean: 1.0504786881343369\n",
      "resetting env. episode reward total was 13.0. running mean: 1.1699739012529933\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1982741622404633\n",
      "resetting env. episode reward total was 9.0. running mean: 1.276291420618059\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3035285064118782\n",
      "resetting env. episode reward total was -7.0. running mean: 1.2204932213477593\n",
      "resetting env. episode reward total was 1.0. running mean: 1.2182882891342817\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2561054062429389\n",
      "resetting env. episode reward total was -7.0. running mean: 1.1735443521805093\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2118089086587043\n",
      "resetting env. episode reward total was -11.0. running mean: 1.089690819572117\n",
      "resetting env. episode reward total was 8.0. running mean: 1.158793911376396\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2072059722626323\n",
      "resetting env. episode reward total was 5.0. running mean: 1.245133912540006\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3026825734146061\n",
      "resetting env. episode reward total was 1.0. running mean: 1.29965574768046\n",
      "resetting env. episode reward total was -8.0. running mean: 1.2066591902036554\n",
      "resetting env. episode reward total was -1.0. running mean: 1.1845925983016188\n",
      "resetting env. episode reward total was 8.0. running mean: 1.2527466723186027\n",
      "resetting env. episode reward total was -9.0. running mean: 1.1502192055954166\n",
      "resetting env. episode reward total was -4.0. running mean: 1.0987170135394624\n",
      "resetting env. episode reward total was -6.0. running mean: 1.0277298434040676\n",
      "resetting env. episode reward total was -5.0. running mean: 0.9674525449700269\n",
      "resetting env. episode reward total was 11.0. running mean: 1.0677780195203266\n",
      "resetting env. episode reward total was -1.0. running mean: 1.0471002393251232\n",
      "resetting env. episode reward total was 10.0. running mean: 1.136629236931872\n",
      "resetting env. episode reward total was 2.0. running mean: 1.1452629445625533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 1.0. running mean: 1.1438103151169277\n",
      "resetting env. episode reward total was -12.0. running mean: 1.0123722119657583\n",
      "resetting env. episode reward total was 3.0. running mean: 1.0322484898461008\n",
      "resetting env. episode reward total was 2.0. running mean: 1.0419260049476398\n",
      "resetting env. episode reward total was 13.0. running mean: 1.1615067448981633\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2098916774491817\n",
      "resetting env. episode reward total was 11.0. running mean: 1.30779276067469\n",
      "resetting env. episode reward total was 5.0. running mean: 1.344714833067943\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3912676847372636\n",
      "resetting env. episode reward total was 5.0. running mean: 1.427355007889891\n",
      "resetting env. episode reward total was 8.0. running mean: 1.493081457810992\n",
      "resetting env. episode reward total was -13.0. running mean: 1.348150643232882\n",
      "resetting env. episode reward total was 6.0. running mean: 1.3946691368005533\n",
      "resetting env. episode reward total was 8.0. running mean: 1.4607224454325478\n",
      "resetting env. episode reward total was 5.0. running mean: 1.4961152209782225\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5511540687684402\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5756425280807558\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6298861027999483\n",
      "resetting env. episode reward total was -4.0. running mean: 1.5735872417719488\n",
      "resetting env. episode reward total was 10.0. running mean: 1.6578513693542294\n",
      "resetting env. episode reward total was 2.0. running mean: 1.661272855660687\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6946601271040802\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7577135258330394\n",
      "resetting env. episode reward total was 12.0. running mean: 1.8601363905747088\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8915350266689617\n",
      "resetting env. episode reward total was 7.0. running mean: 1.942619676402272\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9531934796382493\n",
      "resetting env. episode reward total was 2.0. running mean: 1.9536615448418668\n",
      "resetting env. episode reward total was 10.0. running mean: 2.0341249293934482\n",
      "resetting env. episode reward total was -1.0. running mean: 2.003783680099514\n",
      "resetting env. episode reward total was 12.0. running mean: 2.1037458432985185\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0327083848655336\n",
      "resetting env. episode reward total was 2.0. running mean: 2.032381301016878\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0520574880067093\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9715369131266423\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0118215439953757\n",
      "resetting env. episode reward total was 4.0. running mean: 2.031703328555422\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0213862952698674\n",
      "resetting env. episode reward total was 6.0. running mean: 2.0611724323171687\n",
      "resetting env. episode reward total was 2.0. running mean: 2.060560707993997\n",
      "resetting env. episode reward total was -8.0. running mean: 1.959955100914057\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9503555499049163\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9808519944058671\n",
      "resetting env. episode reward total was -6.0. running mean: 1.9010434744618083\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9220330397171903\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8728127093200184\n",
      "resetting env. episode reward total was -6.0. running mean: 1.794084582226818\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8061437364045498\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8580822990405044\n",
      "resetting env. episode reward total was -8.0. running mean: 1.7595014760500993\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8019064612895983\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8238873966767024\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8156485227099355\n",
      "resetting env. episode reward total was 1.0. running mean: 1.807492037482836\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8594171171080078\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8608229459369277\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8622147164775584\n",
      "resetting env. episode reward total was -13.0. running mean: 1.713592569312783\n",
      "resetting env. episode reward total was -5.0. running mean: 1.646456643619655\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5999920771834584\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6239921564116238\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6277522348475075\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6414747124990325\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5750599653740422\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5493093657203019\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5138162720630988\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5686781093424678\n",
      "resetting env. episode reward total was -5.0. running mean: 1.502991328249043\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5479614149665526\n",
      "resetting env. episode reward total was -9.0. running mean: 1.442481800816887\n",
      "resetting env. episode reward total was 5.0. running mean: 1.478056982808718\n",
      "resetting env. episode reward total was -9.0. running mean: 1.3732764129806307\n",
      "resetting env. episode reward total was 9.0. running mean: 1.4495436488508244\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5050482123623163\n",
      "resetting env. episode reward total was -1.0. running mean: 1.479997730238693\n",
      "resetting env. episode reward total was 6.0. running mean: 1.525197752936306\n",
      "resetting env. episode reward total was -6.0. running mean: 1.449945775406943\n",
      "resetting env. episode reward total was 12.0. running mean: 1.5554463176528737\n",
      "resetting env. episode reward total was 8.0. running mean: 1.619891854476345\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6636929359315815\n",
      "resetting env. episode reward total was 8.0. running mean: 1.7270560065722658\n",
      "resetting env. episode reward total was -10.0. running mean: 1.609785446506543\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6636875920414778\n",
      "resetting env. episode reward total was -3.0. running mean: 1.617050716121063\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6408802089598524\n",
      "resetting env. episode reward total was 7.0. running mean: 1.694471406870254\n",
      "resetting env. episode reward total was 11.0. running mean: 1.7875266928015516\n",
      "resetting env. episode reward total was 2.0. running mean: 1.789651425873536\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8417549116148009\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8033373624986528\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8353039888736664\n",
      "resetting env. episode reward total was -11.0. running mean: 1.7069509489849297\n",
      "resetting env. episode reward total was -11.0. running mean: 1.5798814394950802\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6040826251001294\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5680417988491282\n",
      "resetting env. episode reward total was 1.0. running mean: 1.562361380860637\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6267377670520307\n",
      "resetting env. episode reward total was -10.0. running mean: 1.5104703893815103\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5253656854876954\n",
      "resetting env. episode reward total was 13.0. running mean: 1.6401120286328186\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6537109083464905\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6671737992630256\n",
      "resetting env. episode reward total was 11.0. running mean: 1.7605020612703954\n",
      "resetting env. episode reward total was -3.0. running mean: 1.7128970406576913\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7257680702511144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 5.0. running mean: 1.7585103895486034\n",
      "resetting env. episode reward total was -1.0. running mean: 1.7309252856531174\n",
      "resetting env. episode reward total was 11.0. running mean: 1.8236160327965862\n",
      "resetting env. episode reward total was 8.0. running mean: 1.8853798724686204\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8865260737439342\n",
      "resetting env. episode reward total was 9.0. running mean: 1.957660813006495\n",
      "resetting env. episode reward total was 5.0. running mean: 1.98808420487643\n",
      "resetting env. episode reward total was -2.0. running mean: 1.9482033628276656\n",
      "resetting env. episode reward total was -7.0. running mean: 1.858721329199389\n",
      "resetting env. episode reward total was -1.0. running mean: 1.830134115907395\n",
      "resetting env. episode reward total was 4.0. running mean: 1.851832774748321\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7833144470008377\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7854813025308294\n",
      "resetting env. episode reward total was 10.0. running mean: 1.8676264895055212\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8989502246104661\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9299607223643616\n",
      "resetting env. episode reward total was -10.0. running mean: 1.810661115140718\n",
      "resetting env. episode reward total was 9.0. running mean: 1.8825545039893108\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9137289589494177\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9545916693599237\n",
      "resetting env. episode reward total was -7.0. running mean: 1.8650457526663244\n",
      "resetting env. episode reward total was -6.0. running mean: 1.786395295139661\n",
      "resetting env. episode reward total was 10.0. running mean: 1.8685313421882646\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8998460287663819\n",
      "resetting env. episode reward total was -11.0. running mean: 1.770847568478718\n",
      "resetting env. episode reward total was 10.0. running mean: 1.8531390927939309\n",
      "resetting env. episode reward total was 9.0. running mean: 1.9246077018659915\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8853616248473315\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9465080085988582\n",
      "resetting env. episode reward total was 6.0. running mean: 1.9870429285128697\n",
      "resetting env. episode reward total was 5.0. running mean: 2.017172499227741\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9470007742354634\n",
      "resetting env. episode reward total was -5.0. running mean: 1.8775307664931087\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9087554588281777\n",
      "resetting env. episode reward total was -1.0. running mean: 1.8796679042398958\n",
      "resetting env. episode reward total was -4.0. running mean: 1.8208712251974968\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8426625129455219\n",
      "resetting env. episode reward total was -6.0. running mean: 1.7642358878160667\n",
      "resetting env. episode reward total was 8.0. running mean: 1.826593528937906\n",
      "resetting env. episode reward total was -2.0. running mean: 1.788327593648527\n",
      "resetting env. episode reward total was 11.0. running mean: 1.8804443177120418\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8816398745349214\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9028234757895723\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9637952410316766\n",
      "resetting env. episode reward total was 5.0. running mean: 1.9941572886213599\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0142157157351464\n",
      "resetting env. episode reward total was 8.0. running mean: 2.074073558577795\n",
      "resetting env. episode reward total was 11.0. running mean: 2.163332822992017\n",
      "resetting env. episode reward total was -7.0. running mean: 2.071699494762097\n",
      "resetting env. episode reward total was -2.0. running mean: 2.030982499814476\n",
      "resetting env. episode reward total was 1.0. running mean: 2.020672674816331\n",
      "resetting env. episode reward total was 4.0. running mean: 2.0404659480681677\n",
      "resetting env. episode reward total was 10.0. running mean: 2.120061288587486\n",
      "resetting env. episode reward total was -3.0. running mean: 2.0688606757016115\n",
      "resetting env. episode reward total was 13.0. running mean: 2.1781720689445954\n",
      "resetting env. episode reward total was 13.0. running mean: 2.286390348255149\n",
      "resetting env. episode reward total was -5.0. running mean: 2.2135264447725977\n",
      "resetting env. episode reward total was 1.0. running mean: 2.2013911803248716\n",
      "resetting env. episode reward total was 4.0. running mean: 2.219377268521623\n",
      "resetting env. episode reward total was -2.0. running mean: 2.1771834958364065\n",
      "resetting env. episode reward total was -10.0. running mean: 2.0554116608780424\n",
      "resetting env. episode reward total was -7.0. running mean: 1.9648575442692617\n",
      "resetting env. episode reward total was -3.0. running mean: 1.915208968826569\n",
      "resetting env. episode reward total was -15.0. running mean: 1.7460568791383033\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7385963103469202\n",
      "resetting env. episode reward total was 4.0. running mean: 1.761210347243451\n",
      "resetting env. episode reward total was -11.0. running mean: 1.6335982437710164\n",
      "resetting env. episode reward total was -8.0. running mean: 1.537262261333306\n",
      "resetting env. episode reward total was -3.0. running mean: 1.491889638719973\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5169707423327732\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5718010349094456\n",
      "resetting env. episode reward total was -5.0. running mean: 1.5060830245603511\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5910221943147478\n",
      "resetting env. episode reward total was 5.0. running mean: 1.6251119723716003\n",
      "resetting env. episode reward total was -9.0. running mean: 1.5188608526478842\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5236722441214052\n",
      "resetting env. episode reward total was 11.0. running mean: 1.6184355216801913\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6622511664633894\n",
      "resetting env. episode reward total was 14.0. running mean: 1.7856286547987557\n",
      "resetting env. episode reward total was -1.0. running mean: 1.757772368250768\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7801946445682604\n",
      "resetting env. episode reward total was 6.0. running mean: 1.8223926981225778\n",
      "resetting env. episode reward total was 5.0. running mean: 1.854168771141352\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8656270834299384\n",
      "resetting env. episode reward total was -5.0. running mean: 1.796970812595639\n",
      "resetting env. episode reward total was -10.0. running mean: 1.6790011044696824\n",
      "resetting env. episode reward total was 9.0. running mean: 1.7522110934249857\n",
      "resetting env. episode reward total was -13.0. running mean: 1.6046889824907358\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6486420926658285\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6021556717391703\n",
      "resetting env. episode reward total was -3.0. running mean: 1.5561341150217785\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5305727738715607\n",
      "resetting env. episode reward total was -4.0. running mean: 1.475267046132845\n",
      "resetting env. episode reward total was 2.0. running mean: 1.4805143756715164\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5257092319148013\n",
      "resetting env. episode reward total was 7.0. running mean: 1.5804521395956534\n",
      "resetting env. episode reward total was 2.0. running mean: 1.584647618199697\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5588011420177\n",
      "resetting env. episode reward total was -1.0. running mean: 1.533213130597523\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5078809992915476\n",
      "resetting env. episode reward total was 8.0. running mean: 1.5728021892986321\n",
      "resetting env. episode reward total was 6.0. running mean: 1.617074167405646\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6309034257315895\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6945943914742736\n",
      "resetting env. episode reward total was 3.0. running mean: 1.7076484475595308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 1.7705719630839356\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8028662434530962\n",
      "resetting env. episode reward total was 14.0. running mean: 1.9248375810185654\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9155892052083798\n",
      "resetting env. episode reward total was -9.0. running mean: 1.806433313156296\n",
      "resetting env. episode reward total was -1.0. running mean: 1.7783689800247329\n",
      "resetting env. episode reward total was -11.0. running mean: 1.6505852902244855\n",
      "resetting env. episode reward total was 11.0. running mean: 1.7440794373222408\n",
      "resetting env. episode reward total was -1.0. running mean: 1.7166386429490184\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7494722565195282\n",
      "resetting env. episode reward total was 4.0. running mean: 1.7719775339543329\n",
      "resetting env. episode reward total was -5.0. running mean: 1.7042577586147896\n",
      "resetting env. episode reward total was 12.0. running mean: 1.8072151810286416\n",
      "resetting env. episode reward total was 4.0. running mean: 1.8291430292183553\n",
      "resetting env. episode reward total was 9.0. running mean: 1.9008515989261718\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9618430829369102\n",
      "resetting env. episode reward total was 1.0. running mean: 1.952224652107541\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9427024055864657\n",
      "resetting env. episode reward total was -8.0. running mean: 1.8432753815306009\n",
      "resetting env. episode reward total was 3.0. running mean: 1.854842627715295\n",
      "resetting env. episode reward total was 6.0. running mean: 1.896294201438142\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8573312594237605\n",
      "resetting env. episode reward total was 1.0. running mean: 1.848757946829523\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8002703673612277\n",
      "resetting env. episode reward total was -4.0. running mean: 1.7422676636876153\n",
      "resetting env. episode reward total was 2.0. running mean: 1.7448449870507392\n",
      "resetting env. episode reward total was 1.0. running mean: 1.7373965371802318\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7700225718084295\n",
      "resetting env. episode reward total was 12.0. running mean: 1.8723223460903453\n",
      "resetting env. episode reward total was -3.0. running mean: 1.823599122629442\n",
      "resetting env. episode reward total was 3.0. running mean: 1.8353631314031476\n",
      "resetting env. episode reward total was -8.0. running mean: 1.737009500089116\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6696394050882246\n",
      "resetting env. episode reward total was -7.0. running mean: 1.5829430110373424\n",
      "resetting env. episode reward total was 1.0. running mean: 1.577113580926969\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5813424451176992\n",
      "resetting env. episode reward total was 1.0. running mean: 1.5755290206665222\n",
      "resetting env. episode reward total was 4.0. running mean: 1.599773730459857\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6037759931552584\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5677382332237058\n",
      "resetting env. episode reward total was -8.0. running mean: 1.4720608508914685\n",
      "resetting env. episode reward total was 10.0. running mean: 1.557340242382554\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5617668399587283\n",
      "resetting env. episode reward total was 3.0. running mean: 1.5761491715591411\n",
      "resetting env. episode reward total was 6.0. running mean: 1.6203876798435497\n",
      "resetting env. episode reward total was -3.0. running mean: 1.574183803045114\n",
      "resetting env. episode reward total was -1.0. running mean: 1.5484419650146628\n",
      "resetting env. episode reward total was 15.0. running mean: 1.682957545364516\n",
      "resetting env. episode reward total was -12.0. running mean: 1.546127969910871\n",
      "resetting env. episode reward total was 4.0. running mean: 1.5706666902117623\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5749600233096448\n",
      "resetting env. episode reward total was -2.0. running mean: 1.5392104230765482\n",
      "resetting env. episode reward total was -10.0. running mean: 1.4238183188457827\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3995801356573248\n",
      "resetting env. episode reward total was 3.0. running mean: 1.4155843343007515\n",
      "resetting env. episode reward total was -2.0. running mean: 1.381428490957744\n",
      "resetting env. episode reward total was 3.0. running mean: 1.3976142060481664\n",
      "resetting env. episode reward total was -8.0. running mean: 1.3036380639876848\n",
      "resetting env. episode reward total was 5.0. running mean: 1.340601683347808\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3171956665143298\n",
      "resetting env. episode reward total was -6.0. running mean: 1.2440237098491864\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2815834727506945\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3087676380231876\n",
      "resetting env. episode reward total was 14.0. running mean: 1.4356799616429559\n",
      "resetting env. episode reward total was -1.0. running mean: 1.4113231620265263\n",
      "resetting env. episode reward total was -1.0. running mean: 1.387209930406261\n",
      "resetting env. episode reward total was -7.0. running mean: 1.3033378311021984\n",
      "resetting env. episode reward total was 10.0. running mean: 1.3903044527911765\n",
      "resetting env. episode reward total was 10.0. running mean: 1.4764014082632648\n",
      "resetting env. episode reward total was -6.0. running mean: 1.4016373941806322\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3776210202388257\n",
      "resetting env. episode reward total was 7.0. running mean: 1.4338448100364376\n",
      "resetting env. episode reward total was 13.0. running mean: 1.5495063619360732\n",
      "resetting env. episode reward total was -7.0. running mean: 1.4640112983167124\n",
      "resetting env. episode reward total was 6.0. running mean: 1.5093711853335454\n",
      "resetting env. episode reward total was 8.0. running mean: 1.57427747348021\n",
      "resetting env. episode reward total was -3.0. running mean: 1.528534698745408\n",
      "resetting env. episode reward total was -2.0. running mean: 1.493249351757954\n",
      "resetting env. episode reward total was -4.0. running mean: 1.4383168582403743\n",
      "resetting env. episode reward total was 10.0. running mean: 1.5239336896579705\n",
      "resetting env. episode reward total was 2.0. running mean: 1.5286943527613908\n",
      "resetting env. episode reward total was -10.0. running mean: 1.4134074092337767\n",
      "resetting env. episode reward total was -2.0. running mean: 1.379273335141439\n",
      "resetting env. episode reward total was -1.0. running mean: 1.3554806017900245\n",
      "resetting env. episode reward total was 4.0. running mean: 1.3819257957721243\n",
      "resetting env. episode reward total was -5.0. running mean: 1.318106537814403\n",
      "resetting env. episode reward total was -10.0. running mean: 1.2049254724362588\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2428762177118962\n",
      "resetting env. episode reward total was 1.0. running mean: 1.240447455534777\n",
      "resetting env. episode reward total was -7.0. running mean: 1.1580429809794293\n",
      "resetting env. episode reward total was -5.0. running mean: 1.0964625511696349\n",
      "resetting env. episode reward total was 4.0. running mean: 1.1254979256579385\n",
      "resetting env. episode reward total was 7.0. running mean: 1.184242946401359\n",
      "resetting env. episode reward total was 6.0. running mean: 1.2324005169373455\n",
      "resetting env. episode reward total was 5.0. running mean: 1.2700765117679722\n",
      "resetting env. episode reward total was 3.0. running mean: 1.2873757466502924\n",
      "resetting env. episode reward total was 7.0. running mean: 1.3445019891837895\n",
      "resetting env. episode reward total was 2.0. running mean: 1.3510569692919516\n",
      "resetting env. episode reward total was 7.0. running mean: 1.407546399599032\n",
      "resetting env. episode reward total was 11.0. running mean: 1.5034709356030418\n",
      "resetting env. episode reward total was 9.0. running mean: 1.5784362262470115\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6326518639845415\n",
      "resetting env. episode reward total was 7.0. running mean: 1.6863253453446962\n",
      "resetting env. episode reward total was 5.0. running mean: 1.7194620918912493\n",
      "resetting env. episode reward total was -3.0. running mean: 1.6722674709723369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 8.0. running mean: 1.7355447962626136\n",
      "resetting env. episode reward total was -1.0. running mean: 1.7081893482999875\n",
      "resetting env. episode reward total was -7.0. running mean: 1.6211074548169875\n",
      "resetting env. episode reward total was 3.0. running mean: 1.6348963802688177\n",
      "resetting env. episode reward total was 8.0. running mean: 1.6985474164661296\n",
      "resetting env. episode reward total was -1.0. running mean: 1.6715619423014683\n",
      "resetting env. episode reward total was 2.0. running mean: 1.6748463228784536\n",
      "resetting env. episode reward total was 5.0. running mean: 1.708097859649669\n",
      "resetting env. episode reward total was -5.0. running mean: 1.6410168810531722\n",
      "resetting env. episode reward total was 4.0. running mean: 1.6646067122426405\n",
      "resetting env. episode reward total was 9.0. running mean: 1.737960645120214\n",
      "resetting env. episode reward total was 7.0. running mean: 1.790581038669012\n",
      "resetting env. episode reward total was 9.0. running mean: 1.862675228282322\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8240484759994988\n",
      "resetting env. episode reward total was 14.0. running mean: 1.9458079912395037\n",
      "resetting env. episode reward total was -1.0. running mean: 1.9163499113271085\n",
      "resetting env. episode reward total was -8.0. running mean: 1.8171864122138373\n",
      "resetting env. episode reward total was 5.0. running mean: 1.8490145480916989\n",
      "resetting env. episode reward total was -3.0. running mean: 1.8005244026107818\n",
      "resetting env. episode reward total was 5.0. running mean: 1.832519158584674\n",
      "resetting env. episode reward total was 1.0. running mean: 1.8241939669988274\n",
      "resetting env. episode reward total was 2.0. running mean: 1.8259520273288392\n",
      "resetting env. episode reward total was 11.0. running mean: 1.9176925070555508\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9285155819849953\n",
      "resetting env. episode reward total was -2.0. running mean: 1.8892304261651454\n",
      "resetting env. episode reward total was -7.0. running mean: 1.8003381219034937\n",
      "resetting env. episode reward total was 7.0. running mean: 1.8523347406844588\n",
      "resetting env. episode reward total was -4.0. running mean: 1.793811393277614\n",
      "resetting env. episode reward total was -9.0. running mean: 1.6858732793448379\n",
      "resetting env. episode reward total was 12.0. running mean: 1.7890145465513894\n",
      "resetting env. episode reward total was 10.0. running mean: 1.8711244010858756\n",
      "resetting env. episode reward total was 7.0. running mean: 1.922413157075017\n",
      "resetting env. episode reward total was -4.0. running mean: 1.8631890255042667\n",
      "resetting env. episode reward total was 8.0. running mean: 1.9245571352492241\n",
      "resetting env. episode reward total was 3.0. running mean: 1.935311563896732\n",
      "resetting env. episode reward total was 4.0. running mean: 1.9559584482577648\n",
      "resetting env. episode reward total was 1.0. running mean: 1.946398863775187\n",
      "resetting env. episode reward total was 10.0. running mean: 2.026934875137435\n",
      "resetting env. episode reward total was 5.0. running mean: 2.0566655263860607\n",
      "resetting env. episode reward total was -5.0. running mean: 1.9860988711222\n",
      "resetting env. episode reward total was -1.0. running mean: 1.956237882410978\n",
      "resetting env. episode reward total was 12.0. running mean: 2.0566755035868685\n",
      "resetting env. episode reward total was 10.0. running mean: 2.136108748551\n",
      "resetting env. episode reward total was 8.0. running mean: 2.19474766106549\n",
      "resetting env. episode reward total was 1.0. running mean: 2.182800184454835\n",
      "resetting env. episode reward total was -9.0. running mean: 2.0709721826102867\n",
      "resetting env. episode reward total was 1.0. running mean: 2.0602624607841835\n",
      "resetting env. episode reward total was -1.0. running mean: 2.029659836176342\n",
      "resetting env. episode reward total was 8.0. running mean: 2.0893632378145788\n",
      "resetting env. episode reward total was -1.0. running mean: 2.058469605436433\n",
      "resetting env. episode reward total was 13.0. running mean: 2.1678849093820687\n",
      "resetting env. episode reward total was -5.0. running mean: 2.096206060288248\n",
      "resetting env. episode reward total was -3.0. running mean: 2.0452439996853657\n",
      "resetting env. episode reward total was -3.0. running mean: 1.994791559688512\n",
      "resetting env. episode reward total was 10.0. running mean: 2.0748436440916267\n",
      "resetting env. episode reward total was -2.0. running mean: 2.03409520765071\n",
      "resetting env. episode reward total was 1.0. running mean: 2.023754255574203\n",
      "resetting env. episode reward total was 9.0. running mean: 2.093516713018461\n",
      "resetting env. episode reward total was 1.0. running mean: 2.082581545888276\n",
      "resetting env. episode reward total was -4.0. running mean: 2.021755730429393\n",
      "resetting env. episode reward total was 7.0. running mean: 2.071538173125099\n",
      "resetting env. episode reward total was -3.0. running mean: 2.020822791393848\n",
      "resetting env. episode reward total was 8.0. running mean: 2.0806145634799096\n",
      "resetting env. episode reward total was -5.0. running mean: 2.0098084178451106\n",
      "resetting env. episode reward total was 13.0. running mean: 2.1197103336666596\n",
      "resetting env. episode reward total was 1.0. running mean: 2.1085132303299927\n",
      "resetting env. episode reward total was 12.0. running mean: 2.2074280980266927\n",
      "resetting env. episode reward total was 12.0. running mean: 2.305353817046426\n",
      "resetting env. episode reward total was 4.0. running mean: 2.3223002788759617\n",
      "resetting env. episode reward total was -3.0. running mean: 2.269077276087202\n",
      "resetting env. episode reward total was 1.0. running mean: 2.25638650332633\n",
      "resetting env. episode reward total was 7.0. running mean: 2.3038226382930667\n",
      "resetting env. episode reward total was -9.0. running mean: 2.190784411910136\n",
      "resetting env. episode reward total was 10.0. running mean: 2.2688765677910347\n",
      "resetting env. episode reward total was 17.0. running mean: 2.4161878021131242\n",
      "resetting env. episode reward total was 1.0. running mean: 2.402025924091993\n",
      "resetting env. episode reward total was 6.0. running mean: 2.438005664851073\n",
      "resetting env. episode reward total was 4.0. running mean: 2.4536256082025623\n",
      "resetting env. episode reward total was -2.0. running mean: 2.4090893521205365\n",
      "resetting env. episode reward total was 10.0. running mean: 2.4849984585993314\n",
      "resetting env. episode reward total was 12.0. running mean: 2.5801484740133382\n",
      "resetting env. episode reward total was -6.0. running mean: 2.494346989273205\n",
      "resetting env. episode reward total was 2.0. running mean: 2.4894035193804727\n",
      "resetting env. episode reward total was 3.0. running mean: 2.4945094841866675\n",
      "resetting env. episode reward total was 7.0. running mean: 2.5395643893448008\n",
      "resetting env. episode reward total was 5.0. running mean: 2.5641687454513526\n",
      "resetting env. episode reward total was -2.0. running mean: 2.518527057996839\n",
      "resetting env. episode reward total was 2.0. running mean: 2.513341787416871\n",
      "resetting env. episode reward total was 8.0. running mean: 2.568208369542702\n",
      "resetting env. episode reward total was 10.0. running mean: 2.642526285847275\n",
      "resetting env. episode reward total was 9.0. running mean: 2.706101022988802\n",
      "resetting env. episode reward total was -5.0. running mean: 2.629040012758914\n",
      "resetting env. episode reward total was 1.0. running mean: 2.6127496126313248\n",
      "resetting env. episode reward total was -9.0. running mean: 2.4966221165050118\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5016558953399612\n",
      "resetting env. episode reward total was 7.0. running mean: 2.5466393363865616\n",
      "resetting env. episode reward total was 11.0. running mean: 2.6311729430226958\n",
      "resetting env. episode reward total was -12.0. running mean: 2.4848612135924686\n",
      "resetting env. episode reward total was -2.0. running mean: 2.440012601456544\n",
      "resetting env. episode reward total was 6.0. running mean: 2.4756124754419786\n",
      "resetting env. episode reward total was 6.0. running mean: 2.510856350687559\n",
      "resetting env. episode reward total was -11.0. running mean: 2.3757477871806834\n",
      "resetting env. episode reward total was -8.0. running mean: 2.2719903093088765\n",
      "resetting env. episode reward total was -4.0. running mean: 2.2092704062157877\n",
      "resetting env. episode reward total was -10.0. running mean: 2.08717770215363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -8.0. running mean: 1.9863059251320934\n",
      "resetting env. episode reward total was 1.0. running mean: 1.9764428658807724\n",
      "resetting env. episode reward total was 3.0. running mean: 1.9866784372219648\n",
      "resetting env. episode reward total was 7.0. running mean: 2.036811652849745\n",
      "resetting env. episode reward total was 9.0. running mean: 2.1064435363212475\n",
      "resetting env. episode reward total was 9.0. running mean: 2.1753791009580348\n",
      "resetting env. episode reward total was 2.0. running mean: 2.1736253099484544\n",
      "resetting env. episode reward total was 9.0. running mean: 2.2418890568489696\n",
      "resetting env. episode reward total was 4.0. running mean: 2.25947016628048\n",
      "resetting env. episode reward total was 16.0. running mean: 2.396875464617675\n",
      "resetting env. episode reward total was 5.0. running mean: 2.4229067099714983\n",
      "resetting env. episode reward total was 5.0. running mean: 2.448677642871783\n",
      "resetting env. episode reward total was -6.0. running mean: 2.364190866443065\n",
      "resetting env. episode reward total was 7.0. running mean: 2.410548957778634\n",
      "resetting env. episode reward total was -1.0. running mean: 2.376443468200848\n",
      "resetting env. episode reward total was 13.0. running mean: 2.4826790335188393\n",
      "resetting env. episode reward total was -3.0. running mean: 2.427852243183651\n",
      "resetting env. episode reward total was -10.0. running mean: 2.3035737207518143\n",
      "resetting env. episode reward total was -2.0. running mean: 2.260537983544296\n",
      "resetting env. episode reward total was -4.0. running mean: 2.197932603708853\n",
      "resetting env. episode reward total was 5.0. running mean: 2.2259532776717643\n",
      "resetting env. episode reward total was 11.0. running mean: 2.3136937448950463\n",
      "resetting env. episode reward total was -2.0. running mean: 2.270556807446096\n",
      "resetting env. episode reward total was 4.0. running mean: 2.287851239371635\n",
      "resetting env. episode reward total was -4.0. running mean: 2.2249727269779185\n",
      "resetting env. episode reward total was 9.0. running mean: 2.2927229997081393\n",
      "resetting env. episode reward total was 3.0. running mean: 2.2997957697110576\n",
      "resetting env. episode reward total was 5.0. running mean: 2.3267978120139468\n",
      "resetting env. episode reward total was 5.0. running mean: 2.353529833893807\n",
      "resetting env. episode reward total was 4.0. running mean: 2.3699945355548686\n",
      "resetting env. episode reward total was 9.0. running mean: 2.43629459019932\n",
      "resetting env. episode reward total was -5.0. running mean: 2.361931644297327\n",
      "resetting env. episode reward total was -6.0. running mean: 2.2783123278543536\n",
      "resetting env. episode reward total was 4.0. running mean: 2.2955292045758102\n",
      "resetting env. episode reward total was 12.0. running mean: 2.392573912530052\n",
      "resetting env. episode reward total was 2.0. running mean: 2.3886481734047513\n",
      "resetting env. episode reward total was 3.0. running mean: 2.3947616916707037\n",
      "resetting env. episode reward total was 8.0. running mean: 2.4508140747539966\n",
      "resetting env. episode reward total was 1.0. running mean: 2.4363059340064566\n",
      "resetting env. episode reward total was 12.0. running mean: 2.531942874666392\n",
      "resetting env. episode reward total was 10.0. running mean: 2.606623445919728\n",
      "resetting env. episode reward total was 2.0. running mean: 2.600557211460531\n",
      "resetting env. episode reward total was -13.0. running mean: 2.4445516393459257\n",
      "resetting env. episode reward total was 9.0. running mean: 2.5101061229524664\n",
      "resetting env. episode reward total was 10.0. running mean: 2.5850050617229416\n",
      "resetting env. episode reward total was 16.0. running mean: 2.7191550111057126\n",
      "resetting env. episode reward total was -3.0. running mean: 2.6619634609946554\n",
      "resetting env. episode reward total was 9.0. running mean: 2.7253438263847087\n",
      "resetting env. episode reward total was 7.0. running mean: 2.7680903881208616\n",
      "resetting env. episode reward total was 12.0. running mean: 2.860409484239653\n",
      "resetting env. episode reward total was 8.0. running mean: 2.9118053893972564\n",
      "resetting env. episode reward total was 7.0. running mean: 2.952687335503284\n",
      "resetting env. episode reward total was 12.0. running mean: 3.043160462148251\n",
      "resetting env. episode reward total was 10.0. running mean: 3.1127288575267684\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1216015689515006\n",
      "resetting env. episode reward total was -3.0. running mean: 3.0603855532619857\n",
      "resetting env. episode reward total was 4.0. running mean: 3.0697816977293657\n",
      "resetting env. episode reward total was -7.0. running mean: 2.969083880752072\n",
      "resetting env. episode reward total was 12.0. running mean: 3.0593930419445514\n",
      "resetting env. episode reward total was -11.0. running mean: 2.918799111525106\n",
      "resetting env. episode reward total was 14.0. running mean: 3.029611120409855\n",
      "resetting env. episode reward total was 1.0. running mean: 3.009315009205756\n",
      "resetting env. episode reward total was 6.0. running mean: 3.039221859113699\n",
      "resetting env. episode reward total was 4.0. running mean: 3.0488296405225617\n",
      "resetting env. episode reward total was -2.0. running mean: 2.998341344117336\n",
      "resetting env. episode reward total was 3.0. running mean: 2.9983579306761623\n",
      "resetting env. episode reward total was 2.0. running mean: 2.9883743513694006\n",
      "resetting env. episode reward total was 6.0. running mean: 3.0184906078557066\n",
      "resetting env. episode reward total was 1.0. running mean: 2.998305701777149\n",
      "resetting env. episode reward total was 7.0. running mean: 3.0383226447593774\n",
      "resetting env. episode reward total was -5.0. running mean: 2.957939418311784\n",
      "resetting env. episode reward total was 6.0. running mean: 2.9883600241286663\n",
      "resetting env. episode reward total was 13.0. running mean: 3.0884764238873794\n",
      "resetting env. episode reward total was -5.0. running mean: 3.0075916596485057\n",
      "resetting env. episode reward total was -7.0. running mean: 2.907515743052021\n",
      "resetting env. episode reward total was 3.0. running mean: 2.9084405856215003\n",
      "resetting env. episode reward total was 3.0. running mean: 2.909356179765285\n",
      "resetting env. episode reward total was 4.0. running mean: 2.9202626179676323\n",
      "resetting env. episode reward total was 9.0. running mean: 2.981059991787956\n",
      "resetting env. episode reward total was 12.0. running mean: 3.0712493918700763\n",
      "resetting env. episode reward total was 8.0. running mean: 3.1205368979513755\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1293315289718615\n",
      "resetting env. episode reward total was 13.0. running mean: 3.228038213682143\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2657578315453213\n",
      "resetting env. episode reward total was 9.0. running mean: 3.323100253229868\n",
      "resetting env. episode reward total was 16.0. running mean: 3.4498692506975694\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4353705581905936\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4210168526086875\n",
      "resetting env. episode reward total was 2.0. running mean: 3.406806684082601\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4127386172417746\n",
      "resetting env. episode reward total was 7.0. running mean: 3.4486112310693566\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4541251187586632\n",
      "resetting env. episode reward total was 13.0. running mean: 3.5495838675710765\n",
      "resetting env. episode reward total was -1.0. running mean: 3.504088028895366\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5490471486064123\n",
      "resetting env. episode reward total was 8.0. running mean: 3.593556677120348\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5976211103491447\n",
      "resetting env. episode reward total was 15.0. running mean: 3.711644899245653\n",
      "resetting env. episode reward total was -8.0. running mean: 3.5945284502531964\n",
      "resetting env. episode reward total was 3.0. running mean: 3.588583165750664\n",
      "resetting env. episode reward total was -2.0. running mean: 3.5326973340931573\n",
      "resetting env. episode reward total was 9.0. running mean: 3.5873703607522254\n",
      "resetting env. episode reward total was 9.0. running mean: 3.641496657144703\n",
      "resetting env. episode reward total was -4.0. running mean: 3.565081690573256\n",
      "resetting env. episode reward total was 5.0. running mean: 3.579430873667523\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6036365649308477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -1.0. running mean: 3.5576001992815396\n",
      "resetting env. episode reward total was -1.0. running mean: 3.5120241972887243\n",
      "resetting env. episode reward total was -5.0. running mean: 3.4269039553158374\n",
      "resetting env. episode reward total was 10.0. running mean: 3.4926349157626793\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4977085666050525\n",
      "resetting env. episode reward total was -2.0. running mean: 3.4427314809390017\n",
      "resetting env. episode reward total was 13.0. running mean: 3.5383041661296115\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6029211244683155\n",
      "resetting env. episode reward total was -5.0. running mean: 3.5168919132236325\n",
      "resetting env. episode reward total was 9.0. running mean: 3.571722994091396\n",
      "resetting env. episode reward total was 1.0. running mean: 3.546005764150482\n",
      "resetting env. episode reward total was 6.0. running mean: 3.570545706508977\n",
      "resetting env. episode reward total was 9.0. running mean: 3.624840249443887\n",
      "resetting env. episode reward total was -1.0. running mean: 3.5785918469494487\n",
      "resetting env. episode reward total was -8.0. running mean: 3.462805928479954\n",
      "resetting env. episode reward total was 4.0. running mean: 3.468177869195155\n",
      "resetting env. episode reward total was 3.0. running mean: 3.463496090503203\n",
      "resetting env. episode reward total was 3.0. running mean: 3.4588611295981706\n",
      "resetting env. episode reward total was -9.0. running mean: 3.334272518302189\n",
      "resetting env. episode reward total was -2.0. running mean: 3.280929793119167\n",
      "resetting env. episode reward total was 4.0. running mean: 3.2881204951879757\n",
      "resetting env. episode reward total was -1.0. running mean: 3.2452392902360963\n",
      "resetting env. episode reward total was 7.0. running mean: 3.282786897333735\n",
      "resetting env. episode reward total was 16.0. running mean: 3.4099590283603978\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4158594380767937\n",
      "resetting env. episode reward total was -5.0. running mean: 3.331700843696026\n",
      "resetting env. episode reward total was 4.0. running mean: 3.338383835259066\n",
      "resetting env. episode reward total was 6.0. running mean: 3.364999996906475\n",
      "resetting env. episode reward total was 9.0. running mean: 3.42134999693741\n",
      "resetting env. episode reward total was -3.0. running mean: 3.357136496968036\n",
      "resetting env. episode reward total was 9.0. running mean: 3.4135651319983555\n",
      "resetting env. episode reward total was 10.0. running mean: 3.479429480678372\n",
      "resetting env. episode reward total was -4.0. running mean: 3.404635185871588\n",
      "resetting env. episode reward total was 3.0. running mean: 3.400588834012872\n",
      "resetting env. episode reward total was 5.0. running mean: 3.4165829456727432\n",
      "resetting env. episode reward total was -3.0. running mean: 3.352417116216016\n",
      "resetting env. episode reward total was 11.0. running mean: 3.4288929450538554\n",
      "resetting env. episode reward total was 9.0. running mean: 3.484604015603317\n",
      "resetting env. episode reward total was 4.0. running mean: 3.489757975447284\n",
      "resetting env. episode reward total was -13.0. running mean: 3.324860395692811\n",
      "resetting env. episode reward total was -3.0. running mean: 3.2616117917358833\n",
      "resetting env. episode reward total was 7.0. running mean: 3.298995673818524\n",
      "resetting env. episode reward total was 4.0. running mean: 3.306005717080339\n",
      "resetting env. episode reward total was -1.0. running mean: 3.2629456599095357\n",
      "resetting env. episode reward total was 3.0. running mean: 3.26031620331044\n",
      "resetting env. episode reward total was 1.0. running mean: 3.237713041277335\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2553359108645616\n",
      "resetting env. episode reward total was -2.0. running mean: 3.202782551755916\n",
      "resetting env. episode reward total was -4.0. running mean: 3.130754726238357\n",
      "resetting env. episode reward total was 3.0. running mean: 3.1294471789759735\n",
      "resetting env. episode reward total was 2.0. running mean: 3.118152707186214\n",
      "resetting env. episode reward total was 2.0. running mean: 3.1069711801143516\n",
      "resetting env. episode reward total was 6.0. running mean: 3.1359014683132083\n",
      "resetting env. episode reward total was 8.0. running mean: 3.184542453630076\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1926970290937753\n",
      "resetting env. episode reward total was -1.0. running mean: 3.150770058802838\n",
      "resetting env. episode reward total was 15.0. running mean: 3.2692623582148093\n",
      "resetting env. episode reward total was -2.0. running mean: 3.216569734632661\n",
      "resetting env. episode reward total was -1.0. running mean: 3.174404037286335\n",
      "resetting env. episode reward total was 5.0. running mean: 3.1926599969134712\n",
      "resetting env. episode reward total was 15.0. running mean: 3.3107333969443364\n",
      "resetting env. episode reward total was -8.0. running mean: 3.197626062974893\n",
      "resetting env. episode reward total was 1.0. running mean: 3.1756498023451436\n",
      "resetting env. episode reward total was 5.0. running mean: 3.193893304321692\n",
      "resetting env. episode reward total was 10.0. running mean: 3.261954371278475\n",
      "resetting env. episode reward total was -8.0. running mean: 3.14933482756569\n",
      "resetting env. episode reward total was -1.0. running mean: 3.107841479290033\n",
      "resetting env. episode reward total was -8.0. running mean: 2.9967630644971326\n",
      "resetting env. episode reward total was 8.0. running mean: 3.0467954338521612\n",
      "resetting env. episode reward total was 3.0. running mean: 3.0463274795136392\n",
      "resetting env. episode reward total was -12.0. running mean: 2.8958642047185026\n",
      "resetting env. episode reward total was -1.0. running mean: 2.856905562671318\n",
      "resetting env. episode reward total was 12.0. running mean: 2.948336507044605\n",
      "resetting env. episode reward total was -13.0. running mean: 2.7888531419741587\n",
      "resetting env. episode reward total was -1.0. running mean: 2.7509646105544174\n",
      "resetting env. episode reward total was 5.0. running mean: 2.773454964448873\n",
      "resetting env. episode reward total was 5.0. running mean: 2.795720414804384\n",
      "resetting env. episode reward total was -14.0. running mean: 2.6277632106563398\n",
      "resetting env. episode reward total was 10.0. running mean: 2.7014855785497764\n",
      "resetting env. episode reward total was -3.0. running mean: 2.6444707227642787\n",
      "resetting env. episode reward total was -7.0. running mean: 2.548026015536636\n",
      "resetting env. episode reward total was -2.0. running mean: 2.5025457553812696\n",
      "resetting env. episode reward total was -2.0. running mean: 2.4575202978274566\n",
      "resetting env. episode reward total was 4.0. running mean: 2.472945094849182\n",
      "resetting env. episode reward total was 2.0. running mean: 2.4682156439006904\n",
      "resetting env. episode reward total was 9.0. running mean: 2.5335334874616833\n",
      "resetting env. episode reward total was -7.0. running mean: 2.4381981525870664\n",
      "resetting env. episode reward total was 9.0. running mean: 2.5038161710611955\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5087780093505834\n",
      "resetting env. episode reward total was 9.0. running mean: 2.5736902292570774\n",
      "resetting env. episode reward total was 14.0. running mean: 2.687953326964507\n",
      "resetting env. episode reward total was -7.0. running mean: 2.591073793694862\n",
      "resetting env. episode reward total was -7.0. running mean: 2.4951630557579136\n",
      "resetting env. episode reward total was 4.0. running mean: 2.5102114252003345\n",
      "resetting env. episode reward total was -5.0. running mean: 2.4351093109483313\n",
      "resetting env. episode reward total was 12.0. running mean: 2.530758217838848\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5354506356604594\n",
      "resetting env. episode reward total was -6.0. running mean: 2.4500961293038546\n",
      "resetting env. episode reward total was 8.0. running mean: 2.505595168010816\n",
      "resetting env. episode reward total was -4.0. running mean: 2.440539216330708\n",
      "resetting env. episode reward total was 6.0. running mean: 2.476133824167401\n",
      "resetting env. episode reward total was 2.0. running mean: 2.471372485925727\n",
      "resetting env. episode reward total was 1.0. running mean: 2.4566587610664694\n",
      "resetting env. episode reward total was 8.0. running mean: 2.512092173455805\n",
      "resetting env. episode reward total was 10.0. running mean: 2.5869712517212466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 11.0. running mean: 2.671101539204034\n",
      "resetting env. episode reward total was 7.0. running mean: 2.7143905238119936\n",
      "resetting env. episode reward total was -1.0. running mean: 2.6772466185738737\n",
      "resetting env. episode reward total was 9.0. running mean: 2.740474152388135\n",
      "resetting env. episode reward total was 5.0. running mean: 2.7630694108642535\n",
      "resetting env. episode reward total was -3.0. running mean: 2.7054387167556113\n",
      "resetting env. episode reward total was 6.0. running mean: 2.7383843295880554\n",
      "resetting env. episode reward total was -1.0. running mean: 2.701000486292175\n",
      "resetting env. episode reward total was 8.0. running mean: 2.7539904814292533\n",
      "resetting env. episode reward total was -7.0. running mean: 2.656450576614961\n",
      "resetting env. episode reward total was 12.0. running mean: 2.7498860708488118\n",
      "resetting env. episode reward total was 9.0. running mean: 2.8123872101403236\n",
      "resetting env. episode reward total was -5.0. running mean: 2.7342633380389203\n",
      "resetting env. episode reward total was -6.0. running mean: 2.646920704658531\n",
      "resetting env. episode reward total was 4.0. running mean: 2.6604514976119455\n",
      "resetting env. episode reward total was -2.0. running mean: 2.613846982635826\n",
      "resetting env. episode reward total was -3.0. running mean: 2.557708512809468\n",
      "resetting env. episode reward total was 3.0. running mean: 2.5621314276813734\n",
      "resetting env. episode reward total was 8.0. running mean: 2.61651011340456\n",
      "resetting env. episode reward total was 2.0. running mean: 2.610345012270514\n",
      "resetting env. episode reward total was 6.0. running mean: 2.644241562147809\n",
      "resetting env. episode reward total was 5.0. running mean: 2.6677991465263307\n",
      "resetting env. episode reward total was -7.0. running mean: 2.5711211550610673\n",
      "resetting env. episode reward total was 11.0. running mean: 2.6554099435104566\n",
      "resetting env. episode reward total was 5.0. running mean: 2.678855844075352\n",
      "resetting env. episode reward total was -3.0. running mean: 2.6220672856345986\n",
      "resetting env. episode reward total was 5.0. running mean: 2.6458466127782523\n",
      "resetting env. episode reward total was -4.0. running mean: 2.57938814665047\n",
      "resetting env. episode reward total was 6.0. running mean: 2.613594265183965\n",
      "resetting env. episode reward total was 12.0. running mean: 2.7074583225321254\n",
      "resetting env. episode reward total was 5.0. running mean: 2.730383739306804\n",
      "resetting env. episode reward total was 3.0. running mean: 2.7330799019137357\n",
      "resetting env. episode reward total was 5.0. running mean: 2.755749102894598\n",
      "resetting env. episode reward total was -12.0. running mean: 2.6081916118656516\n",
      "resetting env. episode reward total was 1.0. running mean: 2.592109695746995\n",
      "resetting env. episode reward total was 1.0. running mean: 2.5761885987895248\n",
      "resetting env. episode reward total was -5.0. running mean: 2.5004267128016298\n",
      "resetting env. episode reward total was 6.0. running mean: 2.5354224456736136\n",
      "resetting env. episode reward total was 1.0. running mean: 2.5200682212168775\n",
      "resetting env. episode reward total was -3.0. running mean: 2.464867539004709\n",
      "resetting env. episode reward total was 10.0. running mean: 2.540218863614662\n",
      "resetting env. episode reward total was 9.0. running mean: 2.604816674978515\n",
      "resetting env. episode reward total was -3.0. running mean: 2.5487685082287297\n",
      "resetting env. episode reward total was 4.0. running mean: 2.5632808231464423\n",
      "resetting env. episode reward total was 3.0. running mean: 2.567648014914978\n",
      "resetting env. episode reward total was 8.0. running mean: 2.6219715347658283\n",
      "resetting env. episode reward total was 11.0. running mean: 2.70575181941817\n",
      "resetting env. episode reward total was -1.0. running mean: 2.6686943012239883\n",
      "resetting env. episode reward total was 14.0. running mean: 2.7820073582117484\n",
      "resetting env. episode reward total was 4.0. running mean: 2.794187284629631\n",
      "resetting env. episode reward total was 9.0. running mean: 2.8562454117833345\n",
      "resetting env. episode reward total was -5.0. running mean: 2.777682957665501\n",
      "resetting env. episode reward total was 4.0. running mean: 2.789906128088846\n",
      "resetting env. episode reward total was 6.0. running mean: 2.8220070668079575\n",
      "resetting env. episode reward total was 4.0. running mean: 2.833786996139878\n",
      "resetting env. episode reward total was 7.0. running mean: 2.875449126178479\n",
      "resetting env. episode reward total was 7.0. running mean: 2.916694634916694\n",
      "resetting env. episode reward total was -3.0. running mean: 2.857527688567527\n",
      "resetting env. episode reward total was 3.0. running mean: 2.8589524116818517\n",
      "resetting env. episode reward total was 9.0. running mean: 2.920362887565033\n",
      "resetting env. episode reward total was -10.0. running mean: 2.7911592586893823\n",
      "resetting env. episode reward total was -2.0. running mean: 2.7432476661024885\n",
      "resetting env. episode reward total was 4.0. running mean: 2.7558151894414635\n",
      "resetting env. episode reward total was 7.0. running mean: 2.7982570375470486\n",
      "resetting env. episode reward total was 4.0. running mean: 2.810274467171578\n",
      "resetting env. episode reward total was 9.0. running mean: 2.872171722499862\n",
      "resetting env. episode reward total was 12.0. running mean: 2.9634500052748636\n",
      "resetting env. episode reward total was -11.0. running mean: 2.823815505222115\n",
      "resetting env. episode reward total was 2.0. running mean: 2.8155773501698937\n",
      "resetting env. episode reward total was 7.0. running mean: 2.8574215766681945\n",
      "resetting env. episode reward total was 5.0. running mean: 2.878847360901512\n",
      "resetting env. episode reward total was 6.0. running mean: 2.910058887292497\n",
      "resetting env. episode reward total was 7.0. running mean: 2.9509582984195717\n",
      "resetting env. episode reward total was 4.0. running mean: 2.961448715435376\n",
      "resetting env. episode reward total was 6.0. running mean: 2.9918342282810224\n",
      "resetting env. episode reward total was 8.0. running mean: 3.041915885998212\n",
      "resetting env. episode reward total was 11.0. running mean: 3.1214967271382297\n",
      "resetting env. episode reward total was 4.0. running mean: 3.1302817598668473\n",
      "resetting env. episode reward total was -2.0. running mean: 3.078978942268179\n",
      "resetting env. episode reward total was -3.0. running mean: 3.018189152845497\n",
      "resetting env. episode reward total was 10.0. running mean: 3.0880072613170424\n",
      "resetting env. episode reward total was 4.0. running mean: 3.097127188703872\n",
      "resetting env. episode reward total was -5.0. running mean: 3.0161559168168335\n",
      "resetting env. episode reward total was 11.0. running mean: 3.095994357648665\n",
      "resetting env. episode reward total was 9.0. running mean: 3.1550344140721784\n",
      "resetting env. episode reward total was 11.0. running mean: 3.2334840699314564\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2711492292321416\n",
      "resetting env. episode reward total was -1.0. running mean: 3.2284377369398203\n",
      "resetting env. episode reward total was 15.0. running mean: 3.346153359570422\n",
      "resetting env. episode reward total was -3.0. running mean: 3.282691825974718\n",
      "resetting env. episode reward total was 9.0. running mean: 3.3398649077149707\n",
      "resetting env. episode reward total was -1.0. running mean: 3.296466258637821\n",
      "resetting env. episode reward total was 15.0. running mean: 3.4135015960514425\n",
      "resetting env. episode reward total was 13.0. running mean: 3.509366580090928\n",
      "resetting env. episode reward total was 4.0. running mean: 3.514272914290019\n",
      "resetting env. episode reward total was -8.0. running mean: 3.3991301851471185\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4051388832956473\n",
      "resetting env. episode reward total was 4.0. running mean: 3.411087494462691\n",
      "resetting env. episode reward total was 3.0. running mean: 3.4069766195180637\n",
      "resetting env. episode reward total was -1.0. running mean: 3.362906853322883\n",
      "resetting env. episode reward total was 9.0. running mean: 3.4192777847896543\n",
      "resetting env. episode reward total was 9.0. running mean: 3.4750850069417574\n",
      "resetting env. episode reward total was 1.0. running mean: 3.4503341568723394\n",
      "resetting env. episode reward total was 15.0. running mean: 3.565830815303616\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5501725071505796\n",
      "resetting env. episode reward total was 7.0. running mean: 3.5846707820790735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 18.0. running mean: 3.728824074258283\n",
      "resetting env. episode reward total was 11.0. running mean: 3.8015358335157\n",
      "resetting env. episode reward total was 2.0. running mean: 3.7835204751805427\n",
      "resetting env. episode reward total was 4.0. running mean: 3.785685270428737\n",
      "resetting env. episode reward total was 6.0. running mean: 3.80782841772445\n",
      "resetting env. episode reward total was 5.0. running mean: 3.8197501335472053\n",
      "resetting env. episode reward total was 2.0. running mean: 3.8015526322117332\n",
      "resetting env. episode reward total was -1.0. running mean: 3.753537105889616\n",
      "resetting env. episode reward total was -3.0. running mean: 3.68600173483072\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7391417174824126\n",
      "resetting env. episode reward total was 10.0. running mean: 3.8017503003075888\n",
      "resetting env. episode reward total was -2.0. running mean: 3.7437327973045127\n",
      "resetting env. episode reward total was 3.0. running mean: 3.736295469331467\n",
      "resetting env. episode reward total was 13.0. running mean: 3.8289325146381525\n",
      "resetting env. episode reward total was 12.0. running mean: 3.910643189491771\n",
      "resetting env. episode reward total was 4.0. running mean: 3.911536757596853\n",
      "resetting env. episode reward total was 7.0. running mean: 3.9424213900208844\n",
      "resetting env. episode reward total was 3.0. running mean: 3.9329971761206752\n",
      "resetting env. episode reward total was 6.0. running mean: 3.9536672043594683\n",
      "resetting env. episode reward total was 2.0. running mean: 3.9341305323158737\n",
      "resetting env. episode reward total was -2.0. running mean: 3.874789226992715\n",
      "resetting env. episode reward total was 14.0. running mean: 3.976041334722788\n",
      "resetting env. episode reward total was -11.0. running mean: 3.8262809213755604\n",
      "resetting env. episode reward total was -2.0. running mean: 3.768018112161805\n",
      "resetting env. episode reward total was -7.0. running mean: 3.660337931040187\n",
      "resetting env. episode reward total was -1.0. running mean: 3.6137345517297854\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6475972062124873\n",
      "resetting env. episode reward total was 14.0. running mean: 3.7511212341503626\n",
      "resetting env. episode reward total was 13.0. running mean: 3.8436100218088587\n",
      "resetting env. episode reward total was 16.0. running mean: 3.9651739215907704\n",
      "resetting env. episode reward total was 2.0. running mean: 3.9455221823748627\n",
      "resetting env. episode reward total was 7.0. running mean: 3.976066960551114\n",
      "resetting env. episode reward total was 12.0. running mean: 4.056306290945603\n",
      "resetting env. episode reward total was -8.0. running mean: 3.935743228036147\n",
      "resetting env. episode reward total was 4.0. running mean: 3.9363857957557853\n",
      "resetting env. episode reward total was -8.0. running mean: 3.8170219377982275\n",
      "resetting env. episode reward total was -1.0. running mean: 3.7688517184202452\n",
      "resetting env. episode reward total was -12.0. running mean: 3.611163201236043\n",
      "resetting env. episode reward total was 10.0. running mean: 3.6750515692236823\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6983010535314453\n",
      "resetting env. episode reward total was 2.0. running mean: 3.6813180429961307\n",
      "resetting env. episode reward total was 11.0. running mean: 3.7545048625661694\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7769598139405076\n",
      "resetting env. episode reward total was 3.0. running mean: 3.7691902158011024\n",
      "resetting env. episode reward total was -1.0. running mean: 3.7214983136430915\n",
      "resetting env. episode reward total was 1.0. running mean: 3.6942833305066602\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7473404972015936\n",
      "resetting env. episode reward total was 10.0. running mean: 3.809867092229578\n",
      "resetting env. episode reward total was 3.0. running mean: 3.801768421307282\n",
      "resetting env. episode reward total was -5.0. running mean: 3.7137507370942093\n",
      "resetting env. episode reward total was 7.0. running mean: 3.746613229723267\n",
      "resetting env. episode reward total was 2.0. running mean: 3.7291470974260346\n",
      "resetting env. episode reward total was 8.0. running mean: 3.7718556264517744\n",
      "resetting env. episode reward total was 4.0. running mean: 3.7741370701872565\n",
      "resetting env. episode reward total was 7.0. running mean: 3.8063956994853836\n",
      "resetting env. episode reward total was -1.0. running mean: 3.75833174249053\n",
      "resetting env. episode reward total was 4.0. running mean: 3.760748425065625\n",
      "resetting env. episode reward total was 6.0. running mean: 3.7831409408149685\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7953095314068186\n",
      "resetting env. episode reward total was 12.0. running mean: 3.8773564360927506\n",
      "resetting env. episode reward total was -6.0. running mean: 3.778582871731823\n",
      "resetting env. episode reward total was 7.0. running mean: 3.8107970430145044\n",
      "resetting env. episode reward total was 2.0. running mean: 3.792689072584359\n",
      "resetting env. episode reward total was -4.0. running mean: 3.7147621818585157\n",
      "resetting env. episode reward total was -13.0. running mean: 3.5476145600399307\n",
      "resetting env. episode reward total was 6.0. running mean: 3.5721384144395314\n",
      "resetting env. episode reward total was 10.0. running mean: 3.636417030295136\n",
      "resetting env. episode reward total was 8.0. running mean: 3.6800528599921845\n",
      "resetting env. episode reward total was 3.0. running mean: 3.6732523313922623\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6965198080783397\n",
      "resetting env. episode reward total was -2.0. running mean: 3.6395546099975564\n",
      "resetting env. episode reward total was 8.0. running mean: 3.683159063897581\n",
      "resetting env. episode reward total was 1.0. running mean: 3.656327473258605\n",
      "resetting env. episode reward total was 10.0. running mean: 3.719764198526019\n",
      "resetting env. episode reward total was 7.0. running mean: 3.752566556540758\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7650408909753503\n",
      "resetting env. episode reward total was -3.0. running mean: 3.697390482065597\n",
      "resetting env. episode reward total was -3.0. running mean: 3.6304165772449415\n",
      "resetting env. episode reward total was -1.0. running mean: 3.5841124114724923\n",
      "resetting env. episode reward total was 5.0. running mean: 3.598271287357767\n",
      "resetting env. episode reward total was 7.0. running mean: 3.632288574484189\n",
      "resetting env. episode reward total was 8.0. running mean: 3.675965688739347\n",
      "resetting env. episode reward total was -5.0. running mean: 3.589206031851954\n",
      "resetting env. episode reward total was 14.0. running mean: 3.6933139715334344\n",
      "resetting env. episode reward total was 11.0. running mean: 3.7663808318181\n",
      "resetting env. episode reward total was -10.0. running mean: 3.628717023499919\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6624298532649195\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7158055547322704\n",
      "resetting env. episode reward total was 3.0. running mean: 3.7086474991849476\n",
      "resetting env. episode reward total was -4.0. running mean: 3.6315610241930982\n",
      "resetting env. episode reward total was 8.0. running mean: 3.6752454139511674\n",
      "resetting env. episode reward total was 12.0. running mean: 3.758492959811656\n",
      "resetting env. episode reward total was -2.0. running mean: 3.7009080302135393\n",
      "resetting env. episode reward total was 11.0. running mean: 3.7738989499114037\n",
      "resetting env. episode reward total was 10.0. running mean: 3.8361599604122896\n",
      "resetting env. episode reward total was 4.0. running mean: 3.8377983608081667\n",
      "resetting env. episode reward total was 13.0. running mean: 3.929420377200085\n",
      "resetting env. episode reward total was 12.0. running mean: 4.010126173428084\n",
      "resetting env. episode reward total was -7.0. running mean: 3.9000249116938033\n",
      "resetting env. episode reward total was -2.0. running mean: 3.8410246625768654\n",
      "resetting env. episode reward total was 4.0. running mean: 3.842614415951097\n",
      "resetting env. episode reward total was 6.0. running mean: 3.864188271791586\n",
      "resetting env. episode reward total was 1.0. running mean: 3.83554638907367\n",
      "resetting env. episode reward total was 4.0. running mean: 3.8371909251829335\n",
      "resetting env. episode reward total was -13.0. running mean: 3.668819015931104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was 7.0. running mean: 3.7021308257717926\n",
      "resetting env. episode reward total was -11.0. running mean: 3.555109517514075\n",
      "resetting env. episode reward total was 6.0. running mean: 3.579558422338934\n",
      "resetting env. episode reward total was 2.0. running mean: 3.5637628381155446\n",
      "resetting env. episode reward total was 3.0. running mean: 3.558125209734389\n",
      "resetting env. episode reward total was 14.0. running mean: 3.662543957637045\n",
      "resetting env. episode reward total was -7.0. running mean: 3.555918518060675\n",
      "resetting env. episode reward total was -7.0. running mean: 3.450359332880068\n",
      "resetting env. episode reward total was 2.0. running mean: 3.4358557395512674\n",
      "resetting env. episode reward total was 7.0. running mean: 3.4714971821557548\n",
      "resetting env. episode reward total was -4.0. running mean: 3.396782210334197\n",
      "resetting env. episode reward total was 3.0. running mean: 3.392814388230855\n",
      "resetting env. episode reward total was 5.0. running mean: 3.408886244348546\n",
      "resetting env. episode reward total was 4.0. running mean: 3.4147973819050605\n",
      "resetting env. episode reward total was 13.0. running mean: 3.51064940808601\n",
      "resetting env. episode reward total was 1.0. running mean: 3.4855429140051495\n",
      "resetting env. episode reward total was 3.0. running mean: 3.480687484865098\n",
      "resetting env. episode reward total was -9.0. running mean: 3.355880610016447\n",
      "resetting env. episode reward total was -9.0. running mean: 3.2323218039162827\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2499985858771194\n",
      "resetting env. episode reward total was 4.0. running mean: 3.2574986000183483\n",
      "resetting env. episode reward total was 7.0. running mean: 3.2949236140181646\n",
      "resetting env. episode reward total was -3.0. running mean: 3.2319743778779833\n",
      "resetting env. episode reward total was 6.0. running mean: 3.2596546340992036\n",
      "resetting env. episode reward total was 11.0. running mean: 3.3370580877582117\n",
      "resetting env. episode reward total was 11.0. running mean: 3.4136875068806294\n",
      "resetting env. episode reward total was 10.0. running mean: 3.479550631811823\n",
      "resetting env. episode reward total was 9.0. running mean: 3.5347551254937044\n",
      "resetting env. episode reward total was 7.0. running mean: 3.569407574238767\n",
      "resetting env. episode reward total was 4.0. running mean: 3.5737134984963794\n",
      "resetting env. episode reward total was 7.0. running mean: 3.6079763635114155\n",
      "resetting env. episode reward total was 4.0. running mean: 3.6118965998763013\n",
      "resetting env. episode reward total was 4.0. running mean: 3.6157776338775385\n",
      "resetting env. episode reward total was -7.0. running mean: 3.5096198575387634\n",
      "resetting env. episode reward total was 6.0. running mean: 3.534523658963376\n",
      "resetting env. episode reward total was 10.0. running mean: 3.5991784223737424\n",
      "resetting env. episode reward total was 5.0. running mean: 3.6131866381500046\n",
      "resetting env. episode reward total was -2.0. running mean: 3.5570547717685046\n",
      "resetting env. episode reward total was 10.0. running mean: 3.62148422405082\n",
      "resetting env. episode reward total was 9.0. running mean: 3.6752693818103115\n",
      "resetting env. episode reward total was 1.0. running mean: 3.648516687992208\n",
      "resetting env. episode reward total was -2.0. running mean: 3.5920315211122857\n",
      "resetting env. episode reward total was 12.0. running mean: 3.676111205901163\n",
      "resetting env. episode reward total was 7.0. running mean: 3.709350093842151\n",
      "resetting env. episode reward total was 7.0. running mean: 3.7422565929037295\n",
      "resetting env. episode reward total was 7.0. running mean: 3.774834026974692\n",
      "resetting env. episode reward total was 5.0. running mean: 3.7870856867049447\n",
      "resetting env. episode reward total was 2.0. running mean: 3.769214829837895\n",
      "resetting env. episode reward total was 10.0. running mean: 3.831522681539516\n",
      "resetting env. episode reward total was -9.0. running mean: 3.703207454724121\n",
      "resetting env. episode reward total was -10.0. running mean: 3.5661753801768796\n",
      "resetting env. episode reward total was 9.0. running mean: 3.6205136263751108\n",
      "resetting env. episode reward total was 9.0. running mean: 3.6743084901113594\n",
      "resetting env. episode reward total was 3.0. running mean: 3.6675654052102455\n",
      "resetting env. episode reward total was -4.0. running mean: 3.590889751158143\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6149808536465615\n",
      "resetting env. episode reward total was -6.0. running mean: 3.5188310451100957\n",
      "resetting env. episode reward total was -3.0. running mean: 3.453642734658995\n",
      "resetting env. episode reward total was -9.0. running mean: 3.329106307312405\n",
      "resetting env. episode reward total was 5.0. running mean: 3.345815244239281\n",
      "resetting env. episode reward total was -3.0. running mean: 3.282357091796888\n",
      "resetting env. episode reward total was -7.0. running mean: 3.1795335208789193\n",
      "resetting env. episode reward total was 6.0. running mean: 3.20773818567013\n",
      "resetting env. episode reward total was 6.0. running mean: 3.2356608038134285\n",
      "resetting env. episode reward total was 1.0. running mean: 3.213304195775294\n",
      "resetting env. episode reward total was -7.0. running mean: 3.1111711538175415\n",
      "resetting env. episode reward total was 8.0. running mean: 3.160059442279366\n",
      "resetting env. episode reward total was -6.0. running mean: 3.068458847856572\n",
      "resetting env. episode reward total was 6.0. running mean: 3.0977742593780064\n",
      "resetting env. episode reward total was -5.0. running mean: 3.0167965167842263\n",
      "resetting env. episode reward total was 2.0. running mean: 3.006628551616384\n",
      "resetting env. episode reward total was 8.0. running mean: 3.0565622661002205\n",
      "resetting env. episode reward total was 6.0. running mean: 3.0859966434392185\n",
      "resetting env. episode reward total was 12.0. running mean: 3.1751366770048266\n",
      "resetting env. episode reward total was 3.0. running mean: 3.173385310234778\n",
      "resetting env. episode reward total was 13.0. running mean: 3.27165145713243\n",
      "resetting env. episode reward total was 5.0. running mean: 3.2889349425611054\n",
      "resetting env. episode reward total was -4.0. running mean: 3.2160455931354943\n",
      "resetting env. episode reward total was 7.0. running mean: 3.253885137204139\n",
      "resetting env. episode reward total was 18.0. running mean: 3.4013462858320977\n",
      "resetting env. episode reward total was 5.0. running mean: 3.4173328229737767\n",
      "resetting env. episode reward total was 3.0. running mean: 3.413159494744039\n",
      "resetting env. episode reward total was 11.0. running mean: 3.489027899796598\n",
      "resetting env. episode reward total was 8.0. running mean: 3.5341376207986324\n",
      "resetting env. episode reward total was 5.0. running mean: 3.548796244590646\n",
      "resetting env. episode reward total was 9.0. running mean: 3.6033082821447393\n",
      "resetting env. episode reward total was 5.0. running mean: 3.617275199323292\n",
      "resetting env. episode reward total was 8.0. running mean: 3.661102447330059\n",
      "resetting env. episode reward total was 6.0. running mean: 3.6844914228567585\n",
      "resetting env. episode reward total was 5.0. running mean: 3.6976465086281904\n",
      "resetting env. episode reward total was 9.0. running mean: 3.7506700435419082\n",
      "resetting env. episode reward total was 3.0. running mean: 3.743163343106489\n",
      "resetting env. episode reward total was 7.0. running mean: 3.775731709675424\n",
      "resetting env. episode reward total was 7.0. running mean: 3.8079743925786698\n",
      "resetting env. episode reward total was 4.0. running mean: 3.809894648652883\n",
      "resetting env. episode reward total was -5.0. running mean: 3.721795702166354\n",
      "resetting env. episode reward total was 3.0. running mean: 3.71457774514469\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m### 2 up 3 down\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 更新为新的返回值\u001b[39;00m\n\u001b[1;32m     31\u001b[0m reward_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m     32\u001b[0m prev_x \u001b[38;5;241m=\u001b[39m current_x\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/mem0/lib/python3.10/site-packages/ale_py/env/gym.py:256\u001b[0m, in \u001b[0;36mAtariEnv.step\u001b[0;34m(self, action_ind)\u001b[0m\n\u001b[1;32m    254\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(frameskip):\n\u001b[0;32m--> 256\u001b[0m     reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43male\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m is_terminal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_over(with_truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    258\u001b[0m is_truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_truncated()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle  # 用 pickle 替代 cPickle\n",
    "import gym\n",
    "np.bool8 = np.bool_\n",
    "import gym\n",
    "\n",
    "env = gym.make(\"Pong-v4\")\n",
    "observation, _ = env.reset()\n",
    "\n",
    "def prepro(I):\n",
    "    \"\"\"将 210x160x3 uint8 帧预处理为 6400 (80x80) 1D float 向量\"\"\"\n",
    "    I = I[35:195]  # 裁剪\n",
    "    I = I[::2, ::2, 0]  # 下采样因子为 2\n",
    "    I[I == 144] = 0  # 删除背景类型 1\n",
    "    I[I == 109] = 0  # 删除背景类型 2\n",
    "    I[I != 0] = 1  # 其他设置为 1\n",
    "    return I.astype(np.float32).ravel()\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def policy_forward(x):\n",
    "    ### x: 6400\n",
    "    h = model['W1'] @ x\n",
    "    h[h<0] = 0\n",
    "    v = model['W2'] @ h\n",
    "    return h, sigmoid(v)\n",
    "\n",
    "\n",
    "def policy_backward(xs,logps,hs):\n",
    "    ### xs: N,D logps: N, hs: N,H\n",
    "    dW2 = logps @ hs\n",
    "    h1 = np.outer(logps,model['W2']) ### N,H\n",
    "    h1[hs <= 0] = 0\n",
    "    dW1 = h1.T @ xs ## H,N @ N,D  ## H,D \n",
    "    return {'W1':dW1,'W2':dW2}\n",
    "\n",
    "\n",
    "def discounted_rewards(rewards):\n",
    "    ans = np.zeros_like(rewards)\n",
    "    adding = 0\n",
    "    for t in reversed(range(len(rewards))):\n",
    "        if rewards[t] != 0:adding = 0\n",
    "        adding = adding * 0.99 + rewards[t]\n",
    "        ans[t] = adding\n",
    "    return ans\n",
    "\n",
    "model = {'W1':np.random.randn(H,D),'W2':np.random.randn(H)}\n",
    "model['W1'] = np.random.randn(H, D) / np.sqrt(D)  # \"Xavier\" 初始化\n",
    "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
    "\n",
    "observation, _ = env.reset()\n",
    "prev_x = None\n",
    "running_reward = None\n",
    "\n",
    "xs = []\n",
    "hs = []\n",
    "logps = []\n",
    "rewards = []\n",
    "lr = 1e-3\n",
    "total_sum = 0\n",
    "observation, _ = env.reset()\n",
    "reward_sum = 0\n",
    "episode_number = 0\n",
    "batch_size = 10\n",
    "decay_rate = 0.99\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# 更新缓存，用于 RMSProp 平滑梯度\n",
    "grad_buffer = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "rmsprop_cache = {k: np.zeros_like(v) for k, v in model.items()}\n",
    "\n",
    "\n",
    "while True:#### epoch\n",
    "    current_x = prepro(observation)\n",
    "    gap = np.zeros_like(current_x) if prev_x is None else current_x - prev_x\n",
    "    h,prob = policy_forward(gap)\n",
    "    action = 2 if  np.random.uniform() > prob else 3\n",
    "    y = 0 if action == 2 else 1\n",
    "    ### 2 up 3 down\n",
    "    observation, reward, terminated, truncated, info = env.step(action)  # 更新为新的返回值\n",
    "    reward_sum += reward\n",
    "    prev_x = current_x\n",
    "    logps.append(y-prob)\n",
    "    hs.append(h)\n",
    "    xs.append(gap)\n",
    "    rewards.append(reward)\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        episode_number += 1\n",
    "        ### 轮到一个batch后开始开始模型训练\n",
    "        xs = np.vstack(xs)\n",
    "        hs = np.vstack(hs)\n",
    "        logps = np.vstack(logps).ravel()\n",
    "        rewards = np.vstack(rewards).ravel()\n",
    "        dr = discounted_rewards(rewards)\n",
    "        dr = dr - dr.mean()\n",
    "        dr /= dr.std()\n",
    "        logps = logps * dr\n",
    "        grad = policy_backward(xs,logps,hs)\n",
    "\n",
    "#         ### 先用普通方法更新\n",
    "        for key,value in model.items():\n",
    "            model[key] += lr * grad[key]\n",
    "            \n",
    "                \n",
    "        #### 打印\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        print(f'resetting env. episode reward total was {reward_sum}. running mean: {running_reward}')\n",
    "        reward_sum = 0\n",
    "\n",
    "        #### 清空数据\n",
    "        xs = []\n",
    "        hs = []\n",
    "        logps = []\n",
    "        rewards = []\n",
    "        prev_x = None\n",
    "        total_sum = 0\n",
    "        observation, _ = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make(\"Pong-v4\")\n",
    "# observation, _ = env.reset()\n",
    "# prev_x = None  # 用于计算差分帧\n",
    "# xs, hs, dlogps, drs = [], [], [], []\n",
    "# running_reward = None\n",
    "# reward_sum = 0\n",
    "# episode_number = 0\n",
    "\n",
    "# while True:\n",
    "\n",
    "\n",
    "#     # 预处理观测，设定网络输入为差分图像\n",
    "#     cur_x = prepro(observation)\n",
    "#     x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "#     prev_x = cur_x\n",
    "\n",
    "#     # 前向传播并采样动作\n",
    "#     h,aprob = policy_forward(x)\n",
    "#     action = 2 if np.random.uniform() < aprob else 3  # 投掷骰子！\n",
    "\n",
    "#     # 记录中间变量（后续用于反向传播）\n",
    "#     xs.append(x)  # 观测值\n",
    "#     hs.append(h)  # 隐藏状态\n",
    "#     y = 1 if action == 2 else 0  # “伪标签”\n",
    "#     dlogps.append(y - aprob)  # 梯度鼓励采取的动作\n",
    "\n",
    "#     # 环境步进，获取新状态\n",
    "#     observation, reward, terminated, truncated, info = env.step(action)  # 更新为新的返回值\n",
    "#     reward_sum += reward\n",
    "\n",
    "#     drs.append(reward)  # 记录奖励\n",
    "\n",
    "#     if terminated or truncated:  # 一个回合结束\n",
    "#         episode_number += 1\n",
    "\n",
    "#         # 堆叠输入、隐藏状态、动作梯度和奖励\n",
    "#         epx = np.vstack(xs)\n",
    "#         eph = np.vstack(hs)\n",
    "#         epdlogp = np.vstack(dlogps)\n",
    "#         epr = np.vstack(drs)\n",
    "#         xs, hs, dlogps, drs = [], [], [], []  # 重置数组\n",
    "\n",
    "#         # 计算折扣奖励\n",
    "#         discounted_epr = discounted_rewards(epr)\n",
    "#         # 标准化奖励\n",
    "#         discounted_epr -= np.mean(discounted_epr)\n",
    "#         discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "#         epdlogp *= discounted_epr  # 使用优势调制梯度\n",
    "#         grad = policy_backward(epx,epdlogp,eph)\n",
    "#         for k in model: grad_buffer[k] += grad[k]  # 在 batch 中累积梯度\n",
    "\n",
    "#         # 每 batch_size 集执行 RMSProp 参数更新\n",
    "#         if episode_number % batch_size == 0:\n",
    "#             for k, v in model.items():\n",
    "#                 g = grad_buffer[k]\n",
    "#                 rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g ** 2\n",
    "#                 model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "#                 grad_buffer[k] = np.zeros_like(v)  # 重置 batch 梯度缓存\n",
    "\n",
    "#         # 记录\n",
    "#         running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "#         print(f'resetting env. episode reward total was {reward_sum}. running mean: {running_reward}')\n",
    "#         if episode_number % 100 == 0:\n",
    "#             with open('save.p', 'wb') as f:\n",
    "#                 pickle.dump(model, f)\n",
    "#         reward_sum = 0\n",
    "#         observation, _ = env.reset()\n",
    "#         prev_x = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a658f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
