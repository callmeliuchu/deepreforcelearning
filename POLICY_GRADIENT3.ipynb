{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "99fb453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle  # 用 pickle 替代 cPickle\n",
    "import gym\n",
    "np.bool8 = np.bool_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9fe38673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "59f34294",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pong-v4\")\n",
    "observation, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c9af8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(observation):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # 创建一个随机的 (210, 160, 3) 矩阵\n",
    "    image = observation\n",
    "    # image = prepro_1(observation)\n",
    "\n",
    "    # 使用 matplotlib 显示图像\n",
    "    plt.imshow(image)\n",
    "    # plt.axis('off')  # 隐藏坐标轴\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9b292b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "28b3033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(I):\n",
    "    \"\"\"将 210x160x3 uint8 帧预处理为 6400 (80x80) 1D float 向量\"\"\"\n",
    "    I = I[35:195]  # 裁剪\n",
    "    I = I[::2, ::2, 0]  # 下采样因子为 2\n",
    "    I[I == 144] = 0  # 删除背景类型 1\n",
    "    I[I == 109] = 0  # 删除背景类型 2\n",
    "    I[I != 0] = 1  # 其他设置为 1\n",
    "    return I.astype(np.float32).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f7bba3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 6400\n",
    "H = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "08a379da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "1f3b3305",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim,200,bias=False)\n",
    "        self.linear2 = nn.Linear(200,output_dim,bias=False)\n",
    "        \n",
    "       # Xavier 初始化 + 偏置归零\n",
    "        nn.init.xavier_normal_(self.linear1.weight)\n",
    "        nn.init.xavier_normal_(self.linear2.weight)\n",
    "\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "    def sample_action(self,x):\n",
    "        with torch.no_grad():\n",
    "            prob = self.forward(x)\n",
    "#             prob = torch.clamp(prob, min=1e-8, max=1-1e-8)  # 关键修复\n",
    "\n",
    "#             m = Bernoulli(prob)\n",
    "#             action = m.sample().item()  # 1 表示向上，0 表示向下\n",
    "#             return int(action) + 2\n",
    "        action = 2 if prob.item() < np.random.uniform() else 3\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b357c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards):\n",
    "    ans = np.zeros_like(rewards)\n",
    "    adding = 0\n",
    "    for t in reversed(range(len(rewards))):\n",
    "        if rewards[t] != 0:\n",
    "            adding = 0\n",
    "        adding = adding * 0.99 + rewards[t]\n",
    "        ans[t] = adding\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c8aa6232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(D,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "28e76c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import RMSprop\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "6859a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(model.parameters(), lr=0.001, alpha=0.99, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defeaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total -1.0\n",
      "total -6.0\n",
      "total -2.0\n",
      "total -8.0\n",
      "total -4.0\n",
      "total -6.0\n",
      "total -3.0\n",
      "total -9.0\n",
      "total 5.0\n",
      "total 3.0\n",
      "total -7.0\n",
      "total -6.0\n",
      "total -11.0\n",
      "total -9.0\n",
      "total -9.0\n",
      "total -13.0\n",
      "total -11.0\n",
      "total -12.0\n",
      "total 7.0\n",
      "total -11.0\n",
      "total 6.0\n",
      "total -7.0\n",
      "total -3.0\n",
      "total -10.0\n",
      "total 8.0\n",
      "total -9.0\n",
      "total -2.0\n",
      "total -1.0\n",
      "total -5.0\n",
      "total 10.0\n",
      "total -7.0\n",
      "total -3.0\n",
      "total -7.0\n",
      "total -3.0\n",
      "total -10.0\n",
      "total -9.0\n",
      "total -13.0\n",
      "total -9.0\n",
      "total -5.0\n",
      "total -9.0\n",
      "total -4.0\n",
      "total -9.0\n",
      "total 13.0\n",
      "total -11.0\n",
      "total 4.0\n",
      "total -9.0\n",
      "total -3.0\n",
      "total 3.0\n",
      "total -10.0\n",
      "total -6.0\n",
      "total -6.0\n",
      "total -11.0\n",
      "total -7.0\n",
      "total -15.0\n",
      "total -3.0\n",
      "total 8.0\n",
      "total -16.0\n",
      "total 5.0\n",
      "total 5.0\n",
      "total -3.0\n",
      "total -5.0\n",
      "total -10.0\n",
      "total 3.0\n",
      "total 1.0\n",
      "total 1.0\n",
      "total -9.0\n",
      "total -15.0\n",
      "total -3.0\n",
      "total 8.0\n",
      "total -10.0\n",
      "total -5.0\n",
      "total 7.0\n",
      "total 3.0\n",
      "total -8.0\n",
      "total -4.0\n",
      "total -1.0\n",
      "total -7.0\n",
      "total -8.0\n",
      "total -2.0\n",
      "total -9.0\n",
      "total -5.0\n",
      "total -7.0\n",
      "total -5.0\n",
      "total -7.0\n",
      "total -9.0\n",
      "total -7.0\n",
      "total 1.0\n",
      "total -7.0\n",
      "total -15.0\n",
      "total -10.0\n",
      "total -6.0\n",
      "total -4.0\n",
      "total 13.0\n",
      "total -11.0\n",
      "total -10.0\n",
      "total -5.0\n",
      "total -5.0\n",
      "total -1.0\n",
      "total -9.0\n",
      "total -16.0\n",
      "total -10.0\n",
      "total 4.0\n",
      "total -9.0\n",
      "total -9.0\n",
      "total -2.0\n",
      "total -13.0\n",
      "total 5.0\n",
      "total -3.0\n",
      "total -6.0\n",
      "total -3.0\n",
      "total -9.0\n",
      "total 6.0\n",
      "total -10.0\n",
      "total -7.0\n",
      "total -8.0\n",
      "total -15.0\n",
      "total -7.0\n",
      "total -6.0\n",
      "total -2.0\n",
      "total -3.0\n",
      "total -6.0\n",
      "total -17.0\n",
      "total -18.0\n",
      "total -8.0\n",
      "total -13.0\n",
      "total -4.0\n",
      "total -7.0\n",
      "total -10.0\n",
      "total -8.0\n",
      "total -8.0\n",
      "total -7.0\n",
      "total -3.0\n",
      "total 12.0\n",
      "total -8.0\n",
      "total -5.0\n",
      "total -9.0\n",
      "total -13.0\n",
      "total -4.0\n",
      "total 8.0\n",
      "total -15.0\n",
      "total -6.0\n",
      "total -3.0\n",
      "total -7.0\n",
      "total -13.0\n",
      "total -16.0\n",
      "total -5.0\n",
      "total 1.0\n",
      "total -13.0\n",
      "total 2.0\n",
      "total -6.0\n",
      "total -8.0\n",
      "total -6.0\n",
      "total -11.0\n",
      "total -13.0\n",
      "total -11.0\n",
      "total -1.0\n",
      "total -13.0\n",
      "total -9.0\n",
      "total -12.0\n",
      "total -9.0\n",
      "total -7.0\n",
      "total -2.0\n",
      "total 1.0\n",
      "total -12.0\n",
      "total -9.0\n",
      "total 2.0\n",
      "total -5.0\n",
      "total -6.0\n",
      "total -11.0\n",
      "total -3.0\n",
      "total 3.0\n",
      "total -12.0\n",
      "total -2.0\n",
      "total -4.0\n",
      "total -8.0\n",
      "total -8.0\n",
      "total 2.0\n",
      "total -4.0\n",
      "total -13.0\n",
      "total -12.0\n",
      "total -11.0\n",
      "total -6.0\n",
      "total -3.0\n",
      "total 1.0\n",
      "total 3.0\n",
      "total -11.0\n",
      "total -1.0\n",
      "total -1.0\n",
      "total -8.0\n",
      "total -10.0\n",
      "total -5.0\n",
      "total 15.0\n",
      "total 2.0\n",
      "total 1.0\n",
      "total -6.0\n",
      "total -2.0\n",
      "total -4.0\n",
      "total -12.0\n",
      "total 5.0\n",
      "total -5.0\n",
      "total -9.0\n",
      "total 2.0\n",
      "total -10.0\n",
      "total 1.0\n",
      "total -14.0\n",
      "total -1.0\n",
      "total -9.0\n",
      "total 7.0\n",
      "total -5.0\n",
      "total 3.0\n",
      "total -4.0\n",
      "total 2.0\n",
      "total -4.0\n",
      "total -2.0\n",
      "total -12.0\n",
      "total -3.0\n",
      "total -6.0\n",
      "total 7.0\n",
      "total -6.0\n",
      "total -13.0\n",
      "total -9.0\n",
      "total -2.0\n",
      "total -11.0\n",
      "total -12.0\n",
      "total -7.0\n",
      "total -14.0\n",
      "total -14.0\n",
      "total -6.0\n",
      "total 11.0\n",
      "total -9.0\n",
      "total -10.0\n",
      "total 1.0\n",
      "total -13.0\n",
      "total 4.0\n",
      "total -5.0\n",
      "total -15.0\n",
      "total -5.0\n",
      "total 6.0\n",
      "total -5.0\n",
      "total -10.0\n",
      "total -5.0\n",
      "total -10.0\n",
      "total -9.0\n",
      "total -3.0\n",
      "total -7.0\n",
      "total 8.0\n",
      "total -2.0\n",
      "total -1.0\n",
      "total -1.0\n",
      "total -1.0\n",
      "total -12.0\n",
      "total -11.0\n",
      "total -11.0\n",
      "total -7.0\n",
      "total 2.0\n",
      "total 1.0\n",
      "total -7.0\n",
      "total -3.0\n",
      "total -9.0\n",
      "total -3.0\n",
      "total -7.0\n",
      "total -13.0\n",
      "total -15.0\n",
      "total -7.0\n",
      "total -9.0\n",
      "total -10.0\n",
      "total -10.0\n",
      "total -15.0\n",
      "total -12.0\n",
      "total -5.0\n",
      "total -11.0\n",
      "total -5.0\n",
      "total -11.0\n",
      "total -6.0\n",
      "total -10.0\n",
      "total 2.0\n",
      "total -13.0\n",
      "total -8.0\n",
      "total -12.0\n",
      "total -2.0\n",
      "total -10.0\n",
      "total -9.0\n",
      "total -6.0\n",
      "total -10.0\n",
      "total 1.0\n",
      "total -6.0\n",
      "total -5.0\n",
      "total -17.0\n",
      "total -12.0\n",
      "total -14.0\n",
      "total -5.0\n",
      "total -7.0\n",
      "total -8.0\n",
      "total 3.0\n",
      "total -9.0\n",
      "total 10.0\n",
      "total -2.0\n",
      "total -4.0\n",
      "total -5.0\n",
      "total -12.0\n",
      "total 1.0\n",
      "total -13.0\n",
      "total -11.0\n",
      "total -13.0\n",
      "total -5.0\n",
      "total 2.0\n",
      "total -7.0\n",
      "total -1.0\n",
      "total -10.0\n",
      "total 5.0\n",
      "total -9.0\n",
      "total -9.0\n",
      "total -7.0\n",
      "total 1.0\n",
      "total 6.0\n",
      "total 2.0\n",
      "total -4.0\n",
      "total -4.0\n",
      "total -1.0\n",
      "total -6.0\n",
      "total -7.0\n",
      "total -14.0\n",
      "total -5.0\n",
      "total 3.0\n",
      "total -1.0\n",
      "total -6.0\n",
      "total -5.0\n",
      "total -4.0\n",
      "total 4.0\n",
      "total -5.0\n",
      "total -1.0\n",
      "total 10.0\n",
      "total -1.0\n",
      "total -4.0\n",
      "total -6.0\n",
      "total -7.0\n",
      "total -3.0\n",
      "total -6.0\n",
      "total -8.0\n",
      "total -13.0\n",
      "total 4.0\n",
      "total -1.0\n",
      "total -6.0\n",
      "total -5.0\n",
      "total -6.0\n",
      "total -5.0\n",
      "total 6.0\n",
      "total -8.0\n",
      "total 2.0\n",
      "total -1.0\n",
      "total 9.0\n",
      "total 8.0\n",
      "total 2.0\n",
      "total -3.0\n",
      "total -5.0\n",
      "total 1.0\n",
      "total -8.0\n",
      "total -1.0\n",
      "total -1.0\n",
      "total -3.0\n",
      "total 10.0\n",
      "total 6.0\n",
      "total 6.0\n",
      "total 4.0\n",
      "total 5.0\n",
      "total -7.0\n",
      "total -7.0\n",
      "total -9.0\n",
      "total 3.0\n",
      "total -7.0\n",
      "total -1.0\n",
      "total -7.0\n",
      "total -13.0\n",
      "total -11.0\n",
      "total 8.0\n",
      "total -7.0\n",
      "total -4.0\n",
      "total 7.0\n",
      "total 2.0\n",
      "total 1.0\n",
      "total -6.0\n",
      "total -7.0\n",
      "total -5.0\n",
      "total -9.0\n",
      "total 3.0\n",
      "total -10.0\n",
      "total -12.0\n",
      "total -10.0\n",
      "total -12.0\n",
      "total 10.0\n",
      "total -5.0\n",
      "total 5.0\n",
      "total -17.0\n",
      "total 5.0\n",
      "total 7.0\n",
      "total -8.0\n",
      "total -9.0\n",
      "total 7.0\n",
      "total -6.0\n",
      "total -3.0\n",
      "total -5.0\n",
      "total -5.0\n",
      "total -11.0\n",
      "total -8.0\n",
      "total -7.0\n",
      "total -5.0\n",
      "total 3.0\n",
      "total -6.0\n",
      "total 2.0\n",
      "total -2.0\n",
      "total -9.0\n",
      "total 2.0\n",
      "total 3.0\n",
      "total -9.0\n",
      "total 5.0\n",
      "total -1.0\n",
      "total -7.0\n",
      "total -7.0\n",
      "total -1.0\n",
      "total -7.0\n",
      "total -9.0\n",
      "total -6.0\n",
      "total 9.0\n",
      "total -9.0\n",
      "total 3.0\n",
      "total -5.0\n",
      "total -10.0\n",
      "total -1.0\n",
      "total -5.0\n",
      "total -9.0\n",
      "total 1.0\n",
      "total 4.0\n",
      "total 5.0\n",
      "total 1.0\n",
      "total -5.0\n",
      "total 1.0\n",
      "total 7.0\n",
      "total 12.0\n",
      "total 3.0\n",
      "total -3.0\n",
      "total 4.0\n",
      "total 2.0\n",
      "total -2.0\n",
      "total 1.0\n",
      "total 4.0\n",
      "total -7.0\n",
      "total 2.0\n",
      "total -4.0\n",
      "total -3.0\n",
      "total -11.0\n",
      "total -1.0\n",
      "total -8.0\n",
      "total -9.0\n",
      "total -7.0\n",
      "total -13.0\n",
      "total -1.0\n",
      "total 4.0\n",
      "total -15.0\n",
      "total 9.0\n",
      "total 13.0\n",
      "total -11.0\n",
      "total -3.0\n",
      "total -7.0\n",
      "total 12.0\n",
      "total -6.0\n",
      "total -12.0\n",
      "total -5.0\n",
      "total 13.0\n",
      "total -10.0\n",
      "total 5.0\n",
      "total 11.0\n",
      "total 3.0\n",
      "total -5.0\n",
      "total 2.0\n",
      "total -9.0\n",
      "total 7.0\n",
      "total 9.0\n",
      "total -6.0\n",
      "total -2.0\n",
      "total 1.0\n",
      "total 1.0\n",
      "total -5.0\n",
      "total 1.0\n",
      "total -7.0\n",
      "total -4.0\n",
      "total -9.0\n",
      "total -5.0\n",
      "total -2.0\n",
      "total -11.0\n",
      "total -6.0\n",
      "total 3.0\n",
      "total -4.0\n",
      "total -7.0\n",
      "total -6.0\n",
      "total -3.0\n",
      "total -5.0\n",
      "total -9.0\n",
      "total -10.0\n",
      "total -5.0\n",
      "total -4.0\n",
      "total -10.0\n",
      "total -5.0\n",
      "total -6.0\n",
      "total -10.0\n",
      "total -8.0\n",
      "total -3.0\n",
      "total 6.0\n",
      "total 1.0\n",
      "total -8.0\n",
      "total 8.0\n",
      "total -11.0\n",
      "total 6.0\n",
      "total 9.0\n",
      "total 5.0\n",
      "total -8.0\n",
      "total 4.0\n",
      "total 1.0\n",
      "total 8.0\n",
      "total -5.0\n",
      "total -1.0\n",
      "total -9.0\n",
      "total 4.0\n",
      "total 1.0\n",
      "total -9.0\n",
      "total 2.0\n",
      "total -7.0\n",
      "total -4.0\n",
      "total -2.0\n",
      "total -6.0\n",
      "total 5.0\n",
      "total -3.0\n",
      "total 10.0\n",
      "total 8.0\n",
      "total 5.0\n",
      "total 4.0\n",
      "total -1.0\n",
      "total -4.0\n",
      "total 8.0\n",
      "total -2.0\n",
      "total -8.0\n",
      "total 2.0\n",
      "total -2.0\n",
      "total 3.0\n",
      "total 7.0\n",
      "total 1.0\n",
      "total 4.0\n",
      "total 1.0\n",
      "total 7.0\n",
      "total -8.0\n",
      "total 2.0\n",
      "total -15.0\n",
      "total 3.0\n",
      "total 9.0\n",
      "total -5.0\n",
      "total 2.0\n",
      "total -7.0\n",
      "total 3.0\n",
      "total -6.0\n",
      "total 2.0\n",
      "total 3.0\n",
      "total -6.0\n",
      "total -16.0\n",
      "total -5.0\n",
      "total 2.0\n",
      "total -2.0\n",
      "total 1.0\n",
      "total -3.0\n",
      "total -13.0\n",
      "total -3.0\n",
      "total 8.0\n",
      "total 2.0\n",
      "total -12.0\n",
      "total -13.0\n",
      "total 4.0\n",
      "total 1.0\n",
      "total -15.0\n",
      "total -7.0\n",
      "total 5.0\n",
      "total 9.0\n",
      "total 8.0\n",
      "total -14.0\n",
      "total -5.0\n",
      "total 7.0\n",
      "total 4.0\n",
      "total 9.0\n",
      "total -5.0\n",
      "total 6.0\n",
      "total -7.0\n",
      "total -1.0\n",
      "total -10.0\n",
      "total 6.0\n",
      "total 9.0\n",
      "total -2.0\n",
      "total -11.0\n",
      "total 5.0\n",
      "total -5.0\n",
      "total 4.0\n",
      "total 5.0\n",
      "total -1.0\n",
      "total -11.0\n",
      "total 1.0\n",
      "total -5.0\n",
      "total 7.0\n",
      "total 2.0\n",
      "total 2.0\n",
      "total -2.0\n",
      "total 1.0\n",
      "total -3.0\n",
      "total -3.0\n",
      "total 2.0\n",
      "total 6.0\n",
      "total 6.0\n",
      "total -1.0\n",
      "total -6.0\n",
      "total 1.0\n",
      "total -11.0\n",
      "total 4.0\n",
      "total -12.0\n",
      "total -1.0\n",
      "total 6.0\n",
      "total 3.0\n",
      "total 4.0\n",
      "total 7.0\n",
      "total 6.0\n",
      "total -6.0\n",
      "total 1.0\n",
      "total 2.0\n",
      "total 2.0\n",
      "total 1.0\n",
      "total -5.0\n",
      "total -7.0\n",
      "total 10.0\n",
      "total 2.0\n",
      "total 3.0\n",
      "total 5.0\n",
      "total 6.0\n",
      "total -4.0\n",
      "total 1.0\n",
      "total -4.0\n",
      "total -9.0\n",
      "total 12.0\n",
      "total 1.0\n",
      "total -1.0\n",
      "total -4.0\n",
      "total -7.0\n",
      "total -4.0\n",
      "total 7.0\n",
      "total -5.0\n",
      "total -8.0\n",
      "total -3.0\n",
      "total -8.0\n",
      "total 3.0\n",
      "total 8.0\n",
      "total -12.0\n",
      "total -13.0\n",
      "total 14.0\n",
      "total -7.0\n",
      "total -3.0\n",
      "total 4.0\n",
      "total -1.0\n",
      "total 11.0\n",
      "total -1.0\n",
      "total -5.0\n",
      "total -12.0\n",
      "total 5.0\n",
      "total 4.0\n",
      "total -6.0\n",
      "total -6.0\n",
      "total -7.0\n",
      "total -7.0\n",
      "total -7.0\n",
      "total -4.0\n",
      "total 7.0\n",
      "total -7.0\n",
      "total -1.0\n",
      "total -3.0\n",
      "total -3.0\n",
      "total -1.0\n",
      "total -8.0\n",
      "total 12.0\n",
      "total -3.0\n",
      "total 1.0\n",
      "total 6.0\n",
      "total -1.0\n",
      "total 9.0\n",
      "total 2.0\n",
      "total -3.0\n",
      "total 10.0\n",
      "total 2.0\n",
      "total -7.0\n",
      "total 9.0\n",
      "total -7.0\n",
      "total -6.0\n",
      "total 9.0\n",
      "total 1.0\n",
      "total -7.0\n",
      "total 3.0\n",
      "total -8.0\n",
      "total -11.0\n",
      "total 8.0\n",
      "total 7.0\n",
      "total -3.0\n",
      "total 1.0\n",
      "total -4.0\n",
      "total -7.0\n",
      "total 4.0\n",
      "total 10.0\n",
      "total -9.0\n",
      "total 3.0\n",
      "total -1.0\n",
      "total 1.0\n",
      "total 4.0\n",
      "total -2.0\n",
      "total -7.0\n",
      "total -5.0\n",
      "total 6.0\n",
      "total -3.0\n",
      "total 5.0\n",
      "total 5.0\n",
      "total 6.0\n",
      "total -5.0\n",
      "total 4.0\n",
      "total 1.0\n",
      "total -1.0\n",
      "total 9.0\n",
      "total -1.0\n",
      "total 7.0\n",
      "total 7.0\n",
      "total 3.0\n",
      "total -7.0\n",
      "total 8.0\n",
      "total 10.0\n",
      "total -5.0\n",
      "total 4.0\n",
      "total 12.0\n",
      "total 4.0\n",
      "total -3.0\n",
      "total -1.0\n",
      "total 2.0\n",
      "total -7.0\n",
      "total 6.0\n",
      "total 2.0\n",
      "total -9.0\n",
      "total -7.0\n",
      "total -2.0\n",
      "total 6.0\n",
      "total -5.0\n",
      "total -8.0\n",
      "total -7.0\n",
      "total 2.0\n",
      "total 2.0\n",
      "total -7.0\n",
      "total 14.0\n",
      "total 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9.0\n",
      "total 4.0\n",
      "total 4.0\n",
      "total 5.0\n",
      "total -6.0\n",
      "total 6.0\n",
      "total 5.0\n",
      "total 4.0\n",
      "total 5.0\n",
      "total 2.0\n",
      "total -13.0\n",
      "total 9.0\n",
      "total 11.0\n",
      "total -5.0\n",
      "total 1.0\n",
      "total 1.0\n",
      "total -1.0\n",
      "total 3.0\n",
      "total -9.0\n",
      "total -2.0\n",
      "total 6.0\n",
      "total -2.0\n",
      "total 10.0\n",
      "total 5.0\n",
      "total -1.0\n",
      "total -3.0\n",
      "total 6.0\n",
      "total -2.0\n",
      "total -6.0\n",
      "total 1.0\n",
      "total 11.0\n",
      "total 8.0\n",
      "total 8.0\n",
      "total 2.0\n",
      "total 8.0\n",
      "total -3.0\n",
      "total 9.0\n",
      "total 4.0\n",
      "total 4.0\n",
      "total 5.0\n",
      "total 10.0\n",
      "total 5.0\n",
      "total -4.0\n",
      "total 2.0\n",
      "total -2.0\n",
      "total 10.0\n",
      "total 11.0\n",
      "total 7.0\n",
      "total 7.0\n",
      "total 7.0\n",
      "total -4.0\n",
      "total -3.0\n",
      "total -9.0\n",
      "total 5.0\n",
      "total -11.0\n",
      "total -10.0\n",
      "total 4.0\n",
      "total 6.0\n",
      "total -7.0\n",
      "total -5.0\n",
      "total -9.0\n",
      "total 3.0\n",
      "total -3.0\n",
      "total 1.0\n",
      "total -12.0\n",
      "total -2.0\n",
      "total -13.0\n",
      "total -7.0\n",
      "total 3.0\n",
      "total 4.0\n",
      "total -8.0\n",
      "total 6.0\n",
      "total -3.0\n",
      "total 1.0\n",
      "total -4.0\n",
      "total 1.0\n",
      "total 8.0\n",
      "total 7.0\n",
      "total -5.0\n",
      "total 9.0\n",
      "total 1.0\n",
      "total -4.0\n",
      "total -9.0\n",
      "total 2.0\n",
      "total -3.0\n",
      "total 2.0\n",
      "total 4.0\n",
      "total 8.0\n",
      "total -9.0\n",
      "total -6.0\n",
      "total -7.0\n",
      "total -11.0\n",
      "total 9.0\n",
      "total 5.0\n",
      "total 2.0\n",
      "total -2.0\n",
      "total 10.0\n",
      "total 14.0\n",
      "total 2.0\n",
      "total -3.0\n",
      "total 17.0\n",
      "total 13.0\n",
      "total 6.0\n",
      "total -12.0\n",
      "total 1.0\n",
      "total 13.0\n",
      "total -1.0\n",
      "total 5.0\n",
      "total 9.0\n",
      "total 1.0\n",
      "total 11.0\n",
      "total -5.0\n",
      "total -5.0\n",
      "total 3.0\n",
      "total -1.0\n",
      "total -3.0\n",
      "total 9.0\n",
      "total 4.0\n",
      "total 8.0\n",
      "total -7.0\n",
      "total 7.0\n",
      "total 4.0\n",
      "total -7.0\n",
      "total -2.0\n",
      "total 8.0\n",
      "total 7.0\n",
      "total 3.0\n",
      "total 6.0\n",
      "total 12.0\n",
      "total 13.0\n",
      "total -3.0\n",
      "total 12.0\n",
      "total -3.0\n",
      "total -4.0\n",
      "total 3.0\n",
      "total 10.0\n",
      "total 10.0\n",
      "total 7.0\n",
      "total 11.0\n",
      "total -2.0\n",
      "total -3.0\n",
      "total 9.0\n",
      "total 7.0\n",
      "total 4.0\n",
      "total 9.0\n",
      "total 6.0\n",
      "total 4.0\n",
      "total -3.0\n",
      "total 6.0\n",
      "total 9.0\n",
      "total 5.0\n",
      "total 7.0\n",
      "total 12.0\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions import Bernoulli\n",
    "\n",
    "observation, _ = env.reset()\n",
    "episode_number = 0\n",
    "prev_x = None\n",
    "xs = []\n",
    "logps = []\n",
    "hs = []\n",
    "ys = []\n",
    "rewards = []\n",
    "train_time = 0\n",
    "total_sum = 0\n",
    "while True:\n",
    "    current_x = prepro(observation)\n",
    "    gap = np.zeros_like(current_x) if prev_x is None else current_x - prev_x\n",
    "#     h,p = policy_forward(gap)\n",
    "    action = model.sample_action(torch.from_numpy(gap))\n",
    "#     print(action)\n",
    "    y = 0.0 if action == 2 else 1.0\n",
    "    observation, reward, terminated, truncated, info = env.step(action)  # 更新为新的返回值\n",
    "    prev_x = current_x\n",
    "    rewards.append(reward)\n",
    "    xs.append(gap)\n",
    "    ys.append(y)\n",
    "    total_sum += reward\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        episode_number += 1\n",
    "        xs = np.vstack(xs)\n",
    "        ys = np.vstack(ys).ravel()\n",
    "        rewards = np.vstack(rewards).ravel()\n",
    "        rewards = discount_rewards(rewards)\n",
    "        rewards -= rewards.mean()\n",
    "        rewards /= (rewards.std()+ EPS)\n",
    "\n",
    "        rewards = torch.FloatTensor(rewards)\n",
    "        xs = torch.FloatTensor(xs)\n",
    "        ys = torch.FloatTensor(ys)\n",
    "        \n",
    "        ps = model(xs)\n",
    "        ps = model(xs).squeeze()\n",
    "#         print(ps.shape,ys.shape)\n",
    "\n",
    "        # 防止概率为0或1导致log计算爆炸\n",
    "        logps = torch.log(ys * ps + (1.0-ys) *(1.0-ps))\n",
    "#         print(logps)\n",
    "        loss = -(logps * rewards).mean()\n",
    "#         print('loss',loss,len(rewards),sum(rewards),sum(logps))\n",
    "        \n",
    "        #### \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        \n",
    "        print('total',total_sum)\n",
    "        \n",
    "        xs = []\n",
    "        rewards = []\n",
    "        logps = []\n",
    "        hs = []\n",
    "        ys = []\n",
    "        prev_x = None\n",
    "        total_sum = 0\n",
    "        observation, _ = env.reset()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in model.parameters():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b41ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007287ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem0",
   "language": "python",
   "name": "mem0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
